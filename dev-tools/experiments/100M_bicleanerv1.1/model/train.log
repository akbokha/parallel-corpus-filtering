[2019-06-16 09:03:40] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-06-16 09:03:40] [marian] Running on baldur as process 66425 with command line:
[2019-06-16 09:03:40] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model experiments/100M_bicleanerv1.1/model/model.npz -T . --devices 1 --train-sets experiments/100M_bicleanerv1.1/data/train.bpe.de experiments/100M_bicleanerv1.1/data/train.bpe.en --vocabs experiments/100M_bicleanerv1.1/data/train.bpe.de.json experiments/100M_bicleanerv1.1/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets experiments/100M_bicleanerv1.1/data/dev.bpe.de experiments/100M_bicleanerv1.1/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output experiments/100M_bicleanerv1.1/model/dev.out --valid-script-path ./score-dev_exp.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log experiments/100M_bicleanerv1.1/model/train.log --valid-log experiments/100M_bicleanerv1.1/model/valid.log
[2019-06-16 09:03:40] [config] after-batches: 0
[2019-06-16 09:03:40] [config] after-epochs: 0
[2019-06-16 09:03:40] [config] allow-unk: false
[2019-06-16 09:03:40] [config] beam-size: 12
[2019-06-16 09:03:40] [config] bert-class-symbol: "[CLS]"
[2019-06-16 09:03:40] [config] bert-mask-symbol: "[MASK]"
[2019-06-16 09:03:40] [config] bert-masking-fraction: 0.15
[2019-06-16 09:03:40] [config] bert-sep-symbol: "[SEP]"
[2019-06-16 09:03:40] [config] bert-train-type-embeddings: true
[2019-06-16 09:03:40] [config] bert-type-vocab-size: 2
[2019-06-16 09:03:40] [config] best-deep: false
[2019-06-16 09:03:40] [config] clip-gemm: 0
[2019-06-16 09:03:40] [config] clip-norm: 1
[2019-06-16 09:03:40] [config] cost-type: ce-mean
[2019-06-16 09:03:40] [config] cpu-threads: 0
[2019-06-16 09:03:40] [config] data-weighting: ""
[2019-06-16 09:03:40] [config] data-weighting-type: sentence
[2019-06-16 09:03:40] [config] dec-cell: gru
[2019-06-16 09:03:40] [config] dec-cell-base-depth: 2
[2019-06-16 09:03:40] [config] dec-cell-high-depth: 1
[2019-06-16 09:03:40] [config] dec-depth: 1
[2019-06-16 09:03:40] [config] devices:
[2019-06-16 09:03:40] [config]   - 1
[2019-06-16 09:03:40] [config] dim-emb: 512
[2019-06-16 09:03:40] [config] dim-rnn: 1024
[2019-06-16 09:03:40] [config] dim-vocabs:
[2019-06-16 09:03:40] [config]   - 50000
[2019-06-16 09:03:40] [config]   - 50000
[2019-06-16 09:03:40] [config] disp-first: 0
[2019-06-16 09:03:40] [config] disp-freq: 2000
[2019-06-16 09:03:40] [config] disp-label-counts: false
[2019-06-16 09:03:40] [config] dropout-rnn: 0.2
[2019-06-16 09:03:40] [config] dropout-src: 0.1
[2019-06-16 09:03:40] [config] dropout-trg: 0.1
[2019-06-16 09:03:40] [config] dump-config: ""
[2019-06-16 09:03:40] [config] early-stopping: 5
[2019-06-16 09:03:40] [config] embedding-fix-src: false
[2019-06-16 09:03:40] [config] embedding-fix-trg: false
[2019-06-16 09:03:40] [config] embedding-normalization: false
[2019-06-16 09:03:40] [config] embedding-vectors:
[2019-06-16 09:03:40] [config]   []
[2019-06-16 09:03:40] [config] enc-cell: gru
[2019-06-16 09:03:40] [config] enc-cell-depth: 1
[2019-06-16 09:03:40] [config] enc-depth: 1
[2019-06-16 09:03:40] [config] enc-type: bidirectional
[2019-06-16 09:03:40] [config] exponential-smoothing: 0.0001
[2019-06-16 09:03:40] [config] grad-dropping-momentum: 0
[2019-06-16 09:03:40] [config] grad-dropping-rate: 0
[2019-06-16 09:03:40] [config] grad-dropping-warmup: 100
[2019-06-16 09:03:40] [config] guided-alignment: none
[2019-06-16 09:03:40] [config] guided-alignment-cost: mse
[2019-06-16 09:03:40] [config] guided-alignment-weight: 0.1
[2019-06-16 09:03:40] [config] ignore-model-config: false
[2019-06-16 09:03:40] [config] input-types:
[2019-06-16 09:03:40] [config]   []
[2019-06-16 09:03:40] [config] interpolate-env-vars: false
[2019-06-16 09:03:40] [config] keep-best: false
[2019-06-16 09:03:40] [config] label-smoothing: 0
[2019-06-16 09:03:40] [config] layer-normalization: true
[2019-06-16 09:03:40] [config] learn-rate: 0.0001
[2019-06-16 09:03:40] [config] log: experiments/100M_bicleanerv1.1/model/train.log
[2019-06-16 09:03:40] [config] log-level: info
[2019-06-16 09:03:40] [config] log-time-zone: ""
[2019-06-16 09:03:40] [config] lr-decay: 0
[2019-06-16 09:03:40] [config] lr-decay-freq: 50000
[2019-06-16 09:03:40] [config] lr-decay-inv-sqrt:
[2019-06-16 09:03:40] [config]   - 0
[2019-06-16 09:03:40] [config] lr-decay-repeat-warmup: false
[2019-06-16 09:03:40] [config] lr-decay-reset-optimizer: false
[2019-06-16 09:03:40] [config] lr-decay-start:
[2019-06-16 09:03:40] [config]   - 10
[2019-06-16 09:03:40] [config]   - 1
[2019-06-16 09:03:40] [config] lr-decay-strategy: epoch+stalled
[2019-06-16 09:03:40] [config] lr-report: false
[2019-06-16 09:03:40] [config] lr-warmup: 0
[2019-06-16 09:03:40] [config] lr-warmup-at-reload: false
[2019-06-16 09:03:40] [config] lr-warmup-cycle: false
[2019-06-16 09:03:40] [config] lr-warmup-start-rate: 0
[2019-06-16 09:03:40] [config] max-length: 50
[2019-06-16 09:03:40] [config] max-length-crop: false
[2019-06-16 09:03:40] [config] max-length-factor: 3
[2019-06-16 09:03:40] [config] maxi-batch: 100
[2019-06-16 09:03:40] [config] maxi-batch-sort: trg
[2019-06-16 09:03:40] [config] mini-batch: 64
[2019-06-16 09:03:40] [config] mini-batch-fit: true
[2019-06-16 09:03:40] [config] mini-batch-fit-step: 10
[2019-06-16 09:03:40] [config] mini-batch-overstuff: 1
[2019-06-16 09:03:40] [config] mini-batch-track-lr: false
[2019-06-16 09:03:40] [config] mini-batch-understuff: 1
[2019-06-16 09:03:40] [config] mini-batch-warmup: 0
[2019-06-16 09:03:40] [config] mini-batch-words: 0
[2019-06-16 09:03:40] [config] mini-batch-words-ref: 0
[2019-06-16 09:03:40] [config] model: experiments/100M_bicleanerv1.1/model/model.npz
[2019-06-16 09:03:40] [config] multi-loss-type: sum
[2019-06-16 09:03:40] [config] multi-node: false
[2019-06-16 09:03:40] [config] multi-node-overlap: true
[2019-06-16 09:03:40] [config] n-best: false
[2019-06-16 09:03:40] [config] no-nccl: false
[2019-06-16 09:03:40] [config] no-reload: false
[2019-06-16 09:03:40] [config] no-restore-corpus: false
[2019-06-16 09:03:40] [config] no-shuffle: false
[2019-06-16 09:03:40] [config] normalize: 1
[2019-06-16 09:03:40] [config] num-devices: 0
[2019-06-16 09:03:40] [config] optimizer: adam
[2019-06-16 09:03:40] [config] optimizer-delay: 1
[2019-06-16 09:03:40] [config] optimizer-params:
[2019-06-16 09:03:40] [config]   []
[2019-06-16 09:03:40] [config] overwrite: false
[2019-06-16 09:03:40] [config] pretrained-model: ""
[2019-06-16 09:03:40] [config] quiet: false
[2019-06-16 09:03:40] [config] quiet-translation: true
[2019-06-16 09:03:40] [config] relative-paths: false
[2019-06-16 09:03:40] [config] right-left: false
[2019-06-16 09:03:40] [config] save-freq: 20000
[2019-06-16 09:03:40] [config] seed: 1111
[2019-06-16 09:03:40] [config] shuffle-in-ram: false
[2019-06-16 09:03:40] [config] skip: false
[2019-06-16 09:03:40] [config] sqlite: ""
[2019-06-16 09:03:40] [config] sqlite-drop: false
[2019-06-16 09:03:40] [config] sync-sgd: true
[2019-06-16 09:03:40] [config] tempdir: .
[2019-06-16 09:03:40] [config] tied-embeddings: false
[2019-06-16 09:03:40] [config] tied-embeddings-all: false
[2019-06-16 09:03:40] [config] tied-embeddings-src: false
[2019-06-16 09:03:40] [config] train-sets:
[2019-06-16 09:03:40] [config]   - experiments/100M_bicleanerv1.1/data/train.bpe.de
[2019-06-16 09:03:40] [config]   - experiments/100M_bicleanerv1.1/data/train.bpe.en
[2019-06-16 09:03:40] [config] transformer-aan-activation: swish
[2019-06-16 09:03:40] [config] transformer-aan-depth: 2
[2019-06-16 09:03:40] [config] transformer-aan-nogate: false
[2019-06-16 09:03:40] [config] transformer-decoder-autoreg: self-attention
[2019-06-16 09:03:40] [config] transformer-dim-aan: 2048
[2019-06-16 09:03:40] [config] transformer-dim-ffn: 2048
[2019-06-16 09:03:40] [config] transformer-dropout: 0
[2019-06-16 09:03:40] [config] transformer-dropout-attention: 0
[2019-06-16 09:03:40] [config] transformer-dropout-ffn: 0
[2019-06-16 09:03:40] [config] transformer-ffn-activation: swish
[2019-06-16 09:03:40] [config] transformer-ffn-depth: 2
[2019-06-16 09:03:40] [config] transformer-guided-alignment-layer: last
[2019-06-16 09:03:40] [config] transformer-heads: 8
[2019-06-16 09:03:40] [config] transformer-no-projection: false
[2019-06-16 09:03:40] [config] transformer-postprocess: dan
[2019-06-16 09:03:40] [config] transformer-postprocess-emb: d
[2019-06-16 09:03:40] [config] transformer-preprocess: ""
[2019-06-16 09:03:40] [config] transformer-tied-layers:
[2019-06-16 09:03:40] [config]   []
[2019-06-16 09:03:40] [config] transformer-train-position-embeddings: false
[2019-06-16 09:03:40] [config] type: amun
[2019-06-16 09:03:40] [config] ulr: false
[2019-06-16 09:03:40] [config] ulr-dim-emb: 0
[2019-06-16 09:03:40] [config] ulr-dropout: 0
[2019-06-16 09:03:40] [config] ulr-keys-vectors: ""
[2019-06-16 09:03:40] [config] ulr-query-vectors: ""
[2019-06-16 09:03:40] [config] ulr-softmax-temperature: 1
[2019-06-16 09:03:40] [config] ulr-trainable-transformation: false
[2019-06-16 09:03:40] [config] valid-freq: 20000
[2019-06-16 09:03:40] [config] valid-log: experiments/100M_bicleanerv1.1/model/valid.log
[2019-06-16 09:03:40] [config] valid-max-length: 1000
[2019-06-16 09:03:40] [config] valid-metrics:
[2019-06-16 09:03:40] [config]   - cross-entropy
[2019-06-16 09:03:40] [config]   - perplexity
[2019-06-16 09:03:40] [config]   - translation
[2019-06-16 09:03:40] [config] valid-mini-batch: 8
[2019-06-16 09:03:40] [config] valid-script-path: ./score-dev_exp.sh
[2019-06-16 09:03:40] [config] valid-sets:
[2019-06-16 09:03:40] [config]   - experiments/100M_bicleanerv1.1/data/dev.bpe.de
[2019-06-16 09:03:40] [config]   - experiments/100M_bicleanerv1.1/data/dev.bpe.en
[2019-06-16 09:03:40] [config] valid-translation-output: experiments/100M_bicleanerv1.1/model/dev.out
[2019-06-16 09:03:40] [config] vocabs:
[2019-06-16 09:03:40] [config]   - experiments/100M_bicleanerv1.1/data/train.bpe.de.json
[2019-06-16 09:03:40] [config]   - experiments/100M_bicleanerv1.1/data/train.bpe.en.json
[2019-06-16 09:03:40] [config] word-penalty: 0
[2019-06-16 09:03:40] [config] workspace: 3000
[2019-06-16 09:03:40] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-06-16 09:03:40] Using synchronous training
[2019-06-16 09:03:40] [data] Loading vocabulary from JSON/Yaml file experiments/100M_bicleanerv1.1/data/train.bpe.de.json
[2019-06-16 09:03:41] [data] Using unused word id eos for 0
[2019-06-16 09:03:41] [data] Using unused word id UNK for 1
[2019-06-16 09:03:41] [data] Setting vocabulary size for input 0 to 50000
[2019-06-16 09:03:41] [data] Loading vocabulary from JSON/Yaml file experiments/100M_bicleanerv1.1/data/train.bpe.en.json
[2019-06-16 09:03:41] [data] Using unused word id eos for 0
[2019-06-16 09:03:41] [data] Using unused word id UNK for 1
[2019-06-16 09:03:41] [data] Setting vocabulary size for input 1 to 50000
[2019-06-16 09:03:41] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-06-16 09:03:41] [batching] Collecting statistics for batch fitting with step size 10
[2019-06-16 09:03:41] [memory] Extending reserved space to 3072 MB (device gpu1)
[2019-06-16 09:03:42] [comm] Using NCCL 2.4.2 for GPU communication
[2019-06-16 09:03:42] [comm] NCCLCommunicator constructed successfully.
[2019-06-16 09:03:42] [training] Using 1 GPUs
[2019-06-16 09:03:42] [memory] Reserving 422 MB, device gpu1
[2019-06-16 09:03:42] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-06-16 09:03:42] [memory] Reserving 422 MB, device gpu1
[2019-06-16 09:03:49] [batching] Done. Typical MB size is 4042 target words
[2019-06-16 09:03:50] [memory] Extending reserved space to 3072 MB (device gpu1)
[2019-06-16 09:03:50] [comm] Using NCCL 2.4.2 for GPU communication
[2019-06-16 09:03:50] [comm] NCCLCommunicator constructed successfully.
[2019-06-16 09:03:50] [training] Using 1 GPUs
[2019-06-16 09:03:50] Training started
[2019-06-16 09:03:50] [data] Shuffling data
[2019-06-16 09:03:52] [data] Done reading 4840169 sentences
[2019-06-16 09:04:14] [data] Done shuffling 4840169 sentences to temp files
[2019-06-16 09:04:16] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-06-16 09:04:16] [memory] Reserving 422 MB, device gpu1
[2019-06-16 09:04:16] [memory] Reserving 422 MB, device gpu1
[2019-06-16 09:04:16] [memory] Reserving 422 MB, device gpu1
[2019-06-16 09:04:16] [memory] Reserving 844 MB, device gpu1
[2019-06-16 09:19:33] Ep. 1 : Up. 2000 : Sen. 219,174 : Cost 139.65425110 : Time 952.22s : 5191.64 words/s
[2019-06-16 09:34:53] Ep. 1 : Up. 4000 : Sen. 437,620 : Cost 112.43217468 : Time 919.47s : 5364.56 words/s
[2019-06-16 09:50:15] Ep. 1 : Up. 6000 : Sen. 656,505 : Cost 97.73550415 : Time 922.38s : 5370.49 words/s
[2019-06-16 10:05:30] Ep. 1 : Up. 8000 : Sen. 874,177 : Cost 87.69416046 : Time 915.49s : 5366.64 words/s
[2019-06-16 10:20:51] Ep. 1 : Up. 10000 : Sen. 1,093,011 : Cost 80.83923340 : Time 920.39s : 5372.63 words/s
[2019-06-16 10:36:06] Ep. 1 : Up. 12000 : Sen. 1,310,732 : Cost 75.92761993 : Time 915.37s : 5359.99 words/s
[2019-06-16 10:51:23] Ep. 1 : Up. 14000 : Sen. 1,529,298 : Cost 72.20610046 : Time 916.50s : 5372.91 words/s
[2019-06-16 11:06:38] Ep. 1 : Up. 16000 : Sen. 1,747,413 : Cost 69.62763977 : Time 915.15s : 5369.60 words/s
[2019-06-16 11:21:58] Ep. 1 : Up. 18000 : Sen. 1,966,168 : Cost 67.57692719 : Time 920.02s : 5373.84 words/s
[2019-06-16 11:37:15] Ep. 1 : Up. 20000 : Sen. 2,184,890 : Cost 65.50787354 : Time 917.55s : 5370.46 words/s
[2019-06-16 11:37:15] Saving model to experiments/100M_bicleanerv1.1/model/model.npz.orig.npz
[2019-06-16 11:37:24] Saving model to experiments/100M_bicleanerv1.1/model/model.iter20000.npz
[2019-06-16 11:37:30] Saving model to experiments/100M_bicleanerv1.1/model/model.npz
[2019-06-16 11:37:39] Saving Adam parameters to experiments/100M_bicleanerv1.1/model/model.npz.optimizer.npz
[2019-06-16 11:38:05] [valid] Ep. 1 : Up. 20000 : cross-entropy : 66.7681 : new best
[2019-06-16 11:38:17] [valid] Ep. 1 : Up. 20000 : perplexity : 13.8699 : new best
[2019-06-16 11:39:59] [valid] Ep. 1 : Up. 20000 : translation : 21.57 : new best
[2019-06-16 11:55:20] Ep. 1 : Up. 22000 : Sen. 2,404,758 : Cost 63.71698380 : Time 1084.34s : 4559.43 words/s
[2019-06-16 12:10:36] Ep. 1 : Up. 24000 : Sen. 2,622,731 : Cost 62.81328583 : Time 915.97s : 5369.86 words/s
[2019-06-16 12:25:56] Ep. 1 : Up. 26000 : Sen. 2,841,870 : Cost 61.68055725 : Time 920.63s : 5372.78 words/s
[2019-06-16 12:41:18] Ep. 1 : Up. 28000 : Sen. 3,061,137 : Cost 60.69274902 : Time 921.57s : 5372.76 words/s
[2019-06-16 12:56:40] Ep. 1 : Up. 30000 : Sen. 3,280,494 : Cost 59.64833069 : Time 921.81s : 5366.86 words/s
[2019-06-16 13:11:59] Ep. 1 : Up. 32000 : Sen. 3,499,245 : Cost 58.64873123 : Time 918.92s : 5370.77 words/s
[2019-06-16 13:27:16] Ep. 1 : Up. 34000 : Sen. 3,717,077 : Cost 58.32656479 : Time 916.92s : 5372.89 words/s
[2019-06-16 13:42:34] Ep. 1 : Up. 36000 : Sen. 3,935,742 : Cost 57.41366196 : Time 918.08s : 5365.30 words/s
[2019-06-16 13:57:52] Ep. 1 : Up. 38000 : Sen. 4,153,898 : Cost 56.89171219 : Time 918.37s : 5368.30 words/s
[2019-06-16 14:01:26] Seen 4204916 samples
[2019-06-16 14:01:26] Starting epoch 2
[2019-06-16 14:01:26] [data] Shuffling data
[2019-06-16 14:01:29] [data] Done reading 4840169 sentences
[2019-06-16 14:01:46] [data] Done shuffling 4840169 sentences to temp files
[2019-06-16 14:13:35] Ep. 2 : Up. 40000 : Sen. 168,383 : Cost 55.38656998 : Time 943.05s : 5240.75 words/s
[2019-06-16 14:13:35] Saving model to experiments/100M_bicleanerv1.1/model/model.npz.orig.npz
[2019-06-16 14:13:44] Saving model to experiments/100M_bicleanerv1.1/model/model.iter40000.npz
[2019-06-16 14:13:50] Saving model to experiments/100M_bicleanerv1.1/model/model.npz
[2019-06-16 14:13:59] Saving Adam parameters to experiments/100M_bicleanerv1.1/model/model.npz.optimizer.npz
[2019-06-16 14:14:26] [valid] Ep. 2 : Up. 40000 : cross-entropy : 54.7681 : new best
[2019-06-16 14:14:37] [valid] Ep. 2 : Up. 40000 : perplexity : 8.64595 : new best
[2019-06-16 14:16:16] [valid] Ep. 2 : Up. 40000 : translation : 25.58 : new best
[2019-06-16 14:31:38] Ep. 2 : Up. 42000 : Sen. 387,482 : Cost 54.81988144 : Time 1082.85s : 4563.10 words/s
[2019-06-16 14:46:56] Ep. 2 : Up. 44000 : Sen. 605,924 : Cost 54.35162354 : Time 918.46s : 5360.40 words/s
[2019-06-16 15:02:15] Ep. 2 : Up. 46000 : Sen. 823,765 : Cost 54.11348343 : Time 918.86s : 5357.92 words/s
[2019-06-16 15:17:34] Ep. 2 : Up. 48000 : Sen. 1,042,704 : Cost 53.69707870 : Time 918.81s : 5363.82 words/s
[2019-06-16 15:32:55] Ep. 2 : Up. 50000 : Sen. 1,261,939 : Cost 53.31585693 : Time 920.79s : 5361.03 words/s
[2019-06-16 15:48:20] Ep. 2 : Up. 52000 : Sen. 1,480,920 : Cost 53.22836304 : Time 925.24s : 5351.98 words/s
[2019-06-16 16:03:43] Ep. 2 : Up. 54000 : Sen. 1,699,677 : Cost 52.62244034 : Time 922.57s : 5349.93 words/s
[2019-06-16 16:19:01] Ep. 2 : Up. 56000 : Sen. 1,917,787 : Cost 52.55454636 : Time 918.60s : 5359.89 words/s
[2019-06-16 16:34:25] Ep. 2 : Up. 58000 : Sen. 2,137,395 : Cost 52.42542267 : Time 924.25s : 5363.74 words/s
[2019-06-16 16:49:45] Ep. 2 : Up. 60000 : Sen. 2,356,239 : Cost 51.96785355 : Time 919.38s : 5367.50 words/s
[2019-06-16 16:49:45] Saving model to experiments/100M_bicleanerv1.1/model/model.npz.orig.npz
[2019-06-16 16:49:53] Saving model to experiments/100M_bicleanerv1.1/model/model.iter60000.npz
[2019-06-16 16:50:00] Saving model to experiments/100M_bicleanerv1.1/model/model.npz
[2019-06-16 16:50:09] Saving Adam parameters to experiments/100M_bicleanerv1.1/model/model.npz.optimizer.npz
[2019-06-16 16:50:35] [valid] Ep. 2 : Up. 60000 : cross-entropy : 49.8642 : new best
[2019-06-16 16:50:46] [valid] Ep. 2 : Up. 60000 : perplexity : 7.1274 : new best
[2019-06-16 16:52:25] [valid] Ep. 2 : Up. 60000 : translation : 27.19 : new best
[2019-06-16 17:07:46] Ep. 2 : Up. 62000 : Sen. 2,574,782 : Cost 51.70700073 : Time 1081.05s : 4570.22 words/s
[2019-06-16 17:23:05] Ep. 2 : Up. 64000 : Sen. 2,793,433 : Cost 51.35612869 : Time 918.91s : 5377.25 words/s
[2019-06-16 17:38:24] Ep. 2 : Up. 66000 : Sen. 3,012,893 : Cost 50.94951248 : Time 919.41s : 5376.88 words/s
[2019-06-16 17:53:40] Ep. 2 : Up. 68000 : Sen. 3,230,660 : Cost 50.90856171 : Time 916.07s : 5375.42 words/s
[2019-06-16 18:08:59] Ep. 2 : Up. 70000 : Sen. 3,448,965 : Cost 50.62074661 : Time 918.88s : 5366.09 words/s
[2019-06-16 18:24:17] Ep. 2 : Up. 72000 : Sen. 3,667,921 : Cost 50.55336380 : Time 918.12s : 5374.69 words/s
[2019-06-16 18:39:40] Ep. 2 : Up. 74000 : Sen. 3,887,140 : Cost 50.49218369 : Time 922.27s : 5364.94 words/s
[2019-06-16 18:54:56] Ep. 2 : Up. 76000 : Sen. 4,105,355 : Cost 49.99945831 : Time 916.37s : 5368.58 words/s
[2019-06-16 19:01:54] Seen 4204916 samples
[2019-06-16 19:01:54] Starting epoch 3
[2019-06-16 19:01:54] [data] Shuffling data
[2019-06-16 19:01:57] [data] Done reading 4840169 sentences
[2019-06-16 19:02:18] [data] Done shuffling 4840169 sentences to temp files
[2019-06-16 19:10:38] Ep. 3 : Up. 78000 : Sen. 118,947 : Cost 49.38966370 : Time 941.67s : 5239.87 words/s
[2019-06-16 19:25:59] Ep. 3 : Up. 80000 : Sen. 337,978 : Cost 48.52557755 : Time 921.09s : 5366.83 words/s
[2019-06-16 19:25:59] Saving model to experiments/100M_bicleanerv1.1/model/model.npz.orig.npz
[2019-06-16 19:26:07] Saving model to experiments/100M_bicleanerv1.1/model/model.iter80000.npz
[2019-06-16 19:26:14] Saving model to experiments/100M_bicleanerv1.1/model/model.npz
[2019-06-16 19:26:22] Saving Adam parameters to experiments/100M_bicleanerv1.1/model/model.npz.optimizer.npz
[2019-06-16 19:26:49] [valid] Ep. 3 : Up. 80000 : cross-entropy : 47.0527 : new best
[2019-06-16 19:27:00] [valid] Ep. 3 : Up. 80000 : perplexity : 6.38028 : new best
[2019-06-16 19:28:38] [valid] Ep. 3 : Up. 80000 : translation : 28 : new best
[2019-06-16 19:44:02] Ep. 3 : Up. 82000 : Sen. 556,878 : Cost 48.78125000 : Time 1083.45s : 4568.69 words/s
[2019-06-16 19:59:19] Ep. 3 : Up. 84000 : Sen. 775,132 : Cost 48.50521851 : Time 917.04s : 5371.46 words/s
[2019-06-16 20:14:39] Ep. 3 : Up. 86000 : Sen. 994,404 : Cost 48.28610229 : Time 919.36s : 5377.92 words/s
[2019-06-16 20:29:56] Ep. 3 : Up. 88000 : Sen. 1,212,778 : Cost 48.28118134 : Time 917.47s : 5370.80 words/s
[2019-06-16 20:45:15] Ep. 3 : Up. 90000 : Sen. 1,431,272 : Cost 48.21477509 : Time 918.47s : 5372.20 words/s
[2019-06-16 21:00:32] Ep. 3 : Up. 92000 : Sen. 1,649,350 : Cost 48.12138748 : Time 917.31s : 5361.24 words/s
[2019-06-16 21:15:49] Ep. 3 : Up. 94000 : Sen. 1,867,596 : Cost 48.08089066 : Time 916.77s : 5372.85 words/s
[2019-06-16 21:31:07] Ep. 3 : Up. 96000 : Sen. 2,086,400 : Cost 47.92987442 : Time 917.97s : 5366.67 words/s
[2019-06-16 21:46:24] Ep. 3 : Up. 98000 : Sen. 2,304,234 : Cost 47.72985077 : Time 917.15s : 5365.59 words/s
[2019-06-16 22:01:40] Ep. 3 : Up. 100000 : Sen. 2,521,936 : Cost 47.57775497 : Time 916.47s : 5357.11 words/s
[2019-06-16 22:01:40] Saving model to experiments/100M_bicleanerv1.1/model/model.npz.orig.npz
[2019-06-16 22:01:49] Saving model to experiments/100M_bicleanerv1.1/model/model.iter100000.npz
[2019-06-16 22:01:55] Saving model to experiments/100M_bicleanerv1.1/model/model.npz
[2019-06-16 22:02:04] Saving Adam parameters to experiments/100M_bicleanerv1.1/model/model.npz.optimizer.npz
[2019-06-16 22:02:31] [valid] Ep. 3 : Up. 100000 : cross-entropy : 45.3365 : new best
[2019-06-16 22:02:42] [valid] Ep. 3 : Up. 100000 : perplexity : 5.96327 : new best
[2019-06-16 22:04:20] [valid] Ep. 3 : Up. 100000 : translation : 28.68 : new best
[2019-06-16 22:19:40] Ep. 3 : Up. 102000 : Sen. 2,740,409 : Cost 47.54855728 : Time 1079.48s : 4566.20 words/s
[2019-06-16 22:35:01] Ep. 3 : Up. 104000 : Sen. 2,960,065 : Cost 47.39373016 : Time 921.08s : 5374.09 words/s
[2019-06-16 22:50:22] Ep. 3 : Up. 106000 : Sen. 3,179,183 : Cost 47.39603806 : Time 920.87s : 5366.15 words/s
[2019-06-16 23:05:35] Ep. 3 : Up. 108000 : Sen. 3,396,453 : Cost 47.32685089 : Time 913.65s : 5371.71 words/s
[2019-06-16 23:20:57] Ep. 3 : Up. 110000 : Sen. 3,616,205 : Cost 47.09905243 : Time 922.01s : 5365.66 words/s
[2019-06-16 23:36:14] Ep. 3 : Up. 112000 : Sen. 3,834,417 : Cost 47.02510834 : Time 917.17s : 5369.68 words/s
[2019-06-16 23:51:35] Ep. 3 : Up. 114000 : Sen. 4,052,755 : Cost 47.21892548 : Time 920.85s : 5361.34 words/s
[2019-06-17 00:02:13] Seen 4204916 samples
[2019-06-17 00:02:13] Starting epoch 4
[2019-06-17 00:02:13] [data] Shuffling data
[2019-06-17 00:02:16] [data] Done reading 4840169 sentences
[2019-06-17 00:02:36] [data] Done shuffling 4840169 sentences to temp files
[2019-06-17 00:07:17] Ep. 4 : Up. 116000 : Sen. 66,239 : Cost 46.62559509 : Time 941.88s : 5229.81 words/s
[2019-06-17 00:22:34] Ep. 4 : Up. 118000 : Sen. 283,889 : Cost 45.78523254 : Time 916.64s : 5368.63 words/s
[2019-06-17 00:37:51] Ep. 4 : Up. 120000 : Sen. 503,048 : Cost 45.55791092 : Time 917.20s : 5377.04 words/s
[2019-06-17 00:37:51] Saving model to experiments/100M_bicleanerv1.1/model/model.npz.orig.npz
[2019-06-17 00:37:59] Saving model to experiments/100M_bicleanerv1.1/model/model.iter120000.npz
[2019-06-17 00:38:06] Saving model to experiments/100M_bicleanerv1.1/model/model.npz
[2019-06-17 00:38:15] Saving Adam parameters to experiments/100M_bicleanerv1.1/model/model.npz.optimizer.npz
[2019-06-17 00:38:41] [valid] Ep. 4 : Up. 120000 : cross-entropy : 43.9769 : new best
[2019-06-17 00:38:53] [valid] Ep. 4 : Up. 120000 : perplexity : 5.65233 : new best
[2019-06-17 00:40:31] [valid] Ep. 4 : Up. 120000 : translation : 29.29 : new best
[2019-06-17 00:55:53] Ep. 4 : Up. 122000 : Sen. 721,743 : Cost 45.66771698 : Time 1081.99s : 4569.18 words/s
[2019-06-17 01:11:14] Ep. 4 : Up. 124000 : Sen. 940,698 : Cost 45.80633926 : Time 920.96s : 5365.85 words/s
[2019-06-17 01:26:35] Ep. 4 : Up. 126000 : Sen. 1,159,425 : Cost 45.91588593 : Time 921.02s : 5374.25 words/s
[2019-06-17 01:41:58] Ep. 4 : Up. 128000 : Sen. 1,379,095 : Cost 45.60882187 : Time 923.34s : 5366.75 words/s
[2019-06-17 01:57:18] Ep. 4 : Up. 130000 : Sen. 1,597,675 : Cost 45.52396774 : Time 919.33s : 5361.13 words/s
[2019-06-17 02:12:39] Ep. 4 : Up. 132000 : Sen. 1,816,471 : Cost 45.42949295 : Time 921.15s : 5365.97 words/s
[2019-06-17 02:27:59] Ep. 4 : Up. 134000 : Sen. 2,035,709 : Cost 45.24020386 : Time 919.90s : 5365.03 words/s
[2019-06-17 02:43:17] Ep. 4 : Up. 136000 : Sen. 2,254,322 : Cost 45.32586288 : Time 918.80s : 5369.68 words/s
[2019-06-17 02:58:38] Ep. 4 : Up. 138000 : Sen. 2,474,056 : Cost 45.47590256 : Time 920.43s : 5380.19 words/s
[2019-06-17 03:13:56] Ep. 4 : Up. 140000 : Sen. 2,692,662 : Cost 45.29736710 : Time 918.34s : 5366.63 words/s
[2019-06-17 03:13:56] Saving model to experiments/100M_bicleanerv1.1/model/model.npz.orig.npz
[2019-06-17 03:14:05] Saving model to experiments/100M_bicleanerv1.1/model/model.iter140000.npz
[2019-06-17 03:14:11] Saving model to experiments/100M_bicleanerv1.1/model/model.npz
[2019-06-17 03:14:20] Saving Adam parameters to experiments/100M_bicleanerv1.1/model/model.npz.optimizer.npz
[2019-06-17 03:14:47] [valid] Ep. 4 : Up. 140000 : cross-entropy : 43.0281 : new best
[2019-06-17 03:14:58] [valid] Ep. 4 : Up. 140000 : perplexity : 5.44502 : new best
[2019-06-17 03:16:37] [valid] Ep. 4 : Up. 140000 : translation : 29.58 : new best
[2019-06-17 03:31:58] Ep. 4 : Up. 142000 : Sen. 2,911,447 : Cost 45.28860855 : Time 1081.73s : 4563.22 words/s
[2019-06-17 03:47:18] Ep. 4 : Up. 144000 : Sen. 3,130,484 : Cost 45.28055954 : Time 919.86s : 5367.55 words/s
[2019-06-17 04:02:37] Ep. 4 : Up. 146000 : Sen. 3,348,929 : Cost 45.31678391 : Time 919.50s : 5365.36 words/s
[2019-06-17 04:17:58] Ep. 4 : Up. 148000 : Sen. 3,568,414 : Cost 45.17156982 : Time 920.28s : 5371.72 words/s
[2019-06-17 04:33:19] Ep. 4 : Up. 150000 : Sen. 3,787,181 : Cost 45.23733521 : Time 921.11s : 5370.13 words/s
[2019-06-17 04:48:39] Ep. 4 : Up. 152000 : Sen. 4,006,839 : Cost 45.00110245 : Time 919.93s : 5371.93 words/s
[2019-06-17 05:02:34] Seen 4204916 samples
[2019-06-17 05:02:34] Starting epoch 5
[2019-06-17 05:02:34] [data] Shuffling data
[2019-06-17 05:02:36] [data] Done reading 4840169 sentences
[2019-06-17 05:02:54] [data] Done shuffling 4840169 sentences to temp files
[2019-06-17 05:04:17] Ep. 5 : Up. 154000 : Sen. 19,687 : Cost 45.19707870 : Time 938.13s : 5247.12 words/s
[2019-06-17 05:19:32] Ep. 5 : Up. 156000 : Sen. 237,918 : Cost 43.90663147 : Time 915.65s : 5368.51 words/s
[2019-06-17 05:34:53] Ep. 5 : Up. 158000 : Sen. 456,990 : Cost 43.99078369 : Time 920.95s : 5368.75 words/s
[2019-06-17 05:50:11] Ep. 5 : Up. 160000 : Sen. 675,746 : Cost 43.89057159 : Time 917.99s : 5372.93 words/s
[2019-06-17 05:50:11] Saving model to experiments/100M_bicleanerv1.1/model/model.npz.orig.npz
[2019-06-17 05:50:20] Saving model to experiments/100M_bicleanerv1.1/model/model.iter160000.npz
[2019-06-17 05:50:26] Saving model to experiments/100M_bicleanerv1.1/model/model.npz
[2019-06-17 05:50:35] Saving Adam parameters to experiments/100M_bicleanerv1.1/model/model.npz.optimizer.npz
[2019-06-17 05:51:02] [valid] Ep. 5 : Up. 160000 : cross-entropy : 42.2954 : new best
[2019-06-17 05:51:13] [valid] Ep. 5 : Up. 160000 : perplexity : 5.29013 : new best
[2019-06-17 05:52:52] [valid] Ep. 5 : Up. 160000 : translation : 29.79 : new best
[2019-06-17 06:08:13] Ep. 5 : Up. 162000 : Sen. 894,579 : Cost 44.07517624 : Time 1081.68s : 4568.95 words/s
[2019-06-17 06:23:30] Ep. 5 : Up. 164000 : Sen. 1,112,888 : Cost 44.15145493 : Time 917.40s : 5370.86 words/s
[2019-06-17 06:38:54] Ep. 5 : Up. 166000 : Sen. 1,332,066 : Cost 44.09563065 : Time 923.20s : 5369.02 words/s
[2019-06-17 06:54:14] Ep. 5 : Up. 168000 : Sen. 1,551,127 : Cost 43.97245407 : Time 920.50s : 5373.02 words/s
[2019-06-17 07:09:34] Ep. 5 : Up. 170000 : Sen. 1,770,519 : Cost 43.94203949 : Time 919.78s : 5372.25 words/s
[2019-06-17 07:24:54] Ep. 5 : Up. 172000 : Sen. 1,989,288 : Cost 44.06218719 : Time 920.13s : 5366.17 words/s
[2019-06-17 07:40:10] Ep. 5 : Up. 174000 : Sen. 2,207,168 : Cost 44.00143814 : Time 916.08s : 5367.40 words/s
[2019-06-17 07:55:32] Ep. 5 : Up. 176000 : Sen. 2,426,402 : Cost 43.71974182 : Time 922.02s : 5367.11 words/s
[2019-06-17 08:10:55] Ep. 5 : Up. 178000 : Sen. 2,645,023 : Cost 44.14955139 : Time 922.38s : 5363.78 words/s
[2019-06-17 08:26:13] Ep. 5 : Up. 180000 : Sen. 2,863,704 : Cost 44.05536652 : Time 918.42s : 5362.84 words/s
[2019-06-17 08:26:13] Saving model to experiments/100M_bicleanerv1.1/model/model.npz.orig.npz
[2019-06-17 08:26:21] Saving model to experiments/100M_bicleanerv1.1/model/model.iter180000.npz
[2019-06-17 08:26:28] Saving model to experiments/100M_bicleanerv1.1/model/model.npz
[2019-06-17 08:26:37] Saving Adam parameters to experiments/100M_bicleanerv1.1/model/model.npz.optimizer.npz
[2019-06-17 08:27:04] [valid] Ep. 5 : Up. 180000 : cross-entropy : 41.7587 : new best
[2019-06-17 08:27:15] [valid] Ep. 5 : Up. 180000 : perplexity : 5.17947 : new best
[2019-06-17 08:28:54] [valid] Ep. 5 : Up. 180000 : translation : 29.92 : new best
[2019-06-17 08:44:09] Ep. 5 : Up. 182000 : Sen. 3,082,829 : Cost 43.77922058 : Time 1076.35s : 4567.01 words/s
[2019-06-17 08:59:32] Ep. 5 : Up. 184000 : Sen. 3,302,166 : Cost 43.82493210 : Time 922.48s : 5370.61 words/s
[2019-06-17 09:14:53] Ep. 5 : Up. 186000 : Sen. 3,521,173 : Cost 44.04976273 : Time 920.70s : 5374.57 words/s
[2019-06-17 09:30:09] Ep. 5 : Up. 188000 : Sen. 3,738,800 : Cost 43.88854218 : Time 916.81s : 5362.74 words/s
[2019-06-17 09:45:28] Ep. 5 : Up. 190000 : Sen. 3,957,757 : Cost 43.79841614 : Time 918.91s : 5371.22 words/s
[2019-06-17 10:00:47] Ep. 5 : Up. 192000 : Sen. 4,176,322 : Cost 43.67117691 : Time 918.42s : 5368.60 words/s
[2019-06-17 10:02:50] Seen 4204916 samples
[2019-06-17 10:02:50] Starting epoch 6
[2019-06-17 10:02:50] [data] Shuffling data
[2019-06-17 10:02:52] [data] Done reading 4840169 sentences
[2019-06-17 10:03:10] [data] Done shuffling 4840169 sentences to temp files
[2019-06-17 10:16:32] Ep. 6 : Up. 194000 : Sen. 189,467 : Cost 42.89239120 : Time 945.49s : 5217.13 words/s
[2019-06-17 10:31:53] Ep. 6 : Up. 196000 : Sen. 407,902 : Cost 42.57371140 : Time 920.74s : 5362.79 words/s
[2019-06-17 10:47:13] Ep. 6 : Up. 198000 : Sen. 627,278 : Cost 42.62051773 : Time 920.15s : 5366.01 words/s
[2019-06-17 11:02:31] Ep. 6 : Up. 200000 : Sen. 846,213 : Cost 42.47426987 : Time 917.58s : 5371.38 words/s
[2019-06-17 11:02:31] Saving model to experiments/100M_bicleanerv1.1/model/model.npz.orig.npz
[2019-06-17 11:02:39] Saving model to experiments/100M_bicleanerv1.1/model/model.iter200000.npz
[2019-06-17 11:02:46] Saving model to experiments/100M_bicleanerv1.1/model/model.npz
[2019-06-17 11:02:54] Saving Adam parameters to experiments/100M_bicleanerv1.1/model/model.npz.optimizer.npz
[2019-06-17 11:03:21] [valid] Ep. 6 : Up. 200000 : cross-entropy : 41.2902 : new best
[2019-06-17 11:03:32] [valid] Ep. 6 : Up. 200000 : perplexity : 5.08479 : new best
[2019-06-17 11:05:11] [valid] Ep. 6 : Up. 200000 : translation : 30.17 : new best
[2019-06-17 11:20:32] Ep. 6 : Up. 202000 : Sen. 1,064,302 : Cost 42.79772568 : Time 1081.10s : 4557.63 words/s
[2019-06-17 11:35:54] Ep. 6 : Up. 204000 : Sen. 1,283,675 : Cost 42.82219696 : Time 922.20s : 5369.79 words/s
[2019-06-17 11:51:14] Ep. 6 : Up. 206000 : Sen. 1,502,821 : Cost 42.94980240 : Time 920.05s : 5373.51 words/s
[2019-06-17 12:06:33] Ep. 6 : Up. 208000 : Sen. 1,721,500 : Cost 42.83662033 : Time 918.60s : 5365.31 words/s
[2019-06-17 12:21:52] Ep. 6 : Up. 210000 : Sen. 1,939,875 : Cost 42.74946213 : Time 918.98s : 5359.58 words/s
[2019-06-17 12:37:14] Ep. 6 : Up. 212000 : Sen. 2,159,684 : Cost 42.82355118 : Time 922.54s : 5368.16 words/s
[2019-06-17 12:52:35] Ep. 6 : Up. 214000 : Sen. 2,379,366 : Cost 43.00610352 : Time 920.75s : 5371.34 words/s
[2019-06-17 13:07:59] Ep. 6 : Up. 216000 : Sen. 2,598,784 : Cost 42.96078110 : Time 923.71s : 5364.91 words/s
[2019-06-17 13:23:17] Ep. 6 : Up. 218000 : Sen. 2,816,748 : Cost 42.85894012 : Time 917.99s : 5365.10 words/s
[2019-06-17 13:38:37] Ep. 6 : Up. 220000 : Sen. 3,035,345 : Cost 42.94718933 : Time 920.77s : 5363.53 words/s
[2019-06-17 13:38:37] Saving model to experiments/100M_bicleanerv1.1/model/model.npz.orig.npz
[2019-06-17 13:38:46] Saving model to experiments/100M_bicleanerv1.1/model/model.iter220000.npz
[2019-06-17 13:38:52] Saving model to experiments/100M_bicleanerv1.1/model/model.npz
[2019-06-17 13:39:01] Saving Adam parameters to experiments/100M_bicleanerv1.1/model/model.npz.optimizer.npz
[2019-06-17 13:39:28] [valid] Ep. 6 : Up. 220000 : cross-entropy : 40.8576 : new best
[2019-06-17 13:39:40] [valid] Ep. 6 : Up. 220000 : perplexity : 4.99888 : new best
[2019-06-17 13:41:18] [valid] Ep. 6 : Up. 220000 : translation : 30.2 : new best
[2019-06-17 13:56:40] Ep. 6 : Up. 222000 : Sen. 3,254,772 : Cost 42.73750687 : Time 1082.32s : 4574.02 words/s
[2019-06-17 14:12:00] Ep. 6 : Up. 224000 : Sen. 3,473,171 : Cost 42.74364853 : Time 920.13s : 5362.26 words/s
[2019-06-17 14:27:19] Ep. 6 : Up. 226000 : Sen. 3,692,116 : Cost 42.76444626 : Time 919.04s : 5370.27 words/s
[2019-06-17 14:42:37] Ep. 6 : Up. 228000 : Sen. 3,910,400 : Cost 42.85494232 : Time 918.33s : 5370.70 words/s
[2019-06-17 14:57:57] Ep. 6 : Up. 230000 : Sen. 4,129,057 : Cost 42.61971664 : Time 919.39s : 5369.78 words/s
[2019-06-17 15:03:15] Seen 4204916 samples
[2019-06-17 15:03:15] Starting epoch 7
[2019-06-17 15:03:15] [data] Shuffling data
[2019-06-17 15:03:18] [data] Done reading 4840169 sentences
[2019-06-17 15:03:39] [data] Done shuffling 4840169 sentences to temp files
[2019-06-17 15:13:39] Ep. 7 : Up. 232000 : Sen. 142,444 : Cost 41.94494247 : Time 942.36s : 5227.04 words/s
[2019-06-17 15:28:59] Ep. 7 : Up. 234000 : Sen. 360,916 : Cost 41.82457733 : Time 920.34s : 5366.24 words/s
[2019-06-17 15:44:19] Ep. 7 : Up. 236000 : Sen. 580,114 : Cost 41.63748932 : Time 919.41s : 5371.27 words/s
[2019-06-17 15:59:37] Ep. 7 : Up. 238000 : Sen. 798,373 : Cost 41.94365311 : Time 918.54s : 5367.75 words/s
[2019-06-17 16:14:58] Ep. 7 : Up. 240000 : Sen. 1,016,871 : Cost 41.92246246 : Time 920.43s : 5370.64 words/s
[2019-06-17 16:14:58] Saving model to experiments/100M_bicleanerv1.1/model/model.npz.orig.npz
[2019-06-17 16:15:06] Saving model to experiments/100M_bicleanerv1.1/model/model.iter240000.npz
[2019-06-17 16:15:13] Saving model to experiments/100M_bicleanerv1.1/model/model.npz
[2019-06-17 16:15:21] Saving Adam parameters to experiments/100M_bicleanerv1.1/model/model.npz.optimizer.npz
[2019-06-17 16:15:48] [valid] Ep. 7 : Up. 240000 : cross-entropy : 40.5917 : new best
[2019-06-17 16:16:00] [valid] Ep. 7 : Up. 240000 : perplexity : 4.94679 : new best
[2019-06-17 16:17:38] [valid] Ep. 7 : Up. 240000 : translation : 30.24 : new best
[2019-06-17 16:32:59] Ep. 7 : Up. 242000 : Sen. 1,235,912 : Cost 41.84978485 : Time 1081.00s : 4560.82 words/s
[2019-06-17 16:48:23] Ep. 7 : Up. 244000 : Sen. 1,455,484 : Cost 42.05434036 : Time 924.56s : 5367.63 words/s
[2019-06-17 17:03:43] Ep. 7 : Up. 246000 : Sen. 1,674,016 : Cost 41.98657990 : Time 919.47s : 5362.58 words/s
[2019-06-17 17:19:01] Ep. 7 : Up. 248000 : Sen. 1,893,252 : Cost 41.87552261 : Time 918.50s : 5373.39 words/s
[2019-06-17 17:34:23] Ep. 7 : Up. 250000 : Sen. 2,112,000 : Cost 41.98968506 : Time 922.03s : 5360.11 words/s
[2019-06-17 17:49:42] Ep. 7 : Up. 252000 : Sen. 2,330,420 : Cost 41.80765152 : Time 918.29s : 5365.24 words/s
[2019-06-17 18:05:03] Ep. 7 : Up. 254000 : Sen. 2,549,144 : Cost 42.12637329 : Time 921.30s : 5361.64 words/s
[2019-06-17 18:20:19] Ep. 7 : Up. 256000 : Sen. 2,766,723 : Cost 41.95159912 : Time 916.17s : 5363.60 words/s
[2019-06-17 18:35:34] Ep. 7 : Up. 258000 : Sen. 2,984,991 : Cost 41.84777069 : Time 914.54s : 5368.26 words/s
[2019-06-17 18:50:58] Ep. 7 : Up. 260000 : Sen. 3,204,712 : Cost 42.05067825 : Time 924.11s : 5368.18 words/s
[2019-06-17 18:50:58] Saving model to experiments/100M_bicleanerv1.1/model/model.npz.orig.npz
[2019-06-17 18:51:06] Saving model to experiments/100M_bicleanerv1.1/model/model.iter260000.npz
[2019-06-17 18:51:12] Saving model to experiments/100M_bicleanerv1.1/model/model.npz
[2019-06-17 18:51:21] Saving Adam parameters to experiments/100M_bicleanerv1.1/model/model.npz.optimizer.npz
[2019-06-17 18:51:48] [valid] Ep. 7 : Up. 260000 : cross-entropy : 40.3367 : new best
[2019-06-17 18:52:00] [valid] Ep. 7 : Up. 260000 : perplexity : 4.89737 : new best
[2019-06-17 18:53:38] [valid] Ep. 7 : Up. 260000 : translation : 30.39 : new best
[2019-06-17 19:09:00] Ep. 7 : Up. 262000 : Sen. 3,423,685 : Cost 42.19028091 : Time 1082.01s : 4567.74 words/s
[2019-06-17 19:24:23] Ep. 7 : Up. 264000 : Sen. 3,643,571 : Cost 41.92939377 : Time 923.35s : 5371.43 words/s
[2019-06-17 19:39:43] Ep. 7 : Up. 266000 : Sen. 3,862,738 : Cost 41.85662460 : Time 919.56s : 5362.47 words/s
[2019-06-17 19:55:07] Ep. 7 : Up. 268000 : Sen. 4,082,319 : Cost 42.02913284 : Time 924.17s : 5371.34 words/s
[2019-06-17 20:03:43] Seen 4204916 samples
[2019-06-17 20:03:43] Starting epoch 8
[2019-06-17 20:03:43] [data] Shuffling data
[2019-06-17 20:03:46] [data] Done reading 4840169 sentences
[2019-06-17 20:04:04] [data] Done shuffling 4840169 sentences to temp files
[2019-06-17 20:10:51] Ep. 8 : Up. 270000 : Sen. 95,591 : Cost 41.48824310 : Time 943.95s : 5219.30 words/s
[2019-06-17 20:26:09] Ep. 8 : Up. 272000 : Sen. 313,886 : Cost 41.17452621 : Time 918.45s : 5369.22 words/s
[2019-06-17 20:41:26] Ep. 8 : Up. 274000 : Sen. 531,792 : Cost 40.99311066 : Time 917.21s : 5365.46 words/s
[2019-06-17 20:56:43] Ep. 8 : Up. 276000 : Sen. 750,049 : Cost 40.94179153 : Time 916.56s : 5369.36 words/s
[2019-06-17 21:12:00] Ep. 8 : Up. 278000 : Sen. 967,945 : Cost 41.09497070 : Time 916.62s : 5367.95 words/s
[2019-06-17 21:27:16] Ep. 8 : Up. 280000 : Sen. 1,185,891 : Cost 41.42605972 : Time 916.80s : 5369.78 words/s
[2019-06-17 21:27:16] Saving model to experiments/100M_bicleanerv1.1/model/model.npz.orig.npz
[2019-06-17 21:27:25] Saving model to experiments/100M_bicleanerv1.1/model/model.iter280000.npz
[2019-06-17 21:27:31] Saving model to experiments/100M_bicleanerv1.1/model/model.npz
[2019-06-17 21:27:40] Saving Adam parameters to experiments/100M_bicleanerv1.1/model/model.npz.optimizer.npz
[2019-06-17 21:28:07] [valid] Ep. 8 : Up. 280000 : cross-entropy : 40.0761 : new best
[2019-06-17 21:28:19] [valid] Ep. 8 : Up. 280000 : perplexity : 4.84735 : new best
[2019-06-17 21:29:57] [valid] Ep. 8 : Up. 280000 : translation : 30.58 : new best
[2019-06-17 21:45:21] Ep. 8 : Up. 282000 : Sen. 1,405,681 : Cost 41.21408463 : Time 1084.19s : 4573.61 words/s
[2019-06-17 22:00:42] Ep. 8 : Up. 284000 : Sen. 1,625,240 : Cost 40.98254776 : Time 921.84s : 5360.71 words/s
[2019-06-17 22:15:59] Ep. 8 : Up. 286000 : Sen. 1,842,839 : Cost 41.19406509 : Time 916.40s : 5356.83 words/s
[2019-06-17 22:31:21] Ep. 8 : Up. 288000 : Sen. 2,062,463 : Cost 41.32446289 : Time 921.89s : 5368.08 words/s
[2019-06-17 22:46:39] Ep. 8 : Up. 290000 : Sen. 2,280,456 : Cost 41.51786041 : Time 918.07s : 5364.62 words/s
[2019-06-17 23:02:02] Ep. 8 : Up. 292000 : Sen. 2,499,515 : Cost 41.16252518 : Time 923.02s : 5361.58 words/s
[2019-06-17 23:17:23] Ep. 8 : Up. 294000 : Sen. 2,717,926 : Cost 41.24883270 : Time 920.93s : 5354.05 words/s
[2019-06-17 23:32:38] Ep. 8 : Up. 296000 : Sen. 2,935,626 : Cost 41.20631027 : Time 914.86s : 5354.75 words/s
[2019-06-17 23:47:58] Ep. 8 : Up. 298000 : Sen. 3,153,627 : Cost 41.30483627 : Time 920.17s : 5350.50 words/s
[2019-06-18 00:03:22] Ep. 8 : Up. 300000 : Sen. 3,373,157 : Cost 41.30364227 : Time 924.21s : 5353.72 words/s
[2019-06-18 00:03:22] Saving model to experiments/100M_bicleanerv1.1/model/model.npz.orig.npz
[2019-06-18 00:03:31] Saving model to experiments/100M_bicleanerv1.1/model/model.iter300000.npz
[2019-06-18 00:03:38] Saving model to experiments/100M_bicleanerv1.1/model/model.npz
[2019-06-18 00:03:47] Saving Adam parameters to experiments/100M_bicleanerv1.1/model/model.npz.optimizer.npz
[2019-06-18 00:04:15] [valid] Ep. 8 : Up. 300000 : cross-entropy : 39.8943 : new best
[2019-06-18 00:04:26] [valid] Ep. 8 : Up. 300000 : perplexity : 4.81277 : new best
[2019-06-18 00:06:06] [valid] Ep. 8 : Up. 300000 : translation : 30.62 : new best
[2019-06-18 00:21:32] Ep. 8 : Up. 302000 : Sen. 3,592,100 : Cost 41.55718994 : Time 1089.83s : 4534.78 words/s
[2019-06-18 00:36:52] Ep. 8 : Up. 304000 : Sen. 3,810,710 : Cost 41.41014099 : Time 920.24s : 5354.61 words/s
[2019-06-18 00:52:15] Ep. 8 : Up. 306000 : Sen. 4,029,678 : Cost 41.25537491 : Time 923.32s : 5354.10 words/s
[2019-06-18 01:04:33] Seen 4204916 samples
[2019-06-18 01:04:33] Starting epoch 9
[2019-06-18 01:04:33] [data] Shuffling data
[2019-06-18 01:04:36] [data] Done reading 4840169 sentences
[2019-06-18 01:04:58] [data] Done shuffling 4840169 sentences to temp files
[2019-06-18 01:07:59] Ep. 9 : Up. 308000 : Sen. 43,140 : Cost 41.13804626 : Time 944.14s : 5216.25 words/s
[2019-06-18 01:23:20] Ep. 9 : Up. 310000 : Sen. 261,114 : Cost 40.28963852 : Time 920.16s : 5350.06 words/s
[2019-06-18 01:38:40] Ep. 9 : Up. 312000 : Sen. 479,413 : Cost 40.37406540 : Time 920.57s : 5353.66 words/s
[2019-06-18 01:54:04] Ep. 9 : Up. 314000 : Sen. 698,802 : Cost 40.53306961 : Time 923.69s : 5358.54 words/s
[2019-06-18 02:09:28] Ep. 9 : Up. 316000 : Sen. 917,562 : Cost 40.59239197 : Time 923.91s : 5353.47 words/s
[2019-06-18 02:24:48] Ep. 9 : Up. 318000 : Sen. 1,136,048 : Cost 40.46458435 : Time 920.35s : 5361.64 words/s
[2019-06-18 02:40:09] Ep. 9 : Up. 320000 : Sen. 1,355,415 : Cost 40.38445282 : Time 921.33s : 5362.93 words/s
[2019-06-18 02:40:09] Saving model to experiments/100M_bicleanerv1.1/model/model.npz.orig.npz
[2019-06-18 02:40:18] Saving model to experiments/100M_bicleanerv1.1/model/model.iter320000.npz
[2019-06-18 02:40:25] Saving model to experiments/100M_bicleanerv1.1/model/model.npz
[2019-06-18 02:40:33] Saving Adam parameters to experiments/100M_bicleanerv1.1/model/model.npz.optimizer.npz
[2019-06-18 02:41:00] [valid] Ep. 9 : Up. 320000 : cross-entropy : 39.7734 : new best
[2019-06-18 02:41:12] [valid] Ep. 9 : Up. 320000 : perplexity : 4.7899 : new best
[2019-06-18 02:42:50] [valid] Ep. 9 : Up. 320000 : translation : 30.56 : stalled 1 times (last best: 30.62)
[2019-06-18 02:58:11] Ep. 9 : Up. 322000 : Sen. 1,574,400 : Cost 40.79508972 : Time 1081.76s : 4574.11 words/s
[2019-06-18 03:13:29] Ep. 9 : Up. 324000 : Sen. 1,792,982 : Cost 40.72254181 : Time 917.63s : 5375.74 words/s
[2019-06-18 03:28:44] Ep. 9 : Up. 326000 : Sen. 2,010,840 : Cost 40.66229248 : Time 915.13s : 5367.67 words/s
[2019-06-18 03:43:59] Ep. 9 : Up. 328000 : Sen. 2,229,160 : Cost 40.49726486 : Time 915.30s : 5372.55 words/s
[2019-06-18 03:59:18] Ep. 9 : Up. 330000 : Sen. 2,447,972 : Cost 40.69856262 : Time 918.97s : 5368.96 words/s
[2019-06-18 04:14:38] Ep. 9 : Up. 332000 : Sen. 2,666,123 : Cost 40.70973206 : Time 919.59s : 5359.96 words/s
[2019-06-18 04:29:55] Ep. 9 : Up. 334000 : Sen. 2,884,283 : Cost 40.81138992 : Time 917.16s : 5365.88 words/s
[2019-06-18 04:45:15] Ep. 9 : Up. 336000 : Sen. 3,103,787 : Cost 40.68063736 : Time 920.30s : 5368.73 words/s
[2019-06-18 05:00:32] Ep. 9 : Up. 338000 : Sen. 3,322,029 : Cost 40.62114716 : Time 916.28s : 5370.13 words/s
[2019-06-18 05:15:52] Ep. 9 : Up. 340000 : Sen. 3,540,900 : Cost 40.90839386 : Time 920.91s : 5369.14 words/s
[2019-06-18 05:15:52] Saving model to experiments/100M_bicleanerv1.1/model/model.npz.orig.npz
[2019-06-18 05:16:01] Saving model to experiments/100M_bicleanerv1.1/model/model.iter340000.npz
[2019-06-18 05:16:08] Saving model to experiments/100M_bicleanerv1.1/model/model.npz
[2019-06-18 05:16:16] Saving Adam parameters to experiments/100M_bicleanerv1.1/model/model.npz.optimizer.npz
[2019-06-18 05:16:43] [valid] Ep. 9 : Up. 340000 : cross-entropy : 39.5531 : new best
[2019-06-18 05:16:55] [valid] Ep. 9 : Up. 340000 : perplexity : 4.74852 : new best
[2019-06-18 05:18:32] [valid] Ep. 9 : Up. 340000 : translation : 30.78 : new best
[2019-06-18 05:33:52] Ep. 9 : Up. 342000 : Sen. 3,759,505 : Cost 40.83878326 : Time 1079.84s : 4563.91 words/s
[2019-06-18 05:49:14] Ep. 9 : Up. 344000 : Sen. 3,978,779 : Cost 40.75658417 : Time 921.68s : 5368.24 words/s
[2019-06-18 06:04:35] Ep. 9 : Up. 346000 : Sen. 4,197,391 : Cost 41.12875748 : Time 921.39s : 5363.81 words/s
[2019-06-18 06:05:07] Seen 4204916 samples
[2019-06-18 06:05:07] Starting epoch 10
[2019-06-18 06:05:07] [data] Shuffling data
[2019-06-18 06:05:09] [data] Done reading 4840169 sentences
[2019-06-18 06:05:28] [data] Done shuffling 4840169 sentences to temp files
[2019-06-18 06:20:16] Ep. 10 : Up. 348000 : Sen. 211,122 : Cost 39.66222000 : Time 940.24s : 5239.92 words/s
[2019-06-18 06:35:36] Ep. 10 : Up. 350000 : Sen. 430,102 : Cost 39.91888428 : Time 920.87s : 5369.02 words/s
[2019-06-18 06:50:55] Ep. 10 : Up. 352000 : Sen. 648,770 : Cost 39.59062958 : Time 918.23s : 5364.90 words/s
[2019-06-18 07:06:16] Ep. 10 : Up. 354000 : Sen. 867,461 : Cost 40.05206299 : Time 921.16s : 5370.20 words/s
[2019-06-18 07:21:34] Ep. 10 : Up. 356000 : Sen. 1,085,517 : Cost 40.02871704 : Time 918.45s : 5355.21 words/s
[2019-06-18 07:36:54] Ep. 10 : Up. 358000 : Sen. 1,304,316 : Cost 39.87331390 : Time 919.81s : 5364.32 words/s
[2019-06-18 07:52:15] Ep. 10 : Up. 360000 : Sen. 1,523,200 : Cost 40.03280258 : Time 921.17s : 5359.92 words/s
[2019-06-18 07:52:15] Saving model to experiments/100M_bicleanerv1.1/model/model.npz.orig.npz
[2019-06-18 07:52:24] Saving model to experiments/100M_bicleanerv1.1/model/model.iter360000.npz
[2019-06-18 07:52:31] Saving model to experiments/100M_bicleanerv1.1/model/model.npz
[2019-06-18 07:52:39] Saving Adam parameters to experiments/100M_bicleanerv1.1/model/model.npz.optimizer.npz
[2019-06-18 07:53:06] [valid] Ep. 10 : Up. 360000 : cross-entropy : 39.4703 : new best
[2019-06-18 07:53:18] [valid] Ep. 10 : Up. 360000 : perplexity : 4.73306 : new best
[2019-06-18 07:54:56] [valid] Ep. 10 : Up. 360000 : translation : 30.68 : stalled 1 times (last best: 30.78)
[2019-06-18 08:10:18] Ep. 10 : Up. 362000 : Sen. 1,742,219 : Cost 40.24372864 : Time 1082.96s : 4562.02 words/s
[2019-06-18 08:25:36] Ep. 10 : Up. 364000 : Sen. 1,960,568 : Cost 39.99879074 : Time 917.51s : 5368.43 words/s
[2019-06-18 08:40:56] Ep. 10 : Up. 366000 : Sen. 2,179,322 : Cost 40.21345901 : Time 919.97s : 5366.18 words/s
[2019-06-18 08:56:16] Ep. 10 : Up. 368000 : Sen. 2,397,038 : Cost 40.30850601 : Time 920.13s : 5356.44 words/s
[2019-06-18 09:11:35] Ep. 10 : Up. 370000 : Sen. 2,616,350 : Cost 40.05958557 : Time 919.57s : 5372.46 words/s
[2019-06-18 09:26:55] Ep. 10 : Up. 372000 : Sen. 2,835,122 : Cost 40.20483398 : Time 919.80s : 5364.46 words/s
[2019-06-18 09:42:15] Ep. 10 : Up. 374000 : Sen. 3,053,962 : Cost 40.31942368 : Time 919.67s : 5362.38 words/s
[2019-06-18 09:57:33] Ep. 10 : Up. 376000 : Sen. 3,271,637 : Cost 40.35626221 : Time 917.87s : 5363.60 words/s
[2019-06-18 10:12:51] Ep. 10 : Up. 378000 : Sen. 3,489,929 : Cost 40.21445084 : Time 918.44s : 5360.70 words/s
[2019-06-18 10:28:10] Ep. 10 : Up. 380000 : Sen. 3,708,658 : Cost 40.27070618 : Time 918.48s : 5361.64 words/s
[2019-06-18 10:28:10] Saving model to experiments/100M_bicleanerv1.1/model/model.npz.orig.npz
[2019-06-18 10:28:19] Saving model to experiments/100M_bicleanerv1.1/model/model.iter380000.npz
[2019-06-18 10:28:25] Saving model to experiments/100M_bicleanerv1.1/model/model.npz
[2019-06-18 10:28:34] Saving Adam parameters to experiments/100M_bicleanerv1.1/model/model.npz.optimizer.npz
[2019-06-18 10:29:03] [valid] Ep. 10 : Up. 380000 : cross-entropy : 39.323 : new best
[2019-06-18 10:29:14] [valid] Ep. 10 : Up. 380000 : perplexity : 4.70569 : new best
[2019-06-18 10:30:52] [valid] Ep. 10 : Up. 380000 : translation : 30.81 : new best
[2019-06-18 10:46:13] Ep. 10 : Up. 382000 : Sen. 3,927,223 : Cost 40.25555420 : Time 1083.20s : 4551.53 words/s
[2019-06-18 11:01:34] Ep. 10 : Up. 384000 : Sen. 4,145,742 : Cost 40.53264618 : Time 921.41s : 5361.88 words/s
[2019-06-18 11:05:44] Seen 4204916 samples
[2019-06-18 11:05:44] Starting epoch 11
[2019-06-18 11:05:44] [data] Shuffling data
[2019-06-18 11:05:46] [data] Done reading 4840169 sentences
[2019-06-18 11:06:08] [data] Done shuffling 4840169 sentences to temp files
[2019-06-18 11:17:18] Ep. 11 : Up. 386000 : Sen. 159,300 : Cost 39.57189560 : Time 943.35s : 5219.72 words/s
[2019-06-18 11:32:40] Ep. 11 : Up. 388000 : Sen. 378,381 : Cost 39.38440704 : Time 922.68s : 5361.81 words/s
[2019-06-18 11:48:00] Ep. 11 : Up. 390000 : Sen. 596,809 : Cost 39.43474579 : Time 919.32s : 5356.02 words/s
[2019-06-18 12:03:23] Ep. 11 : Up. 392000 : Sen. 815,584 : Cost 39.27433777 : Time 923.25s : 5333.39 words/s
[2019-06-18 12:18:40] Ep. 11 : Up. 394000 : Sen. 1,032,454 : Cost 39.77080154 : Time 917.09s : 5355.91 words/s
[2019-06-18 12:34:03] Ep. 11 : Up. 396000 : Sen. 1,251,874 : Cost 39.72605896 : Time 923.18s : 5369.50 words/s
[2019-06-18 12:49:22] Ep. 11 : Up. 398000 : Sen. 1,470,324 : Cost 39.55746078 : Time 918.68s : 5360.51 words/s
[2019-06-18 13:04:43] Ep. 11 : Up. 400000 : Sen. 1,689,357 : Cost 39.71011353 : Time 921.55s : 5363.36 words/s
[2019-06-18 13:04:43] Saving model to experiments/100M_bicleanerv1.1/model/model.npz.orig.npz
[2019-06-18 13:04:52] Saving model to experiments/100M_bicleanerv1.1/model/model.iter400000.npz
[2019-06-18 13:04:58] Saving model to experiments/100M_bicleanerv1.1/model/model.npz
[2019-06-18 13:05:07] Saving Adam parameters to experiments/100M_bicleanerv1.1/model/model.npz.optimizer.npz
[2019-06-18 13:05:33] [valid] Ep. 11 : Up. 400000 : cross-entropy : 39.2474 : new best
[2019-06-18 13:05:45] [valid] Ep. 11 : Up. 400000 : perplexity : 4.6917 : new best
[2019-06-18 13:07:23] [valid] Ep. 11 : Up. 400000 : translation : 30.89 : new best
[2019-06-18 13:22:46] Ep. 11 : Up. 402000 : Sen. 1,907,921 : Cost 39.70128250 : Time 1082.60s : 4561.32 words/s
[2019-06-18 13:38:09] Ep. 11 : Up. 404000 : Sen. 2,127,535 : Cost 39.64539719 : Time 922.79s : 5366.37 words/s
[2019-06-18 13:53:31] Ep. 11 : Up. 406000 : Sen. 2,346,297 : Cost 39.93457413 : Time 922.54s : 5361.06 words/s
[2019-06-18 14:08:52] Ep. 11 : Up. 408000 : Sen. 2,565,797 : Cost 39.61612320 : Time 921.07s : 5365.13 words/s
[2019-06-18 14:24:13] Ep. 11 : Up. 410000 : Sen. 2,784,315 : Cost 40.06732941 : Time 920.63s : 5359.78 words/s
[2019-06-18 14:39:32] Ep. 11 : Up. 412000 : Sen. 3,002,853 : Cost 39.82871246 : Time 919.29s : 5360.62 words/s
[2019-06-18 14:54:54] Ep. 11 : Up. 414000 : Sen. 3,222,051 : Cost 39.77338791 : Time 921.44s : 5358.77 words/s
