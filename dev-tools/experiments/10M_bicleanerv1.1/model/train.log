[2019-06-05 12:04:10] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-06-05 12:04:10] [marian] Running on zisa as process 95878 with command line:
[2019-06-05 12:04:10] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model model/model.npz -T . --devices 0 --train-sets data/train.bpe.de data/train.bpe.en --vocabs data/train.bpe.de.json data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets data/dev.bpe.de data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output model/dev.out --valid-script-path ./score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log model/train.log --valid-log model/valid.log
[2019-06-05 12:04:10] [config] after-batches: 0
[2019-06-05 12:04:10] [config] after-epochs: 0
[2019-06-05 12:04:10] [config] allow-unk: false
[2019-06-05 12:04:10] [config] beam-size: 12
[2019-06-05 12:04:10] [config] bert-class-symbol: "[CLS]"
[2019-06-05 12:04:10] [config] bert-mask-symbol: "[MASK]"
[2019-06-05 12:04:10] [config] bert-masking-fraction: 0.15
[2019-06-05 12:04:10] [config] bert-sep-symbol: "[SEP]"
[2019-06-05 12:04:10] [config] bert-train-type-embeddings: true
[2019-06-05 12:04:10] [config] bert-type-vocab-size: 2
[2019-06-05 12:04:10] [config] best-deep: false
[2019-06-05 12:04:10] [config] clip-gemm: 0
[2019-06-05 12:04:10] [config] clip-norm: 1
[2019-06-05 12:04:10] [config] cost-type: ce-mean
[2019-06-05 12:04:10] [config] cpu-threads: 0
[2019-06-05 12:04:10] [config] data-weighting: ""
[2019-06-05 12:04:10] [config] data-weighting-type: sentence
[2019-06-05 12:04:10] [config] dec-cell: gru
[2019-06-05 12:04:10] [config] dec-cell-base-depth: 2
[2019-06-05 12:04:10] [config] dec-cell-high-depth: 1
[2019-06-05 12:04:10] [config] dec-depth: 1
[2019-06-05 12:04:10] [config] devices:
[2019-06-05 12:04:10] [config]   - 0
[2019-06-05 12:04:10] [config] dim-emb: 512
[2019-06-05 12:04:10] [config] dim-rnn: 1024
[2019-06-05 12:04:10] [config] dim-vocabs:
[2019-06-05 12:04:10] [config]   - 50000
[2019-06-05 12:04:10] [config]   - 50000
[2019-06-05 12:04:10] [config] disp-first: 0
[2019-06-05 12:04:10] [config] disp-freq: 2000
[2019-06-05 12:04:10] [config] disp-label-counts: false
[2019-06-05 12:04:10] [config] dropout-rnn: 0.2
[2019-06-05 12:04:10] [config] dropout-src: 0.1
[2019-06-05 12:04:10] [config] dropout-trg: 0.1
[2019-06-05 12:04:10] [config] dump-config: ""
[2019-06-05 12:04:10] [config] early-stopping: 5
[2019-06-05 12:04:10] [config] embedding-fix-src: false
[2019-06-05 12:04:10] [config] embedding-fix-trg: false
[2019-06-05 12:04:10] [config] embedding-normalization: false
[2019-06-05 12:04:10] [config] embedding-vectors:
[2019-06-05 12:04:10] [config]   []
[2019-06-05 12:04:10] [config] enc-cell: gru
[2019-06-05 12:04:10] [config] enc-cell-depth: 1
[2019-06-05 12:04:10] [config] enc-depth: 1
[2019-06-05 12:04:10] [config] enc-type: bidirectional
[2019-06-05 12:04:10] [config] exponential-smoothing: 0.0001
[2019-06-05 12:04:10] [config] grad-dropping-momentum: 0
[2019-06-05 12:04:10] [config] grad-dropping-rate: 0
[2019-06-05 12:04:10] [config] grad-dropping-warmup: 100
[2019-06-05 12:04:10] [config] guided-alignment: none
[2019-06-05 12:04:10] [config] guided-alignment-cost: mse
[2019-06-05 12:04:10] [config] guided-alignment-weight: 0.1
[2019-06-05 12:04:10] [config] ignore-model-config: false
[2019-06-05 12:04:10] [config] input-types:
[2019-06-05 12:04:10] [config]   []
[2019-06-05 12:04:10] [config] interpolate-env-vars: false
[2019-06-05 12:04:10] [config] keep-best: false
[2019-06-05 12:04:10] [config] label-smoothing: 0
[2019-06-05 12:04:10] [config] layer-normalization: true
[2019-06-05 12:04:10] [config] learn-rate: 0.0001
[2019-06-05 12:04:10] [config] log: model/train.log
[2019-06-05 12:04:10] [config] log-level: info
[2019-06-05 12:04:10] [config] log-time-zone: ""
[2019-06-05 12:04:10] [config] lr-decay: 0
[2019-06-05 12:04:10] [config] lr-decay-freq: 50000
[2019-06-05 12:04:10] [config] lr-decay-inv-sqrt:
[2019-06-05 12:04:10] [config]   - 0
[2019-06-05 12:04:10] [config] lr-decay-repeat-warmup: false
[2019-06-05 12:04:10] [config] lr-decay-reset-optimizer: false
[2019-06-05 12:04:10] [config] lr-decay-start:
[2019-06-05 12:04:10] [config]   - 10
[2019-06-05 12:04:10] [config]   - 1
[2019-06-05 12:04:10] [config] lr-decay-strategy: epoch+stalled
[2019-06-05 12:04:10] [config] lr-report: false
[2019-06-05 12:04:10] [config] lr-warmup: 0
[2019-06-05 12:04:10] [config] lr-warmup-at-reload: false
[2019-06-05 12:04:10] [config] lr-warmup-cycle: false
[2019-06-05 12:04:10] [config] lr-warmup-start-rate: 0
[2019-06-05 12:04:10] [config] max-length: 50
[2019-06-05 12:04:10] [config] max-length-crop: false
[2019-06-05 12:04:10] [config] max-length-factor: 3
[2019-06-05 12:04:10] [config] maxi-batch: 100
[2019-06-05 12:04:10] [config] maxi-batch-sort: trg
[2019-06-05 12:04:10] [config] mini-batch: 64
[2019-06-05 12:04:10] [config] mini-batch-fit: true
[2019-06-05 12:04:10] [config] mini-batch-fit-step: 10
[2019-06-05 12:04:10] [config] mini-batch-overstuff: 1
[2019-06-05 12:04:10] [config] mini-batch-track-lr: false
[2019-06-05 12:04:10] [config] mini-batch-understuff: 1
[2019-06-05 12:04:10] [config] mini-batch-warmup: 0
[2019-06-05 12:04:10] [config] mini-batch-words: 0
[2019-06-05 12:04:10] [config] mini-batch-words-ref: 0
[2019-06-05 12:04:10] [config] model: model/model.npz
[2019-06-05 12:04:10] [config] multi-loss-type: sum
[2019-06-05 12:04:10] [config] multi-node: false
[2019-06-05 12:04:10] [config] multi-node-overlap: true
[2019-06-05 12:04:10] [config] n-best: false
[2019-06-05 12:04:10] [config] no-nccl: false
[2019-06-05 12:04:10] [config] no-reload: false
[2019-06-05 12:04:10] [config] no-restore-corpus: false
[2019-06-05 12:04:10] [config] no-shuffle: false
[2019-06-05 12:04:10] [config] normalize: 1
[2019-06-05 12:04:10] [config] num-devices: 0
[2019-06-05 12:04:10] [config] optimizer: adam
[2019-06-05 12:04:10] [config] optimizer-delay: 1
[2019-06-05 12:04:10] [config] optimizer-params:
[2019-06-05 12:04:10] [config]   []
[2019-06-05 12:04:10] [config] overwrite: false
[2019-06-05 12:04:10] [config] pretrained-model: ""
[2019-06-05 12:04:10] [config] quiet: false
[2019-06-05 12:04:10] [config] quiet-translation: true
[2019-06-05 12:04:10] [config] relative-paths: false
[2019-06-05 12:04:10] [config] right-left: false
[2019-06-05 12:04:10] [config] save-freq: 20000
[2019-06-05 12:04:10] [config] seed: 1111
[2019-06-05 12:04:10] [config] shuffle-in-ram: false
[2019-06-05 12:04:10] [config] skip: false
[2019-06-05 12:04:10] [config] sqlite: ""
[2019-06-05 12:04:10] [config] sqlite-drop: false
[2019-06-05 12:04:10] [config] sync-sgd: true
[2019-06-05 12:04:10] [config] tempdir: .
[2019-06-05 12:04:10] [config] tied-embeddings: false
[2019-06-05 12:04:10] [config] tied-embeddings-all: false
[2019-06-05 12:04:10] [config] tied-embeddings-src: false
[2019-06-05 12:04:10] [config] train-sets:
[2019-06-05 12:04:10] [config]   - data/train.bpe.de
[2019-06-05 12:04:10] [config]   - data/train.bpe.en
[2019-06-05 12:04:10] [config] transformer-aan-activation: swish
[2019-06-05 12:04:10] [config] transformer-aan-depth: 2
[2019-06-05 12:04:10] [config] transformer-aan-nogate: false
[2019-06-05 12:04:10] [config] transformer-decoder-autoreg: self-attention
[2019-06-05 12:04:10] [config] transformer-dim-aan: 2048
[2019-06-05 12:04:10] [config] transformer-dim-ffn: 2048
[2019-06-05 12:04:10] [config] transformer-dropout: 0
[2019-06-05 12:04:10] [config] transformer-dropout-attention: 0
[2019-06-05 12:04:10] [config] transformer-dropout-ffn: 0
[2019-06-05 12:04:10] [config] transformer-ffn-activation: swish
[2019-06-05 12:04:10] [config] transformer-ffn-depth: 2
[2019-06-05 12:04:10] [config] transformer-guided-alignment-layer: last
[2019-06-05 12:04:10] [config] transformer-heads: 8
[2019-06-05 12:04:10] [config] transformer-no-projection: false
[2019-06-05 12:04:10] [config] transformer-postprocess: dan
[2019-06-05 12:04:10] [config] transformer-postprocess-emb: d
[2019-06-05 12:04:10] [config] transformer-preprocess: ""
[2019-06-05 12:04:10] [config] transformer-tied-layers:
[2019-06-05 12:04:10] [config]   []
[2019-06-05 12:04:10] [config] transformer-train-position-embeddings: false
[2019-06-05 12:04:10] [config] type: amun
[2019-06-05 12:04:10] [config] ulr: false
[2019-06-05 12:04:10] [config] ulr-dim-emb: 0
[2019-06-05 12:04:10] [config] ulr-dropout: 0
[2019-06-05 12:04:10] [config] ulr-keys-vectors: ""
[2019-06-05 12:04:10] [config] ulr-query-vectors: ""
[2019-06-05 12:04:10] [config] ulr-softmax-temperature: 1
[2019-06-05 12:04:10] [config] ulr-trainable-transformation: false
[2019-06-05 12:04:10] [config] valid-freq: 20000
[2019-06-05 12:04:10] [config] valid-log: model/valid.log
[2019-06-05 12:04:10] [config] valid-max-length: 1000
[2019-06-05 12:04:10] [config] valid-metrics:
[2019-06-05 12:04:10] [config]   - cross-entropy
[2019-06-05 12:04:10] [config]   - perplexity
[2019-06-05 12:04:10] [config]   - translation
[2019-06-05 12:04:10] [config] valid-mini-batch: 8
[2019-06-05 12:04:10] [config] valid-script-path: ./score-dev.sh
[2019-06-05 12:04:10] [config] valid-sets:
[2019-06-05 12:04:10] [config]   - data/dev.bpe.de
[2019-06-05 12:04:10] [config]   - data/dev.bpe.en
[2019-06-05 12:04:10] [config] valid-translation-output: model/dev.out
[2019-06-05 12:04:10] [config] vocabs:
[2019-06-05 12:04:10] [config]   - data/train.bpe.de.json
[2019-06-05 12:04:10] [config]   - data/train.bpe.en.json
[2019-06-05 12:04:10] [config] word-penalty: 0
[2019-06-05 12:04:10] [config] workspace: 3000
[2019-06-05 12:04:10] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-06-05 12:04:10] Using synchronous training
[2019-06-05 12:04:10] [data] Loading vocabulary from JSON/Yaml file data/train.bpe.de.json
[2019-06-05 12:04:10] [data] Using unused word id eos for 0
[2019-06-05 12:04:10] [data] Using unused word id UNK for 1
[2019-06-05 12:04:10] [data] Setting vocabulary size for input 0 to 50000
[2019-06-05 12:04:10] [data] Loading vocabulary from JSON/Yaml file data/train.bpe.en.json
[2019-06-05 12:04:10] [data] Using unused word id eos for 0
[2019-06-05 12:04:10] [data] Using unused word id UNK for 1
[2019-06-05 12:04:10] [data] Setting vocabulary size for input 1 to 50000
[2019-06-05 12:04:10] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-06-05 12:04:10] [batching] Collecting statistics for batch fitting with step size 10
[2019-06-05 12:04:12] [memory] Extending reserved space to 3072 MB (device gpu0)
[2019-06-05 12:04:12] Error: CUDA error 2 'out of memory' - /fs/bil0/abdel/marian-dev/src/tensors/gpu/device.cu:38: cudaMalloc(&data_, size)
[2019-06-05 12:04:12] Error: Aborted from virtual void marian::gpu::Device::reserve(size_t) in /fs/bil0/abdel/marian-dev/src/tensors/gpu/device.cu:38

[CALL STACK]
[0x19f32c1]         marian::gpu::Device::  reserve  (unsigned long)    + 0x1401
[0x93c8cb]          marian::SyncGraphGroup::  SyncGraphGroup  (std::shared_ptr<marian::Options>,  std::shared_ptr<marian::IMPIWrapper>) + 0xdcb
[0x605a90]          std::shared_ptr<marian::SyncGraphGroup> marian::  New  <marian::SyncGraphGroup,std::shared_ptr<marian::Options>&,std::shared_ptr<marian::IMPIWrapper>&>(std::shared_ptr<marian::Options>&,  std::shared_ptr<marian::IMPIWrapper>&) + 0x70
[0x66f24c]          marian::Train<marian::SyncGraphGroup>::  run  ()   + 0x35c
[0x5a13aa]          mainTrainer  (int,  char**)                        + 0x2ca
[0x57dd1a]          main                                               + 0x8a
[0x7fe5b966a830]    __libc_start_main                                  + 0xf0
[0x59edc9]          _start                                             + 0x29

[2019-06-05 12:34:13] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-06-05 12:34:13] [marian] Running on baldur as process 49921 with command line:
[2019-06-05 12:34:13] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model model/model.npz -T . --devices 0 --train-sets data/train.bpe.de data/train.bpe.en --vocabs data/train.bpe.de.json data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets data/dev.bpe.de data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output model/dev.out --valid-script-path ./score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log model/train.log --valid-log model/valid.log
[2019-06-05 12:34:13] [config] after-batches: 0
[2019-06-05 12:34:13] [config] after-epochs: 0
[2019-06-05 12:34:13] [config] allow-unk: false
[2019-06-05 12:34:13] [config] beam-size: 12
[2019-06-05 12:34:13] [config] bert-class-symbol: "[CLS]"
[2019-06-05 12:34:13] [config] bert-mask-symbol: "[MASK]"
[2019-06-05 12:34:13] [config] bert-masking-fraction: 0.15
[2019-06-05 12:34:13] [config] bert-sep-symbol: "[SEP]"
[2019-06-05 12:34:13] [config] bert-train-type-embeddings: true
[2019-06-05 12:34:13] [config] bert-type-vocab-size: 2
[2019-06-05 12:34:13] [config] best-deep: false
[2019-06-05 12:34:13] [config] clip-gemm: 0
[2019-06-05 12:34:13] [config] clip-norm: 1
[2019-06-05 12:34:13] [config] cost-type: ce-mean
[2019-06-05 12:34:13] [config] cpu-threads: 0
[2019-06-05 12:34:13] [config] data-weighting: ""
[2019-06-05 12:34:13] [config] data-weighting-type: sentence
[2019-06-05 12:34:13] [config] dec-cell: gru
[2019-06-05 12:34:13] [config] dec-cell-base-depth: 2
[2019-06-05 12:34:13] [config] dec-cell-high-depth: 1
[2019-06-05 12:34:13] [config] dec-depth: 1
[2019-06-05 12:34:13] [config] devices:
[2019-06-05 12:34:13] [config]   - 0
[2019-06-05 12:34:13] [config] dim-emb: 512
[2019-06-05 12:34:13] [config] dim-rnn: 1024
[2019-06-05 12:34:13] [config] dim-vocabs:
[2019-06-05 12:34:13] [config]   - 50000
[2019-06-05 12:34:13] [config]   - 50000
[2019-06-05 12:34:13] [config] disp-first: 0
[2019-06-05 12:34:13] [config] disp-freq: 2000
[2019-06-05 12:34:13] [config] disp-label-counts: false
[2019-06-05 12:34:13] [config] dropout-rnn: 0.2
[2019-06-05 12:34:13] [config] dropout-src: 0.1
[2019-06-05 12:34:13] [config] dropout-trg: 0.1
[2019-06-05 12:34:13] [config] dump-config: ""
[2019-06-05 12:34:13] [config] early-stopping: 5
[2019-06-05 12:34:13] [config] embedding-fix-src: false
[2019-06-05 12:34:13] [config] embedding-fix-trg: false
[2019-06-05 12:34:13] [config] embedding-normalization: false
[2019-06-05 12:34:13] [config] embedding-vectors:
[2019-06-05 12:34:13] [config]   []
[2019-06-05 12:34:13] [config] enc-cell: gru
[2019-06-05 12:34:13] [config] enc-cell-depth: 1
[2019-06-05 12:34:13] [config] enc-depth: 1
[2019-06-05 12:34:13] [config] enc-type: bidirectional
[2019-06-05 12:34:13] [config] exponential-smoothing: 0.0001
[2019-06-05 12:34:13] [config] grad-dropping-momentum: 0
[2019-06-05 12:34:13] [config] grad-dropping-rate: 0
[2019-06-05 12:34:13] [config] grad-dropping-warmup: 100
[2019-06-05 12:34:13] [config] guided-alignment: none
[2019-06-05 12:34:13] [config] guided-alignment-cost: mse
[2019-06-05 12:34:13] [config] guided-alignment-weight: 0.1
[2019-06-05 12:34:13] [config] ignore-model-config: false
[2019-06-05 12:34:13] [config] input-types:
[2019-06-05 12:34:13] [config]   []
[2019-06-05 12:34:13] [config] interpolate-env-vars: false
[2019-06-05 12:34:13] [config] keep-best: false
[2019-06-05 12:34:13] [config] label-smoothing: 0
[2019-06-05 12:34:13] [config] layer-normalization: true
[2019-06-05 12:34:13] [config] learn-rate: 0.0001
[2019-06-05 12:34:13] [config] log: model/train.log
[2019-06-05 12:34:13] [config] log-level: info
[2019-06-05 12:34:13] [config] log-time-zone: ""
[2019-06-05 12:34:13] [config] lr-decay: 0
[2019-06-05 12:34:13] [config] lr-decay-freq: 50000
[2019-06-05 12:34:13] [config] lr-decay-inv-sqrt:
[2019-06-05 12:34:13] [config]   - 0
[2019-06-05 12:34:13] [config] lr-decay-repeat-warmup: false
[2019-06-05 12:34:13] [config] lr-decay-reset-optimizer: false
[2019-06-05 12:34:13] [config] lr-decay-start:
[2019-06-05 12:34:13] [config]   - 10
[2019-06-05 12:34:13] [config]   - 1
[2019-06-05 12:34:13] [config] lr-decay-strategy: epoch+stalled
[2019-06-05 12:34:13] [config] lr-report: false
[2019-06-05 12:34:13] [config] lr-warmup: 0
[2019-06-05 12:34:13] [config] lr-warmup-at-reload: false
[2019-06-05 12:34:13] [config] lr-warmup-cycle: false
[2019-06-05 12:34:13] [config] lr-warmup-start-rate: 0
[2019-06-05 12:34:13] [config] max-length: 50
[2019-06-05 12:34:13] [config] max-length-crop: false
[2019-06-05 12:34:13] [config] max-length-factor: 3
[2019-06-05 12:34:13] [config] maxi-batch: 100
[2019-06-05 12:34:13] [config] maxi-batch-sort: trg
[2019-06-05 12:34:13] [config] mini-batch: 64
[2019-06-05 12:34:13] [config] mini-batch-fit: true
[2019-06-05 12:34:13] [config] mini-batch-fit-step: 10
[2019-06-05 12:34:13] [config] mini-batch-overstuff: 1
[2019-06-05 12:34:13] [config] mini-batch-track-lr: false
[2019-06-05 12:34:13] [config] mini-batch-understuff: 1
[2019-06-05 12:34:13] [config] mini-batch-warmup: 0
[2019-06-05 12:34:13] [config] mini-batch-words: 0
[2019-06-05 12:34:13] [config] mini-batch-words-ref: 0
[2019-06-05 12:34:13] [config] model: model/model.npz
[2019-06-05 12:34:13] [config] multi-loss-type: sum
[2019-06-05 12:34:13] [config] multi-node: false
[2019-06-05 12:34:13] [config] multi-node-overlap: true
[2019-06-05 12:34:13] [config] n-best: false
[2019-06-05 12:34:13] [config] no-nccl: false
[2019-06-05 12:34:13] [config] no-reload: false
[2019-06-05 12:34:13] [config] no-restore-corpus: false
[2019-06-05 12:34:13] [config] no-shuffle: false
[2019-06-05 12:34:13] [config] normalize: 1
[2019-06-05 12:34:13] [config] num-devices: 0
[2019-06-05 12:34:13] [config] optimizer: adam
[2019-06-05 12:34:13] [config] optimizer-delay: 1
[2019-06-05 12:34:13] [config] optimizer-params:
[2019-06-05 12:34:13] [config]   []
[2019-06-05 12:34:13] [config] overwrite: false
[2019-06-05 12:34:13] [config] pretrained-model: ""
[2019-06-05 12:34:13] [config] quiet: false
[2019-06-05 12:34:13] [config] quiet-translation: true
[2019-06-05 12:34:13] [config] relative-paths: false
[2019-06-05 12:34:13] [config] right-left: false
[2019-06-05 12:34:13] [config] save-freq: 20000
[2019-06-05 12:34:13] [config] seed: 1111
[2019-06-05 12:34:13] [config] shuffle-in-ram: false
[2019-06-05 12:34:13] [config] skip: false
[2019-06-05 12:34:13] [config] sqlite: ""
[2019-06-05 12:34:13] [config] sqlite-drop: false
[2019-06-05 12:34:13] [config] sync-sgd: true
[2019-06-05 12:34:13] [config] tempdir: .
[2019-06-05 12:34:13] [config] tied-embeddings: false
[2019-06-05 12:34:13] [config] tied-embeddings-all: false
[2019-06-05 12:34:13] [config] tied-embeddings-src: false
[2019-06-05 12:34:13] [config] train-sets:
[2019-06-05 12:34:13] [config]   - data/train.bpe.de
[2019-06-05 12:34:13] [config]   - data/train.bpe.en
[2019-06-05 12:34:13] [config] transformer-aan-activation: swish
[2019-06-05 12:34:13] [config] transformer-aan-depth: 2
[2019-06-05 12:34:13] [config] transformer-aan-nogate: false
[2019-06-05 12:34:13] [config] transformer-decoder-autoreg: self-attention
[2019-06-05 12:34:13] [config] transformer-dim-aan: 2048
[2019-06-05 12:34:13] [config] transformer-dim-ffn: 2048
[2019-06-05 12:34:13] [config] transformer-dropout: 0
[2019-06-05 12:34:13] [config] transformer-dropout-attention: 0
[2019-06-05 12:34:13] [config] transformer-dropout-ffn: 0
[2019-06-05 12:34:13] [config] transformer-ffn-activation: swish
[2019-06-05 12:34:13] [config] transformer-ffn-depth: 2
[2019-06-05 12:34:13] [config] transformer-guided-alignment-layer: last
[2019-06-05 12:34:13] [config] transformer-heads: 8
[2019-06-05 12:34:13] [config] transformer-no-projection: false
[2019-06-05 12:34:13] [config] transformer-postprocess: dan
[2019-06-05 12:34:13] [config] transformer-postprocess-emb: d
[2019-06-05 12:34:13] [config] transformer-preprocess: ""
[2019-06-05 12:34:13] [config] transformer-tied-layers:
[2019-06-05 12:34:13] [config]   []
[2019-06-05 12:34:13] [config] transformer-train-position-embeddings: false
[2019-06-05 12:34:13] [config] type: amun
[2019-06-05 12:34:13] [config] ulr: false
[2019-06-05 12:34:13] [config] ulr-dim-emb: 0
[2019-06-05 12:34:13] [config] ulr-dropout: 0
[2019-06-05 12:34:13] [config] ulr-keys-vectors: ""
[2019-06-05 12:34:13] [config] ulr-query-vectors: ""
[2019-06-05 12:34:13] [config] ulr-softmax-temperature: 1
[2019-06-05 12:34:13] [config] ulr-trainable-transformation: false
[2019-06-05 12:34:13] [config] valid-freq: 20000
[2019-06-05 12:34:13] [config] valid-log: model/valid.log
[2019-06-05 12:34:13] [config] valid-max-length: 1000
[2019-06-05 12:34:13] [config] valid-metrics:
[2019-06-05 12:34:13] [config]   - cross-entropy
[2019-06-05 12:34:13] [config]   - perplexity
[2019-06-05 12:34:13] [config]   - translation
[2019-06-05 12:34:13] [config] valid-mini-batch: 8
[2019-06-05 12:34:13] [config] valid-script-path: ./score-dev.sh
[2019-06-05 12:34:13] [config] valid-sets:
[2019-06-05 12:34:13] [config]   - data/dev.bpe.de
[2019-06-05 12:34:13] [config]   - data/dev.bpe.en
[2019-06-05 12:34:13] [config] valid-translation-output: model/dev.out
[2019-06-05 12:34:13] [config] vocabs:
[2019-06-05 12:34:13] [config]   - data/train.bpe.de.json
[2019-06-05 12:34:13] [config]   - data/train.bpe.en.json
[2019-06-05 12:34:13] [config] word-penalty: 0
[2019-06-05 12:34:13] [config] workspace: 3000
[2019-06-05 12:34:13] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-06-05 12:34:13] Using synchronous training
[2019-06-05 12:34:13] [data] Loading vocabulary from JSON/Yaml file data/train.bpe.de.json
[2019-06-05 12:34:14] [data] Using unused word id eos for 0
[2019-06-05 12:34:14] [data] Using unused word id UNK for 1
[2019-06-05 12:34:14] [data] Setting vocabulary size for input 0 to 50000
[2019-06-05 12:34:14] [data] Loading vocabulary from JSON/Yaml file data/train.bpe.en.json
[2019-06-05 12:34:14] [data] Using unused word id eos for 0
[2019-06-05 12:34:14] [data] Using unused word id UNK for 1
[2019-06-05 12:34:14] [data] Setting vocabulary size for input 1 to 50000
[2019-06-05 12:34:14] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-06-05 12:34:14] [batching] Collecting statistics for batch fitting with step size 10
[2019-06-05 12:34:15] [memory] Extending reserved space to 3072 MB (device gpu0)
[2019-06-05 12:34:16] Error: CUDA error 2 'out of memory' - /fs/bil0/abdel/marian-dev/src/tensors/gpu/device.cu:38: cudaMalloc(&data_, size)
[2019-06-05 12:34:16] Error: Aborted from virtual void marian::gpu::Device::reserve(size_t) in /fs/bil0/abdel/marian-dev/src/tensors/gpu/device.cu:38

[CALL STACK]
[0x19f32c1]         marian::gpu::Device::  reserve  (unsigned long)    + 0x1401
[0x93c8cb]          marian::SyncGraphGroup::  SyncGraphGroup  (std::shared_ptr<marian::Options>,  std::shared_ptr<marian::IMPIWrapper>) + 0xdcb
[0x605a90]          std::shared_ptr<marian::SyncGraphGroup> marian::  New  <marian::SyncGraphGroup,std::shared_ptr<marian::Options>&,std::shared_ptr<marian::IMPIWrapper>&>(std::shared_ptr<marian::Options>&,  std::shared_ptr<marian::IMPIWrapper>&) + 0x70
[0x66f24c]          marian::Train<marian::SyncGraphGroup>::  run  ()   + 0x35c
[0x5a13aa]          mainTrainer  (int,  char**)                        + 0x2ca
[0x57dd1a]          main                                               + 0x8a
[0x7f8d95ddd830]    __libc_start_main                                  + 0xf0
[0x59edc9]          _start                                             + 0x29

[2019-06-05 12:36:28] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-06-05 12:36:28] [marian] Running on baldur as process 50014 with command line:
[2019-06-05 12:36:28] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model model/model.npz -T . --devices 0 --train-sets data/train.bpe.de data/train.bpe.en --vocabs data/train.bpe.de.json data/train.bpe.en.json --mini-batch-fit -w 2000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets data/dev.bpe.de data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output model/dev.out --valid-script-path ./score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log model/train.log --valid-log model/valid.log
[2019-06-05 12:36:28] [config] after-batches: 0
[2019-06-05 12:36:28] [config] after-epochs: 0
[2019-06-05 12:36:28] [config] allow-unk: false
[2019-06-05 12:36:28] [config] beam-size: 12
[2019-06-05 12:36:28] [config] bert-class-symbol: "[CLS]"
[2019-06-05 12:36:28] [config] bert-mask-symbol: "[MASK]"
[2019-06-05 12:36:28] [config] bert-masking-fraction: 0.15
[2019-06-05 12:36:28] [config] bert-sep-symbol: "[SEP]"
[2019-06-05 12:36:28] [config] bert-train-type-embeddings: true
[2019-06-05 12:36:28] [config] bert-type-vocab-size: 2
[2019-06-05 12:36:28] [config] best-deep: false
[2019-06-05 12:36:28] [config] clip-gemm: 0
[2019-06-05 12:36:28] [config] clip-norm: 1
[2019-06-05 12:36:28] [config] cost-type: ce-mean
[2019-06-05 12:36:28] [config] cpu-threads: 0
[2019-06-05 12:36:28] [config] data-weighting: ""
[2019-06-05 12:36:28] [config] data-weighting-type: sentence
[2019-06-05 12:36:28] [config] dec-cell: gru
[2019-06-05 12:36:28] [config] dec-cell-base-depth: 2
[2019-06-05 12:36:28] [config] dec-cell-high-depth: 1
[2019-06-05 12:36:28] [config] dec-depth: 1
[2019-06-05 12:36:28] [config] devices:
[2019-06-05 12:36:28] [config]   - 0
[2019-06-05 12:36:28] [config] dim-emb: 512
[2019-06-05 12:36:28] [config] dim-rnn: 1024
[2019-06-05 12:36:28] [config] dim-vocabs:
[2019-06-05 12:36:28] [config]   - 50000
[2019-06-05 12:36:28] [config]   - 50000
[2019-06-05 12:36:28] [config] disp-first: 0
[2019-06-05 12:36:28] [config] disp-freq: 2000
[2019-06-05 12:36:28] [config] disp-label-counts: false
[2019-06-05 12:36:28] [config] dropout-rnn: 0.2
[2019-06-05 12:36:28] [config] dropout-src: 0.1
[2019-06-05 12:36:28] [config] dropout-trg: 0.1
[2019-06-05 12:36:28] [config] dump-config: ""
[2019-06-05 12:36:28] [config] early-stopping: 5
[2019-06-05 12:36:28] [config] embedding-fix-src: false
[2019-06-05 12:36:28] [config] embedding-fix-trg: false
[2019-06-05 12:36:28] [config] embedding-normalization: false
[2019-06-05 12:36:28] [config] embedding-vectors:
[2019-06-05 12:36:28] [config]   []
[2019-06-05 12:36:28] [config] enc-cell: gru
[2019-06-05 12:36:28] [config] enc-cell-depth: 1
[2019-06-05 12:36:28] [config] enc-depth: 1
[2019-06-05 12:36:28] [config] enc-type: bidirectional
[2019-06-05 12:36:28] [config] exponential-smoothing: 0.0001
[2019-06-05 12:36:28] [config] grad-dropping-momentum: 0
[2019-06-05 12:36:28] [config] grad-dropping-rate: 0
[2019-06-05 12:36:28] [config] grad-dropping-warmup: 100
[2019-06-05 12:36:28] [config] guided-alignment: none
[2019-06-05 12:36:28] [config] guided-alignment-cost: mse
[2019-06-05 12:36:28] [config] guided-alignment-weight: 0.1
[2019-06-05 12:36:28] [config] ignore-model-config: false
[2019-06-05 12:36:28] [config] input-types:
[2019-06-05 12:36:28] [config]   []
[2019-06-05 12:36:28] [config] interpolate-env-vars: false
[2019-06-05 12:36:28] [config] keep-best: false
[2019-06-05 12:36:28] [config] label-smoothing: 0
[2019-06-05 12:36:28] [config] layer-normalization: true
[2019-06-05 12:36:28] [config] learn-rate: 0.0001
[2019-06-05 12:36:28] [config] log: model/train.log
[2019-06-05 12:36:28] [config] log-level: info
[2019-06-05 12:36:28] [config] log-time-zone: ""
[2019-06-05 12:36:28] [config] lr-decay: 0
[2019-06-05 12:36:28] [config] lr-decay-freq: 50000
[2019-06-05 12:36:28] [config] lr-decay-inv-sqrt:
[2019-06-05 12:36:28] [config]   - 0
[2019-06-05 12:36:28] [config] lr-decay-repeat-warmup: false
[2019-06-05 12:36:28] [config] lr-decay-reset-optimizer: false
[2019-06-05 12:36:28] [config] lr-decay-start:
[2019-06-05 12:36:28] [config]   - 10
[2019-06-05 12:36:28] [config]   - 1
[2019-06-05 12:36:28] [config] lr-decay-strategy: epoch+stalled
[2019-06-05 12:36:28] [config] lr-report: false
[2019-06-05 12:36:28] [config] lr-warmup: 0
[2019-06-05 12:36:28] [config] lr-warmup-at-reload: false
[2019-06-05 12:36:28] [config] lr-warmup-cycle: false
[2019-06-05 12:36:28] [config] lr-warmup-start-rate: 0
[2019-06-05 12:36:28] [config] max-length: 50
[2019-06-05 12:36:28] [config] max-length-crop: false
[2019-06-05 12:36:28] [config] max-length-factor: 3
[2019-06-05 12:36:28] [config] maxi-batch: 100
[2019-06-05 12:36:28] [config] maxi-batch-sort: trg
[2019-06-05 12:36:28] [config] mini-batch: 64
[2019-06-05 12:36:28] [config] mini-batch-fit: true
[2019-06-05 12:36:28] [config] mini-batch-fit-step: 10
[2019-06-05 12:36:28] [config] mini-batch-overstuff: 1
[2019-06-05 12:36:28] [config] mini-batch-track-lr: false
[2019-06-05 12:36:28] [config] mini-batch-understuff: 1
[2019-06-05 12:36:28] [config] mini-batch-warmup: 0
[2019-06-05 12:36:28] [config] mini-batch-words: 0
[2019-06-05 12:36:28] [config] mini-batch-words-ref: 0
[2019-06-05 12:36:28] [config] model: model/model.npz
[2019-06-05 12:36:28] [config] multi-loss-type: sum
[2019-06-05 12:36:28] [config] multi-node: false
[2019-06-05 12:36:28] [config] multi-node-overlap: true
[2019-06-05 12:36:28] [config] n-best: false
[2019-06-05 12:36:28] [config] no-nccl: false
[2019-06-05 12:36:28] [config] no-reload: false
[2019-06-05 12:36:28] [config] no-restore-corpus: false
[2019-06-05 12:36:28] [config] no-shuffle: false
[2019-06-05 12:36:28] [config] normalize: 1
[2019-06-05 12:36:28] [config] num-devices: 0
[2019-06-05 12:36:28] [config] optimizer: adam
[2019-06-05 12:36:28] [config] optimizer-delay: 1
[2019-06-05 12:36:28] [config] optimizer-params:
[2019-06-05 12:36:28] [config]   []
[2019-06-05 12:36:28] [config] overwrite: false
[2019-06-05 12:36:28] [config] pretrained-model: ""
[2019-06-05 12:36:28] [config] quiet: false
[2019-06-05 12:36:28] [config] quiet-translation: true
[2019-06-05 12:36:28] [config] relative-paths: false
[2019-06-05 12:36:28] [config] right-left: false
[2019-06-05 12:36:28] [config] save-freq: 20000
[2019-06-05 12:36:28] [config] seed: 1111
[2019-06-05 12:36:28] [config] shuffle-in-ram: false
[2019-06-05 12:36:28] [config] skip: false
[2019-06-05 12:36:28] [config] sqlite: ""
[2019-06-05 12:36:28] [config] sqlite-drop: false
[2019-06-05 12:36:28] [config] sync-sgd: true
[2019-06-05 12:36:28] [config] tempdir: .
[2019-06-05 12:36:28] [config] tied-embeddings: false
[2019-06-05 12:36:28] [config] tied-embeddings-all: false
[2019-06-05 12:36:28] [config] tied-embeddings-src: false
[2019-06-05 12:36:28] [config] train-sets:
[2019-06-05 12:36:28] [config]   - data/train.bpe.de
[2019-06-05 12:36:28] [config]   - data/train.bpe.en
[2019-06-05 12:36:28] [config] transformer-aan-activation: swish
[2019-06-05 12:36:28] [config] transformer-aan-depth: 2
[2019-06-05 12:36:28] [config] transformer-aan-nogate: false
[2019-06-05 12:36:28] [config] transformer-decoder-autoreg: self-attention
[2019-06-05 12:36:28] [config] transformer-dim-aan: 2048
[2019-06-05 12:36:28] [config] transformer-dim-ffn: 2048
[2019-06-05 12:36:28] [config] transformer-dropout: 0
[2019-06-05 12:36:28] [config] transformer-dropout-attention: 0
[2019-06-05 12:36:28] [config] transformer-dropout-ffn: 0
[2019-06-05 12:36:28] [config] transformer-ffn-activation: swish
[2019-06-05 12:36:28] [config] transformer-ffn-depth: 2
[2019-06-05 12:36:28] [config] transformer-guided-alignment-layer: last
[2019-06-05 12:36:28] [config] transformer-heads: 8
[2019-06-05 12:36:28] [config] transformer-no-projection: false
[2019-06-05 12:36:28] [config] transformer-postprocess: dan
[2019-06-05 12:36:28] [config] transformer-postprocess-emb: d
[2019-06-05 12:36:28] [config] transformer-preprocess: ""
[2019-06-05 12:36:28] [config] transformer-tied-layers:
[2019-06-05 12:36:28] [config]   []
[2019-06-05 12:36:28] [config] transformer-train-position-embeddings: false
[2019-06-05 12:36:28] [config] type: amun
[2019-06-05 12:36:28] [config] ulr: false
[2019-06-05 12:36:28] [config] ulr-dim-emb: 0
[2019-06-05 12:36:28] [config] ulr-dropout: 0
[2019-06-05 12:36:28] [config] ulr-keys-vectors: ""
[2019-06-05 12:36:28] [config] ulr-query-vectors: ""
[2019-06-05 12:36:28] [config] ulr-softmax-temperature: 1
[2019-06-05 12:36:28] [config] ulr-trainable-transformation: false
[2019-06-05 12:36:28] [config] valid-freq: 20000
[2019-06-05 12:36:28] [config] valid-log: model/valid.log
[2019-06-05 12:36:28] [config] valid-max-length: 1000
[2019-06-05 12:36:28] [config] valid-metrics:
[2019-06-05 12:36:28] [config]   - cross-entropy
[2019-06-05 12:36:28] [config]   - perplexity
[2019-06-05 12:36:28] [config]   - translation
[2019-06-05 12:36:28] [config] valid-mini-batch: 8
[2019-06-05 12:36:28] [config] valid-script-path: ./score-dev.sh
[2019-06-05 12:36:28] [config] valid-sets:
[2019-06-05 12:36:28] [config]   - data/dev.bpe.de
[2019-06-05 12:36:28] [config]   - data/dev.bpe.en
[2019-06-05 12:36:28] [config] valid-translation-output: model/dev.out
[2019-06-05 12:36:28] [config] vocabs:
[2019-06-05 12:36:28] [config]   - data/train.bpe.de.json
[2019-06-05 12:36:28] [config]   - data/train.bpe.en.json
[2019-06-05 12:36:28] [config] word-penalty: 0
[2019-06-05 12:36:28] [config] workspace: 2000
[2019-06-05 12:36:28] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-06-05 12:36:28] Using synchronous training
[2019-06-05 12:36:28] [data] Loading vocabulary from JSON/Yaml file data/train.bpe.de.json
[2019-06-05 12:36:28] [data] Using unused word id eos for 0
[2019-06-05 12:36:28] [data] Using unused word id UNK for 1
[2019-06-05 12:36:28] [data] Setting vocabulary size for input 0 to 50000
[2019-06-05 12:36:28] [data] Loading vocabulary from JSON/Yaml file data/train.bpe.en.json
[2019-06-05 12:36:28] [data] Using unused word id eos for 0
[2019-06-05 12:36:28] [data] Using unused word id UNK for 1
[2019-06-05 12:36:28] [data] Setting vocabulary size for input 1 to 50000
[2019-06-05 12:36:28] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-06-05 12:36:28] [batching] Collecting statistics for batch fitting with step size 10
[2019-06-05 12:36:29] [memory] Extending reserved space to 2048 MB (device gpu0)
[2019-06-05 12:36:29] Error: CUDA error 2 'out of memory' - /fs/bil0/abdel/marian-dev/src/tensors/gpu/device.cu:38: cudaMalloc(&data_, size)
[2019-06-05 12:36:29] Error: Aborted from virtual void marian::gpu::Device::reserve(size_t) in /fs/bil0/abdel/marian-dev/src/tensors/gpu/device.cu:38

[CALL STACK]
[0x19f32c1]         marian::gpu::Device::  reserve  (unsigned long)    + 0x1401
[0x93c8cb]          marian::SyncGraphGroup::  SyncGraphGroup  (std::shared_ptr<marian::Options>,  std::shared_ptr<marian::IMPIWrapper>) + 0xdcb
[0x605a90]          std::shared_ptr<marian::SyncGraphGroup> marian::  New  <marian::SyncGraphGroup,std::shared_ptr<marian::Options>&,std::shared_ptr<marian::IMPIWrapper>&>(std::shared_ptr<marian::Options>&,  std::shared_ptr<marian::IMPIWrapper>&) + 0x70
[0x66f24c]          marian::Train<marian::SyncGraphGroup>::  run  ()   + 0x35c
[0x5a13aa]          mainTrainer  (int,  char**)                        + 0x2ca
[0x57dd1a]          main                                               + 0x8a
[0x7f0f7cc20830]    __libc_start_main                                  + 0xf0
[0x59edc9]          _start                                             + 0x29

[2019-06-05 12:36:58] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-06-05 12:36:58] [marian] Running on baldur as process 50029 with command line:
[2019-06-05 12:36:58] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model model/model.npz -T . --devices 0 --train-sets data/train.bpe.de data/train.bpe.en --vocabs data/train.bpe.de.json data/train.bpe.en.json --mini-batch-fit -w 1000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets data/dev.bpe.de data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output model/dev.out --valid-script-path ./score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log model/train.log --valid-log model/valid.log
[2019-06-05 12:36:58] [config] after-batches: 0
[2019-06-05 12:36:58] [config] after-epochs: 0
[2019-06-05 12:36:58] [config] allow-unk: false
[2019-06-05 12:36:58] [config] beam-size: 12
[2019-06-05 12:36:58] [config] bert-class-symbol: "[CLS]"
[2019-06-05 12:36:58] [config] bert-mask-symbol: "[MASK]"
[2019-06-05 12:36:58] [config] bert-masking-fraction: 0.15
[2019-06-05 12:36:58] [config] bert-sep-symbol: "[SEP]"
[2019-06-05 12:36:58] [config] bert-train-type-embeddings: true
[2019-06-05 12:36:58] [config] bert-type-vocab-size: 2
[2019-06-05 12:36:58] [config] best-deep: false
[2019-06-05 12:36:58] [config] clip-gemm: 0
[2019-06-05 12:36:58] [config] clip-norm: 1
[2019-06-05 12:36:58] [config] cost-type: ce-mean
[2019-06-05 12:36:58] [config] cpu-threads: 0
[2019-06-05 12:36:58] [config] data-weighting: ""
[2019-06-05 12:36:58] [config] data-weighting-type: sentence
[2019-06-05 12:36:58] [config] dec-cell: gru
[2019-06-05 12:36:58] [config] dec-cell-base-depth: 2
[2019-06-05 12:36:58] [config] dec-cell-high-depth: 1
[2019-06-05 12:36:58] [config] dec-depth: 1
[2019-06-05 12:36:58] [config] devices:
[2019-06-05 12:36:58] [config]   - 0
[2019-06-05 12:36:58] [config] dim-emb: 512
[2019-06-05 12:36:58] [config] dim-rnn: 1024
[2019-06-05 12:36:58] [config] dim-vocabs:
[2019-06-05 12:36:58] [config]   - 50000
[2019-06-05 12:36:58] [config]   - 50000
[2019-06-05 12:36:58] [config] disp-first: 0
[2019-06-05 12:36:58] [config] disp-freq: 2000
[2019-06-05 12:36:58] [config] disp-label-counts: false
[2019-06-05 12:36:58] [config] dropout-rnn: 0.2
[2019-06-05 12:36:58] [config] dropout-src: 0.1
[2019-06-05 12:36:58] [config] dropout-trg: 0.1
[2019-06-05 12:36:58] [config] dump-config: ""
[2019-06-05 12:36:58] [config] early-stopping: 5
[2019-06-05 12:36:58] [config] embedding-fix-src: false
[2019-06-05 12:36:58] [config] embedding-fix-trg: false
[2019-06-05 12:36:58] [config] embedding-normalization: false
[2019-06-05 12:36:58] [config] embedding-vectors:
[2019-06-05 12:36:58] [config]   []
[2019-06-05 12:36:58] [config] enc-cell: gru
[2019-06-05 12:36:58] [config] enc-cell-depth: 1
[2019-06-05 12:36:58] [config] enc-depth: 1
[2019-06-05 12:36:58] [config] enc-type: bidirectional
[2019-06-05 12:36:58] [config] exponential-smoothing: 0.0001
[2019-06-05 12:36:58] [config] grad-dropping-momentum: 0
[2019-06-05 12:36:58] [config] grad-dropping-rate: 0
[2019-06-05 12:36:58] [config] grad-dropping-warmup: 100
[2019-06-05 12:36:58] [config] guided-alignment: none
[2019-06-05 12:36:58] [config] guided-alignment-cost: mse
[2019-06-05 12:36:58] [config] guided-alignment-weight: 0.1
[2019-06-05 12:36:58] [config] ignore-model-config: false
[2019-06-05 12:36:58] [config] input-types:
[2019-06-05 12:36:58] [config]   []
[2019-06-05 12:36:58] [config] interpolate-env-vars: false
[2019-06-05 12:36:58] [config] keep-best: false
[2019-06-05 12:36:58] [config] label-smoothing: 0
[2019-06-05 12:36:58] [config] layer-normalization: true
[2019-06-05 12:36:58] [config] learn-rate: 0.0001
[2019-06-05 12:36:58] [config] log: model/train.log
[2019-06-05 12:36:58] [config] log-level: info
[2019-06-05 12:36:58] [config] log-time-zone: ""
[2019-06-05 12:36:58] [config] lr-decay: 0
[2019-06-05 12:36:58] [config] lr-decay-freq: 50000
[2019-06-05 12:36:58] [config] lr-decay-inv-sqrt:
[2019-06-05 12:36:58] [config]   - 0
[2019-06-05 12:36:58] [config] lr-decay-repeat-warmup: false
[2019-06-05 12:36:58] [config] lr-decay-reset-optimizer: false
[2019-06-05 12:36:58] [config] lr-decay-start:
[2019-06-05 12:36:58] [config]   - 10
[2019-06-05 12:36:58] [config]   - 1
[2019-06-05 12:36:58] [config] lr-decay-strategy: epoch+stalled
[2019-06-05 12:36:58] [config] lr-report: false
[2019-06-05 12:36:58] [config] lr-warmup: 0
[2019-06-05 12:36:58] [config] lr-warmup-at-reload: false
[2019-06-05 12:36:58] [config] lr-warmup-cycle: false
[2019-06-05 12:36:58] [config] lr-warmup-start-rate: 0
[2019-06-05 12:36:58] [config] max-length: 50
[2019-06-05 12:36:58] [config] max-length-crop: false
[2019-06-05 12:36:58] [config] max-length-factor: 3
[2019-06-05 12:36:58] [config] maxi-batch: 100
[2019-06-05 12:36:58] [config] maxi-batch-sort: trg
[2019-06-05 12:36:58] [config] mini-batch: 64
[2019-06-05 12:36:58] [config] mini-batch-fit: true
[2019-06-05 12:36:58] [config] mini-batch-fit-step: 10
[2019-06-05 12:36:58] [config] mini-batch-overstuff: 1
[2019-06-05 12:36:58] [config] mini-batch-track-lr: false
[2019-06-05 12:36:58] [config] mini-batch-understuff: 1
[2019-06-05 12:36:58] [config] mini-batch-warmup: 0
[2019-06-05 12:36:58] [config] mini-batch-words: 0
[2019-06-05 12:36:58] [config] mini-batch-words-ref: 0
[2019-06-05 12:36:58] [config] model: model/model.npz
[2019-06-05 12:36:58] [config] multi-loss-type: sum
[2019-06-05 12:36:58] [config] multi-node: false
[2019-06-05 12:36:58] [config] multi-node-overlap: true
[2019-06-05 12:36:58] [config] n-best: false
[2019-06-05 12:36:58] [config] no-nccl: false
[2019-06-05 12:36:58] [config] no-reload: false
[2019-06-05 12:36:58] [config] no-restore-corpus: false
[2019-06-05 12:36:58] [config] no-shuffle: false
[2019-06-05 12:36:58] [config] normalize: 1
[2019-06-05 12:36:58] [config] num-devices: 0
[2019-06-05 12:36:58] [config] optimizer: adam
[2019-06-05 12:36:58] [config] optimizer-delay: 1
[2019-06-05 12:36:58] [config] optimizer-params:
[2019-06-05 12:36:58] [config]   []
[2019-06-05 12:36:58] [config] overwrite: false
[2019-06-05 12:36:58] [config] pretrained-model: ""
[2019-06-05 12:36:58] [config] quiet: false
[2019-06-05 12:36:58] [config] quiet-translation: true
[2019-06-05 12:36:58] [config] relative-paths: false
[2019-06-05 12:36:58] [config] right-left: false
[2019-06-05 12:36:58] [config] save-freq: 20000
[2019-06-05 12:36:58] [config] seed: 1111
[2019-06-05 12:36:58] [config] shuffle-in-ram: false
[2019-06-05 12:36:58] [config] skip: false
[2019-06-05 12:36:58] [config] sqlite: ""
[2019-06-05 12:36:58] [config] sqlite-drop: false
[2019-06-05 12:36:58] [config] sync-sgd: true
[2019-06-05 12:36:58] [config] tempdir: .
[2019-06-05 12:36:58] [config] tied-embeddings: false
[2019-06-05 12:36:58] [config] tied-embeddings-all: false
[2019-06-05 12:36:58] [config] tied-embeddings-src: false
[2019-06-05 12:36:58] [config] train-sets:
[2019-06-05 12:36:58] [config]   - data/train.bpe.de
[2019-06-05 12:36:58] [config]   - data/train.bpe.en
[2019-06-05 12:36:58] [config] transformer-aan-activation: swish
[2019-06-05 12:36:58] [config] transformer-aan-depth: 2
[2019-06-05 12:36:58] [config] transformer-aan-nogate: false
[2019-06-05 12:36:58] [config] transformer-decoder-autoreg: self-attention
[2019-06-05 12:36:58] [config] transformer-dim-aan: 2048
[2019-06-05 12:36:58] [config] transformer-dim-ffn: 2048
[2019-06-05 12:36:58] [config] transformer-dropout: 0
[2019-06-05 12:36:58] [config] transformer-dropout-attention: 0
[2019-06-05 12:36:58] [config] transformer-dropout-ffn: 0
[2019-06-05 12:36:58] [config] transformer-ffn-activation: swish
[2019-06-05 12:36:58] [config] transformer-ffn-depth: 2
[2019-06-05 12:36:58] [config] transformer-guided-alignment-layer: last
[2019-06-05 12:36:58] [config] transformer-heads: 8
[2019-06-05 12:36:58] [config] transformer-no-projection: false
[2019-06-05 12:36:58] [config] transformer-postprocess: dan
[2019-06-05 12:36:58] [config] transformer-postprocess-emb: d
[2019-06-05 12:36:58] [config] transformer-preprocess: ""
[2019-06-05 12:36:58] [config] transformer-tied-layers:
[2019-06-05 12:36:58] [config]   []
[2019-06-05 12:36:58] [config] transformer-train-position-embeddings: false
[2019-06-05 12:36:58] [config] type: amun
[2019-06-05 12:36:58] [config] ulr: false
[2019-06-05 12:36:58] [config] ulr-dim-emb: 0
[2019-06-05 12:36:58] [config] ulr-dropout: 0
[2019-06-05 12:36:58] [config] ulr-keys-vectors: ""
[2019-06-05 12:36:58] [config] ulr-query-vectors: ""
[2019-06-05 12:36:58] [config] ulr-softmax-temperature: 1
[2019-06-05 12:36:58] [config] ulr-trainable-transformation: false
[2019-06-05 12:36:58] [config] valid-freq: 20000
[2019-06-05 12:36:58] [config] valid-log: model/valid.log
[2019-06-05 12:36:58] [config] valid-max-length: 1000
[2019-06-05 12:36:58] [config] valid-metrics:
[2019-06-05 12:36:58] [config]   - cross-entropy
[2019-06-05 12:36:58] [config]   - perplexity
[2019-06-05 12:36:58] [config]   - translation
[2019-06-05 12:36:58] [config] valid-mini-batch: 8
[2019-06-05 12:36:58] [config] valid-script-path: ./score-dev.sh
[2019-06-05 12:36:58] [config] valid-sets:
[2019-06-05 12:36:58] [config]   - data/dev.bpe.de
[2019-06-05 12:36:58] [config]   - data/dev.bpe.en
[2019-06-05 12:36:58] [config] valid-translation-output: model/dev.out
[2019-06-05 12:36:58] [config] vocabs:
[2019-06-05 12:36:58] [config]   - data/train.bpe.de.json
[2019-06-05 12:36:58] [config]   - data/train.bpe.en.json
[2019-06-05 12:36:58] [config] word-penalty: 0
[2019-06-05 12:36:58] [config] workspace: 1000
[2019-06-05 12:36:58] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-06-05 12:36:58] Using synchronous training
[2019-06-05 12:36:58] [data] Loading vocabulary from JSON/Yaml file data/train.bpe.de.json
[2019-06-05 12:36:58] [data] Using unused word id eos for 0
[2019-06-05 12:36:58] [data] Using unused word id UNK for 1
[2019-06-05 12:36:58] [data] Setting vocabulary size for input 0 to 50000
[2019-06-05 12:36:58] [data] Loading vocabulary from JSON/Yaml file data/train.bpe.en.json
[2019-06-05 12:36:58] [data] Using unused word id eos for 0
[2019-06-05 12:36:58] [data] Using unused word id UNK for 1
[2019-06-05 12:36:58] [data] Setting vocabulary size for input 1 to 50000
[2019-06-05 12:36:58] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-06-05 12:36:58] [batching] Collecting statistics for batch fitting with step size 10
[2019-06-05 12:36:59] [memory] Extending reserved space to 1024 MB (device gpu0)
[2019-06-05 12:36:59] Error: CUDA error 2 'out of memory' - /fs/bil0/abdel/marian-dev/src/tensors/gpu/device.cu:38: cudaMalloc(&data_, size)
[2019-06-05 12:36:59] Error: Aborted from virtual void marian::gpu::Device::reserve(size_t) in /fs/bil0/abdel/marian-dev/src/tensors/gpu/device.cu:38

[CALL STACK]
[0x19f32c1]         marian::gpu::Device::  reserve  (unsigned long)    + 0x1401
[0x93c8cb]          marian::SyncGraphGroup::  SyncGraphGroup  (std::shared_ptr<marian::Options>,  std::shared_ptr<marian::IMPIWrapper>) + 0xdcb
[0x605a90]          std::shared_ptr<marian::SyncGraphGroup> marian::  New  <marian::SyncGraphGroup,std::shared_ptr<marian::Options>&,std::shared_ptr<marian::IMPIWrapper>&>(std::shared_ptr<marian::Options>&,  std::shared_ptr<marian::IMPIWrapper>&) + 0x70
[0x66f24c]          marian::Train<marian::SyncGraphGroup>::  run  ()   + 0x35c
[0x5a13aa]          mainTrainer  (int,  char**)                        + 0x2ca
[0x57dd1a]          main                                               + 0x8a
[0x7f72cba2b830]    __libc_start_main                                  + 0xf0
[0x59edc9]          _start                                             + 0x29

[2019-06-05 12:37:29] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-06-05 12:37:29] [marian] Running on baldur as process 50049 with command line:
[2019-06-05 12:37:29] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model model/model.npz -T . --devices 0 --train-sets data/train.bpe.de data/train.bpe.en --vocabs data/train.bpe.de.json data/train.bpe.en.json --mini-batch-fit -w 500 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets data/dev.bpe.de data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output model/dev.out --valid-script-path ./score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log model/train.log --valid-log model/valid.log
[2019-06-05 12:37:29] [config] after-batches: 0
[2019-06-05 12:37:29] [config] after-epochs: 0
[2019-06-05 12:37:29] [config] allow-unk: false
[2019-06-05 12:37:29] [config] beam-size: 12
[2019-06-05 12:37:29] [config] bert-class-symbol: "[CLS]"
[2019-06-05 12:37:29] [config] bert-mask-symbol: "[MASK]"
[2019-06-05 12:37:29] [config] bert-masking-fraction: 0.15
[2019-06-05 12:37:29] [config] bert-sep-symbol: "[SEP]"
[2019-06-05 12:37:29] [config] bert-train-type-embeddings: true
[2019-06-05 12:37:29] [config] bert-type-vocab-size: 2
[2019-06-05 12:37:29] [config] best-deep: false
[2019-06-05 12:37:29] [config] clip-gemm: 0
[2019-06-05 12:37:29] [config] clip-norm: 1
[2019-06-05 12:37:29] [config] cost-type: ce-mean
[2019-06-05 12:37:29] [config] cpu-threads: 0
[2019-06-05 12:37:29] [config] data-weighting: ""
[2019-06-05 12:37:29] [config] data-weighting-type: sentence
[2019-06-05 12:37:29] [config] dec-cell: gru
[2019-06-05 12:37:29] [config] dec-cell-base-depth: 2
[2019-06-05 12:37:29] [config] dec-cell-high-depth: 1
[2019-06-05 12:37:29] [config] dec-depth: 1
[2019-06-05 12:37:29] [config] devices:
[2019-06-05 12:37:29] [config]   - 0
[2019-06-05 12:37:29] [config] dim-emb: 512
[2019-06-05 12:37:29] [config] dim-rnn: 1024
[2019-06-05 12:37:29] [config] dim-vocabs:
[2019-06-05 12:37:29] [config]   - 50000
[2019-06-05 12:37:29] [config]   - 50000
[2019-06-05 12:37:29] [config] disp-first: 0
[2019-06-05 12:37:29] [config] disp-freq: 2000
[2019-06-05 12:37:29] [config] disp-label-counts: false
[2019-06-05 12:37:29] [config] dropout-rnn: 0.2
[2019-06-05 12:37:29] [config] dropout-src: 0.1
[2019-06-05 12:37:29] [config] dropout-trg: 0.1
[2019-06-05 12:37:29] [config] dump-config: ""
[2019-06-05 12:37:29] [config] early-stopping: 5
[2019-06-05 12:37:29] [config] embedding-fix-src: false
[2019-06-05 12:37:29] [config] embedding-fix-trg: false
[2019-06-05 12:37:29] [config] embedding-normalization: false
[2019-06-05 12:37:29] [config] embedding-vectors:
[2019-06-05 12:37:29] [config]   []
[2019-06-05 12:37:29] [config] enc-cell: gru
[2019-06-05 12:37:29] [config] enc-cell-depth: 1
[2019-06-05 12:37:29] [config] enc-depth: 1
[2019-06-05 12:37:29] [config] enc-type: bidirectional
[2019-06-05 12:37:29] [config] exponential-smoothing: 0.0001
[2019-06-05 12:37:29] [config] grad-dropping-momentum: 0
[2019-06-05 12:37:29] [config] grad-dropping-rate: 0
[2019-06-05 12:37:29] [config] grad-dropping-warmup: 100
[2019-06-05 12:37:29] [config] guided-alignment: none
[2019-06-05 12:37:29] [config] guided-alignment-cost: mse
[2019-06-05 12:37:29] [config] guided-alignment-weight: 0.1
[2019-06-05 12:37:29] [config] ignore-model-config: false
[2019-06-05 12:37:29] [config] input-types:
[2019-06-05 12:37:29] [config]   []
[2019-06-05 12:37:29] [config] interpolate-env-vars: false
[2019-06-05 12:37:29] [config] keep-best: false
[2019-06-05 12:37:29] [config] label-smoothing: 0
[2019-06-05 12:37:29] [config] layer-normalization: true
[2019-06-05 12:37:29] [config] learn-rate: 0.0001
[2019-06-05 12:37:29] [config] log: model/train.log
[2019-06-05 12:37:29] [config] log-level: info
[2019-06-05 12:37:29] [config] log-time-zone: ""
[2019-06-05 12:37:29] [config] lr-decay: 0
[2019-06-05 12:37:29] [config] lr-decay-freq: 50000
[2019-06-05 12:37:29] [config] lr-decay-inv-sqrt:
[2019-06-05 12:37:29] [config]   - 0
[2019-06-05 12:37:29] [config] lr-decay-repeat-warmup: false
[2019-06-05 12:37:29] [config] lr-decay-reset-optimizer: false
[2019-06-05 12:37:29] [config] lr-decay-start:
[2019-06-05 12:37:29] [config]   - 10
[2019-06-05 12:37:29] [config]   - 1
[2019-06-05 12:37:29] [config] lr-decay-strategy: epoch+stalled
[2019-06-05 12:37:29] [config] lr-report: false
[2019-06-05 12:37:29] [config] lr-warmup: 0
[2019-06-05 12:37:29] [config] lr-warmup-at-reload: false
[2019-06-05 12:37:29] [config] lr-warmup-cycle: false
[2019-06-05 12:37:29] [config] lr-warmup-start-rate: 0
[2019-06-05 12:37:29] [config] max-length: 50
[2019-06-05 12:37:29] [config] max-length-crop: false
[2019-06-05 12:37:29] [config] max-length-factor: 3
[2019-06-05 12:37:29] [config] maxi-batch: 100
[2019-06-05 12:37:29] [config] maxi-batch-sort: trg
[2019-06-05 12:37:29] [config] mini-batch: 64
[2019-06-05 12:37:29] [config] mini-batch-fit: true
[2019-06-05 12:37:29] [config] mini-batch-fit-step: 10
[2019-06-05 12:37:29] [config] mini-batch-overstuff: 1
[2019-06-05 12:37:29] [config] mini-batch-track-lr: false
[2019-06-05 12:37:29] [config] mini-batch-understuff: 1
[2019-06-05 12:37:29] [config] mini-batch-warmup: 0
[2019-06-05 12:37:29] [config] mini-batch-words: 0
[2019-06-05 12:37:29] [config] mini-batch-words-ref: 0
[2019-06-05 12:37:29] [config] model: model/model.npz
[2019-06-05 12:37:29] [config] multi-loss-type: sum
[2019-06-05 12:37:29] [config] multi-node: false
[2019-06-05 12:37:29] [config] multi-node-overlap: true
[2019-06-05 12:37:29] [config] n-best: false
[2019-06-05 12:37:29] [config] no-nccl: false
[2019-06-05 12:37:29] [config] no-reload: false
[2019-06-05 12:37:29] [config] no-restore-corpus: false
[2019-06-05 12:37:29] [config] no-shuffle: false
[2019-06-05 12:37:29] [config] normalize: 1
[2019-06-05 12:37:29] [config] num-devices: 0
[2019-06-05 12:37:29] [config] optimizer: adam
[2019-06-05 12:37:29] [config] optimizer-delay: 1
[2019-06-05 12:37:29] [config] optimizer-params:
[2019-06-05 12:37:29] [config]   []
[2019-06-05 12:37:29] [config] overwrite: false
[2019-06-05 12:37:29] [config] pretrained-model: ""
[2019-06-05 12:37:29] [config] quiet: false
[2019-06-05 12:37:29] [config] quiet-translation: true
[2019-06-05 12:37:29] [config] relative-paths: false
[2019-06-05 12:37:29] [config] right-left: false
[2019-06-05 12:37:29] [config] save-freq: 20000
[2019-06-05 12:37:29] [config] seed: 1111
[2019-06-05 12:37:29] [config] shuffle-in-ram: false
[2019-06-05 12:37:29] [config] skip: false
[2019-06-05 12:37:29] [config] sqlite: ""
[2019-06-05 12:37:29] [config] sqlite-drop: false
[2019-06-05 12:37:29] [config] sync-sgd: true
[2019-06-05 12:37:29] [config] tempdir: .
[2019-06-05 12:37:29] [config] tied-embeddings: false
[2019-06-05 12:37:29] [config] tied-embeddings-all: false
[2019-06-05 12:37:29] [config] tied-embeddings-src: false
[2019-06-05 12:37:29] [config] train-sets:
[2019-06-05 12:37:29] [config]   - data/train.bpe.de
[2019-06-05 12:37:29] [config]   - data/train.bpe.en
[2019-06-05 12:37:29] [config] transformer-aan-activation: swish
[2019-06-05 12:37:29] [config] transformer-aan-depth: 2
[2019-06-05 12:37:29] [config] transformer-aan-nogate: false
[2019-06-05 12:37:29] [config] transformer-decoder-autoreg: self-attention
[2019-06-05 12:37:29] [config] transformer-dim-aan: 2048
[2019-06-05 12:37:29] [config] transformer-dim-ffn: 2048
[2019-06-05 12:37:29] [config] transformer-dropout: 0
[2019-06-05 12:37:29] [config] transformer-dropout-attention: 0
[2019-06-05 12:37:29] [config] transformer-dropout-ffn: 0
[2019-06-05 12:37:29] [config] transformer-ffn-activation: swish
[2019-06-05 12:37:29] [config] transformer-ffn-depth: 2
[2019-06-05 12:37:29] [config] transformer-guided-alignment-layer: last
[2019-06-05 12:37:29] [config] transformer-heads: 8
[2019-06-05 12:37:29] [config] transformer-no-projection: false
[2019-06-05 12:37:29] [config] transformer-postprocess: dan
[2019-06-05 12:37:29] [config] transformer-postprocess-emb: d
[2019-06-05 12:37:29] [config] transformer-preprocess: ""
[2019-06-05 12:37:29] [config] transformer-tied-layers:
[2019-06-05 12:37:29] [config]   []
[2019-06-05 12:37:29] [config] transformer-train-position-embeddings: false
[2019-06-05 12:37:29] [config] type: amun
[2019-06-05 12:37:29] [config] ulr: false
[2019-06-05 12:37:29] [config] ulr-dim-emb: 0
[2019-06-05 12:37:29] [config] ulr-dropout: 0
[2019-06-05 12:37:29] [config] ulr-keys-vectors: ""
[2019-06-05 12:37:29] [config] ulr-query-vectors: ""
[2019-06-05 12:37:29] [config] ulr-softmax-temperature: 1
[2019-06-05 12:37:29] [config] ulr-trainable-transformation: false
[2019-06-05 12:37:29] [config] valid-freq: 20000
[2019-06-05 12:37:29] [config] valid-log: model/valid.log
[2019-06-05 12:37:29] [config] valid-max-length: 1000
[2019-06-05 12:37:29] [config] valid-metrics:
[2019-06-05 12:37:29] [config]   - cross-entropy
[2019-06-05 12:37:29] [config]   - perplexity
[2019-06-05 12:37:29] [config]   - translation
[2019-06-05 12:37:29] [config] valid-mini-batch: 8
[2019-06-05 12:37:29] [config] valid-script-path: ./score-dev.sh
[2019-06-05 12:37:29] [config] valid-sets:
[2019-06-05 12:37:29] [config]   - data/dev.bpe.de
[2019-06-05 12:37:29] [config]   - data/dev.bpe.en
[2019-06-05 12:37:29] [config] valid-translation-output: model/dev.out
[2019-06-05 12:37:29] [config] vocabs:
[2019-06-05 12:37:29] [config]   - data/train.bpe.de.json
[2019-06-05 12:37:29] [config]   - data/train.bpe.en.json
[2019-06-05 12:37:29] [config] word-penalty: 0
[2019-06-05 12:37:29] [config] workspace: 500
[2019-06-05 12:37:29] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-06-05 12:37:29] Using synchronous training
[2019-06-05 12:37:29] [data] Loading vocabulary from JSON/Yaml file data/train.bpe.de.json
[2019-06-05 12:37:30] [data] Using unused word id eos for 0
[2019-06-05 12:37:30] [data] Using unused word id UNK for 1
[2019-06-05 12:37:30] [data] Setting vocabulary size for input 0 to 50000
[2019-06-05 12:37:30] [data] Loading vocabulary from JSON/Yaml file data/train.bpe.en.json
[2019-06-05 12:37:30] [data] Using unused word id eos for 0
[2019-06-05 12:37:30] [data] Using unused word id UNK for 1
[2019-06-05 12:37:30] [data] Setting vocabulary size for input 1 to 50000
[2019-06-05 12:37:30] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-06-05 12:37:30] [batching] Collecting statistics for batch fitting with step size 10
[2019-06-05 12:37:31] [memory] Extending reserved space to 512 MB (device gpu0)
[2019-06-05 12:37:31] Error: CUDA error 2 'out of memory' - /fs/bil0/abdel/marian-dev/src/tensors/gpu/device.cu:38: cudaMalloc(&data_, size)
[2019-06-05 12:37:31] Error: Aborted from virtual void marian::gpu::Device::reserve(size_t) in /fs/bil0/abdel/marian-dev/src/tensors/gpu/device.cu:38

[CALL STACK]
[0x19f32c1]         marian::gpu::Device::  reserve  (unsigned long)    + 0x1401
[0x93c8cb]          marian::SyncGraphGroup::  SyncGraphGroup  (std::shared_ptr<marian::Options>,  std::shared_ptr<marian::IMPIWrapper>) + 0xdcb
[0x605a90]          std::shared_ptr<marian::SyncGraphGroup> marian::  New  <marian::SyncGraphGroup,std::shared_ptr<marian::Options>&,std::shared_ptr<marian::IMPIWrapper>&>(std::shared_ptr<marian::Options>&,  std::shared_ptr<marian::IMPIWrapper>&) + 0x70
[0x66f24c]          marian::Train<marian::SyncGraphGroup>::  run  ()   + 0x35c
[0x5a13aa]          mainTrainer  (int,  char**)                        + 0x2ca
[0x57dd1a]          main                                               + 0x8a
[0x7ff5072d0830]    __libc_start_main                                  + 0xf0
[0x59edc9]          _start                                             + 0x29

[2019-06-05 12:38:29] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-06-05 12:38:29] [marian] Running on baldur as process 50077 with command line:
[2019-06-05 12:38:29] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model model/model.npz -T . --devices 1 --train-sets data/train.bpe.de data/train.bpe.en --vocabs data/train.bpe.de.json data/train.bpe.en.json --mini-batch-fit -w 500 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets data/dev.bpe.de data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output model/dev.out --valid-script-path ./score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log model/train.log --valid-log model/valid.log
[2019-06-05 12:38:29] [config] after-batches: 0
[2019-06-05 12:38:29] [config] after-epochs: 0
[2019-06-05 12:38:29] [config] allow-unk: false
[2019-06-05 12:38:29] [config] beam-size: 12
[2019-06-05 12:38:29] [config] bert-class-symbol: "[CLS]"
[2019-06-05 12:38:29] [config] bert-mask-symbol: "[MASK]"
[2019-06-05 12:38:29] [config] bert-masking-fraction: 0.15
[2019-06-05 12:38:29] [config] bert-sep-symbol: "[SEP]"
[2019-06-05 12:38:29] [config] bert-train-type-embeddings: true
[2019-06-05 12:38:29] [config] bert-type-vocab-size: 2
[2019-06-05 12:38:29] [config] best-deep: false
[2019-06-05 12:38:29] [config] clip-gemm: 0
[2019-06-05 12:38:29] [config] clip-norm: 1
[2019-06-05 12:38:29] [config] cost-type: ce-mean
[2019-06-05 12:38:29] [config] cpu-threads: 0
[2019-06-05 12:38:29] [config] data-weighting: ""
[2019-06-05 12:38:29] [config] data-weighting-type: sentence
[2019-06-05 12:38:29] [config] dec-cell: gru
[2019-06-05 12:38:29] [config] dec-cell-base-depth: 2
[2019-06-05 12:38:29] [config] dec-cell-high-depth: 1
[2019-06-05 12:38:29] [config] dec-depth: 1
[2019-06-05 12:38:29] [config] devices:
[2019-06-05 12:38:29] [config]   - 1
[2019-06-05 12:38:29] [config] dim-emb: 512
[2019-06-05 12:38:29] [config] dim-rnn: 1024
[2019-06-05 12:38:29] [config] dim-vocabs:
[2019-06-05 12:38:29] [config]   - 50000
[2019-06-05 12:38:29] [config]   - 50000
[2019-06-05 12:38:29] [config] disp-first: 0
[2019-06-05 12:38:29] [config] disp-freq: 2000
[2019-06-05 12:38:29] [config] disp-label-counts: false
[2019-06-05 12:38:29] [config] dropout-rnn: 0.2
[2019-06-05 12:38:29] [config] dropout-src: 0.1
[2019-06-05 12:38:29] [config] dropout-trg: 0.1
[2019-06-05 12:38:29] [config] dump-config: ""
[2019-06-05 12:38:29] [config] early-stopping: 5
[2019-06-05 12:38:29] [config] embedding-fix-src: false
[2019-06-05 12:38:29] [config] embedding-fix-trg: false
[2019-06-05 12:38:29] [config] embedding-normalization: false
[2019-06-05 12:38:29] [config] embedding-vectors:
[2019-06-05 12:38:29] [config]   []
[2019-06-05 12:38:29] [config] enc-cell: gru
[2019-06-05 12:38:29] [config] enc-cell-depth: 1
[2019-06-05 12:38:29] [config] enc-depth: 1
[2019-06-05 12:38:29] [config] enc-type: bidirectional
[2019-06-05 12:38:29] [config] exponential-smoothing: 0.0001
[2019-06-05 12:38:29] [config] grad-dropping-momentum: 0
[2019-06-05 12:38:29] [config] grad-dropping-rate: 0
[2019-06-05 12:38:29] [config] grad-dropping-warmup: 100
[2019-06-05 12:38:29] [config] guided-alignment: none
[2019-06-05 12:38:29] [config] guided-alignment-cost: mse
[2019-06-05 12:38:29] [config] guided-alignment-weight: 0.1
[2019-06-05 12:38:29] [config] ignore-model-config: false
[2019-06-05 12:38:29] [config] input-types:
[2019-06-05 12:38:29] [config]   []
[2019-06-05 12:38:29] [config] interpolate-env-vars: false
[2019-06-05 12:38:29] [config] keep-best: false
[2019-06-05 12:38:29] [config] label-smoothing: 0
[2019-06-05 12:38:29] [config] layer-normalization: true
[2019-06-05 12:38:29] [config] learn-rate: 0.0001
[2019-06-05 12:38:29] [config] log: model/train.log
[2019-06-05 12:38:29] [config] log-level: info
[2019-06-05 12:38:29] [config] log-time-zone: ""
[2019-06-05 12:38:29] [config] lr-decay: 0
[2019-06-05 12:38:29] [config] lr-decay-freq: 50000
[2019-06-05 12:38:29] [config] lr-decay-inv-sqrt:
[2019-06-05 12:38:29] [config]   - 0
[2019-06-05 12:38:29] [config] lr-decay-repeat-warmup: false
[2019-06-05 12:38:29] [config] lr-decay-reset-optimizer: false
[2019-06-05 12:38:29] [config] lr-decay-start:
[2019-06-05 12:38:29] [config]   - 10
[2019-06-05 12:38:29] [config]   - 1
[2019-06-05 12:38:29] [config] lr-decay-strategy: epoch+stalled
[2019-06-05 12:38:29] [config] lr-report: false
[2019-06-05 12:38:29] [config] lr-warmup: 0
[2019-06-05 12:38:29] [config] lr-warmup-at-reload: false
[2019-06-05 12:38:29] [config] lr-warmup-cycle: false
[2019-06-05 12:38:29] [config] lr-warmup-start-rate: 0
[2019-06-05 12:38:29] [config] max-length: 50
[2019-06-05 12:38:29] [config] max-length-crop: false
[2019-06-05 12:38:29] [config] max-length-factor: 3
[2019-06-05 12:38:29] [config] maxi-batch: 100
[2019-06-05 12:38:29] [config] maxi-batch-sort: trg
[2019-06-05 12:38:29] [config] mini-batch: 64
[2019-06-05 12:38:29] [config] mini-batch-fit: true
[2019-06-05 12:38:29] [config] mini-batch-fit-step: 10
[2019-06-05 12:38:29] [config] mini-batch-overstuff: 1
[2019-06-05 12:38:29] [config] mini-batch-track-lr: false
[2019-06-05 12:38:29] [config] mini-batch-understuff: 1
[2019-06-05 12:38:29] [config] mini-batch-warmup: 0
[2019-06-05 12:38:29] [config] mini-batch-words: 0
[2019-06-05 12:38:29] [config] mini-batch-words-ref: 0
[2019-06-05 12:38:29] [config] model: model/model.npz
[2019-06-05 12:38:29] [config] multi-loss-type: sum
[2019-06-05 12:38:29] [config] multi-node: false
[2019-06-05 12:38:29] [config] multi-node-overlap: true
[2019-06-05 12:38:29] [config] n-best: false
[2019-06-05 12:38:29] [config] no-nccl: false
[2019-06-05 12:38:29] [config] no-reload: false
[2019-06-05 12:38:29] [config] no-restore-corpus: false
[2019-06-05 12:38:29] [config] no-shuffle: false
[2019-06-05 12:38:29] [config] normalize: 1
[2019-06-05 12:38:29] [config] num-devices: 0
[2019-06-05 12:38:29] [config] optimizer: adam
[2019-06-05 12:38:29] [config] optimizer-delay: 1
[2019-06-05 12:38:29] [config] optimizer-params:
[2019-06-05 12:38:29] [config]   []
[2019-06-05 12:38:29] [config] overwrite: false
[2019-06-05 12:38:29] [config] pretrained-model: ""
[2019-06-05 12:38:29] [config] quiet: false
[2019-06-05 12:38:29] [config] quiet-translation: true
[2019-06-05 12:38:29] [config] relative-paths: false
[2019-06-05 12:38:29] [config] right-left: false
[2019-06-05 12:38:29] [config] save-freq: 20000
[2019-06-05 12:38:29] [config] seed: 1111
[2019-06-05 12:38:29] [config] shuffle-in-ram: false
[2019-06-05 12:38:29] [config] skip: false
[2019-06-05 12:38:29] [config] sqlite: ""
[2019-06-05 12:38:29] [config] sqlite-drop: false
[2019-06-05 12:38:29] [config] sync-sgd: true
[2019-06-05 12:38:29] [config] tempdir: .
[2019-06-05 12:38:29] [config] tied-embeddings: false
[2019-06-05 12:38:29] [config] tied-embeddings-all: false
[2019-06-05 12:38:29] [config] tied-embeddings-src: false
[2019-06-05 12:38:29] [config] train-sets:
[2019-06-05 12:38:29] [config]   - data/train.bpe.de
[2019-06-05 12:38:29] [config]   - data/train.bpe.en
[2019-06-05 12:38:29] [config] transformer-aan-activation: swish
[2019-06-05 12:38:29] [config] transformer-aan-depth: 2
[2019-06-05 12:38:29] [config] transformer-aan-nogate: false
[2019-06-05 12:38:29] [config] transformer-decoder-autoreg: self-attention
[2019-06-05 12:38:29] [config] transformer-dim-aan: 2048
[2019-06-05 12:38:29] [config] transformer-dim-ffn: 2048
[2019-06-05 12:38:29] [config] transformer-dropout: 0
[2019-06-05 12:38:29] [config] transformer-dropout-attention: 0
[2019-06-05 12:38:29] [config] transformer-dropout-ffn: 0
[2019-06-05 12:38:29] [config] transformer-ffn-activation: swish
[2019-06-05 12:38:29] [config] transformer-ffn-depth: 2
[2019-06-05 12:38:29] [config] transformer-guided-alignment-layer: last
[2019-06-05 12:38:29] [config] transformer-heads: 8
[2019-06-05 12:38:29] [config] transformer-no-projection: false
[2019-06-05 12:38:29] [config] transformer-postprocess: dan
[2019-06-05 12:38:29] [config] transformer-postprocess-emb: d
[2019-06-05 12:38:29] [config] transformer-preprocess: ""
[2019-06-05 12:38:29] [config] transformer-tied-layers:
[2019-06-05 12:38:29] [config]   []
[2019-06-05 12:38:29] [config] transformer-train-position-embeddings: false
[2019-06-05 12:38:29] [config] type: amun
[2019-06-05 12:38:29] [config] ulr: false
[2019-06-05 12:38:29] [config] ulr-dim-emb: 0
[2019-06-05 12:38:29] [config] ulr-dropout: 0
[2019-06-05 12:38:29] [config] ulr-keys-vectors: ""
[2019-06-05 12:38:29] [config] ulr-query-vectors: ""
[2019-06-05 12:38:29] [config] ulr-softmax-temperature: 1
[2019-06-05 12:38:29] [config] ulr-trainable-transformation: false
[2019-06-05 12:38:29] [config] valid-freq: 20000
[2019-06-05 12:38:29] [config] valid-log: model/valid.log
[2019-06-05 12:38:29] [config] valid-max-length: 1000
[2019-06-05 12:38:29] [config] valid-metrics:
[2019-06-05 12:38:29] [config]   - cross-entropy
[2019-06-05 12:38:29] [config]   - perplexity
[2019-06-05 12:38:29] [config]   - translation
[2019-06-05 12:38:29] [config] valid-mini-batch: 8
[2019-06-05 12:38:29] [config] valid-script-path: ./score-dev.sh
[2019-06-05 12:38:29] [config] valid-sets:
[2019-06-05 12:38:29] [config]   - data/dev.bpe.de
[2019-06-05 12:38:29] [config]   - data/dev.bpe.en
[2019-06-05 12:38:29] [config] valid-translation-output: model/dev.out
[2019-06-05 12:38:29] [config] vocabs:
[2019-06-05 12:38:29] [config]   - data/train.bpe.de.json
[2019-06-05 12:38:29] [config]   - data/train.bpe.en.json
[2019-06-05 12:38:29] [config] word-penalty: 0
[2019-06-05 12:38:29] [config] workspace: 500
[2019-06-05 12:38:29] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-06-05 12:38:29] Using synchronous training
[2019-06-05 12:38:29] [data] Loading vocabulary from JSON/Yaml file data/train.bpe.de.json
[2019-06-05 12:38:29] [data] Using unused word id eos for 0
[2019-06-05 12:38:29] [data] Using unused word id UNK for 1
[2019-06-05 12:38:29] [data] Setting vocabulary size for input 0 to 50000
[2019-06-05 12:38:29] [data] Loading vocabulary from JSON/Yaml file data/train.bpe.en.json
[2019-06-05 12:38:30] [data] Using unused word id eos for 0
[2019-06-05 12:38:30] [data] Using unused word id UNK for 1
[2019-06-05 12:38:30] [data] Setting vocabulary size for input 1 to 50000
[2019-06-05 12:38:30] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-06-05 12:38:30] [batching] Collecting statistics for batch fitting with step size 10
[2019-06-05 12:38:30] [memory] Extending reserved space to 512 MB (device gpu1)
[2019-06-05 12:38:30] [comm] Using NCCL 2.4.2 for GPU communication
[2019-06-05 12:38:30] [comm] NCCLCommunicator constructed successfully.
[2019-06-05 12:38:30] [training] Using 1 GPUs
[2019-06-05 12:38:30] [memory] Reserving 422 MB, device gpu1
[2019-06-05 12:38:30] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-06-05 12:38:31] [memory] Reserving 422 MB, device gpu1
[2019-06-05 12:38:31] [batching] Done. Typical MB size is 432 target words
[2019-06-05 12:38:32] [memory] Extending reserved space to 512 MB (device gpu1)
[2019-06-05 12:38:32] [comm] Using NCCL 2.4.2 for GPU communication
[2019-06-05 12:38:32] [comm] NCCLCommunicator constructed successfully.
[2019-06-05 12:38:32] [training] Using 1 GPUs
[2019-06-05 12:38:32] Training started
[2019-06-05 12:38:32] [data] Shuffling data
[2019-06-05 12:38:32] [data] Done reading 626913 sentences
[2019-06-05 12:38:34] [data] Done shuffling 626913 sentences to temp files
[2019-06-05 12:45:45] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-06-05 12:45:45] [marian] Running on baldur as process 51822 with command line:
[2019-06-05 12:45:45] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model model/model.npz -T . --devices 1 --train-sets data/train.bpe.de data/train.bpe.en --vocabs data/train.bpe.de.json data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets data/dev.bpe.de data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output model/dev.out --valid-script-path ./score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log model/train.log --valid-log model/valid.log
[2019-06-05 12:45:45] [config] after-batches: 0
[2019-06-05 12:45:45] [config] after-epochs: 0
[2019-06-05 12:45:45] [config] allow-unk: false
[2019-06-05 12:45:45] [config] beam-size: 12
[2019-06-05 12:45:45] [config] bert-class-symbol: "[CLS]"
[2019-06-05 12:45:45] [config] bert-mask-symbol: "[MASK]"
[2019-06-05 12:45:45] [config] bert-masking-fraction: 0.15
[2019-06-05 12:45:45] [config] bert-sep-symbol: "[SEP]"
[2019-06-05 12:45:45] [config] bert-train-type-embeddings: true
[2019-06-05 12:45:45] [config] bert-type-vocab-size: 2
[2019-06-05 12:45:45] [config] best-deep: false
[2019-06-05 12:45:45] [config] clip-gemm: 0
[2019-06-05 12:45:45] [config] clip-norm: 1
[2019-06-05 12:45:45] [config] cost-type: ce-mean
[2019-06-05 12:45:45] [config] cpu-threads: 0
[2019-06-05 12:45:45] [config] data-weighting: ""
[2019-06-05 12:45:45] [config] data-weighting-type: sentence
[2019-06-05 12:45:45] [config] dec-cell: gru
[2019-06-05 12:45:45] [config] dec-cell-base-depth: 2
[2019-06-05 12:45:45] [config] dec-cell-high-depth: 1
[2019-06-05 12:45:45] [config] dec-depth: 1
[2019-06-05 12:45:45] [config] devices:
[2019-06-05 12:45:45] [config]   - 1
[2019-06-05 12:45:45] [config] dim-emb: 512
[2019-06-05 12:45:45] [config] dim-rnn: 1024
[2019-06-05 12:45:45] [config] dim-vocabs:
[2019-06-05 12:45:45] [config]   - 50000
[2019-06-05 12:45:45] [config]   - 50000
[2019-06-05 12:45:45] [config] disp-first: 0
[2019-06-05 12:45:45] [config] disp-freq: 2000
[2019-06-05 12:45:45] [config] disp-label-counts: false
[2019-06-05 12:45:45] [config] dropout-rnn: 0.2
[2019-06-05 12:45:45] [config] dropout-src: 0.1
[2019-06-05 12:45:45] [config] dropout-trg: 0.1
[2019-06-05 12:45:45] [config] dump-config: ""
[2019-06-05 12:45:45] [config] early-stopping: 5
[2019-06-05 12:45:45] [config] embedding-fix-src: false
[2019-06-05 12:45:45] [config] embedding-fix-trg: false
[2019-06-05 12:45:45] [config] embedding-normalization: false
[2019-06-05 12:45:45] [config] embedding-vectors:
[2019-06-05 12:45:45] [config]   []
[2019-06-05 12:45:45] [config] enc-cell: gru
[2019-06-05 12:45:45] [config] enc-cell-depth: 1
[2019-06-05 12:45:45] [config] enc-depth: 1
[2019-06-05 12:45:45] [config] enc-type: bidirectional
[2019-06-05 12:45:45] [config] exponential-smoothing: 0.0001
[2019-06-05 12:45:45] [config] grad-dropping-momentum: 0
[2019-06-05 12:45:45] [config] grad-dropping-rate: 0
[2019-06-05 12:45:45] [config] grad-dropping-warmup: 100
[2019-06-05 12:45:45] [config] guided-alignment: none
[2019-06-05 12:45:45] [config] guided-alignment-cost: mse
[2019-06-05 12:45:45] [config] guided-alignment-weight: 0.1
[2019-06-05 12:45:45] [config] ignore-model-config: false
[2019-06-05 12:45:45] [config] input-types:
[2019-06-05 12:45:45] [config]   []
[2019-06-05 12:45:45] [config] interpolate-env-vars: false
[2019-06-05 12:45:45] [config] keep-best: false
[2019-06-05 12:45:45] [config] label-smoothing: 0
[2019-06-05 12:45:45] [config] layer-normalization: true
[2019-06-05 12:45:45] [config] learn-rate: 0.0001
[2019-06-05 12:45:45] [config] log: model/train.log
[2019-06-05 12:45:45] [config] log-level: info
[2019-06-05 12:45:45] [config] log-time-zone: ""
[2019-06-05 12:45:45] [config] lr-decay: 0
[2019-06-05 12:45:45] [config] lr-decay-freq: 50000
[2019-06-05 12:45:45] [config] lr-decay-inv-sqrt:
[2019-06-05 12:45:45] [config]   - 0
[2019-06-05 12:45:45] [config] lr-decay-repeat-warmup: false
[2019-06-05 12:45:45] [config] lr-decay-reset-optimizer: false
[2019-06-05 12:45:45] [config] lr-decay-start:
[2019-06-05 12:45:45] [config]   - 10
[2019-06-05 12:45:45] [config]   - 1
[2019-06-05 12:45:45] [config] lr-decay-strategy: epoch+stalled
[2019-06-05 12:45:45] [config] lr-report: false
[2019-06-05 12:45:45] [config] lr-warmup: 0
[2019-06-05 12:45:45] [config] lr-warmup-at-reload: false
[2019-06-05 12:45:45] [config] lr-warmup-cycle: false
[2019-06-05 12:45:45] [config] lr-warmup-start-rate: 0
[2019-06-05 12:45:45] [config] max-length: 50
[2019-06-05 12:45:45] [config] max-length-crop: false
[2019-06-05 12:45:45] [config] max-length-factor: 3
[2019-06-05 12:45:45] [config] maxi-batch: 100
[2019-06-05 12:45:45] [config] maxi-batch-sort: trg
[2019-06-05 12:45:45] [config] mini-batch: 64
[2019-06-05 12:45:45] [config] mini-batch-fit: true
[2019-06-05 12:45:45] [config] mini-batch-fit-step: 10
[2019-06-05 12:45:45] [config] mini-batch-overstuff: 1
[2019-06-05 12:45:45] [config] mini-batch-track-lr: false
[2019-06-05 12:45:45] [config] mini-batch-understuff: 1
[2019-06-05 12:45:45] [config] mini-batch-warmup: 0
[2019-06-05 12:45:45] [config] mini-batch-words: 0
[2019-06-05 12:45:45] [config] mini-batch-words-ref: 0
[2019-06-05 12:45:45] [config] model: model/model.npz
[2019-06-05 12:45:45] [config] multi-loss-type: sum
[2019-06-05 12:45:45] [config] multi-node: false
[2019-06-05 12:45:45] [config] multi-node-overlap: true
[2019-06-05 12:45:45] [config] n-best: false
[2019-06-05 12:45:45] [config] no-nccl: false
[2019-06-05 12:45:45] [config] no-reload: false
[2019-06-05 12:45:45] [config] no-restore-corpus: false
[2019-06-05 12:45:45] [config] no-shuffle: false
[2019-06-05 12:45:45] [config] normalize: 1
[2019-06-05 12:45:45] [config] num-devices: 0
[2019-06-05 12:45:45] [config] optimizer: adam
[2019-06-05 12:45:45] [config] optimizer-delay: 1
[2019-06-05 12:45:45] [config] optimizer-params:
[2019-06-05 12:45:45] [config]   []
[2019-06-05 12:45:45] [config] overwrite: false
[2019-06-05 12:45:45] [config] pretrained-model: ""
[2019-06-05 12:45:45] [config] quiet: false
[2019-06-05 12:45:45] [config] quiet-translation: true
[2019-06-05 12:45:45] [config] relative-paths: false
[2019-06-05 12:45:45] [config] right-left: false
[2019-06-05 12:45:45] [config] save-freq: 20000
[2019-06-05 12:45:45] [config] seed: 1111
[2019-06-05 12:45:45] [config] shuffle-in-ram: false
[2019-06-05 12:45:45] [config] skip: false
[2019-06-05 12:45:45] [config] sqlite: ""
[2019-06-05 12:45:45] [config] sqlite-drop: false
[2019-06-05 12:45:45] [config] sync-sgd: true
[2019-06-05 12:45:45] [config] tempdir: .
[2019-06-05 12:45:45] [config] tied-embeddings: false
[2019-06-05 12:45:45] [config] tied-embeddings-all: false
[2019-06-05 12:45:45] [config] tied-embeddings-src: false
[2019-06-05 12:45:45] [config] train-sets:
[2019-06-05 12:45:45] [config]   - data/train.bpe.de
[2019-06-05 12:45:45] [config]   - data/train.bpe.en
[2019-06-05 12:45:45] [config] transformer-aan-activation: swish
[2019-06-05 12:45:45] [config] transformer-aan-depth: 2
[2019-06-05 12:45:45] [config] transformer-aan-nogate: false
[2019-06-05 12:45:45] [config] transformer-decoder-autoreg: self-attention
[2019-06-05 12:45:45] [config] transformer-dim-aan: 2048
[2019-06-05 12:45:45] [config] transformer-dim-ffn: 2048
[2019-06-05 12:45:45] [config] transformer-dropout: 0
[2019-06-05 12:45:45] [config] transformer-dropout-attention: 0
[2019-06-05 12:45:45] [config] transformer-dropout-ffn: 0
[2019-06-05 12:45:45] [config] transformer-ffn-activation: swish
[2019-06-05 12:45:45] [config] transformer-ffn-depth: 2
[2019-06-05 12:45:45] [config] transformer-guided-alignment-layer: last
[2019-06-05 12:45:45] [config] transformer-heads: 8
[2019-06-05 12:45:45] [config] transformer-no-projection: false
[2019-06-05 12:45:45] [config] transformer-postprocess: dan
[2019-06-05 12:45:45] [config] transformer-postprocess-emb: d
[2019-06-05 12:45:45] [config] transformer-preprocess: ""
[2019-06-05 12:45:45] [config] transformer-tied-layers:
[2019-06-05 12:45:45] [config]   []
[2019-06-05 12:45:45] [config] transformer-train-position-embeddings: false
[2019-06-05 12:45:45] [config] type: amun
[2019-06-05 12:45:45] [config] ulr: false
[2019-06-05 12:45:45] [config] ulr-dim-emb: 0
[2019-06-05 12:45:45] [config] ulr-dropout: 0
[2019-06-05 12:45:45] [config] ulr-keys-vectors: ""
[2019-06-05 12:45:45] [config] ulr-query-vectors: ""
[2019-06-05 12:45:45] [config] ulr-softmax-temperature: 1
[2019-06-05 12:45:45] [config] ulr-trainable-transformation: false
[2019-06-05 12:45:45] [config] valid-freq: 20000
[2019-06-05 12:45:45] [config] valid-log: model/valid.log
[2019-06-05 12:45:45] [config] valid-max-length: 1000
[2019-06-05 12:45:45] [config] valid-metrics:
[2019-06-05 12:45:45] [config]   - cross-entropy
[2019-06-05 12:45:45] [config]   - perplexity
[2019-06-05 12:45:45] [config]   - translation
[2019-06-05 12:45:45] [config] valid-mini-batch: 8
[2019-06-05 12:45:45] [config] valid-script-path: ./score-dev.sh
[2019-06-05 12:45:45] [config] valid-sets:
[2019-06-05 12:45:45] [config]   - data/dev.bpe.de
[2019-06-05 12:45:45] [config]   - data/dev.bpe.en
[2019-06-05 12:45:45] [config] valid-translation-output: model/dev.out
[2019-06-05 12:45:45] [config] vocabs:
[2019-06-05 12:45:45] [config]   - data/train.bpe.de.json
[2019-06-05 12:45:45] [config]   - data/train.bpe.en.json
[2019-06-05 12:45:45] [config] word-penalty: 0
[2019-06-05 12:45:45] [config] workspace: 3000
[2019-06-05 12:45:45] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-06-05 12:45:45] Using synchronous training
[2019-06-05 12:45:45] [data] Loading vocabulary from JSON/Yaml file data/train.bpe.de.json
[2019-06-05 12:45:46] [data] Using unused word id eos for 0
[2019-06-05 12:45:46] [data] Using unused word id UNK for 1
[2019-06-05 12:45:46] [data] Setting vocabulary size for input 0 to 50000
[2019-06-05 12:45:46] [data] Loading vocabulary from JSON/Yaml file data/train.bpe.en.json
[2019-06-05 12:45:46] [data] Using unused word id eos for 0
[2019-06-05 12:45:46] [data] Using unused word id UNK for 1
[2019-06-05 12:45:46] [data] Setting vocabulary size for input 1 to 50000
[2019-06-05 12:45:46] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-06-05 12:45:46] [batching] Collecting statistics for batch fitting with step size 10
[2019-06-05 12:45:47] [memory] Extending reserved space to 3072 MB (device gpu1)
[2019-06-05 12:45:47] [comm] Using NCCL 2.4.2 for GPU communication
[2019-06-05 12:45:47] [comm] NCCLCommunicator constructed successfully.
[2019-06-05 12:45:47] [training] Using 1 GPUs
[2019-06-05 12:45:47] [memory] Reserving 422 MB, device gpu1
[2019-06-05 12:45:47] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-06-05 12:45:47] [memory] Reserving 422 MB, device gpu1
[2019-06-05 12:45:55] [batching] Done. Typical MB size is 4042 target words
[2019-06-05 12:45:55] [memory] Extending reserved space to 3072 MB (device gpu1)
[2019-06-05 12:45:55] [comm] Using NCCL 2.4.2 for GPU communication
[2019-06-05 12:45:55] [comm] NCCLCommunicator constructed successfully.
[2019-06-05 12:45:55] [training] Using 1 GPUs
[2019-06-05 12:45:55] Training started
[2019-06-05 12:45:55] [data] Shuffling data
[2019-06-05 12:45:55] [data] Done reading 626913 sentences
[2019-06-05 12:45:57] [data] Done shuffling 626913 sentences to temp files
[2019-06-05 12:45:59] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-06-05 12:45:59] [memory] Reserving 422 MB, device gpu1
[2019-06-05 12:45:59] [memory] Reserving 422 MB, device gpu1
[2019-06-05 12:45:59] [memory] Reserving 422 MB, device gpu1
[2019-06-05 12:46:00] [memory] Reserving 844 MB, device gpu1
[2019-06-05 13:01:29] Ep. 1 : Up. 2000 : Sen. 259,336 : Cost 115.00904083 : Time 942.73s : 5473.11 words/s
[2019-06-05 13:17:10] Ep. 1 : Up. 4000 : Sen. 519,677 : Cost 83.69757080 : Time 941.16s : 5524.69 words/s
[2019-06-05 13:21:44] Seen 595815 samples
[2019-06-05 13:21:44] Starting epoch 2
[2019-06-05 13:21:44] [data] Shuffling data
[2019-06-05 13:21:44] [data] Done reading 626913 sentences
[2019-06-05 13:21:46] [data] Done shuffling 626913 sentences to temp files
[2019-06-05 13:32:54] Ep. 2 : Up. 6000 : Sen. 184,217 : Cost 68.28725433 : Time 944.19s : 5507.52 words/s
[2019-06-05 13:48:31] Ep. 2 : Up. 8000 : Sen. 445,277 : Cost 59.33092499 : Time 937.33s : 5542.08 words/s
[2019-06-05 13:57:34] Seen 595815 samples
[2019-06-05 13:57:34] Starting epoch 3
[2019-06-05 13:57:34] [data] Shuffling data
[2019-06-05 13:57:34] [data] Done reading 626913 sentences
[2019-06-05 13:57:36] [data] Done shuffling 626913 sentences to temp files
[2019-06-05 14:04:12] Ep. 3 : Up. 10000 : Sen. 109,501 : Cost 53.46736145 : Time 940.98s : 5503.81 words/s
[2019-06-05 14:19:52] Ep. 3 : Up. 12000 : Sen. 370,426 : Cost 49.16324615 : Time 939.18s : 5533.59 words/s
[2019-06-05 14:33:25] Seen 595815 samples
[2019-06-05 14:33:25] Starting epoch 4
[2019-06-05 14:33:25] [data] Shuffling data
[2019-06-05 14:33:26] [data] Done reading 626913 sentences
[2019-06-05 14:33:28] [data] Done shuffling 626913 sentences to temp files
[2019-06-05 14:35:33] Ep. 4 : Up. 14000 : Sen. 34,317 : Cost 46.77990723 : Time 941.34s : 5501.48 words/s
[2019-06-05 14:51:12] Ep. 4 : Up. 16000 : Sen. 294,808 : Cost 43.65505981 : Time 939.04s : 5529.33 words/s
[2019-06-05 15:06:51] Ep. 4 : Up. 18000 : Sen. 555,650 : Cost 42.34523392 : Time 938.70s : 5533.62 words/s
[2019-06-05 15:09:17] Seen 595815 samples
[2019-06-05 15:09:17] Starting epoch 5
[2019-06-05 15:09:17] [data] Shuffling data
[2019-06-05 15:09:17] [data] Done reading 626913 sentences
[2019-06-05 15:09:19] [data] Done shuffling 626913 sentences to temp files
[2019-06-05 15:22:31] Ep. 5 : Up. 20000 : Sen. 220,164 : Cost 39.99911118 : Time 939.92s : 5511.05 words/s
[2019-06-05 15:22:31] Saving model to model/model.npz.orig.npz
[2019-06-05 15:22:40] Saving model to model/model.iter20000.npz
[2019-06-05 15:22:46] Saving model to model/model.npz
[2019-06-05 15:22:56] Saving Adam parameters to model/model.npz.optimizer.npz
[2019-06-05 15:23:23] [valid] Ep. 5 : Up. 20000 : cross-entropy : 74.2994 : new best
[2019-06-05 15:23:35] [valid] Ep. 5 : Up. 20000 : perplexity : 18.4014 : new best
[2019-06-05 15:25:10] [valid] Ep. 5 : Up. 20000 : translation : 21.75 : new best
[2019-06-05 15:40:47] Ep. 5 : Up. 22000 : Sen. 478,398 : Cost 39.27148056 : Time 1096.25s : 4711.34 words/s
[2019-06-05 15:47:54] Seen 595815 samples
[2019-06-05 15:47:54] Starting epoch 6
[2019-06-05 15:47:54] [data] Shuffling data
[2019-06-05 15:47:54] [data] Done reading 626913 sentences
[2019-06-05 15:47:57] [data] Done shuffling 626913 sentences to temp files
[2019-06-05 15:56:35] Ep. 6 : Up. 24000 : Sen. 142,532 : Cost 37.57506561 : Time 948.53s : 5447.76 words/s
[2019-06-05 16:12:29] Ep. 6 : Up. 26000 : Sen. 402,782 : Cost 36.93329620 : Time 954.05s : 5449.20 words/s
[2019-06-05 16:24:17] Seen 595815 samples
[2019-06-05 16:24:17] Starting epoch 7
[2019-06-05 16:24:17] [data] Shuffling data
[2019-06-05 16:24:17] [data] Done reading 626913 sentences
[2019-06-05 16:24:20] [data] Done shuffling 626913 sentences to temp files
[2019-06-05 16:28:31] Ep. 7 : Up. 28000 : Sen. 67,732 : Cost 35.84665298 : Time 961.92s : 5403.97 words/s
[2019-06-05 16:44:27] Ep. 7 : Up. 30000 : Sen. 328,492 : Cost 34.50531006 : Time 955.39s : 5439.51 words/s
[2019-06-05 17:00:21] Ep. 7 : Up. 32000 : Sen. 588,566 : Cost 34.48183441 : Time 954.14s : 5429.42 words/s
[2019-06-05 17:00:48] Seen 595815 samples
[2019-06-05 17:00:48] Starting epoch 8
[2019-06-05 17:00:48] [data] Shuffling data
[2019-06-05 17:00:49] [data] Done reading 626913 sentences
[2019-06-05 17:00:52] [data] Done shuffling 626913 sentences to temp files
[2019-06-05 17:16:23] Ep. 8 : Up. 34000 : Sen. 253,923 : Cost 32.76299286 : Time 962.10s : 5414.40 words/s
[2019-06-05 17:32:18] Ep. 8 : Up. 36000 : Sen. 514,575 : Cost 32.79060745 : Time 955.00s : 5439.47 words/s
[2019-06-05 17:37:15] Seen 595815 samples
[2019-06-05 17:37:15] Starting epoch 9
[2019-06-05 17:37:15] [data] Shuffling data
[2019-06-05 17:37:15] [data] Done reading 626913 sentences
[2019-06-05 17:37:18] [data] Done shuffling 626913 sentences to temp files
[2019-06-05 17:48:12] Ep. 9 : Up. 38000 : Sen. 178,656 : Cost 31.57166100 : Time 954.31s : 5424.90 words/s
[2019-06-05 18:03:56] Ep. 9 : Up. 40000 : Sen. 439,901 : Cost 31.30784798 : Time 943.74s : 5504.37 words/s
[2019-06-05 18:03:56] Saving model to model/model.npz.orig.npz
[2019-06-05 18:04:05] Saving model to model/model.iter40000.npz
[2019-06-05 18:04:12] Saving model to model/model.npz
[2019-06-05 18:04:22] Saving Adam parameters to model/model.npz.optimizer.npz
[2019-06-05 18:04:49] [valid] Ep. 9 : Up. 40000 : cross-entropy : 64.9145 : new best
[2019-06-05 18:05:01] [valid] Ep. 9 : Up. 40000 : perplexity : 12.7375 : new best
[2019-06-05 18:06:39] [valid] Ep. 9 : Up. 40000 : translation : 24.6 : new best
[2019-06-05 18:16:08] Seen 595815 samples
[2019-06-05 18:16:08] Starting epoch 10
[2019-06-05 18:16:08] [data] Shuffling data
[2019-06-05 18:16:09] [data] Done reading 626913 sentences
[2019-06-05 18:16:11] [data] Done shuffling 626913 sentences to temp files
[2019-06-05 18:22:38] Ep. 10 : Up. 42000 : Sen. 105,854 : Cost 30.83782005 : Time 1121.88s : 4659.84 words/s
[2019-06-05 18:38:21] Ep. 10 : Up. 44000 : Sen. 365,896 : Cost 30.08311081 : Time 942.74s : 5501.09 words/s
[2019-06-05 18:52:16] Seen 595815 samples
[2019-06-05 18:52:16] Starting epoch 11
[2019-06-05 18:52:16] [data] Shuffling data
[2019-06-05 18:52:16] [data] Done reading 626913 sentences
[2019-06-05 18:52:19] [data] Done shuffling 626913 sentences to temp files
[2019-06-05 18:54:12] Ep. 11 : Up. 46000 : Sen. 31,222 : Cost 30.05432510 : Time 951.71s : 5463.99 words/s
[2019-06-05 19:10:00] Ep. 11 : Up. 48000 : Sen. 291,392 : Cost 28.77551079 : Time 947.48s : 5468.50 words/s
[2019-06-05 19:25:56] Ep. 11 : Up. 50000 : Sen. 553,476 : Cost 29.31599236 : Time 955.90s : 5468.03 words/s
[2019-06-05 19:28:32] Seen 595815 samples
[2019-06-05 19:28:32] Starting epoch 12
[2019-06-05 19:28:32] [data] Shuffling data
[2019-06-05 19:28:33] [data] Done reading 626913 sentences
[2019-06-05 19:28:35] [data] Done shuffling 626913 sentences to temp files
[2019-06-05 19:41:49] Ep. 12 : Up. 52000 : Sen. 217,886 : Cost 28.20753288 : Time 953.12s : 5457.34 words/s
[2019-06-05 19:57:40] Ep. 12 : Up. 54000 : Sen. 478,410 : Cost 27.98782158 : Time 951.66s : 5457.88 words/s
[2019-06-05 20:04:50] Seen 595815 samples
[2019-06-05 20:04:50] Starting epoch 13
[2019-06-05 20:04:50] [data] Shuffling data
[2019-06-05 20:04:50] [data] Done reading 626913 sentences
[2019-06-05 20:04:53] [data] Done shuffling 626913 sentences to temp files
[2019-06-05 20:13:41] Ep. 13 : Up. 56000 : Sen. 143,471 : Cost 27.39171219 : Time 960.12s : 5409.56 words/s
[2019-06-05 20:29:31] Ep. 13 : Up. 58000 : Sen. 403,200 : Cost 27.14803696 : Time 950.36s : 5442.35 words/s
[2019-06-05 20:41:21] Seen 595815 samples
[2019-06-05 20:41:21] Starting epoch 14
[2019-06-05 20:41:21] [data] Shuffling data
[2019-06-05 20:41:21] [data] Done reading 626913 sentences
[2019-06-05 20:41:24] [data] Done shuffling 626913 sentences to temp files
[2019-06-05 20:45:33] Ep. 14 : Up. 60000 : Sen. 66,772 : Cost 27.03422356 : Time 962.13s : 5377.42 words/s
[2019-06-05 20:45:33] Saving model to model/model.npz.orig.npz
[2019-06-05 20:45:44] Saving model to model/model.iter60000.npz
[2019-06-05 20:45:51] Saving model to model/model.npz
[2019-06-05 20:46:01] Saving Adam parameters to model/model.npz.optimizer.npz
[2019-06-05 20:46:33] [valid] Ep. 14 : Up. 60000 : cross-entropy : 62.3339 : new best
[2019-06-05 20:46:45] [valid] Ep. 14 : Up. 60000 : perplexity : 11.5121 : new best
[2019-06-05 20:48:33] [valid] Ep. 14 : Up. 60000 : translation : 25.42 : new best
[2019-06-05 21:04:37] Ep. 14 : Up. 62000 : Sen. 327,645 : Cost 26.23244095 : Time 1143.54s : 4549.00 words/s
[2019-06-05 21:20:36] Ep. 14 : Up. 64000 : Sen. 588,390 : Cost 26.57917786 : Time 959.58s : 5413.20 words/s
[2019-06-05 21:21:03] Seen 595815 samples
[2019-06-05 21:21:03] Starting epoch 15
[2019-06-05 21:21:03] [data] Shuffling data
[2019-06-05 21:21:04] [data] Done reading 626913 sentences
[2019-06-05 21:21:06] [data] Done shuffling 626913 sentences to temp files
[2019-06-05 21:36:40] Ep. 15 : Up. 66000 : Sen. 253,516 : Cost 25.40329933 : Time 964.14s : 5383.81 words/s
[2019-06-05 21:52:40] Ep. 15 : Up. 68000 : Sen. 513,548 : Cost 25.90558624 : Time 959.40s : 5406.85 words/s
[2019-06-05 21:57:43] Seen 595815 samples
[2019-06-05 21:57:43] Starting epoch 16
[2019-06-05 21:57:43] [data] Shuffling data
[2019-06-05 21:57:44] [data] Done reading 626913 sentences
[2019-06-05 21:57:47] [data] Done shuffling 626913 sentences to temp files
[2019-06-05 22:08:46] Ep. 16 : Up. 70000 : Sen. 178,475 : Cost 25.18238258 : Time 966.64s : 5380.50 words/s
[2019-06-05 22:24:46] Ep. 16 : Up. 72000 : Sen. 439,266 : Cost 24.94205856 : Time 959.63s : 5411.96 words/s
[2019-06-05 22:34:24] Seen 595815 samples
[2019-06-05 22:34:24] Starting epoch 17
[2019-06-05 22:34:24] [data] Shuffling data
[2019-06-05 22:34:25] [data] Done reading 626913 sentences
[2019-06-05 22:34:28] [data] Done shuffling 626913 sentences to temp files
[2019-06-05 22:40:54] Ep. 17 : Up. 74000 : Sen. 104,613 : Cost 24.73299789 : Time 968.28s : 5377.83 words/s
[2019-06-05 22:56:55] Ep. 17 : Up. 76000 : Sen. 365,037 : Cost 24.18286133 : Time 960.33s : 5402.75 words/s
[2019-06-05 23:11:06] Seen 595815 samples
[2019-06-05 23:11:06] Starting epoch 18
[2019-06-05 23:11:06] [data] Shuffling data
[2019-06-05 23:11:07] [data] Done reading 626913 sentences
[2019-06-05 23:11:09] [data] Done shuffling 626913 sentences to temp files
[2019-06-05 23:12:59] Ep. 18 : Up. 78000 : Sen. 29,510 : Cost 24.41945457 : Time 964.49s : 5379.34 words/s
[2019-06-05 23:29:01] Ep. 18 : Up. 80000 : Sen. 289,890 : Cost 23.64830208 : Time 962.24s : 5400.15 words/s
[2019-06-05 23:29:01] Saving model to model/model.npz.orig.npz
[2019-06-05 23:29:11] Saving model to model/model.iter80000.npz
[2019-06-05 23:29:19] Saving model to model/model.npz
[2019-06-05 23:29:29] Saving Adam parameters to model/model.npz.optimizer.npz
[2019-06-05 23:29:58] [valid] Ep. 18 : Up. 80000 : cross-entropy : 61.7438 : new best
[2019-06-05 23:30:10] [valid] Ep. 18 : Up. 80000 : perplexity : 11.2489 : new best
[2019-06-05 23:31:57] [valid] Ep. 18 : Up. 80000 : translation : 25.36 : stalled 1 times (last best: 25.42)
[2019-06-05 23:48:02] Ep. 18 : Up. 82000 : Sen. 551,043 : Cost 24.05671692 : Time 1140.34s : 4563.17 words/s
[2019-06-05 23:50:47] Seen 595815 samples
[2019-06-05 23:50:47] Starting epoch 19
[2019-06-05 23:50:47] [data] Shuffling data
[2019-06-05 23:50:47] [data] Done reading 626913 sentences
[2019-06-05 23:50:50] [data] Done shuffling 626913 sentences to temp files
[2019-06-06 00:04:06] Ep. 19 : Up. 84000 : Sen. 216,223 : Cost 23.07086945 : Time 964.44s : 5378.32 words/s
[2019-06-06 00:20:07] Ep. 19 : Up. 86000 : Sen. 475,810 : Cost 23.55838394 : Time 961.12s : 5398.19 words/s
[2019-06-06 00:27:29] Seen 595815 samples
[2019-06-06 00:27:29] Starting epoch 20
[2019-06-06 00:27:29] [data] Shuffling data
[2019-06-06 00:27:30] [data] Done reading 626913 sentences
[2019-06-06 00:27:32] [data] Done shuffling 626913 sentences to temp files
[2019-06-06 00:36:13] Ep. 20 : Up. 88000 : Sen. 140,722 : Cost 22.77222443 : Time 965.30s : 5379.05 words/s
[2019-06-06 00:52:12] Ep. 20 : Up. 90000 : Sen. 400,796 : Cost 22.75831223 : Time 959.54s : 5407.11 words/s
[2019-06-06 01:04:10] Seen 595815 samples
[2019-06-06 01:04:10] Starting epoch 21
[2019-06-06 01:04:10] [data] Shuffling data
[2019-06-06 01:04:11] [data] Done reading 626913 sentences
[2019-06-06 01:04:13] [data] Done shuffling 626913 sentences to temp files
[2019-06-06 01:08:17] Ep. 21 : Up. 92000 : Sen. 65,571 : Cost 22.74085999 : Time 965.11s : 5379.17 words/s
[2019-06-06 01:24:21] Ep. 21 : Up. 94000 : Sen. 326,875 : Cost 21.94153976 : Time 963.47s : 5395.70 words/s
[2019-06-06 01:40:26] Ep. 21 : Up. 96000 : Sen. 587,269 : Cost 22.69650650 : Time 964.97s : 5386.64 words/s
[2019-06-06 01:40:58] Seen 595815 samples
[2019-06-06 01:40:58] Starting epoch 22
[2019-06-06 01:40:58] [data] Shuffling data
[2019-06-06 01:40:58] [data] Done reading 626913 sentences
[2019-06-06 01:41:01] [data] Done shuffling 626913 sentences to temp files
[2019-06-06 01:56:32] Ep. 22 : Up. 98000 : Sen. 251,665 : Cost 21.57360840 : Time 966.51s : 5363.71 words/s
[2019-06-06 02:12:34] Ep. 22 : Up. 100000 : Sen. 511,582 : Cost 22.11098862 : Time 962.07s : 5391.07 words/s
[2019-06-06 02:12:34] Saving model to model/model.npz.orig.npz
[2019-06-06 02:12:44] Saving model to model/model.iter100000.npz
[2019-06-06 02:12:52] Saving model to model/model.npz
[2019-06-06 02:13:01] Saving Adam parameters to model/model.npz.optimizer.npz
[2019-06-06 02:13:32] [valid] Ep. 22 : Up. 100000 : cross-entropy : 61.9988 : stalled 1 times (last best: 61.7438)
[2019-06-06 02:13:44] [valid] Ep. 22 : Up. 100000 : perplexity : 11.3619 : stalled 1 times (last best: 11.2489)
[2019-06-06 02:15:33] [valid] Ep. 22 : Up. 100000 : translation : 25.26 : stalled 2 times (last best: 25.42)
[2019-06-06 02:20:45] Seen 595815 samples
[2019-06-06 02:20:45] Starting epoch 23
[2019-06-06 02:20:45] [data] Shuffling data
[2019-06-06 02:20:46] [data] Done reading 626913 sentences
[2019-06-06 02:20:48] [data] Done shuffling 626913 sentences to temp files
[2019-06-06 02:31:45] Ep. 23 : Up. 102000 : Sen. 177,099 : Cost 21.31431007 : Time 1150.35s : 4523.55 words/s
[2019-06-06 02:47:43] Ep. 23 : Up. 104000 : Sen. 436,260 : Cost 21.55921364 : Time 958.59s : 5388.87 words/s
[2019-06-06 02:57:33] Seen 595815 samples
[2019-06-06 02:57:33] Starting epoch 24
[2019-06-06 02:57:33] [data] Shuffling data
[2019-06-06 02:57:34] [data] Done reading 626913 sentences
[2019-06-06 02:57:36] [data] Done shuffling 626913 sentences to temp files
[2019-06-06 03:03:52] Ep. 24 : Up. 106000 : Sen. 101,348 : Cost 21.27907372 : Time 969.30s : 5367.22 words/s
[2019-06-06 03:19:56] Ep. 24 : Up. 108000 : Sen. 361,927 : Cost 20.99656677 : Time 963.83s : 5393.30 words/s
[2019-06-06 03:34:19] Seen 595815 samples
[2019-06-06 03:34:19] Starting epoch 25
[2019-06-06 03:34:19] [data] Shuffling data
[2019-06-06 03:34:19] [data] Done reading 626913 sentences
[2019-06-06 03:34:22] [data] Done shuffling 626913 sentences to temp files
[2019-06-06 03:36:04] Ep. 25 : Up. 110000 : Sen. 27,341 : Cost 21.13760376 : Time 967.83s : 5371.17 words/s
[2019-06-06 03:52:10] Ep. 25 : Up. 112000 : Sen. 287,795 : Cost 20.59479713 : Time 965.62s : 5382.87 words/s
[2019-06-06 04:08:17] Ep. 25 : Up. 114000 : Sen. 549,218 : Cost 20.87506676 : Time 967.12s : 5390.07 words/s
[2019-06-06 04:11:09] Seen 595815 samples
[2019-06-06 04:11:09] Starting epoch 26
[2019-06-06 04:11:09] [data] Shuffling data
[2019-06-06 04:11:09] [data] Done reading 626913 sentences
[2019-06-06 04:11:12] [data] Done shuffling 626913 sentences to temp files
[2019-06-06 04:24:25] Ep. 26 : Up. 116000 : Sen. 214,352 : Cost 20.11133575 : Time 968.13s : 5365.45 words/s
[2019-06-06 04:40:29] Ep. 26 : Up. 118000 : Sen. 475,186 : Cost 20.49880219 : Time 963.79s : 5393.61 words/s
[2019-06-06 04:47:55] Seen 595815 samples
[2019-06-06 04:47:55] Starting epoch 27
[2019-06-06 04:47:55] [data] Shuffling data
[2019-06-06 04:47:55] [data] Done reading 626913 sentences
[2019-06-06 04:47:59] [data] Done shuffling 626913 sentences to temp files
[2019-06-06 04:56:35] Ep. 27 : Up. 120000 : Sen. 139,287 : Cost 20.14710617 : Time 966.25s : 5363.12 words/s
[2019-06-06 04:56:35] Saving model to model/model.npz.orig.npz
[2019-06-06 04:56:45] Saving model to model/model.iter120000.npz
[2019-06-06 04:56:53] Saving model to model/model.npz
[2019-06-06 04:57:04] Saving Adam parameters to model/model.npz.optimizer.npz
[2019-06-06 04:57:37] [valid] Ep. 27 : Up. 120000 : cross-entropy : 62.9182 : stalled 2 times (last best: 61.7438)
[2019-06-06 04:57:49] [valid] Ep. 27 : Up. 120000 : perplexity : 11.7788 : stalled 2 times (last best: 11.2489)
[2019-06-06 04:59:38] [valid] Ep. 27 : Up. 120000 : translation : 25.08 : stalled 3 times (last best: 25.42)
[2019-06-06 05:15:40] Ep. 27 : Up. 122000 : Sen. 400,361 : Cost 19.98041725 : Time 1144.84s : 4537.67 words/s
[2019-06-06 05:27:42] Seen 595815 samples
[2019-06-06 05:27:42] Starting epoch 28
[2019-06-06 05:27:42] [data] Shuffling data
[2019-06-06 05:27:43] [data] Done reading 626913 sentences
[2019-06-06 05:27:45] [data] Done shuffling 626913 sentences to temp files
[2019-06-06 05:31:47] Ep. 28 : Up. 124000 : Sen. 64,700 : Cost 20.02166748 : Time 966.71s : 5374.71 words/s
[2019-06-06 05:47:46] Ep. 28 : Up. 126000 : Sen. 325,328 : Cost 19.55724144 : Time 959.17s : 5407.66 words/s
[2019-06-06 06:03:45] Ep. 28 : Up. 128000 : Sen. 585,682 : Cost 20.03636932 : Time 959.28s : 5408.75 words/s
[2019-06-06 06:04:24] Seen 595815 samples
[2019-06-06 06:04:24] Starting epoch 29
[2019-06-06 06:04:24] [data] Shuffling data
[2019-06-06 06:04:24] [data] Done reading 626913 sentences
[2019-06-06 06:04:27] [data] Done shuffling 626913 sentences to temp files
[2019-06-06 06:19:52] Ep. 29 : Up. 130000 : Sen. 250,487 : Cost 19.18343735 : Time 967.22s : 5379.56 words/s
[2019-06-06 06:35:55] Ep. 29 : Up. 132000 : Sen. 511,685 : Cost 19.77236366 : Time 962.55s : 5406.83 words/s
[2019-06-06 06:41:05] Seen 595815 samples
[2019-06-06 06:41:05] Starting epoch 30
[2019-06-06 06:41:05] [data] Shuffling data
[2019-06-06 06:41:06] [data] Done reading 626913 sentences
[2019-06-06 06:41:08] [data] Done shuffling 626913 sentences to temp files
[2019-06-06 06:52:00] Ep. 30 : Up. 134000 : Sen. 176,813 : Cost 19.04512024 : Time 965.55s : 5377.11 words/s
[2019-06-06 07:08:07] Ep. 30 : Up. 136000 : Sen. 438,095 : Cost 19.19639778 : Time 966.25s : 5407.14 words/s
[2019-06-06 07:17:46] Seen 595815 samples
[2019-06-06 07:17:46] Starting epoch 31
[2019-06-06 07:17:46] [data] Shuffling data
[2019-06-06 07:17:47] [data] Done reading 626913 sentences
[2019-06-06 07:17:49] [data] Done shuffling 626913 sentences to temp files
[2019-06-06 07:24:12] Ep. 31 : Up. 138000 : Sen. 103,558 : Cost 18.88076210 : Time 965.65s : 5384.07 words/s
[2019-06-06 07:40:12] Ep. 31 : Up. 140000 : Sen. 363,694 : Cost 18.69878578 : Time 959.35s : 5403.71 words/s
[2019-06-06 07:40:12] Saving model to model/model.npz.orig.npz
[2019-06-06 07:40:22] Saving model to model/model.iter140000.npz
[2019-06-06 07:40:29] Saving model to model/model.npz
[2019-06-06 07:40:39] Saving Adam parameters to model/model.npz.optimizer.npz
[2019-06-06 07:41:11] [valid] Ep. 31 : Up. 140000 : cross-entropy : 64.0561 : stalled 3 times (last best: 61.7438)
[2019-06-06 07:41:23] [valid] Ep. 31 : Up. 140000 : perplexity : 12.3161 : stalled 3 times (last best: 11.2489)
[2019-06-06 07:43:10] [valid] Ep. 31 : Up. 140000 : translation : 24.92 : stalled 4 times (last best: 25.42)
[2019-06-06 07:57:28] Seen 595815 samples
[2019-06-06 07:57:28] Starting epoch 32
[2019-06-06 07:57:28] [data] Shuffling data
[2019-06-06 07:57:29] [data] Done reading 626913 sentences
[2019-06-06 07:57:32] [data] Done shuffling 626913 sentences to temp files
[2019-06-06 07:59:17] Ep. 32 : Up. 142000 : Sen. 28,839 : Cost 19.11998367 : Time 1145.80s : 4530.37 words/s
[2019-06-06 08:15:20] Ep. 32 : Up. 144000 : Sen. 288,984 : Cost 18.40999031 : Time 962.29s : 5397.73 words/s
[2019-06-06 08:31:20] Ep. 32 : Up. 146000 : Sen. 549,477 : Cost 18.64913559 : Time 959.98s : 5406.70 words/s
[2019-06-06 08:34:12] Seen 595815 samples
[2019-06-06 08:34:12] Starting epoch 33
[2019-06-06 08:34:12] [data] Shuffling data
[2019-06-06 08:34:12] [data] Done reading 626913 sentences
[2019-06-06 08:34:15] [data] Done shuffling 626913 sentences to temp files
[2019-06-06 08:47:29] Ep. 33 : Up. 148000 : Sen. 214,398 : Cost 18.21443176 : Time 969.16s : 5371.88 words/s
[2019-06-06 09:03:27] Ep. 33 : Up. 150000 : Sen. 475,065 : Cost 18.37472725 : Time 957.88s : 5413.72 words/s
[2019-06-06 09:10:53] Seen 595815 samples
[2019-06-06 09:10:53] Starting epoch 34
[2019-06-06 09:10:53] [data] Shuffling data
[2019-06-06 09:10:54] [data] Done reading 626913 sentences
[2019-06-06 09:10:57] [data] Done shuffling 626913 sentences to temp files
[2019-06-06 09:19:33] Ep. 34 : Up. 152000 : Sen. 139,393 : Cost 18.16450310 : Time 966.45s : 5369.79 words/s
[2019-06-06 09:35:39] Ep. 34 : Up. 154000 : Sen. 400,870 : Cost 18.02366257 : Time 965.65s : 5389.57 words/s
[2019-06-06 09:47:40] Seen 595815 samples
[2019-06-06 09:47:40] Starting epoch 35
[2019-06-06 09:47:40] [data] Shuffling data
[2019-06-06 09:47:41] [data] Done reading 626913 sentences
[2019-06-06 09:47:44] [data] Done shuffling 626913 sentences to temp files
[2019-06-06 09:51:50] Ep. 35 : Up. 156000 : Sen. 65,496 : Cost 18.21507454 : Time 970.82s : 5354.12 words/s
[2019-06-06 10:07:51] Ep. 35 : Up. 158000 : Sen. 326,212 : Cost 17.65441322 : Time 961.75s : 5391.38 words/s
[2019-06-06 10:23:56] Ep. 35 : Up. 160000 : Sen. 586,637 : Cost 18.12885857 : Time 964.87s : 5388.35 words/s
[2019-06-06 10:23:56] Saving model to model/model.npz.orig.npz
[2019-06-06 10:24:06] Saving model to model/model.iter160000.npz
[2019-06-06 10:24:14] Saving model to model/model.npz
[2019-06-06 10:24:24] Saving Adam parameters to model/model.npz.optimizer.npz
[2019-06-06 10:24:55] [valid] Ep. 35 : Up. 160000 : cross-entropy : 65.2677 : stalled 4 times (last best: 61.7438)
[2019-06-06 10:25:07] [valid] Ep. 35 : Up. 160000 : perplexity : 12.9151 : stalled 4 times (last best: 11.2489)
[2019-06-06 10:26:56] [valid] Ep. 35 : Up. 160000 : translation : 24.93 : stalled 5 times (last best: 25.42)
[2019-06-06 10:27:32] Seen 595815 samples
[2019-06-06 10:27:32] Starting epoch 36
[2019-06-06 10:27:32] [data] Shuffling data
[2019-06-06 10:27:32] [data] Done reading 626913 sentences
[2019-06-06 10:27:35] [data] Done shuffling 626913 sentences to temp files
[2019-06-06 10:43:04] Ep. 36 : Up. 162000 : Sen. 251,250 : Cost 17.43019676 : Time 1148.02s : 4517.94 words/s
[2019-06-06 10:59:06] Ep. 36 : Up. 164000 : Sen. 511,787 : Cost 17.92126846 : Time 962.18s : 5398.26 words/s
[2019-06-06 11:04:18] Seen 595815 samples
[2019-06-06 11:04:18] Starting epoch 37
[2019-06-06 11:04:18] [data] Shuffling data
[2019-06-06 11:04:18] [data] Done reading 626913 sentences
[2019-06-06 11:04:21] [data] Done shuffling 626913 sentences to temp files
[2019-06-06 11:15:18] Ep. 37 : Up. 166000 : Sen. 177,236 : Cost 17.41488647 : Time 971.13s : 5368.13 words/s
[2019-06-06 11:31:20] Ep. 37 : Up. 168000 : Sen. 438,432 : Cost 17.54176903 : Time 962.55s : 5404.13 words/s
[2019-06-06 11:41:02] Seen 595815 samples
[2019-06-06 11:41:02] Starting epoch 38
[2019-06-06 11:41:02] [data] Shuffling data
[2019-06-06 11:41:03] [data] Done reading 626913 sentences
[2019-06-06 11:41:06] [data] Done shuffling 626913 sentences to temp files
[2019-06-06 11:47:26] Ep. 38 : Up. 170000 : Sen. 102,740 : Cost 17.44112587 : Time 965.94s : 5375.17 words/s
[2019-06-06 12:03:27] Ep. 38 : Up. 172000 : Sen. 363,267 : Cost 17.08747673 : Time 960.86s : 5406.55 words/s
[2019-06-06 12:17:44] Seen 595815 samples
[2019-06-06 12:17:44] Starting epoch 39
[2019-06-06 12:17:44] [data] Shuffling data
[2019-06-06 12:17:45] [data] Done reading 626913 sentences
[2019-06-06 12:17:48] [data] Done shuffling 626913 sentences to temp files
[2019-06-06 12:19:34] Ep. 39 : Up. 174000 : Sen. 28,752 : Cost 17.13581276 : Time 967.25s : 5371.42 words/s
[2019-06-06 12:35:35] Ep. 39 : Up. 176000 : Sen. 288,258 : Cost 16.71043015 : Time 961.25s : 5390.89 words/s
[2019-06-06 12:51:40] Ep. 39 : Up. 178000 : Sen. 549,133 : Cost 17.20995331 : Time 964.30s : 5391.25 words/s
[2019-06-06 12:54:32] Seen 595815 samples
[2019-06-06 12:54:32] Starting epoch 40
[2019-06-06 12:54:32] [data] Shuffling data
[2019-06-06 12:54:33] [data] Done reading 626913 sentences
[2019-06-06 12:54:36] [data] Done shuffling 626913 sentences to temp files
[2019-06-06 13:07:48] Ep. 40 : Up. 180000 : Sen. 214,053 : Cost 16.54411507 : Time 968.35s : 5364.23 words/s
[2019-06-06 13:07:48] Saving model to model/model.npz.orig.npz
[2019-06-06 13:08:00] Saving model to model/model.iter180000.npz
[2019-06-06 13:08:08] Saving model to model/model.npz
[2019-06-06 13:08:21] Saving Adam parameters to model/model.npz.optimizer.npz
[2019-06-06 13:08:54] [valid] Ep. 40 : Up. 180000 : cross-entropy : 66.5295 : stalled 5 times (last best: 61.7438)
[2019-06-06 13:09:07] [valid] Ep. 40 : Up. 180000 : perplexity : 13.57 : stalled 5 times (last best: 11.2489)
[2019-06-06 13:10:55] [valid] Ep. 40 : Up. 180000 : translation : 24.71 : stalled 6 times (last best: 25.42)
[2019-06-06 13:10:58] Training finished
[2019-06-06 13:11:02] Saving model to model/model.npz.orig.npz
[2019-06-06 13:11:12] Saving model to model/model.npz
[2019-06-06 13:11:25] Saving Adam parameters to model/model.npz.optimizer.npz
