[2019-07-25 02:12:20] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-25 02:12:20] [marian] Running on bil as process 414939 with command line:
[2019-07-25 02:12:20] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_bicleaner_dcce/model/model.npz -T . --devices 3 4 --train-sets ../experiments/100M_bicleaner_dcce/data/train.bpe.de ../experiments/100M_bicleaner_dcce/data/train.bpe.en --vocabs ../experiments/100M_bicleaner_dcce/data/train.bpe.de.json ../experiments/100M_bicleaner_dcce/data/train.bpe.en.json --mini-batch-fit -w 5000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_bicleaner_dcce/data/dev.bpe.de ../experiments/100M_bicleaner_dcce/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_bicleaner_dcce/model/dev.out --valid-script-path ../experiments/100M_bicleaner_dcce/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_bicleaner_dcce/model/train.log --valid-log ../experiments/100M_bicleaner_dcce/model/valid.log
[2019-07-25 02:12:20] [config] after-batches: 0
[2019-07-25 02:12:20] [config] after-epochs: 0
[2019-07-25 02:12:20] [config] allow-unk: false
[2019-07-25 02:12:20] [config] beam-size: 12
[2019-07-25 02:12:20] [config] bert-class-symbol: "[CLS]"
[2019-07-25 02:12:20] [config] bert-mask-symbol: "[MASK]"
[2019-07-25 02:12:20] [config] bert-masking-fraction: 0.15
[2019-07-25 02:12:20] [config] bert-sep-symbol: "[SEP]"
[2019-07-25 02:12:20] [config] bert-train-type-embeddings: true
[2019-07-25 02:12:20] [config] bert-type-vocab-size: 2
[2019-07-25 02:12:20] [config] best-deep: false
[2019-07-25 02:12:20] [config] clip-gemm: 0
[2019-07-25 02:12:20] [config] clip-norm: 1
[2019-07-25 02:12:20] [config] cost-type: ce-mean
[2019-07-25 02:12:20] [config] cpu-threads: 0
[2019-07-25 02:12:20] [config] data-weighting: ""
[2019-07-25 02:12:20] [config] data-weighting-type: sentence
[2019-07-25 02:12:20] [config] dec-cell: gru
[2019-07-25 02:12:20] [config] dec-cell-base-depth: 2
[2019-07-25 02:12:20] [config] dec-cell-high-depth: 1
[2019-07-25 02:12:20] [config] dec-depth: 1
[2019-07-25 02:12:20] [config] devices:
[2019-07-25 02:12:20] [config]   - 3
[2019-07-25 02:12:20] [config]   - 4
[2019-07-25 02:12:20] [config] dim-emb: 512
[2019-07-25 02:12:20] [config] dim-rnn: 1024
[2019-07-25 02:12:20] [config] dim-vocabs:
[2019-07-25 02:12:20] [config]   - 50000
[2019-07-25 02:12:20] [config]   - 50000
[2019-07-25 02:12:20] [config] disp-first: 0
[2019-07-25 02:12:20] [config] disp-freq: 2000
[2019-07-25 02:12:20] [config] disp-label-counts: false
[2019-07-25 02:12:20] [config] dropout-rnn: 0.2
[2019-07-25 02:12:20] [config] dropout-src: 0.1
[2019-07-25 02:12:20] [config] dropout-trg: 0.1
[2019-07-25 02:12:20] [config] dump-config: ""
[2019-07-25 02:12:20] [config] early-stopping: 5
[2019-07-25 02:12:20] [config] embedding-fix-src: false
[2019-07-25 02:12:20] [config] embedding-fix-trg: false
[2019-07-25 02:12:20] [config] embedding-normalization: false
[2019-07-25 02:12:20] [config] embedding-vectors:
[2019-07-25 02:12:20] [config]   []
[2019-07-25 02:12:20] [config] enc-cell: gru
[2019-07-25 02:12:20] [config] enc-cell-depth: 1
[2019-07-25 02:12:20] [config] enc-depth: 1
[2019-07-25 02:12:20] [config] enc-type: bidirectional
[2019-07-25 02:12:20] [config] exponential-smoothing: 0.0001
[2019-07-25 02:12:20] [config] grad-dropping-momentum: 0
[2019-07-25 02:12:20] [config] grad-dropping-rate: 0
[2019-07-25 02:12:20] [config] grad-dropping-warmup: 100
[2019-07-25 02:12:20] [config] guided-alignment: none
[2019-07-25 02:12:20] [config] guided-alignment-cost: mse
[2019-07-25 02:12:20] [config] guided-alignment-weight: 0.1
[2019-07-25 02:12:20] [config] ignore-model-config: false
[2019-07-25 02:12:20] [config] input-types:
[2019-07-25 02:12:20] [config]   []
[2019-07-25 02:12:20] [config] interpolate-env-vars: false
[2019-07-25 02:12:20] [config] keep-best: false
[2019-07-25 02:12:20] [config] label-smoothing: 0
[2019-07-25 02:12:20] [config] layer-normalization: true
[2019-07-25 02:12:20] [config] learn-rate: 0.0001
[2019-07-25 02:12:20] [config] log: ../experiments/100M_bicleaner_dcce/model/train.log
[2019-07-25 02:12:20] [config] log-level: info
[2019-07-25 02:12:20] [config] log-time-zone: ""
[2019-07-25 02:12:20] [config] lr-decay: 0
[2019-07-25 02:12:20] [config] lr-decay-freq: 50000
[2019-07-25 02:12:20] [config] lr-decay-inv-sqrt:
[2019-07-25 02:12:20] [config]   - 0
[2019-07-25 02:12:20] [config] lr-decay-repeat-warmup: false
[2019-07-25 02:12:20] [config] lr-decay-reset-optimizer: false
[2019-07-25 02:12:20] [config] lr-decay-start:
[2019-07-25 02:12:20] [config]   - 10
[2019-07-25 02:12:20] [config]   - 1
[2019-07-25 02:12:20] [config] lr-decay-strategy: epoch+stalled
[2019-07-25 02:12:20] [config] lr-report: false
[2019-07-25 02:12:20] [config] lr-warmup: 0
[2019-07-25 02:12:20] [config] lr-warmup-at-reload: false
[2019-07-25 02:12:20] [config] lr-warmup-cycle: false
[2019-07-25 02:12:20] [config] lr-warmup-start-rate: 0
[2019-07-25 02:12:20] [config] max-length: 50
[2019-07-25 02:12:20] [config] max-length-crop: false
[2019-07-25 02:12:20] [config] max-length-factor: 3
[2019-07-25 02:12:20] [config] maxi-batch: 100
[2019-07-25 02:12:20] [config] maxi-batch-sort: trg
[2019-07-25 02:12:20] [config] mini-batch: 64
[2019-07-25 02:12:20] [config] mini-batch-fit: true
[2019-07-25 02:12:20] [config] mini-batch-fit-step: 10
[2019-07-25 02:12:20] [config] mini-batch-overstuff: 1
[2019-07-25 02:12:20] [config] mini-batch-track-lr: false
[2019-07-25 02:12:20] [config] mini-batch-understuff: 1
[2019-07-25 02:12:20] [config] mini-batch-warmup: 0
[2019-07-25 02:12:20] [config] mini-batch-words: 0
[2019-07-25 02:12:20] [config] mini-batch-words-ref: 0
[2019-07-25 02:12:20] [config] model: ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-25 02:12:20] [config] multi-loss-type: sum
[2019-07-25 02:12:20] [config] multi-node: false
[2019-07-25 02:12:20] [config] multi-node-overlap: true
[2019-07-25 02:12:20] [config] n-best: false
[2019-07-25 02:12:20] [config] no-nccl: false
[2019-07-25 02:12:20] [config] no-reload: false
[2019-07-25 02:12:20] [config] no-restore-corpus: false
[2019-07-25 02:12:20] [config] no-shuffle: false
[2019-07-25 02:12:20] [config] normalize: 1
[2019-07-25 02:12:20] [config] num-devices: 0
[2019-07-25 02:12:20] [config] optimizer: adam
[2019-07-25 02:12:20] [config] optimizer-delay: 1
[2019-07-25 02:12:20] [config] optimizer-params:
[2019-07-25 02:12:20] [config]   []
[2019-07-25 02:12:20] [config] overwrite: false
[2019-07-25 02:12:20] [config] pretrained-model: ""
[2019-07-25 02:12:20] [config] quiet: false
[2019-07-25 02:12:20] [config] quiet-translation: true
[2019-07-25 02:12:20] [config] relative-paths: false
[2019-07-25 02:12:20] [config] right-left: false
[2019-07-25 02:12:20] [config] save-freq: 20000
[2019-07-25 02:12:20] [config] seed: 1111
[2019-07-25 02:12:20] [config] shuffle-in-ram: false
[2019-07-25 02:12:20] [config] skip: false
[2019-07-25 02:12:20] [config] sqlite: ""
[2019-07-25 02:12:20] [config] sqlite-drop: false
[2019-07-25 02:12:20] [config] sync-sgd: true
[2019-07-25 02:12:20] [config] tempdir: .
[2019-07-25 02:12:20] [config] tied-embeddings: false
[2019-07-25 02:12:20] [config] tied-embeddings-all: false
[2019-07-25 02:12:20] [config] tied-embeddings-src: false
[2019-07-25 02:12:20] [config] train-sets:
[2019-07-25 02:12:20] [config]   - ../experiments/100M_bicleaner_dcce/data/train.bpe.de
[2019-07-25 02:12:20] [config]   - ../experiments/100M_bicleaner_dcce/data/train.bpe.en
[2019-07-25 02:12:20] [config] transformer-aan-activation: swish
[2019-07-25 02:12:20] [config] transformer-aan-depth: 2
[2019-07-25 02:12:20] [config] transformer-aan-nogate: false
[2019-07-25 02:12:20] [config] transformer-decoder-autoreg: self-attention
[2019-07-25 02:12:20] [config] transformer-dim-aan: 2048
[2019-07-25 02:12:20] [config] transformer-dim-ffn: 2048
[2019-07-25 02:12:20] [config] transformer-dropout: 0
[2019-07-25 02:12:20] [config] transformer-dropout-attention: 0
[2019-07-25 02:12:20] [config] transformer-dropout-ffn: 0
[2019-07-25 02:12:20] [config] transformer-ffn-activation: swish
[2019-07-25 02:12:20] [config] transformer-ffn-depth: 2
[2019-07-25 02:12:20] [config] transformer-guided-alignment-layer: last
[2019-07-25 02:12:20] [config] transformer-heads: 8
[2019-07-25 02:12:20] [config] transformer-no-projection: false
[2019-07-25 02:12:20] [config] transformer-postprocess: dan
[2019-07-25 02:12:20] [config] transformer-postprocess-emb: d
[2019-07-25 02:12:20] [config] transformer-preprocess: ""
[2019-07-25 02:12:20] [config] transformer-tied-layers:
[2019-07-25 02:12:20] [config]   []
[2019-07-25 02:12:20] [config] transformer-train-position-embeddings: false
[2019-07-25 02:12:20] [config] type: amun
[2019-07-25 02:12:20] [config] ulr: false
[2019-07-25 02:12:20] [config] ulr-dim-emb: 0
[2019-07-25 02:12:20] [config] ulr-dropout: 0
[2019-07-25 02:12:20] [config] ulr-keys-vectors: ""
[2019-07-25 02:12:20] [config] ulr-query-vectors: ""
[2019-07-25 02:12:20] [config] ulr-softmax-temperature: 1
[2019-07-25 02:12:20] [config] ulr-trainable-transformation: false
[2019-07-25 02:12:20] [config] valid-freq: 20000
[2019-07-25 02:12:20] [config] valid-log: ../experiments/100M_bicleaner_dcce/model/valid.log
[2019-07-25 02:12:20] [config] valid-max-length: 1000
[2019-07-25 02:12:20] [config] valid-metrics:
[2019-07-25 02:12:20] [config]   - cross-entropy
[2019-07-25 02:12:20] [config]   - perplexity
[2019-07-25 02:12:20] [config]   - translation
[2019-07-25 02:12:20] [config] valid-mini-batch: 8
[2019-07-25 02:12:20] [config] valid-script-path: ../experiments/100M_bicleaner_dcce/score-dev.sh
[2019-07-25 02:12:20] [config] valid-sets:
[2019-07-25 02:12:20] [config]   - ../experiments/100M_bicleaner_dcce/data/dev.bpe.de
[2019-07-25 02:12:20] [config]   - ../experiments/100M_bicleaner_dcce/data/dev.bpe.en
[2019-07-25 02:12:20] [config] valid-translation-output: ../experiments/100M_bicleaner_dcce/model/dev.out
[2019-07-25 02:12:20] [config] vocabs:
[2019-07-25 02:12:20] [config]   - ../experiments/100M_bicleaner_dcce/data/train.bpe.de.json
[2019-07-25 02:12:20] [config]   - ../experiments/100M_bicleaner_dcce/data/train.bpe.en.json
[2019-07-25 02:12:20] [config] word-penalty: 0
[2019-07-25 02:12:20] [config] workspace: 5000
[2019-07-25 02:12:20] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-25 02:12:20] Using synchronous training
[2019-07-25 02:12:20] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_bicleaner_dcce/data/train.bpe.de.json
[2019-07-25 02:12:20] [data] Using unused word id eos for 0
[2019-07-25 02:12:20] [data] Using unused word id UNK for 1
[2019-07-25 02:12:20] [data] Setting vocabulary size for input 0 to 50000
[2019-07-25 02:12:20] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_bicleaner_dcce/data/train.bpe.en.json
[2019-07-25 02:12:20] [data] Using unused word id eos for 0
[2019-07-25 02:12:20] [data] Using unused word id UNK for 1
[2019-07-25 02:12:20] [data] Setting vocabulary size for input 1 to 50000
[2019-07-25 02:12:20] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-25 02:12:20] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-25 02:12:22] [memory] Extending reserved space to 5120 MB (device gpu3)
[2019-07-25 02:12:23] [memory] Extending reserved space to 5120 MB (device gpu4)
[2019-07-25 02:12:23] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-25 02:12:24] [comm] NCCLCommunicator constructed successfully.
[2019-07-25 02:12:24] [training] Using 2 GPUs
[2019-07-25 02:12:24] [memory] Reserving 422 MB, device gpu3
[2019-07-25 02:12:24] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-25 02:12:24] [memory] Reserving 422 MB, device gpu3
[2019-07-25 02:12:28] [batching] Done. Typical MB size is 13760 target words
[2019-07-25 02:12:28] [memory] Extending reserved space to 5120 MB (device gpu3)
[2019-07-25 02:12:28] [memory] Extending reserved space to 5120 MB (device gpu4)
[2019-07-25 02:12:28] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-25 02:12:28] [comm] NCCLCommunicator constructed successfully.
[2019-07-25 02:12:28] [training] Using 2 GPUs
[2019-07-25 02:12:28] Training started
[2019-07-25 02:12:28] [data] Shuffling data
[2019-07-25 02:12:32] [data] Done reading 4828705 sentences
[2019-07-25 02:12:56] [data] Done shuffling 4828705 sentences to temp files
[2019-07-25 02:12:58] [training] Batches are processed as 1 process(es) x 2 devices/process
[2019-07-25 02:12:58] [memory] Reserving 422 MB, device gpu3
[2019-07-25 02:12:58] [memory] Reserving 422 MB, device gpu4
[2019-07-25 02:12:58] [memory] Reserving 422 MB, device gpu3
[2019-07-25 02:12:58] [memory] Reserving 422 MB, device gpu4
[2019-07-25 02:12:58] [memory] Reserving 211 MB, device gpu3
[2019-07-25 02:12:58] [memory] Reserving 211 MB, device gpu4
[2019-07-25 02:12:59] [memory] Reserving 422 MB, device gpu3
[2019-07-25 02:12:59] [memory] Reserving 422 MB, device gpu4
[2019-07-25 02:23:25] Ep. 1 : Up. 2000 : Sen. 670,342 : Cost 131.58685303 : Time 664.50s : 22824.97 words/s
[2019-07-25 02:33:54] Ep. 1 : Up. 4000 : Sen. 1,344,528 : Cost 97.78229523 : Time 628.87s : 24261.81 words/s
[2019-07-25 02:44:24] Ep. 1 : Up. 6000 : Sen. 2,020,816 : Cost 82.13488770 : Time 630.07s : 24250.91 words/s
[2019-07-25 02:54:51] Ep. 1 : Up. 8000 : Sen. 2,691,838 : Cost 74.00823212 : Time 627.12s : 24219.76 words/s
[2019-07-25 03:05:19] Ep. 1 : Up. 10000 : Sen. 3,365,608 : Cost 68.82608032 : Time 627.94s : 24255.29 words/s
[2019-07-25 03:15:47] Ep. 1 : Up. 12000 : Sen. 4,039,208 : Cost 65.32459259 : Time 628.42s : 24252.23 words/s
[2019-07-25 03:18:17] Seen 4199891 samples
[2019-07-25 03:18:17] Starting epoch 2
[2019-07-25 03:18:17] [data] Shuffling data
[2019-07-25 03:18:20] [data] Done reading 4828705 sentences
[2019-07-25 03:18:43] [data] Done shuffling 4828705 sentences to temp files
[2019-07-25 03:26:43] Ep. 2 : Up. 14000 : Sen. 516,018 : Cost 62.32477188 : Time 656.26s : 23330.39 words/s
[2019-07-25 03:37:04] Ep. 2 : Up. 16000 : Sen. 1,188,648 : Cost 60.18663406 : Time 620.41s : 24503.00 words/s
[2019-07-25 03:47:32] Ep. 2 : Up. 18000 : Sen. 1,863,098 : Cost 58.60685349 : Time 628.64s : 24264.58 words/s
[2019-07-25 03:58:00] Ep. 2 : Up. 20000 : Sen. 2,535,228 : Cost 57.58921051 : Time 627.71s : 24227.46 words/s
[2019-07-25 03:58:00] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-25 03:58:05] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter20000.npz
[2019-07-25 03:58:08] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-25 03:58:13] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-25 03:58:27] [valid] Ep. 2 : Up. 20000 : cross-entropy : 56.502 : new best
[2019-07-25 03:58:31] [valid] Ep. 2 : Up. 20000 : perplexity : 9.25838 : new best
[2019-07-25 03:59:17] [valid] Ep. 2 : Up. 20000 : translation : 25.86 : new best
[2019-07-25 04:09:48] Ep. 2 : Up. 22000 : Sen. 3,208,000 : Cost 56.40161514 : Time 707.94s : 21512.88 words/s
[2019-07-25 04:20:17] Ep. 2 : Up. 24000 : Sen. 3,882,504 : Cost 55.42382431 : Time 628.56s : 24278.56 words/s
[2019-07-25 04:25:13] Seen 4199891 samples
[2019-07-25 04:25:13] Starting epoch 3
[2019-07-25 04:25:13] [data] Shuffling data
[2019-07-25 04:25:16] [data] Done reading 4828705 sentences
[2019-07-25 04:25:38] [data] Done shuffling 4828705 sentences to temp files
[2019-07-25 04:31:11] Ep. 3 : Up. 26000 : Sen. 355,490 : Cost 54.02565384 : Time 654.49s : 23264.85 words/s
[2019-07-25 04:41:40] Ep. 3 : Up. 28000 : Sen. 1,028,978 : Cost 53.03683472 : Time 629.05s : 24233.75 words/s
[2019-07-25 04:52:09] Ep. 3 : Up. 30000 : Sen. 1,704,502 : Cost 52.38540649 : Time 628.57s : 24292.38 words/s
[2019-07-25 05:02:37] Ep. 3 : Up. 32000 : Sen. 2,377,158 : Cost 51.89547729 : Time 628.30s : 24204.55 words/s
[2019-07-25 05:13:07] Ep. 3 : Up. 34000 : Sen. 3,051,151 : Cost 51.57451248 : Time 630.39s : 24218.99 words/s
[2019-07-25 05:23:36] Ep. 3 : Up. 36000 : Sen. 3,723,380 : Cost 50.98400879 : Time 628.55s : 24159.13 words/s
[2019-07-25 05:30:57] Seen 4199891 samples
[2019-07-25 05:30:57] Starting epoch 4
[2019-07-25 05:30:57] [data] Shuffling data
[2019-07-25 05:31:00] [data] Done reading 4828705 sentences
[2019-07-25 05:31:24] [data] Done shuffling 4828705 sentences to temp files
[2019-07-25 05:34:25] Ep. 4 : Up. 38000 : Sen. 195,002 : Cost 50.47195816 : Time 648.64s : 23435.67 words/s
[2019-07-25 05:44:51] Ep. 4 : Up. 40000 : Sen. 867,466 : Cost 49.36795807 : Time 626.38s : 24277.69 words/s
[2019-07-25 05:44:51] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-25 05:44:57] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter40000.npz
[2019-07-25 05:44:59] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-25 05:45:05] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-25 05:45:22] [valid] Ep. 4 : Up. 40000 : cross-entropy : 47.919 : new best
[2019-07-25 05:45:26] [valid] Ep. 4 : Up. 40000 : perplexity : 6.60256 : new best
[2019-07-25 05:46:10] [valid] Ep. 4 : Up. 40000 : translation : 28.48 : new best
[2019-07-25 05:56:38] Ep. 4 : Up. 42000 : Sen. 1,540,884 : Cost 49.17490005 : Time 707.38s : 21518.03 words/s
[2019-07-25 06:07:06] Ep. 4 : Up. 44000 : Sen. 2,213,216 : Cost 49.09935760 : Time 627.60s : 24254.35 words/s
[2019-07-25 06:17:35] Ep. 4 : Up. 46000 : Sen. 2,888,920 : Cost 48.67517090 : Time 629.26s : 24278.93 words/s
[2019-07-25 06:28:05] Ep. 4 : Up. 48000 : Sen. 3,564,188 : Cost 48.35230255 : Time 629.50s : 24267.48 words/s
[2019-07-25 06:37:57] Seen 4199891 samples
[2019-07-25 06:37:57] Starting epoch 5
[2019-07-25 06:37:57] [data] Shuffling data
[2019-07-25 06:38:00] [data] Done reading 4828705 sentences
[2019-07-25 06:38:23] [data] Done shuffling 4828705 sentences to temp files
[2019-07-25 06:39:00] Ep. 5 : Up. 50000 : Sen. 38,664 : Cost 48.15750122 : Time 655.57s : 23272.43 words/s
[2019-07-25 06:49:30] Ep. 5 : Up. 52000 : Sen. 713,864 : Cost 47.03032303 : Time 629.66s : 24241.30 words/s
[2019-07-25 06:59:59] Ep. 5 : Up. 54000 : Sen. 1,389,064 : Cost 47.16819763 : Time 628.66s : 24312.55 words/s
[2019-07-25 07:10:28] Ep. 5 : Up. 56000 : Sen. 2,063,362 : Cost 46.90708160 : Time 629.45s : 24225.54 words/s
[2019-07-25 07:20:58] Ep. 5 : Up. 58000 : Sen. 2,738,936 : Cost 46.72618484 : Time 629.51s : 24262.27 words/s
[2019-07-25 07:31:27] Ep. 5 : Up. 60000 : Sen. 3,412,700 : Cost 46.62287521 : Time 629.71s : 24218.13 words/s
[2019-07-25 07:31:27] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-25 07:31:33] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter60000.npz
[2019-07-25 07:31:35] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-25 07:31:41] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-25 07:31:58] [valid] Ep. 5 : Up. 60000 : cross-entropy : 44.6133 : new best
[2019-07-25 07:32:01] [valid] Ep. 5 : Up. 60000 : perplexity : 5.79647 : new best
[2019-07-25 07:32:48] [valid] Ep. 5 : Up. 60000 : translation : 29.59 : new best
[2019-07-25 07:43:20] Ep. 5 : Up. 62000 : Sen. 4,088,264 : Cost 46.65267944 : Time 713.05s : 21430.06 words/s
[2019-07-25 07:45:04] Seen 4199891 samples
[2019-07-25 07:45:04] Starting epoch 6
[2019-07-25 07:45:04] [data] Shuffling data
[2019-07-25 07:45:08] [data] Done reading 4828705 sentences
[2019-07-25 07:45:30] [data] Done shuffling 4828705 sentences to temp files
[2019-07-25 07:54:15] Ep. 6 : Up. 64000 : Sen. 561,948 : Cost 45.49931717 : Time 654.26s : 23272.42 words/s
[2019-07-25 08:04:43] Ep. 6 : Up. 66000 : Sen. 1,235,200 : Cost 45.50413132 : Time 628.58s : 24232.36 words/s
[2019-07-25 08:15:12] Ep. 6 : Up. 68000 : Sen. 1,909,694 : Cost 45.33882141 : Time 628.31s : 24255.07 words/s
[2019-07-25 08:25:40] Ep. 6 : Up. 70000 : Sen. 2,581,582 : Cost 45.73089600 : Time 628.22s : 24233.02 words/s
[2019-07-25 08:36:08] Ep. 6 : Up. 72000 : Sen. 3,255,234 : Cost 45.32934952 : Time 628.48s : 24266.46 words/s
[2019-07-25 08:46:36] Ep. 6 : Up. 74000 : Sen. 3,927,386 : Cost 45.19478989 : Time 627.26s : 24245.86 words/s
[2019-07-25 08:50:49] Seen 4199891 samples
[2019-07-25 08:50:49] Starting epoch 7
[2019-07-25 08:50:49] [data] Shuffling data
[2019-07-25 08:50:53] [data] Done reading 4828705 sentences
[2019-07-25 08:51:15] [data] Done shuffling 4828705 sentences to temp files
[2019-07-25 08:57:28] Ep. 7 : Up. 76000 : Sen. 402,740 : Cost 44.59552765 : Time 652.15s : 23407.32 words/s
[2019-07-25 09:07:52] Ep. 7 : Up. 78000 : Sen. 1,075,464 : Cost 44.25369263 : Time 624.31s : 24370.98 words/s
[2019-07-25 09:18:22] Ep. 7 : Up. 80000 : Sen. 1,752,876 : Cost 44.33097839 : Time 629.67s : 24319.34 words/s
[2019-07-25 09:18:22] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-25 09:18:27] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter80000.npz
[2019-07-25 09:18:30] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-25 09:18:36] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-25 09:18:52] [valid] Ep. 7 : Up. 80000 : cross-entropy : 42.809 : new best
[2019-07-25 09:18:56] [valid] Ep. 7 : Up. 80000 : perplexity : 5.39884 : new best
[2019-07-25 09:19:42] [valid] Ep. 7 : Up. 80000 : translation : 30.15 : new best
[2019-07-25 09:30:11] Ep. 7 : Up. 82000 : Sen. 2,426,212 : Cost 44.28651810 : Time 709.00s : 21478.85 words/s
[2019-07-25 09:40:29] Ep. 7 : Up. 84000 : Sen. 3,099,840 : Cost 44.21585083 : Time 618.58s : 24650.60 words/s
[2019-07-25 09:50:58] Ep. 7 : Up. 86000 : Sen. 3,773,064 : Cost 44.17073059 : Time 628.34s : 24238.39 words/s
[2019-07-25 09:57:37] Seen 4199891 samples
[2019-07-25 09:57:37] Starting epoch 8
[2019-07-25 09:57:37] [data] Shuffling data
[2019-07-25 09:57:40] [data] Done reading 4828705 sentences
[2019-07-25 09:58:02] [data] Done shuffling 4828705 sentences to temp files
[2019-07-25 10:01:54] Ep. 8 : Up. 88000 : Sen. 246,902 : Cost 43.73652649 : Time 656.89s : 23209.42 words/s
[2019-07-25 10:12:25] Ep. 8 : Up. 90000 : Sen. 924,384 : Cost 43.29657745 : Time 630.94s : 24265.40 words/s
[2019-07-25 10:22:55] Ep. 8 : Up. 92000 : Sen. 1,598,400 : Cost 43.33434677 : Time 629.35s : 24204.07 words/s
[2019-07-25 10:33:25] Ep. 8 : Up. 94000 : Sen. 2,273,793 : Cost 43.49512482 : Time 630.09s : 24254.24 words/s
[2019-07-25 10:43:48] Ep. 8 : Up. 96000 : Sen. 2,945,668 : Cost 43.48668289 : Time 622.78s : 24446.57 words/s
[2019-07-25 10:54:16] Ep. 8 : Up. 98000 : Sen. 3,619,025 : Cost 43.24242401 : Time 628.73s : 24197.86 words/s
[2019-07-25 11:03:19] Seen 4199891 samples
[2019-07-25 11:03:19] Starting epoch 9
[2019-07-25 11:03:19] [data] Shuffling data
[2019-07-25 11:03:22] [data] Done reading 4828705 sentences
[2019-07-25 11:03:44] [data] Done shuffling 4828705 sentences to temp files
[2019-07-25 11:05:12] Ep. 9 : Up. 100000 : Sen. 93,984 : Cost 43.21261215 : Time 656.03s : 23264.16 words/s
[2019-07-25 11:05:12] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-25 11:05:18] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter100000.npz
[2019-07-25 11:05:21] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-25 11:05:27] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-25 11:05:45] [valid] Ep. 9 : Up. 100000 : cross-entropy : 41.6349 : new best
[2019-07-25 11:05:49] [valid] Ep. 9 : Up. 100000 : perplexity : 5.15485 : new best
[2019-07-25 11:06:39] [valid] Ep. 9 : Up. 100000 : translation : 30.51 : new best
[2019-07-25 11:17:09] Ep. 9 : Up. 102000 : Sen. 764,800 : Cost 42.60090256 : Time 716.69s : 21196.84 words/s
[2019-07-25 11:27:38] Ep. 9 : Up. 104000 : Sen. 1,439,736 : Cost 42.60485840 : Time 629.20s : 24256.49 words/s
[2019-07-25 11:38:07] Ep. 9 : Up. 106000 : Sen. 2,114,144 : Cost 42.56166840 : Time 628.89s : 24238.18 words/s
[2019-07-25 11:48:36] Ep. 9 : Up. 108000 : Sen. 2,789,260 : Cost 42.60588455 : Time 629.27s : 24253.26 words/s
[2019-07-25 11:59:06] Ep. 9 : Up. 110000 : Sen. 3,463,916 : Cost 42.72161102 : Time 629.71s : 24277.64 words/s
[2019-07-25 12:09:35] Ep. 9 : Up. 112000 : Sen. 4,137,252 : Cost 42.63197327 : Time 628.84s : 24194.24 words/s
[2019-07-25 12:10:34] Seen 4199891 samples
[2019-07-25 12:10:34] Starting epoch 10
[2019-07-25 12:10:34] [data] Shuffling data
[2019-07-25 12:10:37] [data] Done reading 4828705 sentences
[2019-07-25 12:11:00] [data] Done shuffling 4828705 sentences to temp files
[2019-07-25 12:20:33] Ep. 10 : Up. 114000 : Sen. 611,518 : Cost 41.82889175 : Time 657.77s : 23188.37 words/s
[2019-07-25 12:31:04] Ep. 10 : Up. 116000 : Sen. 1,283,840 : Cost 42.19499207 : Time 630.91s : 24175.01 words/s
[2019-07-25 12:41:34] Ep. 10 : Up. 118000 : Sen. 1,959,012 : Cost 41.88554382 : Time 630.39s : 24211.12 words/s
[2019-07-25 12:52:05] Ep. 10 : Up. 120000 : Sen. 2,636,008 : Cost 41.97415924 : Time 631.24s : 24229.77 words/s
[2019-07-25 12:52:05] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-25 12:52:11] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter120000.npz
[2019-07-25 12:52:14] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-25 12:52:20] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-25 12:52:37] [valid] Ep. 10 : Up. 120000 : cross-entropy : 40.867 : new best
[2019-07-25 12:52:40] [valid] Ep. 10 : Up. 120000 : perplexity : 5.00125 : new best
[2019-07-25 12:53:28] [valid] Ep. 10 : Up. 120000 : translation : 30.7 : new best
[2019-07-25 13:03:59] Ep. 10 : Up. 122000 : Sen. 3,306,392 : Cost 42.00444794 : Time 713.58s : 21259.75 words/s
[2019-07-25 13:14:28] Ep. 10 : Up. 124000 : Sen. 3,980,272 : Cost 42.00238419 : Time 629.21s : 24194.65 words/s
[2019-07-25 13:17:54] Seen 4199891 samples
[2019-07-25 13:17:54] Starting epoch 11
[2019-07-25 13:17:54] [data] Shuffling data
[2019-07-25 13:17:57] [data] Done reading 4828705 sentences
[2019-07-25 13:18:20] [data] Done shuffling 4828705 sentences to temp files
[2019-07-25 13:25:26] Ep. 11 : Up. 126000 : Sen. 453,872 : Cost 41.59236526 : Time 658.20s : 23134.42 words/s
[2019-07-25 13:35:56] Ep. 11 : Up. 128000 : Sen. 1,125,750 : Cost 41.28440475 : Time 630.01s : 24132.27 words/s
[2019-07-25 13:46:27] Ep. 11 : Up. 130000 : Sen. 1,798,400 : Cost 41.37794876 : Time 630.27s : 24163.53 words/s
[2019-07-25 13:56:57] Ep. 11 : Up. 132000 : Sen. 2,471,652 : Cost 41.52911377 : Time 630.19s : 24171.67 words/s
[2019-07-25 14:36:12] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-25 14:36:12] [marian] Running on bil as process 2338 with command line:
[2019-07-25 14:36:12] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_bicleaner_dcce/model/model.npz -T . --devices 3 4 --train-sets ../experiments/100M_bicleaner_dcce/data/train.bpe.de ../experiments/100M_bicleaner_dcce/data/train.bpe.en --vocabs ../experiments/100M_bicleaner_dcce/data/train.bpe.de.json ../experiments/100M_bicleaner_dcce/data/train.bpe.en.json --mini-batch-fit -w 5000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_bicleaner_dcce/data/dev.bpe.de ../experiments/100M_bicleaner_dcce/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_bicleaner_dcce/model/dev.out --valid-script-path ../experiments/100M_bicleaner_dcce/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_bicleaner_dcce/model/train.log --valid-log ../experiments/100M_bicleaner_dcce/model/valid.log
[2019-07-25 14:36:12] [config] after-batches: 0
[2019-07-25 14:36:12] [config] after-epochs: 0
[2019-07-25 14:36:12] [config] allow-unk: false
[2019-07-25 14:36:12] [config] beam-size: 12
[2019-07-25 14:36:12] [config] bert-class-symbol: "[CLS]"
[2019-07-25 14:36:12] [config] bert-mask-symbol: "[MASK]"
[2019-07-25 14:36:12] [config] bert-masking-fraction: 0.15
[2019-07-25 14:36:12] [config] bert-sep-symbol: "[SEP]"
[2019-07-25 14:36:12] [config] bert-train-type-embeddings: true
[2019-07-25 14:36:12] [config] bert-type-vocab-size: 2
[2019-07-25 14:36:12] [config] best-deep: false
[2019-07-25 14:36:12] [config] clip-gemm: 0
[2019-07-25 14:36:12] [config] clip-norm: 1
[2019-07-25 14:36:12] [config] cost-type: ce-mean
[2019-07-25 14:36:12] [config] cpu-threads: 0
[2019-07-25 14:36:12] [config] data-weighting: ""
[2019-07-25 14:36:12] [config] data-weighting-type: sentence
[2019-07-25 14:36:12] [config] dec-cell: gru
[2019-07-25 14:36:12] [config] dec-cell-base-depth: 2
[2019-07-25 14:36:12] [config] dec-cell-high-depth: 1
[2019-07-25 14:36:12] [config] dec-depth: 1
[2019-07-25 14:36:12] [config] devices:
[2019-07-25 14:36:12] [config]   - 3
[2019-07-25 14:36:12] [config]   - 4
[2019-07-25 14:36:12] [config] dim-emb: 512
[2019-07-25 14:36:12] [config] dim-rnn: 1024
[2019-07-25 14:36:12] [config] dim-vocabs:
[2019-07-25 14:36:12] [config]   - 50000
[2019-07-25 14:36:12] [config]   - 50000
[2019-07-25 14:36:12] [config] disp-first: 0
[2019-07-25 14:36:12] [config] disp-freq: 2000
[2019-07-25 14:36:12] [config] disp-label-counts: false
[2019-07-25 14:36:12] [config] dropout-rnn: 0.2
[2019-07-25 14:36:12] [config] dropout-src: 0.1
[2019-07-25 14:36:12] [config] dropout-trg: 0.1
[2019-07-25 14:36:12] [config] dump-config: ""
[2019-07-25 14:36:12] [config] early-stopping: 5
[2019-07-25 14:36:12] [config] embedding-fix-src: false
[2019-07-25 14:36:12] [config] embedding-fix-trg: false
[2019-07-25 14:36:12] [config] embedding-normalization: false
[2019-07-25 14:36:12] [config] embedding-vectors:
[2019-07-25 14:36:12] [config]   []
[2019-07-25 14:36:12] [config] enc-cell: gru
[2019-07-25 14:36:12] [config] enc-cell-depth: 1
[2019-07-25 14:36:12] [config] enc-depth: 1
[2019-07-25 14:36:12] [config] enc-type: bidirectional
[2019-07-25 14:36:12] [config] exponential-smoothing: 0.0001
[2019-07-25 14:36:12] [config] grad-dropping-momentum: 0
[2019-07-25 14:36:12] [config] grad-dropping-rate: 0
[2019-07-25 14:36:12] [config] grad-dropping-warmup: 100
[2019-07-25 14:36:12] [config] guided-alignment: none
[2019-07-25 14:36:12] [config] guided-alignment-cost: mse
[2019-07-25 14:36:12] [config] guided-alignment-weight: 0.1
[2019-07-25 14:36:12] [config] ignore-model-config: false
[2019-07-25 14:36:12] [config] input-types:
[2019-07-25 14:36:12] [config]   []
[2019-07-25 14:36:12] [config] interpolate-env-vars: false
[2019-07-25 14:36:12] [config] keep-best: false
[2019-07-25 14:36:12] [config] label-smoothing: 0
[2019-07-25 14:36:12] [config] layer-normalization: true
[2019-07-25 14:36:12] [config] learn-rate: 0.0001
[2019-07-25 14:36:12] [config] log: ../experiments/100M_bicleaner_dcce/model/train.log
[2019-07-25 14:36:12] [config] log-level: info
[2019-07-25 14:36:12] [config] log-time-zone: ""
[2019-07-25 14:36:12] [config] lr-decay: 0
[2019-07-25 14:36:12] [config] lr-decay-freq: 50000
[2019-07-25 14:36:12] [config] lr-decay-inv-sqrt:
[2019-07-25 14:36:12] [config]   - 0
[2019-07-25 14:36:12] [config] lr-decay-repeat-warmup: false
[2019-07-25 14:36:12] [config] lr-decay-reset-optimizer: false
[2019-07-25 14:36:12] [config] lr-decay-start:
[2019-07-25 14:36:12] [config]   - 10
[2019-07-25 14:36:12] [config]   - 1
[2019-07-25 14:36:12] [config] lr-decay-strategy: epoch+stalled
[2019-07-25 14:36:12] [config] lr-report: false
[2019-07-25 14:36:12] [config] lr-warmup: 0
[2019-07-25 14:36:12] [config] lr-warmup-at-reload: false
[2019-07-25 14:36:12] [config] lr-warmup-cycle: false
[2019-07-25 14:36:12] [config] lr-warmup-start-rate: 0
[2019-07-25 14:36:12] [config] max-length: 50
[2019-07-25 14:36:12] [config] max-length-crop: false
[2019-07-25 14:36:12] [config] max-length-factor: 3
[2019-07-25 14:36:12] [config] maxi-batch: 100
[2019-07-25 14:36:12] [config] maxi-batch-sort: trg
[2019-07-25 14:36:12] [config] mini-batch: 64
[2019-07-25 14:36:12] [config] mini-batch-fit: true
[2019-07-25 14:36:12] [config] mini-batch-fit-step: 10
[2019-07-25 14:36:12] [config] mini-batch-overstuff: 1
[2019-07-25 14:36:12] [config] mini-batch-track-lr: false
[2019-07-25 14:36:12] [config] mini-batch-understuff: 1
[2019-07-25 14:36:12] [config] mini-batch-warmup: 0
[2019-07-25 14:36:12] [config] mini-batch-words: 0
[2019-07-25 14:36:12] [config] mini-batch-words-ref: 0
[2019-07-25 14:36:12] [config] model: ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-25 14:36:12] [config] multi-loss-type: sum
[2019-07-25 14:36:12] [config] multi-node: false
[2019-07-25 14:36:12] [config] multi-node-overlap: true
[2019-07-25 14:36:12] [config] n-best: false
[2019-07-25 14:36:12] [config] no-nccl: false
[2019-07-25 14:36:12] [config] no-reload: false
[2019-07-25 14:36:12] [config] no-restore-corpus: false
[2019-07-25 14:36:12] [config] no-shuffle: false
[2019-07-25 14:36:12] [config] normalize: 1
[2019-07-25 14:36:12] [config] num-devices: 0
[2019-07-25 14:36:12] [config] optimizer: adam
[2019-07-25 14:36:12] [config] optimizer-delay: 1
[2019-07-25 14:36:12] [config] optimizer-params:
[2019-07-25 14:36:12] [config]   []
[2019-07-25 14:36:12] [config] overwrite: false
[2019-07-25 14:36:12] [config] pretrained-model: ""
[2019-07-25 14:36:12] [config] quiet: false
[2019-07-25 14:36:12] [config] quiet-translation: true
[2019-07-25 14:36:12] [config] relative-paths: false
[2019-07-25 14:36:12] [config] right-left: false
[2019-07-25 14:36:12] [config] save-freq: 20000
[2019-07-25 14:36:12] [config] seed: 1111
[2019-07-25 14:36:12] [config] shuffle-in-ram: false
[2019-07-25 14:36:12] [config] skip: false
[2019-07-25 14:36:12] [config] sqlite: ""
[2019-07-25 14:36:12] [config] sqlite-drop: false
[2019-07-25 14:36:12] [config] sync-sgd: true
[2019-07-25 14:36:12] [config] tempdir: .
[2019-07-25 14:36:12] [config] tied-embeddings: false
[2019-07-25 14:36:12] [config] tied-embeddings-all: false
[2019-07-25 14:36:12] [config] tied-embeddings-src: false
[2019-07-25 14:36:12] [config] train-sets:
[2019-07-25 14:36:12] [config]   - ../experiments/100M_bicleaner_dcce/data/train.bpe.de
[2019-07-25 14:36:12] [config]   - ../experiments/100M_bicleaner_dcce/data/train.bpe.en
[2019-07-25 14:36:12] [config] transformer-aan-activation: swish
[2019-07-25 14:36:12] [config] transformer-aan-depth: 2
[2019-07-25 14:36:12] [config] transformer-aan-nogate: false
[2019-07-25 14:36:12] [config] transformer-decoder-autoreg: self-attention
[2019-07-25 14:36:12] [config] transformer-dim-aan: 2048
[2019-07-25 14:36:12] [config] transformer-dim-ffn: 2048
[2019-07-25 14:36:12] [config] transformer-dropout: 0
[2019-07-25 14:36:12] [config] transformer-dropout-attention: 0
[2019-07-25 14:36:12] [config] transformer-dropout-ffn: 0
[2019-07-25 14:36:12] [config] transformer-ffn-activation: swish
[2019-07-25 14:36:12] [config] transformer-ffn-depth: 2
[2019-07-25 14:36:12] [config] transformer-guided-alignment-layer: last
[2019-07-25 14:36:12] [config] transformer-heads: 8
[2019-07-25 14:36:12] [config] transformer-no-projection: false
[2019-07-25 14:36:12] [config] transformer-postprocess: dan
[2019-07-25 14:36:12] [config] transformer-postprocess-emb: d
[2019-07-25 14:36:12] [config] transformer-preprocess: ""
[2019-07-25 14:36:12] [config] transformer-tied-layers:
[2019-07-25 14:36:12] [config]   []
[2019-07-25 14:36:12] [config] transformer-train-position-embeddings: false
[2019-07-25 14:36:12] [config] type: amun
[2019-07-25 14:36:12] [config] ulr: false
[2019-07-25 14:36:12] [config] ulr-dim-emb: 0
[2019-07-25 14:36:12] [config] ulr-dropout: 0
[2019-07-25 14:36:12] [config] ulr-keys-vectors: ""
[2019-07-25 14:36:12] [config] ulr-query-vectors: ""
[2019-07-25 14:36:12] [config] ulr-softmax-temperature: 1
[2019-07-25 14:36:12] [config] ulr-trainable-transformation: false
[2019-07-25 14:36:12] [config] valid-freq: 20000
[2019-07-25 14:36:12] [config] valid-log: ../experiments/100M_bicleaner_dcce/model/valid.log
[2019-07-25 14:36:12] [config] valid-max-length: 1000
[2019-07-25 14:36:12] [config] valid-metrics:
[2019-07-25 14:36:12] [config]   - cross-entropy
[2019-07-25 14:36:12] [config]   - perplexity
[2019-07-25 14:36:12] [config]   - translation
[2019-07-25 14:36:12] [config] valid-mini-batch: 8
[2019-07-25 14:36:12] [config] valid-script-path: ../experiments/100M_bicleaner_dcce/score-dev.sh
[2019-07-25 14:36:12] [config] valid-sets:
[2019-07-25 14:36:12] [config]   - ../experiments/100M_bicleaner_dcce/data/dev.bpe.de
[2019-07-25 14:36:12] [config]   - ../experiments/100M_bicleaner_dcce/data/dev.bpe.en
[2019-07-25 14:36:12] [config] valid-translation-output: ../experiments/100M_bicleaner_dcce/model/dev.out
[2019-07-25 14:36:12] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-25 14:36:12] [config] vocabs:
[2019-07-25 14:36:12] [config]   - ../experiments/100M_bicleaner_dcce/data/train.bpe.de.json
[2019-07-25 14:36:12] [config]   - ../experiments/100M_bicleaner_dcce/data/train.bpe.en.json
[2019-07-25 14:36:12] [config] word-penalty: 0
[2019-07-25 14:36:12] [config] workspace: 5000
[2019-07-25 14:36:12] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-25 14:36:12] Using synchronous training
[2019-07-25 14:36:12] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_bicleaner_dcce/data/train.bpe.de.json
[2019-07-25 14:36:13] [data] Using unused word id eos for 0
[2019-07-25 14:36:13] [data] Using unused word id UNK for 1
[2019-07-25 14:36:13] [data] Setting vocabulary size for input 0 to 50000
[2019-07-25 14:36:13] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_bicleaner_dcce/data/train.bpe.en.json
[2019-07-25 14:36:13] [data] Using unused word id eos for 0
[2019-07-25 14:36:13] [data] Using unused word id UNK for 1
[2019-07-25 14:36:13] [data] Setting vocabulary size for input 1 to 50000
[2019-07-25 14:36:13] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-25 14:36:13] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-25 14:36:15] [memory] Extending reserved space to 5120 MB (device gpu3)
[2019-07-25 14:36:16] [memory] Extending reserved space to 5120 MB (device gpu4)
[2019-07-25 14:36:16] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-25 14:36:17] [comm] NCCLCommunicator constructed successfully.
[2019-07-25 14:36:17] [training] Using 2 GPUs
[2019-07-25 14:36:17] [memory] Reserving 422 MB, device gpu3
[2019-07-25 14:36:17] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-25 14:36:17] [memory] Reserving 422 MB, device gpu3
[2019-07-25 14:36:21] [batching] Done. Typical MB size is 13760 target words
[2019-07-25 14:36:21] [memory] Extending reserved space to 5120 MB (device gpu3)
[2019-07-25 14:36:21] [memory] Extending reserved space to 5120 MB (device gpu4)
[2019-07-25 14:36:21] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-25 14:36:21] [comm] NCCLCommunicator constructed successfully.
[2019-07-25 14:36:21] [training] Using 2 GPUs
[2019-07-25 14:36:21] Loading model from ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-25 14:36:24] Loading model from ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-25 14:36:27] Loading Adam parameters from ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-25 14:36:30] [memory] Reserving 422 MB, device gpu3
[2019-07-25 14:36:30] [memory] Reserving 422 MB, device gpu4
[2019-07-25 14:36:31] [training] Model reloaded from ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-25 14:36:31] [data] Restoring the corpus state to epoch 10, batch 120000
[2019-07-25 14:36:31] [data] Shuffling data
[2019-07-25 14:36:34] [data] Done reading 4828705 sentences
[2019-07-25 14:36:52] [data] Done shuffling 4828705 sentences to temp files
[2019-07-25 14:38:07] Training started
[2019-07-25 14:38:07] [training] Batches are processed as 1 process(es) x 2 devices/process
[2019-07-25 14:38:07] [memory] Reserving 422 MB, device gpu4
[2019-07-25 14:38:07] [memory] Reserving 422 MB, device gpu3
[2019-07-25 14:38:07] [memory] Reserving 422 MB, device gpu4
[2019-07-25 14:38:07] [memory] Reserving 422 MB, device gpu3
[2019-07-25 14:38:07] Loading model from ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-25 14:38:10] [memory] Reserving 422 MB, device cpu0
[2019-07-25 14:38:11] [memory] Reserving 211 MB, device gpu3
[2019-07-25 14:38:11] [memory] Reserving 211 MB, device gpu4
[2019-07-25 14:48:37] Ep. 10 : Up. 122000 : Sen. 3,306,392 : Cost 42.03512955 : Time 744.27s : 20383.06 words/s
[2019-07-25 14:59:55] Ep. 10 : Up. 124000 : Sen. 3,980,272 : Cost 42.02889252 : Time 677.77s : 22461.13 words/s
[2019-07-25 15:05:36] Seen 4199891 samples
[2019-07-25 15:05:36] Starting epoch 11
[2019-07-25 15:05:36] [data] Shuffling data
[2019-07-25 15:05:45] [data] Done reading 4828705 sentences
[2019-07-25 15:07:04] [data] Done shuffling 4828705 sentences to temp files
[2019-07-25 15:19:02] Ep. 11 : Up. 126000 : Sen. 453,872 : Cost 41.47884369 : Time 1146.72s : 13278.81 words/s
[2019-07-25 15:36:37] Ep. 11 : Up. 128000 : Sen. 1,125,750 : Cost 41.39072800 : Time 1055.36s : 14406.14 words/s
[2019-07-25 15:53:18] Ep. 11 : Up. 130000 : Sen. 1,798,400 : Cost 41.60004044 : Time 1000.89s : 15216.14 words/s
[2019-07-25 16:10:44] Ep. 11 : Up. 132000 : Sen. 2,471,652 : Cost 41.48713684 : Time 1045.68s : 14567.41 words/s
[2019-07-25 16:28:23] Ep. 11 : Up. 134000 : Sen. 3,143,360 : Cost 41.72653198 : Time 1059.77s : 14343.20 words/s
[2019-07-25 16:46:28] Ep. 11 : Up. 136000 : Sen. 3,818,933 : Cost 41.59030533 : Time 1084.89s : 14068.85 words/s
[2019-07-25 16:53:04] Seen 4199891 samples
[2019-07-25 16:53:04] Starting epoch 12
[2019-07-25 16:53:04] [data] Shuffling data
[2019-07-25 16:53:07] [data] Done reading 4828705 sentences
[2019-07-25 16:53:32] [data] Done shuffling 4828705 sentences to temp files
[2019-07-25 16:58:34] Ep. 12 : Up. 138000 : Sen. 294,400 : Cost 41.32466507 : Time 725.51s : 21069.29 words/s
[2019-07-25 17:10:04] Ep. 12 : Up. 140000 : Sen. 970,110 : Cost 40.85347748 : Time 690.38s : 22153.04 words/s
[2019-07-25 17:10:04] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-25 17:10:10] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter140000.npz
[2019-07-25 17:10:12] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-25 17:10:18] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-25 17:10:35] [valid] Ep. 12 : Up. 140000 : cross-entropy : 40.2595 : new best
[2019-07-25 17:10:39] [valid] Ep. 12 : Up. 140000 : perplexity : 4.883 : new best
[2019-07-25 17:11:27] [valid] Ep. 12 : Up. 140000 : translation : 30.96 : new best
[2019-07-25 17:22:58] Ep. 12 : Up. 142000 : Sen. 1,643,924 : Cost 40.93310928 : Time 774.18s : 19683.39 words/s
[2019-07-25 17:34:29] Ep. 12 : Up. 144000 : Sen. 2,318,776 : Cost 41.01846313 : Time 690.70s : 22102.89 words/s
[2019-07-25 20:28:17] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-25 20:28:17] [marian] Running on bil as process 2425 with command line:
[2019-07-25 20:28:17] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_bicleaner_dcce/model/model.npz -T . --devices 3 4 --train-sets ../experiments/100M_bicleaner_dcce/data/train.bpe.de ../experiments/100M_bicleaner_dcce/data/train.bpe.en --vocabs ../experiments/100M_bicleaner_dcce/data/train.bpe.de.json ../experiments/100M_bicleaner_dcce/data/train.bpe.en.json --mini-batch-fit -w 5000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_bicleaner_dcce/data/dev.bpe.de ../experiments/100M_bicleaner_dcce/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_bicleaner_dcce/model/dev.out --valid-script-path ../experiments/100M_bicleaner_dcce/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_bicleaner_dcce/model/train.log --valid-log ../experiments/100M_bicleaner_dcce/model/valid.log
[2019-07-25 20:28:17] [config] after-batches: 0
[2019-07-25 20:28:17] [config] after-epochs: 0
[2019-07-25 20:28:17] [config] allow-unk: false
[2019-07-25 20:28:17] [config] beam-size: 12
[2019-07-25 20:28:17] [config] bert-class-symbol: "[CLS]"
[2019-07-25 20:28:17] [config] bert-mask-symbol: "[MASK]"
[2019-07-25 20:28:17] [config] bert-masking-fraction: 0.15
[2019-07-25 20:28:17] [config] bert-sep-symbol: "[SEP]"
[2019-07-25 20:28:17] [config] bert-train-type-embeddings: true
[2019-07-25 20:28:17] [config] bert-type-vocab-size: 2
[2019-07-25 20:28:17] [config] best-deep: false
[2019-07-25 20:28:17] [config] clip-gemm: 0
[2019-07-25 20:28:17] [config] clip-norm: 1
[2019-07-25 20:28:17] [config] cost-type: ce-mean
[2019-07-25 20:28:17] [config] cpu-threads: 0
[2019-07-25 20:28:17] [config] data-weighting: ""
[2019-07-25 20:28:17] [config] data-weighting-type: sentence
[2019-07-25 20:28:17] [config] dec-cell: gru
[2019-07-25 20:28:17] [config] dec-cell-base-depth: 2
[2019-07-25 20:28:17] [config] dec-cell-high-depth: 1
[2019-07-25 20:28:17] [config] dec-depth: 1
[2019-07-25 20:28:17] [config] devices:
[2019-07-25 20:28:17] [config]   - 3
[2019-07-25 20:28:17] [config]   - 4
[2019-07-25 20:28:17] [config] dim-emb: 512
[2019-07-25 20:28:17] [config] dim-rnn: 1024
[2019-07-25 20:28:17] [config] dim-vocabs:
[2019-07-25 20:28:17] [config]   - 50000
[2019-07-25 20:28:17] [config]   - 50000
[2019-07-25 20:28:17] [config] disp-first: 0
[2019-07-25 20:28:17] [config] disp-freq: 2000
[2019-07-25 20:28:17] [config] disp-label-counts: false
[2019-07-25 20:28:17] [config] dropout-rnn: 0.2
[2019-07-25 20:28:17] [config] dropout-src: 0.1
[2019-07-25 20:28:17] [config] dropout-trg: 0.1
[2019-07-25 20:28:17] [config] dump-config: ""
[2019-07-25 20:28:17] [config] early-stopping: 5
[2019-07-25 20:28:17] [config] embedding-fix-src: false
[2019-07-25 20:28:17] [config] embedding-fix-trg: false
[2019-07-25 20:28:17] [config] embedding-normalization: false
[2019-07-25 20:28:17] [config] embedding-vectors:
[2019-07-25 20:28:17] [config]   []
[2019-07-25 20:28:17] [config] enc-cell: gru
[2019-07-25 20:28:17] [config] enc-cell-depth: 1
[2019-07-25 20:28:17] [config] enc-depth: 1
[2019-07-25 20:28:17] [config] enc-type: bidirectional
[2019-07-25 20:28:17] [config] exponential-smoothing: 0.0001
[2019-07-25 20:28:17] [config] grad-dropping-momentum: 0
[2019-07-25 20:28:17] [config] grad-dropping-rate: 0
[2019-07-25 20:28:17] [config] grad-dropping-warmup: 100
[2019-07-25 20:28:17] [config] guided-alignment: none
[2019-07-25 20:28:17] [config] guided-alignment-cost: mse
[2019-07-25 20:28:17] [config] guided-alignment-weight: 0.1
[2019-07-25 20:28:17] [config] ignore-model-config: false
[2019-07-25 20:28:17] [config] input-types:
[2019-07-25 20:28:17] [config]   []
[2019-07-25 20:28:17] [config] interpolate-env-vars: false
[2019-07-25 20:28:17] [config] keep-best: false
[2019-07-25 20:28:17] [config] label-smoothing: 0
[2019-07-25 20:28:17] [config] layer-normalization: true
[2019-07-25 20:28:17] [config] learn-rate: 0.0001
[2019-07-25 20:28:17] [config] log: ../experiments/100M_bicleaner_dcce/model/train.log
[2019-07-25 20:28:17] [config] log-level: info
[2019-07-25 20:28:17] [config] log-time-zone: ""
[2019-07-25 20:28:17] [config] lr-decay: 0
[2019-07-25 20:28:17] [config] lr-decay-freq: 50000
[2019-07-25 20:28:17] [config] lr-decay-inv-sqrt:
[2019-07-25 20:28:17] [config]   - 0
[2019-07-25 20:28:17] [config] lr-decay-repeat-warmup: false
[2019-07-25 20:28:17] [config] lr-decay-reset-optimizer: false
[2019-07-25 20:28:17] [config] lr-decay-start:
[2019-07-25 20:28:17] [config]   - 10
[2019-07-25 20:28:17] [config]   - 1
[2019-07-25 20:28:17] [config] lr-decay-strategy: epoch+stalled
[2019-07-25 20:28:17] [config] lr-report: false
[2019-07-25 20:28:17] [config] lr-warmup: 0
[2019-07-25 20:28:17] [config] lr-warmup-at-reload: false
[2019-07-25 20:28:17] [config] lr-warmup-cycle: false
[2019-07-25 20:28:17] [config] lr-warmup-start-rate: 0
[2019-07-25 20:28:17] [config] max-length: 50
[2019-07-25 20:28:17] [config] max-length-crop: false
[2019-07-25 20:28:17] [config] max-length-factor: 3
[2019-07-25 20:28:17] [config] maxi-batch: 100
[2019-07-25 20:28:17] [config] maxi-batch-sort: trg
[2019-07-25 20:28:17] [config] mini-batch: 64
[2019-07-25 20:28:17] [config] mini-batch-fit: true
[2019-07-25 20:28:17] [config] mini-batch-fit-step: 10
[2019-07-25 20:28:17] [config] mini-batch-overstuff: 1
[2019-07-25 20:28:17] [config] mini-batch-track-lr: false
[2019-07-25 20:28:17] [config] mini-batch-understuff: 1
[2019-07-25 20:28:17] [config] mini-batch-warmup: 0
[2019-07-25 20:28:17] [config] mini-batch-words: 0
[2019-07-25 20:28:17] [config] mini-batch-words-ref: 0
[2019-07-25 20:28:17] [config] model: ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-25 20:28:17] [config] multi-loss-type: sum
[2019-07-25 20:28:17] [config] multi-node: false
[2019-07-25 20:28:17] [config] multi-node-overlap: true
[2019-07-25 20:28:17] [config] n-best: false
[2019-07-25 20:28:17] [config] no-nccl: false
[2019-07-25 20:28:17] [config] no-reload: false
[2019-07-25 20:28:17] [config] no-restore-corpus: false
[2019-07-25 20:28:17] [config] no-shuffle: false
[2019-07-25 20:28:17] [config] normalize: 1
[2019-07-25 20:28:17] [config] num-devices: 0
[2019-07-25 20:28:17] [config] optimizer: adam
[2019-07-25 20:28:17] [config] optimizer-delay: 1
[2019-07-25 20:28:17] [config] optimizer-params:
[2019-07-25 20:28:17] [config]   []
[2019-07-25 20:28:17] [config] overwrite: false
[2019-07-25 20:28:17] [config] pretrained-model: ""
[2019-07-25 20:28:17] [config] quiet: false
[2019-07-25 20:28:17] [config] quiet-translation: true
[2019-07-25 20:28:17] [config] relative-paths: false
[2019-07-25 20:28:17] [config] right-left: false
[2019-07-25 20:28:17] [config] save-freq: 20000
[2019-07-25 20:28:17] [config] seed: 1111
[2019-07-25 20:28:17] [config] shuffle-in-ram: false
[2019-07-25 20:28:17] [config] skip: false
[2019-07-25 20:28:17] [config] sqlite: ""
[2019-07-25 20:28:17] [config] sqlite-drop: false
[2019-07-25 20:28:17] [config] sync-sgd: true
[2019-07-25 20:28:17] [config] tempdir: .
[2019-07-25 20:28:17] [config] tied-embeddings: false
[2019-07-25 20:28:17] [config] tied-embeddings-all: false
[2019-07-25 20:28:17] [config] tied-embeddings-src: false
[2019-07-25 20:28:17] [config] train-sets:
[2019-07-25 20:28:17] [config]   - ../experiments/100M_bicleaner_dcce/data/train.bpe.de
[2019-07-25 20:28:17] [config]   - ../experiments/100M_bicleaner_dcce/data/train.bpe.en
[2019-07-25 20:28:17] [config] transformer-aan-activation: swish
[2019-07-25 20:28:17] [config] transformer-aan-depth: 2
[2019-07-25 20:28:17] [config] transformer-aan-nogate: false
[2019-07-25 20:28:17] [config] transformer-decoder-autoreg: self-attention
[2019-07-25 20:28:17] [config] transformer-dim-aan: 2048
[2019-07-25 20:28:17] [config] transformer-dim-ffn: 2048
[2019-07-25 20:28:17] [config] transformer-dropout: 0
[2019-07-25 20:28:17] [config] transformer-dropout-attention: 0
[2019-07-25 20:28:17] [config] transformer-dropout-ffn: 0
[2019-07-25 20:28:17] [config] transformer-ffn-activation: swish
[2019-07-25 20:28:17] [config] transformer-ffn-depth: 2
[2019-07-25 20:28:17] [config] transformer-guided-alignment-layer: last
[2019-07-25 20:28:17] [config] transformer-heads: 8
[2019-07-25 20:28:17] [config] transformer-no-projection: false
[2019-07-25 20:28:17] [config] transformer-postprocess: dan
[2019-07-25 20:28:17] [config] transformer-postprocess-emb: d
[2019-07-25 20:28:17] [config] transformer-preprocess: ""
[2019-07-25 20:28:17] [config] transformer-tied-layers:
[2019-07-25 20:28:17] [config]   []
[2019-07-25 20:28:17] [config] transformer-train-position-embeddings: false
[2019-07-25 20:28:17] [config] type: amun
[2019-07-25 20:28:17] [config] ulr: false
[2019-07-25 20:28:17] [config] ulr-dim-emb: 0
[2019-07-25 20:28:17] [config] ulr-dropout: 0
[2019-07-25 20:28:17] [config] ulr-keys-vectors: ""
[2019-07-25 20:28:17] [config] ulr-query-vectors: ""
[2019-07-25 20:28:17] [config] ulr-softmax-temperature: 1
[2019-07-25 20:28:17] [config] ulr-trainable-transformation: false
[2019-07-25 20:28:17] [config] valid-freq: 20000
[2019-07-25 20:28:17] [config] valid-log: ../experiments/100M_bicleaner_dcce/model/valid.log
[2019-07-25 20:28:17] [config] valid-max-length: 1000
[2019-07-25 20:28:17] [config] valid-metrics:
[2019-07-25 20:28:17] [config]   - cross-entropy
[2019-07-25 20:28:17] [config]   - perplexity
[2019-07-25 20:28:17] [config]   - translation
[2019-07-25 20:28:17] [config] valid-mini-batch: 8
[2019-07-25 20:28:17] [config] valid-script-path: ../experiments/100M_bicleaner_dcce/score-dev.sh
[2019-07-25 20:28:17] [config] valid-sets:
[2019-07-25 20:28:17] [config]   - ../experiments/100M_bicleaner_dcce/data/dev.bpe.de
[2019-07-25 20:28:17] [config]   - ../experiments/100M_bicleaner_dcce/data/dev.bpe.en
[2019-07-25 20:28:17] [config] valid-translation-output: ../experiments/100M_bicleaner_dcce/model/dev.out
[2019-07-25 20:28:17] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-25 20:28:17] [config] vocabs:
[2019-07-25 20:28:17] [config]   - ../experiments/100M_bicleaner_dcce/data/train.bpe.de.json
[2019-07-25 20:28:17] [config]   - ../experiments/100M_bicleaner_dcce/data/train.bpe.en.json
[2019-07-25 20:28:17] [config] word-penalty: 0
[2019-07-25 20:28:17] [config] workspace: 5000
[2019-07-25 20:28:17] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-25 20:28:17] Using synchronous training
[2019-07-25 20:28:17] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_bicleaner_dcce/data/train.bpe.de.json
[2019-07-25 20:28:18] [data] Using unused word id eos for 0
[2019-07-25 20:28:18] [data] Using unused word id UNK for 1
[2019-07-25 20:28:18] [data] Setting vocabulary size for input 0 to 50000
[2019-07-25 20:28:18] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_bicleaner_dcce/data/train.bpe.en.json
[2019-07-25 20:28:18] [data] Using unused word id eos for 0
[2019-07-25 20:28:18] [data] Using unused word id UNK for 1
[2019-07-25 20:28:18] [data] Setting vocabulary size for input 1 to 50000
[2019-07-25 20:28:18] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-25 20:28:18] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-25 20:28:20] [memory] Extending reserved space to 5120 MB (device gpu3)
[2019-07-25 20:28:21] [memory] Extending reserved space to 5120 MB (device gpu4)
[2019-07-25 20:28:21] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-25 20:28:22] [comm] NCCLCommunicator constructed successfully.
[2019-07-25 20:28:22] [training] Using 2 GPUs
[2019-07-25 20:28:22] [memory] Reserving 422 MB, device gpu3
[2019-07-25 20:28:22] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-25 20:28:22] [memory] Reserving 422 MB, device gpu3
[2019-07-25 20:28:26] [batching] Done. Typical MB size is 13760 target words
[2019-07-25 20:28:26] [memory] Extending reserved space to 5120 MB (device gpu3)
[2019-07-25 20:28:26] [memory] Extending reserved space to 5120 MB (device gpu4)
[2019-07-25 20:28:26] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-25 20:28:26] [comm] NCCLCommunicator constructed successfully.
[2019-07-25 20:28:26] [training] Using 2 GPUs
[2019-07-25 20:28:26] Loading model from ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-25 20:28:29] Loading model from ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-25 20:28:32] Loading Adam parameters from ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-25 20:28:35] [memory] Reserving 422 MB, device gpu3
[2019-07-25 20:28:35] [memory] Reserving 422 MB, device gpu4
[2019-07-25 20:28:36] [training] Model reloaded from ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-25 20:28:36] [data] Restoring the corpus state to epoch 12, batch 140000
[2019-07-25 20:28:36] [data] Shuffling data
[2019-07-25 20:28:39] [data] Done reading 4828705 sentences
[2019-07-25 20:28:58] [data] Done shuffling 4828705 sentences to temp files
[2019-07-25 20:29:26] Training started
[2019-07-25 20:29:26] [training] Batches are processed as 1 process(es) x 2 devices/process
[2019-07-25 20:29:26] [memory] Reserving 422 MB, device gpu4
[2019-07-25 20:29:26] [memory] Reserving 422 MB, device gpu3
[2019-07-25 20:29:26] [memory] Reserving 422 MB, device gpu4
[2019-07-25 20:29:26] [memory] Reserving 422 MB, device gpu3
[2019-07-25 20:29:26] Loading model from ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-25 20:29:29] [memory] Reserving 422 MB, device cpu0
[2019-07-25 20:29:29] [memory] Reserving 211 MB, device gpu3
[2019-07-25 20:29:30] [memory] Reserving 211 MB, device gpu4
[2019-07-25 20:39:33] Ep. 12 : Up. 142000 : Sen. 1,643,924 : Cost 40.84982300 : Time 674.95s : 22577.24 words/s
[2019-07-25 20:49:39] Ep. 12 : Up. 144000 : Sen. 2,318,776 : Cost 41.09255600 : Time 605.93s : 25195.02 words/s
[2019-07-25 20:59:44] Ep. 12 : Up. 146000 : Sen. 2,991,012 : Cost 41.13049698 : Time 604.86s : 25124.91 words/s
[2019-07-25 21:09:53] Ep. 12 : Up. 148000 : Sen. 3,665,252 : Cost 41.10898209 : Time 609.44s : 25012.47 words/s
[2019-07-25 21:18:12] Seen 4199891 samples
[2019-07-25 21:18:12] Starting epoch 13
[2019-07-25 21:18:12] [data] Shuffling data
[2019-07-25 21:18:15] [data] Done reading 4828705 sentences
[2019-07-25 21:18:36] [data] Done shuffling 4828705 sentences to temp files
[2019-07-25 21:20:45] Ep. 13 : Up. 150000 : Sen. 135,904 : Cost 41.07016373 : Time 652.17s : 23274.64 words/s
[2019-07-25 21:31:26] Ep. 13 : Up. 152000 : Sen. 808,528 : Cost 40.41902161 : Time 640.76s : 23756.68 words/s
[2019-07-25 21:42:08] Ep. 13 : Up. 154000 : Sen. 1,481,516 : Cost 40.63484573 : Time 641.36s : 23734.72 words/s
[2019-07-25 21:52:49] Ep. 13 : Up. 156000 : Sen. 2,155,576 : Cost 40.63439941 : Time 641.54s : 23752.85 words/s
[2019-07-25 22:03:32] Ep. 13 : Up. 158000 : Sen. 2,829,427 : Cost 40.74842453 : Time 642.82s : 23709.67 words/s
[2019-07-25 22:14:15] Ep. 13 : Up. 160000 : Sen. 3,504,460 : Cost 40.64587784 : Time 642.96s : 23722.19 words/s
[2019-07-25 22:14:15] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-25 22:14:21] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter160000.npz
[2019-07-25 22:14:23] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-25 22:14:28] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-25 22:14:44] [valid] Ep. 13 : Up. 160000 : cross-entropy : 39.9165 : new best
[2019-07-25 22:14:48] [valid] Ep. 13 : Up. 160000 : perplexity : 4.81748 : new best
[2019-07-25 22:15:34] [valid] Ep. 13 : Up. 160000 : translation : 31.06 : new best
[2019-07-25 22:26:21] Ep. 13 : Up. 162000 : Sen. 4,180,008 : Cost 40.87453079 : Time 725.73s : 21071.11 words/s
[2019-07-25 22:26:40] Seen 4199891 samples
[2019-07-25 22:26:40] Starting epoch 14
[2019-07-25 22:26:40] [data] Shuffling data
[2019-07-25 22:26:43] [data] Done reading 4828705 sentences
[2019-07-25 22:27:04] [data] Done shuffling 4828705 sentences to temp files
[2019-07-25 22:37:29] Ep. 14 : Up. 164000 : Sen. 654,222 : Cost 39.99499512 : Time 668.68s : 22771.08 words/s
[2019-07-25 22:48:12] Ep. 14 : Up. 166000 : Sen. 1,327,732 : Cost 40.34415054 : Time 642.27s : 23734.32 words/s
[2019-07-25 22:58:56] Ep. 14 : Up. 168000 : Sen. 2,003,728 : Cost 40.23469543 : Time 644.18s : 23734.77 words/s
[2019-07-25 23:09:38] Ep. 14 : Up. 170000 : Sen. 2,675,464 : Cost 40.43340683 : Time 642.43s : 23647.55 words/s
[2019-07-25 23:20:21] Ep. 14 : Up. 172000 : Sen. 3,347,812 : Cost 40.45206451 : Time 643.11s : 23669.27 words/s
[2019-07-25 23:31:03] Ep. 14 : Up. 174000 : Sen. 4,019,754 : Cost 40.44890213 : Time 642.18s : 23667.35 words/s
[2019-07-25 23:33:56] Seen 4199891 samples
[2019-07-25 23:33:56] Starting epoch 15
[2019-07-25 23:33:56] [data] Shuffling data
[2019-07-25 23:33:59] [data] Done reading 4828705 sentences
[2019-07-25 23:34:21] [data] Done shuffling 4828705 sentences to temp files
[2019-07-25 23:42:13] Ep. 15 : Up. 176000 : Sen. 494,110 : Cost 39.91283417 : Time 669.16s : 22782.93 words/s
[2019-07-25 23:52:55] Ep. 15 : Up. 178000 : Sen. 1,164,800 : Cost 39.88047409 : Time 642.52s : 23644.98 words/s
[2019-07-26 00:03:38] Ep. 15 : Up. 180000 : Sen. 1,837,328 : Cost 39.78033447 : Time 642.56s : 23681.58 words/s
[2019-07-26 00:03:38] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-26 00:03:44] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter180000.npz
[2019-07-26 00:03:46] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-26 00:03:52] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-26 00:04:08] [valid] Ep. 15 : Up. 180000 : cross-entropy : 39.6792 : new best
[2019-07-26 00:04:11] [valid] Ep. 15 : Up. 180000 : perplexity : 4.77266 : new best
[2019-07-26 00:04:57] [valid] Ep. 15 : Up. 180000 : translation : 31.17 : new best
[2019-07-26 00:15:45] Ep. 15 : Up. 182000 : Sen. 2,512,086 : Cost 40.17100906 : Time 727.28s : 20993.25 words/s
[2019-07-26 00:26:29] Ep. 15 : Up. 184000 : Sen. 3,186,144 : Cost 40.06578827 : Time 644.13s : 23636.98 words/s
[2019-07-26 00:37:14] Ep. 15 : Up. 186000 : Sen. 3,860,256 : Cost 40.20400620 : Time 645.27s : 23676.41 words/s
[2019-07-26 00:42:39] Seen 4199891 samples
[2019-07-26 00:42:39] Starting epoch 16
[2019-07-26 00:42:39] [data] Shuffling data
[2019-07-26 00:42:42] [data] Done reading 4828705 sentences
[2019-07-26 00:43:03] [data] Done shuffling 4828705 sentences to temp files
[2019-07-26 00:48:23] Ep. 16 : Up. 188000 : Sen. 334,204 : Cost 39.79546356 : Time 669.08s : 22786.76 words/s
[2019-07-26 00:58:58] Ep. 16 : Up. 190000 : Sen. 1,005,788 : Cost 39.45272064 : Time 634.97s : 23913.33 words/s
[2019-07-26 01:09:41] Ep. 16 : Up. 192000 : Sen. 1,680,724 : Cost 39.56786346 : Time 642.81s : 23728.53 words/s
[2019-07-26 01:20:25] Ep. 16 : Up. 194000 : Sen. 2,354,324 : Cost 39.62639999 : Time 644.12s : 23644.12 words/s
[2019-07-26 01:31:09] Ep. 16 : Up. 196000 : Sen. 3,027,200 : Cost 39.92145538 : Time 643.38s : 23669.24 words/s
[2019-07-26 01:41:53] Ep. 16 : Up. 198000 : Sen. 3,701,412 : Cost 39.83912659 : Time 644.76s : 23655.57 words/s
[2019-07-26 01:49:50] Seen 4199891 samples
[2019-07-26 01:49:50] Starting epoch 17
[2019-07-26 01:49:50] [data] Shuffling data
[2019-07-26 01:49:52] [data] Done reading 4828705 sentences
[2019-07-26 01:50:14] [data] Done shuffling 4828705 sentences to temp files
[2019-07-26 01:53:03] Ep. 17 : Up. 200000 : Sen. 175,411 : Cost 39.69889832 : Time 669.78s : 22774.08 words/s
[2019-07-26 01:53:03] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-26 01:53:09] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter200000.npz
[2019-07-26 01:53:11] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-26 01:53:17] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-26 01:53:33] [valid] Ep. 17 : Up. 200000 : cross-entropy : 39.4204 : new best
[2019-07-26 01:53:36] [valid] Ep. 17 : Up. 200000 : perplexity : 4.72425 : new best
[2019-07-26 01:54:23] [valid] Ep. 17 : Up. 200000 : translation : 31.52 : new best
[2019-07-26 02:05:12] Ep. 17 : Up. 202000 : Sen. 851,464 : Cost 39.05172729 : Time 728.81s : 20969.07 words/s
[2019-07-26 02:15:56] Ep. 17 : Up. 204000 : Sen. 1,525,788 : Cost 39.31154633 : Time 643.94s : 23653.42 words/s
[2019-07-26 02:26:40] Ep. 17 : Up. 206000 : Sen. 2,198,578 : Cost 39.42341232 : Time 644.44s : 23635.61 words/s
[2019-07-26 02:37:21] Ep. 17 : Up. 208000 : Sen. 2,869,786 : Cost 39.51377487 : Time 640.58s : 23684.91 words/s
[2019-07-26 02:48:07] Ep. 17 : Up. 210000 : Sen. 3,542,900 : Cost 39.66894531 : Time 645.60s : 23623.52 words/s
[2019-07-26 02:58:35] Seen 4199891 samples
[2019-07-26 02:58:35] Starting epoch 18
[2019-07-26 02:58:35] [data] Shuffling data
[2019-07-26 02:58:38] [data] Done reading 4828705 sentences
[2019-07-26 02:58:59] [data] Done shuffling 4828705 sentences to temp files
[2019-07-26 02:59:15] Ep. 18 : Up. 212000 : Sen. 15,705 : Cost 39.64912796 : Time 668.81s : 22749.97 words/s
[2019-07-26 03:10:02] Ep. 18 : Up. 214000 : Sen. 689,892 : Cost 38.90676117 : Time 646.07s : 23605.45 words/s
[2019-07-26 03:20:47] Ep. 18 : Up. 216000 : Sen. 1,364,160 : Cost 39.03544998 : Time 645.53s : 23634.26 words/s
[2019-07-26 03:31:30] Ep. 18 : Up. 218000 : Sen. 2,036,356 : Cost 39.02810669 : Time 643.27s : 23624.42 words/s
[2019-07-26 03:42:16] Ep. 18 : Up. 220000 : Sen. 2,710,136 : Cost 39.19658661 : Time 645.24s : 23617.88 words/s
[2019-07-26 03:42:16] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-26 03:42:21] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter220000.npz
[2019-07-26 03:42:24] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-26 03:42:30] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-26 03:42:47] [valid] Ep. 18 : Up. 220000 : cross-entropy : 39.2795 : new best
[2019-07-26 03:42:50] [valid] Ep. 18 : Up. 220000 : perplexity : 4.6981 : new best
[2019-07-26 03:43:37] [valid] Ep. 18 : Up. 220000 : translation : 31.48 : stalled 1 times (last best: 31.52)
[2019-07-26 03:54:22] Ep. 18 : Up. 222000 : Sen. 3,383,362 : Cost 39.53246307 : Time 726.11s : 20974.55 words/s
[2019-07-26 04:05:04] Ep. 18 : Up. 224000 : Sen. 4,054,708 : Cost 39.43087769 : Time 642.11s : 23653.56 words/s
[2019-07-26 04:07:23] Seen 4199891 samples
[2019-07-26 04:07:23] Starting epoch 19
[2019-07-26 04:07:23] [data] Shuffling data
[2019-07-26 04:07:26] [data] Done reading 4828705 sentences
[2019-07-26 04:07:48] [data] Done shuffling 4828705 sentences to temp files
[2019-07-26 04:16:13] Ep. 19 : Up. 226000 : Sen. 527,767 : Cost 38.72070312 : Time 668.85s : 22768.08 words/s
[2019-07-26 04:26:58] Ep. 19 : Up. 228000 : Sen. 1,204,188 : Cost 38.79219055 : Time 644.90s : 23744.94 words/s
[2019-07-26 04:37:31] Ep. 19 : Up. 230000 : Sen. 1,875,992 : Cost 38.98755264 : Time 633.09s : 24026.39 words/s
[2019-07-26 04:48:14] Ep. 19 : Up. 232000 : Sen. 2,552,962 : Cost 38.92435455 : Time 643.48s : 23771.41 words/s
[2019-07-26 04:58:56] Ep. 19 : Up. 234000 : Sen. 3,227,200 : Cost 39.16498566 : Time 641.84s : 23751.99 words/s
[2019-07-26 05:09:37] Ep. 19 : Up. 236000 : Sen. 3,899,268 : Cost 39.20082092 : Time 640.87s : 23752.07 words/s
[2019-07-26 05:14:22] Seen 4199891 samples
[2019-07-26 05:14:22] Starting epoch 20
[2019-07-26 05:14:22] [data] Shuffling data
[2019-07-26 05:14:25] [data] Done reading 4828705 sentences
[2019-07-26 05:14:48] [data] Done shuffling 4828705 sentences to temp files
[2019-07-26 05:20:45] Ep. 20 : Up. 238000 : Sen. 374,722 : Cost 38.58996964 : Time 668.44s : 22811.61 words/s
[2019-07-26 05:31:29] Ep. 20 : Up. 240000 : Sen. 1,050,476 : Cost 38.51640320 : Time 643.49s : 23745.27 words/s
[2019-07-26 05:31:29] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-26 05:31:34] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter240000.npz
[2019-07-26 05:31:37] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-26 05:31:42] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-26 05:31:59] [valid] Ep. 20 : Up. 240000 : cross-entropy : 39.1689 : new best
[2019-07-26 05:32:02] [valid] Ep. 20 : Up. 240000 : perplexity : 4.67769 : new best
[2019-07-26 05:32:48] [valid] Ep. 20 : Up. 240000 : translation : 31.58 : new best
[2019-07-26 05:43:32] Ep. 20 : Up. 242000 : Sen. 1,723,284 : Cost 38.71142197 : Time 722.93s : 21059.17 words/s
[2019-07-26 05:54:13] Ep. 20 : Up. 244000 : Sen. 2,395,200 : Cost 38.82547379 : Time 640.94s : 23742.67 words/s
[2019-07-26 06:04:54] Ep. 20 : Up. 246000 : Sen. 3,068,952 : Cost 38.85791397 : Time 640.94s : 23751.59 words/s
[2019-07-26 06:15:35] Ep. 20 : Up. 248000 : Sen. 3,742,401 : Cost 38.82493210 : Time 641.48s : 23739.06 words/s
[2019-07-26 06:22:51] Seen 4199891 samples
[2019-07-26 06:22:51] Starting epoch 21
[2019-07-26 06:22:51] [data] Shuffling data
[2019-07-26 06:22:54] [data] Done reading 4828705 sentences
[2019-07-26 06:23:17] [data] Done shuffling 4828705 sentences to temp files
[2019-07-26 06:26:44] Ep. 21 : Up. 250000 : Sen. 216,876 : Cost 38.75813293 : Time 668.51s : 22830.33 words/s
[2019-07-26 06:37:26] Ep. 21 : Up. 252000 : Sen. 889,600 : Cost 38.17816925 : Time 642.06s : 23704.01 words/s
[2019-07-26 06:48:07] Ep. 21 : Up. 254000 : Sen. 1,561,072 : Cost 38.52604294 : Time 641.08s : 23679.04 words/s
[2019-07-26 06:58:49] Ep. 21 : Up. 256000 : Sen. 2,235,004 : Cost 38.51386261 : Time 642.30s : 23768.90 words/s
[2019-07-26 07:09:31] Ep. 21 : Up. 258000 : Sen. 2,907,898 : Cost 38.49711990 : Time 641.81s : 23705.11 words/s
[2019-07-26 07:20:12] Ep. 21 : Up. 260000 : Sen. 3,577,864 : Cost 38.69243622 : Time 641.19s : 23650.02 words/s
[2019-07-26 07:20:12] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-26 07:20:18] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter260000.npz
[2019-07-26 07:20:20] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-26 07:20:26] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-26 07:20:43] [valid] Ep. 21 : Up. 260000 : cross-entropy : 39.0243 : new best
[2019-07-26 07:20:46] [valid] Ep. 21 : Up. 260000 : perplexity : 4.65111 : new best
[2019-07-26 07:21:32] [valid] Ep. 21 : Up. 260000 : translation : 31.46 : stalled 1 times (last best: 31.58)
[2019-07-26 07:31:26] Seen 4199891 samples
[2019-07-26 07:31:26] Starting epoch 22
[2019-07-26 07:31:26] [data] Shuffling data
[2019-07-26 07:31:29] [data] Done reading 4828705 sentences
[2019-07-26 07:31:51] [data] Done shuffling 4828705 sentences to temp files
[2019-07-26 07:32:44] Ep. 22 : Up. 262000 : Sen. 55,182 : Cost 38.63737869 : Time 752.29s : 20330.60 words/s
[2019-07-26 07:43:23] Ep. 22 : Up. 264000 : Sen. 726,871 : Cost 38.19805527 : Time 638.65s : 23806.78 words/s
[2019-07-26 07:54:04] Ep. 22 : Up. 266000 : Sen. 1,398,204 : Cost 38.20378113 : Time 640.83s : 23701.49 words/s
[2019-07-26 08:04:45] Ep. 22 : Up. 268000 : Sen. 2,072,962 : Cost 38.30643845 : Time 641.31s : 23768.30 words/s
[2019-07-26 08:15:28] Ep. 22 : Up. 270000 : Sen. 2,748,604 : Cost 38.55014801 : Time 642.60s : 23805.98 words/s
[2019-07-26 08:26:01] Ep. 22 : Up. 272000 : Sen. 3,423,388 : Cost 38.51565933 : Time 633.31s : 24114.04 words/s
[2019-07-26 08:36:43] Ep. 22 : Up. 274000 : Sen. 4,098,824 : Cost 38.51889420 : Time 641.93s : 23779.94 words/s
[2019-07-26 08:38:20] Seen 4199891 samples
[2019-07-26 08:38:20] Starting epoch 23
[2019-07-26 08:38:20] [data] Shuffling data
[2019-07-26 08:38:23] [data] Done reading 4828705 sentences
[2019-07-26 08:38:46] [data] Done shuffling 4828705 sentences to temp files
[2019-07-26 08:47:51] Ep. 23 : Up. 276000 : Sen. 573,508 : Cost 37.95211411 : Time 668.37s : 22846.89 words/s
[2019-07-26 08:58:33] Ep. 23 : Up. 278000 : Sen. 1,246,578 : Cost 38.00977325 : Time 641.56s : 23744.02 words/s
[2019-07-26 09:09:15] Ep. 23 : Up. 280000 : Sen. 1,923,448 : Cost 38.17259598 : Time 641.80s : 23836.83 words/s
[2019-07-26 09:09:15] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-26 09:09:20] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter280000.npz
[2019-07-26 09:09:22] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-26 09:09:28] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-26 09:09:45] [valid] Ep. 23 : Up. 280000 : cross-entropy : 38.9461 : new best
[2019-07-26 09:09:48] [valid] Ep. 23 : Up. 280000 : perplexity : 4.63682 : new best
[2019-07-26 09:10:34] [valid] Ep. 23 : Up. 280000 : translation : 31.47 : stalled 2 times (last best: 31.58)
[2019-07-26 09:21:18] Ep. 23 : Up. 282000 : Sen. 2,599,012 : Cost 38.24998474 : Time 722.91s : 21124.22 words/s
[2019-07-26 09:31:59] Ep. 23 : Up. 284000 : Sen. 3,273,602 : Cost 38.41706085 : Time 641.42s : 23798.76 words/s
[2019-07-26 09:42:40] Ep. 23 : Up. 286000 : Sen. 3,946,534 : Cost 38.34854507 : Time 640.72s : 23754.72 words/s
[2019-07-26 09:46:42] Seen 4199891 samples
[2019-07-26 09:46:42] Starting epoch 24
[2019-07-26 09:46:42] [data] Shuffling data
[2019-07-26 09:46:45] [data] Done reading 4828705 sentences
[2019-07-26 09:47:07] [data] Done shuffling 4828705 sentences to temp files
[2019-07-26 09:53:49] Ep. 24 : Up. 288000 : Sen. 421,148 : Cost 38.05561066 : Time 669.01s : 22800.14 words/s
[2019-07-26 10:04:31] Ep. 24 : Up. 290000 : Sen. 1,094,928 : Cost 37.76806259 : Time 642.55s : 23736.58 words/s
[2019-07-26 10:15:12] Ep. 24 : Up. 292000 : Sen. 1,769,655 : Cost 37.87633514 : Time 641.15s : 23788.46 words/s
[2019-07-26 10:25:55] Ep. 24 : Up. 294000 : Sen. 2,441,336 : Cost 38.11006546 : Time 642.28s : 23678.00 words/s
[2019-07-26 10:36:56] Ep. 24 : Up. 296000 : Sen. 3,115,376 : Cost 38.06298065 : Time 661.68s : 23014.72 words/s
[2019-07-26 10:48:24] Ep. 24 : Up. 298000 : Sen. 3,788,800 : Cost 38.21126175 : Time 687.89s : 22159.95 words/s
[2019-07-26 10:55:21] Seen 4199891 samples
[2019-07-26 10:55:21] Starting epoch 25
[2019-07-26 10:55:21] [data] Shuffling data
[2019-07-26 10:55:25] [data] Done reading 4828705 sentences
[2019-07-26 10:55:50] [data] Done shuffling 4828705 sentences to temp files
[2019-07-26 11:01:02] Ep. 25 : Up. 300000 : Sen. 262,400 : Cost 38.05136108 : Time 758.04s : 20117.04 words/s
[2019-07-26 11:01:02] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-26 11:01:13] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter300000.npz
[2019-07-26 11:01:17] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-26 11:01:28] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-26 11:02:02] [valid] Ep. 25 : Up. 300000 : cross-entropy : 38.9087 : new best
[2019-07-26 11:02:08] [valid] Ep. 25 : Up. 300000 : perplexity : 4.63 : new best
[2019-07-26 11:03:17] [valid] Ep. 25 : Up. 300000 : translation : 31.58 : stalled 3 times (last best: 31.58)
[2019-07-26 11:19:28] Ep. 25 : Up. 302000 : Sen. 934,400 : Cost 37.66544342 : Time 1105.52s : 13755.26 words/s
[2019-07-26 11:35:32] Ep. 25 : Up. 304000 : Sen. 1,608,722 : Cost 37.74628448 : Time 964.39s : 15809.72 words/s
[2019-07-26 11:51:34] Ep. 25 : Up. 306000 : Sen. 2,282,520 : Cost 37.93922043 : Time 961.53s : 15850.86 words/s
[2019-07-26 12:07:41] Ep. 25 : Up. 308000 : Sen. 2,957,064 : Cost 37.86724472 : Time 967.24s : 15757.58 words/s
[2019-07-26 12:23:28] Ep. 25 : Up. 310000 : Sen. 3,628,340 : Cost 38.06201172 : Time 947.37s : 16045.74 words/s
[2019-07-26 12:37:11] Seen 4199891 samples
[2019-07-26 12:37:11] Starting epoch 26
[2019-07-26 12:37:11] [data] Shuffling data
[2019-07-26 12:37:19] [data] Done reading 4828705 sentences
[2019-07-26 12:38:27] [data] Done shuffling 4828705 sentences to temp files
[2019-07-26 12:41:00] Ep. 26 : Up. 312000 : Sen. 103,472 : Cost 37.95733643 : Time 1051.21s : 14510.38 words/s
[2019-07-26 12:57:06] Ep. 26 : Up. 314000 : Sen. 774,748 : Cost 37.48701096 : Time 966.07s : 15723.18 words/s
[2019-07-26 13:13:16] Ep. 26 : Up. 316000 : Sen. 1,446,664 : Cost 37.54463577 : Time 970.17s : 15669.80 words/s
[2019-07-26 13:28:55] Ep. 26 : Up. 318000 : Sen. 2,120,000 : Cost 37.68514252 : Time 938.93s : 16222.41 words/s
[2019-07-26 13:44:34] Ep. 26 : Up. 320000 : Sen. 2,795,464 : Cost 37.83017731 : Time 939.40s : 16261.51 words/s
[2019-07-26 13:44:34] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-26 13:44:45] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter320000.npz
[2019-07-26 13:44:49] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-26 13:45:00] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-26 13:45:33] [valid] Ep. 26 : Up. 320000 : cross-entropy : 38.8942 : new best
[2019-07-26 13:45:39] [valid] Ep. 26 : Up. 320000 : perplexity : 4.62735 : new best
[2019-07-26 13:46:48] [valid] Ep. 26 : Up. 320000 : translation : 31.56 : stalled 4 times (last best: 31.58)
[2019-07-26 14:01:37] Ep. 26 : Up. 322000 : Sen. 3,467,228 : Cost 37.97206497 : Time 1022.67s : 14876.64 words/s
[2019-07-26 14:33:17] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-26 14:33:17] [marian] Running on bil as process 2200 with command line:
[2019-07-26 14:33:17] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_bicleaner_dcce/model/model.npz -T . --devices 3 4 --train-sets ../experiments/100M_bicleaner_dcce/data/train.bpe.de ../experiments/100M_bicleaner_dcce/data/train.bpe.en --vocabs ../experiments/100M_bicleaner_dcce/data/train.bpe.de.json ../experiments/100M_bicleaner_dcce/data/train.bpe.en.json --mini-batch-fit -w 5000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_bicleaner_dcce/data/dev.bpe.de ../experiments/100M_bicleaner_dcce/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_bicleaner_dcce/model/dev.out --valid-script-path ../experiments/100M_bicleaner_dcce/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_bicleaner_dcce/model/train.log --valid-log ../experiments/100M_bicleaner_dcce/model/valid.log
[2019-07-26 14:33:18] [config] after-batches: 0
[2019-07-26 14:33:18] [config] after-epochs: 0
[2019-07-26 14:33:18] [config] allow-unk: false
[2019-07-26 14:33:18] [config] beam-size: 12
[2019-07-26 14:33:18] [config] bert-class-symbol: "[CLS]"
[2019-07-26 14:33:18] [config] bert-mask-symbol: "[MASK]"
[2019-07-26 14:33:18] [config] bert-masking-fraction: 0.15
[2019-07-26 14:33:18] [config] bert-sep-symbol: "[SEP]"
[2019-07-26 14:33:18] [config] bert-train-type-embeddings: true
[2019-07-26 14:33:18] [config] bert-type-vocab-size: 2
[2019-07-26 14:33:18] [config] best-deep: false
[2019-07-26 14:33:18] [config] clip-gemm: 0
[2019-07-26 14:33:18] [config] clip-norm: 1
[2019-07-26 14:33:18] [config] cost-type: ce-mean
[2019-07-26 14:33:18] [config] cpu-threads: 0
[2019-07-26 14:33:18] [config] data-weighting: ""
[2019-07-26 14:33:18] [config] data-weighting-type: sentence
[2019-07-26 14:33:18] [config] dec-cell: gru
[2019-07-26 14:33:18] [config] dec-cell-base-depth: 2
[2019-07-26 14:33:18] [config] dec-cell-high-depth: 1
[2019-07-26 14:33:18] [config] dec-depth: 1
[2019-07-26 14:33:18] [config] devices:
[2019-07-26 14:33:18] [config]   - 3
[2019-07-26 14:33:18] [config]   - 4
[2019-07-26 14:33:18] [config] dim-emb: 512
[2019-07-26 14:33:18] [config] dim-rnn: 1024
[2019-07-26 14:33:18] [config] dim-vocabs:
[2019-07-26 14:33:18] [config]   - 50000
[2019-07-26 14:33:18] [config]   - 50000
[2019-07-26 14:33:18] [config] disp-first: 0
[2019-07-26 14:33:18] [config] disp-freq: 2000
[2019-07-26 14:33:18] [config] disp-label-counts: false
[2019-07-26 14:33:18] [config] dropout-rnn: 0.2
[2019-07-26 14:33:18] [config] dropout-src: 0.1
[2019-07-26 14:33:18] [config] dropout-trg: 0.1
[2019-07-26 14:33:18] [config] dump-config: ""
[2019-07-26 14:33:18] [config] early-stopping: 5
[2019-07-26 14:33:18] [config] embedding-fix-src: false
[2019-07-26 14:33:18] [config] embedding-fix-trg: false
[2019-07-26 14:33:18] [config] embedding-normalization: false
[2019-07-26 14:33:18] [config] embedding-vectors:
[2019-07-26 14:33:18] [config]   []
[2019-07-26 14:33:18] [config] enc-cell: gru
[2019-07-26 14:33:18] [config] enc-cell-depth: 1
[2019-07-26 14:33:18] [config] enc-depth: 1
[2019-07-26 14:33:18] [config] enc-type: bidirectional
[2019-07-26 14:33:18] [config] exponential-smoothing: 0.0001
[2019-07-26 14:33:18] [config] grad-dropping-momentum: 0
[2019-07-26 14:33:18] [config] grad-dropping-rate: 0
[2019-07-26 14:33:18] [config] grad-dropping-warmup: 100
[2019-07-26 14:33:18] [config] guided-alignment: none
[2019-07-26 14:33:18] [config] guided-alignment-cost: mse
[2019-07-26 14:33:18] [config] guided-alignment-weight: 0.1
[2019-07-26 14:33:18] [config] ignore-model-config: false
[2019-07-26 14:33:18] [config] input-types:
[2019-07-26 14:33:18] [config]   []
[2019-07-26 14:33:18] [config] interpolate-env-vars: false
[2019-07-26 14:33:18] [config] keep-best: false
[2019-07-26 14:33:18] [config] label-smoothing: 0
[2019-07-26 14:33:18] [config] layer-normalization: true
[2019-07-26 14:33:18] [config] learn-rate: 0.0001
[2019-07-26 14:33:18] [config] log: ../experiments/100M_bicleaner_dcce/model/train.log
[2019-07-26 14:33:18] [config] log-level: info
[2019-07-26 14:33:18] [config] log-time-zone: ""
[2019-07-26 14:33:18] [config] lr-decay: 0
[2019-07-26 14:33:18] [config] lr-decay-freq: 50000
[2019-07-26 14:33:18] [config] lr-decay-inv-sqrt:
[2019-07-26 14:33:18] [config]   - 0
[2019-07-26 14:33:18] [config] lr-decay-repeat-warmup: false
[2019-07-26 14:33:18] [config] lr-decay-reset-optimizer: false
[2019-07-26 14:33:18] [config] lr-decay-start:
[2019-07-26 14:33:18] [config]   - 10
[2019-07-26 14:33:18] [config]   - 1
[2019-07-26 14:33:18] [config] lr-decay-strategy: epoch+stalled
[2019-07-26 14:33:18] [config] lr-report: false
[2019-07-26 14:33:18] [config] lr-warmup: 0
[2019-07-26 14:33:18] [config] lr-warmup-at-reload: false
[2019-07-26 14:33:18] [config] lr-warmup-cycle: false
[2019-07-26 14:33:18] [config] lr-warmup-start-rate: 0
[2019-07-26 14:33:18] [config] max-length: 50
[2019-07-26 14:33:18] [config] max-length-crop: false
[2019-07-26 14:33:18] [config] max-length-factor: 3
[2019-07-26 14:33:18] [config] maxi-batch: 100
[2019-07-26 14:33:18] [config] maxi-batch-sort: trg
[2019-07-26 14:33:18] [config] mini-batch: 64
[2019-07-26 14:33:18] [config] mini-batch-fit: true
[2019-07-26 14:33:18] [config] mini-batch-fit-step: 10
[2019-07-26 14:33:18] [config] mini-batch-overstuff: 1
[2019-07-26 14:33:18] [config] mini-batch-track-lr: false
[2019-07-26 14:33:18] [config] mini-batch-understuff: 1
[2019-07-26 14:33:18] [config] mini-batch-warmup: 0
[2019-07-26 14:33:18] [config] mini-batch-words: 0
[2019-07-26 14:33:18] [config] mini-batch-words-ref: 0
[2019-07-26 14:33:18] [config] model: ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-26 14:33:18] [config] multi-loss-type: sum
[2019-07-26 14:33:18] [config] multi-node: false
[2019-07-26 14:33:18] [config] multi-node-overlap: true
[2019-07-26 14:33:18] [config] n-best: false
[2019-07-26 14:33:18] [config] no-nccl: false
[2019-07-26 14:33:18] [config] no-reload: false
[2019-07-26 14:33:18] [config] no-restore-corpus: false
[2019-07-26 14:33:18] [config] no-shuffle: false
[2019-07-26 14:33:18] [config] normalize: 1
[2019-07-26 14:33:18] [config] num-devices: 0
[2019-07-26 14:33:18] [config] optimizer: adam
[2019-07-26 14:33:18] [config] optimizer-delay: 1
[2019-07-26 14:33:18] [config] optimizer-params:
[2019-07-26 14:33:18] [config]   []
[2019-07-26 14:33:18] [config] overwrite: false
[2019-07-26 14:33:18] [config] pretrained-model: ""
[2019-07-26 14:33:18] [config] quiet: false
[2019-07-26 14:33:18] [config] quiet-translation: true
[2019-07-26 14:33:18] [config] relative-paths: false
[2019-07-26 14:33:18] [config] right-left: false
[2019-07-26 14:33:18] [config] save-freq: 20000
[2019-07-26 14:33:18] [config] seed: 1111
[2019-07-26 14:33:18] [config] shuffle-in-ram: false
[2019-07-26 14:33:18] [config] skip: false
[2019-07-26 14:33:18] [config] sqlite: ""
[2019-07-26 14:33:18] [config] sqlite-drop: false
[2019-07-26 14:33:18] [config] sync-sgd: true
[2019-07-26 14:33:18] [config] tempdir: .
[2019-07-26 14:33:18] [config] tied-embeddings: false
[2019-07-26 14:33:18] [config] tied-embeddings-all: false
[2019-07-26 14:33:18] [config] tied-embeddings-src: false
[2019-07-26 14:33:18] [config] train-sets:
[2019-07-26 14:33:18] [config]   - ../experiments/100M_bicleaner_dcce/data/train.bpe.de
[2019-07-26 14:33:18] [config]   - ../experiments/100M_bicleaner_dcce/data/train.bpe.en
[2019-07-26 14:33:18] [config] transformer-aan-activation: swish
[2019-07-26 14:33:18] [config] transformer-aan-depth: 2
[2019-07-26 14:33:18] [config] transformer-aan-nogate: false
[2019-07-26 14:33:18] [config] transformer-decoder-autoreg: self-attention
[2019-07-26 14:33:18] [config] transformer-dim-aan: 2048
[2019-07-26 14:33:18] [config] transformer-dim-ffn: 2048
[2019-07-26 14:33:18] [config] transformer-dropout: 0
[2019-07-26 14:33:18] [config] transformer-dropout-attention: 0
[2019-07-26 14:33:18] [config] transformer-dropout-ffn: 0
[2019-07-26 14:33:18] [config] transformer-ffn-activation: swish
[2019-07-26 14:33:18] [config] transformer-ffn-depth: 2
[2019-07-26 14:33:18] [config] transformer-guided-alignment-layer: last
[2019-07-26 14:33:18] [config] transformer-heads: 8
[2019-07-26 14:33:18] [config] transformer-no-projection: false
[2019-07-26 14:33:18] [config] transformer-postprocess: dan
[2019-07-26 14:33:18] [config] transformer-postprocess-emb: d
[2019-07-26 14:33:18] [config] transformer-preprocess: ""
[2019-07-26 14:33:18] [config] transformer-tied-layers:
[2019-07-26 14:33:18] [config]   []
[2019-07-26 14:33:18] [config] transformer-train-position-embeddings: false
[2019-07-26 14:33:18] [config] type: amun
[2019-07-26 14:33:18] [config] ulr: false
[2019-07-26 14:33:18] [config] ulr-dim-emb: 0
[2019-07-26 14:33:18] [config] ulr-dropout: 0
[2019-07-26 14:33:18] [config] ulr-keys-vectors: ""
[2019-07-26 14:33:18] [config] ulr-query-vectors: ""
[2019-07-26 14:33:18] [config] ulr-softmax-temperature: 1
[2019-07-26 14:33:18] [config] ulr-trainable-transformation: false
[2019-07-26 14:33:18] [config] valid-freq: 20000
[2019-07-26 14:33:18] [config] valid-log: ../experiments/100M_bicleaner_dcce/model/valid.log
[2019-07-26 14:33:18] [config] valid-max-length: 1000
[2019-07-26 14:33:18] [config] valid-metrics:
[2019-07-26 14:33:18] [config]   - cross-entropy
[2019-07-26 14:33:18] [config]   - perplexity
[2019-07-26 14:33:18] [config]   - translation
[2019-07-26 14:33:18] [config] valid-mini-batch: 8
[2019-07-26 14:33:18] [config] valid-script-path: ../experiments/100M_bicleaner_dcce/score-dev.sh
[2019-07-26 14:33:18] [config] valid-sets:
[2019-07-26 14:33:18] [config]   - ../experiments/100M_bicleaner_dcce/data/dev.bpe.de
[2019-07-26 14:33:18] [config]   - ../experiments/100M_bicleaner_dcce/data/dev.bpe.en
[2019-07-26 14:33:18] [config] valid-translation-output: ../experiments/100M_bicleaner_dcce/model/dev.out
[2019-07-26 14:33:18] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-26 14:33:18] [config] vocabs:
[2019-07-26 14:33:18] [config]   - ../experiments/100M_bicleaner_dcce/data/train.bpe.de.json
[2019-07-26 14:33:18] [config]   - ../experiments/100M_bicleaner_dcce/data/train.bpe.en.json
[2019-07-26 14:33:18] [config] word-penalty: 0
[2019-07-26 14:33:18] [config] workspace: 5000
[2019-07-26 14:33:18] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-26 14:33:18] Using synchronous training
[2019-07-26 14:33:18] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_bicleaner_dcce/data/train.bpe.de.json
[2019-07-26 14:33:18] [data] Using unused word id eos for 0
[2019-07-26 14:33:18] [data] Using unused word id UNK for 1
[2019-07-26 14:33:18] [data] Setting vocabulary size for input 0 to 50000
[2019-07-26 14:33:18] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_bicleaner_dcce/data/train.bpe.en.json
[2019-07-26 14:33:18] [data] Using unused word id eos for 0
[2019-07-26 14:33:18] [data] Using unused word id UNK for 1
[2019-07-26 14:33:18] [data] Setting vocabulary size for input 1 to 50000
[2019-07-26 14:33:18] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-26 14:33:18] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-26 14:33:19] [memory] Extending reserved space to 5120 MB (device gpu3)
[2019-07-26 14:33:20] [memory] Extending reserved space to 5120 MB (device gpu4)
[2019-07-26 14:33:21] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-26 14:33:21] [comm] NCCLCommunicator constructed successfully.
[2019-07-26 14:33:21] [training] Using 2 GPUs
[2019-07-26 14:33:21] [memory] Reserving 422 MB, device gpu3
[2019-07-26 14:33:21] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-26 14:33:21] [memory] Reserving 422 MB, device gpu3
[2019-07-26 14:33:25] [batching] Done. Typical MB size is 13760 target words
[2019-07-26 14:33:25] [memory] Extending reserved space to 5120 MB (device gpu3)
[2019-07-26 14:33:25] [memory] Extending reserved space to 5120 MB (device gpu4)
[2019-07-26 14:33:25] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-26 14:33:26] [comm] NCCLCommunicator constructed successfully.
[2019-07-26 14:33:26] [training] Using 2 GPUs
[2019-07-26 14:33:26] Loading model from ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-26 14:33:28] Loading model from ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-26 14:33:31] Loading Adam parameters from ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-26 14:33:34] [memory] Reserving 422 MB, device gpu3
[2019-07-26 14:33:34] [memory] Reserving 422 MB, device gpu4
[2019-07-26 14:33:35] [training] Model reloaded from ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-26 14:33:35] [data] Restoring the corpus state to epoch 26, batch 320000
[2019-07-26 14:33:35] [data] Shuffling data
[2019-07-26 14:33:38] [data] Done reading 4828705 sentences
[2019-07-26 14:33:57] [data] Done shuffling 4828705 sentences to temp files
[2019-07-26 14:35:16] Training started
[2019-07-26 14:35:16] [training] Batches are processed as 1 process(es) x 2 devices/process
[2019-07-26 14:35:16] [memory] Reserving 422 MB, device gpu4
[2019-07-26 14:35:16] [memory] Reserving 422 MB, device gpu3
[2019-07-26 14:35:16] [memory] Reserving 422 MB, device gpu4
[2019-07-26 14:35:16] [memory] Reserving 422 MB, device gpu3
[2019-07-26 14:35:16] Loading model from ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-26 14:35:19] [memory] Reserving 422 MB, device cpu0
[2019-07-26 14:35:19] [memory] Reserving 211 MB, device gpu3
[2019-07-26 14:35:19] [memory] Reserving 211 MB, device gpu4
[2019-07-26 14:45:28] Ep. 26 : Up. 322000 : Sen. 3,467,228 : Cost 37.93759155 : Time 730.09s : 20838.25 words/s
[2019-07-26 14:55:38] Ep. 26 : Up. 324000 : Sen. 4,141,064 : Cost 38.03166580 : Time 610.14s : 24963.93 words/s
[2019-07-26 14:56:32] Seen 4199891 samples
[2019-07-26 14:56:32] Starting epoch 27
[2019-07-26 14:56:32] [data] Shuffling data
[2019-07-26 14:56:34] [data] Done reading 4828705 sentences
[2019-07-26 14:56:52] [data] Done shuffling 4828705 sentences to temp files
[2019-07-26 15:06:11] Ep. 27 : Up. 326000 : Sen. 615,472 : Cost 37.23801804 : Time 632.53s : 24117.06 words/s
[2019-07-26 15:16:21] Ep. 27 : Up. 328000 : Sen. 1,286,400 : Cost 37.42139435 : Time 610.01s : 24880.44 words/s
[2019-07-26 15:26:47] Ep. 27 : Up. 330000 : Sen. 1,958,400 : Cost 37.47830200 : Time 626.28s : 24276.99 words/s
[2019-07-26 15:39:45] Ep. 27 : Up. 332000 : Sen. 2,633,600 : Cost 37.62609482 : Time 778.18s : 19629.70 words/s
[2019-07-26 15:55:44] Ep. 27 : Up. 334000 : Sen. 3,306,154 : Cost 37.69071960 : Time 958.53s : 15871.08 words/s
[2019-07-26 16:11:41] Ep. 27 : Up. 336000 : Sen. 3,980,452 : Cost 37.82567596 : Time 956.68s : 15938.76 words/s
[2019-07-26 16:16:52] Seen 4199891 samples
[2019-07-26 16:16:52] Starting epoch 28
[2019-07-26 16:16:52] [data] Shuffling data
[2019-07-26 16:16:59] [data] Done reading 4828705 sentences
[2019-07-26 16:17:47] [data] Done shuffling 4828705 sentences to temp files
[2019-07-26 16:28:43] Ep. 28 : Up. 338000 : Sen. 454,664 : Cost 37.45340729 : Time 1022.50s : 14900.83 words/s
[2019-07-26 16:44:44] Ep. 28 : Up. 340000 : Sen. 1,129,530 : Cost 37.18425751 : Time 960.82s : 15876.98 words/s
[2019-07-26 16:44:44] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-26 16:44:54] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter340000.npz
[2019-07-26 16:44:57] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-26 16:45:08] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-26 16:45:35] [valid] Ep. 28 : Up. 340000 : cross-entropy : 38.8341 : new best
[2019-07-26 16:45:41] [valid] Ep. 28 : Up. 340000 : perplexity : 4.61641 : new best
[2019-07-26 16:46:47] [valid] Ep. 28 : Up. 340000 : translation : 31.75 : new best
[2019-07-26 17:02:53] Ep. 28 : Up. 342000 : Sen. 1,802,222 : Cost 37.47546387 : Time 1088.99s : 14002.95 words/s
[2019-07-26 17:16:44] Ep. 28 : Up. 344000 : Sen. 2,476,340 : Cost 37.38975143 : Time 830.93s : 18330.41 words/s
[2019-07-26 17:30:32] Ep. 28 : Up. 346000 : Sen. 3,151,626 : Cost 37.64505386 : Time 828.06s : 18452.66 words/s
[2019-07-26 17:44:20] Ep. 28 : Up. 348000 : Sen. 3,826,588 : Cost 37.71680832 : Time 827.84s : 18444.63 words/s
[2019-07-26 17:51:55] Seen 4199891 samples
[2019-07-26 17:51:55] Starting epoch 29
[2019-07-26 17:51:55] [data] Shuffling data
[2019-07-26 17:52:00] [data] Done reading 4828705 sentences
[2019-07-26 17:52:36] [data] Done shuffling 4828705 sentences to temp files
[2019-07-26 17:58:43] Ep. 29 : Up. 350000 : Sen. 298,646 : Cost 37.36810684 : Time 862.94s : 17609.29 words/s
[2019-07-26 18:12:05] Ep. 29 : Up. 352000 : Sen. 971,464 : Cost 37.12609482 : Time 801.89s : 18980.11 words/s
[2019-07-26 18:25:37] Ep. 29 : Up. 354000 : Sen. 1,643,838 : Cost 37.18510818 : Time 812.54s : 18731.92 words/s
[2019-07-26 18:38:57] Ep. 29 : Up. 356000 : Sen. 2,317,481 : Cost 37.34409332 : Time 800.04s : 19028.94 words/s
[2019-07-26 18:52:23] Ep. 29 : Up. 358000 : Sen. 2,990,218 : Cost 37.58003616 : Time 806.19s : 18899.57 words/s
[2019-07-26 19:05:00] Ep. 29 : Up. 360000 : Sen. 3,667,660 : Cost 37.45968628 : Time 756.33s : 20229.33 words/s
[2019-07-26 19:05:00] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-26 19:05:09] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter360000.npz
[2019-07-26 19:05:12] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-26 19:05:19] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-26 19:05:40] [valid] Ep. 29 : Up. 360000 : cross-entropy : 38.8182 : new best
[2019-07-26 19:05:44] [valid] Ep. 29 : Up. 360000 : perplexity : 4.61351 : new best
[2019-07-26 19:06:49] [valid] Ep. 29 : Up. 360000 : translation : 31.83 : new best
[2019-07-26 19:16:17] Seen 4199891 samples
[2019-07-26 19:16:17] Starting epoch 30
[2019-07-26 19:16:17] [data] Shuffling data
[2019-07-26 19:16:21] [data] Done reading 4828705 sentences
[2019-07-26 19:16:59] [data] Done shuffling 4828705 sentences to temp files
[2019-07-26 19:19:31] Ep. 30 : Up. 362000 : Sen. 141,882 : Cost 37.53459167 : Time 871.48s : 17512.07 words/s
[2019-07-26 19:31:25] Ep. 30 : Up. 364000 : Sen. 815,498 : Cost 36.77371216 : Time 713.63s : 21346.69 words/s
[2019-07-26 19:43:14] Ep. 30 : Up. 366000 : Sen. 1,486,484 : Cost 37.03931427 : Time 709.18s : 21382.03 words/s
[2019-07-26 19:55:05] Ep. 30 : Up. 368000 : Sen. 2,160,037 : Cost 37.20011902 : Time 711.43s : 21427.73 words/s
[2019-07-26 20:06:54] Ep. 30 : Up. 370000 : Sen. 2,834,186 : Cost 37.24751282 : Time 708.85s : 21514.77 words/s
[2019-07-26 20:17:59] Ep. 30 : Up. 372000 : Sen. 3,505,712 : Cost 37.33258057 : Time 664.18s : 22867.67 words/s
[2019-07-26 20:28:29] Ep. 30 : Up. 374000 : Sen. 4,178,240 : Cost 37.62209702 : Time 630.25s : 24148.16 words/s
[2019-07-26 20:28:49] Seen 4199891 samples
[2019-07-26 20:28:49] Starting epoch 31
[2019-07-26 20:28:49] [data] Shuffling data
[2019-07-26 20:28:52] [data] Done reading 4828705 sentences
[2019-07-26 20:29:12] [data] Done shuffling 4828705 sentences to temp files
[2019-07-26 20:39:24] Ep. 31 : Up. 376000 : Sen. 650,362 : Cost 36.84738541 : Time 655.21s : 23213.14 words/s
[2019-07-26 20:49:56] Ep. 31 : Up. 378000 : Sen. 1,323,642 : Cost 37.00494003 : Time 631.79s : 24124.08 words/s
[2019-07-26 21:00:28] Ep. 31 : Up. 380000 : Sen. 1,999,472 : Cost 37.05670547 : Time 632.51s : 24159.76 words/s
[2019-07-26 21:00:28] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-26 21:00:34] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter380000.npz
[2019-07-26 21:00:36] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-26 21:00:41] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-26 21:00:57] [valid] Ep. 31 : Up. 380000 : cross-entropy : 38.8066 : new best
[2019-07-26 21:01:00] [valid] Ep. 31 : Up. 380000 : perplexity : 4.61142 : new best
[2019-07-26 21:01:49] [valid] Ep. 31 : Up. 380000 : translation : 31.8 : stalled 1 times (last best: 31.83)
[2019-07-26 21:12:23] Ep. 31 : Up. 382000 : Sen. 2,673,112 : Cost 37.27515793 : Time 714.27s : 21344.25 words/s
[2019-07-26 21:22:52] Ep. 31 : Up. 384000 : Sen. 3,346,058 : Cost 37.22560883 : Time 629.08s : 24156.00 words/s
[2019-07-26 21:33:23] Ep. 31 : Up. 386000 : Sen. 4,020,536 : Cost 37.43399048 : Time 631.66s : 24168.91 words/s
[2019-07-26 21:36:12] Seen 4199891 samples
[2019-07-26 21:36:12] Starting epoch 32
[2019-07-26 21:36:12] [data] Shuffling data
[2019-07-26 21:36:15] [data] Done reading 4828705 sentences
[2019-07-26 21:36:37] [data] Done shuffling 4828705 sentences to temp files
[2019-07-26 21:44:18] Ep. 32 : Up. 388000 : Sen. 492,272 : Cost 36.88982391 : Time 654.80s : 23187.68 words/s
[2019-07-26 21:54:30] Ep. 32 : Up. 390000 : Sen. 1,166,204 : Cost 36.85916519 : Time 612.06s : 24936.60 words/s
[2019-07-26 22:04:41] Ep. 32 : Up. 392000 : Sen. 1,840,042 : Cost 37.06540298 : Time 610.85s : 24934.93 words/s
[2019-07-26 22:14:52] Ep. 32 : Up. 394000 : Sen. 2,514,504 : Cost 37.05763626 : Time 610.98s : 24956.02 words/s
[2019-07-26 22:25:05] Ep. 32 : Up. 396000 : Sen. 3,189,872 : Cost 37.17561340 : Time 612.88s : 24945.28 words/s
[2019-07-26 22:35:16] Ep. 32 : Up. 398000 : Sen. 3,862,532 : Cost 37.16112137 : Time 610.90s : 24896.17 words/s
[2019-07-26 22:40:23] Seen 4199891 samples
[2019-07-26 22:40:23] Starting epoch 33
[2019-07-26 22:40:23] [data] Shuffling data
[2019-07-26 22:40:25] [data] Done reading 4828705 sentences
[2019-07-26 22:40:43] [data] Done shuffling 4828705 sentences to temp files
[2019-07-26 22:45:49] Ep. 33 : Up. 400000 : Sen. 337,600 : Cost 36.95483017 : Time 633.29s : 24095.09 words/s
[2019-07-26 22:45:49] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-26 22:45:54] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter400000.npz
[2019-07-26 22:45:56] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-26 22:46:01] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-26 22:46:16] [valid] Ep. 33 : Up. 400000 : cross-entropy : 38.7615 : new best
[2019-07-26 22:46:19] [valid] Ep. 33 : Up. 400000 : perplexity : 4.60323 : new best
[2019-07-26 22:46:58] [valid] Ep. 33 : Up. 400000 : translation : 31.89 : new best
[2019-07-26 22:57:11] Ep. 33 : Up. 402000 : Sen. 1,010,852 : Cost 36.61015320 : Time 682.38s : 22319.03 words/s
[2019-07-26 23:07:28] Ep. 33 : Up. 404000 : Sen. 1,683,896 : Cost 36.90215302 : Time 616.57s : 24720.16 words/s
[2019-07-26 23:17:47] Ep. 33 : Up. 406000 : Sen. 2,359,218 : Cost 36.84708023 : Time 619.18s : 24691.69 words/s
[2019-07-26 23:28:13] Ep. 33 : Up. 408000 : Sen. 3,031,250 : Cost 37.05966568 : Time 625.82s : 24291.52 words/s
[2019-07-26 23:38:34] Ep. 33 : Up. 410000 : Sen. 3,703,785 : Cost 36.99457169 : Time 621.31s : 24446.66 words/s
[2019-07-26 23:46:11] Seen 4199891 samples
[2019-07-26 23:46:11] Starting epoch 34
[2019-07-26 23:46:11] [data] Shuffling data
[2019-07-26 23:46:14] [data] Done reading 4828705 sentences
[2019-07-26 23:46:35] [data] Done shuffling 4828705 sentences to temp files
[2019-07-26 23:49:18] Ep. 34 : Up. 412000 : Sen. 176,392 : Cost 37.01708603 : Time 644.06s : 23644.11 words/s
[2019-07-26 23:59:40] Ep. 34 : Up. 414000 : Sen. 853,998 : Cost 36.40767288 : Time 621.81s : 24630.08 words/s
[2019-07-27 00:10:03] Ep. 34 : Up. 416000 : Sen. 1,524,452 : Cost 36.70428848 : Time 623.16s : 24347.42 words/s
[2019-07-27 00:20:32] Ep. 34 : Up. 418000 : Sen. 2,198,136 : Cost 36.67447662 : Time 628.82s : 24226.01 words/s
[2019-07-27 00:31:03] Ep. 34 : Up. 420000 : Sen. 2,871,558 : Cost 36.96363068 : Time 630.41s : 24158.89 words/s
[2019-07-27 00:31:03] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-27 00:31:08] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter420000.npz
[2019-07-27 00:31:10] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-27 00:31:15] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-27 00:31:30] [valid] Ep. 34 : Up. 420000 : cross-entropy : 38.7843 : stalled 1 times (last best: 38.7615)
[2019-07-27 00:31:33] [valid] Ep. 34 : Up. 420000 : perplexity : 4.60736 : stalled 1 times (last best: 4.60323)
[2019-07-27 00:32:16] [valid] Ep. 34 : Up. 420000 : translation : 32.12 : new best
[2019-07-27 00:42:39] Ep. 34 : Up. 422000 : Sen. 3,544,264 : Cost 37.12240219 : Time 696.29s : 21869.41 words/s
[2019-07-27 00:52:47] Seen 4199891 samples
[2019-07-27 00:52:47] Starting epoch 35
[2019-07-27 00:52:47] [data] Shuffling data
[2019-07-27 00:52:50] [data] Done reading 4828705 sentences
[2019-07-27 00:53:10] [data] Done shuffling 4828705 sentences to temp files
[2019-07-27 00:53:29] Ep. 35 : Up. 424000 : Sen. 18,672 : Cost 37.13571548 : Time 649.98s : 23448.87 words/s
[2019-07-27 01:03:55] Ep. 35 : Up. 426000 : Sen. 693,176 : Cost 36.36540985 : Time 625.88s : 24375.13 words/s
[2019-07-27 01:14:19] Ep. 35 : Up. 428000 : Sen. 1,366,295 : Cost 36.57952499 : Time 623.76s : 24384.83 words/s
[2019-07-27 01:24:46] Ep. 35 : Up. 430000 : Sen. 2,042,740 : Cost 36.67628479 : Time 627.19s : 24422.93 words/s
[2019-07-27 01:35:12] Ep. 35 : Up. 432000 : Sen. 2,717,733 : Cost 36.87926865 : Time 626.34s : 24371.29 words/s
[2019-07-27 01:45:38] Ep. 35 : Up. 434000 : Sen. 3,390,014 : Cost 36.91625214 : Time 625.53s : 24313.69 words/s
[2019-07-27 01:56:02] Ep. 35 : Up. 436000 : Sen. 4,061,760 : Cost 37.14109039 : Time 624.82s : 24331.93 words/s
[2019-07-27 01:58:11] Seen 4199891 samples
[2019-07-27 01:58:11] Starting epoch 36
[2019-07-27 01:58:11] [data] Shuffling data
[2019-07-27 01:58:14] [data] Done reading 4828705 sentences
[2019-07-27 01:58:35] [data] Done shuffling 4828705 sentences to temp files
[2019-07-27 02:06:53] Ep. 36 : Up. 438000 : Sen. 537,336 : Cost 36.31631470 : Time 650.49s : 23468.84 words/s
[2019-07-27 02:17:18] Ep. 36 : Up. 440000 : Sen. 1,208,657 : Cost 36.42152405 : Time 624.68s : 24322.93 words/s
[2019-07-27 02:17:18] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-27 02:17:23] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter440000.npz
[2019-07-27 02:17:25] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-27 02:17:31] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-27 02:17:46] [valid] Ep. 36 : Up. 440000 : cross-entropy : 38.8027 : stalled 2 times (last best: 38.7615)
[2019-07-27 02:17:49] [valid] Ep. 36 : Up. 440000 : perplexity : 4.6107 : stalled 2 times (last best: 4.60323)
[2019-07-27 02:18:44] [valid] Ep. 36 : Up. 440000 : translation : 31.94 : stalled 1 times (last best: 32.12)
[2019-07-27 02:29:10] Ep. 36 : Up. 442000 : Sen. 1,880,152 : Cost 36.60020828 : Time 712.43s : 21315.66 words/s
[2019-07-27 02:39:35] Ep. 36 : Up. 444000 : Sen. 2,553,600 : Cost 36.72755051 : Time 624.72s : 24379.43 words/s
[2019-07-27 02:50:01] Ep. 36 : Up. 446000 : Sen. 3,227,380 : Cost 36.81973267 : Time 626.35s : 24352.01 words/s
[2019-07-27 03:00:26] Ep. 36 : Up. 448000 : Sen. 3,898,476 : Cost 36.96525955 : Time 624.79s : 24304.46 words/s
[2019-07-27 03:05:06] Seen 4199891 samples
[2019-07-27 03:05:06] Starting epoch 37
[2019-07-27 03:05:06] [data] Shuffling data
[2019-07-27 03:05:09] [data] Done reading 4828705 sentences
[2019-07-27 03:05:31] [data] Done shuffling 4828705 sentences to temp files
[2019-07-27 03:11:18] Ep. 37 : Up. 450000 : Sen. 372,450 : Cost 36.46590805 : Time 651.88s : 23381.22 words/s
[2019-07-27 03:21:43] Ep. 37 : Up. 452000 : Sen. 1,047,234 : Cost 36.26509094 : Time 625.22s : 24392.73 words/s
[2019-07-27 03:32:09] Ep. 37 : Up. 454000 : Sen. 1,721,864 : Cost 36.59023666 : Time 626.10s : 24388.82 words/s
[2019-07-27 03:42:34] Ep. 37 : Up. 456000 : Sen. 2,394,562 : Cost 36.53235626 : Time 625.17s : 24330.05 words/s
[2019-07-27 03:52:59] Ep. 37 : Up. 458000 : Sen. 3,066,936 : Cost 36.67209625 : Time 624.84s : 24339.94 words/s
[2019-07-27 04:03:24] Ep. 37 : Up. 460000 : Sen. 3,741,258 : Cost 36.80465317 : Time 625.32s : 24373.59 words/s
[2019-07-27 04:03:24] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-27 04:03:30] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter460000.npz
[2019-07-27 04:03:32] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-27 04:03:37] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-27 04:03:53] [valid] Ep. 37 : Up. 460000 : cross-entropy : 38.7894 : stalled 3 times (last best: 38.7615)
[2019-07-27 04:03:56] [valid] Ep. 37 : Up. 460000 : perplexity : 4.60828 : stalled 3 times (last best: 4.60323)
[2019-07-27 04:04:51] [valid] Ep. 37 : Up. 460000 : translation : 31.86 : stalled 2 times (last best: 32.12)
[2019-07-27 04:12:02] Seen 4199891 samples
[2019-07-27 04:12:02] Starting epoch 38
[2019-07-27 04:12:02] [data] Shuffling data
[2019-07-27 04:12:04] [data] Done reading 4828705 sentences
[2019-07-27 04:12:26] [data] Done shuffling 4828705 sentences to temp files
[2019-07-27 04:15:44] Ep. 38 : Up. 462000 : Sen. 213,788 : Cost 36.64801407 : Time 739.65s : 20585.57 words/s
[2019-07-27 04:26:11] Ep. 38 : Up. 464000 : Sen. 889,140 : Cost 36.24364090 : Time 626.74s : 24418.84 words/s
[2019-07-27 04:36:35] Ep. 38 : Up. 466000 : Sen. 1,561,336 : Cost 36.33779526 : Time 624.12s : 24357.63 words/s
[2019-07-27 04:47:01] Ep. 38 : Up. 468000 : Sen. 2,235,046 : Cost 36.52570343 : Time 626.05s : 24341.74 words/s
[2019-07-27 04:57:25] Ep. 38 : Up. 470000 : Sen. 2,907,548 : Cost 36.45556259 : Time 623.77s : 24377.52 words/s
[2019-07-27 05:07:51] Ep. 38 : Up. 472000 : Sen. 3,584,264 : Cost 36.61442184 : Time 626.74s : 24418.34 words/s
[2019-07-27 05:17:24] Seen 4199891 samples
[2019-07-27 05:17:24] Starting epoch 39
[2019-07-27 05:17:24] [data] Shuffling data
[2019-07-27 05:17:27] [data] Done reading 4828705 sentences
[2019-07-27 05:17:47] [data] Done shuffling 4828705 sentences to temp files
[2019-07-27 05:18:41] Ep. 39 : Up. 474000 : Sen. 56,248 : Cost 36.65747833 : Time 649.34s : 23409.99 words/s
[2019-07-27 05:29:05] Ep. 39 : Up. 476000 : Sen. 731,268 : Cost 35.93093491 : Time 624.25s : 24406.19 words/s
[2019-07-27 05:39:31] Ep. 39 : Up. 478000 : Sen. 1,406,842 : Cost 36.21000671 : Time 626.30s : 24421.26 words/s
[2019-07-27 05:49:56] Ep. 39 : Up. 480000 : Sen. 2,080,528 : Cost 36.43808746 : Time 624.97s : 24373.16 words/s
[2019-07-27 05:49:56] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-27 05:50:02] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter480000.npz
[2019-07-27 05:50:04] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-27 05:50:10] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-27 05:50:26] [valid] Ep. 39 : Up. 480000 : cross-entropy : 38.7932 : stalled 4 times (last best: 38.7615)
[2019-07-27 05:50:29] [valid] Ep. 39 : Up. 480000 : perplexity : 4.60897 : stalled 4 times (last best: 4.60323)
[2019-07-27 05:51:25] [valid] Ep. 39 : Up. 480000 : translation : 31.82 : stalled 3 times (last best: 32.12)
[2019-07-27 06:01:52] Ep. 39 : Up. 482000 : Sen. 2,753,796 : Cost 36.58366013 : Time 715.43s : 21291.29 words/s
[2019-07-27 06:12:16] Ep. 39 : Up. 484000 : Sen. 3,425,574 : Cost 36.62685776 : Time 624.23s : 24344.46 words/s
[2019-07-27 06:22:42] Ep. 39 : Up. 486000 : Sen. 4,100,442 : Cost 36.79985428 : Time 625.64s : 24406.49 words/s
[2019-07-27 06:24:14] Seen 4199891 samples
[2019-07-27 06:24:14] Starting epoch 40
[2019-07-27 06:24:14] [data] Shuffling data
[2019-07-27 06:24:17] [data] Done reading 4828705 sentences
[2019-07-27 06:24:44] [data] Done shuffling 4828705 sentences to temp files
[2019-07-27 06:33:36] Ep. 40 : Up. 488000 : Sen. 571,380 : Cost 36.24502182 : Time 654.39s : 23214.91 words/s
[2019-07-27 06:44:01] Ep. 40 : Up. 490000 : Sen. 1,246,204 : Cost 36.01971817 : Time 624.81s : 24422.83 words/s
[2019-07-27 06:54:27] Ep. 40 : Up. 492000 : Sen. 1,921,056 : Cost 36.33469391 : Time 625.80s : 24395.53 words/s
[2019-07-27 07:04:48] Ep. 40 : Up. 494000 : Sen. 2,595,144 : Cost 36.34719086 : Time 621.60s : 24505.79 words/s
[2019-07-27 07:15:09] Ep. 40 : Up. 496000 : Sen. 3,267,454 : Cost 36.48754501 : Time 621.06s : 24492.88 words/s
[2019-07-27 07:25:31] Ep. 40 : Up. 498000 : Sen. 3,939,796 : Cost 36.66958618 : Time 621.34s : 24497.29 words/s
[2019-07-27 07:29:31] Seen 4199891 samples
[2019-07-27 07:29:31] Starting epoch 41
[2019-07-27 07:29:31] [data] Shuffling data
[2019-07-27 07:29:33] [data] Done reading 4828705 sentences
[2019-07-27 07:29:54] [data] Done shuffling 4828705 sentences to temp files
[2019-07-27 07:36:19] Ep. 41 : Up. 500000 : Sen. 416,460 : Cost 36.03378677 : Time 648.38s : 23593.25 words/s
[2019-07-27 07:36:19] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-27 07:36:25] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter500000.npz
[2019-07-27 07:36:27] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-27 07:36:33] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-27 07:36:50] [valid] Ep. 41 : Up. 500000 : cross-entropy : 38.7592 : new best
[2019-07-27 07:36:53] [valid] Ep. 41 : Up. 500000 : perplexity : 4.60282 : new best
[2019-07-27 07:37:49] [valid] Ep. 41 : Up. 500000 : translation : 31.74 : stalled 4 times (last best: 32.12)
[2019-07-27 07:48:14] Ep. 41 : Up. 502000 : Sen. 1,090,845 : Cost 35.99510574 : Time 714.64s : 21375.51 words/s
[2019-07-27 07:58:32] Ep. 41 : Up. 504000 : Sen. 1,763,550 : Cost 36.11634064 : Time 618.42s : 24602.40 words/s
[2019-07-27 08:08:47] Ep. 41 : Up. 506000 : Sen. 2,437,592 : Cost 36.27382278 : Time 614.99s : 24784.39 words/s
[2019-07-27 08:19:01] Ep. 41 : Up. 508000 : Sen. 3,110,928 : Cost 36.34427261 : Time 614.23s : 24805.47 words/s
[2019-07-27 08:29:17] Ep. 41 : Up. 510000 : Sen. 3,784,876 : Cost 36.59045029 : Time 615.64s : 24779.01 words/s
[2019-07-27 08:35:35] Seen 4199891 samples
[2019-07-27 08:35:35] Starting epoch 42
[2019-07-27 08:35:35] [data] Shuffling data
[2019-07-27 08:35:37] [data] Done reading 4828705 sentences
[2019-07-27 08:35:55] [data] Done shuffling 4828705 sentences to temp files
[2019-07-27 08:39:52] Ep. 42 : Up. 512000 : Sen. 258,948 : Cost 36.16489410 : Time 635.56s : 23938.89 words/s
[2019-07-27 08:50:07] Ep. 42 : Up. 514000 : Sen. 931,058 : Cost 35.94767380 : Time 614.50s : 24781.06 words/s
[2019-07-27 09:00:21] Ep. 42 : Up. 516000 : Sen. 1,604,188 : Cost 36.10376740 : Time 614.06s : 24789.58 words/s
[2019-07-27 09:10:41] Ep. 42 : Up. 518000 : Sen. 2,278,136 : Cost 36.08343124 : Time 620.21s : 24553.36 words/s
[2019-07-27 09:21:08] Ep. 42 : Up. 520000 : Sen. 2,952,706 : Cost 36.47646713 : Time 627.12s : 24330.69 words/s
[2019-07-27 09:21:08] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-27 09:21:14] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter520000.npz
[2019-07-27 09:21:16] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-27 09:21:22] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-27 09:21:38] [valid] Ep. 42 : Up. 520000 : cross-entropy : 38.7701 : stalled 1 times (last best: 38.7592)
[2019-07-27 09:21:41] [valid] Ep. 42 : Up. 520000 : perplexity : 4.60479 : stalled 1 times (last best: 4.60282)
[2019-07-27 09:22:22] [valid] Ep. 42 : Up. 520000 : translation : 31.83 : stalled 5 times (last best: 32.12)
[2019-07-27 09:32:43] Ep. 42 : Up. 522000 : Sen. 3,627,396 : Cost 36.45654297 : Time 694.75s : 21978.81 words/s
[2019-07-27 09:41:24] Seen 4199891 samples
[2019-07-27 09:41:24] Starting epoch 43
[2019-07-27 09:41:24] [data] Shuffling data
[2019-07-27 09:41:27] [data] Done reading 4828705 sentences
[2019-07-27 09:41:49] [data] Done shuffling 4828705 sentences to temp files
[2019-07-27 09:43:25] Ep. 43 : Up. 524000 : Sen. 103,540 : Cost 36.33675385 : Time 642.30s : 23814.41 words/s
[2019-07-27 09:53:44] Ep. 43 : Up. 526000 : Sen. 777,504 : Cost 35.76157379 : Time 618.75s : 24629.71 words/s
[2019-07-27 10:04:02] Ep. 43 : Up. 528000 : Sen. 1,451,737 : Cost 36.00383377 : Time 617.86s : 24668.40 words/s
[2019-07-27 10:14:18] Ep. 43 : Up. 530000 : Sen. 2,124,102 : Cost 36.16571426 : Time 616.18s : 24693.01 words/s
[2019-07-27 10:24:40] Ep. 43 : Up. 532000 : Sen. 2,798,958 : Cost 36.29892731 : Time 622.16s : 24547.38 words/s
[2019-07-27 10:35:03] Ep. 43 : Up. 534000 : Sen. 3,473,880 : Cost 36.26610947 : Time 622.79s : 24498.26 words/s
[2019-07-27 10:45:30] Ep. 43 : Up. 536000 : Sen. 4,148,356 : Cost 36.44461441 : Time 627.21s : 24327.53 words/s
[2019-07-27 10:46:18] Seen 4199891 samples
[2019-07-27 10:46:18] Starting epoch 44
[2019-07-27 10:46:18] [data] Shuffling data
[2019-07-27 10:46:21] [data] Done reading 4828705 sentences
[2019-07-27 10:46:43] [data] Done shuffling 4828705 sentences to temp files
[2019-07-27 10:56:19] Ep. 44 : Up. 538000 : Sen. 623,932 : Cost 35.75407791 : Time 648.18s : 23556.38 words/s
[2019-07-27 11:06:36] Ep. 44 : Up. 540000 : Sen. 1,293,592 : Cost 36.00074005 : Time 617.23s : 24574.08 words/s
[2019-07-27 11:06:36] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-27 11:06:41] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter540000.npz
[2019-07-27 11:06:43] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-27 11:06:49] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-27 11:07:05] [valid] Ep. 44 : Up. 540000 : cross-entropy : 38.8166 : stalled 2 times (last best: 38.7592)
[2019-07-27 11:07:08] [valid] Ep. 44 : Up. 540000 : perplexity : 4.61323 : stalled 2 times (last best: 4.60282)
[2019-07-27 11:07:54] [valid] Ep. 44 : Up. 540000 : translation : 31.87 : stalled 6 times (last best: 32.12)
[2019-07-27 11:18:20] Ep. 44 : Up. 542000 : Sen. 1,969,252 : Cost 36.09267044 : Time 703.72s : 21729.38 words/s
[2019-07-27 11:28:43] Ep. 44 : Up. 544000 : Sen. 2,644,076 : Cost 36.32686615 : Time 623.41s : 24500.02 words/s
[2019-07-27 11:39:06] Ep. 44 : Up. 546000 : Sen. 3,318,774 : Cost 36.18178177 : Time 622.60s : 24489.74 words/s
[2019-07-27 11:49:28] Ep. 44 : Up. 548000 : Sen. 3,991,624 : Cost 36.29106522 : Time 622.04s : 24457.91 words/s
[2019-07-27 11:52:41] Seen 4199891 samples
[2019-07-27 11:52:41] Starting epoch 45
[2019-07-27 11:52:41] [data] Shuffling data
[2019-07-27 11:52:44] [data] Done reading 4828705 sentences
[2019-07-27 11:53:05] [data] Done shuffling 4828705 sentences to temp files
[2019-07-27 12:00:16] Ep. 45 : Up. 550000 : Sen. 465,448 : Cost 35.70531082 : Time 648.28s : 23488.79 words/s
[2019-07-27 12:10:39] Ep. 45 : Up. 552000 : Sen. 1,140,272 : Cost 35.96526718 : Time 623.61s : 24506.25 words/s
[2019-07-27 12:21:01] Ep. 45 : Up. 554000 : Sen. 1,811,931 : Cost 36.01432037 : Time 621.88s : 24452.27 words/s
[2019-07-27 12:31:22] Ep. 45 : Up. 556000 : Sen. 2,484,859 : Cost 35.98817062 : Time 621.02s : 24491.33 words/s
[2019-07-27 12:41:44] Ep. 45 : Up. 558000 : Sen. 3,159,668 : Cost 36.01369476 : Time 621.59s : 24523.83 words/s
[2019-07-27 12:52:05] Ep. 45 : Up. 560000 : Sen. 3,830,290 : Cost 36.41437912 : Time 621.33s : 24445.50 words/s
[2019-07-27 12:52:05] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-27 12:52:11] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter560000.npz
[2019-07-27 12:52:13] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-27 12:52:18] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-27 12:52:34] [valid] Ep. 45 : Up. 560000 : cross-entropy : 38.8431 : stalled 3 times (last best: 38.7592)
[2019-07-27 12:52:38] [valid] Ep. 45 : Up. 560000 : perplexity : 4.61805 : stalled 3 times (last best: 4.60282)
[2019-07-27 12:53:22] [valid] Ep. 45 : Up. 560000 : translation : 31.72 : stalled 7 times (last best: 32.12)
[2019-07-27 12:59:06] Seen 4199891 samples
[2019-07-27 12:59:06] Starting epoch 46
[2019-07-27 12:59:06] [data] Shuffling data
[2019-07-27 12:59:08] [data] Done reading 4828705 sentences
[2019-07-27 12:59:28] [data] Done shuffling 4828705 sentences to temp files
[2019-07-27 13:04:09] Ep. 46 : Up. 562000 : Sen. 303,584 : Cost 35.89458847 : Time 724.13s : 21023.82 words/s
[2019-07-27 13:14:32] Ep. 46 : Up. 564000 : Sen. 976,787 : Cost 35.72690964 : Time 623.05s : 24439.23 words/s
[2019-07-27 13:24:55] Ep. 46 : Up. 566000 : Sen. 1,650,238 : Cost 35.94329453 : Time 622.81s : 24469.94 words/s
[2019-07-27 13:35:19] Ep. 46 : Up. 568000 : Sen. 2,324,452 : Cost 36.13593674 : Time 623.22s : 24488.03 words/s
[2019-07-27 13:45:39] Ep. 46 : Up. 570000 : Sen. 2,994,936 : Cost 36.13982010 : Time 620.08s : 24441.66 words/s
[2019-07-27 13:56:01] Ep. 46 : Up. 572000 : Sen. 3,668,536 : Cost 36.21468353 : Time 622.87s : 24480.38 words/s
[2019-07-27 14:04:11] Seen 4199891 samples
[2019-07-27 14:04:11] Starting epoch 47
[2019-07-27 14:04:11] [data] Shuffling data
[2019-07-27 14:04:14] [data] Done reading 4828705 sentences
[2019-07-27 14:04:33] [data] Done shuffling 4828705 sentences to temp files
[2019-07-27 14:06:47] Ep. 47 : Up. 574000 : Sen. 143,446 : Cost 36.05134964 : Time 645.41s : 23616.72 words/s
[2019-07-27 14:17:09] Ep. 47 : Up. 576000 : Sen. 816,836 : Cost 35.56438446 : Time 622.55s : 24464.05 words/s
[2019-07-27 14:27:34] Ep. 47 : Up. 578000 : Sen. 1,494,776 : Cost 35.74889755 : Time 624.09s : 24577.70 words/s
[2019-07-27 14:37:57] Ep. 47 : Up. 580000 : Sen. 2,169,072 : Cost 35.77795029 : Time 623.18s : 24478.05 words/s
[2019-07-27 14:37:57] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-27 14:38:02] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter580000.npz
[2019-07-27 14:38:04] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-27 14:38:09] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-27 14:38:25] [valid] Ep. 47 : Up. 580000 : cross-entropy : 38.8424 : stalled 4 times (last best: 38.7592)
[2019-07-27 14:38:28] [valid] Ep. 47 : Up. 580000 : perplexity : 4.61792 : stalled 4 times (last best: 4.60282)
[2019-07-27 14:39:15] [valid] Ep. 47 : Up. 580000 : translation : 31.72 : stalled 8 times (last best: 32.12)
[2019-07-27 14:49:38] Ep. 47 : Up. 582000 : Sen. 2,838,110 : Cost 36.03692627 : Time 701.17s : 21593.72 words/s
[2019-07-27 15:00:00] Ep. 47 : Up. 584000 : Sen. 3,510,916 : Cost 36.06912231 : Time 621.75s : 24463.99 words/s
[2019-07-27 15:10:23] Ep. 47 : Up. 586000 : Sen. 4,185,864 : Cost 36.28958130 : Time 623.27s : 24510.16 words/s
[2019-07-27 15:10:36] Seen 4199891 samples
[2019-07-27 15:10:36] Starting epoch 48
[2019-07-27 15:10:36] [data] Shuffling data
[2019-07-27 15:10:39] [data] Done reading 4828705 sentences
[2019-07-27 15:10:58] [data] Done shuffling 4828705 sentences to temp files
[2019-07-27 15:21:06] Ep. 48 : Up. 588000 : Sen. 659,200 : Cost 35.44635773 : Time 643.48s : 23649.78 words/s
[2019-07-27 15:31:28] Ep. 48 : Up. 590000 : Sen. 1,334,400 : Cost 35.64244843 : Time 622.03s : 24521.34 words/s
[2019-07-27 15:41:49] Ep. 48 : Up. 592000 : Sen. 2,005,634 : Cost 35.77128220 : Time 620.68s : 24493.15 words/s
[2019-07-27 15:52:12] Ep. 48 : Up. 594000 : Sen. 2,680,026 : Cost 36.08753204 : Time 622.99s : 24499.86 words/s
[2019-07-27 16:02:34] Ep. 48 : Up. 596000 : Sen. 3,353,600 : Cost 36.04796982 : Time 621.89s : 24499.77 words/s
[2019-07-27 16:12:55] Ep. 48 : Up. 598000 : Sen. 4,027,142 : Cost 36.09954071 : Time 620.95s : 24522.03 words/s
[2019-07-27 16:15:36] Seen 4199891 samples
[2019-07-27 16:15:36] Starting epoch 49
[2019-07-27 16:15:36] [data] Shuffling data
[2019-07-27 16:15:38] [data] Done reading 4828705 sentences
[2019-07-27 16:15:58] [data] Done shuffling 4828705 sentences to temp files
[2019-07-27 16:23:40] Ep. 49 : Up. 600000 : Sen. 500,603 : Cost 35.67500687 : Time 644.97s : 23637.05 words/s
[2019-07-27 16:23:40] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-27 16:23:45] Saving model to ../experiments/100M_bicleaner_dcce/model/model.iter600000.npz
[2019-07-27 16:23:47] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-27 16:23:52] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
[2019-07-27 16:24:08] [valid] Ep. 49 : Up. 600000 : cross-entropy : 38.8229 : stalled 5 times (last best: 38.7592)
[2019-07-27 16:24:11] [valid] Ep. 49 : Up. 600000 : perplexity : 4.61437 : stalled 5 times (last best: 4.60282)
[2019-07-27 16:25:00] [valid] Ep. 49 : Up. 600000 : translation : 31.69 : stalled 9 times (last best: 32.12)
[2019-07-27 16:25:02] Training finished
[2019-07-27 16:25:08] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz.orig.npz
[2019-07-27 16:25:13] Saving model to ../experiments/100M_bicleaner_dcce/model/model.npz
[2019-07-27 16:25:19] Saving Adam parameters to ../experiments/100M_bicleaner_dcce/model/model.npz.optimizer.npz
