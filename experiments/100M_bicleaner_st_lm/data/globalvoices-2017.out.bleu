MT evaluation scorer began on 2019 Jul 27 at 18:37:38
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/100M_bicleaner_st_lm/data/globalvoices-2017.de.sgm -r ../experiments/100M_bicleaner_st_lm/data/globalvoices-2017.en.sgm -t ../experiments/100M_bicleaner_st_lm/data/globalvoices-2017.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 3000 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 1.06826509479051 (67055/62770), penalty (log): 0
NIST score = 6.9205  BLEU score = 0.2596 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  5.2379   1.4177   0.2359   0.0241   0.0049   0.0013   0.0005   0.0002   0.0001  "Edinburgh"

 BLEU:  0.5623   0.3168   0.1986   0.1284   0.0851   0.0575   0.0387   0.0261   0.0178  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  5.2379   6.6556   6.8915   6.9156   6.9205   6.9218   6.9223   6.9225   6.9226  "Edinburgh"

 BLEU:  0.5623   0.4221   0.3283   0.2596   0.2077   0.1677   0.1360   0.1106   0.0903  "Edinburgh"
MT evaluation scorer ended on 2019 Jul 27 at 18:37:56
