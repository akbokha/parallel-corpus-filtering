[2019-07-26 09:37:04] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-26 09:37:04] [marian] Running on bil as process 125611 with command line:
[2019-07-26 09:37:04] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz -T . --devices 5 --train-sets ../experiments/100M_bicleaner_st_lm_w3000/data/train.bpe.de ../experiments/100M_bicleaner_st_lm_w3000/data/train.bpe.en --vocabs ../experiments/100M_bicleaner_st_lm_w3000/data/train.bpe.de.json ../experiments/100M_bicleaner_st_lm_w3000/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_bicleaner_st_lm_w3000/data/dev.bpe.de ../experiments/100M_bicleaner_st_lm_w3000/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_bicleaner_st_lm_w3000/model/dev.out --valid-script-path ../experiments/100M_bicleaner_st_lm_w3000/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_bicleaner_st_lm_w3000/model/train.log --valid-log ../experiments/100M_bicleaner_st_lm_w3000/model/valid.log
[2019-07-26 09:37:04] [config] after-batches: 0
[2019-07-26 09:37:04] [config] after-epochs: 0
[2019-07-26 09:37:04] [config] allow-unk: false
[2019-07-26 09:37:04] [config] beam-size: 12
[2019-07-26 09:37:04] [config] bert-class-symbol: "[CLS]"
[2019-07-26 09:37:04] [config] bert-mask-symbol: "[MASK]"
[2019-07-26 09:37:04] [config] bert-masking-fraction: 0.15
[2019-07-26 09:37:04] [config] bert-sep-symbol: "[SEP]"
[2019-07-26 09:37:04] [config] bert-train-type-embeddings: true
[2019-07-26 09:37:04] [config] bert-type-vocab-size: 2
[2019-07-26 09:37:04] [config] best-deep: false
[2019-07-26 09:37:04] [config] clip-gemm: 0
[2019-07-26 09:37:04] [config] clip-norm: 1
[2019-07-26 09:37:04] [config] cost-type: ce-mean
[2019-07-26 09:37:04] [config] cpu-threads: 0
[2019-07-26 09:37:04] [config] data-weighting: ""
[2019-07-26 09:37:04] [config] data-weighting-type: sentence
[2019-07-26 09:37:04] [config] dec-cell: gru
[2019-07-26 09:37:04] [config] dec-cell-base-depth: 2
[2019-07-26 09:37:04] [config] dec-cell-high-depth: 1
[2019-07-26 09:37:04] [config] dec-depth: 1
[2019-07-26 09:37:04] [config] devices:
[2019-07-26 09:37:04] [config]   - 5
[2019-07-26 09:37:04] [config] dim-emb: 512
[2019-07-26 09:37:04] [config] dim-rnn: 1024
[2019-07-26 09:37:04] [config] dim-vocabs:
[2019-07-26 09:37:04] [config]   - 50000
[2019-07-26 09:37:04] [config]   - 50000
[2019-07-26 09:37:04] [config] disp-first: 0
[2019-07-26 09:37:04] [config] disp-freq: 2000
[2019-07-26 09:37:04] [config] disp-label-counts: false
[2019-07-26 09:37:04] [config] dropout-rnn: 0.2
[2019-07-26 09:37:04] [config] dropout-src: 0.1
[2019-07-26 09:37:04] [config] dropout-trg: 0.1
[2019-07-26 09:37:04] [config] dump-config: ""
[2019-07-26 09:37:04] [config] early-stopping: 5
[2019-07-26 09:37:04] [config] embedding-fix-src: false
[2019-07-26 09:37:04] [config] embedding-fix-trg: false
[2019-07-26 09:37:04] [config] embedding-normalization: false
[2019-07-26 09:37:04] [config] embedding-vectors:
[2019-07-26 09:37:04] [config]   []
[2019-07-26 09:37:04] [config] enc-cell: gru
[2019-07-26 09:37:04] [config] enc-cell-depth: 1
[2019-07-26 09:37:04] [config] enc-depth: 1
[2019-07-26 09:37:04] [config] enc-type: bidirectional
[2019-07-26 09:37:04] [config] exponential-smoothing: 0.0001
[2019-07-26 09:37:04] [config] grad-dropping-momentum: 0
[2019-07-26 09:37:04] [config] grad-dropping-rate: 0
[2019-07-26 09:37:04] [config] grad-dropping-warmup: 100
[2019-07-26 09:37:04] [config] guided-alignment: none
[2019-07-26 09:37:04] [config] guided-alignment-cost: mse
[2019-07-26 09:37:04] [config] guided-alignment-weight: 0.1
[2019-07-26 09:37:04] [config] ignore-model-config: false
[2019-07-26 09:37:04] [config] input-types:
[2019-07-26 09:37:04] [config]   []
[2019-07-26 09:37:04] [config] interpolate-env-vars: false
[2019-07-26 09:37:04] [config] keep-best: false
[2019-07-26 09:37:04] [config] label-smoothing: 0
[2019-07-26 09:37:04] [config] layer-normalization: true
[2019-07-26 09:37:04] [config] learn-rate: 0.0001
[2019-07-26 09:37:04] [config] log: ../experiments/100M_bicleaner_st_lm_w3000/model/train.log
[2019-07-26 09:37:04] [config] log-level: info
[2019-07-26 09:37:04] [config] log-time-zone: ""
[2019-07-26 09:37:04] [config] lr-decay: 0
[2019-07-26 09:37:04] [config] lr-decay-freq: 50000
[2019-07-26 09:37:04] [config] lr-decay-inv-sqrt:
[2019-07-26 09:37:04] [config]   - 0
[2019-07-26 09:37:04] [config] lr-decay-repeat-warmup: false
[2019-07-26 09:37:04] [config] lr-decay-reset-optimizer: false
[2019-07-26 09:37:04] [config] lr-decay-start:
[2019-07-26 09:37:04] [config]   - 10
[2019-07-26 09:37:04] [config]   - 1
[2019-07-26 09:37:04] [config] lr-decay-strategy: epoch+stalled
[2019-07-26 09:37:04] [config] lr-report: false
[2019-07-26 09:37:04] [config] lr-warmup: 0
[2019-07-26 09:37:04] [config] lr-warmup-at-reload: false
[2019-07-26 09:37:04] [config] lr-warmup-cycle: false
[2019-07-26 09:37:04] [config] lr-warmup-start-rate: 0
[2019-07-26 09:37:04] [config] max-length: 50
[2019-07-26 09:37:04] [config] max-length-crop: false
[2019-07-26 09:37:04] [config] max-length-factor: 3
[2019-07-26 09:37:04] [config] maxi-batch: 100
[2019-07-26 09:37:04] [config] maxi-batch-sort: trg
[2019-07-26 09:37:04] [config] mini-batch: 64
[2019-07-26 09:37:04] [config] mini-batch-fit: true
[2019-07-26 09:37:04] [config] mini-batch-fit-step: 10
[2019-07-26 09:37:04] [config] mini-batch-overstuff: 1
[2019-07-26 09:37:04] [config] mini-batch-track-lr: false
[2019-07-26 09:37:04] [config] mini-batch-understuff: 1
[2019-07-26 09:37:04] [config] mini-batch-warmup: 0
[2019-07-26 09:37:04] [config] mini-batch-words: 0
[2019-07-26 09:37:04] [config] mini-batch-words-ref: 0
[2019-07-26 09:37:04] [config] model: ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-26 09:37:04] [config] multi-loss-type: sum
[2019-07-26 09:37:04] [config] multi-node: false
[2019-07-26 09:37:04] [config] multi-node-overlap: true
[2019-07-26 09:37:04] [config] n-best: false
[2019-07-26 09:37:04] [config] no-nccl: false
[2019-07-26 09:37:04] [config] no-reload: false
[2019-07-26 09:37:04] [config] no-restore-corpus: false
[2019-07-26 09:37:04] [config] no-shuffle: false
[2019-07-26 09:37:04] [config] normalize: 1
[2019-07-26 09:37:04] [config] num-devices: 0
[2019-07-26 09:37:04] [config] optimizer: adam
[2019-07-26 09:37:04] [config] optimizer-delay: 1
[2019-07-26 09:37:04] [config] optimizer-params:
[2019-07-26 09:37:04] [config]   []
[2019-07-26 09:37:04] [config] overwrite: false
[2019-07-26 09:37:04] [config] pretrained-model: ""
[2019-07-26 09:37:04] [config] quiet: false
[2019-07-26 09:37:04] [config] quiet-translation: true
[2019-07-26 09:37:04] [config] relative-paths: false
[2019-07-26 09:37:04] [config] right-left: false
[2019-07-26 09:37:04] [config] save-freq: 20000
[2019-07-26 09:37:04] [config] seed: 1111
[2019-07-26 09:37:04] [config] shuffle-in-ram: false
[2019-07-26 09:37:04] [config] skip: false
[2019-07-26 09:37:04] [config] sqlite: ""
[2019-07-26 09:37:04] [config] sqlite-drop: false
[2019-07-26 09:37:04] [config] sync-sgd: true
[2019-07-26 09:37:04] [config] tempdir: .
[2019-07-26 09:37:04] [config] tied-embeddings: false
[2019-07-26 09:37:04] [config] tied-embeddings-all: false
[2019-07-26 09:37:04] [config] tied-embeddings-src: false
[2019-07-26 09:37:04] [config] train-sets:
[2019-07-26 09:37:04] [config]   - ../experiments/100M_bicleaner_st_lm_w3000/data/train.bpe.de
[2019-07-26 09:37:04] [config]   - ../experiments/100M_bicleaner_st_lm_w3000/data/train.bpe.en
[2019-07-26 09:37:04] [config] transformer-aan-activation: swish
[2019-07-26 09:37:04] [config] transformer-aan-depth: 2
[2019-07-26 09:37:04] [config] transformer-aan-nogate: false
[2019-07-26 09:37:04] [config] transformer-decoder-autoreg: self-attention
[2019-07-26 09:37:04] [config] transformer-dim-aan: 2048
[2019-07-26 09:37:04] [config] transformer-dim-ffn: 2048
[2019-07-26 09:37:04] [config] transformer-dropout: 0
[2019-07-26 09:37:04] [config] transformer-dropout-attention: 0
[2019-07-26 09:37:04] [config] transformer-dropout-ffn: 0
[2019-07-26 09:37:04] [config] transformer-ffn-activation: swish
[2019-07-26 09:37:04] [config] transformer-ffn-depth: 2
[2019-07-26 09:37:04] [config] transformer-guided-alignment-layer: last
[2019-07-26 09:37:04] [config] transformer-heads: 8
[2019-07-26 09:37:04] [config] transformer-no-projection: false
[2019-07-26 09:37:04] [config] transformer-postprocess: dan
[2019-07-26 09:37:04] [config] transformer-postprocess-emb: d
[2019-07-26 09:37:04] [config] transformer-preprocess: ""
[2019-07-26 09:37:04] [config] transformer-tied-layers:
[2019-07-26 09:37:04] [config]   []
[2019-07-26 09:37:04] [config] transformer-train-position-embeddings: false
[2019-07-26 09:37:04] [config] type: amun
[2019-07-26 09:37:04] [config] ulr: false
[2019-07-26 09:37:04] [config] ulr-dim-emb: 0
[2019-07-26 09:37:04] [config] ulr-dropout: 0
[2019-07-26 09:37:04] [config] ulr-keys-vectors: ""
[2019-07-26 09:37:04] [config] ulr-query-vectors: ""
[2019-07-26 09:37:04] [config] ulr-softmax-temperature: 1
[2019-07-26 09:37:04] [config] ulr-trainable-transformation: false
[2019-07-26 09:37:04] [config] valid-freq: 20000
[2019-07-26 09:37:04] [config] valid-log: ../experiments/100M_bicleaner_st_lm_w3000/model/valid.log
[2019-07-26 09:37:04] [config] valid-max-length: 1000
[2019-07-26 09:37:04] [config] valid-metrics:
[2019-07-26 09:37:04] [config]   - cross-entropy
[2019-07-26 09:37:04] [config]   - perplexity
[2019-07-26 09:37:04] [config]   - translation
[2019-07-26 09:37:04] [config] valid-mini-batch: 8
[2019-07-26 09:37:04] [config] valid-script-path: ../experiments/100M_bicleaner_st_lm_w3000/score-dev.sh
[2019-07-26 09:37:04] [config] valid-sets:
[2019-07-26 09:37:04] [config]   - ../experiments/100M_bicleaner_st_lm_w3000/data/dev.bpe.de
[2019-07-26 09:37:04] [config]   - ../experiments/100M_bicleaner_st_lm_w3000/data/dev.bpe.en
[2019-07-26 09:37:04] [config] valid-translation-output: ../experiments/100M_bicleaner_st_lm_w3000/model/dev.out
[2019-07-26 09:37:04] [config] vocabs:
[2019-07-26 09:37:04] [config]   - ../experiments/100M_bicleaner_st_lm_w3000/data/train.bpe.de.json
[2019-07-26 09:37:04] [config]   - ../experiments/100M_bicleaner_st_lm_w3000/data/train.bpe.en.json
[2019-07-26 09:37:04] [config] word-penalty: 0
[2019-07-26 09:37:04] [config] workspace: 3000
[2019-07-26 09:37:04] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-26 09:37:04] Using synchronous training
[2019-07-26 09:37:04] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_bicleaner_st_lm_w3000/data/train.bpe.de.json
[2019-07-26 09:37:05] [data] Using unused word id eos for 0
[2019-07-26 09:37:05] [data] Using unused word id UNK for 1
[2019-07-26 09:37:05] [data] Setting vocabulary size for input 0 to 50000
[2019-07-26 09:37:05] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_bicleaner_st_lm_w3000/data/train.bpe.en.json
[2019-07-26 09:37:05] [data] Using unused word id eos for 0
[2019-07-26 09:37:05] [data] Using unused word id UNK for 1
[2019-07-26 09:37:05] [data] Setting vocabulary size for input 1 to 50000
[2019-07-26 09:37:05] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-26 09:37:05] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-26 09:37:06] [memory] Extending reserved space to 3072 MB (device gpu5)
[2019-07-26 09:37:07] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-26 09:37:07] [comm] NCCLCommunicator constructed successfully.
[2019-07-26 09:37:07] [training] Using 1 GPUs
[2019-07-26 09:37:07] [memory] Reserving 422 MB, device gpu5
[2019-07-26 09:37:07] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-26 09:37:07] [memory] Reserving 422 MB, device gpu5
[2019-07-26 09:37:10] [batching] Done. Typical MB size is 4042 target words
[2019-07-26 09:37:10] [memory] Extending reserved space to 3072 MB (device gpu5)
[2019-07-26 09:37:10] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-26 09:37:10] [comm] NCCLCommunicator constructed successfully.
[2019-07-26 09:37:10] [training] Using 1 GPUs
[2019-07-26 09:37:10] Training started
[2019-07-26 09:37:10] [data] Shuffling data
[2019-07-26 09:37:13] [data] Done reading 4864128 sentences
[2019-07-26 09:37:40] [data] Done shuffling 4864128 sentences to temp files
[2019-07-26 09:37:42] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-07-26 09:37:42] [memory] Reserving 422 MB, device gpu5
[2019-07-26 09:37:42] [memory] Reserving 422 MB, device gpu5
[2019-07-26 09:37:42] [memory] Reserving 422 MB, device gpu5
[2019-07-26 09:37:42] [memory] Reserving 844 MB, device gpu5
[2019-07-26 09:43:06] Ep. 1 : Up. 2000 : Sen. 219,148 : Cost 139.17892456 : Time 360.97s : 13624.46 words/s
[2019-07-26 09:48:31] Ep. 1 : Up. 4000 : Sen. 438,485 : Cost 112.06346130 : Time 325.25s : 15169.83 words/s
[2019-07-26 09:53:56] Ep. 1 : Up. 6000 : Sen. 657,124 : Cost 97.00512695 : Time 325.16s : 15131.04 words/s
[2019-07-26 09:59:21] Ep. 1 : Up. 8000 : Sen. 876,569 : Cost 87.02635193 : Time 324.93s : 15156.24 words/s
[2019-07-26 10:04:45] Ep. 1 : Up. 10000 : Sen. 1,094,298 : Cost 80.30594635 : Time 323.35s : 15140.32 words/s
[2019-07-26 10:10:10] Ep. 1 : Up. 12000 : Sen. 1,313,589 : Cost 75.22855377 : Time 325.31s : 15131.42 words/s
[2019-07-26 10:15:35] Ep. 1 : Up. 14000 : Sen. 1,531,571 : Cost 72.22867584 : Time 324.75s : 15100.52 words/s
[2019-07-26 10:20:59] Ep. 1 : Up. 16000 : Sen. 1,750,391 : Cost 69.23148346 : Time 324.33s : 15153.71 words/s
[2019-07-26 10:26:22] Ep. 1 : Up. 18000 : Sen. 1,968,375 : Cost 67.07655334 : Time 323.30s : 15162.11 words/s
[2019-07-26 10:31:46] Ep. 1 : Up. 20000 : Sen. 2,187,378 : Cost 65.26053619 : Time 323.94s : 15202.97 words/s
[2019-07-26 10:31:46] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-26 10:31:51] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter20000.npz
[2019-07-26 10:31:53] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-26 10:31:58] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-26 10:32:15] [valid] Ep. 1 : Up. 20000 : cross-entropy : 66.5347 : new best
[2019-07-26 10:32:22] [valid] Ep. 1 : Up. 20000 : perplexity : 13.743 : new best
[2019-07-26 10:33:20] [valid] Ep. 1 : Up. 20000 : translation : 21.55 : new best
[2019-07-26 10:38:56] Ep. 1 : Up. 22000 : Sen. 2,406,904 : Cost 63.43820953 : Time 429.93s : 11441.66 words/s
[2019-07-26 10:44:30] Ep. 1 : Up. 24000 : Sen. 2,626,075 : Cost 62.43965530 : Time 333.33s : 14777.36 words/s
[2019-07-26 10:50:03] Ep. 1 : Up. 26000 : Sen. 2,845,686 : Cost 60.96897125 : Time 333.46s : 14758.49 words/s
[2019-07-26 10:55:36] Ep. 1 : Up. 28000 : Sen. 3,064,952 : Cost 60.08356094 : Time 332.56s : 14803.82 words/s
[2019-07-26 11:01:54] Ep. 1 : Up. 30000 : Sen. 3,284,157 : Cost 59.30431747 : Time 378.47s : 13016.85 words/s
[2019-07-26 11:08:24] Ep. 1 : Up. 32000 : Sen. 3,503,255 : Cost 58.40933228 : Time 390.31s : 12615.93 words/s
[2019-07-26 11:14:36] Ep. 1 : Up. 34000 : Sen. 3,722,582 : Cost 57.82535553 : Time 371.11s : 13294.31 words/s
[2019-07-26 11:20:48] Ep. 1 : Up. 36000 : Sen. 3,941,576 : Cost 57.08697128 : Time 372.01s : 13225.16 words/s
[2019-07-26 11:26:59] Ep. 1 : Up. 38000 : Sen. 4,159,922 : Cost 56.64861679 : Time 371.05s : 13248.65 words/s
[2019-07-26 11:28:57] Seen 4231167 samples
[2019-07-26 11:28:57] Starting epoch 2
[2019-07-26 11:28:57] [data] Shuffling data
[2019-07-26 11:29:02] [data] Done reading 4864128 sentences
[2019-07-26 11:29:44] [data] Done shuffling 4864128 sentences to temp files
[2019-07-26 11:34:31] Ep. 2 : Up. 40000 : Sen. 147,697 : Cost 55.34817505 : Time 452.51s : 10870.30 words/s
[2019-07-26 11:34:31] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-26 11:34:41] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter40000.npz
[2019-07-26 11:34:44] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-26 11:34:54] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-26 11:35:32] [valid] Ep. 2 : Up. 40000 : cross-entropy : 54.6037 : new best
[2019-07-26 11:35:42] [valid] Ep. 2 : Up. 40000 : perplexity : 8.59016 : new best
[2019-07-26 11:36:56] [valid] Ep. 2 : Up. 40000 : translation : 25.69 : new best
[2019-07-26 11:43:29] Ep. 2 : Up. 42000 : Sen. 367,525 : Cost 54.33961105 : Time 537.70s : 9165.19 words/s
[2019-07-26 11:49:36] Ep. 2 : Up. 44000 : Sen. 585,965 : Cost 54.17227173 : Time 367.51s : 13367.65 words/s
[2019-07-26 11:55:49] Ep. 2 : Up. 46000 : Sen. 804,484 : Cost 53.66099548 : Time 373.18s : 13173.30 words/s
[2019-07-26 12:01:58] Ep. 2 : Up. 48000 : Sen. 1,024,213 : Cost 53.21801376 : Time 368.65s : 13375.58 words/s
[2019-07-26 12:08:06] Ep. 2 : Up. 50000 : Sen. 1,242,693 : Cost 53.04932785 : Time 368.01s : 13330.36 words/s
[2019-07-26 12:14:15] Ep. 2 : Up. 52000 : Sen. 1,459,772 : Cost 52.87547302 : Time 369.11s : 13228.63 words/s
[2019-07-26 12:20:20] Ep. 2 : Up. 54000 : Sen. 1,678,508 : Cost 52.50701141 : Time 364.31s : 13480.13 words/s
[2019-07-26 12:26:31] Ep. 2 : Up. 56000 : Sen. 1,897,735 : Cost 52.06438065 : Time 371.59s : 13232.97 words/s
[2019-07-26 12:32:43] Ep. 2 : Up. 58000 : Sen. 2,116,752 : Cost 52.01299286 : Time 371.83s : 13225.44 words/s
[2019-07-26 12:38:51] Ep. 2 : Up. 60000 : Sen. 2,334,649 : Cost 51.50668716 : Time 368.10s : 13299.60 words/s
[2019-07-26 12:38:51] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-26 12:39:01] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter60000.npz
[2019-07-26 12:39:05] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-26 12:39:14] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-26 12:39:43] [valid] Ep. 2 : Up. 60000 : cross-entropy : 49.9274 : new best
[2019-07-26 12:39:52] [valid] Ep. 2 : Up. 60000 : perplexity : 7.14518 : new best
[2019-07-26 12:41:06] [valid] Ep. 2 : Up. 60000 : translation : 27.34 : new best
[2019-07-26 12:47:22] Ep. 2 : Up. 62000 : Sen. 2,553,366 : Cost 51.61831665 : Time 510.43s : 9637.61 words/s
[2019-07-26 12:53:35] Ep. 2 : Up. 64000 : Sen. 2,772,422 : Cost 51.16772842 : Time 373.53s : 13195.91 words/s
[2019-07-26 12:59:44] Ep. 2 : Up. 66000 : Sen. 2,990,984 : Cost 50.79844666 : Time 369.29s : 13306.26 words/s
[2019-07-26 13:05:56] Ep. 2 : Up. 68000 : Sen. 3,210,212 : Cost 50.53858185 : Time 371.85s : 13241.16 words/s
[2019-07-26 13:12:05] Ep. 2 : Up. 70000 : Sen. 3,427,914 : Cost 50.29976654 : Time 368.48s : 13264.52 words/s
[2019-07-26 13:18:14] Ep. 2 : Up. 72000 : Sen. 3,646,334 : Cost 50.51188660 : Time 369.15s : 13331.61 words/s
[2019-07-26 13:24:23] Ep. 2 : Up. 74000 : Sen. 3,864,698 : Cost 49.87444687 : Time 369.18s : 13282.20 words/s
[2019-07-26 13:30:27] Ep. 2 : Up. 76000 : Sen. 4,083,020 : Cost 49.92415619 : Time 364.28s : 13461.21 words/s
[2019-07-26 13:34:34] Seen 4231167 samples
[2019-07-26 13:34:34] Starting epoch 3
[2019-07-26 13:34:34] [data] Shuffling data
[2019-07-26 13:34:40] [data] Done reading 4864128 sentences
[2019-07-26 13:35:21] [data] Done shuffling 4864128 sentences to temp files
[2019-07-26 13:37:24] Ep. 3 : Up. 78000 : Sen. 71,436 : Cost 49.41852951 : Time 416.54s : 11863.83 words/s
[2019-07-26 13:43:34] Ep. 3 : Up. 80000 : Sen. 289,693 : Cost 48.49018478 : Time 369.96s : 13276.42 words/s
[2019-07-26 13:43:34] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-26 13:43:42] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter80000.npz
[2019-07-26 13:43:46] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-26 13:43:55] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-26 13:44:25] [valid] Ep. 3 : Up. 80000 : cross-entropy : 47.0911 : new best
[2019-07-26 13:44:34] [valid] Ep. 3 : Up. 80000 : perplexity : 6.38993 : new best
[2019-07-26 13:45:48] [valid] Ep. 3 : Up. 80000 : translation : 28.31 : new best
[2019-07-26 13:52:02] Ep. 3 : Up. 82000 : Sen. 507,472 : Cost 48.30918503 : Time 507.95s : 9625.99 words/s
[2019-07-26 13:58:12] Ep. 3 : Up. 84000 : Sen. 727,551 : Cost 48.13607407 : Time 370.60s : 13354.55 words/s
[2019-07-26 14:34:21] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-26 14:34:21] [marian] Running on bil as process 2292 with command line:
[2019-07-26 14:34:21] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz -T . --devices 5 --train-sets ../experiments/100M_bicleaner_st_lm_w3000/data/train.bpe.de ../experiments/100M_bicleaner_st_lm_w3000/data/train.bpe.en --vocabs ../experiments/100M_bicleaner_st_lm_w3000/data/train.bpe.de.json ../experiments/100M_bicleaner_st_lm_w3000/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_bicleaner_st_lm_w3000/data/dev.bpe.de ../experiments/100M_bicleaner_st_lm_w3000/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_bicleaner_st_lm_w3000/model/dev.out --valid-script-path ../experiments/100M_bicleaner_st_lm_w3000/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_bicleaner_st_lm_w3000/model/train.log --valid-log ../experiments/100M_bicleaner_st_lm_w3000/model/valid.log
[2019-07-26 14:34:21] [config] after-batches: 0
[2019-07-26 14:34:21] [config] after-epochs: 0
[2019-07-26 14:34:21] [config] allow-unk: false
[2019-07-26 14:34:21] [config] beam-size: 12
[2019-07-26 14:34:21] [config] bert-class-symbol: "[CLS]"
[2019-07-26 14:34:21] [config] bert-mask-symbol: "[MASK]"
[2019-07-26 14:34:21] [config] bert-masking-fraction: 0.15
[2019-07-26 14:34:21] [config] bert-sep-symbol: "[SEP]"
[2019-07-26 14:34:21] [config] bert-train-type-embeddings: true
[2019-07-26 14:34:21] [config] bert-type-vocab-size: 2
[2019-07-26 14:34:21] [config] best-deep: false
[2019-07-26 14:34:21] [config] clip-gemm: 0
[2019-07-26 14:34:21] [config] clip-norm: 1
[2019-07-26 14:34:21] [config] cost-type: ce-mean
[2019-07-26 14:34:21] [config] cpu-threads: 0
[2019-07-26 14:34:21] [config] data-weighting: ""
[2019-07-26 14:34:21] [config] data-weighting-type: sentence
[2019-07-26 14:34:21] [config] dec-cell: gru
[2019-07-26 14:34:21] [config] dec-cell-base-depth: 2
[2019-07-26 14:34:21] [config] dec-cell-high-depth: 1
[2019-07-26 14:34:21] [config] dec-depth: 1
[2019-07-26 14:34:21] [config] devices:
[2019-07-26 14:34:21] [config]   - 5
[2019-07-26 14:34:21] [config] dim-emb: 512
[2019-07-26 14:34:21] [config] dim-rnn: 1024
[2019-07-26 14:34:21] [config] dim-vocabs:
[2019-07-26 14:34:21] [config]   - 50000
[2019-07-26 14:34:21] [config]   - 50000
[2019-07-26 14:34:21] [config] disp-first: 0
[2019-07-26 14:34:21] [config] disp-freq: 2000
[2019-07-26 14:34:21] [config] disp-label-counts: false
[2019-07-26 14:34:21] [config] dropout-rnn: 0.2
[2019-07-26 14:34:21] [config] dropout-src: 0.1
[2019-07-26 14:34:21] [config] dropout-trg: 0.1
[2019-07-26 14:34:21] [config] dump-config: ""
[2019-07-26 14:34:21] [config] early-stopping: 5
[2019-07-26 14:34:21] [config] embedding-fix-src: false
[2019-07-26 14:34:21] [config] embedding-fix-trg: false
[2019-07-26 14:34:21] [config] embedding-normalization: false
[2019-07-26 14:34:21] [config] embedding-vectors:
[2019-07-26 14:34:21] [config]   []
[2019-07-26 14:34:21] [config] enc-cell: gru
[2019-07-26 14:34:21] [config] enc-cell-depth: 1
[2019-07-26 14:34:21] [config] enc-depth: 1
[2019-07-26 14:34:21] [config] enc-type: bidirectional
[2019-07-26 14:34:21] [config] exponential-smoothing: 0.0001
[2019-07-26 14:34:21] [config] grad-dropping-momentum: 0
[2019-07-26 14:34:21] [config] grad-dropping-rate: 0
[2019-07-26 14:34:21] [config] grad-dropping-warmup: 100
[2019-07-26 14:34:21] [config] guided-alignment: none
[2019-07-26 14:34:21] [config] guided-alignment-cost: mse
[2019-07-26 14:34:21] [config] guided-alignment-weight: 0.1
[2019-07-26 14:34:21] [config] ignore-model-config: false
[2019-07-26 14:34:21] [config] input-types:
[2019-07-26 14:34:21] [config]   []
[2019-07-26 14:34:21] [config] interpolate-env-vars: false
[2019-07-26 14:34:21] [config] keep-best: false
[2019-07-26 14:34:21] [config] label-smoothing: 0
[2019-07-26 14:34:21] [config] layer-normalization: true
[2019-07-26 14:34:21] [config] learn-rate: 0.0001
[2019-07-26 14:34:21] [config] log: ../experiments/100M_bicleaner_st_lm_w3000/model/train.log
[2019-07-26 14:34:21] [config] log-level: info
[2019-07-26 14:34:21] [config] log-time-zone: ""
[2019-07-26 14:34:21] [config] lr-decay: 0
[2019-07-26 14:34:21] [config] lr-decay-freq: 50000
[2019-07-26 14:34:21] [config] lr-decay-inv-sqrt:
[2019-07-26 14:34:21] [config]   - 0
[2019-07-26 14:34:21] [config] lr-decay-repeat-warmup: false
[2019-07-26 14:34:21] [config] lr-decay-reset-optimizer: false
[2019-07-26 14:34:21] [config] lr-decay-start:
[2019-07-26 14:34:21] [config]   - 10
[2019-07-26 14:34:21] [config]   - 1
[2019-07-26 14:34:21] [config] lr-decay-strategy: epoch+stalled
[2019-07-26 14:34:21] [config] lr-report: false
[2019-07-26 14:34:21] [config] lr-warmup: 0
[2019-07-26 14:34:21] [config] lr-warmup-at-reload: false
[2019-07-26 14:34:21] [config] lr-warmup-cycle: false
[2019-07-26 14:34:21] [config] lr-warmup-start-rate: 0
[2019-07-26 14:34:21] [config] max-length: 50
[2019-07-26 14:34:21] [config] max-length-crop: false
[2019-07-26 14:34:21] [config] max-length-factor: 3
[2019-07-26 14:34:21] [config] maxi-batch: 100
[2019-07-26 14:34:21] [config] maxi-batch-sort: trg
[2019-07-26 14:34:21] [config] mini-batch: 64
[2019-07-26 14:34:21] [config] mini-batch-fit: true
[2019-07-26 14:34:21] [config] mini-batch-fit-step: 10
[2019-07-26 14:34:21] [config] mini-batch-overstuff: 1
[2019-07-26 14:34:21] [config] mini-batch-track-lr: false
[2019-07-26 14:34:21] [config] mini-batch-understuff: 1
[2019-07-26 14:34:21] [config] mini-batch-warmup: 0
[2019-07-26 14:34:21] [config] mini-batch-words: 0
[2019-07-26 14:34:21] [config] mini-batch-words-ref: 0
[2019-07-26 14:34:21] [config] model: ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-26 14:34:21] [config] multi-loss-type: sum
[2019-07-26 14:34:21] [config] multi-node: false
[2019-07-26 14:34:21] [config] multi-node-overlap: true
[2019-07-26 14:34:21] [config] n-best: false
[2019-07-26 14:34:21] [config] no-nccl: false
[2019-07-26 14:34:21] [config] no-reload: false
[2019-07-26 14:34:21] [config] no-restore-corpus: false
[2019-07-26 14:34:21] [config] no-shuffle: false
[2019-07-26 14:34:21] [config] normalize: 1
[2019-07-26 14:34:21] [config] num-devices: 0
[2019-07-26 14:34:21] [config] optimizer: adam
[2019-07-26 14:34:21] [config] optimizer-delay: 1
[2019-07-26 14:34:21] [config] optimizer-params:
[2019-07-26 14:34:21] [config]   []
[2019-07-26 14:34:21] [config] overwrite: false
[2019-07-26 14:34:21] [config] pretrained-model: ""
[2019-07-26 14:34:21] [config] quiet: false
[2019-07-26 14:34:21] [config] quiet-translation: true
[2019-07-26 14:34:21] [config] relative-paths: false
[2019-07-26 14:34:21] [config] right-left: false
[2019-07-26 14:34:21] [config] save-freq: 20000
[2019-07-26 14:34:21] [config] seed: 1111
[2019-07-26 14:34:21] [config] shuffle-in-ram: false
[2019-07-26 14:34:21] [config] skip: false
[2019-07-26 14:34:21] [config] sqlite: ""
[2019-07-26 14:34:21] [config] sqlite-drop: false
[2019-07-26 14:34:21] [config] sync-sgd: true
[2019-07-26 14:34:21] [config] tempdir: .
[2019-07-26 14:34:21] [config] tied-embeddings: false
[2019-07-26 14:34:21] [config] tied-embeddings-all: false
[2019-07-26 14:34:21] [config] tied-embeddings-src: false
[2019-07-26 14:34:21] [config] train-sets:
[2019-07-26 14:34:21] [config]   - ../experiments/100M_bicleaner_st_lm_w3000/data/train.bpe.de
[2019-07-26 14:34:21] [config]   - ../experiments/100M_bicleaner_st_lm_w3000/data/train.bpe.en
[2019-07-26 14:34:21] [config] transformer-aan-activation: swish
[2019-07-26 14:34:21] [config] transformer-aan-depth: 2
[2019-07-26 14:34:21] [config] transformer-aan-nogate: false
[2019-07-26 14:34:21] [config] transformer-decoder-autoreg: self-attention
[2019-07-26 14:34:21] [config] transformer-dim-aan: 2048
[2019-07-26 14:34:21] [config] transformer-dim-ffn: 2048
[2019-07-26 14:34:21] [config] transformer-dropout: 0
[2019-07-26 14:34:21] [config] transformer-dropout-attention: 0
[2019-07-26 14:34:21] [config] transformer-dropout-ffn: 0
[2019-07-26 14:34:21] [config] transformer-ffn-activation: swish
[2019-07-26 14:34:21] [config] transformer-ffn-depth: 2
[2019-07-26 14:34:21] [config] transformer-guided-alignment-layer: last
[2019-07-26 14:34:21] [config] transformer-heads: 8
[2019-07-26 14:34:21] [config] transformer-no-projection: false
[2019-07-26 14:34:21] [config] transformer-postprocess: dan
[2019-07-26 14:34:21] [config] transformer-postprocess-emb: d
[2019-07-26 14:34:21] [config] transformer-preprocess: ""
[2019-07-26 14:34:21] [config] transformer-tied-layers:
[2019-07-26 14:34:21] [config]   []
[2019-07-26 14:34:21] [config] transformer-train-position-embeddings: false
[2019-07-26 14:34:21] [config] type: amun
[2019-07-26 14:34:21] [config] ulr: false
[2019-07-26 14:34:21] [config] ulr-dim-emb: 0
[2019-07-26 14:34:21] [config] ulr-dropout: 0
[2019-07-26 14:34:21] [config] ulr-keys-vectors: ""
[2019-07-26 14:34:21] [config] ulr-query-vectors: ""
[2019-07-26 14:34:21] [config] ulr-softmax-temperature: 1
[2019-07-26 14:34:21] [config] ulr-trainable-transformation: false
[2019-07-26 14:34:21] [config] valid-freq: 20000
[2019-07-26 14:34:21] [config] valid-log: ../experiments/100M_bicleaner_st_lm_w3000/model/valid.log
[2019-07-26 14:34:21] [config] valid-max-length: 1000
[2019-07-26 14:34:21] [config] valid-metrics:
[2019-07-26 14:34:21] [config]   - cross-entropy
[2019-07-26 14:34:21] [config]   - perplexity
[2019-07-26 14:34:21] [config]   - translation
[2019-07-26 14:34:21] [config] valid-mini-batch: 8
[2019-07-26 14:34:21] [config] valid-script-path: ../experiments/100M_bicleaner_st_lm_w3000/score-dev.sh
[2019-07-26 14:34:21] [config] valid-sets:
[2019-07-26 14:34:21] [config]   - ../experiments/100M_bicleaner_st_lm_w3000/data/dev.bpe.de
[2019-07-26 14:34:21] [config]   - ../experiments/100M_bicleaner_st_lm_w3000/data/dev.bpe.en
[2019-07-26 14:34:21] [config] valid-translation-output: ../experiments/100M_bicleaner_st_lm_w3000/model/dev.out
[2019-07-26 14:34:21] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-26 14:34:21] [config] vocabs:
[2019-07-26 14:34:21] [config]   - ../experiments/100M_bicleaner_st_lm_w3000/data/train.bpe.de.json
[2019-07-26 14:34:21] [config]   - ../experiments/100M_bicleaner_st_lm_w3000/data/train.bpe.en.json
[2019-07-26 14:34:21] [config] word-penalty: 0
[2019-07-26 14:34:21] [config] workspace: 3000
[2019-07-26 14:34:21] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-26 14:34:21] Using synchronous training
[2019-07-26 14:34:21] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_bicleaner_st_lm_w3000/data/train.bpe.de.json
[2019-07-26 14:34:22] [data] Using unused word id eos for 0
[2019-07-26 14:34:22] [data] Using unused word id UNK for 1
[2019-07-26 14:34:22] [data] Setting vocabulary size for input 0 to 50000
[2019-07-26 14:34:22] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_bicleaner_st_lm_w3000/data/train.bpe.en.json
[2019-07-26 14:34:22] [data] Using unused word id eos for 0
[2019-07-26 14:34:22] [data] Using unused word id UNK for 1
[2019-07-26 14:34:22] [data] Setting vocabulary size for input 1 to 50000
[2019-07-26 14:34:22] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-26 14:34:22] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-26 14:34:23] [memory] Extending reserved space to 3072 MB (device gpu5)
[2019-07-26 14:34:23] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-26 14:34:23] [comm] NCCLCommunicator constructed successfully.
[2019-07-26 14:34:23] [training] Using 1 GPUs
[2019-07-26 14:34:23] [memory] Reserving 422 MB, device gpu5
[2019-07-26 14:34:23] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-26 14:34:23] [memory] Reserving 422 MB, device gpu5
[2019-07-26 14:34:26] [batching] Done. Typical MB size is 4042 target words
[2019-07-26 14:34:26] [memory] Extending reserved space to 3072 MB (device gpu5)
[2019-07-26 14:34:26] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-26 14:34:26] [comm] NCCLCommunicator constructed successfully.
[2019-07-26 14:34:26] [training] Using 1 GPUs
[2019-07-26 14:34:26] Loading model from ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-26 14:34:29] Loading Adam parameters from ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-26 14:34:32] [memory] Reserving 844 MB, device gpu5
[2019-07-26 14:34:33] [training] Model reloaded from ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-26 14:34:33] [data] Restoring the corpus state to epoch 3, batch 80000
[2019-07-26 14:34:33] [data] Shuffling data
[2019-07-26 14:34:36] [data] Done reading 4864128 sentences
[2019-07-26 14:34:56] [data] Done shuffling 4864128 sentences to temp files
[2019-07-26 14:35:06] Training started
[2019-07-26 14:35:06] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-07-26 14:35:06] [memory] Reserving 422 MB, device gpu5
[2019-07-26 14:35:07] [memory] Reserving 422 MB, device gpu5
[2019-07-26 14:35:07] Loading model from ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-26 14:35:10] [memory] Reserving 422 MB, device cpu0
[2019-07-26 14:35:10] [memory] Reserving 422 MB, device gpu5
[2019-07-26 14:40:30] Ep. 3 : Up. 82000 : Sen. 507,472 : Cost 48.81252670 : Time 367.62s : 13300.37 words/s
[2019-07-26 14:45:53] Ep. 3 : Up. 84000 : Sen. 727,551 : Cost 48.40742493 : Time 323.16s : 15315.22 words/s
[2019-07-26 14:51:16] Ep. 3 : Up. 86000 : Sen. 947,577 : Cost 48.09166336 : Time 322.87s : 15317.47 words/s
[2019-07-26 14:56:35] Ep. 3 : Up. 88000 : Sen. 1,165,214 : Cost 47.94937515 : Time 319.83s : 15301.40 words/s
[2019-07-26 15:01:57] Ep. 3 : Up. 90000 : Sen. 1,384,234 : Cost 47.79541779 : Time 321.49s : 15277.72 words/s
[2019-07-26 15:07:18] Ep. 3 : Up. 92000 : Sen. 1,602,331 : Cost 47.80482864 : Time 321.04s : 15260.90 words/s
[2019-07-26 15:12:41] Ep. 3 : Up. 94000 : Sen. 1,821,781 : Cost 47.57396317 : Time 322.64s : 15240.44 words/s
[2019-07-26 15:18:03] Ep. 3 : Up. 96000 : Sen. 2,040,565 : Cost 47.73111725 : Time 322.35s : 15244.13 words/s
[2019-07-26 15:23:24] Ep. 3 : Up. 98000 : Sen. 2,259,065 : Cost 47.53264999 : Time 321.38s : 15298.56 words/s
[2019-07-26 15:28:47] Ep. 3 : Up. 100000 : Sen. 2,478,294 : Cost 47.32807159 : Time 323.01s : 15246.83 words/s
[2019-07-26 15:28:47] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-26 15:28:52] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter100000.npz
[2019-07-26 15:28:54] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-26 15:28:59] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-26 15:29:17] [valid] Ep. 3 : Up. 100000 : cross-entropy : 45.4025 : new best
[2019-07-26 15:29:23] [valid] Ep. 3 : Up. 100000 : perplexity : 5.9788 : new best
[2019-07-26 15:30:23] [valid] Ep. 3 : Up. 100000 : translation : 28.78 : new best
[2019-07-26 15:37:11] Ep. 3 : Up. 102000 : Sen. 2,697,117 : Cost 47.43720627 : Time 503.71s : 9765.72 words/s
[2019-07-26 15:43:22] Ep. 3 : Up. 104000 : Sen. 2,916,217 : Cost 47.22491837 : Time 370.53s : 13261.40 words/s
[2019-07-26 15:49:23] Ep. 3 : Up. 106000 : Sen. 3,134,818 : Cost 47.30147552 : Time 361.56s : 13605.66 words/s
[2019-07-26 15:55:24] Ep. 3 : Up. 108000 : Sen. 3,353,117 : Cost 47.27857971 : Time 361.13s : 13615.21 words/s
[2019-07-26 16:01:24] Ep. 3 : Up. 110000 : Sen. 3,571,491 : Cost 46.94623947 : Time 360.22s : 13626.03 words/s
[2019-07-26 16:07:25] Ep. 3 : Up. 112000 : Sen. 3,791,174 : Cost 46.75856018 : Time 360.08s : 13678.59 words/s
[2019-07-26 16:13:28] Ep. 3 : Up. 114000 : Sen. 4,010,152 : Cost 46.65312195 : Time 363.52s : 13546.28 words/s
[2019-07-26 16:19:31] Ep. 3 : Up. 116000 : Sen. 4,230,556 : Cost 46.63954926 : Time 362.83s : 13656.92 words/s
[2019-07-26 16:19:32] Seen 4231167 samples
[2019-07-26 16:19:32] Starting epoch 4
[2019-07-26 16:19:32] [data] Shuffling data
[2019-07-26 16:19:37] [data] Done reading 4864128 sentences
[2019-07-26 16:20:11] [data] Done shuffling 4864128 sentences to temp files
[2019-07-26 16:26:13] Ep. 4 : Up. 118000 : Sen. 218,325 : Cost 45.45195007 : Time 402.44s : 12227.49 words/s
[2019-07-26 16:32:14] Ep. 4 : Up. 120000 : Sen. 436,251 : Cost 45.50214767 : Time 360.54s : 13581.62 words/s
[2019-07-26 16:32:14] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-26 16:32:21] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter120000.npz
[2019-07-26 16:32:25] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-26 16:32:33] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-26 16:32:57] [valid] Ep. 4 : Up. 120000 : cross-entropy : 43.9856 : new best
[2019-07-26 16:33:06] [valid] Ep. 4 : Up. 120000 : perplexity : 5.65427 : new best
[2019-07-26 16:34:16] [valid] Ep. 4 : Up. 120000 : translation : 29.1 : new best
[2019-07-26 16:40:22] Ep. 4 : Up. 122000 : Sen. 655,394 : Cost 45.26417542 : Time 487.95s : 10063.62 words/s
[2019-07-26 16:46:20] Ep. 4 : Up. 124000 : Sen. 873,635 : Cost 45.46643829 : Time 358.44s : 13684.66 words/s
[2019-07-26 16:52:22] Ep. 4 : Up. 126000 : Sen. 1,093,258 : Cost 45.24681091 : Time 361.41s : 13623.78 words/s
[2019-07-26 16:58:26] Ep. 4 : Up. 128000 : Sen. 1,312,772 : Cost 45.53709030 : Time 364.51s : 13539.81 words/s
[2019-07-26 17:04:29] Ep. 4 : Up. 130000 : Sen. 1,530,846 : Cost 45.32363892 : Time 362.66s : 13503.06 words/s
[2019-07-26 17:11:10] Ep. 4 : Up. 132000 : Sen. 1,749,467 : Cost 45.26018906 : Time 401.58s : 12253.61 words/s
[2019-07-26 17:17:56] Ep. 4 : Up. 134000 : Sen. 1,968,429 : Cost 45.19898605 : Time 405.39s : 12105.60 words/s
[2019-07-26 17:24:42] Ep. 4 : Up. 136000 : Sen. 2,186,886 : Cost 45.12218857 : Time 406.13s : 12110.34 words/s
[2019-07-26 17:31:26] Ep. 4 : Up. 138000 : Sen. 2,406,220 : Cost 44.92462540 : Time 403.66s : 12188.67 words/s
[2019-07-26 17:38:12] Ep. 4 : Up. 140000 : Sen. 2,624,983 : Cost 45.24591446 : Time 406.58s : 12112.76 words/s
[2019-07-26 17:38:12] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-26 17:38:20] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter140000.npz
[2019-07-26 17:38:23] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-26 17:38:33] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-26 17:39:04] [valid] Ep. 4 : Up. 140000 : cross-entropy : 43.096 : new best
[2019-07-26 17:39:13] [valid] Ep. 4 : Up. 140000 : perplexity : 5.45959 : new best
[2019-07-26 17:40:38] [valid] Ep. 4 : Up. 140000 : translation : 29.31 : new best
[2019-07-26 17:47:25] Ep. 4 : Up. 142000 : Sen. 2,843,970 : Cost 45.14091110 : Time 552.95s : 8897.52 words/s
[2019-07-26 17:54:04] Ep. 4 : Up. 144000 : Sen. 3,062,568 : Cost 45.23224640 : Time 398.67s : 12329.12 words/s
[2019-07-26 18:00:49] Ep. 4 : Up. 146000 : Sen. 3,282,012 : Cost 45.18255997 : Time 405.72s : 12145.06 words/s
[2019-07-26 18:07:10] Ep. 4 : Up. 148000 : Sen. 3,500,878 : Cost 45.05485535 : Time 380.71s : 12918.98 words/s
[2019-07-26 18:13:22] Ep. 4 : Up. 150000 : Sen. 3,720,268 : Cost 44.92249298 : Time 372.23s : 13238.88 words/s
[2019-07-26 18:20:01] Ep. 4 : Up. 152000 : Sen. 3,938,847 : Cost 44.86504745 : Time 398.60s : 12326.41 words/s
[2019-07-26 18:26:45] Ep. 4 : Up. 154000 : Sen. 4,157,204 : Cost 44.92931366 : Time 404.11s : 12165.90 words/s
[2019-07-26 18:28:56] Seen 4231167 samples
[2019-07-26 18:28:56] Starting epoch 5
[2019-07-26 18:28:56] [data] Shuffling data
[2019-07-26 18:29:02] [data] Done reading 4864128 sentences
[2019-07-26 18:29:45] [data] Done shuffling 4864128 sentences to temp files
[2019-07-26 18:33:47] Ep. 5 : Up. 156000 : Sen. 145,167 : Cost 44.06670380 : Time 421.38s : 11674.77 words/s
[2019-07-26 18:39:49] Ep. 5 : Up. 158000 : Sen. 363,021 : Cost 43.77789688 : Time 362.19s : 13545.05 words/s
[2019-07-26 18:45:52] Ep. 5 : Up. 160000 : Sen. 581,508 : Cost 43.57087326 : Time 362.87s : 13480.70 words/s
[2019-07-26 18:45:52] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-26 18:46:00] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter160000.npz
[2019-07-26 18:46:03] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-26 18:46:12] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-26 18:46:38] [valid] Ep. 5 : Up. 160000 : cross-entropy : 42.331 : new best
[2019-07-26 18:46:47] [valid] Ep. 5 : Up. 160000 : perplexity : 5.29756 : new best
[2019-07-26 18:47:58] [valid] Ep. 5 : Up. 160000 : translation : 29.58 : new best
[2019-07-26 18:54:06] Ep. 5 : Up. 162000 : Sen. 800,283 : Cost 43.85393143 : Time 494.37s : 9947.87 words/s
[2019-07-26 19:00:08] Ep. 5 : Up. 164000 : Sen. 1,019,431 : Cost 43.98604584 : Time 362.54s : 13596.75 words/s
[2019-07-26 19:05:56] Ep. 5 : Up. 166000 : Sen. 1,238,718 : Cost 43.92972565 : Time 347.76s : 14197.47 words/s
[2019-07-26 19:11:43] Ep. 5 : Up. 168000 : Sen. 1,457,205 : Cost 43.67735672 : Time 346.64s : 14160.42 words/s
[2019-07-26 19:17:29] Ep. 5 : Up. 170000 : Sen. 1,675,725 : Cost 43.60686493 : Time 345.62s : 14206.47 words/s
[2019-07-26 19:23:18] Ep. 5 : Up. 172000 : Sen. 1,895,888 : Cost 43.60064697 : Time 349.65s : 14115.29 words/s
[2019-07-26 19:29:06] Ep. 5 : Up. 174000 : Sen. 2,114,841 : Cost 43.56073380 : Time 347.74s : 14152.84 words/s
[2019-07-26 19:34:54] Ep. 5 : Up. 176000 : Sen. 2,333,989 : Cost 43.67277527 : Time 348.27s : 14130.68 words/s
[2019-07-26 19:40:40] Ep. 5 : Up. 178000 : Sen. 2,552,822 : Cost 43.62773514 : Time 345.93s : 14199.74 words/s
[2019-07-26 19:46:29] Ep. 5 : Up. 180000 : Sen. 2,772,377 : Cost 43.70773697 : Time 348.68s : 14141.10 words/s
[2019-07-26 19:46:29] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-26 19:46:35] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter180000.npz
[2019-07-26 19:46:38] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-26 19:46:45] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-26 19:47:08] [valid] Ep. 5 : Up. 180000 : cross-entropy : 41.7738 : new best
[2019-07-26 19:47:16] [valid] Ep. 5 : Up. 180000 : perplexity : 5.18256 : new best
[2019-07-26 19:48:19] [valid] Ep. 5 : Up. 180000 : translation : 29.78 : new best
[2019-07-26 19:54:11] Ep. 5 : Up. 182000 : Sen. 2,991,646 : Cost 43.81326675 : Time 462.01s : 10675.80 words/s
[2019-07-26 19:59:58] Ep. 5 : Up. 184000 : Sen. 3,209,316 : Cost 43.67281723 : Time 347.03s : 14117.60 words/s
[2019-07-26 20:05:39] Ep. 5 : Up. 186000 : Sen. 3,428,900 : Cost 43.58674622 : Time 340.94s : 14438.51 words/s
[2019-07-26 20:11:11] Ep. 5 : Up. 188000 : Sen. 3,647,090 : Cost 43.81733322 : Time 332.45s : 14769.65 words/s
[2019-07-26 20:16:38] Ep. 5 : Up. 190000 : Sen. 3,865,342 : Cost 43.68415451 : Time 326.56s : 15033.88 words/s
[2019-07-26 20:21:59] Ep. 5 : Up. 192000 : Sen. 4,083,902 : Cost 43.44498062 : Time 320.88s : 15301.88 words/s
[2019-07-26 20:25:36] Seen 4231167 samples
[2019-07-26 20:25:36] Starting epoch 6
[2019-07-26 20:25:36] [data] Shuffling data
[2019-07-26 20:25:39] [data] Done reading 4864128 sentences
[2019-07-26 20:25:59] [data] Done shuffling 4864128 sentences to temp files
[2019-07-26 20:27:44] Ep. 6 : Up. 194000 : Sen. 70,573 : Cost 43.14665985 : Time 344.98s : 14193.53 words/s
[2019-07-26 20:33:10] Ep. 6 : Up. 196000 : Sen. 291,051 : Cost 42.29277802 : Time 326.77s : 15139.90 words/s
[2019-07-26 20:38:36] Ep. 6 : Up. 198000 : Sen. 509,961 : Cost 42.32915878 : Time 325.51s : 15108.52 words/s
[2019-07-26 20:43:59] Ep. 6 : Up. 200000 : Sen. 728,091 : Cost 42.45412064 : Time 322.84s : 15192.46 words/s
[2019-07-26 20:43:59] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-26 20:44:04] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter200000.npz
[2019-07-26 20:44:06] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-26 20:44:11] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-26 20:44:29] [valid] Ep. 6 : Up. 200000 : cross-entropy : 41.2359 : new best
[2019-07-26 20:44:36] [valid] Ep. 6 : Up. 200000 : perplexity : 5.07391 : new best
[2019-07-26 20:45:27] [valid] Ep. 6 : Up. 200000 : translation : 29.88 : new best
[2019-07-26 20:50:53] Ep. 6 : Up. 202000 : Sen. 947,413 : Cost 42.67648315 : Time 414.59s : 11914.57 words/s
[2019-07-26 20:56:17] Ep. 6 : Up. 204000 : Sen. 1,167,098 : Cost 42.50823593 : Time 323.52s : 15257.42 words/s
[2019-07-26 21:01:40] Ep. 6 : Up. 206000 : Sen. 1,386,363 : Cost 42.64714432 : Time 323.07s : 15252.80 words/s
[2019-07-26 21:07:02] Ep. 6 : Up. 208000 : Sen. 1,604,299 : Cost 42.49427795 : Time 321.92s : 15193.37 words/s
[2019-07-26 21:12:24] Ep. 6 : Up. 210000 : Sen. 1,822,176 : Cost 42.50209045 : Time 322.30s : 15180.62 words/s
[2019-07-26 21:17:48] Ep. 6 : Up. 212000 : Sen. 2,041,504 : Cost 42.73468018 : Time 324.16s : 15210.16 words/s
[2019-07-26 21:23:11] Ep. 6 : Up. 214000 : Sen. 2,260,318 : Cost 42.77314377 : Time 322.98s : 15232.58 words/s
[2019-07-26 21:28:34] Ep. 6 : Up. 216000 : Sen. 2,479,688 : Cost 42.43084717 : Time 322.88s : 15246.98 words/s
[2019-07-26 21:33:58] Ep. 6 : Up. 218000 : Sen. 2,698,015 : Cost 42.74452209 : Time 323.77s : 15191.07 words/s
[2019-07-26 21:39:22] Ep. 6 : Up. 220000 : Sen. 2,916,462 : Cost 42.85226059 : Time 323.61s : 15219.75 words/s
[2019-07-26 21:39:22] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-26 21:39:27] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter220000.npz
[2019-07-26 21:39:29] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-26 21:39:34] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-26 21:39:52] [valid] Ep. 6 : Up. 220000 : cross-entropy : 40.8681 : new best
[2019-07-26 21:39:58] [valid] Ep. 6 : Up. 220000 : perplexity : 5.00095 : new best
[2019-07-26 21:40:49] [valid] Ep. 6 : Up. 220000 : translation : 30.01 : new best
[2019-07-26 21:46:12] Ep. 6 : Up. 222000 : Sen. 3,135,006 : Cost 42.38440704 : Time 410.35s : 11925.73 words/s
[2019-07-26 21:51:33] Ep. 6 : Up. 224000 : Sen. 3,353,805 : Cost 42.48577118 : Time 321.49s : 15267.54 words/s
[2019-07-26 21:56:55] Ep. 6 : Up. 226000 : Sen. 3,573,207 : Cost 42.51944351 : Time 322.09s : 15282.39 words/s
[2019-07-26 22:02:18] Ep. 6 : Up. 228000 : Sen. 3,791,374 : Cost 42.69260788 : Time 322.79s : 15206.86 words/s
[2019-07-26 22:07:41] Ep. 6 : Up. 230000 : Sen. 4,010,801 : Cost 42.34017563 : Time 322.61s : 15249.55 words/s
[2019-07-26 22:13:03] Ep. 6 : Up. 232000 : Sen. 4,229,212 : Cost 42.49906921 : Time 322.16s : 15255.91 words/s
[2019-07-26 22:13:06] Seen 4231167 samples
[2019-07-26 22:13:06] Starting epoch 7
[2019-07-26 22:13:06] [data] Shuffling data
[2019-07-26 22:13:09] [data] Done reading 4864128 sentences
[2019-07-26 22:13:29] [data] Done shuffling 4864128 sentences to temp files
[2019-07-26 22:18:50] Ep. 7 : Up. 234000 : Sen. 217,465 : Cost 41.52997589 : Time 346.86s : 14230.12 words/s
[2019-07-26 22:24:11] Ep. 7 : Up. 236000 : Sen. 435,821 : Cost 41.32345200 : Time 320.96s : 15280.02 words/s
[2019-07-26 22:29:33] Ep. 7 : Up. 238000 : Sen. 655,006 : Cost 41.48749161 : Time 322.19s : 15247.71 words/s
[2019-07-26 22:34:55] Ep. 7 : Up. 240000 : Sen. 874,206 : Cost 41.72887421 : Time 322.28s : 15285.99 words/s
[2019-07-26 22:34:55] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-26 22:35:00] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter240000.npz
[2019-07-26 22:35:02] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-26 22:35:07] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-26 22:35:24] [valid] Ep. 7 : Up. 240000 : cross-entropy : 40.5571 : new best
[2019-07-26 22:35:31] [valid] Ep. 7 : Up. 240000 : perplexity : 4.94006 : new best
[2019-07-26 22:36:20] [valid] Ep. 7 : Up. 240000 : translation : 30.13 : new best
[2019-07-26 22:41:44] Ep. 7 : Up. 242000 : Sen. 1,092,559 : Cost 41.51610947 : Time 408.90s : 11998.36 words/s
[2019-07-26 22:47:06] Ep. 7 : Up. 244000 : Sen. 1,310,590 : Cost 41.75558472 : Time 321.77s : 15243.17 words/s
[2019-07-26 22:52:29] Ep. 7 : Up. 246000 : Sen. 1,529,924 : Cost 41.62026596 : Time 322.66s : 15264.82 words/s
[2019-07-26 22:57:52] Ep. 7 : Up. 248000 : Sen. 1,750,152 : Cost 41.58052063 : Time 323.79s : 15254.79 words/s
[2019-07-26 23:03:12] Ep. 7 : Up. 250000 : Sen. 1,968,418 : Cost 41.70769119 : Time 319.43s : 15350.22 words/s
[2019-07-26 23:08:33] Ep. 7 : Up. 252000 : Sen. 2,187,311 : Cost 41.98945618 : Time 321.33s : 15340.81 words/s
[2019-07-26 23:13:54] Ep. 7 : Up. 254000 : Sen. 2,406,400 : Cost 41.65106964 : Time 320.85s : 15340.56 words/s
[2019-07-26 23:19:15] Ep. 7 : Up. 256000 : Sen. 2,625,053 : Cost 41.74324036 : Time 321.39s : 15297.43 words/s
[2019-07-26 23:24:38] Ep. 7 : Up. 258000 : Sen. 2,844,739 : Cost 41.61830521 : Time 322.86s : 15257.17 words/s
[2019-07-26 23:30:00] Ep. 7 : Up. 260000 : Sen. 3,062,316 : Cost 41.87815857 : Time 321.99s : 15215.64 words/s
[2019-07-26 23:30:00] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-26 23:30:05] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter260000.npz
[2019-07-26 23:30:07] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-26 23:30:12] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-26 23:30:30] [valid] Ep. 7 : Up. 260000 : cross-entropy : 40.2929 : new best
[2019-07-26 23:30:36] [valid] Ep. 7 : Up. 260000 : perplexity : 4.88893 : new best
[2019-07-26 23:31:27] [valid] Ep. 7 : Up. 260000 : translation : 30.32 : new best
[2019-07-26 23:36:51] Ep. 7 : Up. 262000 : Sen. 3,282,075 : Cost 41.66554260 : Time 410.47s : 12003.74 words/s
[2019-07-26 23:42:15] Ep. 7 : Up. 264000 : Sen. 3,501,722 : Cost 41.64496613 : Time 323.97s : 15246.47 words/s
[2019-07-26 23:47:37] Ep. 7 : Up. 266000 : Sen. 3,720,776 : Cost 41.73430634 : Time 322.64s : 15246.24 words/s
[2019-07-26 23:53:02] Ep. 7 : Up. 268000 : Sen. 3,940,108 : Cost 41.85752487 : Time 324.23s : 15226.75 words/s
[2019-07-26 23:58:26] Ep. 7 : Up. 270000 : Sen. 4,159,173 : Cost 42.05756378 : Time 324.44s : 15202.29 words/s
[2019-07-27 00:00:12] Seen 4231167 samples
[2019-07-27 00:00:12] Starting epoch 8
[2019-07-27 00:00:12] [data] Shuffling data
[2019-07-27 00:00:15] [data] Done reading 4864128 sentences
[2019-07-27 00:00:36] [data] Done shuffling 4864128 sentences to temp files
[2019-07-27 00:04:14] Ep. 8 : Up. 272000 : Sen. 147,393 : Cost 40.87816620 : Time 348.01s : 14156.44 words/s
[2019-07-27 00:09:39] Ep. 8 : Up. 274000 : Sen. 365,972 : Cost 40.62332916 : Time 324.93s : 15151.42 words/s
[2019-07-27 00:15:03] Ep. 8 : Up. 276000 : Sen. 585,793 : Cost 40.62127686 : Time 323.61s : 15260.43 words/s
[2019-07-27 00:20:25] Ep. 8 : Up. 278000 : Sen. 805,643 : Cost 40.70811844 : Time 321.96s : 15308.87 words/s
[2019-07-27 00:25:49] Ep. 8 : Up. 280000 : Sen. 1,025,392 : Cost 40.86518860 : Time 324.08s : 15271.49 words/s
[2019-07-27 00:25:49] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-27 00:25:54] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter280000.npz
[2019-07-27 00:25:56] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-27 00:26:01] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-27 00:26:17] [valid] Ep. 8 : Up. 280000 : cross-entropy : 40.0444 : new best
[2019-07-27 00:26:24] [valid] Ep. 8 : Up. 280000 : perplexity : 4.8413 : new best
[2019-07-27 00:27:14] [valid] Ep. 8 : Up. 280000 : translation : 30.63 : new best
[2019-07-27 00:32:39] Ep. 8 : Up. 282000 : Sen. 1,244,230 : Cost 41.00568390 : Time 409.95s : 11987.22 words/s
[2019-07-27 00:38:04] Ep. 8 : Up. 284000 : Sen. 1,464,678 : Cost 40.87070465 : Time 324.95s : 15232.32 words/s
[2019-07-27 00:43:27] Ep. 8 : Up. 286000 : Sen. 1,684,467 : Cost 40.84896851 : Time 323.81s : 15228.00 words/s
[2019-07-27 00:48:49] Ep. 8 : Up. 288000 : Sen. 1,902,933 : Cost 40.93504715 : Time 321.86s : 15261.66 words/s
[2019-07-27 00:54:11] Ep. 8 : Up. 290000 : Sen. 2,121,853 : Cost 41.18313599 : Time 322.11s : 15265.94 words/s
[2019-07-27 00:59:35] Ep. 8 : Up. 292000 : Sen. 2,341,818 : Cost 41.08270264 : Time 323.70s : 15282.74 words/s
[2019-07-27 01:04:56] Ep. 8 : Up. 294000 : Sen. 2,560,874 : Cost 41.11751938 : Time 321.37s : 15299.63 words/s
[2019-07-27 01:10:19] Ep. 8 : Up. 296000 : Sen. 2,780,601 : Cost 40.97758484 : Time 322.56s : 15314.81 words/s
[2019-07-27 01:15:40] Ep. 8 : Up. 298000 : Sen. 2,998,877 : Cost 41.20114136 : Time 321.06s : 15275.65 words/s
[2019-07-27 01:21:02] Ep. 8 : Up. 300000 : Sen. 3,217,778 : Cost 41.10533524 : Time 322.22s : 15262.55 words/s
[2019-07-27 01:21:02] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-27 01:21:07] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter300000.npz
[2019-07-27 01:21:09] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-27 01:21:14] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-27 01:21:32] [valid] Ep. 8 : Up. 300000 : cross-entropy : 39.8368 : new best
[2019-07-27 01:21:38] [valid] Ep. 8 : Up. 300000 : perplexity : 4.80189 : new best
[2019-07-27 01:22:28] [valid] Ep. 8 : Up. 300000 : translation : 30.63 : stalled 1 times (last best: 30.63)
[2019-07-27 01:27:52] Ep. 8 : Up. 302000 : Sen. 3,436,461 : Cost 40.91740036 : Time 409.45s : 11988.00 words/s
[2019-07-27 01:33:13] Ep. 8 : Up. 304000 : Sen. 3,654,940 : Cost 41.23723984 : Time 321.13s : 15288.74 words/s
[2019-07-27 01:38:35] Ep. 8 : Up. 306000 : Sen. 3,873,433 : Cost 41.25591278 : Time 322.17s : 15252.86 words/s
[2019-07-27 01:43:56] Ep. 8 : Up. 308000 : Sen. 4,092,117 : Cost 41.13213730 : Time 320.58s : 15291.71 words/s
[2019-07-27 01:47:21] Seen 4231167 samples
[2019-07-27 01:47:21] Starting epoch 9
[2019-07-27 01:47:21] [data] Shuffling data
[2019-07-27 01:47:24] [data] Done reading 4864128 sentences
[2019-07-27 01:47:44] [data] Done shuffling 4864128 sentences to temp files
[2019-07-27 01:49:40] Ep. 9 : Up. 310000 : Sen. 78,208 : Cost 40.91043854 : Time 344.32s : 14208.72 words/s
[2019-07-27 01:55:02] Ep. 9 : Up. 312000 : Sen. 297,633 : Cost 39.96023560 : Time 322.44s : 15270.84 words/s
[2019-07-27 02:00:24] Ep. 9 : Up. 314000 : Sen. 515,949 : Cost 40.31148529 : Time 321.48s : 15288.81 words/s
[2019-07-27 02:05:46] Ep. 9 : Up. 316000 : Sen. 735,316 : Cost 40.09716415 : Time 322.55s : 15272.17 words/s
[2019-07-27 02:11:09] Ep. 9 : Up. 318000 : Sen. 955,210 : Cost 40.20019913 : Time 323.06s : 15285.22 words/s
[2019-07-27 02:16:32] Ep. 9 : Up. 320000 : Sen. 1,174,009 : Cost 40.34605408 : Time 322.46s : 15261.17 words/s
[2019-07-27 02:16:32] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-27 02:16:37] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter320000.npz
[2019-07-27 02:16:39] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-27 02:16:44] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-27 02:17:00] [valid] Ep. 9 : Up. 320000 : cross-entropy : 39.7172 : new best
[2019-07-27 02:17:07] [valid] Ep. 9 : Up. 320000 : perplexity : 4.77931 : new best
[2019-07-27 02:17:57] [valid] Ep. 9 : Up. 320000 : translation : 30.86 : new best
[2019-07-27 02:23:22] Ep. 9 : Up. 322000 : Sen. 1,393,360 : Cost 40.30765915 : Time 409.86s : 12032.99 words/s
[2019-07-27 02:28:44] Ep. 9 : Up. 324000 : Sen. 1,612,800 : Cost 40.26942825 : Time 322.23s : 15275.53 words/s
[2019-07-27 02:34:05] Ep. 9 : Up. 326000 : Sen. 1,831,188 : Cost 40.47323608 : Time 321.18s : 15286.55 words/s
[2019-07-27 02:39:27] Ep. 9 : Up. 328000 : Sen. 2,049,712 : Cost 40.34819794 : Time 321.37s : 15264.87 words/s
[2019-07-27 02:44:50] Ep. 9 : Up. 330000 : Sen. 2,269,131 : Cost 40.57474518 : Time 323.35s : 15276.42 words/s
[2019-07-27 02:50:12] Ep. 9 : Up. 332000 : Sen. 2,488,838 : Cost 40.40448380 : Time 322.09s : 15289.85 words/s
[2019-07-27 02:55:34] Ep. 9 : Up. 334000 : Sen. 2,707,977 : Cost 40.61552429 : Time 322.26s : 15305.65 words/s
[2019-07-27 03:00:57] Ep. 9 : Up. 336000 : Sen. 2,927,804 : Cost 40.77277756 : Time 322.50s : 15316.54 words/s
[2019-07-27 03:06:18] Ep. 9 : Up. 338000 : Sen. 3,146,212 : Cost 40.52632523 : Time 321.16s : 15258.39 words/s
[2019-07-27 03:11:41] Ep. 9 : Up. 340000 : Sen. 3,365,929 : Cost 40.50584793 : Time 322.89s : 15288.81 words/s
[2019-07-27 03:11:41] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-27 03:11:46] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter340000.npz
[2019-07-27 03:11:48] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-27 03:11:53] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-27 03:12:10] [valid] Ep. 9 : Up. 340000 : cross-entropy : 39.5644 : new best
[2019-07-27 03:12:17] [valid] Ep. 9 : Up. 340000 : perplexity : 4.75064 : new best
[2019-07-27 03:13:08] [valid] Ep. 9 : Up. 340000 : translation : 30.97 : new best
[2019-07-27 03:18:32] Ep. 9 : Up. 342000 : Sen. 3,584,078 : Cost 40.71533966 : Time 411.00s : 11930.38 words/s
[2019-07-27 03:23:54] Ep. 9 : Up. 344000 : Sen. 3,802,954 : Cost 40.63270187 : Time 322.27s : 15269.56 words/s
[2019-07-27 03:29:17] Ep. 9 : Up. 346000 : Sen. 4,021,708 : Cost 40.57183075 : Time 322.75s : 15227.15 words/s
[2019-07-27 03:34:26] Seen 4231167 samples
[2019-07-27 03:34:26] Starting epoch 10
[2019-07-27 03:34:26] [data] Shuffling data
[2019-07-27 03:34:28] [data] Done reading 4864128 sentences
[2019-07-27 03:34:48] [data] Done shuffling 4864128 sentences to temp files
[2019-07-27 03:35:03] Ep. 10 : Up. 348000 : Sen. 9,714 : Cost 40.68516541 : Time 346.24s : 14237.49 words/s
[2019-07-27 03:40:25] Ep. 10 : Up. 350000 : Sen. 228,691 : Cost 39.41253281 : Time 322.09s : 15272.32 words/s
[2019-07-27 03:45:46] Ep. 10 : Up. 352000 : Sen. 447,210 : Cost 39.38249588 : Time 321.30s : 15265.15 words/s
[2019-07-27 03:51:09] Ep. 10 : Up. 354000 : Sen. 666,687 : Cost 39.64015198 : Time 322.54s : 15283.00 words/s
[2019-07-27 03:56:32] Ep. 10 : Up. 356000 : Sen. 886,589 : Cost 39.65187836 : Time 323.05s : 15285.48 words/s
[2019-07-27 04:01:55] Ep. 10 : Up. 358000 : Sen. 1,106,349 : Cost 39.71476746 : Time 322.48s : 15287.35 words/s
[2019-07-27 04:07:16] Ep. 10 : Up. 360000 : Sen. 1,324,800 : Cost 39.94808960 : Time 321.42s : 15290.05 words/s
[2019-07-27 04:07:16] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-27 04:07:21] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter360000.npz
[2019-07-27 04:07:23] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-27 04:07:28] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-27 04:07:45] [valid] Ep. 10 : Up. 360000 : cross-entropy : 39.4161 : new best
[2019-07-27 04:07:51] [valid] Ep. 10 : Up. 360000 : perplexity : 4.72297 : new best
[2019-07-27 04:08:42] [valid] Ep. 10 : Up. 360000 : translation : 30.71 : stalled 1 times (last best: 30.97)
[2019-07-27 04:14:05] Ep. 10 : Up. 362000 : Sen. 1,543,199 : Cost 39.96221542 : Time 409.16s : 11998.26 words/s
[2019-07-27 04:19:27] Ep. 10 : Up. 364000 : Sen. 1,762,490 : Cost 39.82954788 : Time 321.90s : 15293.84 words/s
[2019-07-27 04:24:49] Ep. 10 : Up. 366000 : Sen. 1,981,824 : Cost 39.87221146 : Time 322.33s : 15259.41 words/s
[2019-07-27 04:30:12] Ep. 10 : Up. 368000 : Sen. 2,200,925 : Cost 39.93770981 : Time 322.78s : 15254.56 words/s
[2019-07-27 04:35:35] Ep. 10 : Up. 370000 : Sen. 2,420,763 : Cost 39.86437225 : Time 322.97s : 15285.25 words/s
[2019-07-27 04:40:57] Ep. 10 : Up. 372000 : Sen. 2,639,179 : Cost 40.13107681 : Time 322.18s : 15259.84 words/s
[2019-07-27 04:46:20] Ep. 10 : Up. 374000 : Sen. 2,857,526 : Cost 40.02969742 : Time 322.41s : 15254.93 words/s
[2019-07-27 04:51:42] Ep. 10 : Up. 376000 : Sen. 3,077,289 : Cost 39.82639313 : Time 322.74s : 15277.97 words/s
[2019-07-27 04:57:05] Ep. 10 : Up. 378000 : Sen. 3,295,671 : Cost 40.15018082 : Time 322.32s : 15249.10 words/s
[2019-07-27 05:02:26] Ep. 10 : Up. 380000 : Sen. 3,514,227 : Cost 40.16357040 : Time 321.71s : 15271.45 words/s
[2019-07-27 05:02:26] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-27 05:02:31] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter380000.npz
[2019-07-27 05:02:33] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-27 05:02:38] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-27 05:02:55] [valid] Ep. 10 : Up. 380000 : cross-entropy : 39.2539 : new best
[2019-07-27 05:03:02] [valid] Ep. 10 : Up. 380000 : perplexity : 4.69289 : new best
[2019-07-27 05:03:52] [valid] Ep. 10 : Up. 380000 : translation : 31.03 : new best
[2019-07-27 05:09:16] Ep. 10 : Up. 382000 : Sen. 3,732,768 : Cost 40.12498474 : Time 409.62s : 11998.26 words/s
[2019-07-27 05:14:38] Ep. 10 : Up. 384000 : Sen. 3,952,017 : Cost 40.07108307 : Time 322.02s : 15281.38 words/s
[2019-07-27 05:20:00] Ep. 10 : Up. 386000 : Sen. 4,171,012 : Cost 40.26094055 : Time 322.07s : 15283.27 words/s
[2019-07-27 05:21:29] Seen 4231167 samples
[2019-07-27 05:21:29] Starting epoch 11
[2019-07-27 05:21:29] [data] Shuffling data
[2019-07-27 05:21:31] [data] Done reading 4864128 sentences
[2019-07-27 05:21:51] [data] Done shuffling 4864128 sentences to temp files
[2019-07-27 05:25:45] Ep. 11 : Up. 388000 : Sen. 158,148 : Cost 39.35298920 : Time 344.84s : 14246.10 words/s
[2019-07-27 05:31:07] Ep. 11 : Up. 390000 : Sen. 377,600 : Cost 38.71146774 : Time 322.00s : 15280.33 words/s
[2019-07-27 05:36:29] Ep. 11 : Up. 392000 : Sen. 595,744 : Cost 39.14879990 : Time 322.10s : 15226.92 words/s
[2019-07-27 05:41:51] Ep. 11 : Up. 394000 : Sen. 814,072 : Cost 39.50147629 : Time 321.96s : 15283.72 words/s
[2019-07-27 05:47:12] Ep. 11 : Up. 396000 : Sen. 1,032,168 : Cost 39.43751526 : Time 321.36s : 15261.17 words/s
[2019-07-27 05:52:33] Ep. 11 : Up. 398000 : Sen. 1,250,118 : Cost 39.44625854 : Time 320.59s : 15284.29 words/s
[2019-07-27 05:57:55] Ep. 11 : Up. 400000 : Sen. 1,468,824 : Cost 39.39949799 : Time 322.11s : 15264.92 words/s
[2019-07-27 05:57:55] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-27 05:58:00] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter400000.npz
[2019-07-27 05:58:02] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-27 05:58:07] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-27 05:58:24] [valid] Ep. 11 : Up. 400000 : cross-entropy : 39.1719 : new best
[2019-07-27 05:58:30] [valid] Ep. 11 : Up. 400000 : perplexity : 4.67776 : new best
[2019-07-27 05:59:20] [valid] Ep. 11 : Up. 400000 : translation : 31.03 : stalled 1 times (last best: 31.03)
[2019-07-27 06:04:45] Ep. 11 : Up. 402000 : Sen. 1,687,946 : Cost 39.50873566 : Time 409.93s : 12019.59 words/s
[2019-07-27 06:10:08] Ep. 11 : Up. 404000 : Sen. 1,907,020 : Cost 39.47481155 : Time 323.19s : 15224.43 words/s
[2019-07-27 06:15:30] Ep. 11 : Up. 406000 : Sen. 2,126,247 : Cost 39.66034698 : Time 322.05s : 15280.31 words/s
[2019-07-27 06:20:53] Ep. 11 : Up. 408000 : Sen. 2,345,824 : Cost 39.58276749 : Time 322.93s : 15278.20 words/s
[2019-07-27 06:26:15] Ep. 11 : Up. 410000 : Sen. 2,565,092 : Cost 39.58866882 : Time 322.00s : 15278.85 words/s
[2019-07-27 06:31:39] Ep. 11 : Up. 412000 : Sen. 2,784,258 : Cost 39.49448395 : Time 323.36s : 15234.34 words/s
[2019-07-27 06:37:02] Ep. 11 : Up. 414000 : Sen. 3,003,307 : Cost 39.74901581 : Time 323.39s : 15230.58 words/s
[2019-07-27 06:42:25] Ep. 11 : Up. 416000 : Sen. 3,222,163 : Cost 39.59720612 : Time 322.97s : 15216.55 words/s
[2019-07-27 06:47:49] Ep. 11 : Up. 418000 : Sen. 3,441,097 : Cost 39.96146393 : Time 323.99s : 15212.87 words/s
[2019-07-27 06:53:12] Ep. 11 : Up. 420000 : Sen. 3,660,211 : Cost 39.49300003 : Time 323.28s : 15207.86 words/s
[2019-07-27 06:53:12] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-27 06:53:17] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter420000.npz
[2019-07-27 06:53:19] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-27 06:53:24] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-27 06:53:42] [valid] Ep. 11 : Up. 420000 : cross-entropy : 39.0318 : new best
[2019-07-27 06:53:49] [valid] Ep. 11 : Up. 420000 : perplexity : 4.65202 : new best
[2019-07-27 06:54:41] [valid] Ep. 11 : Up. 420000 : translation : 30.95 : stalled 2 times (last best: 31.03)
[2019-07-27 07:00:07] Ep. 11 : Up. 422000 : Sen. 3,879,575 : Cost 39.53625870 : Time 414.42s : 11887.42 words/s
[2019-07-27 07:05:28] Ep. 11 : Up. 424000 : Sen. 4,098,173 : Cost 39.72299957 : Time 321.72s : 15209.46 words/s
[2019-07-27 07:08:44] Seen 4231167 samples
[2019-07-27 07:08:44] Starting epoch 12
[2019-07-27 07:08:44] [data] Shuffling data
[2019-07-27 07:08:47] [data] Done reading 4864128 sentences
[2019-07-27 07:09:06] [data] Done shuffling 4864128 sentences to temp files
[2019-07-27 07:11:14] Ep. 12 : Up. 426000 : Sen. 85,606 : Cost 39.51729584 : Time 345.55s : 14259.88 words/s
[2019-07-27 07:16:37] Ep. 12 : Up. 428000 : Sen. 305,722 : Cost 38.64115143 : Time 323.23s : 15278.14 words/s
[2019-07-27 07:22:00] Ep. 12 : Up. 430000 : Sen. 524,902 : Cost 38.74050140 : Time 323.15s : 15243.45 words/s
[2019-07-27 07:27:23] Ep. 12 : Up. 432000 : Sen. 743,973 : Cost 38.59849167 : Time 322.39s : 15223.09 words/s
[2019-07-27 07:32:46] Ep. 12 : Up. 434000 : Sen. 963,091 : Cost 38.94567871 : Time 323.06s : 15255.73 words/s
[2019-07-27 07:38:08] Ep. 12 : Up. 436000 : Sen. 1,181,595 : Cost 38.74290466 : Time 322.78s : 15200.87 words/s
[2019-07-27 07:43:28] Ep. 12 : Up. 438000 : Sen. 1,399,886 : Cost 38.95710373 : Time 319.98s : 15297.23 words/s
[2019-07-27 07:48:48] Ep. 12 : Up. 440000 : Sen. 1,618,287 : Cost 38.93571472 : Time 319.96s : 15328.66 words/s
[2019-07-27 07:48:48] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-27 07:48:53] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter440000.npz
[2019-07-27 07:48:55] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-27 07:49:00] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-27 07:49:17] [valid] Ep. 12 : Up. 440000 : cross-entropy : 39.0136 : new best
[2019-07-27 07:49:24] [valid] Ep. 12 : Up. 440000 : perplexity : 4.64868 : new best
[2019-07-27 07:50:13] [valid] Ep. 12 : Up. 440000 : translation : 30.93 : stalled 3 times (last best: 31.03)
[2019-07-27 07:55:35] Ep. 12 : Up. 442000 : Sen. 1,837,533 : Cost 39.21949005 : Time 406.98s : 12107.07 words/s
[2019-07-27 08:00:56] Ep. 12 : Up. 444000 : Sen. 2,056,424 : Cost 39.14653778 : Time 320.72s : 15349.86 words/s
[2019-07-27 08:06:16] Ep. 12 : Up. 446000 : Sen. 2,275,291 : Cost 39.15323639 : Time 319.90s : 15362.78 words/s
[2019-07-27 08:11:37] Ep. 12 : Up. 448000 : Sen. 2,493,973 : Cost 39.26802444 : Time 320.67s : 15336.22 words/s
[2019-07-27 08:16:56] Ep. 12 : Up. 450000 : Sen. 2,712,924 : Cost 39.13875580 : Time 319.81s : 15370.13 words/s
[2019-07-27 08:22:18] Ep. 12 : Up. 452000 : Sen. 2,931,692 : Cost 39.47985077 : Time 321.70s : 15319.32 words/s
[2019-07-27 08:27:39] Ep. 12 : Up. 454000 : Sen. 3,151,264 : Cost 39.31970978 : Time 320.79s : 15387.14 words/s
[2019-07-27 08:32:59] Ep. 12 : Up. 456000 : Sen. 3,370,260 : Cost 39.47974777 : Time 320.33s : 15369.85 words/s
[2019-07-27 08:38:20] Ep. 12 : Up. 458000 : Sen. 3,589,275 : Cost 39.35490417 : Time 320.53s : 15362.44 words/s
[2019-07-27 08:43:40] Ep. 12 : Up. 460000 : Sen. 3,808,502 : Cost 39.35442352 : Time 320.63s : 15360.92 words/s
[2019-07-27 08:43:40] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-27 08:43:45] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter460000.npz
[2019-07-27 08:43:47] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-27 08:43:52] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-27 08:44:10] [valid] Ep. 12 : Up. 460000 : cross-entropy : 38.863 : new best
[2019-07-27 08:44:16] [valid] Ep. 12 : Up. 460000 : perplexity : 4.62121 : new best
[2019-07-27 08:45:05] [valid] Ep. 12 : Up. 460000 : translation : 31.14 : new best
[2019-07-27 08:50:28] Ep. 12 : Up. 462000 : Sen. 4,027,726 : Cost 39.39821243 : Time 407.36s : 12121.37 words/s
[2019-07-27 08:55:24] Seen 4231167 samples
[2019-07-27 08:55:24] Starting epoch 13
[2019-07-27 08:55:24] [data] Shuffling data
[2019-07-27 08:55:30] [data] Done reading 4864128 sentences
[2019-07-27 08:55:49] [data] Done shuffling 4864128 sentences to temp files
[2019-07-27 08:56:13] Ep. 13 : Up. 464000 : Sen. 16,242 : Cost 39.13920593 : Time 345.46s : 14250.65 words/s
[2019-07-27 09:01:33] Ep. 13 : Up. 466000 : Sen. 235,940 : Cost 38.32318878 : Time 319.89s : 15402.57 words/s
[2019-07-27 09:06:54] Ep. 13 : Up. 468000 : Sen. 454,893 : Cost 38.42859268 : Time 321.25s : 15331.12 words/s
[2019-07-27 09:12:17] Ep. 13 : Up. 470000 : Sen. 672,798 : Cost 38.46649551 : Time 322.21s : 15211.92 words/s
[2019-07-27 09:17:39] Ep. 13 : Up. 472000 : Sen. 891,637 : Cost 38.31723022 : Time 322.85s : 15231.46 words/s
[2019-07-27 09:23:03] Ep. 13 : Up. 474000 : Sen. 1,110,143 : Cost 38.64322281 : Time 323.62s : 15198.48 words/s
[2019-07-27 09:28:24] Ep. 13 : Up. 476000 : Sen. 1,329,201 : Cost 38.56602859 : Time 321.31s : 15300.01 words/s
[2019-07-27 09:33:49] Ep. 13 : Up. 478000 : Sen. 1,548,146 : Cost 39.05968094 : Time 324.58s : 15209.15 words/s
[2019-07-27 09:39:11] Ep. 13 : Up. 480000 : Sen. 1,766,974 : Cost 38.74240494 : Time 321.99s : 15228.63 words/s
[2019-07-27 09:39:11] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-27 09:39:16] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter480000.npz
[2019-07-27 09:39:18] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-27 09:39:23] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-27 09:39:41] [valid] Ep. 13 : Up. 480000 : cross-entropy : 38.8588 : new best
[2019-07-27 09:39:48] [valid] Ep. 13 : Up. 480000 : perplexity : 4.62043 : new best
[2019-07-27 09:40:40] [valid] Ep. 13 : Up. 480000 : translation : 31.02 : stalled 1 times (last best: 31.14)
[2019-07-27 09:46:03] Ep. 13 : Up. 482000 : Sen. 1,985,213 : Cost 38.72827530 : Time 412.09s : 11890.23 words/s
[2019-07-27 09:51:24] Ep. 13 : Up. 484000 : Sen. 2,204,011 : Cost 38.72318649 : Time 321.40s : 15283.36 words/s
[2019-07-27 09:56:47] Ep. 13 : Up. 486000 : Sen. 2,422,091 : Cost 38.99079132 : Time 322.99s : 15237.31 words/s
[2019-07-27 10:02:09] Ep. 13 : Up. 488000 : Sen. 2,641,902 : Cost 38.83850861 : Time 321.95s : 15299.43 words/s
[2019-07-27 10:07:31] Ep. 13 : Up. 490000 : Sen. 2,860,620 : Cost 39.05941391 : Time 321.47s : 15301.58 words/s
[2019-07-27 10:12:53] Ep. 13 : Up. 492000 : Sen. 3,079,468 : Cost 38.92288589 : Time 322.41s : 15235.08 words/s
[2019-07-27 10:18:17] Ep. 13 : Up. 494000 : Sen. 3,297,923 : Cost 38.90744400 : Time 323.37s : 15179.28 words/s
[2019-07-27 10:23:42] Ep. 13 : Up. 496000 : Sen. 3,516,875 : Cost 38.94346237 : Time 325.67s : 15101.55 words/s
[2019-07-27 10:29:08] Ep. 13 : Up. 498000 : Sen. 3,736,053 : Cost 38.85871887 : Time 325.23s : 15111.38 words/s
[2019-07-27 10:34:33] Ep. 13 : Up. 500000 : Sen. 3,954,831 : Cost 39.13249207 : Time 325.88s : 15096.13 words/s
[2019-07-27 10:34:33] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-27 10:34:39] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter500000.npz
[2019-07-27 10:34:41] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-27 10:34:47] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-27 10:35:05] [valid] Ep. 13 : Up. 500000 : cross-entropy : 38.7332 : new best
[2019-07-27 10:35:11] [valid] Ep. 13 : Up. 500000 : perplexity : 4.59764 : new best
[2019-07-27 10:36:03] [valid] Ep. 13 : Up. 500000 : translation : 31.17 : new best
[2019-07-27 10:41:31] Ep. 13 : Up. 502000 : Sen. 4,173,698 : Cost 39.23182678 : Time 417.54s : 11789.18 words/s
[2019-07-27 10:42:57] Seen 4231167 samples
[2019-07-27 10:42:57] Starting epoch 14
[2019-07-27 10:42:57] [data] Shuffling data
[2019-07-27 10:42:59] [data] Done reading 4864128 sentences
[2019-07-27 10:43:20] [data] Done shuffling 4864128 sentences to temp files
[2019-07-27 10:47:21] Ep. 14 : Up. 504000 : Sen. 161,053 : Cost 38.23506927 : Time 349.64s : 14044.16 words/s
[2019-07-27 10:52:43] Ep. 14 : Up. 506000 : Sen. 379,540 : Cost 38.07398605 : Time 322.63s : 15191.44 words/s
[2019-07-27 10:58:07] Ep. 14 : Up. 508000 : Sen. 598,405 : Cost 38.01926804 : Time 323.31s : 15215.83 words/s
[2019-07-27 11:03:31] Ep. 14 : Up. 510000 : Sen. 818,223 : Cost 38.34804535 : Time 323.96s : 15248.72 words/s
[2019-07-27 11:08:53] Ep. 14 : Up. 512000 : Sen. 1,037,703 : Cost 38.26300049 : Time 322.70s : 15259.81 words/s
[2019-07-27 11:14:15] Ep. 14 : Up. 514000 : Sen. 1,256,115 : Cost 38.43934250 : Time 322.15s : 15255.36 words/s
[2019-07-27 11:19:38] Ep. 14 : Up. 516000 : Sen. 1,474,838 : Cost 38.46503067 : Time 323.04s : 15249.26 words/s
[2019-07-27 11:25:01] Ep. 14 : Up. 518000 : Sen. 1,694,037 : Cost 38.22170639 : Time 322.78s : 15226.08 words/s
[2019-07-27 11:30:24] Ep. 14 : Up. 520000 : Sen. 1,912,097 : Cost 38.48696518 : Time 322.65s : 15231.12 words/s
[2019-07-27 11:30:24] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-27 11:30:29] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter520000.npz
[2019-07-27 11:30:31] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-27 11:30:36] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-27 11:30:54] [valid] Ep. 14 : Up. 520000 : cross-entropy : 38.7953 : stalled 1 times (last best: 38.7332)
[2019-07-27 11:31:00] [valid] Ep. 14 : Up. 520000 : perplexity : 4.60889 : stalled 1 times (last best: 4.59764)
[2019-07-27 11:31:52] [valid] Ep. 14 : Up. 520000 : translation : 31.22 : new best
[2019-07-27 11:37:17] Ep. 14 : Up. 522000 : Sen. 2,131,078 : Cost 38.43449783 : Time 413.19s : 11907.97 words/s
[2019-07-27 11:42:38] Ep. 14 : Up. 524000 : Sen. 2,348,800 : Cost 38.69692612 : Time 321.10s : 15235.02 words/s
[2019-07-27 11:48:01] Ep. 14 : Up. 526000 : Sen. 2,568,244 : Cost 38.51022720 : Time 322.67s : 15265.67 words/s
[2019-07-27 11:53:25] Ep. 14 : Up. 528000 : Sen. 2,787,061 : Cost 38.60915375 : Time 323.76s : 15209.42 words/s
[2019-07-27 11:58:48] Ep. 14 : Up. 530000 : Sen. 3,005,768 : Cost 38.79363251 : Time 323.65s : 15207.08 words/s
[2019-07-27 12:04:12] Ep. 14 : Up. 532000 : Sen. 3,225,678 : Cost 38.73239517 : Time 323.63s : 15227.43 words/s
[2019-07-27 12:09:36] Ep. 14 : Up. 534000 : Sen. 3,444,695 : Cost 38.87850571 : Time 323.71s : 15214.07 words/s
[2019-07-27 12:14:57] Ep. 14 : Up. 536000 : Sen. 3,663,683 : Cost 38.46890259 : Time 321.33s : 15247.47 words/s
[2019-07-27 12:20:20] Ep. 14 : Up. 538000 : Sen. 3,882,584 : Cost 38.84229279 : Time 323.37s : 15205.33 words/s
[2019-07-27 12:25:44] Ep. 14 : Up. 540000 : Sen. 4,101,444 : Cost 38.84411621 : Time 323.41s : 15218.27 words/s
[2019-07-27 12:25:44] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-27 12:25:49] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter540000.npz
[2019-07-27 12:25:51] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-27 12:25:56] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-27 12:26:14] [valid] Ep. 14 : Up. 540000 : cross-entropy : 38.6517 : new best
[2019-07-27 12:26:21] [valid] Ep. 14 : Up. 540000 : perplexity : 4.58289 : new best
[2019-07-27 12:27:12] [valid] Ep. 14 : Up. 540000 : translation : 31.28 : new best
[2019-07-27 12:30:26] Seen 4231167 samples
[2019-07-27 12:30:26] Starting epoch 15
[2019-07-27 12:30:26] [data] Shuffling data
[2019-07-27 12:30:28] [data] Done reading 4864128 sentences
[2019-07-27 12:30:48] [data] Done shuffling 4864128 sentences to temp files
[2019-07-27 12:33:01] Ep. 15 : Up. 542000 : Sen. 89,600 : Cost 38.32905197 : Time 437.82s : 11262.74 words/s
[2019-07-27 12:38:25] Ep. 15 : Up. 544000 : Sen. 308,370 : Cost 37.79201126 : Time 323.51s : 15199.72 words/s
[2019-07-27 12:43:48] Ep. 15 : Up. 546000 : Sen. 526,825 : Cost 37.90143204 : Time 322.83s : 15205.74 words/s
[2019-07-27 12:49:12] Ep. 15 : Up. 548000 : Sen. 746,327 : Cost 37.94910812 : Time 324.44s : 15213.11 words/s
[2019-07-27 12:54:35] Ep. 15 : Up. 550000 : Sen. 965,001 : Cost 37.95546722 : Time 322.66s : 15218.93 words/s
[2019-07-27 12:59:58] Ep. 15 : Up. 552000 : Sen. 1,183,664 : Cost 38.01620865 : Time 323.24s : 15190.00 words/s
[2019-07-27 13:05:22] Ep. 15 : Up. 554000 : Sen. 1,402,682 : Cost 38.13295746 : Time 324.08s : 15209.15 words/s
[2019-07-27 13:10:43] Ep. 15 : Up. 556000 : Sen. 1,620,178 : Cost 38.13850784 : Time 321.14s : 15224.37 words/s
[2019-07-27 13:16:07] Ep. 15 : Up. 558000 : Sen. 1,838,823 : Cost 38.19384384 : Time 323.61s : 15216.60 words/s
[2019-07-27 13:21:30] Ep. 15 : Up. 560000 : Sen. 2,057,661 : Cost 38.36420441 : Time 322.98s : 15214.76 words/s
[2019-07-27 13:21:30] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-27 13:21:35] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter560000.npz
[2019-07-27 13:21:37] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-27 13:21:42] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-27 13:22:02] [valid] Ep. 15 : Up. 560000 : cross-entropy : 38.7241 : stalled 1 times (last best: 38.6517)
[2019-07-27 13:22:08] [valid] Ep. 15 : Up. 560000 : perplexity : 4.59599 : stalled 1 times (last best: 4.58289)
[2019-07-27 13:23:00] [valid] Ep. 15 : Up. 560000 : translation : 31.22 : stalled 1 times (last best: 31.28)
[2019-07-27 13:28:27] Ep. 15 : Up. 562000 : Sen. 2,277,392 : Cost 38.29826355 : Time 416.55s : 11872.29 words/s
[2019-07-27 13:33:49] Ep. 15 : Up. 564000 : Sen. 2,496,315 : Cost 38.45162964 : Time 322.84s : 15203.87 words/s
[2019-07-27 13:39:13] Ep. 15 : Up. 566000 : Sen. 2,715,608 : Cost 38.30413055 : Time 323.31s : 15221.33 words/s
[2019-07-27 13:44:36] Ep. 15 : Up. 568000 : Sen. 2,934,652 : Cost 38.25388336 : Time 323.22s : 15223.37 words/s
[2019-07-27 13:49:58] Ep. 15 : Up. 570000 : Sen. 3,152,737 : Cost 38.44279861 : Time 322.04s : 15206.14 words/s
[2019-07-27 13:55:21] Ep. 15 : Up. 572000 : Sen. 3,370,934 : Cost 38.50541306 : Time 322.60s : 15206.08 words/s
[2019-07-27 14:00:45] Ep. 15 : Up. 574000 : Sen. 3,590,046 : Cost 38.58290863 : Time 323.99s : 15203.67 words/s
[2019-07-27 14:06:08] Ep. 15 : Up. 576000 : Sen. 3,808,873 : Cost 38.51802444 : Time 323.08s : 15223.24 words/s
[2019-07-27 14:11:31] Ep. 15 : Up. 578000 : Sen. 4,028,294 : Cost 38.52856827 : Time 323.59s : 15236.46 words/s
[2019-07-27 14:16:30] Seen 4231167 samples
[2019-07-27 14:16:30] Starting epoch 16
[2019-07-27 14:16:30] [data] Shuffling data
[2019-07-27 14:16:33] [data] Done reading 4864128 sentences
[2019-07-27 14:16:54] [data] Done shuffling 4864128 sentences to temp files
[2019-07-27 14:17:18] Ep. 16 : Up. 580000 : Sen. 15,818 : Cost 38.64897156 : Time 346.90s : 14151.94 words/s
[2019-07-27 14:17:18] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-27 14:17:23] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter580000.npz
[2019-07-27 14:17:25] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-27 14:17:30] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-27 14:17:48] [valid] Ep. 16 : Up. 580000 : cross-entropy : 38.5965 : new best
[2019-07-27 14:17:55] [valid] Ep. 16 : Up. 580000 : perplexity : 4.57296 : new best
[2019-07-27 14:18:46] [valid] Ep. 16 : Up. 580000 : translation : 31.28 : stalled 2 times (last best: 31.28)
[2019-07-27 14:24:13] Ep. 16 : Up. 582000 : Sen. 234,512 : Cost 37.65372849 : Time 414.45s : 11892.15 words/s
[2019-07-27 14:29:37] Ep. 16 : Up. 584000 : Sen. 454,400 : Cost 37.57805252 : Time 324.30s : 15210.98 words/s
[2019-07-27 14:35:00] Ep. 16 : Up. 586000 : Sen. 671,799 : Cost 37.75360489 : Time 322.73s : 15155.25 words/s
[2019-07-27 14:40:23] Ep. 16 : Up. 588000 : Sen. 890,449 : Cost 37.67648697 : Time 323.35s : 15206.74 words/s
[2019-07-27 14:45:46] Ep. 16 : Up. 590000 : Sen. 1,109,123 : Cost 37.69788361 : Time 323.29s : 15185.80 words/s
[2019-07-27 14:51:10] Ep. 16 : Up. 592000 : Sen. 1,327,674 : Cost 38.04967880 : Time 323.47s : 15201.60 words/s
[2019-07-27 14:56:35] Ep. 16 : Up. 594000 : Sen. 1,547,426 : Cost 37.94237518 : Time 325.02s : 15205.90 words/s
[2019-07-27 15:01:58] Ep. 16 : Up. 596000 : Sen. 1,766,502 : Cost 37.79382706 : Time 323.67s : 15200.51 words/s
[2019-07-27 15:07:21] Ep. 16 : Up. 598000 : Sen. 1,985,013 : Cost 37.94845200 : Time 322.83s : 15184.70 words/s
[2019-07-27 15:12:45] Ep. 16 : Up. 600000 : Sen. 2,203,864 : Cost 38.08902740 : Time 324.29s : 15179.35 words/s
[2019-07-27 15:12:45] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-27 15:12:51] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter600000.npz
[2019-07-27 15:12:53] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-27 15:12:58] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-27 15:13:16] [valid] Ep. 16 : Up. 600000 : cross-entropy : 38.676 : stalled 1 times (last best: 38.5965)
[2019-07-27 15:13:23] [valid] Ep. 16 : Up. 600000 : perplexity : 4.58729 : stalled 1 times (last best: 4.57296)
[2019-07-27 15:14:14] [valid] Ep. 16 : Up. 600000 : translation : 31.27 : stalled 3 times (last best: 31.28)
[2019-07-27 15:19:40] Ep. 16 : Up. 602000 : Sen. 2,422,949 : Cost 38.04434204 : Time 414.88s : 11872.88 words/s
[2019-07-27 15:25:04] Ep. 16 : Up. 604000 : Sen. 2,641,999 : Cost 38.14927673 : Time 323.19s : 15217.48 words/s
[2019-07-27 15:30:28] Ep. 16 : Up. 606000 : Sen. 2,861,486 : Cost 38.33476639 : Time 324.19s : 15228.15 words/s
[2019-07-27 15:35:51] Ep. 16 : Up. 608000 : Sen. 3,080,258 : Cost 37.98230743 : Time 323.48s : 15177.91 words/s
[2019-07-27 15:41:14] Ep. 16 : Up. 610000 : Sen. 3,299,175 : Cost 38.11746597 : Time 322.98s : 15204.91 words/s
[2019-07-27 15:46:39] Ep. 16 : Up. 612000 : Sen. 3,518,820 : Cost 38.12476349 : Time 324.46s : 15215.55 words/s
[2019-07-27 15:52:02] Ep. 16 : Up. 614000 : Sen. 3,737,756 : Cost 38.31475449 : Time 323.31s : 15222.10 words/s
[2019-07-27 15:57:24] Ep. 16 : Up. 616000 : Sen. 3,955,703 : Cost 38.36208344 : Time 322.51s : 15187.72 words/s
[2019-07-27 16:02:48] Ep. 16 : Up. 618000 : Sen. 4,174,666 : Cost 38.02003479 : Time 323.54s : 15179.29 words/s
[2019-07-27 16:04:12] Seen 4231167 samples
[2019-07-27 16:04:12] Starting epoch 17
[2019-07-27 16:04:12] [data] Shuffling data
[2019-07-27 16:04:14] [data] Done reading 4864128 sentences
[2019-07-27 16:04:35] [data] Done shuffling 4864128 sentences to temp files
[2019-07-27 16:08:35] Ep. 17 : Up. 620000 : Sen. 161,950 : Cost 37.54087830 : Time 347.39s : 14113.99 words/s
[2019-07-27 16:08:35] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-27 16:08:40] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter620000.npz
[2019-07-27 16:08:42] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-27 16:08:47] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-27 16:09:06] [valid] Ep. 17 : Up. 620000 : cross-entropy : 38.5235 : new best
[2019-07-27 16:09:12] [valid] Ep. 17 : Up. 620000 : perplexity : 4.55982 : new best
[2019-07-27 16:10:04] [valid] Ep. 17 : Up. 620000 : translation : 31.48 : new best
[2019-07-27 16:15:28] Ep. 17 : Up. 622000 : Sen. 379,473 : Cost 37.28904343 : Time 413.06s : 11824.63 words/s
[2019-07-27 16:20:51] Ep. 17 : Up. 624000 : Sen. 598,398 : Cost 37.39457703 : Time 322.72s : 15209.59 words/s
[2019-07-27 16:26:14] Ep. 17 : Up. 626000 : Sen. 817,897 : Cost 37.45926666 : Time 323.01s : 15264.32 words/s
[2019-07-27 16:31:34] Ep. 17 : Up. 628000 : Sen. 1,037,532 : Cost 37.71453857 : Time 319.74s : 15450.47 words/s
[2019-07-27 16:36:54] Ep. 17 : Up. 630000 : Sen. 1,255,327 : Cost 37.69068146 : Time 319.71s : 15373.02 words/s
[2019-07-27 16:42:14] Ep. 17 : Up. 632000 : Sen. 1,475,201 : Cost 37.69885254 : Time 320.20s : 15443.39 words/s
[2019-07-27 16:47:33] Ep. 17 : Up. 634000 : Sen. 1,694,080 : Cost 37.70621490 : Time 318.85s : 15414.50 words/s
[2019-07-27 16:52:52] Ep. 17 : Up. 636000 : Sen. 1,912,848 : Cost 37.91649628 : Time 319.32s : 15420.38 words/s
[2019-07-27 16:58:09] Ep. 17 : Up. 638000 : Sen. 2,130,860 : Cost 37.62911606 : Time 317.22s : 15421.92 words/s
[2019-07-27 17:03:28] Ep. 17 : Up. 640000 : Sen. 2,349,326 : Cost 38.03752136 : Time 318.65s : 15409.86 words/s
[2019-07-27 17:03:28] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-27 17:03:33] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter640000.npz
[2019-07-27 17:03:35] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-27 17:03:39] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-27 17:03:56] [valid] Ep. 17 : Up. 640000 : cross-entropy : 38.5939 : stalled 1 times (last best: 38.5235)
[2019-07-27 17:04:02] [valid] Ep. 17 : Up. 640000 : perplexity : 4.57248 : stalled 1 times (last best: 4.55982)
[2019-07-27 17:04:51] [valid] Ep. 17 : Up. 640000 : translation : 31.47 : stalled 1 times (last best: 31.48)
[2019-07-27 17:10:11] Ep. 17 : Up. 642000 : Sen. 2,567,881 : Cost 37.64273453 : Time 403.06s : 12157.06 words/s
[2019-07-27 17:15:34] Ep. 17 : Up. 644000 : Sen. 2,786,748 : Cost 37.83715057 : Time 322.92s : 15245.90 words/s
[2019-07-27 17:20:57] Ep. 17 : Up. 646000 : Sen. 3,005,256 : Cost 38.10558319 : Time 322.79s : 15223.07 words/s
[2019-07-27 17:26:20] Ep. 17 : Up. 648000 : Sen. 3,224,843 : Cost 38.06896210 : Time 323.41s : 15248.70 words/s
[2019-07-27 17:31:43] Ep. 17 : Up. 650000 : Sen. 3,444,291 : Cost 38.05273819 : Time 322.83s : 15255.58 words/s
[2019-07-27 17:37:05] Ep. 17 : Up. 652000 : Sen. 3,663,140 : Cost 38.07626724 : Time 322.50s : 15257.06 words/s
[2019-07-27 17:42:27] Ep. 17 : Up. 654000 : Sen. 3,881,596 : Cost 38.14663315 : Time 321.94s : 15252.37 words/s
[2019-07-27 17:47:49] Ep. 17 : Up. 656000 : Sen. 4,100,081 : Cost 38.05088806 : Time 321.77s : 15270.38 words/s
[2019-07-27 17:51:02] Seen 4231167 samples
[2019-07-27 17:51:02] Starting epoch 18
[2019-07-27 17:51:02] [data] Shuffling data
[2019-07-27 17:51:04] [data] Done reading 4864128 sentences
[2019-07-27 17:51:25] [data] Done shuffling 4864128 sentences to temp files
[2019-07-27 17:53:36] Ep. 18 : Up. 658000 : Sen. 87,813 : Cost 37.66608429 : Time 347.15s : 14145.42 words/s
[2019-07-27 17:58:59] Ep. 18 : Up. 660000 : Sen. 306,553 : Cost 37.36759949 : Time 322.87s : 15244.20 words/s
[2019-07-27 17:58:59] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-27 17:59:04] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter660000.npz
[2019-07-27 17:59:07] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-27 17:59:13] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-27 17:59:31] [valid] Ep. 18 : Up. 660000 : cross-entropy : 38.4565 : new best
[2019-07-27 17:59:37] [valid] Ep. 18 : Up. 660000 : perplexity : 4.5478 : new best
[2019-07-27 18:00:27] [valid] Ep. 18 : Up. 660000 : translation : 31.36 : stalled 2 times (last best: 31.48)
[2019-07-27 18:05:52] Ep. 18 : Up. 662000 : Sen. 525,649 : Cost 37.08032608 : Time 412.56s : 11897.40 words/s
[2019-07-27 18:11:14] Ep. 18 : Up. 664000 : Sen. 744,676 : Cost 37.24814606 : Time 322.57s : 15278.55 words/s
[2019-07-27 18:16:36] Ep. 18 : Up. 666000 : Sen. 964,434 : Cost 37.11516190 : Time 322.16s : 15278.16 words/s
[2019-07-27 18:21:59] Ep. 18 : Up. 668000 : Sen. 1,182,279 : Cost 37.55661774 : Time 322.64s : 15206.62 words/s
[2019-07-27 18:27:22] Ep. 18 : Up. 670000 : Sen. 1,401,039 : Cost 37.28183746 : Time 322.75s : 15207.05 words/s
[2019-07-27 18:32:45] Ep. 18 : Up. 672000 : Sen. 1,618,893 : Cost 37.55163956 : Time 322.78s : 15177.88 words/s
[2019-07-27 18:38:08] Ep. 18 : Up. 674000 : Sen. 1,837,701 : Cost 37.65320206 : Time 323.46s : 15215.69 words/s
[2019-07-27 18:43:31] Ep. 18 : Up. 676000 : Sen. 2,057,552 : Cost 37.54248047 : Time 323.15s : 15249.91 words/s
[2019-07-27 18:48:54] Ep. 18 : Up. 678000 : Sen. 2,275,427 : Cost 37.95602798 : Time 322.44s : 15231.81 words/s
[2019-07-27 18:54:16] Ep. 18 : Up. 680000 : Sen. 2,494,964 : Cost 37.61809540 : Time 322.71s : 15257.82 words/s
[2019-07-27 18:54:16] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-27 18:54:21] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter680000.npz
[2019-07-27 18:54:23] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-27 18:54:29] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-27 18:54:47] [valid] Ep. 18 : Up. 680000 : cross-entropy : 38.495 : stalled 1 times (last best: 38.4565)
[2019-07-27 18:54:53] [valid] Ep. 18 : Up. 680000 : perplexity : 4.55471 : stalled 1 times (last best: 4.5478)
[2019-07-27 18:55:44] [valid] Ep. 18 : Up. 680000 : translation : 31.28 : stalled 3 times (last best: 31.48)
[2019-07-27 19:01:09] Ep. 18 : Up. 682000 : Sen. 2,713,406 : Cost 37.73617172 : Time 412.46s : 11919.88 words/s
[2019-07-27 19:06:31] Ep. 18 : Up. 684000 : Sen. 2,932,655 : Cost 37.64402771 : Time 322.63s : 15251.97 words/s
[2019-07-27 19:11:55] Ep. 18 : Up. 686000 : Sen. 3,152,990 : Cost 37.89157104 : Time 323.89s : 15294.37 words/s
[2019-07-27 19:17:18] Ep. 18 : Up. 688000 : Sen. 3,371,702 : Cost 37.63376236 : Time 322.57s : 15241.10 words/s
[2019-07-27 19:22:41] Ep. 18 : Up. 690000 : Sen. 3,592,024 : Cost 37.73716736 : Time 323.43s : 15289.83 words/s
[2019-07-27 19:28:05] Ep. 18 : Up. 692000 : Sen. 3,811,892 : Cost 37.73508835 : Time 323.15s : 15256.05 words/s
[2019-07-27 19:33:27] Ep. 18 : Up. 694000 : Sen. 4,030,344 : Cost 37.84532166 : Time 322.39s : 15247.53 words/s
[2019-07-27 19:38:23] Seen 4231167 samples
[2019-07-27 19:38:23] Starting epoch 19
[2019-07-27 19:38:23] [data] Shuffling data
[2019-07-27 19:38:26] [data] Done reading 4864128 sentences
[2019-07-27 19:38:47] [data] Done shuffling 4864128 sentences to temp files
[2019-07-27 19:39:15] Ep. 19 : Up. 696000 : Sen. 17,614 : Cost 37.92749405 : Time 347.67s : 14132.34 words/s
[2019-07-27 19:44:38] Ep. 19 : Up. 698000 : Sen. 237,392 : Cost 36.81315994 : Time 323.21s : 15290.63 words/s
[2019-07-27 19:50:01] Ep. 19 : Up. 700000 : Sen. 456,674 : Cost 36.88752747 : Time 323.18s : 15247.27 words/s
[2019-07-27 19:50:01] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-27 19:50:06] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter700000.npz
[2019-07-27 19:50:08] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-27 19:50:13] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-27 19:50:30] [valid] Ep. 19 : Up. 700000 : cross-entropy : 38.4385 : new best
[2019-07-27 19:50:37] [valid] Ep. 19 : Up. 700000 : perplexity : 4.54458 : new best
[2019-07-27 19:51:27] [valid] Ep. 19 : Up. 700000 : translation : 31.25 : stalled 4 times (last best: 31.48)
[2019-07-27 19:56:51] Ep. 19 : Up. 702000 : Sen. 674,831 : Cost 36.93274689 : Time 409.66s : 11952.06 words/s
[2019-07-27 20:02:13] Ep. 19 : Up. 704000 : Sen. 894,309 : Cost 36.75149155 : Time 322.67s : 15249.77 words/s
[2019-07-27 20:07:37] Ep. 19 : Up. 706000 : Sen. 1,114,300 : Cost 37.07664108 : Time 323.24s : 15274.09 words/s
[2019-07-27 20:12:58] Ep. 19 : Up. 708000 : Sen. 1,332,696 : Cost 37.37244415 : Time 321.59s : 15293.23 words/s
[2019-07-27 20:18:21] Ep. 19 : Up. 710000 : Sen. 1,552,340 : Cost 37.30557632 : Time 323.00s : 15274.70 words/s
[2019-07-27 20:23:41] Ep. 19 : Up. 712000 : Sen. 1,770,226 : Cost 37.32852173 : Time 320.32s : 15282.27 words/s
[2019-07-27 20:29:06] Ep. 19 : Up. 714000 : Sen. 1,989,937 : Cost 37.46319962 : Time 324.51s : 15252.06 words/s
[2019-07-27 20:34:29] Ep. 19 : Up. 716000 : Sen. 2,209,196 : Cost 37.48242569 : Time 322.87s : 15272.75 words/s
[2019-07-27 20:39:51] Ep. 19 : Up. 718000 : Sen. 2,427,756 : Cost 37.64989853 : Time 322.00s : 15248.25 words/s
[2019-07-27 20:45:12] Ep. 19 : Up. 720000 : Sen. 2,645,371 : Cost 37.51422882 : Time 321.03s : 15224.98 words/s
[2019-07-27 20:45:12] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-27 20:45:17] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter720000.npz
[2019-07-27 20:45:19] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-27 20:45:24] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-27 20:45:43] [valid] Ep. 19 : Up. 720000 : cross-entropy : 38.4808 : stalled 1 times (last best: 38.4385)
[2019-07-27 20:45:50] [valid] Ep. 19 : Up. 720000 : perplexity : 4.55216 : stalled 1 times (last best: 4.54458)
[2019-07-27 20:46:41] [valid] Ep. 19 : Up. 720000 : translation : 31.2 : stalled 5 times (last best: 31.48)
[2019-07-27 20:52:05] Ep. 19 : Up. 722000 : Sen. 2,864,550 : Cost 37.62009048 : Time 412.80s : 11916.04 words/s
[2019-07-27 20:57:28] Ep. 19 : Up. 724000 : Sen. 3,084,145 : Cost 37.61439133 : Time 323.41s : 15267.94 words/s
[2019-07-27 21:02:50] Ep. 19 : Up. 726000 : Sen. 3,302,691 : Cost 37.50117493 : Time 322.03s : 15258.79 words/s
[2019-07-27 21:08:13] Ep. 19 : Up. 728000 : Sen. 3,521,863 : Cost 37.65250015 : Time 322.60s : 15260.17 words/s
[2019-07-27 21:13:35] Ep. 19 : Up. 730000 : Sen. 3,740,059 : Cost 37.59484482 : Time 322.38s : 15216.31 words/s
[2019-07-27 21:18:58] Ep. 19 : Up. 732000 : Sen. 3,959,131 : Cost 37.53142929 : Time 322.43s : 15243.93 words/s
[2019-07-27 21:24:20] Ep. 19 : Up. 734000 : Sen. 4,178,324 : Cost 37.69462585 : Time 322.57s : 15246.89 words/s
[2019-07-27 21:25:38] Seen 4231167 samples
[2019-07-27 21:25:38] Starting epoch 20
[2019-07-27 21:25:38] [data] Shuffling data
[2019-07-27 21:25:41] [data] Done reading 4864128 sentences
[2019-07-27 21:26:02] [data] Done shuffling 4864128 sentences to temp files
[2019-07-27 21:30:08] Ep. 20 : Up. 736000 : Sen. 166,039 : Cost 36.98794556 : Time 347.56s : 14170.29 words/s
[2019-07-27 21:35:29] Ep. 20 : Up. 738000 : Sen. 384,164 : Cost 36.62910080 : Time 321.52s : 15249.83 words/s
[2019-07-27 21:40:52] Ep. 20 : Up. 740000 : Sen. 603,569 : Cost 37.03227997 : Time 323.22s : 15271.13 words/s
[2019-07-27 21:40:52] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-27 21:40:57] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter740000.npz
[2019-07-27 21:40:59] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-27 21:41:04] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-27 21:41:22] [valid] Ep. 20 : Up. 740000 : cross-entropy : 38.4461 : stalled 2 times (last best: 38.4385)
[2019-07-27 21:41:29] [valid] Ep. 20 : Up. 740000 : perplexity : 4.54594 : stalled 2 times (last best: 4.54458)
[2019-07-27 21:42:19] [valid] Ep. 20 : Up. 740000 : translation : 31.23 : stalled 6 times (last best: 31.48)
[2019-07-27 21:47:44] Ep. 20 : Up. 742000 : Sen. 822,638 : Cost 36.74837875 : Time 411.69s : 11944.42 words/s
[2019-07-27 21:53:06] Ep. 20 : Up. 744000 : Sen. 1,041,744 : Cost 36.99802017 : Time 322.38s : 15297.80 words/s
[2019-07-27 21:58:29] Ep. 20 : Up. 746000 : Sen. 1,260,800 : Cost 36.91834641 : Time 322.84s : 15211.75 words/s
[2019-07-27 22:03:54] Ep. 20 : Up. 748000 : Sen. 1,480,246 : Cost 37.11646271 : Time 324.70s : 15186.18 words/s
[2019-07-27 22:09:16] Ep. 20 : Up. 750000 : Sen. 1,699,605 : Cost 36.94950867 : Time 322.15s : 15301.46 words/s
[2019-07-27 22:14:38] Ep. 20 : Up. 752000 : Sen. 1,918,403 : Cost 37.24948502 : Time 321.36s : 15312.34 words/s
[2019-07-27 22:19:58] Ep. 20 : Up. 754000 : Sen. 2,137,365 : Cost 37.23135757 : Time 320.89s : 15319.06 words/s
[2019-07-27 22:25:20] Ep. 20 : Up. 756000 : Sen. 2,356,119 : Cost 37.29005051 : Time 321.26s : 15313.53 words/s
[2019-07-27 22:30:40] Ep. 20 : Up. 758000 : Sen. 2,574,574 : Cost 37.37158966 : Time 319.92s : 15319.90 words/s
[2019-07-27 22:36:00] Ep. 20 : Up. 760000 : Sen. 2,793,005 : Cost 37.23952484 : Time 320.53s : 15323.14 words/s
[2019-07-27 22:36:00] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-27 22:36:05] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter760000.npz
[2019-07-27 22:36:07] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-27 22:36:12] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-27 22:36:30] [valid] Ep. 20 : Up. 760000 : cross-entropy : 38.4789 : stalled 3 times (last best: 38.4385)
[2019-07-27 22:36:36] [valid] Ep. 20 : Up. 760000 : perplexity : 4.55182 : stalled 3 times (last best: 4.54458)
[2019-07-27 22:37:29] [valid] Ep. 20 : Up. 760000 : translation : 31.31 : stalled 7 times (last best: 31.48)
[2019-07-27 22:42:54] Ep. 20 : Up. 762000 : Sen. 3,012,553 : Cost 37.30013657 : Time 413.44s : 11913.89 words/s
[2019-07-27 22:48:17] Ep. 20 : Up. 764000 : Sen. 3,232,237 : Cost 37.41147995 : Time 323.72s : 15258.82 words/s
[2019-07-27 22:53:40] Ep. 20 : Up. 766000 : Sen. 3,450,922 : Cost 37.37174988 : Time 322.40s : 15216.41 words/s
[2019-07-27 22:59:03] Ep. 20 : Up. 768000 : Sen. 3,669,760 : Cost 37.44389343 : Time 323.04s : 15217.58 words/s
[2019-07-27 23:04:27] Ep. 20 : Up. 770000 : Sen. 3,889,031 : Cost 37.56383133 : Time 323.90s : 15226.16 words/s
[2019-07-27 23:09:48] Ep. 20 : Up. 772000 : Sen. 4,107,841 : Cost 37.48762894 : Time 321.14s : 15306.55 words/s
[2019-07-27 23:12:49] Seen 4231167 samples
[2019-07-27 23:12:49] Starting epoch 21
[2019-07-27 23:12:49] [data] Shuffling data
[2019-07-27 23:12:52] [data] Done reading 4864128 sentences
[2019-07-27 23:13:13] [data] Done shuffling 4864128 sentences to temp files
[2019-07-27 23:15:32] Ep. 21 : Up. 774000 : Sen. 94,238 : Cost 37.21468353 : Time 344.39s : 14210.27 words/s
[2019-07-27 23:20:53] Ep. 21 : Up. 776000 : Sen. 312,899 : Cost 36.53476715 : Time 320.49s : 15311.55 words/s
[2019-07-27 23:26:13] Ep. 21 : Up. 778000 : Sen. 531,278 : Cost 36.60877991 : Time 320.32s : 15319.58 words/s
[2019-07-27 23:31:34] Ep. 21 : Up. 780000 : Sen. 750,731 : Cost 36.92003250 : Time 321.17s : 15336.83 words/s
[2019-07-27 23:31:34] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-27 23:31:39] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter780000.npz
[2019-07-27 23:31:41] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-27 23:31:47] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-27 23:32:04] [valid] Ep. 21 : Up. 780000 : cross-entropy : 38.4076 : new best
[2019-07-27 23:32:11] [valid] Ep. 21 : Up. 780000 : perplexity : 4.53906 : new best
[2019-07-27 23:33:02] [valid] Ep. 21 : Up. 780000 : translation : 31.23 : stalled 8 times (last best: 31.48)
[2019-07-27 23:38:25] Ep. 21 : Up. 782000 : Sen. 969,464 : Cost 36.76619720 : Time 410.47s : 11965.98 words/s
[2019-07-27 23:43:45] Ep. 21 : Up. 784000 : Sen. 1,187,937 : Cost 36.73982620 : Time 320.15s : 15313.62 words/s
[2019-07-27 23:49:06] Ep. 21 : Up. 786000 : Sen. 1,406,930 : Cost 36.79612732 : Time 321.16s : 15299.64 words/s
[2019-07-27 23:54:29] Ep. 21 : Up. 788000 : Sen. 1,627,453 : Cost 36.92921066 : Time 322.72s : 15366.61 words/s
[2019-07-27 23:59:49] Ep. 21 : Up. 790000 : Sen. 1,846,485 : Cost 37.00439072 : Time 320.62s : 15347.30 words/s
[2019-07-28 00:05:10] Ep. 21 : Up. 792000 : Sen. 2,064,688 : Cost 37.05882263 : Time 320.63s : 15289.19 words/s
[2019-07-28 00:10:31] Ep. 21 : Up. 794000 : Sen. 2,284,281 : Cost 37.21473312 : Time 321.28s : 15359.31 words/s
[2019-07-28 00:15:52] Ep. 21 : Up. 796000 : Sen. 2,502,715 : Cost 37.11462784 : Time 320.46s : 15330.82 words/s
[2019-07-28 00:21:14] Ep. 21 : Up. 798000 : Sen. 2,722,536 : Cost 37.21757889 : Time 322.42s : 15317.53 words/s
[2019-07-28 00:26:35] Ep. 21 : Up. 800000 : Sen. 2,941,396 : Cost 37.11007309 : Time 320.97s : 15290.19 words/s
[2019-07-28 00:26:35] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-28 00:26:40] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter800000.npz
[2019-07-28 00:26:42] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-28 00:26:47] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-28 00:27:05] [valid] Ep. 21 : Up. 800000 : cross-entropy : 38.434 : stalled 1 times (last best: 38.4076)
[2019-07-28 00:27:11] [valid] Ep. 21 : Up. 800000 : perplexity : 4.54377 : stalled 1 times (last best: 4.53906)
[2019-07-28 00:28:02] [valid] Ep. 21 : Up. 800000 : translation : 31.41 : stalled 9 times (last best: 31.48)
[2019-07-28 00:33:25] Ep. 21 : Up. 802000 : Sen. 3,159,531 : Cost 37.43001175 : Time 410.10s : 11984.76 words/s
[2019-07-28 00:38:47] Ep. 21 : Up. 804000 : Sen. 3,379,356 : Cost 37.28063583 : Time 322.14s : 15327.79 words/s
[2019-07-28 00:44:08] Ep. 21 : Up. 806000 : Sen. 3,597,193 : Cost 37.44859314 : Time 320.66s : 15277.05 words/s
[2019-07-28 00:49:28] Ep. 21 : Up. 808000 : Sen. 3,815,908 : Cost 37.15224838 : Time 320.21s : 15334.18 words/s
[2019-07-28 00:54:49] Ep. 21 : Up. 810000 : Sen. 4,033,617 : Cost 37.43621445 : Time 320.47s : 15284.25 words/s
[2019-07-28 00:59:40] Seen 4231167 samples
[2019-07-28 00:59:40] Starting epoch 22
[2019-07-28 00:59:40] [data] Shuffling data
[2019-07-28 00:59:43] [data] Done reading 4864128 sentences
[2019-07-28 01:00:04] [data] Done shuffling 4864128 sentences to temp files
[2019-07-28 01:00:34] Ep. 22 : Up. 812000 : Sen. 20,404 : Cost 37.45203018 : Time 345.90s : 14196.35 words/s
[2019-07-28 01:05:56] Ep. 22 : Up. 814000 : Sen. 238,173 : Cost 36.42464828 : Time 321.82s : 15256.01 words/s
[2019-07-28 01:11:18] Ep. 22 : Up. 816000 : Sen. 457,675 : Cost 36.36728287 : Time 321.46s : 15309.30 words/s
[2019-07-28 01:16:39] Ep. 22 : Up. 818000 : Sen. 677,788 : Cost 36.33409119 : Time 321.59s : 15342.88 words/s
[2019-07-28 01:21:59] Ep. 22 : Up. 820000 : Sen. 895,200 : Cost 36.82775879 : Time 319.98s : 15308.36 words/s
[2019-07-28 01:21:59] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-28 01:22:04] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter820000.npz
[2019-07-28 01:22:06] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-28 01:22:11] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-28 01:22:28] [valid] Ep. 22 : Up. 820000 : cross-entropy : 38.3767 : new best
[2019-07-28 01:22:35] [valid] Ep. 22 : Up. 820000 : perplexity : 4.53352 : new best
[2019-07-28 01:23:25] [valid] Ep. 22 : Up. 820000 : translation : 31.49 : new best
[2019-07-28 01:28:49] Ep. 22 : Up. 822000 : Sen. 1,115,193 : Cost 36.63632202 : Time 409.68s : 12062.77 words/s
[2019-07-28 01:34:11] Ep. 22 : Up. 824000 : Sen. 1,334,526 : Cost 36.85886002 : Time 321.87s : 15316.77 words/s
[2019-07-28 01:39:33] Ep. 22 : Up. 826000 : Sen. 1,554,036 : Cost 36.76247025 : Time 321.81s : 15310.37 words/s
[2019-07-28 01:44:56] Ep. 22 : Up. 828000 : Sen. 1,773,444 : Cost 37.20121765 : Time 322.97s : 15291.00 words/s
[2019-07-28 01:50:17] Ep. 22 : Up. 830000 : Sen. 1,993,416 : Cost 36.84263992 : Time 321.61s : 15334.47 words/s
[2019-07-28 01:55:39] Ep. 22 : Up. 832000 : Sen. 2,211,880 : Cost 37.08893204 : Time 321.71s : 15305.08 words/s
[2019-07-28 02:01:01] Ep. 22 : Up. 834000 : Sen. 2,430,883 : Cost 37.01266098 : Time 321.91s : 15291.32 words/s
[2019-07-28 02:06:22] Ep. 22 : Up. 836000 : Sen. 2,649,600 : Cost 36.95400238 : Time 320.63s : 15320.78 words/s
[2019-07-28 02:11:43] Ep. 22 : Up. 838000 : Sen. 2,868,694 : Cost 36.86643982 : Time 321.22s : 15302.55 words/s
[2019-07-28 02:17:04] Ep. 22 : Up. 840000 : Sen. 3,087,519 : Cost 37.06130600 : Time 321.45s : 15297.57 words/s
[2019-07-28 02:17:04] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-28 02:17:09] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter840000.npz
[2019-07-28 02:17:11] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-28 02:17:16] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-28 02:17:34] [valid] Ep. 22 : Up. 840000 : cross-entropy : 38.3629 : new best
[2019-07-28 02:17:40] [valid] Ep. 22 : Up. 840000 : perplexity : 4.53107 : new best
[2019-07-28 02:18:31] [valid] Ep. 22 : Up. 840000 : translation : 31.63 : new best
[2019-07-28 02:23:54] Ep. 22 : Up. 842000 : Sen. 3,306,080 : Cost 37.17196274 : Time 410.13s : 11990.31 words/s
[2019-07-28 02:29:16] Ep. 22 : Up. 844000 : Sen. 3,526,144 : Cost 37.27802277 : Time 321.58s : 15355.31 words/s
[2019-07-28 02:34:39] Ep. 22 : Up. 846000 : Sen. 3,745,323 : Cost 37.32192612 : Time 322.65s : 15282.51 words/s
[2019-07-28 02:40:00] Ep. 22 : Up. 848000 : Sen. 3,964,863 : Cost 37.20729065 : Time 321.26s : 15333.12 words/s
[2019-07-28 02:45:22] Ep. 22 : Up. 850000 : Sen. 4,184,726 : Cost 37.27997208 : Time 322.01s : 15321.21 words/s
[2019-07-28 02:46:30] Seen 4231167 samples
[2019-07-28 02:46:30] Starting epoch 23
[2019-07-28 02:46:30] [data] Shuffling data
[2019-07-28 02:46:33] [data] Done reading 4864128 sentences
[2019-07-28 02:46:53] [data] Done shuffling 4864128 sentences to temp files
[2019-07-28 02:51:07] Ep. 23 : Up. 852000 : Sen. 172,172 : Cost 36.56816864 : Time 345.30s : 14232.83 words/s
[2019-07-28 02:56:29] Ep. 23 : Up. 854000 : Sen. 391,281 : Cost 36.12377930 : Time 321.63s : 15310.80 words/s
[2019-07-28 03:01:50] Ep. 23 : Up. 856000 : Sen. 609,482 : Cost 36.33580017 : Time 320.92s : 15273.72 words/s
[2019-07-28 03:07:11] Ep. 23 : Up. 858000 : Sen. 828,295 : Cost 36.40083694 : Time 321.82s : 15277.83 words/s
[2019-07-28 03:12:34] Ep. 23 : Up. 860000 : Sen. 1,047,540 : Cost 36.51227570 : Time 322.20s : 15285.02 words/s
[2019-07-28 03:12:34] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-28 03:12:39] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter860000.npz
[2019-07-28 03:12:41] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-28 03:12:46] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-28 03:13:03] [valid] Ep. 23 : Up. 860000 : cross-entropy : 38.3324 : new best
[2019-07-28 03:13:10] [valid] Ep. 23 : Up. 860000 : perplexity : 4.52562 : new best
[2019-07-28 03:14:00] [valid] Ep. 23 : Up. 860000 : translation : 31.44 : stalled 1 times (last best: 31.63)
[2019-07-28 03:19:25] Ep. 23 : Up. 862000 : Sen. 1,267,122 : Cost 36.60391235 : Time 410.84s : 12009.93 words/s
[2019-07-28 03:24:47] Ep. 23 : Up. 864000 : Sen. 1,487,282 : Cost 36.48105621 : Time 322.33s : 15321.29 words/s
[2019-07-28 03:30:10] Ep. 23 : Up. 866000 : Sen. 1,706,603 : Cost 36.73746109 : Time 323.10s : 15303.18 words/s
[2019-07-28 03:35:32] Ep. 23 : Up. 868000 : Sen. 1,925,983 : Cost 36.51345062 : Time 321.54s : 15296.76 words/s
[2019-07-28 03:40:54] Ep. 23 : Up. 870000 : Sen. 2,145,252 : Cost 36.81798935 : Time 322.27s : 15322.95 words/s
[2019-07-28 03:46:15] Ep. 23 : Up. 872000 : Sen. 2,364,406 : Cost 36.67041016 : Time 320.92s : 15306.40 words/s
[2019-07-28 03:51:37] Ep. 23 : Up. 874000 : Sen. 2,583,975 : Cost 37.01703644 : Time 322.36s : 15330.72 words/s
[2019-07-28 03:56:58] Ep. 23 : Up. 876000 : Sen. 2,803,200 : Cost 36.82878494 : Time 321.31s : 15308.88 words/s
[2019-07-28 04:02:20] Ep. 23 : Up. 878000 : Sen. 3,022,553 : Cost 37.07126617 : Time 321.53s : 15314.62 words/s
[2019-07-28 04:07:41] Ep. 23 : Up. 880000 : Sen. 3,241,786 : Cost 36.95656586 : Time 321.38s : 15303.45 words/s
[2019-07-28 04:07:41] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-28 04:07:46] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter880000.npz
[2019-07-28 04:07:49] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-28 04:07:54] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-28 04:08:11] [valid] Ep. 23 : Up. 880000 : cross-entropy : 38.3385 : stalled 1 times (last best: 38.3324)
[2019-07-28 04:08:18] [valid] Ep. 23 : Up. 880000 : perplexity : 4.52671 : stalled 1 times (last best: 4.52562)
[2019-07-28 04:09:08] [valid] Ep. 23 : Up. 880000 : translation : 31.5 : stalled 2 times (last best: 31.63)
[2019-07-28 04:14:32] Ep. 23 : Up. 882000 : Sen. 3,460,350 : Cost 37.23838043 : Time 410.42s : 12000.06 words/s
[2019-07-28 04:19:53] Ep. 23 : Up. 884000 : Sen. 3,679,607 : Cost 36.93811035 : Time 320.93s : 15332.88 words/s
[2019-07-28 04:25:14] Ep. 23 : Up. 886000 : Sen. 3,897,678 : Cost 37.02861786 : Time 321.03s : 15283.61 words/s
[2019-07-28 04:30:35] Ep. 23 : Up. 888000 : Sen. 4,116,660 : Cost 36.93319702 : Time 321.22s : 15299.63 words/s
[2019-07-28 04:33:23] Seen 4231167 samples
[2019-07-28 04:33:23] Starting epoch 24
[2019-07-28 04:33:23] [data] Shuffling data
[2019-07-28 04:33:26] [data] Done reading 4864128 sentences
[2019-07-28 04:33:47] [data] Done shuffling 4864128 sentences to temp files
[2019-07-28 04:36:22] Ep. 24 : Up. 890000 : Sen. 104,670 : Cost 36.75522232 : Time 347.45s : 14211.09 words/s
[2019-07-28 04:41:44] Ep. 24 : Up. 892000 : Sen. 324,646 : Cost 35.88267899 : Time 321.55s : 15341.69 words/s
[2019-07-28 04:47:03] Ep. 24 : Up. 894000 : Sen. 542,420 : Cost 36.39018250 : Time 319.59s : 15307.95 words/s
[2019-07-28 04:52:25] Ep. 24 : Up. 896000 : Sen. 760,938 : Cost 36.37435913 : Time 321.23s : 15271.16 words/s
[2019-07-28 04:57:45] Ep. 24 : Up. 898000 : Sen. 979,335 : Cost 36.34323883 : Time 320.15s : 15312.41 words/s
[2019-07-28 05:03:07] Ep. 24 : Up. 900000 : Sen. 1,198,671 : Cost 36.44528198 : Time 321.82s : 15312.51 words/s
[2019-07-28 05:03:07] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-28 05:03:12] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter900000.npz
[2019-07-28 05:03:14] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-28 05:03:19] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-28 05:03:36] [valid] Ep. 24 : Up. 900000 : cross-entropy : 38.3607 : stalled 2 times (last best: 38.3324)
[2019-07-28 05:03:42] [valid] Ep. 24 : Up. 900000 : perplexity : 4.53067 : stalled 2 times (last best: 4.52562)
[2019-07-28 05:04:33] [valid] Ep. 24 : Up. 900000 : translation : 31.31 : stalled 3 times (last best: 31.63)
[2019-07-28 05:09:56] Ep. 24 : Up. 902000 : Sen. 1,416,677 : Cost 36.50132751 : Time 409.15s : 12008.82 words/s
[2019-07-28 05:15:16] Ep. 24 : Up. 904000 : Sen. 1,634,995 : Cost 36.51265717 : Time 320.07s : 15304.14 words/s
[2019-07-28 05:20:39] Ep. 24 : Up. 906000 : Sen. 1,854,315 : Cost 36.80274200 : Time 322.89s : 15263.84 words/s
[2019-07-28 05:26:02] Ep. 24 : Up. 908000 : Sen. 2,074,183 : Cost 36.61760330 : Time 323.58s : 15253.04 words/s
[2019-07-28 05:31:27] Ep. 24 : Up. 910000 : Sen. 2,293,706 : Cost 36.67660522 : Time 325.04s : 15201.04 words/s
[2019-07-28 05:36:52] Ep. 24 : Up. 912000 : Sen. 2,512,384 : Cost 36.72576523 : Time 324.19s : 15147.40 words/s
[2019-07-28 05:42:16] Ep. 24 : Up. 914000 : Sen. 2,730,454 : Cost 36.74747467 : Time 324.58s : 15113.76 words/s
[2019-07-28 05:47:41] Ep. 24 : Up. 916000 : Sen. 2,949,493 : Cost 36.80535889 : Time 324.41s : 15153.66 words/s
[2019-07-28 05:53:04] Ep. 24 : Up. 918000 : Sen. 3,168,253 : Cost 36.89271164 : Time 323.70s : 15197.82 words/s
[2019-07-28 05:58:27] Ep. 24 : Up. 920000 : Sen. 3,386,173 : Cost 37.06393814 : Time 322.86s : 15197.22 words/s
[2019-07-28 05:58:27] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-28 05:58:33] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter920000.npz
[2019-07-28 05:58:35] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-28 05:58:40] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-28 05:58:58] [valid] Ep. 24 : Up. 920000 : cross-entropy : 38.3247 : new best
[2019-07-28 05:59:04] [valid] Ep. 24 : Up. 920000 : perplexity : 4.52425 : new best
[2019-07-28 05:59:55] [valid] Ep. 24 : Up. 920000 : translation : 31.42 : stalled 4 times (last best: 31.63)
[2019-07-28 06:05:20] Ep. 24 : Up. 922000 : Sen. 3,605,210 : Cost 36.88181305 : Time 412.94s : 11913.13 words/s
[2019-07-28 06:10:42] Ep. 24 : Up. 924000 : Sen. 3,824,068 : Cost 36.92918396 : Time 321.68s : 15282.98 words/s
[2019-07-28 06:16:04] Ep. 24 : Up. 926000 : Sen. 4,043,479 : Cost 36.80956268 : Time 322.57s : 15272.46 words/s
[2019-07-28 06:20:40] Seen 4231167 samples
[2019-07-28 06:20:40] Starting epoch 25
[2019-07-28 06:20:40] [data] Shuffling data
[2019-07-28 06:20:43] [data] Done reading 4864128 sentences
[2019-07-28 06:21:03] [data] Done shuffling 4864128 sentences to temp files
[2019-07-28 06:21:49] Ep. 25 : Up. 928000 : Sen. 30,363 : Cost 36.71406937 : Time 344.88s : 14207.34 words/s
[2019-07-28 06:27:12] Ep. 25 : Up. 930000 : Sen. 249,412 : Cost 35.96294403 : Time 322.46s : 15255.00 words/s
[2019-07-28 06:32:33] Ep. 25 : Up. 932000 : Sen. 467,945 : Cost 36.16699600 : Time 321.53s : 15281.19 words/s
[2019-07-28 06:37:56] Ep. 25 : Up. 934000 : Sen. 687,883 : Cost 36.09345245 : Time 322.65s : 15294.99 words/s
[2019-07-28 06:43:19] Ep. 25 : Up. 936000 : Sen. 906,362 : Cost 36.37769318 : Time 322.93s : 15222.83 words/s
[2019-07-28 06:48:41] Ep. 25 : Up. 938000 : Sen. 1,124,969 : Cost 36.24635696 : Time 322.56s : 15219.69 words/s
[2019-07-28 06:54:03] Ep. 25 : Up. 940000 : Sen. 1,343,439 : Cost 36.31347275 : Time 322.07s : 15234.05 words/s
[2019-07-28 06:54:03] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-28 06:54:09] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter940000.npz
[2019-07-28 06:54:11] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-28 06:54:16] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-28 06:54:33] [valid] Ep. 25 : Up. 940000 : cross-entropy : 38.3343 : stalled 1 times (last best: 38.3247)
[2019-07-28 06:54:40] [valid] Ep. 25 : Up. 940000 : perplexity : 4.52596 : stalled 1 times (last best: 4.52425)
[2019-07-28 06:55:30] [valid] Ep. 25 : Up. 940000 : translation : 31.38 : stalled 5 times (last best: 31.63)
[2019-07-28 07:00:54] Ep. 25 : Up. 942000 : Sen. 1,562,363 : Cost 36.37720490 : Time 411.04s : 11971.71 words/s
[2019-07-28 07:06:15] Ep. 25 : Up. 944000 : Sen. 1,780,842 : Cost 36.49996948 : Time 320.51s : 15334.56 words/s
[2019-07-28 07:11:42] Ep. 25 : Up. 946000 : Sen. 2,000,130 : Cost 36.63346481 : Time 323.19s : 15267.03 words/s
[2019-07-28 07:17:02] Ep. 25 : Up. 948000 : Sen. 2,218,096 : Cost 36.53598404 : Time 320.17s : 15278.76 words/s
[2019-07-28 07:22:23] Ep. 25 : Up. 950000 : Sen. 2,436,430 : Cost 36.62438202 : Time 320.45s : 15308.37 words/s
[2019-07-28 07:27:45] Ep. 25 : Up. 952000 : Sen. 2,655,898 : Cost 36.78660583 : Time 322.45s : 15316.60 words/s
[2019-07-28 07:33:06] Ep. 25 : Up. 954000 : Sen. 2,874,686 : Cost 36.64158630 : Time 321.39s : 15313.38 words/s
[2019-07-28 07:38:28] Ep. 25 : Up. 956000 : Sen. 3,093,203 : Cost 36.68016434 : Time 321.31s : 15302.19 words/s
[2019-07-28 07:43:48] Ep. 25 : Up. 958000 : Sen. 3,312,858 : Cost 36.45864868 : Time 320.42s : 15347.34 words/s
[2019-07-28 07:49:08] Ep. 25 : Up. 960000 : Sen. 3,531,101 : Cost 36.71346283 : Time 319.85s : 15340.06 words/s
[2019-07-28 07:49:08] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-28 07:49:13] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter960000.npz
[2019-07-28 07:49:15] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-28 07:49:20] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-28 07:49:37] [valid] Ep. 25 : Up. 960000 : cross-entropy : 38.3085 : new best
[2019-07-28 07:49:43] [valid] Ep. 25 : Up. 960000 : perplexity : 4.52138 : new best
[2019-07-28 07:50:32] [valid] Ep. 25 : Up. 960000 : translation : 31.64 : new best
[2019-07-28 07:55:55] Ep. 25 : Up. 962000 : Sen. 3,750,535 : Cost 36.66922760 : Time 406.59s : 12126.43 words/s
[2019-07-28 08:01:14] Ep. 25 : Up. 964000 : Sen. 3,970,467 : Cost 36.71203995 : Time 319.54s : 15435.96 words/s
[2019-07-28 08:06:34] Ep. 25 : Up. 966000 : Sen. 4,189,915 : Cost 36.68684387 : Time 319.84s : 15394.50 words/s
[2019-07-28 08:07:35] Seen 4231167 samples
[2019-07-28 08:07:35] Starting epoch 26
[2019-07-28 08:07:35] [data] Shuffling data
[2019-07-28 08:07:37] [data] Done reading 4864128 sentences
[2019-07-28 08:07:57] [data] Done shuffling 4864128 sentences to temp files
[2019-07-28 08:12:17] Ep. 26 : Up. 968000 : Sen. 177,865 : Cost 36.11672592 : Time 343.44s : 14345.40 words/s
[2019-07-28 08:17:38] Ep. 26 : Up. 970000 : Sen. 397,013 : Cost 36.02196884 : Time 320.55s : 15373.20 words/s
[2019-07-28 08:22:57] Ep. 26 : Up. 972000 : Sen. 615,343 : Cost 36.05884171 : Time 319.06s : 15361.64 words/s
[2019-07-28 08:28:16] Ep. 26 : Up. 974000 : Sen. 834,238 : Cost 36.04705429 : Time 318.66s : 15411.68 words/s
[2019-07-28 08:33:34] Ep. 26 : Up. 976000 : Sen. 1,053,290 : Cost 36.31096649 : Time 318.77s : 15466.35 words/s
[2019-07-28 08:38:53] Ep. 26 : Up. 978000 : Sen. 1,272,564 : Cost 36.38139343 : Time 318.57s : 15470.46 words/s
[2019-07-28 08:44:12] Ep. 26 : Up. 980000 : Sen. 1,492,261 : Cost 36.25225830 : Time 319.20s : 15449.20 words/s
[2019-07-28 08:44:12] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-28 08:44:17] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter980000.npz
[2019-07-28 08:44:19] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-28 08:44:24] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-28 08:44:41] [valid] Ep. 26 : Up. 980000 : cross-entropy : 38.3417 : stalled 1 times (last best: 38.3085)
[2019-07-28 08:44:47] [valid] Ep. 26 : Up. 980000 : perplexity : 4.52729 : stalled 1 times (last best: 4.52138)
[2019-07-28 08:45:35] [valid] Ep. 26 : Up. 980000 : translation : 31.35 : stalled 1 times (last best: 31.64)
[2019-07-28 08:50:56] Ep. 26 : Up. 982000 : Sen. 1,711,596 : Cost 36.44243622 : Time 403.40s : 12248.89 words/s
[2019-07-28 08:56:13] Ep. 26 : Up. 984000 : Sen. 1,931,175 : Cost 36.26543427 : Time 317.50s : 15483.06 words/s
[2019-07-28 09:01:31] Ep. 26 : Up. 986000 : Sen. 2,149,331 : Cost 36.20759583 : Time 318.13s : 15445.33 words/s
[2019-07-28 09:06:49] Ep. 26 : Up. 988000 : Sen. 2,368,208 : Cost 36.48907852 : Time 317.26s : 15482.26 words/s
[2019-07-28 09:12:06] Ep. 26 : Up. 990000 : Sen. 2,587,634 : Cost 36.39413834 : Time 317.75s : 15492.51 words/s
[2019-07-28 09:17:23] Ep. 26 : Up. 992000 : Sen. 2,805,647 : Cost 36.77229309 : Time 317.13s : 15466.79 words/s
[2019-07-28 09:22:41] Ep. 26 : Up. 994000 : Sen. 3,024,324 : Cost 36.42057419 : Time 317.77s : 15446.33 words/s
[2019-07-28 09:28:01] Ep. 26 : Up. 996000 : Sen. 3,242,701 : Cost 36.69514084 : Time 319.45s : 15396.39 words/s
[2019-07-28 09:33:19] Ep. 26 : Up. 998000 : Sen. 3,461,556 : Cost 36.53695297 : Time 318.79s : 15391.44 words/s
[2019-07-28 09:38:39] Ep. 26 : Up. 1000000 : Sen. 3,680,000 : Cost 36.78451157 : Time 319.21s : 15401.46 words/s
[2019-07-28 09:38:39] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-28 09:38:44] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter1000000.npz
[2019-07-28 09:38:45] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-28 09:38:50] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-28 09:39:07] [valid] Ep. 26 : Up. 1000000 : cross-entropy : 38.3368 : stalled 2 times (last best: 38.3085)
[2019-07-28 09:39:13] [valid] Ep. 26 : Up. 1000000 : perplexity : 4.52641 : stalled 2 times (last best: 4.52138)
[2019-07-28 09:40:01] [valid] Ep. 26 : Up. 1000000 : translation : 31.5 : stalled 2 times (last best: 31.64)
[2019-07-28 09:45:22] Ep. 26 : Up. 1002000 : Sen. 3,898,333 : Cost 36.70188522 : Time 403.68s : 12162.55 words/s
[2019-07-28 09:50:41] Ep. 26 : Up. 1004000 : Sen. 4,117,124 : Cost 36.66789246 : Time 318.90s : 15422.32 words/s
[2019-07-28 09:53:27] Seen 4231167 samples
[2019-07-28 09:53:27] Starting epoch 27
[2019-07-28 09:53:27] [data] Shuffling data
[2019-07-28 09:53:30] [data] Done reading 4864128 sentences
[2019-07-28 09:53:48] [data] Done shuffling 4864128 sentences to temp files
[2019-07-28 09:56:21] Ep. 27 : Up. 1006000 : Sen. 104,046 : Cost 36.32909012 : Time 339.81s : 14434.78 words/s
[2019-07-28 10:01:41] Ep. 27 : Up. 1008000 : Sen. 322,492 : Cost 35.63080978 : Time 320.13s : 15370.60 words/s
[2019-07-28 10:07:00] Ep. 27 : Up. 1010000 : Sen. 541,007 : Cost 35.86637497 : Time 318.59s : 15385.96 words/s
[2019-07-28 10:12:19] Ep. 27 : Up. 1012000 : Sen. 759,654 : Cost 36.14797592 : Time 319.22s : 15395.64 words/s
[2019-07-28 10:17:38] Ep. 27 : Up. 1014000 : Sen. 978,534 : Cost 35.94635773 : Time 319.25s : 15387.79 words/s
[2019-07-28 10:22:58] Ep. 27 : Up. 1016000 : Sen. 1,197,742 : Cost 36.21418762 : Time 320.10s : 15402.49 words/s
[2019-07-28 10:28:18] Ep. 27 : Up. 1018000 : Sen. 1,416,902 : Cost 35.85174179 : Time 319.44s : 15359.10 words/s
[2019-07-28 10:33:38] Ep. 27 : Up. 1020000 : Sen. 1,635,997 : Cost 36.22505188 : Time 319.85s : 15399.78 words/s
[2019-07-28 10:33:38] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-28 10:33:43] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter1020000.npz
[2019-07-28 10:33:44] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-28 10:33:49] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-28 10:34:06] [valid] Ep. 27 : Up. 1020000 : cross-entropy : 38.3701 : stalled 3 times (last best: 38.3085)
[2019-07-28 10:34:12] [valid] Ep. 27 : Up. 1020000 : perplexity : 4.53234 : stalled 3 times (last best: 4.52138)
[2019-07-28 10:35:00] [valid] Ep. 27 : Up. 1020000 : translation : 31.66 : new best
[2019-07-28 10:40:21] Ep. 27 : Up. 1022000 : Sen. 1,855,459 : Cost 36.13619614 : Time 403.63s : 12208.24 words/s
[2019-07-28 10:45:40] Ep. 27 : Up. 1024000 : Sen. 2,074,534 : Cost 36.33143234 : Time 319.24s : 15416.70 words/s
[2019-07-28 10:51:00] Ep. 27 : Up. 1026000 : Sen. 2,294,055 : Cost 36.48171234 : Time 319.44s : 15424.22 words/s
[2019-07-28 10:56:20] Ep. 27 : Up. 1028000 : Sen. 2,512,862 : Cost 36.48906708 : Time 319.63s : 15396.31 words/s
[2019-07-28 11:01:39] Ep. 27 : Up. 1030000 : Sen. 2,732,414 : Cost 36.46881104 : Time 319.39s : 15428.37 words/s
[2019-07-28 11:06:57] Ep. 27 : Up. 1032000 : Sen. 2,950,117 : Cost 36.54101562 : Time 318.13s : 15416.22 words/s
[2019-07-28 11:12:15] Ep. 27 : Up. 1034000 : Sen. 3,168,394 : Cost 36.32217407 : Time 317.79s : 15400.13 words/s
[2019-07-28 11:17:34] Ep. 27 : Up. 1036000 : Sen. 3,387,179 : Cost 36.49382782 : Time 319.25s : 15404.73 words/s
[2019-07-28 11:22:54] Ep. 27 : Up. 1038000 : Sen. 3,606,618 : Cost 36.63315201 : Time 320.25s : 15396.00 words/s
[2019-07-28 11:28:14] Ep. 27 : Up. 1040000 : Sen. 3,826,024 : Cost 36.48974228 : Time 320.12s : 15407.39 words/s
[2019-07-28 11:28:14] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-28 11:28:19] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter1040000.npz
[2019-07-28 11:28:21] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-28 11:28:26] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-28 11:28:43] [valid] Ep. 27 : Up. 1040000 : cross-entropy : 38.3206 : stalled 4 times (last best: 38.3085)
[2019-07-28 11:28:49] [valid] Ep. 27 : Up. 1040000 : perplexity : 4.52352 : stalled 4 times (last best: 4.52138)
[2019-07-28 11:29:37] [valid] Ep. 27 : Up. 1040000 : translation : 31.56 : stalled 1 times (last best: 31.66)
[2019-07-28 11:34:59] Ep. 27 : Up. 1042000 : Sen. 4,044,931 : Cost 36.83342743 : Time 404.40s : 12197.94 words/s
[2019-07-28 11:39:30] Seen 4231167 samples
[2019-07-28 11:39:30] Starting epoch 28
[2019-07-28 11:39:30] [data] Shuffling data
[2019-07-28 11:39:33] [data] Done reading 4864128 sentences
[2019-07-28 11:39:51] [data] Done shuffling 4864128 sentences to temp files
[2019-07-28 11:40:40] Ep. 28 : Up. 1044000 : Sen. 32,924 : Cost 36.39871216 : Time 340.87s : 14422.08 words/s
[2019-07-28 11:45:59] Ep. 28 : Up. 1046000 : Sen. 250,872 : Cost 35.78528214 : Time 319.31s : 15365.52 words/s
[2019-07-28 11:51:18] Ep. 28 : Up. 1048000 : Sen. 469,798 : Cost 35.59125519 : Time 319.03s : 15421.89 words/s
[2019-07-28 11:56:37] Ep. 28 : Up. 1050000 : Sen. 688,167 : Cost 35.69617462 : Time 319.24s : 15355.51 words/s
[2019-07-28 12:01:57] Ep. 28 : Up. 1052000 : Sen. 907,079 : Cost 35.92838287 : Time 319.29s : 15401.31 words/s
[2019-07-28 12:07:16] Ep. 28 : Up. 1054000 : Sen. 1,126,613 : Cost 35.87697983 : Time 319.62s : 15422.83 words/s
[2019-07-28 12:12:36] Ep. 28 : Up. 1056000 : Sen. 1,345,710 : Cost 35.82530212 : Time 319.49s : 15417.24 words/s
[2019-07-28 12:17:55] Ep. 28 : Up. 1058000 : Sen. 1,564,540 : Cost 36.05371857 : Time 319.54s : 15387.86 words/s
[2019-07-28 12:23:15] Ep. 28 : Up. 1060000 : Sen. 1,784,331 : Cost 36.06622314 : Time 320.15s : 15426.84 words/s
[2019-07-28 12:23:15] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-28 12:23:21] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.iter1060000.npz
[2019-07-28 12:23:22] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-28 12:23:27] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-28 12:23:45] [valid] Ep. 28 : Up. 1060000 : cross-entropy : 38.3825 : stalled 5 times (last best: 38.3085)
[2019-07-28 12:23:51] [valid] Ep. 28 : Up. 1060000 : perplexity : 4.53457 : stalled 5 times (last best: 4.52138)
[2019-07-28 12:24:38] [valid] Ep. 28 : Up. 1060000 : translation : 31.64 : stalled 2 times (last best: 31.66)
[2019-07-28 12:24:40] Training finished
[2019-07-28 12:24:45] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-28 12:24:49] Saving model to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-28 12:24:54] Saving Adam parameters to ../experiments/100M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
