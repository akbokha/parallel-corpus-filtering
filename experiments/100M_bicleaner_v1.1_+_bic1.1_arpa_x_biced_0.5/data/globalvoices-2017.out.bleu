MT evaluation scorer began on 2019 Aug 12 at 23:03:26
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/100M_bicleaner_v1.1_+_bic1.1_arpa_x_biced_0.5/data/globalvoices-2017.de.sgm -r ../experiments/100M_bicleaner_v1.1_+_bic1.1_arpa_x_biced_0.5/data/globalvoices-2017.en.sgm -t ../experiments/100M_bicleaner_v1.1_+_bic1.1_arpa_x_biced_0.5/data/globalvoices-2017.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 3000 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 1.07089373904732 (67220/62770), penalty (log): 0
NIST score = 6.9282  BLEU score = 0.2603 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  5.2348   1.4229   0.2407   0.0249   0.0048   0.0013   0.0005   0.0002   0.0001  "Edinburgh"

 BLEU:  0.5618   0.3176   0.1991   0.1292   0.0857   0.0579   0.0392   0.0274   0.0195  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  5.2348   6.6577   6.8984   6.9233   6.9282   6.9294   6.9299   6.9301   6.9302  "Edinburgh"

 BLEU:  0.5618   0.4224   0.3287   0.2603   0.2084   0.1683   0.1367   0.1118   0.0921  "Edinburgh"
MT evaluation scorer ended on 2019 Aug 12 at 23:03:46
