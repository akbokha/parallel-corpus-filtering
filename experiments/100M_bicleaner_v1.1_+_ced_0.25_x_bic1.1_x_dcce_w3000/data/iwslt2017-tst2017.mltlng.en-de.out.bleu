MT evaluation scorer began on 2019 Aug 3 at 22:15:52
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_bic1.1_x_dcce_w3000/data/iwslt2017-tst2017.mltlng.en-de.de.sgm -r ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_bic1.1_x_dcce_w3000/data/iwslt2017-tst2017.mltlng.en-de.en.sgm -t ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_bic1.1_x_dcce_w3000/data/iwslt2017-tst2017.mltlng.en-de.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 1138 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 0.949599465954606 (19915/20972), penalty (log): -0.0530755711775044
NIST score = 6.5095  BLEU score = 0.2543 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.9610   1.3118   0.2103   0.0225   0.0038   0.0009   0.0005   0.0001   0.0000  "Edinburgh"

 BLEU:  0.5936   0.3348   0.2045   0.1274   0.0801   0.0499   0.0311   0.0192   0.0122  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.9610   6.2729   6.4832   6.5057   6.5095   6.5104   6.5109   6.5110   6.5110  "Edinburgh"

 BLEU:  0.5629   0.4227   0.3260   0.2543   0.1998   0.1571   0.1237   0.0974   0.0768  "Edinburgh"
MT evaluation scorer ended on 2019 Aug 3 at 22:15:56
