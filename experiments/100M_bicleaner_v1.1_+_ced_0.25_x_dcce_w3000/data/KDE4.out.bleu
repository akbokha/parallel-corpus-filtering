MT evaluation scorer began on 2019 Aug 5 at 11:03:11
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/data/KDE4.de.sgm -r ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/data/KDE4.en.sgm -t ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/data/KDE4.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 3000 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 0.931961295066451 (119141/127839), penalty (log): -0.0730059341452565
NIST score = 6.9242  BLEU score = 0.2398 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  5.0067   1.4806   0.3470   0.0738   0.0161   0.0048   0.0019   0.0014   0.0007  "Edinburgh"

 BLEU:  0.6082   0.3175   0.1912   0.1198   0.0779   0.0527   0.0371   0.0271   0.0206  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  5.0067   6.4873   6.8343   6.9081   6.9242   6.9289   6.9309   6.9322   6.9329  "Edinburgh"

 BLEU:  0.5654   0.4085   0.3096   0.2398   0.1887   0.1507   0.1221   0.1002   0.0834  "Edinburgh"
MT evaluation scorer ended on 2019 Aug 5 at 11:03:55
