[2019-08-02 02:32:44] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-02 02:32:44] [marian] Running on hretha as process 12147 with command line:
[2019-08-02 02:32:44] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz -T . --devices 0 --train-sets ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/data/train.bpe.de ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/data/train.bpe.en --vocabs ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/data/train.bpe.de.json ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/data/dev.bpe.de ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/dev.out --valid-script-path ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/train.log --valid-log ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/valid.log
[2019-08-02 02:32:44] [config] after-batches: 0
[2019-08-02 02:32:44] [config] after-epochs: 0
[2019-08-02 02:32:44] [config] allow-unk: false
[2019-08-02 02:32:44] [config] beam-size: 12
[2019-08-02 02:32:44] [config] bert-class-symbol: "[CLS]"
[2019-08-02 02:32:44] [config] bert-mask-symbol: "[MASK]"
[2019-08-02 02:32:44] [config] bert-masking-fraction: 0.15
[2019-08-02 02:32:44] [config] bert-sep-symbol: "[SEP]"
[2019-08-02 02:32:44] [config] bert-train-type-embeddings: true
[2019-08-02 02:32:44] [config] bert-type-vocab-size: 2
[2019-08-02 02:32:44] [config] best-deep: false
[2019-08-02 02:32:44] [config] clip-gemm: 0
[2019-08-02 02:32:44] [config] clip-norm: 1
[2019-08-02 02:32:44] [config] cost-type: ce-mean
[2019-08-02 02:32:44] [config] cpu-threads: 0
[2019-08-02 02:32:44] [config] data-weighting: ""
[2019-08-02 02:32:44] [config] data-weighting-type: sentence
[2019-08-02 02:32:44] [config] dec-cell: gru
[2019-08-02 02:32:44] [config] dec-cell-base-depth: 2
[2019-08-02 02:32:44] [config] dec-cell-high-depth: 1
[2019-08-02 02:32:44] [config] dec-depth: 1
[2019-08-02 02:32:44] [config] devices:
[2019-08-02 02:32:44] [config]   - 0
[2019-08-02 02:32:44] [config] dim-emb: 512
[2019-08-02 02:32:44] [config] dim-rnn: 1024
[2019-08-02 02:32:44] [config] dim-vocabs:
[2019-08-02 02:32:44] [config]   - 50000
[2019-08-02 02:32:44] [config]   - 50000
[2019-08-02 02:32:44] [config] disp-first: 0
[2019-08-02 02:32:44] [config] disp-freq: 2000
[2019-08-02 02:32:44] [config] disp-label-counts: false
[2019-08-02 02:32:44] [config] dropout-rnn: 0.2
[2019-08-02 02:32:44] [config] dropout-src: 0.1
[2019-08-02 02:32:44] [config] dropout-trg: 0.1
[2019-08-02 02:32:44] [config] dump-config: ""
[2019-08-02 02:32:44] [config] early-stopping: 5
[2019-08-02 02:32:44] [config] embedding-fix-src: false
[2019-08-02 02:32:44] [config] embedding-fix-trg: false
[2019-08-02 02:32:44] [config] embedding-normalization: false
[2019-08-02 02:32:44] [config] embedding-vectors:
[2019-08-02 02:32:44] [config]   []
[2019-08-02 02:32:44] [config] enc-cell: gru
[2019-08-02 02:32:44] [config] enc-cell-depth: 1
[2019-08-02 02:32:44] [config] enc-depth: 1
[2019-08-02 02:32:44] [config] enc-type: bidirectional
[2019-08-02 02:32:44] [config] exponential-smoothing: 0.0001
[2019-08-02 02:32:44] [config] grad-dropping-momentum: 0
[2019-08-02 02:32:44] [config] grad-dropping-rate: 0
[2019-08-02 02:32:44] [config] grad-dropping-warmup: 100
[2019-08-02 02:32:44] [config] guided-alignment: none
[2019-08-02 02:32:44] [config] guided-alignment-cost: mse
[2019-08-02 02:32:44] [config] guided-alignment-weight: 0.1
[2019-08-02 02:32:44] [config] ignore-model-config: false
[2019-08-02 02:32:44] [config] input-types:
[2019-08-02 02:32:44] [config]   []
[2019-08-02 02:32:44] [config] interpolate-env-vars: false
[2019-08-02 02:32:44] [config] keep-best: false
[2019-08-02 02:32:44] [config] label-smoothing: 0
[2019-08-02 02:32:44] [config] layer-normalization: true
[2019-08-02 02:32:44] [config] learn-rate: 0.0001
[2019-08-02 02:32:44] [config] log: ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/train.log
[2019-08-02 02:32:44] [config] log-level: info
[2019-08-02 02:32:44] [config] log-time-zone: ""
[2019-08-02 02:32:44] [config] lr-decay: 0
[2019-08-02 02:32:44] [config] lr-decay-freq: 50000
[2019-08-02 02:32:44] [config] lr-decay-inv-sqrt:
[2019-08-02 02:32:44] [config]   - 0
[2019-08-02 02:32:44] [config] lr-decay-repeat-warmup: false
[2019-08-02 02:32:44] [config] lr-decay-reset-optimizer: false
[2019-08-02 02:32:44] [config] lr-decay-start:
[2019-08-02 02:32:44] [config]   - 10
[2019-08-02 02:32:44] [config]   - 1
[2019-08-02 02:32:44] [config] lr-decay-strategy: epoch+stalled
[2019-08-02 02:32:44] [config] lr-report: false
[2019-08-02 02:32:44] [config] lr-warmup: 0
[2019-08-02 02:32:44] [config] lr-warmup-at-reload: false
[2019-08-02 02:32:44] [config] lr-warmup-cycle: false
[2019-08-02 02:32:44] [config] lr-warmup-start-rate: 0
[2019-08-02 02:32:44] [config] max-length: 50
[2019-08-02 02:32:44] [config] max-length-crop: false
[2019-08-02 02:32:44] [config] max-length-factor: 3
[2019-08-02 02:32:44] [config] maxi-batch: 100
[2019-08-02 02:32:44] [config] maxi-batch-sort: trg
[2019-08-02 02:32:44] [config] mini-batch: 64
[2019-08-02 02:32:44] [config] mini-batch-fit: true
[2019-08-02 02:32:44] [config] mini-batch-fit-step: 10
[2019-08-02 02:32:44] [config] mini-batch-overstuff: 1
[2019-08-02 02:32:44] [config] mini-batch-track-lr: false
[2019-08-02 02:32:44] [config] mini-batch-understuff: 1
[2019-08-02 02:32:44] [config] mini-batch-warmup: 0
[2019-08-02 02:32:44] [config] mini-batch-words: 0
[2019-08-02 02:32:44] [config] mini-batch-words-ref: 0
[2019-08-02 02:32:44] [config] model: ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz
[2019-08-02 02:32:44] [config] multi-loss-type: sum
[2019-08-02 02:32:44] [config] multi-node: false
[2019-08-02 02:32:44] [config] multi-node-overlap: true
[2019-08-02 02:32:44] [config] n-best: false
[2019-08-02 02:32:44] [config] no-nccl: false
[2019-08-02 02:32:44] [config] no-reload: false
[2019-08-02 02:32:44] [config] no-restore-corpus: false
[2019-08-02 02:32:44] [config] no-shuffle: false
[2019-08-02 02:32:44] [config] normalize: 1
[2019-08-02 02:32:44] [config] num-devices: 0
[2019-08-02 02:32:44] [config] optimizer: adam
[2019-08-02 02:32:44] [config] optimizer-delay: 1
[2019-08-02 02:32:44] [config] optimizer-params:
[2019-08-02 02:32:44] [config]   []
[2019-08-02 02:32:44] [config] overwrite: false
[2019-08-02 02:32:44] [config] pretrained-model: ""
[2019-08-02 02:32:44] [config] quiet: false
[2019-08-02 02:32:44] [config] quiet-translation: true
[2019-08-02 02:32:44] [config] relative-paths: false
[2019-08-02 02:32:44] [config] right-left: false
[2019-08-02 02:32:44] [config] save-freq: 20000
[2019-08-02 02:32:44] [config] seed: 1111
[2019-08-02 02:32:44] [config] shuffle-in-ram: false
[2019-08-02 02:32:44] [config] skip: false
[2019-08-02 02:32:44] [config] sqlite: ""
[2019-08-02 02:32:44] [config] sqlite-drop: false
[2019-08-02 02:32:44] [config] sync-sgd: true
[2019-08-02 02:32:44] [config] tempdir: .
[2019-08-02 02:32:44] [config] tied-embeddings: false
[2019-08-02 02:32:44] [config] tied-embeddings-all: false
[2019-08-02 02:32:44] [config] tied-embeddings-src: false
[2019-08-02 02:32:44] [config] train-sets:
[2019-08-02 02:32:44] [config]   - ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/data/train.bpe.de
[2019-08-02 02:32:44] [config]   - ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/data/train.bpe.en
[2019-08-02 02:32:44] [config] transformer-aan-activation: swish
[2019-08-02 02:32:44] [config] transformer-aan-depth: 2
[2019-08-02 02:32:44] [config] transformer-aan-nogate: false
[2019-08-02 02:32:44] [config] transformer-decoder-autoreg: self-attention
[2019-08-02 02:32:44] [config] transformer-dim-aan: 2048
[2019-08-02 02:32:44] [config] transformer-dim-ffn: 2048
[2019-08-02 02:32:44] [config] transformer-dropout: 0
[2019-08-02 02:32:44] [config] transformer-dropout-attention: 0
[2019-08-02 02:32:44] [config] transformer-dropout-ffn: 0
[2019-08-02 02:32:44] [config] transformer-ffn-activation: swish
[2019-08-02 02:32:44] [config] transformer-ffn-depth: 2
[2019-08-02 02:32:44] [config] transformer-guided-alignment-layer: last
[2019-08-02 02:32:44] [config] transformer-heads: 8
[2019-08-02 02:32:44] [config] transformer-no-projection: false
[2019-08-02 02:32:44] [config] transformer-postprocess: dan
[2019-08-02 02:32:44] [config] transformer-postprocess-emb: d
[2019-08-02 02:32:44] [config] transformer-preprocess: ""
[2019-08-02 02:32:44] [config] transformer-tied-layers:
[2019-08-02 02:32:44] [config]   []
[2019-08-02 02:32:44] [config] transformer-train-position-embeddings: false
[2019-08-02 02:32:44] [config] type: amun
[2019-08-02 02:32:44] [config] ulr: false
[2019-08-02 02:32:44] [config] ulr-dim-emb: 0
[2019-08-02 02:32:44] [config] ulr-dropout: 0
[2019-08-02 02:32:44] [config] ulr-keys-vectors: ""
[2019-08-02 02:32:44] [config] ulr-query-vectors: ""
[2019-08-02 02:32:44] [config] ulr-softmax-temperature: 1
[2019-08-02 02:32:44] [config] ulr-trainable-transformation: false
[2019-08-02 02:32:44] [config] valid-freq: 20000
[2019-08-02 02:32:44] [config] valid-log: ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/valid.log
[2019-08-02 02:32:44] [config] valid-max-length: 1000
[2019-08-02 02:32:44] [config] valid-metrics:
[2019-08-02 02:32:44] [config]   - cross-entropy
[2019-08-02 02:32:44] [config]   - perplexity
[2019-08-02 02:32:44] [config]   - translation
[2019-08-02 02:32:44] [config] valid-mini-batch: 8
[2019-08-02 02:32:44] [config] valid-script-path: ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/score-dev.sh
[2019-08-02 02:32:44] [config] valid-sets:
[2019-08-02 02:32:44] [config]   - ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/data/dev.bpe.de
[2019-08-02 02:32:44] [config]   - ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/data/dev.bpe.en
[2019-08-02 02:32:44] [config] valid-translation-output: ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/dev.out
[2019-08-02 02:32:44] [config] vocabs:
[2019-08-02 02:32:44] [config]   - ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/data/train.bpe.de.json
[2019-08-02 02:32:44] [config]   - ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/data/train.bpe.en.json
[2019-08-02 02:32:44] [config] word-penalty: 0
[2019-08-02 02:32:44] [config] workspace: 3000
[2019-08-02 02:32:44] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-02 02:32:44] Using synchronous training
[2019-08-02 02:32:44] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/data/train.bpe.de.json
[2019-08-02 02:32:45] [data] Using unused word id eos for 0
[2019-08-02 02:32:45] [data] Using unused word id UNK for 1
[2019-08-02 02:32:45] [data] Setting vocabulary size for input 0 to 50000
[2019-08-02 02:32:45] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/data/train.bpe.en.json
[2019-08-02 02:32:45] [data] Using unused word id eos for 0
[2019-08-02 02:32:45] [data] Using unused word id UNK for 1
[2019-08-02 02:32:45] [data] Setting vocabulary size for input 1 to 50000
[2019-08-02 02:32:45] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-02 02:32:45] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-02 02:32:47] [memory] Extending reserved space to 3072 MB (device gpu0)
[2019-08-02 02:32:47] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-02 02:32:47] [comm] NCCLCommunicator constructed successfully.
[2019-08-02 02:32:47] [training] Using 1 GPUs
[2019-08-02 02:32:47] [memory] Reserving 422 MB, device gpu0
[2019-08-02 02:32:47] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-02 02:32:47] [memory] Reserving 422 MB, device gpu0
[2019-08-02 02:32:52] [batching] Done. Typical MB size is 4042 target words
[2019-08-02 02:32:52] [memory] Extending reserved space to 3072 MB (device gpu0)
[2019-08-02 02:32:52] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-02 02:32:52] [comm] NCCLCommunicator constructed successfully.
[2019-08-02 02:32:52] [training] Using 1 GPUs
[2019-08-02 02:32:52] Training started
[2019-08-02 02:32:52] [data] Shuffling data
[2019-08-02 02:32:56] [data] Done reading 5667937 sentences
[2019-08-02 02:33:29] [data] Done shuffling 5667937 sentences to temp files
[2019-08-02 02:33:31] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-02 02:33:31] [memory] Reserving 422 MB, device gpu0
[2019-08-02 02:33:31] [memory] Reserving 422 MB, device gpu0
[2019-08-02 02:33:32] [memory] Reserving 422 MB, device gpu0
[2019-08-02 02:33:32] [memory] Reserving 844 MB, device gpu0
[2019-08-02 02:41:59] Ep. 1 : Up. 2000 : Sen. 227,655 : Cost 127.06432343 : Time 553.57s : 8266.33 words/s
[2019-08-02 02:50:27] Ep. 1 : Up. 4000 : Sen. 453,587 : Cost 102.64824677 : Time 508.46s : 8972.30 words/s
[2019-08-02 02:58:57] Ep. 1 : Up. 6000 : Sen. 680,061 : Cost 89.95032501 : Time 509.89s : 8941.36 words/s
[2019-08-02 03:07:23] Ep. 1 : Up. 8000 : Sen. 906,622 : Cost 81.12069702 : Time 506.22s : 8993.40 words/s
[2019-08-02 03:15:51] Ep. 1 : Up. 10000 : Sen. 1,134,122 : Cost 75.30191803 : Time 507.13s : 9023.47 words/s
[2019-08-02 03:24:17] Ep. 1 : Up. 12000 : Sen. 1,361,373 : Cost 71.51815033 : Time 506.84s : 9041.70 words/s
[2019-08-02 03:32:41] Ep. 1 : Up. 14000 : Sen. 1,588,473 : Cost 67.61078644 : Time 503.69s : 9041.65 words/s
[2019-08-02 03:41:11] Ep. 1 : Up. 16000 : Sen. 1,816,676 : Cost 65.46694183 : Time 509.78s : 9004.53 words/s
[2019-08-02 03:49:40] Ep. 1 : Up. 18000 : Sen. 2,043,287 : Cost 63.65647125 : Time 508.62s : 8984.27 words/s
[2019-08-02 03:58:06] Ep. 1 : Up. 20000 : Sen. 2,271,553 : Cost 61.65365982 : Time 506.71s : 9027.95 words/s
[2019-08-02 03:58:06] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz.orig.npz
[2019-08-02 03:58:15] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.iter20000.npz
[2019-08-02 03:58:22] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz
[2019-08-02 03:58:31] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz.optimizer.npz
[2019-08-02 03:58:55] [valid] Ep. 1 : Up. 20000 : cross-entropy : 74.7424 : new best
[2019-08-02 03:59:03] [valid] Ep. 1 : Up. 20000 : perplexity : 18.8789 : new best
[2019-08-02 04:00:15] [valid] Ep. 1 : Up. 20000 : translation : 18.59 : new best
[2019-08-02 04:08:44] Ep. 1 : Up. 22000 : Sen. 2,497,820 : Cost 60.71510696 : Time 637.28s : 7145.65 words/s
[2019-08-02 04:17:14] Ep. 1 : Up. 24000 : Sen. 2,725,658 : Cost 59.57900238 : Time 510.07s : 9001.74 words/s
[2019-08-02 04:25:39] Ep. 1 : Up. 26000 : Sen. 2,952,781 : Cost 58.32456589 : Time 505.69s : 9034.25 words/s
[2019-08-02 04:34:06] Ep. 1 : Up. 28000 : Sen. 3,179,020 : Cost 57.50750732 : Time 506.67s : 9013.81 words/s
[2019-08-02 04:42:34] Ep. 1 : Up. 30000 : Sen. 3,405,946 : Cost 56.66994476 : Time 507.61s : 9000.49 words/s
[2019-08-02 04:50:59] Ep. 1 : Up. 32000 : Sen. 3,632,302 : Cost 55.80435181 : Time 505.33s : 9035.22 words/s
[2019-08-02 04:59:25] Ep. 1 : Up. 34000 : Sen. 3,858,758 : Cost 55.30527878 : Time 505.83s : 9012.36 words/s
[2019-08-02 05:07:53] Ep. 1 : Up. 36000 : Sen. 4,085,577 : Cost 54.67374420 : Time 508.61s : 8982.66 words/s
[2019-08-02 05:16:22] Ep. 1 : Up. 38000 : Sen. 4,312,739 : Cost 54.09144211 : Time 508.96s : 8974.69 words/s
[2019-08-02 05:24:52] Ep. 1 : Up. 40000 : Sen. 4,539,950 : Cost 53.49020767 : Time 510.02s : 8972.33 words/s
[2019-08-02 05:24:52] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz.orig.npz
[2019-08-02 05:25:02] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.iter40000.npz
[2019-08-02 05:25:09] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz
[2019-08-02 05:25:18] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz.optimizer.npz
[2019-08-02 05:25:43] [valid] Ep. 1 : Up. 40000 : cross-entropy : 61.2657 : new best
[2019-08-02 05:25:51] [valid] Ep. 1 : Up. 40000 : perplexity : 11.115 : new best
[2019-08-02 05:27:01] [valid] Ep. 1 : Up. 40000 : translation : 22.95 : new best
[2019-08-02 05:35:32] Ep. 1 : Up. 42000 : Sen. 4,767,787 : Cost 52.92500305 : Time 639.35s : 7157.02 words/s
[2019-08-02 05:43:14] Seen 4974685 samples
[2019-08-02 05:43:14] Starting epoch 2
[2019-08-02 05:43:14] [data] Shuffling data
[2019-08-02 05:43:17] [data] Done reading 5667937 sentences
[2019-08-02 05:43:41] [data] Done shuffling 5667937 sentences to temp files
[2019-08-02 05:44:31] Ep. 2 : Up. 44000 : Sen. 21,331 : Cost 52.18437576 : Time 539.50s : 8482.12 words/s
[2019-08-02 05:52:59] Ep. 2 : Up. 46000 : Sen. 248,067 : Cost 51.40576553 : Time 508.14s : 9001.24 words/s
[2019-08-02 06:01:27] Ep. 2 : Up. 48000 : Sen. 474,815 : Cost 51.12820816 : Time 508.10s : 8993.32 words/s
[2019-08-02 06:09:56] Ep. 2 : Up. 50000 : Sen. 702,828 : Cost 50.73960876 : Time 508.07s : 9023.88 words/s
[2019-08-02 06:18:20] Ep. 2 : Up. 52000 : Sen. 929,233 : Cost 50.16149521 : Time 504.67s : 9019.67 words/s
[2019-08-02 06:26:50] Ep. 2 : Up. 54000 : Sen. 1,156,560 : Cost 50.12868500 : Time 509.81s : 8987.72 words/s
[2019-08-02 06:35:16] Ep. 2 : Up. 56000 : Sen. 1,382,031 : Cost 49.67535782 : Time 505.73s : 8970.15 words/s
[2019-08-02 06:43:42] Ep. 2 : Up. 58000 : Sen. 1,608,795 : Cost 49.59227753 : Time 505.77s : 9019.86 words/s
[2019-08-02 06:52:09] Ep. 2 : Up. 60000 : Sen. 1,836,485 : Cost 49.47498322 : Time 507.44s : 9041.28 words/s
[2019-08-02 06:52:09] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz.orig.npz
[2019-08-02 06:52:18] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.iter60000.npz
[2019-08-02 06:52:25] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz
[2019-08-02 06:52:34] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz.optimizer.npz
[2019-08-02 06:52:59] [valid] Ep. 2 : Up. 60000 : cross-entropy : 55.5729 : new best
[2019-08-02 06:53:07] [valid] Ep. 2 : Up. 60000 : perplexity : 8.88634 : new best
[2019-08-02 06:54:13] [valid] Ep. 2 : Up. 60000 : translation : 24.89 : new best
[2019-08-02 07:02:42] Ep. 2 : Up. 62000 : Sen. 2,063,753 : Cost 49.28920364 : Time 633.02s : 7230.73 words/s
[2019-08-02 07:11:10] Ep. 2 : Up. 64000 : Sen. 2,291,876 : Cost 48.82423782 : Time 508.50s : 9027.05 words/s
[2019-08-02 07:19:39] Ep. 2 : Up. 66000 : Sen. 2,519,302 : Cost 48.31262207 : Time 508.94s : 8980.23 words/s
[2019-08-02 07:28:07] Ep. 2 : Up. 68000 : Sen. 2,745,600 : Cost 48.73891449 : Time 507.33s : 8998.09 words/s
[2019-08-02 07:36:34] Ep. 2 : Up. 70000 : Sen. 2,972,962 : Cost 48.28886795 : Time 506.98s : 9021.01 words/s
[2019-08-02 07:45:01] Ep. 2 : Up. 72000 : Sen. 3,200,521 : Cost 47.86048508 : Time 507.31s : 9019.35 words/s
[2019-08-02 07:53:27] Ep. 2 : Up. 74000 : Sen. 3,427,092 : Cost 47.96954727 : Time 506.28s : 9021.29 words/s
[2019-08-02 08:01:53] Ep. 2 : Up. 76000 : Sen. 3,655,224 : Cost 47.63472366 : Time 506.02s : 9041.61 words/s
[2019-08-02 08:10:19] Ep. 2 : Up. 78000 : Sen. 3,882,557 : Cost 47.36658478 : Time 506.04s : 9015.11 words/s
[2019-08-02 08:18:46] Ep. 2 : Up. 80000 : Sen. 4,109,501 : Cost 47.35457230 : Time 506.69s : 9015.83 words/s
[2019-08-02 08:18:46] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz.orig.npz
[2019-08-02 08:18:56] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.iter80000.npz
[2019-08-02 08:19:05] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz
[2019-08-02 08:19:14] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz.optimizer.npz
[2019-08-02 08:19:40] [valid] Ep. 2 : Up. 80000 : cross-entropy : 52.1846 : new best
[2019-08-02 08:19:48] [valid] Ep. 2 : Up. 80000 : perplexity : 7.77818 : new best
[2019-08-02 08:20:57] [valid] Ep. 2 : Up. 80000 : translation : 25.86 : new best
[2019-08-02 08:29:29] Ep. 2 : Up. 82000 : Sen. 4,336,433 : Cost 47.44023895 : Time 643.04s : 7118.18 words/s
[2019-08-02 08:37:56] Ep. 2 : Up. 84000 : Sen. 4,563,200 : Cost 46.96443939 : Time 506.48s : 8982.60 words/s
[2019-08-02 08:46:27] Ep. 2 : Up. 86000 : Sen. 4,789,954 : Cost 47.14318466 : Time 511.07s : 8945.19 words/s
[2019-08-02 08:53:21] Seen 4974685 samples
[2019-08-02 08:53:21] Starting epoch 3
[2019-08-02 08:53:21] [data] Shuffling data
[2019-08-02 08:53:24] [data] Done reading 5667937 sentences
[2019-08-02 08:53:49] [data] Done shuffling 5667937 sentences to temp files
[2019-08-02 08:55:23] Ep. 3 : Up. 88000 : Sen. 42,241 : Cost 46.46928406 : Time 536.49s : 8507.38 words/s
[2019-08-02 09:03:48] Ep. 3 : Up. 90000 : Sen. 268,350 : Cost 45.42692947 : Time 504.74s : 9004.95 words/s
[2019-08-02 09:12:16] Ep. 3 : Up. 92000 : Sen. 495,094 : Cost 45.62932968 : Time 508.37s : 8978.92 words/s
[2019-08-02 09:20:47] Ep. 3 : Up. 94000 : Sen. 722,342 : Cost 45.33033371 : Time 510.42s : 8951.23 words/s
[2019-08-02 09:29:19] Ep. 3 : Up. 96000 : Sen. 949,716 : Cost 45.57088470 : Time 511.84s : 8963.86 words/s
[2019-08-02 09:37:46] Ep. 3 : Up. 98000 : Sen. 1,176,940 : Cost 45.32588577 : Time 507.73s : 8997.45 words/s
[2019-08-02 09:46:13] Ep. 3 : Up. 100000 : Sen. 1,404,021 : Cost 45.17788315 : Time 507.14s : 9019.84 words/s
[2019-08-02 09:46:13] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz.orig.npz
[2019-08-02 09:46:27] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.iter100000.npz
[2019-08-02 09:46:36] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz
[2019-08-02 09:46:45] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz.optimizer.npz
[2019-08-02 09:47:14] [valid] Ep. 3 : Up. 100000 : cross-entropy : 49.9876 : new best
[2019-08-02 09:47:22] [valid] Ep. 3 : Up. 100000 : perplexity : 7.13463 : new best
[2019-08-02 09:48:32] [valid] Ep. 3 : Up. 100000 : translation : 26.48 : new best
[2019-08-02 09:57:03] Ep. 3 : Up. 102000 : Sen. 1,630,240 : Cost 45.05255508 : Time 649.74s : 7013.19 words/s
[2019-08-02 10:05:35] Ep. 3 : Up. 104000 : Sen. 1,858,679 : Cost 45.03393555 : Time 511.61s : 8985.88 words/s
[2019-08-02 10:14:05] Ep. 3 : Up. 106000 : Sen. 2,086,063 : Cost 44.88407898 : Time 510.55s : 8959.57 words/s
[2019-08-02 10:22:35] Ep. 3 : Up. 108000 : Sen. 2,312,983 : Cost 45.12744522 : Time 509.92s : 8981.07 words/s
[2019-08-02 10:31:04] Ep. 3 : Up. 110000 : Sen. 2,540,658 : Cost 44.93237305 : Time 508.33s : 9013.18 words/s
[2019-08-02 10:39:31] Ep. 3 : Up. 112000 : Sen. 2,767,558 : Cost 44.56423187 : Time 507.38s : 8986.65 words/s
[2019-08-02 10:47:59] Ep. 3 : Up. 114000 : Sen. 2,994,771 : Cost 44.53488159 : Time 508.19s : 8977.63 words/s
[2019-08-02 10:56:30] Ep. 3 : Up. 116000 : Sen. 3,222,010 : Cost 44.71758270 : Time 510.40s : 8975.99 words/s
[2019-08-02 11:04:57] Ep. 3 : Up. 118000 : Sen. 3,448,364 : Cost 44.50288391 : Time 507.04s : 8975.60 words/s
[2019-08-02 11:13:24] Ep. 3 : Up. 120000 : Sen. 3,674,923 : Cost 44.55510330 : Time 506.90s : 8998.46 words/s
[2019-08-02 11:13:24] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz.orig.npz
[2019-08-02 11:13:33] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.iter120000.npz
[2019-08-02 11:13:40] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz
[2019-08-02 11:13:49] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz.optimizer.npz
[2019-08-02 11:14:14] [valid] Ep. 3 : Up. 120000 : cross-entropy : 48.345 : new best
[2019-08-02 11:14:22] [valid] Ep. 3 : Up. 120000 : perplexity : 6.68851 : new best
[2019-08-02 11:15:28] [valid] Ep. 3 : Up. 120000 : translation : 26.88 : new best
[2019-08-02 11:24:00] Ep. 3 : Up. 122000 : Sen. 3,902,308 : Cost 44.44461441 : Time 636.08s : 7204.48 words/s
[2019-08-02 11:32:25] Ep. 3 : Up. 124000 : Sen. 4,129,056 : Cost 44.44668198 : Time 505.76s : 9004.45 words/s
[2019-08-02 11:40:54] Ep. 3 : Up. 126000 : Sen. 4,356,232 : Cost 44.21851349 : Time 508.30s : 9011.20 words/s
[2019-08-02 11:49:24] Ep. 3 : Up. 128000 : Sen. 4,584,751 : Cost 44.03567886 : Time 510.18s : 9006.39 words/s
[2019-08-02 11:57:53] Ep. 3 : Up. 130000 : Sen. 4,812,800 : Cost 43.91080856 : Time 509.16s : 9004.90 words/s
[2019-08-02 12:03:54] Seen 4974685 samples
[2019-08-02 12:03:54] Starting epoch 4
[2019-08-02 12:03:54] [data] Shuffling data
[2019-08-02 12:03:57] [data] Done reading 5667937 sentences
[2019-08-02 12:04:19] [data] Done shuffling 5667937 sentences to temp files
[2019-08-02 12:06:49] Ep. 4 : Up. 132000 : Sen. 66,301 : Cost 43.65035629 : Time 535.93s : 8551.87 words/s
[2019-08-02 12:15:17] Ep. 4 : Up. 134000 : Sen. 292,929 : Cost 43.13469315 : Time 508.16s : 9010.42 words/s
[2019-08-02 12:23:42] Ep. 4 : Up. 136000 : Sen. 519,605 : Cost 42.91750717 : Time 505.08s : 9019.35 words/s
[2019-08-02 12:32:10] Ep. 4 : Up. 138000 : Sen. 746,716 : Cost 43.06260681 : Time 507.49s : 9011.87 words/s
[2019-08-02 12:40:35] Ep. 4 : Up. 140000 : Sen. 973,193 : Cost 42.86111069 : Time 505.56s : 9026.75 words/s
[2019-08-02 12:40:35] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz.orig.npz
[2019-08-02 12:40:44] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.iter140000.npz
[2019-08-02 12:40:51] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz
[2019-08-02 12:41:00] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz.optimizer.npz
[2019-08-02 12:41:24] [valid] Ep. 4 : Up. 140000 : cross-entropy : 47.121 : new best
[2019-08-02 12:41:31] [valid] Ep. 4 : Up. 140000 : perplexity : 6.37432 : new best
[2019-08-02 12:42:37] [valid] Ep. 4 : Up. 140000 : translation : 27.49 : new best
[2019-08-02 12:51:05] Ep. 4 : Up. 142000 : Sen. 1,200,577 : Cost 42.87294006 : Time 629.24s : 7261.20 words/s
[2019-08-02 12:59:32] Ep. 4 : Up. 144000 : Sen. 1,427,122 : Cost 43.13030243 : Time 507.86s : 8996.34 words/s
[2019-08-02 13:08:01] Ep. 4 : Up. 146000 : Sen. 1,653,866 : Cost 42.88708878 : Time 508.35s : 8990.58 words/s
[2019-08-02 13:16:28] Ep. 4 : Up. 148000 : Sen. 1,881,444 : Cost 42.54453278 : Time 507.67s : 9019.50 words/s
[2019-08-02 13:24:56] Ep. 4 : Up. 150000 : Sen. 2,108,261 : Cost 42.78979874 : Time 507.73s : 8990.47 words/s
[2019-08-02 13:33:24] Ep. 4 : Up. 152000 : Sen. 2,335,701 : Cost 42.91186523 : Time 508.17s : 9010.71 words/s
[2019-08-02 13:41:54] Ep. 4 : Up. 154000 : Sen. 2,563,437 : Cost 42.66576385 : Time 509.33s : 8990.43 words/s
[2019-08-02 13:50:22] Ep. 4 : Up. 156000 : Sen. 2,791,488 : Cost 42.52774429 : Time 508.63s : 9014.11 words/s
[2019-08-02 13:58:50] Ep. 4 : Up. 158000 : Sen. 3,018,782 : Cost 42.72801590 : Time 508.16s : 9000.45 words/s
[2019-08-02 14:07:20] Ep. 4 : Up. 160000 : Sen. 3,247,028 : Cost 42.48646164 : Time 510.07s : 9000.01 words/s
[2019-08-02 14:07:20] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz.orig.npz
[2019-08-02 14:07:30] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.iter160000.npz
[2019-08-02 14:07:37] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz
[2019-08-02 14:07:46] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz.optimizer.npz
[2019-08-02 14:08:11] [valid] Ep. 4 : Up. 160000 : cross-entropy : 46.2959 : new best
[2019-08-02 14:08:18] [valid] Ep. 4 : Up. 160000 : perplexity : 6.17091 : new best
[2019-08-02 14:09:27] [valid] Ep. 4 : Up. 160000 : translation : 27.75 : new best
[2019-08-02 14:17:58] Ep. 4 : Up. 162000 : Sen. 3,474,199 : Cost 42.53240204 : Time 637.36s : 7167.39 words/s
[2019-08-02 14:26:23] Ep. 4 : Up. 164000 : Sen. 3,700,865 : Cost 42.46558380 : Time 505.14s : 9014.18 words/s
[2019-08-02 14:34:53] Ep. 4 : Up. 166000 : Sen. 3,928,313 : Cost 42.76121140 : Time 509.76s : 8989.30 words/s
[2019-08-02 14:43:22] Ep. 4 : Up. 168000 : Sen. 4,155,818 : Cost 42.51296997 : Time 509.17s : 8998.01 words/s
[2019-08-02 14:51:52] Ep. 4 : Up. 170000 : Sen. 4,383,099 : Cost 42.28525543 : Time 509.74s : 8974.50 words/s
[2019-08-02 15:00:19] Ep. 4 : Up. 172000 : Sen. 4,610,140 : Cost 42.53844452 : Time 507.63s : 9006.09 words/s
[2019-08-02 15:08:48] Ep. 4 : Up. 174000 : Sen. 4,837,270 : Cost 42.23251343 : Time 509.05s : 8955.85 words/s
[2019-08-02 15:13:58] Seen 4974685 samples
[2019-08-02 15:13:58] Starting epoch 5
[2019-08-02 15:13:58] [data] Shuffling data
[2019-08-02 15:14:01] [data] Done reading 5667937 sentences
[2019-08-02 15:14:31] [data] Done shuffling 5667937 sentences to temp files
[2019-08-02 15:17:58] Ep. 5 : Up. 176000 : Sen. 89,244 : Cost 41.89520264 : Time 549.23s : 8309.41 words/s
[2019-08-02 15:26:28] Ep. 5 : Up. 178000 : Sen. 316,326 : Cost 41.16852570 : Time 510.01s : 8957.59 words/s
[2019-08-02 15:34:59] Ep. 5 : Up. 180000 : Sen. 541,693 : Cost 41.52283096 : Time 511.41s : 8915.29 words/s
[2019-08-02 15:34:59] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz.orig.npz
[2019-08-02 15:35:08] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.iter180000.npz
[2019-08-02 15:35:15] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz
[2019-08-02 15:35:24] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz.optimizer.npz
[2019-08-02 15:35:49] [valid] Ep. 5 : Up. 180000 : cross-entropy : 45.4828 : new best
[2019-08-02 15:35:57] [valid] Ep. 5 : Up. 180000 : perplexity : 5.97678 : new best
[2019-08-02 15:37:06] [valid] Ep. 5 : Up. 180000 : translation : 28.09 : new best
[2019-08-02 15:45:40] Ep. 5 : Up. 182000 : Sen. 769,515 : Cost 41.21668625 : Time 640.75s : 7147.19 words/s
[2019-08-02 15:54:12] Ep. 5 : Up. 184000 : Sen. 996,628 : Cost 41.58059311 : Time 511.79s : 8932.53 words/s
[2019-08-02 16:02:41] Ep. 5 : Up. 186000 : Sen. 1,223,792 : Cost 41.16803360 : Time 509.36s : 8952.32 words/s
[2019-08-02 16:11:11] Ep. 5 : Up. 188000 : Sen. 1,451,171 : Cost 41.50787735 : Time 510.49s : 8967.33 words/s
[2019-08-02 16:19:45] Ep. 5 : Up. 190000 : Sen. 1,678,995 : Cost 41.52298355 : Time 513.25s : 8935.21 words/s
[2019-08-02 16:28:16] Ep. 5 : Up. 192000 : Sen. 1,906,072 : Cost 41.33097076 : Time 511.16s : 8941.93 words/s
[2019-08-02 16:36:48] Ep. 5 : Up. 194000 : Sen. 2,133,920 : Cost 41.35081863 : Time 512.69s : 8948.40 words/s
[2019-08-02 16:45:20] Ep. 5 : Up. 196000 : Sen. 2,360,817 : Cost 41.52683258 : Time 511.77s : 8923.80 words/s
[2019-08-02 16:53:54] Ep. 5 : Up. 198000 : Sen. 2,589,007 : Cost 41.43645477 : Time 513.80s : 8937.19 words/s
[2019-08-02 17:02:21] Ep. 5 : Up. 200000 : Sen. 2,816,102 : Cost 41.32086945 : Time 506.81s : 9000.45 words/s
[2019-08-02 17:02:21] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz.orig.npz
[2019-08-02 17:02:30] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.iter200000.npz
[2019-08-02 17:02:37] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz
[2019-08-02 17:02:46] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz.optimizer.npz
[2019-08-02 17:03:11] [valid] Ep. 5 : Up. 200000 : cross-entropy : 44.9781 : new best
[2019-08-02 17:03:19] [valid] Ep. 5 : Up. 200000 : perplexity : 5.85937 : new best
[2019-08-02 17:04:25] [valid] Ep. 5 : Up. 200000 : translation : 28.15 : new best
[2019-08-02 17:12:54] Ep. 5 : Up. 202000 : Sen. 3,043,424 : Cost 41.08631516 : Time 632.94s : 7226.63 words/s
[2019-08-02 17:21:23] Ep. 5 : Up. 204000 : Sen. 3,270,826 : Cost 41.27714920 : Time 509.60s : 8974.90 words/s
[2019-08-02 17:29:54] Ep. 5 : Up. 206000 : Sen. 3,497,715 : Cost 41.36034393 : Time 510.18s : 8948.54 words/s
[2019-08-02 17:38:21] Ep. 5 : Up. 208000 : Sen. 3,725,271 : Cost 41.11793900 : Time 507.22s : 9010.58 words/s
[2019-08-02 17:46:46] Ep. 5 : Up. 210000 : Sen. 3,951,606 : Cost 41.15557098 : Time 504.91s : 9006.24 words/s
[2019-08-02 17:55:15] Ep. 5 : Up. 212000 : Sen. 4,178,154 : Cost 41.35425949 : Time 509.40s : 8969.11 words/s
[2019-08-02 18:03:46] Ep. 5 : Up. 214000 : Sen. 4,405,213 : Cost 41.21428299 : Time 511.01s : 8945.31 words/s
[2019-08-02 18:12:14] Ep. 5 : Up. 216000 : Sen. 4,632,554 : Cost 40.92943573 : Time 507.89s : 8997.85 words/s
[2019-08-02 18:20:48] Ep. 5 : Up. 218000 : Sen. 4,861,238 : Cost 41.18162155 : Time 514.32s : 8946.72 words/s
[2019-08-02 18:25:03] Seen 4974685 samples
[2019-08-02 18:25:03] Starting epoch 6
[2019-08-02 18:25:03] [data] Shuffling data
[2019-08-02 18:25:12] [data] Done reading 5667937 sentences
[2019-08-02 18:25:36] [data] Done shuffling 5667937 sentences to temp files
[2019-08-02 18:29:53] Ep. 6 : Up. 220000 : Sen. 113,079 : Cost 40.88285065 : Time 544.29s : 8390.40 words/s
[2019-08-02 18:29:53] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz.orig.npz
[2019-08-02 18:30:01] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.iter220000.npz
[2019-08-02 18:30:08] Saving model to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz
[2019-08-02 18:30:19] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_+_ced_0.25_x_dcce_w3000/model/model.npz.optimizer.npz
[2019-08-02 18:30:44] [valid] Ep. 6 : Up. 220000 : cross-entropy : 44.4345 : new best
[2019-08-02 18:30:51] [valid] Ep. 6 : Up. 220000 : perplexity : 5.73551 : new best
[2019-08-02 18:31:57] [valid] Ep. 6 : Up. 220000 : translation : 28.3 : new best
[2019-08-02 18:40:25] Ep. 6 : Up. 222000 : Sen. 340,091 : Cost 39.92399597 : Time 632.51s : 7207.41 words/s
[2019-08-02 18:48:54] Ep. 6 : Up. 224000 : Sen. 567,323 : Cost 40.26297379 : Time 508.81s : 8985.07 words/s
