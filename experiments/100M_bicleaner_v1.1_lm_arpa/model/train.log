[2019-08-10 18:27:26] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-10 18:27:26] [marian] Running on bil as process 97069 with command line:
[2019-08-10 18:27:26] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz -T . --devices 4 --train-sets ../experiments/100M_bicleaner_v1.1_lm_arpa/data/train.bpe.de ../experiments/100M_bicleaner_v1.1_lm_arpa/data/train.bpe.en --vocabs ../experiments/100M_bicleaner_v1.1_lm_arpa/data/train.bpe.de.json ../experiments/100M_bicleaner_v1.1_lm_arpa/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_bicleaner_v1.1_lm_arpa/data/dev.bpe.de ../experiments/100M_bicleaner_v1.1_lm_arpa/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_bicleaner_v1.1_lm_arpa/model/dev.out --valid-script-path ../experiments/100M_bicleaner_v1.1_lm_arpa/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_bicleaner_v1.1_lm_arpa/model/train.log --valid-log ../experiments/100M_bicleaner_v1.1_lm_arpa/model/valid.log
[2019-08-10 18:27:26] [config] after-batches: 0
[2019-08-10 18:27:26] [config] after-epochs: 0
[2019-08-10 18:27:26] [config] allow-unk: false
[2019-08-10 18:27:26] [config] beam-size: 12
[2019-08-10 18:27:26] [config] bert-class-symbol: "[CLS]"
[2019-08-10 18:27:26] [config] bert-mask-symbol: "[MASK]"
[2019-08-10 18:27:26] [config] bert-masking-fraction: 0.15
[2019-08-10 18:27:26] [config] bert-sep-symbol: "[SEP]"
[2019-08-10 18:27:26] [config] bert-train-type-embeddings: true
[2019-08-10 18:27:26] [config] bert-type-vocab-size: 2
[2019-08-10 18:27:26] [config] best-deep: false
[2019-08-10 18:27:26] [config] clip-gemm: 0
[2019-08-10 18:27:26] [config] clip-norm: 1
[2019-08-10 18:27:26] [config] cost-type: ce-mean
[2019-08-10 18:27:26] [config] cpu-threads: 0
[2019-08-10 18:27:26] [config] data-weighting: ""
[2019-08-10 18:27:26] [config] data-weighting-type: sentence
[2019-08-10 18:27:26] [config] dec-cell: gru
[2019-08-10 18:27:26] [config] dec-cell-base-depth: 2
[2019-08-10 18:27:26] [config] dec-cell-high-depth: 1
[2019-08-10 18:27:26] [config] dec-depth: 1
[2019-08-10 18:27:26] [config] devices:
[2019-08-10 18:27:26] [config]   - 4
[2019-08-10 18:27:26] [config] dim-emb: 512
[2019-08-10 18:27:26] [config] dim-rnn: 1024
[2019-08-10 18:27:26] [config] dim-vocabs:
[2019-08-10 18:27:26] [config]   - 50000
[2019-08-10 18:27:26] [config]   - 50000
[2019-08-10 18:27:26] [config] disp-first: 0
[2019-08-10 18:27:26] [config] disp-freq: 2000
[2019-08-10 18:27:26] [config] disp-label-counts: false
[2019-08-10 18:27:26] [config] dropout-rnn: 0.2
[2019-08-10 18:27:26] [config] dropout-src: 0.1
[2019-08-10 18:27:26] [config] dropout-trg: 0.1
[2019-08-10 18:27:26] [config] dump-config: ""
[2019-08-10 18:27:26] [config] early-stopping: 5
[2019-08-10 18:27:26] [config] embedding-fix-src: false
[2019-08-10 18:27:26] [config] embedding-fix-trg: false
[2019-08-10 18:27:26] [config] embedding-normalization: false
[2019-08-10 18:27:26] [config] embedding-vectors:
[2019-08-10 18:27:26] [config]   []
[2019-08-10 18:27:26] [config] enc-cell: gru
[2019-08-10 18:27:26] [config] enc-cell-depth: 1
[2019-08-10 18:27:26] [config] enc-depth: 1
[2019-08-10 18:27:26] [config] enc-type: bidirectional
[2019-08-10 18:27:26] [config] exponential-smoothing: 0.0001
[2019-08-10 18:27:26] [config] grad-dropping-momentum: 0
[2019-08-10 18:27:26] [config] grad-dropping-rate: 0
[2019-08-10 18:27:26] [config] grad-dropping-warmup: 100
[2019-08-10 18:27:26] [config] guided-alignment: none
[2019-08-10 18:27:26] [config] guided-alignment-cost: mse
[2019-08-10 18:27:26] [config] guided-alignment-weight: 0.1
[2019-08-10 18:27:26] [config] ignore-model-config: false
[2019-08-10 18:27:26] [config] input-types:
[2019-08-10 18:27:26] [config]   []
[2019-08-10 18:27:26] [config] interpolate-env-vars: false
[2019-08-10 18:27:26] [config] keep-best: false
[2019-08-10 18:27:26] [config] label-smoothing: 0
[2019-08-10 18:27:26] [config] layer-normalization: true
[2019-08-10 18:27:26] [config] learn-rate: 0.0001
[2019-08-10 18:27:26] [config] log: ../experiments/100M_bicleaner_v1.1_lm_arpa/model/train.log
[2019-08-10 18:27:26] [config] log-level: info
[2019-08-10 18:27:26] [config] log-time-zone: ""
[2019-08-10 18:27:26] [config] lr-decay: 0
[2019-08-10 18:27:26] [config] lr-decay-freq: 50000
[2019-08-10 18:27:26] [config] lr-decay-inv-sqrt:
[2019-08-10 18:27:26] [config]   - 0
[2019-08-10 18:27:26] [config] lr-decay-repeat-warmup: false
[2019-08-10 18:27:26] [config] lr-decay-reset-optimizer: false
[2019-08-10 18:27:26] [config] lr-decay-start:
[2019-08-10 18:27:26] [config]   - 10
[2019-08-10 18:27:26] [config]   - 1
[2019-08-10 18:27:26] [config] lr-decay-strategy: epoch+stalled
[2019-08-10 18:27:26] [config] lr-report: false
[2019-08-10 18:27:26] [config] lr-warmup: 0
[2019-08-10 18:27:26] [config] lr-warmup-at-reload: false
[2019-08-10 18:27:26] [config] lr-warmup-cycle: false
[2019-08-10 18:27:26] [config] lr-warmup-start-rate: 0
[2019-08-10 18:27:26] [config] max-length: 50
[2019-08-10 18:27:26] [config] max-length-crop: false
[2019-08-10 18:27:26] [config] max-length-factor: 3
[2019-08-10 18:27:26] [config] maxi-batch: 100
[2019-08-10 18:27:26] [config] maxi-batch-sort: trg
[2019-08-10 18:27:26] [config] mini-batch: 64
[2019-08-10 18:27:26] [config] mini-batch-fit: true
[2019-08-10 18:27:26] [config] mini-batch-fit-step: 10
[2019-08-10 18:27:26] [config] mini-batch-overstuff: 1
[2019-08-10 18:27:26] [config] mini-batch-track-lr: false
[2019-08-10 18:27:26] [config] mini-batch-understuff: 1
[2019-08-10 18:27:26] [config] mini-batch-warmup: 0
[2019-08-10 18:27:26] [config] mini-batch-words: 0
[2019-08-10 18:27:26] [config] mini-batch-words-ref: 0
[2019-08-10 18:27:26] [config] model: ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz
[2019-08-10 18:27:26] [config] multi-loss-type: sum
[2019-08-10 18:27:26] [config] multi-node: false
[2019-08-10 18:27:26] [config] multi-node-overlap: true
[2019-08-10 18:27:26] [config] n-best: false
[2019-08-10 18:27:26] [config] no-nccl: false
[2019-08-10 18:27:26] [config] no-reload: false
[2019-08-10 18:27:26] [config] no-restore-corpus: false
[2019-08-10 18:27:26] [config] no-shuffle: false
[2019-08-10 18:27:26] [config] normalize: 1
[2019-08-10 18:27:26] [config] num-devices: 0
[2019-08-10 18:27:26] [config] optimizer: adam
[2019-08-10 18:27:26] [config] optimizer-delay: 1
[2019-08-10 18:27:26] [config] optimizer-params:
[2019-08-10 18:27:26] [config]   []
[2019-08-10 18:27:26] [config] overwrite: false
[2019-08-10 18:27:26] [config] pretrained-model: ""
[2019-08-10 18:27:26] [config] quiet: false
[2019-08-10 18:27:26] [config] quiet-translation: true
[2019-08-10 18:27:26] [config] relative-paths: false
[2019-08-10 18:27:26] [config] right-left: false
[2019-08-10 18:27:26] [config] save-freq: 20000
[2019-08-10 18:27:26] [config] seed: 1111
[2019-08-10 18:27:26] [config] shuffle-in-ram: false
[2019-08-10 18:27:26] [config] skip: false
[2019-08-10 18:27:26] [config] sqlite: ""
[2019-08-10 18:27:26] [config] sqlite-drop: false
[2019-08-10 18:27:26] [config] sync-sgd: true
[2019-08-10 18:27:26] [config] tempdir: .
[2019-08-10 18:27:26] [config] tied-embeddings: false
[2019-08-10 18:27:26] [config] tied-embeddings-all: false
[2019-08-10 18:27:26] [config] tied-embeddings-src: false
[2019-08-10 18:27:26] [config] train-sets:
[2019-08-10 18:27:26] [config]   - ../experiments/100M_bicleaner_v1.1_lm_arpa/data/train.bpe.de
[2019-08-10 18:27:26] [config]   - ../experiments/100M_bicleaner_v1.1_lm_arpa/data/train.bpe.en
[2019-08-10 18:27:26] [config] transformer-aan-activation: swish
[2019-08-10 18:27:26] [config] transformer-aan-depth: 2
[2019-08-10 18:27:26] [config] transformer-aan-nogate: false
[2019-08-10 18:27:26] [config] transformer-decoder-autoreg: self-attention
[2019-08-10 18:27:26] [config] transformer-dim-aan: 2048
[2019-08-10 18:27:26] [config] transformer-dim-ffn: 2048
[2019-08-10 18:27:26] [config] transformer-dropout: 0
[2019-08-10 18:27:26] [config] transformer-dropout-attention: 0
[2019-08-10 18:27:26] [config] transformer-dropout-ffn: 0
[2019-08-10 18:27:26] [config] transformer-ffn-activation: swish
[2019-08-10 18:27:26] [config] transformer-ffn-depth: 2
[2019-08-10 18:27:26] [config] transformer-guided-alignment-layer: last
[2019-08-10 18:27:26] [config] transformer-heads: 8
[2019-08-10 18:27:26] [config] transformer-no-projection: false
[2019-08-10 18:27:26] [config] transformer-postprocess: dan
[2019-08-10 18:27:26] [config] transformer-postprocess-emb: d
[2019-08-10 18:27:26] [config] transformer-preprocess: ""
[2019-08-10 18:27:26] [config] transformer-tied-layers:
[2019-08-10 18:27:26] [config]   []
[2019-08-10 18:27:26] [config] transformer-train-position-embeddings: false
[2019-08-10 18:27:26] [config] type: amun
[2019-08-10 18:27:26] [config] ulr: false
[2019-08-10 18:27:26] [config] ulr-dim-emb: 0
[2019-08-10 18:27:26] [config] ulr-dropout: 0
[2019-08-10 18:27:26] [config] ulr-keys-vectors: ""
[2019-08-10 18:27:26] [config] ulr-query-vectors: ""
[2019-08-10 18:27:26] [config] ulr-softmax-temperature: 1
[2019-08-10 18:27:26] [config] ulr-trainable-transformation: false
[2019-08-10 18:27:26] [config] valid-freq: 20000
[2019-08-10 18:27:26] [config] valid-log: ../experiments/100M_bicleaner_v1.1_lm_arpa/model/valid.log
[2019-08-10 18:27:26] [config] valid-max-length: 1000
[2019-08-10 18:27:26] [config] valid-metrics:
[2019-08-10 18:27:26] [config]   - cross-entropy
[2019-08-10 18:27:26] [config]   - perplexity
[2019-08-10 18:27:26] [config]   - translation
[2019-08-10 18:27:26] [config] valid-mini-batch: 8
[2019-08-10 18:27:26] [config] valid-script-path: ../experiments/100M_bicleaner_v1.1_lm_arpa/score-dev.sh
[2019-08-10 18:27:26] [config] valid-sets:
[2019-08-10 18:27:26] [config]   - ../experiments/100M_bicleaner_v1.1_lm_arpa/data/dev.bpe.de
[2019-08-10 18:27:26] [config]   - ../experiments/100M_bicleaner_v1.1_lm_arpa/data/dev.bpe.en
[2019-08-10 18:27:26] [config] valid-translation-output: ../experiments/100M_bicleaner_v1.1_lm_arpa/model/dev.out
[2019-08-10 18:27:26] [config] vocabs:
[2019-08-10 18:27:26] [config]   - ../experiments/100M_bicleaner_v1.1_lm_arpa/data/train.bpe.de.json
[2019-08-10 18:27:26] [config]   - ../experiments/100M_bicleaner_v1.1_lm_arpa/data/train.bpe.en.json
[2019-08-10 18:27:26] [config] word-penalty: 0
[2019-08-10 18:27:26] [config] workspace: 3000
[2019-08-10 18:27:26] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-10 18:27:26] Using synchronous training
[2019-08-10 18:27:26] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_bicleaner_v1.1_lm_arpa/data/train.bpe.de.json
[2019-08-10 18:27:26] [data] Using unused word id eos for 0
[2019-08-10 18:27:26] [data] Using unused word id UNK for 1
[2019-08-10 18:27:26] [data] Setting vocabulary size for input 0 to 50000
[2019-08-10 18:27:26] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_bicleaner_v1.1_lm_arpa/data/train.bpe.en.json
[2019-08-10 18:27:27] [data] Using unused word id eos for 0
[2019-08-10 18:27:27] [data] Using unused word id UNK for 1
[2019-08-10 18:27:27] [data] Setting vocabulary size for input 1 to 50000
[2019-08-10 18:27:27] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-10 18:27:27] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-10 18:27:28] [memory] Extending reserved space to 3072 MB (device gpu4)
[2019-08-10 18:27:28] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-10 18:27:28] [comm] NCCLCommunicator constructed successfully.
[2019-08-10 18:27:28] [training] Using 1 GPUs
[2019-08-10 18:27:28] [memory] Reserving 422 MB, device gpu4
[2019-08-10 18:27:28] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-10 18:27:28] [memory] Reserving 422 MB, device gpu4
[2019-08-10 18:27:34] [batching] Done. Typical MB size is 4042 target words
[2019-08-10 18:27:35] [memory] Extending reserved space to 3072 MB (device gpu4)
[2019-08-10 18:27:35] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-10 18:27:35] [comm] NCCLCommunicator constructed successfully.
[2019-08-10 18:27:35] [training] Using 1 GPUs
[2019-08-10 18:27:35] Training started
[2019-08-10 18:27:35] [data] Shuffling data
[2019-08-10 18:27:38] [data] Done reading 4840170 sentences
[2019-08-10 18:28:03] [data] Done shuffling 4840170 sentences to temp files
[2019-08-10 18:28:04] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-10 18:28:04] [memory] Reserving 422 MB, device gpu4
[2019-08-10 18:28:04] [memory] Reserving 422 MB, device gpu4
[2019-08-10 18:28:04] [memory] Reserving 422 MB, device gpu4
[2019-08-10 18:28:05] [memory] Reserving 844 MB, device gpu4
[2019-08-10 18:35:50] Ep. 1 : Up. 2000 : Sen. 218,506 : Cost 139.33367920 : Time 502.76s : 9791.46 words/s
[2019-08-10 18:41:18] Ep. 1 : Up. 4000 : Sen. 436,460 : Cost 112.32852936 : Time 328.75s : 14983.91 words/s
[2019-08-10 18:46:48] Ep. 1 : Up. 6000 : Sen. 655,346 : Cost 97.30661011 : Time 330.01s : 15002.32 words/s
[2019-08-10 18:52:18] Ep. 1 : Up. 8000 : Sen. 874,528 : Cost 86.96938324 : Time 329.22s : 14987.06 words/s
[2019-08-10 18:57:46] Ep. 1 : Up. 10000 : Sen. 1,092,491 : Cost 80.66788483 : Time 328.24s : 15021.67 words/s
[2019-08-10 19:03:14] Ep. 1 : Up. 12000 : Sen. 1,310,913 : Cost 75.40434265 : Time 328.66s : 14964.18 words/s
[2019-08-10 19:08:44] Ep. 1 : Up. 14000 : Sen. 1,530,009 : Cost 71.86341858 : Time 329.52s : 14983.57 words/s
[2019-08-10 19:14:14] Ep. 1 : Up. 16000 : Sen. 1,749,355 : Cost 69.35979462 : Time 329.82s : 14996.35 words/s
[2019-08-10 19:19:46] Ep. 1 : Up. 18000 : Sen. 1,969,092 : Cost 67.31489563 : Time 332.02s : 14942.99 words/s
[2019-08-10 19:25:15] Ep. 1 : Up. 20000 : Sen. 2,187,690 : Cost 65.39635468 : Time 329.09s : 14981.05 words/s
[2019-08-10 19:25:15] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.orig.npz
[2019-08-10 19:25:20] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.iter20000.npz
[2019-08-10 19:25:22] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz
[2019-08-10 19:25:27] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.optimizer.npz
[2019-08-10 19:25:44] [valid] Ep. 1 : Up. 20000 : cross-entropy : 66.4628 : new best
[2019-08-10 19:25:51] [valid] Ep. 1 : Up. 20000 : perplexity : 13.7065 : new best
[2019-08-10 19:26:45] [valid] Ep. 1 : Up. 20000 : translation : 21.74 : new best
[2019-08-10 19:32:16] Ep. 1 : Up. 22000 : Sen. 2,406,109 : Cost 63.68824005 : Time 421.39s : 11673.98 words/s
[2019-08-10 19:37:46] Ep. 1 : Up. 24000 : Sen. 2,625,146 : Cost 62.28293991 : Time 329.68s : 14954.06 words/s
[2019-08-10 19:43:16] Ep. 1 : Up. 26000 : Sen. 2,843,856 : Cost 61.52968216 : Time 330.13s : 14976.52 words/s
[2019-08-10 19:48:47] Ep. 1 : Up. 28000 : Sen. 3,063,250 : Cost 60.27475357 : Time 330.70s : 14977.79 words/s
[2019-08-10 19:54:18] Ep. 1 : Up. 30000 : Sen. 3,282,963 : Cost 59.54916000 : Time 331.15s : 14983.17 words/s
[2019-08-10 19:59:47] Ep. 1 : Up. 32000 : Sen. 3,500,923 : Cost 58.67395020 : Time 329.09s : 14951.04 words/s
[2019-08-10 20:05:16] Ep. 1 : Up. 34000 : Sen. 3,719,146 : Cost 57.84239578 : Time 329.10s : 14971.63 words/s
[2019-08-10 20:10:46] Ep. 1 : Up. 36000 : Sen. 3,937,514 : Cost 57.37116623 : Time 329.79s : 14930.03 words/s
[2019-08-10 20:16:17] Ep. 1 : Up. 38000 : Sen. 4,156,110 : Cost 56.72697449 : Time 330.82s : 14944.87 words/s
[2019-08-10 20:17:30] Seen 4204911 samples
[2019-08-10 20:17:30] Starting epoch 2
[2019-08-10 20:17:30] [data] Shuffling data
[2019-08-10 20:17:33] [data] Done reading 4840170 sentences
[2019-08-10 20:17:55] [data] Done shuffling 4840170 sentences to temp files
[2019-08-10 20:22:13] Ep. 2 : Up. 40000 : Sen. 170,704 : Cost 55.25328064 : Time 356.32s : 13915.73 words/s
[2019-08-10 20:22:13] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.orig.npz
[2019-08-10 20:22:19] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.iter40000.npz
[2019-08-10 20:22:21] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz
[2019-08-10 20:22:27] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.optimizer.npz
[2019-08-10 20:22:46] [valid] Ep. 2 : Up. 40000 : cross-entropy : 54.6476 : new best
[2019-08-10 20:22:52] [valid] Ep. 2 : Up. 40000 : perplexity : 8.60624 : new best
[2019-08-10 20:23:45] [valid] Ep. 2 : Up. 40000 : translation : 25.63 : new best
[2019-08-10 20:29:19] Ep. 2 : Up. 42000 : Sen. 389,389 : Cost 54.53218842 : Time 425.90s : 11564.75 words/s
[2019-08-10 20:34:49] Ep. 2 : Up. 44000 : Sen. 607,449 : Cost 54.34584427 : Time 330.08s : 14899.27 words/s
[2019-08-10 20:40:20] Ep. 2 : Up. 46000 : Sen. 825,600 : Cost 54.03448105 : Time 330.77s : 14899.09 words/s
[2019-08-10 20:45:48] Ep. 2 : Up. 48000 : Sen. 1,043,491 : Cost 53.40194321 : Time 328.07s : 14952.14 words/s
[2019-08-10 20:51:17] Ep. 2 : Up. 50000 : Sen. 1,262,537 : Cost 52.90600586 : Time 329.46s : 14974.53 words/s
[2019-08-10 20:56:47] Ep. 2 : Up. 52000 : Sen. 1,481,888 : Cost 52.83922577 : Time 329.69s : 14996.68 words/s
[2019-08-10 21:02:17] Ep. 2 : Up. 54000 : Sen. 1,700,425 : Cost 52.76564026 : Time 330.24s : 14932.57 words/s
[2019-08-10 21:07:48] Ep. 2 : Up. 56000 : Sen. 1,918,701 : Cost 52.52014542 : Time 330.98s : 14917.10 words/s
[2019-08-10 21:13:17] Ep. 2 : Up. 58000 : Sen. 2,137,275 : Cost 51.88620758 : Time 328.77s : 14991.97 words/s
[2019-08-10 21:18:46] Ep. 2 : Up. 60000 : Sen. 2,355,278 : Cost 51.83249283 : Time 329.40s : 14937.70 words/s
[2019-08-10 21:18:46] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.orig.npz
[2019-08-10 21:18:52] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.iter60000.npz
[2019-08-10 21:18:54] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz
[2019-08-10 21:19:00] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.optimizer.npz
[2019-08-10 21:19:20] [valid] Ep. 2 : Up. 60000 : cross-entropy : 49.8306 : new best
[2019-08-10 21:19:27] [valid] Ep. 2 : Up. 60000 : perplexity : 7.11889 : new best
[2019-08-10 21:20:20] [valid] Ep. 2 : Up. 60000 : translation : 27.27 : new best
[2019-08-10 21:25:51] Ep. 2 : Up. 62000 : Sen. 2,573,040 : Cost 51.59204102 : Time 424.73s : 11584.87 words/s
[2019-08-10 21:31:20] Ep. 2 : Up. 64000 : Sen. 2,791,121 : Cost 51.08794022 : Time 329.05s : 14954.68 words/s
[2019-08-10 21:36:49] Ep. 2 : Up. 66000 : Sen. 3,009,762 : Cost 51.00482178 : Time 329.06s : 14985.57 words/s
[2019-08-10 21:42:19] Ep. 2 : Up. 68000 : Sen. 3,228,580 : Cost 50.59796143 : Time 329.34s : 14977.49 words/s
[2019-08-10 21:47:48] Ep. 2 : Up. 70000 : Sen. 3,446,251 : Cost 50.80260086 : Time 328.92s : 14948.62 words/s
[2019-08-10 21:53:20] Ep. 2 : Up. 72000 : Sen. 3,665,016 : Cost 50.31204605 : Time 332.40s : 14837.82 words/s
[2019-08-10 21:58:50] Ep. 2 : Up. 74000 : Sen. 3,883,682 : Cost 50.27103043 : Time 330.46s : 14932.70 words/s
[2019-08-10 22:04:19] Ep. 2 : Up. 76000 : Sen. 4,101,786 : Cost 49.98488235 : Time 328.48s : 15002.77 words/s
[2019-08-10 22:06:55] Seen 4204911 samples
[2019-08-10 22:06:55] Starting epoch 3
[2019-08-10 22:06:55] [data] Shuffling data
[2019-08-10 22:06:58] [data] Done reading 4840170 sentences
[2019-08-10 22:07:23] [data] Done shuffling 4840170 sentences to temp files
[2019-08-10 22:10:18] Ep. 3 : Up. 78000 : Sen. 115,970 : Cost 49.18675613 : Time 359.62s : 13742.28 words/s
[2019-08-10 22:15:49] Ep. 3 : Up. 80000 : Sen. 335,208 : Cost 48.69094849 : Time 330.53s : 14964.46 words/s
[2019-08-10 22:15:49] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.orig.npz
[2019-08-10 22:15:55] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.iter80000.npz
[2019-08-10 22:15:58] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz
[2019-08-10 22:16:05] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.optimizer.npz
[2019-08-10 22:16:24] [valid] Ep. 3 : Up. 80000 : cross-entropy : 46.9614 : new best
[2019-08-10 22:16:31] [valid] Ep. 3 : Up. 80000 : perplexity : 6.35817 : new best
[2019-08-10 22:17:23] [valid] Ep. 3 : Up. 80000 : translation : 28.29 : new best
[2019-08-10 22:22:55] Ep. 3 : Up. 82000 : Sen. 554,163 : Cost 48.51284409 : Time 425.72s : 11606.97 words/s
[2019-08-10 22:28:25] Ep. 3 : Up. 84000 : Sen. 772,751 : Cost 48.31295395 : Time 330.24s : 14942.37 words/s
[2019-08-10 22:33:56] Ep. 3 : Up. 86000 : Sen. 991,642 : Cost 48.31079865 : Time 330.62s : 14948.89 words/s
[2019-08-10 22:39:27] Ep. 3 : Up. 88000 : Sen. 1,211,156 : Cost 48.27999496 : Time 331.57s : 14953.32 words/s
[2019-08-10 22:44:57] Ep. 3 : Up. 90000 : Sen. 1,429,915 : Cost 48.08173370 : Time 329.99s : 14934.45 words/s
[2019-08-10 22:50:29] Ep. 3 : Up. 92000 : Sen. 1,648,420 : Cost 48.17328262 : Time 331.58s : 14889.69 words/s
[2019-08-10 22:55:59] Ep. 3 : Up. 94000 : Sen. 1,867,440 : Cost 47.66951752 : Time 329.83s : 14950.61 words/s
[2019-08-10 23:01:28] Ep. 3 : Up. 96000 : Sen. 2,085,530 : Cost 47.56100845 : Time 329.47s : 14917.70 words/s
[2019-08-10 23:07:00] Ep. 3 : Up. 98000 : Sen. 2,305,018 : Cost 47.64037704 : Time 331.52s : 14945.62 words/s
[2019-08-10 23:12:29] Ep. 3 : Up. 100000 : Sen. 2,523,717 : Cost 47.71390533 : Time 329.45s : 14988.05 words/s
[2019-08-10 23:12:29] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.orig.npz
[2019-08-10 23:12:36] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.iter100000.npz
[2019-08-10 23:12:38] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz
[2019-08-10 23:12:43] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.optimizer.npz
[2019-08-10 23:13:04] [valid] Ep. 3 : Up. 100000 : cross-entropy : 45.2527 : new best
[2019-08-10 23:13:11] [valid] Ep. 3 : Up. 100000 : perplexity : 5.94431 : new best
[2019-08-10 23:14:04] [valid] Ep. 3 : Up. 100000 : translation : 28.84 : new best
[2019-08-10 23:19:35] Ep. 3 : Up. 102000 : Sen. 2,742,267 : Cost 47.35938644 : Time 426.17s : 11566.70 words/s
[2019-08-10 23:25:06] Ep. 3 : Up. 104000 : Sen. 2,961,250 : Cost 47.27362061 : Time 331.06s : 14910.06 words/s
[2019-08-10 23:30:36] Ep. 3 : Up. 106000 : Sen. 3,179,406 : Cost 47.12647247 : Time 329.52s : 14920.24 words/s
[2019-08-10 23:36:05] Ep. 3 : Up. 108000 : Sen. 3,397,414 : Cost 47.37485504 : Time 329.70s : 14954.31 words/s
[2019-08-10 23:41:36] Ep. 3 : Up. 110000 : Sen. 3,615,893 : Cost 46.97237778 : Time 330.36s : 14913.98 words/s
[2019-08-10 23:47:07] Ep. 3 : Up. 112000 : Sen. 3,834,882 : Cost 46.97486115 : Time 331.21s : 14928.89 words/s
[2019-08-10 23:52:38] Ep. 3 : Up. 114000 : Sen. 4,054,312 : Cost 46.93930054 : Time 331.24s : 14959.98 words/s
[2019-08-10 23:56:26] Seen 4204911 samples
[2019-08-10 23:56:26] Starting epoch 4
[2019-08-10 23:56:26] [data] Shuffling data
[2019-08-10 23:56:29] [data] Done reading 4840170 sentences
[2019-08-10 23:56:54] [data] Done shuffling 4840170 sentences to temp files
[2019-08-10 23:58:39] Ep. 4 : Up. 116000 : Sen. 68,581 : Cost 46.58303070 : Time 360.98s : 13715.33 words/s
[2019-08-11 00:04:10] Ep. 4 : Up. 118000 : Sen. 287,114 : Cost 45.46800613 : Time 330.58s : 14922.17 words/s
[2019-08-11 00:09:39] Ep. 4 : Up. 120000 : Sen. 505,161 : Cost 45.64232635 : Time 328.98s : 14975.36 words/s
[2019-08-11 00:09:39] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.orig.npz
[2019-08-11 00:09:44] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.iter120000.npz
[2019-08-11 00:09:47] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz
[2019-08-11 00:09:52] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.optimizer.npz
[2019-08-11 00:10:11] [valid] Ep. 4 : Up. 120000 : cross-entropy : 43.8776 : new best
[2019-08-11 00:10:18] [valid] Ep. 4 : Up. 120000 : perplexity : 5.63092 : new best
[2019-08-11 00:11:10] [valid] Ep. 4 : Up. 120000 : translation : 29.18 : new best
[2019-08-11 00:16:44] Ep. 4 : Up. 122000 : Sen. 724,572 : Cost 45.57789230 : Time 424.89s : 11641.68 words/s
[2019-08-11 00:22:14] Ep. 4 : Up. 124000 : Sen. 942,727 : Cost 45.50977325 : Time 330.07s : 14904.19 words/s
[2019-08-11 00:27:43] Ep. 4 : Up. 126000 : Sen. 1,161,302 : Cost 45.64606094 : Time 329.69s : 14962.99 words/s
[2019-08-11 00:33:14] Ep. 4 : Up. 128000 : Sen. 1,379,731 : Cost 45.47377777 : Time 330.34s : 14897.04 words/s
[2019-08-11 00:38:45] Ep. 4 : Up. 130000 : Sen. 1,598,722 : Cost 45.38056946 : Time 331.21s : 14932.57 words/s
[2019-08-11 00:44:16] Ep. 4 : Up. 132000 : Sen. 1,818,435 : Cost 45.35658264 : Time 330.71s : 14981.33 words/s
[2019-08-11 00:49:47] Ep. 4 : Up. 134000 : Sen. 2,038,118 : Cost 45.19118881 : Time 330.83s : 14951.40 words/s
[2019-08-11 00:55:16] Ep. 4 : Up. 136000 : Sen. 2,256,117 : Cost 45.61936951 : Time 329.74s : 14967.08 words/s
[2019-08-11 01:00:47] Ep. 4 : Up. 138000 : Sen. 2,475,017 : Cost 45.31555176 : Time 331.07s : 14923.40 words/s
[2019-08-11 01:06:18] Ep. 4 : Up. 140000 : Sen. 2,693,168 : Cost 45.36528778 : Time 330.58s : 14895.81 words/s
[2019-08-11 01:06:18] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.orig.npz
[2019-08-11 01:06:23] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.iter140000.npz
[2019-08-11 01:06:25] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz
[2019-08-11 01:06:32] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.optimizer.npz
[2019-08-11 01:06:52] [valid] Ep. 4 : Up. 140000 : cross-entropy : 42.9622 : new best
[2019-08-11 01:06:59] [valid] Ep. 4 : Up. 140000 : perplexity : 5.43149 : new best
[2019-08-11 01:07:52] [valid] Ep. 4 : Up. 140000 : translation : 29.67 : new best
[2019-08-11 01:13:24] Ep. 4 : Up. 142000 : Sen. 2,911,787 : Cost 45.04335403 : Time 425.87s : 11567.32 words/s
[2019-08-11 01:18:54] Ep. 4 : Up. 144000 : Sen. 3,130,831 : Cost 45.06335831 : Time 330.29s : 14960.51 words/s
[2019-08-11 01:24:25] Ep. 4 : Up. 146000 : Sen. 3,349,548 : Cost 45.19203186 : Time 330.43s : 14954.05 words/s
[2019-08-11 01:29:54] Ep. 4 : Up. 148000 : Sen. 3,567,263 : Cost 44.92325592 : Time 329.10s : 14932.83 words/s
[2019-08-11 01:35:23] Ep. 4 : Up. 150000 : Sen. 3,785,952 : Cost 44.98529434 : Time 329.13s : 14971.71 words/s
[2019-08-11 01:40:53] Ep. 4 : Up. 152000 : Sen. 4,004,755 : Cost 45.07629395 : Time 329.91s : 14956.78 words/s
[2019-08-11 01:45:55] Seen 4204911 samples
[2019-08-11 01:45:55] Starting epoch 5
[2019-08-11 01:45:55] [data] Shuffling data
[2019-08-11 01:45:58] [data] Done reading 4840170 sentences
[2019-08-11 01:46:21] [data] Done shuffling 4840170 sentences to temp files
[2019-08-11 01:46:50] Ep. 5 : Up. 154000 : Sen. 18,061 : Cost 44.85646820 : Time 357.47s : 13779.54 words/s
[2019-08-11 01:52:21] Ep. 5 : Up. 156000 : Sen. 236,800 : Cost 43.66633224 : Time 330.38s : 14897.08 words/s
[2019-08-11 01:57:49] Ep. 5 : Up. 158000 : Sen. 455,303 : Cost 43.64458084 : Time 328.41s : 14974.22 words/s
[2019-08-11 02:03:19] Ep. 5 : Up. 160000 : Sen. 673,006 : Cost 43.94109344 : Time 329.76s : 14941.31 words/s
[2019-08-11 02:03:19] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.orig.npz
[2019-08-11 02:03:24] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.iter160000.npz
[2019-08-11 02:03:26] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz
[2019-08-11 02:03:31] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.optimizer.npz
[2019-08-11 02:03:49] [valid] Ep. 5 : Up. 160000 : cross-entropy : 42.2185 : new best
[2019-08-11 02:03:55] [valid] Ep. 5 : Up. 160000 : perplexity : 5.2747 : new best
[2019-08-11 02:04:45] [valid] Ep. 5 : Up. 160000 : translation : 29.75 : new best
[2019-08-11 02:10:13] Ep. 5 : Up. 162000 : Sen. 890,922 : Cost 43.82119370 : Time 414.44s : 11876.35 words/s
[2019-08-11 02:15:42] Ep. 5 : Up. 164000 : Sen. 1,109,029 : Cost 44.00781631 : Time 329.09s : 14990.25 words/s
[2019-08-11 02:21:12] Ep. 5 : Up. 166000 : Sen. 1,327,525 : Cost 43.97581100 : Time 330.23s : 14956.69 words/s
[2019-08-11 02:26:41] Ep. 5 : Up. 168000 : Sen. 1,546,369 : Cost 43.71059799 : Time 328.92s : 14969.76 words/s
[2019-08-11 02:32:11] Ep. 5 : Up. 170000 : Sen. 1,764,580 : Cost 44.02876282 : Time 329.96s : 14934.61 words/s
[2019-08-11 02:37:41] Ep. 5 : Up. 172000 : Sen. 1,983,856 : Cost 43.68169022 : Time 329.85s : 14942.09 words/s
[2019-08-11 02:43:10] Ep. 5 : Up. 174000 : Sen. 2,202,269 : Cost 43.68910599 : Time 328.47s : 15003.65 words/s
[2019-08-11 02:48:38] Ep. 5 : Up. 176000 : Sen. 2,420,791 : Cost 43.85272598 : Time 327.92s : 15071.93 words/s
[2019-08-11 02:54:04] Ep. 5 : Up. 178000 : Sen. 2,638,733 : Cost 43.86648560 : Time 326.80s : 15073.84 words/s
[2019-08-11 02:59:30] Ep. 5 : Up. 180000 : Sen. 2,856,788 : Cost 43.87066650 : Time 325.59s : 15098.12 words/s
[2019-08-11 02:59:30] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.orig.npz
[2019-08-11 02:59:35] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.iter180000.npz
[2019-08-11 02:59:37] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz
[2019-08-11 02:59:42] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.optimizer.npz
[2019-08-11 03:00:00] [valid] Ep. 5 : Up. 180000 : cross-entropy : 41.6716 : new best
[2019-08-11 03:00:06] [valid] Ep. 5 : Up. 180000 : perplexity : 5.1623 : new best
[2019-08-11 03:00:55] [valid] Ep. 5 : Up. 180000 : translation : 29.98 : new best
[2019-08-11 03:06:24] Ep. 5 : Up. 182000 : Sen. 3,075,534 : Cost 43.83830261 : Time 413.88s : 11948.60 words/s
[2019-08-11 03:11:50] Ep. 5 : Up. 184000 : Sen. 3,293,869 : Cost 43.81242752 : Time 325.93s : 15116.13 words/s
[2019-08-11 03:17:15] Ep. 5 : Up. 186000 : Sen. 3,513,019 : Cost 43.47454071 : Time 325.40s : 15162.18 words/s
[2019-08-11 03:22:43] Ep. 5 : Up. 188000 : Sen. 3,731,585 : Cost 43.99182129 : Time 327.74s : 15056.50 words/s
[2019-08-11 03:28:10] Ep. 5 : Up. 190000 : Sen. 3,950,358 : Cost 43.65508270 : Time 327.15s : 15092.12 words/s
[2019-08-11 03:33:37] Ep. 5 : Up. 192000 : Sen. 4,170,452 : Cost 43.69336319 : Time 327.28s : 15147.40 words/s
[2019-08-11 03:34:29] Seen 4204911 samples
[2019-08-11 03:34:29] Starting epoch 6
[2019-08-11 03:34:29] [data] Shuffling data
[2019-08-11 03:34:32] [data] Done reading 4840170 sentences
[2019-08-11 03:34:53] [data] Done shuffling 4840170 sentences to temp files
[2019-08-11 03:39:30] Ep. 6 : Up. 194000 : Sen. 185,031 : Cost 42.85037994 : Time 352.32s : 14060.37 words/s
[2019-08-11 03:44:57] Ep. 6 : Up. 196000 : Sen. 403,512 : Cost 42.51123428 : Time 326.83s : 15109.06 words/s
[2019-08-11 03:50:21] Ep. 6 : Up. 198000 : Sen. 621,722 : Cost 42.63306046 : Time 324.99s : 15121.76 words/s
[2019-08-11 03:55:49] Ep. 6 : Up. 200000 : Sen. 841,588 : Cost 42.59238052 : Time 327.53s : 15141.24 words/s
[2019-08-11 03:55:49] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.orig.npz
[2019-08-11 03:55:54] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.iter200000.npz
[2019-08-11 03:55:56] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz
[2019-08-11 03:56:01] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.optimizer.npz
[2019-08-11 03:56:21] [valid] Ep. 6 : Up. 200000 : cross-entropy : 41.2337 : new best
[2019-08-11 03:56:27] [valid] Ep. 6 : Up. 200000 : perplexity : 5.07401 : new best
[2019-08-11 03:57:16] [valid] Ep. 6 : Up. 200000 : translation : 30.14 : new best
[2019-08-11 04:02:43] Ep. 6 : Up. 202000 : Sen. 1,058,893 : Cost 42.79263687 : Time 414.45s : 11858.83 words/s
[2019-08-11 04:08:10] Ep. 6 : Up. 204000 : Sen. 1,277,874 : Cost 42.72777939 : Time 326.63s : 15107.44 words/s
[2019-08-11 04:13:37] Ep. 6 : Up. 206000 : Sen. 1,496,465 : Cost 42.89927673 : Time 326.74s : 15105.86 words/s
[2019-08-11 04:19:08] Ep. 6 : Up. 208000 : Sen. 1,715,767 : Cost 42.68442917 : Time 331.12s : 14947.91 words/s
[2019-08-11 04:24:38] Ep. 6 : Up. 210000 : Sen. 1,934,637 : Cost 42.85556793 : Time 329.80s : 14938.35 words/s
[2019-08-11 04:30:08] Ep. 6 : Up. 212000 : Sen. 2,153,513 : Cost 42.92985916 : Time 330.01s : 14965.86 words/s
[2019-08-11 04:35:34] Ep. 6 : Up. 214000 : Sen. 2,372,269 : Cost 42.54348373 : Time 325.74s : 15121.40 words/s
[2019-08-11 04:41:00] Ep. 6 : Up. 216000 : Sen. 2,591,289 : Cost 42.79622269 : Time 326.75s : 15128.74 words/s
[2019-08-11 04:46:26] Ep. 6 : Up. 218000 : Sen. 2,809,821 : Cost 42.76964569 : Time 326.20s : 15124.66 words/s
[2019-08-11 04:51:53] Ep. 6 : Up. 220000 : Sen. 3,028,420 : Cost 42.68191147 : Time 326.58s : 15113.83 words/s
[2019-08-11 04:51:53] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.orig.npz
[2019-08-11 04:51:58] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.iter220000.npz
[2019-08-11 04:52:00] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz
[2019-08-11 04:52:05] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.optimizer.npz
[2019-08-11 04:52:23] [valid] Ep. 6 : Up. 220000 : cross-entropy : 40.8348 : new best
[2019-08-11 04:52:30] [valid] Ep. 6 : Up. 220000 : perplexity : 4.99491 : new best
[2019-08-11 04:53:19] [valid] Ep. 6 : Up. 220000 : translation : 30.15 : new best
[2019-08-11 04:58:48] Ep. 6 : Up. 222000 : Sen. 3,247,008 : Cost 42.95876312 : Time 414.98s : 11901.54 words/s
[2019-08-11 05:04:16] Ep. 6 : Up. 224000 : Sen. 3,466,019 : Cost 42.52167511 : Time 328.06s : 15056.71 words/s
[2019-08-11 05:09:44] Ep. 6 : Up. 226000 : Sen. 3,685,331 : Cost 42.97671890 : Time 328.39s : 15075.61 words/s
[2019-08-11 05:15:11] Ep. 6 : Up. 228000 : Sen. 3,904,320 : Cost 42.63295364 : Time 326.19s : 15112.80 words/s
[2019-08-11 05:20:37] Ep. 6 : Up. 230000 : Sen. 4,122,092 : Cost 42.77774429 : Time 326.74s : 15078.90 words/s
[2019-08-11 05:22:41] Seen 4204911 samples
[2019-08-11 05:22:41] Starting epoch 7
[2019-08-11 05:22:41] [data] Shuffling data
[2019-08-11 05:22:45] [data] Done reading 4840170 sentences
[2019-08-11 05:23:14] [data] Done shuffling 4840170 sentences to temp files
[2019-08-11 05:26:40] Ep. 7 : Up. 232000 : Sen. 136,074 : Cost 41.84035110 : Time 362.36s : 13615.88 words/s
[2019-08-11 05:32:11] Ep. 7 : Up. 234000 : Sen. 354,939 : Cost 41.60469818 : Time 330.92s : 14937.52 words/s
[2019-08-11 05:37:40] Ep. 7 : Up. 236000 : Sen. 573,467 : Cost 41.71924973 : Time 328.83s : 14955.45 words/s
[2019-08-11 05:43:10] Ep. 7 : Up. 238000 : Sen. 791,888 : Cost 41.69088745 : Time 330.59s : 14926.50 words/s
[2019-08-11 05:48:40] Ep. 7 : Up. 240000 : Sen. 1,010,694 : Cost 41.81734085 : Time 329.99s : 14980.91 words/s
[2019-08-11 05:48:40] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.orig.npz
[2019-08-11 05:48:46] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.iter240000.npz
[2019-08-11 05:48:49] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz
[2019-08-11 05:48:55] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.optimizer.npz
[2019-08-11 05:49:15] [valid] Ep. 7 : Up. 240000 : cross-entropy : 40.5015 : new best
[2019-08-11 05:49:22] [valid] Ep. 7 : Up. 240000 : perplexity : 4.92977 : new best
[2019-08-11 05:50:11] [valid] Ep. 7 : Up. 240000 : translation : 30.49 : new best
[2019-08-11 05:55:40] Ep. 7 : Up. 242000 : Sen. 1,229,758 : Cost 41.88427734 : Time 419.67s : 11753.00 words/s
[2019-08-11 06:01:09] Ep. 7 : Up. 244000 : Sen. 1,448,845 : Cost 41.83759689 : Time 329.24s : 15001.69 words/s
[2019-08-11 06:06:36] Ep. 7 : Up. 246000 : Sen. 1,666,978 : Cost 41.94537735 : Time 326.72s : 15114.63 words/s
[2019-08-11 06:12:02] Ep. 7 : Up. 248000 : Sen. 1,885,293 : Cost 41.65422821 : Time 326.08s : 15070.59 words/s
[2019-08-11 06:17:30] Ep. 7 : Up. 250000 : Sen. 2,104,308 : Cost 41.91666412 : Time 327.72s : 15108.05 words/s
[2019-08-11 06:22:55] Ep. 7 : Up. 252000 : Sen. 2,322,610 : Cost 42.04431152 : Time 325.86s : 15119.24 words/s
[2019-08-11 06:28:23] Ep. 7 : Up. 254000 : Sen. 2,542,617 : Cost 41.78486252 : Time 327.70s : 15128.55 words/s
[2019-08-11 06:33:50] Ep. 7 : Up. 256000 : Sen. 2,761,128 : Cost 41.87993240 : Time 326.53s : 15109.04 words/s
[2019-08-11 06:39:20] Ep. 7 : Up. 258000 : Sen. 2,980,750 : Cost 41.89822006 : Time 330.00s : 15019.37 words/s
[2019-08-11 06:44:50] Ep. 7 : Up. 260000 : Sen. 3,198,484 : Cost 41.92994308 : Time 329.92s : 14900.69 words/s
[2019-08-11 06:44:50] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.orig.npz
[2019-08-11 06:44:55] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.iter260000.npz
[2019-08-11 06:44:57] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz
[2019-08-11 06:45:02] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.optimizer.npz
[2019-08-11 06:45:21] [valid] Ep. 7 : Up. 260000 : cross-entropy : 40.2376 : new best
[2019-08-11 06:45:27] [valid] Ep. 7 : Up. 260000 : perplexity : 4.8788 : new best
[2019-08-11 06:46:17] [valid] Ep. 7 : Up. 260000 : translation : 30.55 : new best
[2019-08-11 06:51:46] Ep. 7 : Up. 262000 : Sen. 3,417,080 : Cost 41.81450272 : Time 416.74s : 11839.58 words/s
[2019-08-11 06:57:13] Ep. 7 : Up. 264000 : Sen. 3,636,357 : Cost 42.02252960 : Time 327.02s : 15115.20 words/s
[2019-08-11 07:02:41] Ep. 7 : Up. 266000 : Sen. 3,856,029 : Cost 41.65825272 : Time 327.63s : 15097.73 words/s
[2019-08-11 07:08:09] Ep. 7 : Up. 268000 : Sen. 4,074,712 : Cost 42.11894226 : Time 327.95s : 15088.82 words/s
[2019-08-11 07:11:24] Seen 4204911 samples
[2019-08-11 07:11:24] Starting epoch 8
[2019-08-11 07:11:24] [data] Shuffling data
[2019-08-11 07:11:28] [data] Done reading 4840170 sentences
[2019-08-11 07:11:48] [data] Done shuffling 4840170 sentences to temp files
[2019-08-11 07:14:01] Ep. 8 : Up. 270000 : Sen. 88,274 : Cost 41.57496643 : Time 351.75s : 13995.00 words/s
[2019-08-11 07:19:28] Ep. 8 : Up. 272000 : Sen. 307,200 : Cost 40.82356262 : Time 326.95s : 15114.16 words/s
[2019-08-11 07:24:57] Ep. 8 : Up. 274000 : Sen. 526,556 : Cost 40.82727432 : Time 329.74s : 15023.08 words/s
[2019-08-11 07:30:28] Ep. 8 : Up. 276000 : Sen. 745,902 : Cost 41.05905151 : Time 330.87s : 14950.58 words/s
[2019-08-11 07:35:59] Ep. 8 : Up. 278000 : Sen. 964,609 : Cost 40.86635971 : Time 330.73s : 14907.35 words/s
[2019-08-11 07:41:28] Ep. 8 : Up. 280000 : Sen. 1,183,166 : Cost 40.86461639 : Time 329.14s : 14964.87 words/s
[2019-08-11 07:41:28] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.orig.npz
[2019-08-11 07:41:34] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.iter280000.npz
[2019-08-11 07:41:36] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz
[2019-08-11 07:41:41] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.optimizer.npz
[2019-08-11 07:42:00] [valid] Ep. 8 : Up. 280000 : cross-entropy : 40.053 : new best
[2019-08-11 07:42:07] [valid] Ep. 8 : Up. 280000 : perplexity : 4.84345 : new best
[2019-08-11 07:42:57] [valid] Ep. 8 : Up. 280000 : translation : 30.49 : stalled 1 times (last best: 30.55)
[2019-08-11 07:48:27] Ep. 8 : Up. 282000 : Sen. 1,401,522 : Cost 41.05923462 : Time 418.48s : 11767.64 words/s
[2019-08-11 07:53:54] Ep. 8 : Up. 284000 : Sen. 1,620,756 : Cost 41.04111099 : Time 327.66s : 15077.15 words/s
[2019-08-11 07:59:23] Ep. 8 : Up. 286000 : Sen. 1,839,984 : Cost 41.12573242 : Time 329.02s : 15011.29 words/s
[2019-08-11 08:04:52] Ep. 8 : Up. 288000 : Sen. 2,058,342 : Cost 41.26303482 : Time 329.25s : 14991.15 words/s
[2019-08-11 08:10:22] Ep. 8 : Up. 290000 : Sen. 2,276,715 : Cost 41.02423859 : Time 329.54s : 14941.81 words/s
[2019-08-11 08:15:52] Ep. 8 : Up. 292000 : Sen. 2,495,275 : Cost 41.39170837 : Time 330.42s : 14963.41 words/s
[2019-08-11 08:21:23] Ep. 8 : Up. 294000 : Sen. 2,714,772 : Cost 41.03522110 : Time 330.38s : 14964.67 words/s
[2019-08-11 08:26:50] Ep. 8 : Up. 296000 : Sen. 2,933,366 : Cost 41.26112747 : Time 327.64s : 15075.14 words/s
[2019-08-11 08:32:17] Ep. 8 : Up. 298000 : Sen. 3,151,105 : Cost 41.31983566 : Time 326.64s : 15056.80 words/s
[2019-08-11 08:37:44] Ep. 8 : Up. 300000 : Sen. 3,369,820 : Cost 41.32906342 : Time 326.82s : 15102.46 words/s
[2019-08-11 08:37:44] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.orig.npz
[2019-08-11 08:37:49] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.iter300000.npz
[2019-08-11 08:37:51] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz
[2019-08-11 08:37:56] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.optimizer.npz
[2019-08-11 08:38:15] [valid] Ep. 8 : Up. 300000 : cross-entropy : 39.8352 : new best
[2019-08-11 08:38:21] [valid] Ep. 8 : Up. 300000 : perplexity : 4.80207 : new best
[2019-08-11 08:39:10] [valid] Ep. 8 : Up. 300000 : translation : 30.58 : new best
[2019-08-11 08:44:40] Ep. 8 : Up. 302000 : Sen. 3,589,111 : Cost 41.15158844 : Time 416.35s : 11894.17 words/s
[2019-08-11 08:50:10] Ep. 8 : Up. 304000 : Sen. 3,808,078 : Cost 41.23313141 : Time 329.49s : 14996.85 words/s
[2019-08-11 08:55:38] Ep. 8 : Up. 306000 : Sen. 4,025,970 : Cost 41.26260757 : Time 328.37s : 14950.19 words/s
[2019-08-11 09:00:09] Seen 4204911 samples
[2019-08-11 09:00:09] Starting epoch 9
[2019-08-11 09:00:09] [data] Shuffling data
[2019-08-11 09:00:12] [data] Done reading 4840170 sentences
[2019-08-11 09:00:34] [data] Done shuffling 4840170 sentences to temp files
[2019-08-11 09:01:35] Ep. 9 : Up. 308000 : Sen. 39,715 : Cost 41.27360916 : Time 356.82s : 13862.32 words/s
[2019-08-11 09:07:05] Ep. 9 : Up. 310000 : Sen. 258,943 : Cost 40.03416824 : Time 329.88s : 14989.32 words/s
[2019-08-11 09:12:37] Ep. 9 : Up. 312000 : Sen. 476,787 : Cost 40.34065628 : Time 332.00s : 14825.33 words/s
[2019-08-11 09:18:08] Ep. 9 : Up. 314000 : Sen. 695,235 : Cost 40.43553543 : Time 331.14s : 14886.04 words/s
[2019-08-11 09:23:38] Ep. 9 : Up. 316000 : Sen. 913,209 : Cost 40.31886292 : Time 330.06s : 14925.93 words/s
[2019-08-11 09:29:06] Ep. 9 : Up. 318000 : Sen. 1,130,633 : Cost 40.35728455 : Time 327.77s : 14961.19 words/s
[2019-08-11 09:34:35] Ep. 9 : Up. 320000 : Sen. 1,349,544 : Cost 40.26190567 : Time 329.41s : 14960.30 words/s
[2019-08-11 09:34:35] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.orig.npz
[2019-08-11 09:34:41] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.iter320000.npz
[2019-08-11 09:34:43] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz
[2019-08-11 09:34:48] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.optimizer.npz
[2019-08-11 09:35:08] [valid] Ep. 9 : Up. 320000 : cross-entropy : 39.67 : new best
[2019-08-11 09:35:15] [valid] Ep. 9 : Up. 320000 : perplexity : 4.77093 : new best
[2019-08-11 09:36:07] [valid] Ep. 9 : Up. 320000 : translation : 30.5 : stalled 1 times (last best: 30.58)
[2019-08-11 09:41:38] Ep. 9 : Up. 322000 : Sen. 1,567,512 : Cost 40.65743256 : Time 423.09s : 11627.87 words/s
[2019-08-11 09:47:08] Ep. 9 : Up. 324000 : Sen. 1,786,259 : Cost 40.38059998 : Time 329.34s : 14959.17 words/s
[2019-08-11 09:52:37] Ep. 9 : Up. 326000 : Sen. 2,004,304 : Cost 40.61915970 : Time 329.61s : 14968.76 words/s
[2019-08-11 09:58:08] Ep. 9 : Up. 328000 : Sen. 2,224,825 : Cost 40.49306870 : Time 330.87s : 14985.31 words/s
[2019-08-11 10:03:38] Ep. 9 : Up. 330000 : Sen. 2,443,351 : Cost 40.77532578 : Time 329.63s : 14970.56 words/s
[2019-08-11 10:09:07] Ep. 9 : Up. 332000 : Sen. 2,662,613 : Cost 40.53879547 : Time 329.54s : 14997.44 words/s
[2019-08-11 10:14:37] Ep. 9 : Up. 334000 : Sen. 2,881,954 : Cost 40.54117584 : Time 330.08s : 14990.53 words/s
[2019-08-11 10:20:07] Ep. 9 : Up. 336000 : Sen. 3,100,666 : Cost 40.65813828 : Time 329.54s : 14957.46 words/s
[2019-08-11 10:25:39] Ep. 9 : Up. 338000 : Sen. 3,319,359 : Cost 40.70782471 : Time 332.36s : 14870.35 words/s
[2019-08-11 10:31:12] Ep. 9 : Up. 340000 : Sen. 3,537,288 : Cost 40.60181427 : Time 332.87s : 14785.49 words/s
[2019-08-11 10:31:12] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.orig.npz
[2019-08-11 10:31:18] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.iter340000.npz
[2019-08-11 10:31:20] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz
[2019-08-11 10:31:26] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.optimizer.npz
[2019-08-11 10:31:46] [valid] Ep. 9 : Up. 340000 : cross-entropy : 39.4868 : new best
[2019-08-11 10:31:53] [valid] Ep. 9 : Up. 340000 : perplexity : 4.73663 : new best
[2019-08-11 10:32:46] [valid] Ep. 9 : Up. 340000 : translation : 30.8 : new best
[2019-08-11 10:38:21] Ep. 9 : Up. 342000 : Sen. 3,755,749 : Cost 40.93340683 : Time 428.86s : 11502.95 words/s
[2019-08-11 10:43:50] Ep. 9 : Up. 344000 : Sen. 3,973,913 : Cost 40.85690308 : Time 329.25s : 14972.64 words/s
[2019-08-11 10:49:20] Ep. 9 : Up. 346000 : Sen. 4,193,197 : Cost 40.79180145 : Time 329.69s : 14964.50 words/s
[2019-08-11 10:49:38] Seen 4204911 samples
[2019-08-11 10:49:38] Starting epoch 10
[2019-08-11 10:49:38] [data] Shuffling data
[2019-08-11 10:49:42] [data] Done reading 4840170 sentences
[2019-08-11 10:50:04] [data] Done shuffling 4840170 sentences to temp files
[2019-08-11 10:55:16] Ep. 10 : Up. 348000 : Sen. 206,097 : Cost 39.60612106 : Time 355.96s : 13840.42 words/s
[2019-08-11 11:00:46] Ep. 10 : Up. 350000 : Sen. 426,029 : Cost 39.47388840 : Time 329.64s : 15013.68 words/s
[2019-08-11 11:06:15] Ep. 10 : Up. 352000 : Sen. 645,004 : Cost 39.72947693 : Time 329.67s : 14991.85 words/s
[2019-08-11 11:11:44] Ep. 10 : Up. 354000 : Sen. 863,195 : Cost 39.75894928 : Time 328.81s : 14949.66 words/s
[2019-08-11 11:17:13] Ep. 10 : Up. 356000 : Sen. 1,081,763 : Cost 39.78305435 : Time 329.08s : 14969.40 words/s
[2019-08-11 11:22:43] Ep. 10 : Up. 358000 : Sen. 1,300,559 : Cost 39.93877792 : Time 330.13s : 14963.59 words/s
[2019-08-11 11:28:13] Ep. 10 : Up. 360000 : Sen. 1,519,440 : Cost 40.01723480 : Time 329.44s : 14980.79 words/s
[2019-08-11 11:28:13] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.orig.npz
[2019-08-11 11:28:18] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.iter360000.npz
[2019-08-11 11:28:21] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz
[2019-08-11 11:28:26] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.optimizer.npz
[2019-08-11 11:28:46] [valid] Ep. 10 : Up. 360000 : cross-entropy : 39.3964 : new best
[2019-08-11 11:28:52] [valid] Ep. 10 : Up. 360000 : perplexity : 4.71979 : new best
[2019-08-11 11:29:46] [valid] Ep. 10 : Up. 360000 : translation : 30.77 : stalled 1 times (last best: 30.8)
[2019-08-11 11:35:17] Ep. 10 : Up. 362000 : Sen. 1,737,209 : Cost 40.18994904 : Time 424.62s : 11578.75 words/s
[2019-08-11 11:40:49] Ep. 10 : Up. 364000 : Sen. 1,956,228 : Cost 40.16796112 : Time 331.86s : 14874.61 words/s
[2019-08-11 11:46:20] Ep. 10 : Up. 366000 : Sen. 2,175,582 : Cost 40.27399063 : Time 330.98s : 14984.17 words/s
[2019-08-11 11:51:51] Ep. 10 : Up. 368000 : Sen. 2,394,780 : Cost 40.20379257 : Time 330.76s : 14981.48 words/s
[2019-08-11 11:57:20] Ep. 10 : Up. 370000 : Sen. 2,613,249 : Cost 40.20403671 : Time 328.78s : 14956.66 words/s
[2019-08-11 12:02:51] Ep. 10 : Up. 372000 : Sen. 2,831,411 : Cost 40.25724411 : Time 331.13s : 14907.42 words/s
[2019-08-11 12:08:22] Ep. 10 : Up. 374000 : Sen. 3,050,791 : Cost 40.20497131 : Time 331.07s : 14934.92 words/s
[2019-08-11 12:13:54] Ep. 10 : Up. 376000 : Sen. 3,269,904 : Cost 40.26389694 : Time 331.67s : 14908.95 words/s
[2019-08-11 12:19:25] Ep. 10 : Up. 378000 : Sen. 3,488,156 : Cost 40.15262222 : Time 331.15s : 14877.21 words/s
[2019-08-11 12:24:55] Ep. 10 : Up. 380000 : Sen. 3,706,553 : Cost 40.16930008 : Time 330.28s : 14912.25 words/s
[2019-08-11 12:24:55] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.orig.npz
[2019-08-11 12:25:01] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.iter380000.npz
[2019-08-11 12:25:03] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz
[2019-08-11 12:25:09] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.optimizer.npz
[2019-08-11 12:25:29] [valid] Ep. 10 : Up. 380000 : cross-entropy : 39.2725 : new best
[2019-08-11 12:25:36] [valid] Ep. 10 : Up. 380000 : perplexity : 4.69681 : new best
[2019-08-11 12:26:29] [valid] Ep. 10 : Up. 380000 : translation : 30.96 : new best
[2019-08-11 12:32:01] Ep. 10 : Up. 382000 : Sen. 3,925,289 : Cost 40.31550980 : Time 425.89s : 11587.76 words/s
[2019-08-11 12:37:31] Ep. 10 : Up. 384000 : Sen. 4,144,136 : Cost 40.29621506 : Time 330.44s : 14956.41 words/s
[2019-08-11 12:39:04] Seen 4204911 samples
[2019-08-11 12:39:04] Starting epoch 11
[2019-08-11 12:39:04] [data] Shuffling data
[2019-08-11 12:39:07] [data] Done reading 4840170 sentences
[2019-08-11 12:39:31] [data] Done shuffling 4840170 sentences to temp files
[2019-08-11 12:43:31] Ep. 11 : Up. 386000 : Sen. 158,162 : Cost 39.47305298 : Time 359.81s : 13719.37 words/s
[2019-08-11 12:49:03] Ep. 11 : Up. 388000 : Sen. 377,756 : Cost 39.24866486 : Time 331.82s : 14933.86 words/s
[2019-08-11 12:54:33] Ep. 11 : Up. 390000 : Sen. 595,701 : Cost 39.29521561 : Time 330.13s : 14918.68 words/s
[2019-08-11 13:00:03] Ep. 11 : Up. 392000 : Sen. 813,997 : Cost 39.25050735 : Time 330.02s : 14925.31 words/s
[2019-08-11 13:05:36] Ep. 11 : Up. 394000 : Sen. 1,031,841 : Cost 39.62207413 : Time 332.91s : 14781.88 words/s
[2019-08-11 13:11:07] Ep. 11 : Up. 396000 : Sen. 1,249,773 : Cost 39.46906281 : Time 331.44s : 14849.65 words/s
[2019-08-11 13:16:41] Ep. 11 : Up. 398000 : Sen. 1,467,920 : Cost 39.47376633 : Time 333.57s : 14748.77 words/s
[2019-08-11 13:22:14] Ep. 11 : Up. 400000 : Sen. 1,687,033 : Cost 39.45831299 : Time 332.55s : 14833.49 words/s
[2019-08-11 13:22:14] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.orig.npz
[2019-08-11 13:22:19] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.iter400000.npz
[2019-08-11 13:22:21] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz
[2019-08-11 13:22:29] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.optimizer.npz
[2019-08-11 13:22:49] [valid] Ep. 11 : Up. 400000 : cross-entropy : 39.2373 : new best
[2019-08-11 13:22:55] [valid] Ep. 11 : Up. 400000 : perplexity : 4.69031 : new best
[2019-08-11 13:23:48] [valid] Ep. 11 : Up. 400000 : translation : 30.93 : stalled 1 times (last best: 30.96)
[2019-08-11 13:29:20] Ep. 11 : Up. 402000 : Sen. 1,905,135 : Cost 39.88072205 : Time 425.97s : 11567.71 words/s
[2019-08-11 13:34:49] Ep. 11 : Up. 404000 : Sen. 2,123,369 : Cost 39.67734909 : Time 329.11s : 14976.53 words/s
[2019-08-11 13:40:17] Ep. 11 : Up. 406000 : Sen. 2,341,233 : Cost 39.71461868 : Time 328.56s : 14961.36 words/s
[2019-08-11 13:45:47] Ep. 11 : Up. 408000 : Sen. 2,559,426 : Cost 39.88525391 : Time 329.46s : 14960.79 words/s
[2019-08-11 13:51:16] Ep. 11 : Up. 410000 : Sen. 2,777,837 : Cost 39.88405991 : Time 329.36s : 14957.65 words/s
[2019-08-11 13:56:46] Ep. 11 : Up. 412000 : Sen. 2,996,815 : Cost 39.87525558 : Time 330.19s : 14959.71 words/s
[2019-08-11 14:02:16] Ep. 11 : Up. 414000 : Sen. 3,215,195 : Cost 39.76573944 : Time 329.63s : 14937.39 words/s
[2019-08-11 14:07:47] Ep. 11 : Up. 416000 : Sen. 3,434,782 : Cost 39.85947418 : Time 331.06s : 14969.85 words/s
[2019-08-11 14:13:17] Ep. 11 : Up. 418000 : Sen. 3,654,400 : Cost 39.91017151 : Time 330.32s : 14999.72 words/s
[2019-08-11 14:18:47] Ep. 11 : Up. 420000 : Sen. 3,871,607 : Cost 39.93739319 : Time 329.41s : 14880.52 words/s
[2019-08-11 14:18:47] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.orig.npz
[2019-08-11 14:18:52] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.iter420000.npz
[2019-08-11 14:18:54] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz
[2019-08-11 14:19:00] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.optimizer.npz
[2019-08-11 14:19:20] [valid] Ep. 11 : Up. 420000 : cross-entropy : 39.1078 : new best
[2019-08-11 14:19:26] [valid] Ep. 11 : Up. 420000 : perplexity : 4.66644 : new best
[2019-08-11 14:20:20] [valid] Ep. 11 : Up. 420000 : translation : 31.01 : new best
[2019-08-11 14:25:52] Ep. 11 : Up. 422000 : Sen. 4,090,003 : Cost 39.97232056 : Time 425.41s : 11583.59 words/s
[2019-08-11 14:28:44] Seen 4204911 samples
[2019-08-11 14:28:44] Starting epoch 12
[2019-08-11 14:28:44] [data] Shuffling data
[2019-08-11 14:28:47] [data] Done reading 4840170 sentences
[2019-08-11 14:29:10] [data] Done shuffling 4840170 sentences to temp files
[2019-08-11 14:31:49] Ep. 12 : Up. 424000 : Sen. 105,198 : Cost 39.31601715 : Time 356.75s : 13885.36 words/s
[2019-08-11 14:37:19] Ep. 12 : Up. 426000 : Sen. 323,779 : Cost 38.96987915 : Time 330.09s : 14976.37 words/s
[2019-08-11 14:42:49] Ep. 12 : Up. 428000 : Sen. 542,354 : Cost 39.00016403 : Time 330.20s : 14965.51 words/s
[2019-08-11 14:48:20] Ep. 12 : Up. 430000 : Sen. 761,983 : Cost 38.91868973 : Time 330.61s : 14998.08 words/s
[2019-08-11 14:53:51] Ep. 12 : Up. 432000 : Sen. 982,229 : Cost 39.02687073 : Time 331.06s : 15004.55 words/s
[2019-08-11 14:59:21] Ep. 12 : Up. 434000 : Sen. 1,201,052 : Cost 38.88399887 : Time 329.80s : 14943.69 words/s
[2019-08-11 15:04:55] Ep. 12 : Up. 436000 : Sen. 1,420,356 : Cost 39.05735779 : Time 334.77s : 14777.81 words/s
[2019-08-11 15:10:29] Ep. 12 : Up. 438000 : Sen. 1,639,054 : Cost 39.14872742 : Time 333.67s : 14778.14 words/s
[2019-08-11 15:16:02] Ep. 12 : Up. 440000 : Sen. 1,856,748 : Cost 39.39434433 : Time 332.67s : 14763.03 words/s
[2019-08-11 15:16:02] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.orig.npz
[2019-08-11 15:16:08] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.iter440000.npz
[2019-08-11 15:16:10] Saving model to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz
[2019-08-11 15:16:17] Saving Adam parameters to ../experiments/100M_bicleaner_v1.1_lm_arpa/model/model.npz.optimizer.npz
[2019-08-11 15:16:38] [valid] Ep. 12 : Up. 440000 : cross-entropy : 39.0491 : new best
[2019-08-11 15:16:44] [valid] Ep. 12 : Up. 440000 : perplexity : 4.65567 : new best
[2019-08-11 15:17:37] [valid] Ep. 12 : Up. 440000 : translation : 30.8 : stalled 1 times (last best: 31.01)
[2019-08-11 15:23:08] Ep. 12 : Up. 442000 : Sen. 2,075,097 : Cost 39.09208298 : Time 426.64s : 11537.21 words/s
[2019-08-11 15:28:38] Ep. 12 : Up. 444000 : Sen. 2,294,653 : Cost 39.42473984 : Time 329.99s : 15010.59 words/s
[2019-08-11 15:34:08] Ep. 12 : Up. 446000 : Sen. 2,513,585 : Cost 39.17783737 : Time 329.60s : 14960.56 words/s
[2019-08-11 15:39:37] Ep. 12 : Up. 448000 : Sen. 2,731,579 : Cost 39.54298782 : Time 329.03s : 14967.49 words/s
[2019-08-11 15:45:06] Ep. 12 : Up. 450000 : Sen. 2,949,577 : Cost 39.43923187 : Time 328.74s : 14967.00 words/s
[2019-08-11 15:50:35] Ep. 12 : Up. 452000 : Sen. 3,167,498 : Cost 39.41698074 : Time 328.93s : 14927.08 words/s
