[2019-06-29 20:20:24] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-06-29 20:20:24] [marian] Running on zisa as process 138802 with command line:
[2019-06-29 20:20:24] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_bc1.1/model/model.npz -T . --devices 2 3 --train-sets ../experiments/100M_fasttext_bc1.1/data/train.bpe.de ../experiments/100M_fasttext_bc1.1/data/train.bpe.en --vocabs ../experiments/100M_fasttext_bc1.1/data/train.bpe.de.json ../experiments/100M_fasttext_bc1.1/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_bc1.1/data/dev.bpe.de ../experiments/100M_fasttext_bc1.1/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_bc1.1/model/dev.out --valid-script-path ../experiments/100M_fasttext_bc1.1/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_bc1.1/model/train.log --valid-log ../experiments/100M_fasttext_bc1.1/model/valid.log
[2019-06-29 20:20:24] [config] after-batches: 0
[2019-06-29 20:20:24] [config] after-epochs: 0
[2019-06-29 20:20:24] [config] allow-unk: false
[2019-06-29 20:20:24] [config] beam-size: 12
[2019-06-29 20:20:24] [config] bert-class-symbol: "[CLS]"
[2019-06-29 20:20:24] [config] bert-mask-symbol: "[MASK]"
[2019-06-29 20:20:24] [config] bert-masking-fraction: 0.15
[2019-06-29 20:20:24] [config] bert-sep-symbol: "[SEP]"
[2019-06-29 20:20:24] [config] bert-train-type-embeddings: true
[2019-06-29 20:20:24] [config] bert-type-vocab-size: 2
[2019-06-29 20:20:24] [config] best-deep: false
[2019-06-29 20:20:24] [config] clip-gemm: 0
[2019-06-29 20:20:24] [config] clip-norm: 1
[2019-06-29 20:20:24] [config] cost-type: ce-mean
[2019-06-29 20:20:24] [config] cpu-threads: 0
[2019-06-29 20:20:24] [config] data-weighting: ""
[2019-06-29 20:20:24] [config] data-weighting-type: sentence
[2019-06-29 20:20:24] [config] dec-cell: gru
[2019-06-29 20:20:24] [config] dec-cell-base-depth: 2
[2019-06-29 20:20:24] [config] dec-cell-high-depth: 1
[2019-06-29 20:20:24] [config] dec-depth: 1
[2019-06-29 20:20:24] [config] devices:
[2019-06-29 20:20:24] [config]   - 2
[2019-06-29 20:20:24] [config]   - 3
[2019-06-29 20:20:24] [config] dim-emb: 512
[2019-06-29 20:20:24] [config] dim-rnn: 1024
[2019-06-29 20:20:24] [config] dim-vocabs:
[2019-06-29 20:20:24] [config]   - 50000
[2019-06-29 20:20:24] [config]   - 50000
[2019-06-29 20:20:24] [config] disp-first: 0
[2019-06-29 20:20:24] [config] disp-freq: 2000
[2019-06-29 20:20:24] [config] disp-label-counts: false
[2019-06-29 20:20:24] [config] dropout-rnn: 0.2
[2019-06-29 20:20:24] [config] dropout-src: 0.1
[2019-06-29 20:20:24] [config] dropout-trg: 0.1
[2019-06-29 20:20:24] [config] dump-config: ""
[2019-06-29 20:20:24] [config] early-stopping: 5
[2019-06-29 20:20:24] [config] embedding-fix-src: false
[2019-06-29 20:20:24] [config] embedding-fix-trg: false
[2019-06-29 20:20:24] [config] embedding-normalization: false
[2019-06-29 20:20:24] [config] embedding-vectors:
[2019-06-29 20:20:24] [config]   []
[2019-06-29 20:20:24] [config] enc-cell: gru
[2019-06-29 20:20:24] [config] enc-cell-depth: 1
[2019-06-29 20:20:24] [config] enc-depth: 1
[2019-06-29 20:20:24] [config] enc-type: bidirectional
[2019-06-29 20:20:24] [config] exponential-smoothing: 0.0001
[2019-06-29 20:20:24] [config] grad-dropping-momentum: 0
[2019-06-29 20:20:24] [config] grad-dropping-rate: 0
[2019-06-29 20:20:24] [config] grad-dropping-warmup: 100
[2019-06-29 20:20:24] [config] guided-alignment: none
[2019-06-29 20:20:24] [config] guided-alignment-cost: mse
[2019-06-29 20:20:24] [config] guided-alignment-weight: 0.1
[2019-06-29 20:20:24] [config] ignore-model-config: false
[2019-06-29 20:20:24] [config] input-types:
[2019-06-29 20:20:24] [config]   []
[2019-06-29 20:20:24] [config] interpolate-env-vars: false
[2019-06-29 20:20:24] [config] keep-best: false
[2019-06-29 20:20:24] [config] label-smoothing: 0
[2019-06-29 20:20:24] [config] layer-normalization: true
[2019-06-29 20:20:24] [config] learn-rate: 0.0001
[2019-06-29 20:20:24] [config] log: ../experiments/100M_fasttext_bc1.1/model/train.log
[2019-06-29 20:20:24] [config] log-level: info
[2019-06-29 20:20:24] [config] log-time-zone: ""
[2019-06-29 20:20:24] [config] lr-decay: 0
[2019-06-29 20:20:24] [config] lr-decay-freq: 50000
[2019-06-29 20:20:24] [config] lr-decay-inv-sqrt:
[2019-06-29 20:20:24] [config]   - 0
[2019-06-29 20:20:24] [config] lr-decay-repeat-warmup: false
[2019-06-29 20:20:24] [config] lr-decay-reset-optimizer: false
[2019-06-29 20:20:24] [config] lr-decay-start:
[2019-06-29 20:20:24] [config]   - 10
[2019-06-29 20:20:24] [config]   - 1
[2019-06-29 20:20:24] [config] lr-decay-strategy: epoch+stalled
[2019-06-29 20:20:24] [config] lr-report: false
[2019-06-29 20:20:24] [config] lr-warmup: 0
[2019-06-29 20:20:24] [config] lr-warmup-at-reload: false
[2019-06-29 20:20:24] [config] lr-warmup-cycle: false
[2019-06-29 20:20:24] [config] lr-warmup-start-rate: 0
[2019-06-29 20:20:24] [config] max-length: 50
[2019-06-29 20:20:24] [config] max-length-crop: false
[2019-06-29 20:20:24] [config] max-length-factor: 3
[2019-06-29 20:20:24] [config] maxi-batch: 100
[2019-06-29 20:20:24] [config] maxi-batch-sort: trg
[2019-06-29 20:20:24] [config] mini-batch: 64
[2019-06-29 20:20:24] [config] mini-batch-fit: true
[2019-06-29 20:20:24] [config] mini-batch-fit-step: 10
[2019-06-29 20:20:24] [config] mini-batch-overstuff: 1
[2019-06-29 20:20:24] [config] mini-batch-track-lr: false
[2019-06-29 20:20:24] [config] mini-batch-understuff: 1
[2019-06-29 20:20:24] [config] mini-batch-warmup: 0
[2019-06-29 20:20:24] [config] mini-batch-words: 0
[2019-06-29 20:20:24] [config] mini-batch-words-ref: 0
[2019-06-29 20:20:24] [config] model: ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-06-29 20:20:24] [config] multi-loss-type: sum
[2019-06-29 20:20:24] [config] multi-node: false
[2019-06-29 20:20:24] [config] multi-node-overlap: true
[2019-06-29 20:20:24] [config] n-best: false
[2019-06-29 20:20:24] [config] no-nccl: false
[2019-06-29 20:20:24] [config] no-reload: false
[2019-06-29 20:20:24] [config] no-restore-corpus: false
[2019-06-29 20:20:24] [config] no-shuffle: false
[2019-06-29 20:20:24] [config] normalize: 1
[2019-06-29 20:20:24] [config] num-devices: 0
[2019-06-29 20:20:24] [config] optimizer: adam
[2019-06-29 20:20:24] [config] optimizer-delay: 1
[2019-06-29 20:20:24] [config] optimizer-params:
[2019-06-29 20:20:24] [config]   []
[2019-06-29 20:20:24] [config] overwrite: false
[2019-06-29 20:20:24] [config] pretrained-model: ""
[2019-06-29 20:20:24] [config] quiet: false
[2019-06-29 20:20:24] [config] quiet-translation: true
[2019-06-29 20:20:24] [config] relative-paths: false
[2019-06-29 20:20:24] [config] right-left: false
[2019-06-29 20:20:24] [config] save-freq: 20000
[2019-06-29 20:20:24] [config] seed: 1111
[2019-06-29 20:20:24] [config] shuffle-in-ram: false
[2019-06-29 20:20:24] [config] skip: false
[2019-06-29 20:20:24] [config] sqlite: ""
[2019-06-29 20:20:24] [config] sqlite-drop: false
[2019-06-29 20:20:24] [config] sync-sgd: true
[2019-06-29 20:20:24] [config] tempdir: .
[2019-06-29 20:20:24] [config] tied-embeddings: false
[2019-06-29 20:20:24] [config] tied-embeddings-all: false
[2019-06-29 20:20:24] [config] tied-embeddings-src: false
[2019-06-29 20:20:24] [config] train-sets:
[2019-06-29 20:20:24] [config]   - ../experiments/100M_fasttext_bc1.1/data/train.bpe.de
[2019-06-29 20:20:24] [config]   - ../experiments/100M_fasttext_bc1.1/data/train.bpe.en
[2019-06-29 20:20:24] [config] transformer-aan-activation: swish
[2019-06-29 20:20:24] [config] transformer-aan-depth: 2
[2019-06-29 20:20:24] [config] transformer-aan-nogate: false
[2019-06-29 20:20:24] [config] transformer-decoder-autoreg: self-attention
[2019-06-29 20:20:24] [config] transformer-dim-aan: 2048
[2019-06-29 20:20:24] [config] transformer-dim-ffn: 2048
[2019-06-29 20:20:24] [config] transformer-dropout: 0
[2019-06-29 20:20:24] [config] transformer-dropout-attention: 0
[2019-06-29 20:20:24] [config] transformer-dropout-ffn: 0
[2019-06-29 20:20:24] [config] transformer-ffn-activation: swish
[2019-06-29 20:20:24] [config] transformer-ffn-depth: 2
[2019-06-29 20:20:24] [config] transformer-guided-alignment-layer: last
[2019-06-29 20:20:24] [config] transformer-heads: 8
[2019-06-29 20:20:24] [config] transformer-no-projection: false
[2019-06-29 20:20:24] [config] transformer-postprocess: dan
[2019-06-29 20:20:24] [config] transformer-postprocess-emb: d
[2019-06-29 20:20:24] [config] transformer-preprocess: ""
[2019-06-29 20:20:24] [config] transformer-tied-layers:
[2019-06-29 20:20:24] [config]   []
[2019-06-29 20:20:24] [config] transformer-train-position-embeddings: false
[2019-06-29 20:20:24] [config] type: amun
[2019-06-29 20:20:24] [config] ulr: false
[2019-06-29 20:20:24] [config] ulr-dim-emb: 0
[2019-06-29 20:20:24] [config] ulr-dropout: 0
[2019-06-29 20:20:24] [config] ulr-keys-vectors: ""
[2019-06-29 20:20:24] [config] ulr-query-vectors: ""
[2019-06-29 20:20:24] [config] ulr-softmax-temperature: 1
[2019-06-29 20:20:24] [config] ulr-trainable-transformation: false
[2019-06-29 20:20:24] [config] valid-freq: 20000
[2019-06-29 20:20:24] [config] valid-log: ../experiments/100M_fasttext_bc1.1/model/valid.log
[2019-06-29 20:20:24] [config] valid-max-length: 1000
[2019-06-29 20:20:24] [config] valid-metrics:
[2019-06-29 20:20:24] [config]   - cross-entropy
[2019-06-29 20:20:24] [config]   - perplexity
[2019-06-29 20:20:24] [config]   - translation
[2019-06-29 20:20:24] [config] valid-mini-batch: 8
[2019-06-29 20:20:24] [config] valid-script-path: ../experiments/100M_fasttext_bc1.1/score-dev.sh
[2019-06-29 20:20:24] [config] valid-sets:
[2019-06-29 20:20:24] [config]   - ../experiments/100M_fasttext_bc1.1/data/dev.bpe.de
[2019-06-29 20:20:24] [config]   - ../experiments/100M_fasttext_bc1.1/data/dev.bpe.en
[2019-06-29 20:20:24] [config] valid-translation-output: ../experiments/100M_fasttext_bc1.1/model/dev.out
[2019-06-29 20:20:24] [config] vocabs:
[2019-06-29 20:20:24] [config]   - ../experiments/100M_fasttext_bc1.1/data/train.bpe.de.json
[2019-06-29 20:20:24] [config]   - ../experiments/100M_fasttext_bc1.1/data/train.bpe.en.json
[2019-06-29 20:20:24] [config] word-penalty: 0
[2019-06-29 20:20:24] [config] workspace: 3000
[2019-06-29 20:20:24] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-06-29 20:20:24] Using synchronous training
[2019-06-29 20:20:24] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_bc1.1/data/train.bpe.de.json
[2019-06-29 20:20:24] [data] Using unused word id eos for 0
[2019-06-29 20:20:24] [data] Using unused word id UNK for 1
[2019-06-29 20:20:24] [data] Setting vocabulary size for input 0 to 50000
[2019-06-29 20:20:24] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_bc1.1/data/train.bpe.en.json
[2019-06-29 20:20:24] [data] Using unused word id eos for 0
[2019-06-29 20:20:24] [data] Using unused word id UNK for 1
[2019-06-29 20:20:24] [data] Setting vocabulary size for input 1 to 50000
[2019-06-29 20:20:24] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-06-29 20:20:24] [batching] Collecting statistics for batch fitting with step size 10
[2019-06-29 20:20:25] [memory] Extending reserved space to 3072 MB (device gpu2)
[2019-06-29 20:20:26] [memory] Extending reserved space to 3072 MB (device gpu3)
[2019-06-29 20:20:26] [comm] Using NCCL 2.4.2 for GPU communication
[2019-06-29 20:20:26] [comm] NCCLCommunicator constructed successfully.
[2019-06-29 20:20:26] [training] Using 2 GPUs
[2019-06-29 20:20:26] [memory] Reserving 422 MB, device gpu2
[2019-06-29 20:20:26] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-06-29 20:20:26] [memory] Reserving 422 MB, device gpu2
[2019-06-29 20:20:33] [batching] Done. Typical MB size is 8084 target words
[2019-06-29 20:20:33] [memory] Extending reserved space to 3072 MB (device gpu2)
[2019-06-29 20:20:33] [memory] Extending reserved space to 3072 MB (device gpu3)
[2019-06-29 20:20:33] [comm] Using NCCL 2.4.2 for GPU communication
[2019-06-29 20:20:33] [comm] NCCLCommunicator constructed successfully.
[2019-06-29 20:20:33] [training] Using 2 GPUs
[2019-06-29 20:20:33] Training started
[2019-06-29 20:20:33] [data] Shuffling data
[2019-06-29 20:20:35] [data] Done reading 4863734 sentences
[2019-06-29 20:20:55] [data] Done shuffling 4863734 sentences to temp files
[2019-06-29 20:21:01] [training] Batches are processed as 1 process(es) x 2 devices/process
[2019-06-29 20:21:01] [memory] Reserving 422 MB, device gpu3
[2019-06-29 20:21:01] [memory] Reserving 422 MB, device gpu2
[2019-06-29 20:21:02] [memory] Reserving 422 MB, device gpu3
[2019-06-29 20:21:02] [memory] Reserving 422 MB, device gpu2
[2019-06-29 20:21:02] [memory] Reserving 211 MB, device gpu2
[2019-06-29 20:21:02] [memory] Reserving 211 MB, device gpu3
[2019-06-29 20:21:02] [memory] Reserving 422 MB, device gpu3
[2019-06-29 20:21:02] [memory] Reserving 422 MB, device gpu2
[2019-06-29 20:34:43] Ep. 1 : Up. 2000 : Sen. 394,866 : Cost 135.32624817 : Time 858.48s : 10387.04 words/s
[2019-06-29 20:48:28] Ep. 1 : Up. 4000 : Sen. 789,470 : Cost 104.52682495 : Time 825.28s : 10784.85 words/s
[2019-06-29 21:02:15] Ep. 1 : Up. 6000 : Sen. 1,184,000 : Cost 89.11405182 : Time 826.35s : 10780.50 words/s
[2019-06-29 21:16:00] Ep. 1 : Up. 8000 : Sen. 1,577,588 : Cost 79.86175537 : Time 825.66s : 10770.15 words/s
[2019-06-29 21:29:45] Ep. 1 : Up. 10000 : Sen. 1,972,408 : Cost 73.83278656 : Time 825.12s : 10784.05 words/s
[2019-06-29 21:43:32] Ep. 1 : Up. 12000 : Sen. 2,366,312 : Cost 70.11210632 : Time 826.64s : 10780.86 words/s
[2019-06-29 21:57:18] Ep. 1 : Up. 14000 : Sen. 2,760,850 : Cost 66.77095032 : Time 825.58s : 10776.15 words/s
[2019-06-29 22:11:06] Ep. 1 : Up. 16000 : Sen. 3,157,378 : Cost 64.51947784 : Time 827.94s : 10804.66 words/s
[2019-06-29 22:24:50] Ep. 1 : Up. 18000 : Sen. 3,551,516 : Cost 62.52338409 : Time 824.96s : 10771.53 words/s
[2019-06-29 22:38:37] Ep. 1 : Up. 20000 : Sen. 3,946,422 : Cost 61.16750717 : Time 826.12s : 10794.07 words/s
[2019-06-29 22:38:37] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-06-29 22:38:45] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter20000.npz
[2019-06-29 22:38:52] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-06-29 22:39:01] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-06-29 22:39:23] [valid] Ep. 1 : Up. 20000 : cross-entropy : 60.984 : new best
[2019-06-29 22:39:28] [valid] Ep. 1 : Up. 20000 : perplexity : 11.0429 : new best
[2019-06-29 22:40:15] [valid] Ep. 1 : Up. 20000 : translation : 24.18 : new best
[2019-06-29 22:49:48] Seen 4220483 samples
[2019-06-29 22:49:48] Starting epoch 2
[2019-06-29 22:49:48] [data] Shuffling data
[2019-06-29 22:49:50] [data] Done reading 4863734 sentences
[2019-06-29 22:50:09] [data] Done shuffling 4863734 sentences to temp files
[2019-06-29 22:54:29] Ep. 2 : Up. 22000 : Sen. 121,396 : Cost 59.49729919 : Time 952.01s : 9383.17 words/s
[2019-06-29 23:08:15] Ep. 2 : Up. 24000 : Sen. 516,918 : Cost 57.86877441 : Time 826.22s : 10803.46 words/s
[2019-06-29 23:22:00] Ep. 2 : Up. 26000 : Sen. 911,178 : Cost 56.96163559 : Time 825.11s : 10776.24 words/s
[2019-06-29 23:35:44] Ep. 2 : Up. 28000 : Sen. 1,304,049 : Cost 56.38755798 : Time 823.83s : 10766.88 words/s
[2019-06-29 23:49:26] Ep. 2 : Up. 30000 : Sen. 1,696,738 : Cost 55.63767624 : Time 822.06s : 10774.65 words/s
[2019-06-30 00:03:10] Ep. 2 : Up. 32000 : Sen. 2,090,464 : Cost 54.80509186 : Time 824.03s : 10789.60 words/s
[2019-06-30 00:16:52] Ep. 2 : Up. 34000 : Sen. 2,484,306 : Cost 54.33305359 : Time 822.39s : 10803.03 words/s
[2019-06-30 00:30:37] Ep. 2 : Up. 36000 : Sen. 2,878,746 : Cost 53.67845535 : Time 824.81s : 10801.67 words/s
[2019-06-30 00:44:23] Ep. 2 : Up. 38000 : Sen. 3,272,653 : Cost 53.14688492 : Time 826.22s : 10768.64 words/s
[2019-06-30 00:58:07] Ep. 2 : Up. 40000 : Sen. 3,666,726 : Cost 52.72246170 : Time 823.78s : 10794.74 words/s
[2019-06-30 00:58:07] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-06-30 00:58:16] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter40000.npz
[2019-06-30 00:58:22] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-06-30 00:58:31] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-06-30 00:58:52] [valid] Ep. 2 : Up. 40000 : cross-entropy : 50.9132 : new best
[2019-06-30 00:58:57] [valid] Ep. 2 : Up. 40000 : perplexity : 7.42726 : new best
[2019-06-30 00:59:43] [valid] Ep. 2 : Up. 40000 : translation : 27.24 : new best
[2019-06-30 01:13:31] Ep. 2 : Up. 42000 : Sen. 4,061,746 : Cost 52.44852448 : Time 923.57s : 9661.48 words/s
[2019-06-30 01:19:01] Seen 4220483 samples
[2019-06-30 01:19:01] Starting epoch 3
[2019-06-30 01:19:01] [data] Shuffling data
[2019-06-30 01:19:03] [data] Done reading 4863734 sentences
[2019-06-30 01:19:25] [data] Done shuffling 4863734 sentences to temp files
[2019-06-30 01:27:41] Ep. 3 : Up. 44000 : Sen. 235,744 : Cost 51.15497208 : Time 850.58s : 10466.04 words/s
[2019-06-30 01:41:25] Ep. 3 : Up. 46000 : Sen. 629,150 : Cost 50.63489151 : Time 824.03s : 10771.65 words/s
[2019-06-30 01:55:13] Ep. 3 : Up. 48000 : Sen. 1,025,524 : Cost 50.37750244 : Time 827.59s : 10803.95 words/s
[2019-06-30 02:09:01] Ep. 3 : Up. 50000 : Sen. 1,420,800 : Cost 50.24956131 : Time 828.09s : 10782.22 words/s
[2019-06-30 02:22:47] Ep. 3 : Up. 52000 : Sen. 1,814,693 : Cost 49.96788406 : Time 826.55s : 10773.71 words/s
[2019-06-30 02:36:31] Ep. 3 : Up. 54000 : Sen. 2,207,688 : Cost 49.48250198 : Time 823.16s : 10763.79 words/s
[2019-06-30 02:50:14] Ep. 3 : Up. 56000 : Sen. 2,600,376 : Cost 49.40004349 : Time 823.02s : 10771.05 words/s
[2019-06-30 03:03:59] Ep. 3 : Up. 58000 : Sen. 2,995,782 : Cost 49.07551575 : Time 825.40s : 10799.07 words/s
[2019-06-30 03:17:45] Ep. 3 : Up. 60000 : Sen. 3,390,738 : Cost 49.06502914 : Time 826.28s : 10805.23 words/s
[2019-06-30 03:17:45] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-06-30 03:17:54] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter60000.npz
[2019-06-30 03:18:01] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-06-30 03:18:10] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-06-30 03:18:31] [valid] Ep. 3 : Up. 60000 : cross-entropy : 46.8149 : new best
[2019-06-30 03:18:36] [valid] Ep. 3 : Up. 60000 : perplexity : 6.32019 : new best
[2019-06-30 03:19:23] [valid] Ep. 3 : Up. 60000 : translation : 28.56 : new best
[2019-06-30 03:33:09] Ep. 3 : Up. 62000 : Sen. 3,785,122 : Cost 48.75591278 : Time 923.23s : 9621.10 words/s
[2019-06-30 03:46:52] Ep. 3 : Up. 64000 : Sen. 4,179,200 : Cost 48.57867813 : Time 823.71s : 10800.12 words/s
[2019-06-30 03:48:19] Seen 4220483 samples
[2019-06-30 03:48:19] Starting epoch 4
[2019-06-30 03:48:19] [data] Shuffling data
[2019-06-30 03:48:21] [data] Done reading 4863734 sentences
[2019-06-30 03:48:43] [data] Done shuffling 4863734 sentences to temp files
[2019-06-30 04:01:04] Ep. 4 : Up. 66000 : Sen. 354,354 : Cost 47.51176453 : Time 851.85s : 10487.36 words/s
[2019-06-30 04:14:49] Ep. 4 : Up. 68000 : Sen. 748,800 : Cost 47.42048264 : Time 824.53s : 10793.27 words/s
[2019-06-30 04:28:33] Ep. 4 : Up. 70000 : Sen. 1,143,332 : Cost 47.30548477 : Time 824.85s : 10791.38 words/s
[2019-06-30 04:42:16] Ep. 4 : Up. 72000 : Sen. 1,536,516 : Cost 47.18688965 : Time 822.87s : 10786.98 words/s
[2019-06-30 04:56:02] Ep. 4 : Up. 74000 : Sen. 1,932,332 : Cost 47.08251190 : Time 826.13s : 10807.79 words/s
[2019-06-30 05:09:48] Ep. 4 : Up. 76000 : Sen. 2,326,272 : Cost 47.04381943 : Time 825.51s : 10790.84 words/s
[2019-06-30 05:23:31] Ep. 4 : Up. 78000 : Sen. 2,721,225 : Cost 46.72566986 : Time 823.23s : 10797.80 words/s
[2019-06-30 05:37:16] Ep. 4 : Up. 80000 : Sen. 3,114,980 : Cost 46.83644485 : Time 824.92s : 10788.86 words/s
[2019-06-30 05:37:16] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-06-30 05:37:25] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter80000.npz
[2019-06-30 05:37:31] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-06-30 05:37:40] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-06-30 05:38:02] [valid] Ep. 4 : Up. 80000 : cross-entropy : 44.593 : new best
[2019-06-30 05:38:06] [valid] Ep. 4 : Up. 80000 : perplexity : 5.79065 : new best
[2019-06-30 05:38:53] [valid] Ep. 4 : Up. 80000 : translation : 29.6 : new best
[2019-06-30 05:52:39] Ep. 4 : Up. 82000 : Sen. 3,509,042 : Cost 46.60958862 : Time 922.52s : 9639.52 words/s
[2019-06-30 06:06:24] Ep. 4 : Up. 84000 : Sen. 3,902,570 : Cost 46.58267212 : Time 825.40s : 10764.03 words/s
[2019-06-30 06:17:31] Seen 4220483 samples
[2019-06-30 06:17:31] Starting epoch 5
[2019-06-30 06:17:31] [data] Shuffling data
[2019-06-30 06:17:33] [data] Done reading 4863734 sentences
[2019-06-30 06:17:55] [data] Done shuffling 4863734 sentences to temp files
[2019-06-30 06:20:35] Ep. 5 : Up. 86000 : Sen. 76,440 : Cost 46.14426804 : Time 850.75s : 10467.30 words/s
[2019-06-30 06:34:19] Ep. 5 : Up. 88000 : Sen. 470,985 : Cost 45.35080338 : Time 824.49s : 10811.00 words/s
[2019-06-30 06:48:05] Ep. 5 : Up. 90000 : Sen. 866,654 : Cost 45.31840897 : Time 825.38s : 10813.32 words/s
[2019-06-30 07:01:47] Ep. 5 : Up. 92000 : Sen. 1,260,456 : Cost 45.28378677 : Time 821.88s : 10802.65 words/s
[2019-06-30 07:15:29] Ep. 5 : Up. 94000 : Sen. 1,654,515 : Cost 45.31262207 : Time 822.59s : 10809.14 words/s
[2019-06-30 07:29:11] Ep. 5 : Up. 96000 : Sen. 2,047,148 : Cost 45.38140106 : Time 821.43s : 10803.59 words/s
[2019-06-30 07:42:51] Ep. 5 : Up. 98000 : Sen. 2,440,836 : Cost 45.09083939 : Time 820.49s : 10806.05 words/s
[2019-06-30 07:56:36] Ep. 5 : Up. 100000 : Sen. 2,834,888 : Cost 45.15270615 : Time 824.60s : 10786.01 words/s
[2019-06-30 07:56:36] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-06-30 07:56:45] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter100000.npz
[2019-06-30 07:56:52] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-06-30 07:57:01] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-06-30 07:57:22] [valid] Ep. 5 : Up. 100000 : cross-entropy : 43.1358 : new best
[2019-06-30 07:57:26] [valid] Ep. 5 : Up. 100000 : perplexity : 5.46768 : new best
[2019-06-30 07:58:13] [valid] Ep. 5 : Up. 100000 : translation : 30.01 : new best
[2019-06-30 08:11:59] Ep. 5 : Up. 102000 : Sen. 3,229,763 : Cost 45.04526901 : Time 923.56s : 9646.35 words/s
[2019-06-30 08:25:45] Ep. 5 : Up. 104000 : Sen. 3,622,916 : Cost 45.16601562 : Time 826.20s : 10762.11 words/s
[2019-06-30 08:39:32] Ep. 5 : Up. 106000 : Sen. 4,017,986 : Cost 45.10823059 : Time 826.84s : 10791.72 words/s
[2019-06-30 08:46:36] Seen 4220483 samples
[2019-06-30 08:46:36] Starting epoch 6
[2019-06-30 08:46:36] [data] Shuffling data
[2019-06-30 08:46:39] [data] Done reading 4863734 sentences
[2019-06-30 08:47:00] [data] Done shuffling 4863734 sentences to temp files
[2019-06-30 08:53:40] Ep. 6 : Up. 108000 : Sen. 191,214 : Cost 44.32498932 : Time 848.21s : 10473.09 words/s
[2019-06-30 09:07:24] Ep. 6 : Up. 110000 : Sen. 584,038 : Cost 43.87512589 : Time 823.79s : 10760.39 words/s
[2019-06-30 09:21:10] Ep. 6 : Up. 112000 : Sen. 978,888 : Cost 43.89447021 : Time 825.80s : 10782.82 words/s
[2019-06-30 09:34:56] Ep. 6 : Up. 114000 : Sen. 1,374,344 : Cost 43.93545532 : Time 826.06s : 10790.20 words/s
[2019-06-30 09:48:39] Ep. 6 : Up. 116000 : Sen. 1,767,186 : Cost 44.15351105 : Time 822.72s : 10787.28 words/s
[2019-06-30 10:02:25] Ep. 6 : Up. 118000 : Sen. 2,161,504 : Cost 44.13579559 : Time 826.12s : 10783.75 words/s
[2019-06-30 10:16:10] Ep. 6 : Up. 120000 : Sen. 2,555,346 : Cost 43.94601440 : Time 825.45s : 10779.90 words/s
[2019-06-30 10:16:10] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-06-30 10:16:19] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter120000.npz
[2019-06-30 10:16:26] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-06-30 10:16:35] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-06-30 10:16:57] [valid] Ep. 6 : Up. 120000 : cross-entropy : 42.0796 : new best
[2019-06-30 10:17:02] [valid] Ep. 6 : Up. 120000 : perplexity : 5.24491 : new best
[2019-06-30 10:17:49] [valid] Ep. 6 : Up. 120000 : translation : 30.23 : new best
[2019-06-30 10:31:37] Ep. 6 : Up. 122000 : Sen. 2,949,614 : Cost 44.06574249 : Time 926.12s : 9608.50 words/s
[2019-06-30 10:45:20] Ep. 6 : Up. 124000 : Sen. 3,342,702 : Cost 43.98417664 : Time 822.95s : 10790.82 words/s
[2019-06-30 10:59:03] Ep. 6 : Up. 126000 : Sen. 3,737,036 : Cost 43.78408813 : Time 823.22s : 10792.97 words/s
[2019-06-30 11:12:48] Ep. 6 : Up. 128000 : Sen. 4,131,129 : Cost 43.85039520 : Time 824.78s : 10789.56 words/s
[2019-06-30 11:15:55] Seen 4220483 samples
[2019-06-30 11:15:55] Starting epoch 7
[2019-06-30 11:15:55] [data] Shuffling data
[2019-06-30 11:15:57] [data] Done reading 4863734 sentences
[2019-06-30 11:16:13] [data] Done shuffling 4863734 sentences to temp files
[2019-06-30 11:26:55] Ep. 7 : Up. 130000 : Sen. 305,284 : Cost 43.09676743 : Time 847.78s : 10511.62 words/s
[2019-06-30 11:40:40] Ep. 7 : Up. 132000 : Sen. 699,960 : Cost 42.75743103 : Time 824.55s : 10784.92 words/s
[2019-06-30 11:54:24] Ep. 7 : Up. 134000 : Sen. 1,093,527 : Cost 43.04404068 : Time 824.35s : 10796.25 words/s
[2019-06-30 12:08:09] Ep. 7 : Up. 136000 : Sen. 1,487,610 : Cost 42.93449020 : Time 824.96s : 10781.42 words/s
[2019-06-30 12:21:55] Ep. 7 : Up. 138000 : Sen. 1,882,542 : Cost 42.92576981 : Time 825.79s : 10796.71 words/s
[2019-06-30 12:35:42] Ep. 7 : Up. 140000 : Sen. 2,278,244 : Cost 43.03202057 : Time 826.78s : 10807.02 words/s
[2019-06-30 12:35:42] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-06-30 12:35:50] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter140000.npz
[2019-06-30 12:35:57] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-06-30 12:36:06] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-06-30 12:36:27] [valid] Ep. 7 : Up. 140000 : cross-entropy : 41.3241 : new best
[2019-06-30 12:36:32] [valid] Ep. 7 : Up. 140000 : perplexity : 5.09114 : new best
[2019-06-30 12:37:19] [valid] Ep. 7 : Up. 140000 : translation : 30.45 : new best
[2019-06-30 12:51:05] Ep. 7 : Up. 142000 : Sen. 2,673,784 : Cost 42.96740723 : Time 923.05s : 9655.15 words/s
[2019-06-30 13:04:49] Ep. 7 : Up. 144000 : Sen. 3,067,807 : Cost 42.87764359 : Time 823.73s : 10792.48 words/s
[2019-06-30 13:18:35] Ep. 7 : Up. 146000 : Sen. 3,462,868 : Cost 42.86047363 : Time 826.36s : 10792.63 words/s
[2019-06-30 13:32:20] Ep. 7 : Up. 148000 : Sen. 3,857,848 : Cost 43.02750397 : Time 825.45s : 10807.38 words/s
[2019-06-30 13:44:59] Seen 4220483 samples
[2019-06-30 13:44:59] Starting epoch 8
[2019-06-30 13:44:59] [data] Shuffling data
[2019-06-30 13:45:01] [data] Done reading 4863734 sentences
[2019-06-30 13:45:18] [data] Done shuffling 4863734 sentences to temp files
[2019-06-30 13:46:27] Ep. 8 : Up. 150000 : Sen. 31,688 : Cost 42.67969513 : Time 846.26s : 10518.13 words/s
[2019-06-30 14:00:11] Ep. 8 : Up. 152000 : Sen. 425,646 : Cost 41.95188904 : Time 824.38s : 10794.24 words/s
[2019-06-30 14:13:57] Ep. 8 : Up. 154000 : Sen. 821,518 : Cost 42.02185822 : Time 826.34s : 10803.71 words/s
[2019-06-30 14:27:41] Ep. 8 : Up. 156000 : Sen. 1,214,804 : Cost 42.22748184 : Time 823.78s : 10790.98 words/s
[2019-06-30 14:41:26] Ep. 8 : Up. 158000 : Sen. 1,608,967 : Cost 42.22524261 : Time 824.46s : 10796.73 words/s
[2019-06-30 14:55:11] Ep. 8 : Up. 160000 : Sen. 2,003,470 : Cost 42.04260635 : Time 824.99s : 10771.96 words/s
[2019-06-30 14:55:11] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-06-30 14:55:19] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter160000.npz
[2019-06-30 14:55:26] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-06-30 14:55:35] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-06-30 14:55:56] [valid] Ep. 8 : Up. 160000 : cross-entropy : 40.7923 : new best
[2019-06-30 14:56:01] [valid] Ep. 8 : Up. 160000 : perplexity : 4.98562 : new best
[2019-06-30 14:56:48] [valid] Ep. 8 : Up. 160000 : translation : 30.58 : new best
[2019-06-30 15:10:34] Ep. 8 : Up. 162000 : Sen. 2,397,180 : Cost 42.25013351 : Time 923.73s : 9624.16 words/s
[2019-06-30 15:24:19] Ep. 8 : Up. 164000 : Sen. 2,791,998 : Cost 42.19363022 : Time 824.94s : 10799.20 words/s
[2019-06-30 15:38:06] Ep. 8 : Up. 166000 : Sen. 3,188,346 : Cost 42.18893814 : Time 827.22s : 10805.90 words/s
[2019-06-30 15:51:50] Ep. 8 : Up. 168000 : Sen. 3,582,344 : Cost 42.11420822 : Time 823.44s : 10785.24 words/s
[2019-06-30 16:05:34] Ep. 8 : Up. 170000 : Sen. 3,976,384 : Cost 42.35181046 : Time 824.20s : 10811.21 words/s
[2019-06-30 16:14:05] Seen 4220483 samples
[2019-06-30 16:14:05] Starting epoch 9
[2019-06-30 16:14:05] [data] Shuffling data
[2019-06-30 16:14:07] [data] Done reading 4863734 sentences
[2019-06-30 16:14:26] [data] Done shuffling 4863734 sentences to temp files
[2019-06-30 16:19:41] Ep. 9 : Up. 172000 : Sen. 150,772 : Cost 41.79183197 : Time 847.13s : 10529.35 words/s
[2019-06-30 16:33:26] Ep. 9 : Up. 174000 : Sen. 545,619 : Cost 41.33910751 : Time 824.33s : 10803.59 words/s
[2019-06-30 16:47:11] Ep. 9 : Up. 176000 : Sen. 942,404 : Cost 41.28955460 : Time 825.75s : 10828.97 words/s
[2019-06-30 17:00:55] Ep. 9 : Up. 178000 : Sen. 1,336,142 : Cost 41.52710342 : Time 823.79s : 10797.94 words/s
[2019-06-30 17:14:38] Ep. 9 : Up. 180000 : Sen. 1,729,918 : Cost 41.34250259 : Time 822.75s : 10794.84 words/s
[2019-06-30 17:14:38] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-06-30 17:14:46] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter180000.npz
[2019-06-30 17:14:53] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-06-30 17:15:02] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-06-30 17:15:24] [valid] Ep. 9 : Up. 180000 : cross-entropy : 40.3954 : new best
[2019-06-30 17:15:28] [valid] Ep. 9 : Up. 180000 : perplexity : 4.90829 : new best
[2019-06-30 17:16:15] [valid] Ep. 9 : Up. 180000 : translation : 30.74 : new best
[2019-06-30 17:30:01] Ep. 9 : Up. 182000 : Sen. 2,123,948 : Cost 41.69050980 : Time 922.91s : 9646.54 words/s
[2019-06-30 17:43:46] Ep. 9 : Up. 184000 : Sen. 2,518,704 : Cost 41.62680054 : Time 825.46s : 10798.76 words/s
[2019-06-30 17:57:30] Ep. 9 : Up. 186000 : Sen. 2,913,320 : Cost 41.52598190 : Time 824.05s : 10810.30 words/s
[2019-06-30 18:11:12] Ep. 9 : Up. 188000 : Sen. 3,307,924 : Cost 41.54809189 : Time 821.69s : 10821.32 words/s
[2019-06-30 18:24:56] Ep. 9 : Up. 190000 : Sen. 3,702,102 : Cost 41.56660080 : Time 824.33s : 10792.22 words/s
[2019-06-30 18:38:40] Ep. 9 : Up. 192000 : Sen. 4,095,640 : Cost 41.64860916 : Time 823.39s : 10802.29 words/s
[2019-06-30 18:43:02] Seen 4220483 samples
[2019-06-30 18:43:02] Starting epoch 10
[2019-06-30 18:43:02] [data] Shuffling data
[2019-06-30 18:43:04] [data] Done reading 4863734 sentences
[2019-06-30 18:43:21] [data] Done shuffling 4863734 sentences to temp files
[2019-06-30 18:52:47] Ep. 10 : Up. 194000 : Sen. 268,800 : Cost 41.00083160 : Time 846.86s : 10499.91 words/s
[2019-06-30 19:06:31] Ep. 10 : Up. 196000 : Sen. 662,982 : Cost 40.84818268 : Time 824.08s : 10801.46 words/s
[2019-06-30 19:20:14] Ep. 10 : Up. 198000 : Sen. 1,056,984 : Cost 40.76952362 : Time 823.10s : 10802.09 words/s
[2019-06-30 19:34:00] Ep. 10 : Up. 200000 : Sen. 1,452,643 : Cost 40.83560944 : Time 826.12s : 10800.96 words/s
[2019-06-30 19:34:00] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-06-30 19:34:10] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter200000.npz
[2019-06-30 19:34:16] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-06-30 19:34:28] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-06-30 19:34:50] [valid] Ep. 10 : Up. 200000 : cross-entropy : 40.0496 : new best
[2019-06-30 19:34:54] [valid] Ep. 10 : Up. 200000 : perplexity : 4.8419 : new best
[2019-06-30 19:35:41] [valid] Ep. 10 : Up. 200000 : translation : 31.03 : new best
[2019-06-30 19:49:24] Ep. 10 : Up. 202000 : Sen. 1,844,133 : Cost 41.08760071 : Time 923.97s : 9578.73 words/s
[2019-06-30 20:03:04] Ep. 10 : Up. 204000 : Sen. 2,237,910 : Cost 40.96353912 : Time 820.65s : 10817.67 words/s
[2019-06-30 20:16:47] Ep. 10 : Up. 206000 : Sen. 2,631,336 : Cost 41.21644211 : Time 822.63s : 10806.84 words/s
[2019-06-30 20:30:30] Ep. 10 : Up. 208000 : Sen. 3,025,634 : Cost 40.96078110 : Time 822.83s : 10800.74 words/s
[2019-06-30 20:44:12] Ep. 10 : Up. 210000 : Sen. 3,420,404 : Cost 41.03764343 : Time 822.23s : 10829.08 words/s
[2019-06-30 20:57:59] Ep. 10 : Up. 212000 : Sen. 3,816,334 : Cost 41.11225510 : Time 826.79s : 10819.77 words/s
[2019-06-30 21:11:43] Ep. 10 : Up. 214000 : Sen. 4,210,840 : Cost 41.08413696 : Time 823.73s : 10811.01 words/s
[2019-06-30 21:12:03] Seen 4220483 samples
[2019-06-30 21:12:03] Starting epoch 11
[2019-06-30 21:12:03] [data] Shuffling data
[2019-06-30 21:12:05] [data] Done reading 4863734 sentences
[2019-06-30 21:12:20] [data] Done shuffling 4863734 sentences to temp files
[2019-06-30 21:25:47] Ep. 11 : Up. 216000 : Sen. 384,624 : Cost 40.16709900 : Time 844.42s : 10540.40 words/s
[2019-06-30 21:39:29] Ep. 11 : Up. 218000 : Sen. 778,490 : Cost 40.10410309 : Time 822.22s : 10800.22 words/s
[2019-06-30 21:53:14] Ep. 11 : Up. 220000 : Sen. 1,172,232 : Cost 40.36755371 : Time 824.89s : 10787.83 words/s
[2019-06-30 21:53:14] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-06-30 21:53:23] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter220000.npz
[2019-06-30 21:53:30] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-06-30 21:53:39] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-06-30 21:54:00] [valid] Ep. 11 : Up. 220000 : cross-entropy : 39.8108 : new best
[2019-06-30 21:54:04] [valid] Ep. 11 : Up. 220000 : perplexity : 4.79657 : new best
[2019-06-30 21:54:51] [valid] Ep. 11 : Up. 220000 : translation : 31.21 : new best
[2019-06-30 22:08:34] Ep. 11 : Up. 222000 : Sen. 1,565,880 : Cost 40.46903992 : Time 920.21s : 9649.88 words/s
[2019-06-30 22:22:17] Ep. 11 : Up. 224000 : Sen. 1,959,908 : Cost 40.54216385 : Time 822.12s : 10813.41 words/s
[2019-06-30 22:35:57] Ep. 11 : Up. 226000 : Sen. 2,353,004 : Cost 40.51254272 : Time 820.91s : 10811.61 words/s
[2019-06-30 22:49:40] Ep. 11 : Up. 228000 : Sen. 2,746,338 : Cost 40.67814636 : Time 822.67s : 10794.62 words/s
[2019-06-30 23:03:25] Ep. 11 : Up. 230000 : Sen. 3,141,884 : Cost 40.39260864 : Time 825.35s : 10806.62 words/s
[2019-06-30 23:17:13] Ep. 11 : Up. 232000 : Sen. 3,536,904 : Cost 40.66629028 : Time 827.07s : 10793.88 words/s
[2019-06-30 23:30:56] Ep. 11 : Up. 234000 : Sen. 3,932,139 : Cost 40.41688538 : Time 823.22s : 10809.20 words/s
[2019-06-30 23:41:00] Seen 4220483 samples
[2019-06-30 23:41:00] Starting epoch 12
[2019-06-30 23:41:00] [data] Shuffling data
[2019-06-30 23:41:03] [data] Done reading 4863734 sentences
[2019-06-30 23:41:20] [data] Done shuffling 4863734 sentences to temp files
[2019-06-30 23:45:02] Ep. 12 : Up. 236000 : Sen. 104,572 : Cost 40.54758453 : Time 846.54s : 10496.56 words/s
[2019-06-30 23:58:48] Ep. 12 : Up. 238000 : Sen. 498,406 : Cost 39.82789993 : Time 825.80s : 10784.11 words/s
[2019-07-01 00:12:32] Ep. 12 : Up. 240000 : Sen. 893,018 : Cost 39.71468353 : Time 823.56s : 10808.52 words/s
[2019-07-01 00:12:32] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-07-01 00:12:40] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter240000.npz
[2019-07-01 00:12:47] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-07-01 00:12:56] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-07-01 00:13:17] [valid] Ep. 12 : Up. 240000 : cross-entropy : 39.5955 : new best
[2019-07-01 00:13:22] [valid] Ep. 12 : Up. 240000 : perplexity : 4.75607 : new best
[2019-07-01 00:14:09] [valid] Ep. 12 : Up. 240000 : translation : 31.13 : stalled 1 times (last best: 31.21)
[2019-07-01 00:27:55] Ep. 12 : Up. 242000 : Sen. 1,288,623 : Cost 39.79340744 : Time 923.85s : 9653.88 words/s
[2019-07-01 00:41:42] Ep. 12 : Up. 244000 : Sen. 1,684,028 : Cost 40.34900665 : Time 826.71s : 10828.98 words/s
[2019-07-01 00:55:26] Ep. 12 : Up. 246000 : Sen. 2,079,256 : Cost 40.08936691 : Time 823.94s : 10820.38 words/s
[2019-07-01 01:09:09] Ep. 12 : Up. 248000 : Sen. 2,474,244 : Cost 39.91857910 : Time 823.35s : 10797.13 words/s
[2019-07-01 01:22:51] Ep. 12 : Up. 250000 : Sen. 2,866,004 : Cost 40.41884232 : Time 821.94s : 10783.76 words/s
[2019-07-01 01:36:35] Ep. 12 : Up. 252000 : Sen. 3,260,640 : Cost 40.10697937 : Time 823.96s : 10799.15 words/s
[2019-07-01 01:50:19] Ep. 12 : Up. 254000 : Sen. 3,654,874 : Cost 40.12433624 : Time 823.84s : 10786.81 words/s
[2019-07-01 02:04:02] Ep. 12 : Up. 256000 : Sen. 4,048,447 : Cost 40.23896790 : Time 822.80s : 10799.17 words/s
[2019-07-01 02:10:02] Seen 4220483 samples
[2019-07-01 02:10:02] Starting epoch 13
[2019-07-01 02:10:02] [data] Shuffling data
[2019-07-01 02:10:05] [data] Done reading 4863734 sentences
[2019-07-01 02:10:31] [data] Done shuffling 4863734 sentences to temp files
[2019-07-01 02:18:16] Ep. 13 : Up. 258000 : Sen. 221,666 : Cost 39.73983002 : Time 854.28s : 10408.94 words/s
[2019-07-01 02:31:59] Ep. 13 : Up. 260000 : Sen. 614,810 : Cost 39.47879791 : Time 822.82s : 10776.52 words/s
[2019-07-01 02:31:59] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-07-01 02:32:08] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter260000.npz
[2019-07-01 02:32:15] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-07-01 02:32:24] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-07-01 02:32:45] [valid] Ep. 13 : Up. 260000 : cross-entropy : 39.4343 : new best
[2019-07-01 02:32:49] [valid] Ep. 13 : Up. 260000 : perplexity : 4.72598 : new best
[2019-07-01 02:33:37] [valid] Ep. 13 : Up. 260000 : translation : 31.28 : new best
[2019-07-01 02:47:22] Ep. 13 : Up. 262000 : Sen. 1,008,242 : Cost 39.53670502 : Time 923.15s : 9628.47 words/s
[2019-07-01 03:01:05] Ep. 13 : Up. 264000 : Sen. 1,403,580 : Cost 39.56645966 : Time 822.91s : 10835.27 words/s
[2019-07-01 03:14:48] Ep. 13 : Up. 266000 : Sen. 1,797,630 : Cost 39.59840775 : Time 822.94s : 10827.11 words/s
[2019-07-01 03:28:30] Ep. 13 : Up. 268000 : Sen. 2,191,218 : Cost 39.80594635 : Time 821.82s : 10800.85 words/s
[2019-07-01 03:42:14] Ep. 13 : Up. 270000 : Sen. 2,585,870 : Cost 39.67963028 : Time 823.81s : 10808.89 words/s
[2019-07-01 03:55:58] Ep. 13 : Up. 272000 : Sen. 2,979,916 : Cost 39.87102890 : Time 823.91s : 10785.46 words/s
[2019-07-01 04:09:41] Ep. 13 : Up. 274000 : Sen. 3,374,832 : Cost 39.85456467 : Time 823.06s : 10814.57 words/s
[2019-07-01 04:23:25] Ep. 13 : Up. 276000 : Sen. 3,767,576 : Cost 39.97733307 : Time 823.77s : 10782.71 words/s
[2019-07-01 04:37:10] Ep. 13 : Up. 278000 : Sen. 4,163,568 : Cost 39.95339203 : Time 825.78s : 10825.86 words/s
[2019-07-01 04:39:09] Seen 4220483 samples
[2019-07-01 04:39:09] Starting epoch 14
[2019-07-01 04:39:09] [data] Shuffling data
[2019-07-01 04:39:11] [data] Done reading 4863734 sentences
[2019-07-01 04:39:29] [data] Done shuffling 4863734 sentences to temp files
[2019-07-01 04:51:14] Ep. 14 : Up. 280000 : Sen. 335,222 : Cost 39.02005005 : Time 844.17s : 10465.05 words/s
[2019-07-01 04:51:14] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-07-01 04:51:23] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter280000.npz
[2019-07-01 04:51:30] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-07-01 04:51:39] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-07-01 04:52:00] [valid] Ep. 14 : Up. 280000 : cross-entropy : 39.3052 : new best
[2019-07-01 04:52:05] [valid] Ep. 14 : Up. 280000 : perplexity : 4.70201 : new best
[2019-07-01 04:52:52] [valid] Ep. 14 : Up. 280000 : translation : 31.21 : stalled 1 times (last best: 31.28)
[2019-07-01 05:06:37] Ep. 14 : Up. 282000 : Sen. 729,132 : Cost 38.83909607 : Time 922.89s : 9646.33 words/s
[2019-07-01 05:20:20] Ep. 14 : Up. 284000 : Sen. 1,122,791 : Cost 39.21983337 : Time 822.37s : 10803.49 words/s
[2019-07-01 05:34:03] Ep. 14 : Up. 286000 : Sen. 1,516,062 : Cost 39.30410004 : Time 823.49s : 10783.60 words/s
[2019-07-01 05:47:50] Ep. 14 : Up. 288000 : Sen. 1,912,454 : Cost 39.38017273 : Time 826.45s : 10820.69 words/s
[2019-07-01 06:01:35] Ep. 14 : Up. 290000 : Sen. 2,305,786 : Cost 39.71246338 : Time 825.05s : 10781.96 words/s
[2019-07-01 06:15:19] Ep. 14 : Up. 292000 : Sen. 2,701,379 : Cost 39.37242126 : Time 823.89s : 10830.36 words/s
[2019-07-01 06:29:01] Ep. 14 : Up. 294000 : Sen. 3,096,362 : Cost 39.42071533 : Time 822.89s : 10822.13 words/s
[2019-07-01 06:42:44] Ep. 14 : Up. 296000 : Sen. 3,491,732 : Cost 39.51279449 : Time 822.96s : 10833.12 words/s
[2019-07-01 06:56:26] Ep. 14 : Up. 298000 : Sen. 3,883,641 : Cost 39.69931412 : Time 821.12s : 10794.20 words/s
[2019-07-01 07:32:24] Error: Error reading from file '.'
[2019-07-01 07:32:24] Error: Aborted from marian::io::InputFileStream& marian::io::getline(marian::io::InputFileStream&, std::__cxx11::string&) in /fs/bil0/abdel/marian-dev/src/common/file_stream.h:216

[CALL STACK]
[0x727f12]                                                            
[0x728985]          marian::data::Corpus::  next  ()                   + 0x6f5
[0x716e4f]          marian::data::CorpusIterator::  increment  ()      + 0x2f
[0x681a7d]          marian::data::BatchGenerator<marian::data::CorpusBase>::  fetchBatches  () + 0x10dd
[0x682adb]          std::future<std::result_of<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1} ()>::type> marian::ThreadPool::enqueue<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}>(std::result_of&&,(marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}&&)...)::{lambda()#1}::  operator()  () const + 0x2b
[0x6834be]          std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base,std::__future_base::_Result_base::_Deleter> (),std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<std::deque<std::shared_ptr<marian::data::CorpusBatch>,std::allocator<std::shared_ptr<marian::data::CorpusBatch>>>>,std::__future_base::_Result_base::_Deleter>,std::_Bind_simple<std::reference_wrapper<std::future<std::result_of<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1} ()>::type> marian::ThreadPool::enqueue<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}>(std::result_of&&,(marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}&&)...)::{lambda()#1}> ()>,std::deque<std::shared_ptr<marian::data::CorpusBatch>,std::allocator<std::shared_ptr<marian::data::CorpusBatch>>>>>::  _M_invoke  (std::_Any_data const&) + 0x3e
[0x5a5f19]          std::__future_base::_State_baseV2::  _M_do_set  (std::function<std::unique_ptr<std::__future_base::_Result_base,std::__future_base::_Result_base::_Deleter> ()>*,  bool*) + 0x29
[0x7f3364de4a99]                                                       + 0xea99
[0x59fac2]                                                            
[0x5a7341]          std::__future_base::_Task_state<std::future<std::result_of<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1} ()>::type> marian::ThreadPool::enqueue<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}>(std::result_of&&,(marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}&&)...)::{lambda()#1},std::allocator<int>,std::deque<std::shared_ptr<marian::data::CorpusBatch>,std::allocator<std::shared_ptr>> ()>::  _M_run  () + 0x51
[0x5d00b4]          std::thread::_Impl<std::_Bind_simple<marian::ThreadPool::reserve(unsigned long)::{lambda()#1} ()>>::  _M_run  () + 0x174
[0x7f3364904c80]                                                       + 0xb8c80
[0x7f3364ddd6ba]                                                       + 0x76ba
[0x7f336406a41d]    clone                                              + 0x6d

[2019-07-01 09:08:25] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-01 09:08:25] [marian] Running on zisa as process 93569 with command line:
[2019-07-01 09:08:25] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_bc1.1/model/model.npz -T . --devices 2 3 --train-sets ../experiments/100M_fasttext_bc1.1/data/train.bpe.de ../experiments/100M_fasttext_bc1.1/data/train.bpe.en --vocabs ../experiments/100M_fasttext_bc1.1/data/train.bpe.de.json ../experiments/100M_fasttext_bc1.1/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_bc1.1/data/dev.bpe.de ../experiments/100M_fasttext_bc1.1/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_bc1.1/model/dev.out --valid-script-path ../experiments/100M_fasttext_bc1.1/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_bc1.1/model/train.log --valid-log ../experiments/100M_fasttext_bc1.1/model/valid.log
[2019-07-01 09:08:25] [config] after-batches: 0
[2019-07-01 09:08:25] [config] after-epochs: 0
[2019-07-01 09:08:25] [config] allow-unk: false
[2019-07-01 09:08:25] [config] beam-size: 12
[2019-07-01 09:08:25] [config] bert-class-symbol: "[CLS]"
[2019-07-01 09:08:25] [config] bert-mask-symbol: "[MASK]"
[2019-07-01 09:08:25] [config] bert-masking-fraction: 0.15
[2019-07-01 09:08:25] [config] bert-sep-symbol: "[SEP]"
[2019-07-01 09:08:25] [config] bert-train-type-embeddings: true
[2019-07-01 09:08:25] [config] bert-type-vocab-size: 2
[2019-07-01 09:08:25] [config] best-deep: false
[2019-07-01 09:08:25] [config] clip-gemm: 0
[2019-07-01 09:08:25] [config] clip-norm: 1
[2019-07-01 09:08:25] [config] cost-type: ce-mean
[2019-07-01 09:08:25] [config] cpu-threads: 0
[2019-07-01 09:08:25] [config] data-weighting: ""
[2019-07-01 09:08:25] [config] data-weighting-type: sentence
[2019-07-01 09:08:25] [config] dec-cell: gru
[2019-07-01 09:08:25] [config] dec-cell-base-depth: 2
[2019-07-01 09:08:25] [config] dec-cell-high-depth: 1
[2019-07-01 09:08:25] [config] dec-depth: 1
[2019-07-01 09:08:25] [config] devices:
[2019-07-01 09:08:25] [config]   - 2
[2019-07-01 09:08:25] [config]   - 3
[2019-07-01 09:08:25] [config] dim-emb: 512
[2019-07-01 09:08:25] [config] dim-rnn: 1024
[2019-07-01 09:08:25] [config] dim-vocabs:
[2019-07-01 09:08:25] [config]   - 50000
[2019-07-01 09:08:25] [config]   - 50000
[2019-07-01 09:08:25] [config] disp-first: 0
[2019-07-01 09:08:25] [config] disp-freq: 2000
[2019-07-01 09:08:25] [config] disp-label-counts: false
[2019-07-01 09:08:25] [config] dropout-rnn: 0.2
[2019-07-01 09:08:25] [config] dropout-src: 0.1
[2019-07-01 09:08:25] [config] dropout-trg: 0.1
[2019-07-01 09:08:25] [config] dump-config: ""
[2019-07-01 09:08:25] [config] early-stopping: 5
[2019-07-01 09:08:25] [config] embedding-fix-src: false
[2019-07-01 09:08:25] [config] embedding-fix-trg: false
[2019-07-01 09:08:25] [config] embedding-normalization: false
[2019-07-01 09:08:25] [config] embedding-vectors:
[2019-07-01 09:08:25] [config]   []
[2019-07-01 09:08:25] [config] enc-cell: gru
[2019-07-01 09:08:25] [config] enc-cell-depth: 1
[2019-07-01 09:08:25] [config] enc-depth: 1
[2019-07-01 09:08:25] [config] enc-type: bidirectional
[2019-07-01 09:08:25] [config] exponential-smoothing: 0.0001
[2019-07-01 09:08:25] [config] grad-dropping-momentum: 0
[2019-07-01 09:08:25] [config] grad-dropping-rate: 0
[2019-07-01 09:08:25] [config] grad-dropping-warmup: 100
[2019-07-01 09:08:25] [config] guided-alignment: none
[2019-07-01 09:08:25] [config] guided-alignment-cost: mse
[2019-07-01 09:08:25] [config] guided-alignment-weight: 0.1
[2019-07-01 09:08:25] [config] ignore-model-config: false
[2019-07-01 09:08:25] [config] input-types:
[2019-07-01 09:08:25] [config]   []
[2019-07-01 09:08:25] [config] interpolate-env-vars: false
[2019-07-01 09:08:25] [config] keep-best: false
[2019-07-01 09:08:25] [config] label-smoothing: 0
[2019-07-01 09:08:25] [config] layer-normalization: true
[2019-07-01 09:08:25] [config] learn-rate: 0.0001
[2019-07-01 09:08:25] [config] log: ../experiments/100M_fasttext_bc1.1/model/train.log
[2019-07-01 09:08:25] [config] log-level: info
[2019-07-01 09:08:25] [config] log-time-zone: ""
[2019-07-01 09:08:25] [config] lr-decay: 0
[2019-07-01 09:08:25] [config] lr-decay-freq: 50000
[2019-07-01 09:08:25] [config] lr-decay-inv-sqrt:
[2019-07-01 09:08:25] [config]   - 0
[2019-07-01 09:08:25] [config] lr-decay-repeat-warmup: false
[2019-07-01 09:08:25] [config] lr-decay-reset-optimizer: false
[2019-07-01 09:08:25] [config] lr-decay-start:
[2019-07-01 09:08:25] [config]   - 10
[2019-07-01 09:08:25] [config]   - 1
[2019-07-01 09:08:25] [config] lr-decay-strategy: epoch+stalled
[2019-07-01 09:08:25] [config] lr-report: false
[2019-07-01 09:08:25] [config] lr-warmup: 0
[2019-07-01 09:08:25] [config] lr-warmup-at-reload: false
[2019-07-01 09:08:25] [config] lr-warmup-cycle: false
[2019-07-01 09:08:25] [config] lr-warmup-start-rate: 0
[2019-07-01 09:08:25] [config] max-length: 50
[2019-07-01 09:08:25] [config] max-length-crop: false
[2019-07-01 09:08:25] [config] max-length-factor: 3
[2019-07-01 09:08:25] [config] maxi-batch: 100
[2019-07-01 09:08:25] [config] maxi-batch-sort: trg
[2019-07-01 09:08:25] [config] mini-batch: 64
[2019-07-01 09:08:25] [config] mini-batch-fit: true
[2019-07-01 09:08:25] [config] mini-batch-fit-step: 10
[2019-07-01 09:08:25] [config] mini-batch-overstuff: 1
[2019-07-01 09:08:25] [config] mini-batch-track-lr: false
[2019-07-01 09:08:25] [config] mini-batch-understuff: 1
[2019-07-01 09:08:25] [config] mini-batch-warmup: 0
[2019-07-01 09:08:25] [config] mini-batch-words: 0
[2019-07-01 09:08:25] [config] mini-batch-words-ref: 0
[2019-07-01 09:08:25] [config] model: ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-07-01 09:08:25] [config] multi-loss-type: sum
[2019-07-01 09:08:25] [config] multi-node: false
[2019-07-01 09:08:25] [config] multi-node-overlap: true
[2019-07-01 09:08:25] [config] n-best: false
[2019-07-01 09:08:25] [config] no-nccl: false
[2019-07-01 09:08:25] [config] no-reload: false
[2019-07-01 09:08:25] [config] no-restore-corpus: false
[2019-07-01 09:08:25] [config] no-shuffle: false
[2019-07-01 09:08:25] [config] normalize: 1
[2019-07-01 09:08:25] [config] num-devices: 0
[2019-07-01 09:08:25] [config] optimizer: adam
[2019-07-01 09:08:25] [config] optimizer-delay: 1
[2019-07-01 09:08:25] [config] optimizer-params:
[2019-07-01 09:08:25] [config]   []
[2019-07-01 09:08:25] [config] overwrite: false
[2019-07-01 09:08:25] [config] pretrained-model: ""
[2019-07-01 09:08:25] [config] quiet: false
[2019-07-01 09:08:25] [config] quiet-translation: true
[2019-07-01 09:08:25] [config] relative-paths: false
[2019-07-01 09:08:25] [config] right-left: false
[2019-07-01 09:08:25] [config] save-freq: 20000
[2019-07-01 09:08:25] [config] seed: 1111
[2019-07-01 09:08:25] [config] shuffle-in-ram: false
[2019-07-01 09:08:25] [config] skip: false
[2019-07-01 09:08:25] [config] sqlite: ""
[2019-07-01 09:08:25] [config] sqlite-drop: false
[2019-07-01 09:08:25] [config] sync-sgd: true
[2019-07-01 09:08:25] [config] tempdir: .
[2019-07-01 09:08:25] [config] tied-embeddings: false
[2019-07-01 09:08:25] [config] tied-embeddings-all: false
[2019-07-01 09:08:25] [config] tied-embeddings-src: false
[2019-07-01 09:08:25] [config] train-sets:
[2019-07-01 09:08:25] [config]   - ../experiments/100M_fasttext_bc1.1/data/train.bpe.de
[2019-07-01 09:08:25] [config]   - ../experiments/100M_fasttext_bc1.1/data/train.bpe.en
[2019-07-01 09:08:25] [config] transformer-aan-activation: swish
[2019-07-01 09:08:25] [config] transformer-aan-depth: 2
[2019-07-01 09:08:25] [config] transformer-aan-nogate: false
[2019-07-01 09:08:25] [config] transformer-decoder-autoreg: self-attention
[2019-07-01 09:08:25] [config] transformer-dim-aan: 2048
[2019-07-01 09:08:25] [config] transformer-dim-ffn: 2048
[2019-07-01 09:08:25] [config] transformer-dropout: 0
[2019-07-01 09:08:25] [config] transformer-dropout-attention: 0
[2019-07-01 09:08:25] [config] transformer-dropout-ffn: 0
[2019-07-01 09:08:25] [config] transformer-ffn-activation: swish
[2019-07-01 09:08:25] [config] transformer-ffn-depth: 2
[2019-07-01 09:08:25] [config] transformer-guided-alignment-layer: last
[2019-07-01 09:08:25] [config] transformer-heads: 8
[2019-07-01 09:08:25] [config] transformer-no-projection: false
[2019-07-01 09:08:25] [config] transformer-postprocess: dan
[2019-07-01 09:08:25] [config] transformer-postprocess-emb: d
[2019-07-01 09:08:25] [config] transformer-preprocess: ""
[2019-07-01 09:08:25] [config] transformer-tied-layers:
[2019-07-01 09:08:25] [config]   []
[2019-07-01 09:08:25] [config] transformer-train-position-embeddings: false
[2019-07-01 09:08:25] [config] type: amun
[2019-07-01 09:08:25] [config] ulr: false
[2019-07-01 09:08:25] [config] ulr-dim-emb: 0
[2019-07-01 09:08:25] [config] ulr-dropout: 0
[2019-07-01 09:08:25] [config] ulr-keys-vectors: ""
[2019-07-01 09:08:25] [config] ulr-query-vectors: ""
[2019-07-01 09:08:25] [config] ulr-softmax-temperature: 1
[2019-07-01 09:08:25] [config] ulr-trainable-transformation: false
[2019-07-01 09:08:25] [config] valid-freq: 20000
[2019-07-01 09:08:25] [config] valid-log: ../experiments/100M_fasttext_bc1.1/model/valid.log
[2019-07-01 09:08:25] [config] valid-max-length: 1000
[2019-07-01 09:08:25] [config] valid-metrics:
[2019-07-01 09:08:25] [config]   - cross-entropy
[2019-07-01 09:08:25] [config]   - perplexity
[2019-07-01 09:08:25] [config]   - translation
[2019-07-01 09:08:25] [config] valid-mini-batch: 8
[2019-07-01 09:08:25] [config] valid-script-path: ../experiments/100M_fasttext_bc1.1/score-dev.sh
[2019-07-01 09:08:25] [config] valid-sets:
[2019-07-01 09:08:25] [config]   - ../experiments/100M_fasttext_bc1.1/data/dev.bpe.de
[2019-07-01 09:08:25] [config]   - ../experiments/100M_fasttext_bc1.1/data/dev.bpe.en
[2019-07-01 09:08:25] [config] valid-translation-output: ../experiments/100M_fasttext_bc1.1/model/dev.out
[2019-07-01 09:08:25] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-01 09:08:25] [config] vocabs:
[2019-07-01 09:08:25] [config]   - ../experiments/100M_fasttext_bc1.1/data/train.bpe.de.json
[2019-07-01 09:08:25] [config]   - ../experiments/100M_fasttext_bc1.1/data/train.bpe.en.json
[2019-07-01 09:08:25] [config] word-penalty: 0
[2019-07-01 09:08:25] [config] workspace: 3000
[2019-07-01 09:08:25] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-01 09:08:25] Using synchronous training
[2019-07-01 09:08:25] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_bc1.1/data/train.bpe.de.json
[2019-07-01 09:08:25] [data] Using unused word id eos for 0
[2019-07-01 09:08:25] [data] Using unused word id UNK for 1
[2019-07-01 09:08:25] [data] Setting vocabulary size for input 0 to 50000
[2019-07-01 09:08:25] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_bc1.1/data/train.bpe.en.json
[2019-07-01 09:08:26] [data] Using unused word id eos for 0
[2019-07-01 09:08:26] [data] Using unused word id UNK for 1
[2019-07-01 09:08:26] [data] Setting vocabulary size for input 1 to 50000
[2019-07-01 09:08:26] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-01 09:08:26] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-01 09:08:26] [memory] Extending reserved space to 3072 MB (device gpu2)
[2019-07-01 09:08:27] [memory] Extending reserved space to 3072 MB (device gpu3)
[2019-07-01 09:08:27] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-01 09:08:27] [comm] NCCLCommunicator constructed successfully.
[2019-07-01 09:08:27] [training] Using 2 GPUs
[2019-07-01 09:08:27] [memory] Reserving 422 MB, device gpu2
[2019-07-01 09:08:27] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-01 09:08:27] [memory] Reserving 422 MB, device gpu2
[2019-07-01 09:08:34] [batching] Done. Typical MB size is 8084 target words
[2019-07-01 09:08:34] [memory] Extending reserved space to 3072 MB (device gpu2)
[2019-07-01 09:08:34] [memory] Extending reserved space to 3072 MB (device gpu3)
[2019-07-01 09:08:34] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-01 09:08:34] [comm] NCCLCommunicator constructed successfully.
[2019-07-01 09:08:34] [training] Using 2 GPUs
[2019-07-01 09:08:34] Loading model from ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-07-01 09:08:40] Loading model from ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-07-01 09:08:42] Loading Adam parameters from ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-07-01 09:08:53] [memory] Reserving 422 MB, device gpu2
[2019-07-01 09:08:53] [memory] Reserving 422 MB, device gpu3
[2019-07-01 09:08:54] [training] Model reloaded from ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-07-01 09:08:54] [data] Restoring the corpus state to epoch 14, batch 280000
[2019-07-01 09:08:54] [data] Shuffling data
[2019-07-01 09:08:56] [data] Done reading 4863734 sentences
[2019-07-01 09:09:20] [data] Done shuffling 4863734 sentences to temp files
[2019-07-01 09:09:30] Training started
[2019-07-01 09:09:30] [training] Batches are processed as 1 process(es) x 2 devices/process
[2019-07-01 09:09:30] [memory] Reserving 422 MB, device gpu3
[2019-07-01 09:09:30] [memory] Reserving 422 MB, device gpu2
[2019-07-01 09:09:31] [memory] Reserving 422 MB, device gpu3
[2019-07-01 09:09:31] [memory] Reserving 422 MB, device gpu2
[2019-07-01 09:09:31] Loading model from ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-07-01 09:09:37] [memory] Reserving 422 MB, device cpu0
[2019-07-01 09:09:37] [memory] Reserving 211 MB, device gpu2
[2019-07-01 09:09:37] [memory] Reserving 211 MB, device gpu3
[2019-07-01 09:23:18] Ep. 14 : Up. 282000 : Sen. 729,132 : Cost 39.07765961 : Time 892.62s : 9973.49 words/s
[2019-07-01 09:37:01] Ep. 14 : Up. 284000 : Sen. 1,122,791 : Cost 39.17987442 : Time 822.53s : 10801.40 words/s
[2019-07-01 09:50:45] Ep. 14 : Up. 286000 : Sen. 1,516,062 : Cost 39.21925354 : Time 824.26s : 10773.51 words/s
[2019-07-01 10:04:32] Ep. 14 : Up. 288000 : Sen. 1,912,454 : Cost 39.44766617 : Time 827.15s : 10811.52 words/s
[2019-07-01 10:18:18] Ep. 14 : Up. 290000 : Sen. 2,305,786 : Cost 39.60933685 : Time 825.75s : 10772.84 words/s
[2019-07-01 10:32:03] Ep. 14 : Up. 292000 : Sen. 2,701,379 : Cost 39.39681244 : Time 825.23s : 10812.78 words/s
[2019-07-01 10:45:48] Ep. 14 : Up. 294000 : Sen. 3,096,362 : Cost 39.27491379 : Time 824.73s : 10797.96 words/s
[2019-07-01 10:59:33] Ep. 14 : Up. 296000 : Sen. 3,491,732 : Cost 39.47852325 : Time 824.98s : 10806.53 words/s
[2019-07-01 11:13:17] Ep. 14 : Up. 298000 : Sen. 3,883,641 : Cost 39.68530273 : Time 823.67s : 10760.70 words/s
[2019-07-01 11:25:01] Seen 4220483 samples
[2019-07-01 11:25:01] Starting epoch 15
[2019-07-01 11:25:01] [data] Shuffling data
[2019-07-01 11:25:03] [data] Done reading 4863734 sentences
[2019-07-01 11:25:19] [data] Done shuffling 4863734 sentences to temp files
[2019-07-01 11:27:22] Ep. 15 : Up. 300000 : Sen. 57,240 : Cost 39.51423645 : Time 845.57s : 10511.62 words/s
[2019-07-01 11:27:22] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-07-01 11:27:31] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter300000.npz
[2019-07-01 11:27:37] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-07-01 11:27:47] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-07-01 11:28:09] [valid] Ep. 15 : Up. 300000 : cross-entropy : 39.1526 : new best
[2019-07-01 11:28:14] [valid] Ep. 15 : Up. 300000 : perplexity : 4.67383 : new best
[2019-07-01 11:29:00] [valid] Ep. 15 : Up. 300000 : translation : 31.52 : new best
[2019-07-01 11:42:46] Ep. 15 : Up. 302000 : Sen. 452,440 : Cost 38.44190216 : Time 924.16s : 9633.40 words/s
[2019-07-01 11:56:34] Ep. 15 : Up. 304000 : Sen. 847,612 : Cost 38.79586792 : Time 827.66s : 10784.03 words/s
[2019-07-01 12:10:20] Ep. 15 : Up. 306000 : Sen. 1,241,600 : Cost 38.97140884 : Time 826.17s : 10788.77 words/s
[2019-07-01 12:24:05] Ep. 15 : Up. 308000 : Sen. 1,636,275 : Cost 39.02701569 : Time 824.66s : 10798.15 words/s
[2019-07-01 12:37:49] Ep. 15 : Up. 310000 : Sen. 2,030,558 : Cost 38.91780472 : Time 823.63s : 10791.18 words/s
[2019-07-01 12:51:33] Ep. 15 : Up. 312000 : Sen. 2,423,890 : Cost 39.20052719 : Time 824.93s : 10775.01 words/s
[2019-07-01 13:05:20] Ep. 15 : Up. 314000 : Sen. 2,820,694 : Cost 39.12145233 : Time 826.94s : 10818.43 words/s
[2019-07-01 13:19:05] Ep. 15 : Up. 316000 : Sen. 3,214,286 : Cost 39.31390381 : Time 824.63s : 10781.47 words/s
[2019-07-01 13:32:51] Ep. 15 : Up. 318000 : Sen. 3,608,724 : Cost 39.31878662 : Time 825.77s : 10787.04 words/s
[2019-07-01 13:46:36] Ep. 15 : Up. 320000 : Sen. 4,004,523 : Cost 39.44969177 : Time 825.19s : 10814.90 words/s
[2019-07-01 13:46:36] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-07-01 13:46:45] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter320000.npz
[2019-07-01 13:46:51] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-07-01 13:47:01] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-07-01 13:47:29] [valid] Ep. 15 : Up. 320000 : cross-entropy : 39.0658 : new best
[2019-07-01 13:47:33] [valid] Ep. 15 : Up. 320000 : perplexity : 4.65788 : new best
[2019-07-01 13:48:21] [valid] Ep. 15 : Up. 320000 : translation : 31.7 : new best
[2019-07-01 13:55:56] Seen 4220483 samples
[2019-07-01 13:55:56] Starting epoch 16
[2019-07-01 13:55:56] [data] Shuffling data
[2019-07-01 13:55:58] [data] Done reading 4863734 sentences
[2019-07-01 13:56:15] [data] Done shuffling 4863734 sentences to temp files
[2019-07-01 14:02:32] Ep. 16 : Up. 322000 : Sen. 178,732 : Cost 38.83179474 : Time 956.16s : 9315.21 words/s
[2019-07-01 14:16:18] Ep. 16 : Up. 324000 : Sen. 574,092 : Cost 38.37005997 : Time 826.03s : 10791.92 words/s
[2019-07-01 14:30:06] Ep. 16 : Up. 326000 : Sen. 970,470 : Cost 38.73421097 : Time 828.13s : 10816.47 words/s
[2019-07-01 14:43:50] Ep. 16 : Up. 328000 : Sen. 1,364,348 : Cost 38.77624512 : Time 824.07s : 10786.89 words/s
[2019-07-01 14:57:43] Ep. 16 : Up. 330000 : Sen. 1,758,944 : Cost 38.75079727 : Time 833.01s : 10687.19 words/s
[2019-07-01 15:11:32] Ep. 16 : Up. 332000 : Sen. 2,154,350 : Cost 38.89305496 : Time 828.39s : 10788.06 words/s
[2019-07-01 15:25:16] Ep. 16 : Up. 334000 : Sen. 2,547,716 : Cost 38.88130951 : Time 824.39s : 10770.79 words/s
[2019-07-01 15:39:00] Ep. 16 : Up. 336000 : Sen. 2,941,198 : Cost 39.08226395 : Time 823.99s : 10784.96 words/s
[2019-07-01 15:52:46] Ep. 16 : Up. 338000 : Sen. 3,336,162 : Cost 38.77285004 : Time 825.44s : 10772.63 words/s
[2019-07-01 16:06:30] Ep. 16 : Up. 340000 : Sen. 3,729,224 : Cost 38.99684906 : Time 824.03s : 10765.92 words/s
[2019-07-01 16:06:30] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-07-01 16:06:38] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter340000.npz
[2019-07-01 16:06:45] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-07-01 16:06:54] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-07-01 16:07:15] [valid] Ep. 16 : Up. 340000 : cross-entropy : 38.9762 : new best
[2019-07-01 16:07:19] [valid] Ep. 16 : Up. 340000 : perplexity : 4.64147 : new best
[2019-07-01 16:08:07] [valid] Ep. 16 : Up. 340000 : translation : 31.8 : new best
[2019-07-01 16:21:55] Ep. 16 : Up. 342000 : Sen. 4,122,926 : Cost 39.15554810 : Time 925.58s : 9607.18 words/s
[2019-07-01 16:25:21] Seen 4220483 samples
[2019-07-01 16:25:21] Starting epoch 17
[2019-07-01 16:25:21] [data] Shuffling data
[2019-07-01 16:25:24] [data] Done reading 4863734 sentences
[2019-07-01 16:25:44] [data] Done shuffling 4863734 sentences to temp files
[2019-07-01 16:36:02] Ep. 17 : Up. 344000 : Sen. 294,400 : Cost 38.41996002 : Time 846.31s : 10457.91 words/s
[2019-07-01 16:49:48] Ep. 17 : Up. 346000 : Sen. 689,099 : Cost 38.27463531 : Time 826.26s : 10783.35 words/s
[2019-07-01 17:03:33] Ep. 17 : Up. 348000 : Sen. 1,082,698 : Cost 38.32500458 : Time 825.49s : 10761.61 words/s
[2019-07-01 17:17:21] Ep. 17 : Up. 350000 : Sen. 1,477,770 : Cost 38.55114746 : Time 828.00s : 10771.12 words/s
[2019-07-01 17:31:08] Ep. 17 : Up. 352000 : Sen. 1,872,554 : Cost 38.58006287 : Time 826.50s : 10782.41 words/s
[2019-07-01 17:44:52] Ep. 17 : Up. 354000 : Sen. 2,265,444 : Cost 38.70150375 : Time 824.46s : 10758.28 words/s
[2019-07-01 17:58:40] Ep. 17 : Up. 356000 : Sen. 2,660,382 : Cost 38.68481064 : Time 828.07s : 10768.34 words/s
[2019-07-01 18:12:29] Ep. 17 : Up. 358000 : Sen. 3,055,821 : Cost 38.85889435 : Time 828.75s : 10775.01 words/s
[2019-07-01 18:26:15] Ep. 17 : Up. 360000 : Sen. 3,451,123 : Cost 38.75222397 : Time 826.18s : 10783.49 words/s
[2019-07-01 18:26:15] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-07-01 18:26:24] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter360000.npz
[2019-07-01 18:26:31] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-07-01 18:26:40] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-07-01 18:27:01] [valid] Ep. 17 : Up. 360000 : cross-entropy : 38.9625 : new best
[2019-07-01 18:27:05] [valid] Ep. 17 : Up. 360000 : perplexity : 4.63897 : new best
[2019-07-01 18:27:53] [valid] Ep. 17 : Up. 360000 : translation : 31.89 : new best
[2019-07-01 18:41:42] Ep. 17 : Up. 362000 : Sen. 3,845,776 : Cost 38.89841461 : Time 926.53s : 9612.70 words/s
[2019-07-01 18:54:45] Seen 4220483 samples
[2019-07-01 18:54:45] Starting epoch 18
[2019-07-01 18:54:45] [data] Shuffling data
[2019-07-01 18:54:48] [data] Done reading 4863734 sentences
[2019-07-01 18:55:11] [data] Done shuffling 4863734 sentences to temp files
[2019-07-01 18:55:54] Ep. 18 : Up. 364000 : Sen. 20,170 : Cost 38.94805908 : Time 852.46s : 10461.22 words/s
[2019-07-01 19:09:40] Ep. 18 : Up. 366000 : Sen. 414,362 : Cost 37.82635117 : Time 825.46s : 10769.39 words/s
[2019-07-01 19:23:24] Ep. 18 : Up. 368000 : Sen. 807,912 : Cost 38.12224579 : Time 824.28s : 10760.87 words/s
[2019-07-01 19:37:08] Ep. 18 : Up. 370000 : Sen. 1,201,290 : Cost 38.25947952 : Time 824.40s : 10762.63 words/s
[2019-07-01 19:50:53] Ep. 18 : Up. 372000 : Sen. 1,593,444 : Cost 38.19849014 : Time 824.36s : 10728.08 words/s
[2019-07-01 20:04:45] Ep. 18 : Up. 374000 : Sen. 1,987,418 : Cost 38.31613922 : Time 831.77s : 10698.61 words/s
[2019-07-01 20:18:31] Ep. 18 : Up. 376000 : Sen. 2,382,038 : Cost 38.47820282 : Time 826.96s : 10771.27 words/s
[2019-07-01 20:32:19] Ep. 18 : Up. 378000 : Sen. 2,776,645 : Cost 38.53989029 : Time 827.61s : 10772.35 words/s
[2019-07-01 20:46:07] Ep. 18 : Up. 380000 : Sen. 3,170,534 : Cost 38.70152283 : Time 827.69s : 10766.45 words/s
[2019-07-01 20:46:07] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-07-01 20:46:16] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter380000.npz
[2019-07-01 20:46:22] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-07-01 20:46:32] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-07-01 20:46:54] [valid] Ep. 18 : Up. 380000 : cross-entropy : 38.9252 : new best
[2019-07-01 20:46:58] [valid] Ep. 18 : Up. 380000 : perplexity : 4.63215 : new best
[2019-07-01 20:47:46] [valid] Ep. 18 : Up. 380000 : translation : 31.82 : stalled 1 times (last best: 31.89)
[2019-07-01 21:01:36] Ep. 18 : Up. 382000 : Sen. 3,565,538 : Cost 38.65429306 : Time 929.47s : 9590.60 words/s
[2019-07-01 21:15:21] Ep. 18 : Up. 384000 : Sen. 3,958,907 : Cost 38.70572281 : Time 824.72s : 10777.77 words/s
[2019-07-01 21:24:29] Seen 4220483 samples
[2019-07-01 21:24:29] Starting epoch 19
[2019-07-01 21:24:29] [data] Shuffling data
[2019-07-01 21:24:32] [data] Done reading 4863734 sentences
[2019-07-01 21:24:49] [data] Done shuffling 4863734 sentences to temp files
[2019-07-01 21:29:28] Ep. 19 : Up. 386000 : Sen. 132,784 : Cost 38.39085770 : Time 846.62s : 10495.89 words/s
[2019-07-01 21:43:14] Ep. 19 : Up. 388000 : Sen. 527,568 : Cost 38.04023361 : Time 826.19s : 10786.43 words/s
[2019-07-01 21:57:00] Ep. 19 : Up. 390000 : Sen. 921,016 : Cost 38.00985718 : Time 826.72s : 10760.78 words/s
[2019-07-01 22:10:45] Ep. 19 : Up. 392000 : Sen. 1,314,384 : Cost 38.23327255 : Time 824.16s : 10777.04 words/s
[2019-07-01 22:24:29] Ep. 19 : Up. 394000 : Sen. 1,707,660 : Cost 38.05104446 : Time 824.61s : 10758.56 words/s
[2019-07-01 22:38:17] Ep. 19 : Up. 396000 : Sen. 2,101,596 : Cost 38.28915024 : Time 827.30s : 10771.64 words/s
[2019-07-01 22:52:00] Ep. 19 : Up. 398000 : Sen. 2,495,574 : Cost 38.18378067 : Time 823.17s : 10785.53 words/s
[2019-07-01 23:05:46] Ep. 19 : Up. 400000 : Sen. 2,888,857 : Cost 38.49431229 : Time 826.03s : 10750.00 words/s
[2019-07-01 23:05:46] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-07-01 23:05:55] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter400000.npz
[2019-07-01 23:06:01] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-07-01 23:06:11] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-07-01 23:06:34] [valid] Ep. 19 : Up. 400000 : cross-entropy : 38.8635 : new best
[2019-07-01 23:06:38] [valid] Ep. 19 : Up. 400000 : perplexity : 4.62093 : new best
[2019-07-01 23:07:26] [valid] Ep. 19 : Up. 400000 : translation : 31.74 : stalled 2 times (last best: 31.89)
[2019-07-01 23:21:15] Ep. 19 : Up. 402000 : Sen. 3,283,944 : Cost 38.23401260 : Time 929.43s : 9589.63 words/s
[2019-07-01 23:35:00] Ep. 19 : Up. 404000 : Sen. 3,677,411 : Cost 38.42181778 : Time 824.39s : 10760.81 words/s
[2019-07-01 23:48:44] Ep. 19 : Up. 406000 : Sen. 4,070,556 : Cost 38.44427109 : Time 824.41s : 10757.78 words/s
[2019-07-01 23:53:59] Seen 4220483 samples
[2019-07-01 23:53:59] Starting epoch 20
[2019-07-01 23:53:59] [data] Shuffling data
[2019-07-01 23:54:01] [data] Done reading 4863734 sentences
[2019-07-01 23:54:24] [data] Done shuffling 4863734 sentences to temp files
[2019-07-02 00:02:55] Ep. 20 : Up. 408000 : Sen. 244,256 : Cost 37.73994827 : Time 851.13s : 10439.79 words/s
[2019-07-02 00:16:40] Ep. 20 : Up. 410000 : Sen. 637,904 : Cost 37.79205704 : Time 824.88s : 10777.54 words/s
[2019-07-02 00:30:26] Ep. 20 : Up. 412000 : Sen. 1,031,508 : Cost 37.78785706 : Time 825.97s : 10758.13 words/s
[2019-07-02 00:44:14] Ep. 20 : Up. 414000 : Sen. 1,425,528 : Cost 38.10898209 : Time 827.75s : 10771.98 words/s
[2019-07-02 00:58:02] Ep. 20 : Up. 416000 : Sen. 1,820,080 : Cost 37.86152267 : Time 827.95s : 10735.73 words/s
[2019-07-02 01:11:48] Ep. 20 : Up. 418000 : Sen. 2,215,408 : Cost 38.02711868 : Time 826.27s : 10791.76 words/s
[2019-07-02 01:25:33] Ep. 20 : Up. 420000 : Sen. 2,608,758 : Cost 38.21242142 : Time 825.24s : 10768.28 words/s
[2019-07-02 01:25:33] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-07-02 01:25:42] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter420000.npz
[2019-07-02 01:25:49] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-07-02 01:25:58] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-07-02 01:26:20] [valid] Ep. 20 : Up. 420000 : cross-entropy : 38.8196 : new best
[2019-07-02 01:26:25] [valid] Ep. 20 : Up. 420000 : perplexity : 4.61293 : new best
[2019-07-02 01:27:12] [valid] Ep. 20 : Up. 420000 : translation : 31.74 : stalled 3 times (last best: 31.89)
[2019-07-02 01:41:00] Ep. 20 : Up. 422000 : Sen. 3,003,748 : Cost 38.17203140 : Time 927.18s : 9620.06 words/s
[2019-07-02 01:54:46] Ep. 20 : Up. 424000 : Sen. 3,397,680 : Cost 38.13356018 : Time 825.29s : 10759.19 words/s
[2019-07-02 02:08:34] Ep. 20 : Up. 426000 : Sen. 3,792,054 : Cost 38.26972198 : Time 827.97s : 10761.46 words/s
[2019-07-02 02:22:18] Ep. 20 : Up. 428000 : Sen. 4,186,068 : Cost 38.31535339 : Time 824.75s : 10777.91 words/s
[2019-07-02 02:23:30] Seen 4220483 samples
[2019-07-02 02:23:30] Starting epoch 21
[2019-07-02 02:23:30] [data] Shuffling data
[2019-07-02 02:23:33] [data] Done reading 4863734 sentences
[2019-07-02 02:23:54] [data] Done shuffling 4863734 sentences to temp files
[2019-07-02 02:36:30] Ep. 21 : Up. 430000 : Sen. 360,708 : Cost 37.33636856 : Time 851.72s : 10464.37 words/s
[2019-07-02 02:50:15] Ep. 21 : Up. 432000 : Sen. 754,102 : Cost 37.41474915 : Time 824.87s : 10753.81 words/s
[2019-07-02 03:04:04] Ep. 21 : Up. 434000 : Sen. 1,148,360 : Cost 37.85645294 : Time 829.03s : 10758.30 words/s
[2019-07-02 03:17:49] Ep. 21 : Up. 436000 : Sen. 1,543,908 : Cost 37.63826752 : Time 825.30s : 10794.01 words/s
[2019-07-02 03:31:38] Ep. 21 : Up. 438000 : Sen. 1,940,052 : Cost 37.75651932 : Time 828.88s : 10802.58 words/s
[2019-07-02 03:45:25] Ep. 21 : Up. 440000 : Sen. 2,335,074 : Cost 37.94290924 : Time 826.84s : 10785.19 words/s
[2019-07-02 03:45:25] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-07-02 03:45:34] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter440000.npz
[2019-07-02 03:45:40] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-07-02 03:45:50] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-07-02 03:46:12] [valid] Ep. 21 : Up. 440000 : cross-entropy : 38.7856 : new best
[2019-07-02 03:46:16] [valid] Ep. 21 : Up. 440000 : perplexity : 4.60676 : new best
[2019-07-02 03:47:04] [valid] Ep. 21 : Up. 440000 : translation : 31.74 : stalled 4 times (last best: 31.89)
[2019-07-02 04:00:51] Ep. 21 : Up. 442000 : Sen. 2,727,072 : Cost 38.02244949 : Time 925.51s : 9563.45 words/s
[2019-07-02 04:14:35] Ep. 21 : Up. 444000 : Sen. 3,120,840 : Cost 38.03614044 : Time 824.53s : 10778.86 words/s
[2019-07-02 04:28:23] Ep. 21 : Up. 446000 : Sen. 3,515,648 : Cost 38.02890396 : Time 828.11s : 10761.86 words/s
[2019-07-02 04:42:10] Ep. 21 : Up. 448000 : Sen. 3,909,426 : Cost 38.17521286 : Time 826.46s : 10768.80 words/s
[2019-07-02 04:52:59] Seen 4220483 samples
[2019-07-02 04:52:59] Starting epoch 22
[2019-07-02 04:52:59] [data] Shuffling data
[2019-07-02 04:53:02] [data] Done reading 4863734 sentences
[2019-07-02 04:53:25] [data] Done shuffling 4863734 sentences to temp files
[2019-07-02 04:56:21] Ep. 22 : Up. 450000 : Sen. 83,670 : Cost 37.79740906 : Time 851.60s : 10433.72 words/s
[2019-07-02 05:10:31] Ep. 22 : Up. 452000 : Sen. 478,510 : Cost 37.21365356 : Time 850.19s : 10486.91 words/s
[2019-07-02 05:24:14] Ep. 22 : Up. 454000 : Sen. 871,030 : Cost 37.24891281 : Time 822.34s : 10766.58 words/s
[2019-07-02 05:37:59] Ep. 22 : Up. 456000 : Sen. 1,265,332 : Cost 37.43271637 : Time 824.94s : 10792.94 words/s
[2019-07-02 05:51:44] Ep. 22 : Up. 458000 : Sen. 1,658,968 : Cost 37.77499771 : Time 825.32s : 10758.05 words/s
[2019-07-02 06:05:34] Ep. 22 : Up. 460000 : Sen. 2,054,244 : Cost 37.68472290 : Time 829.60s : 10754.39 words/s
[2019-07-02 06:05:34] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-07-02 06:05:44] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter460000.npz
[2019-07-02 06:05:50] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-07-02 06:06:00] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-07-02 06:06:26] [valid] Ep. 22 : Up. 460000 : cross-entropy : 38.7877 : stalled 1 times (last best: 38.7856)
[2019-07-02 06:06:31] [valid] Ep. 22 : Up. 460000 : perplexity : 4.60714 : stalled 1 times (last best: 4.60676)
[2019-07-02 06:07:18] [valid] Ep. 22 : Up. 460000 : translation : 31.75 : stalled 5 times (last best: 31.89)
[2019-07-02 06:21:07] Ep. 22 : Up. 462000 : Sen. 2,448,332 : Cost 37.83644104 : Time 933.84s : 9527.51 words/s
[2019-07-02 06:34:55] Ep. 22 : Up. 464000 : Sen. 2,844,158 : Cost 37.88537598 : Time 827.10s : 10791.16 words/s
[2019-07-02 06:48:43] Ep. 22 : Up. 466000 : Sen. 3,238,916 : Cost 38.07013321 : Time 828.00s : 10793.08 words/s
[2019-07-02 07:02:26] Ep. 22 : Up. 468000 : Sen. 3,632,465 : Cost 37.83610153 : Time 823.71s : 10768.29 words/s
[2019-07-02 07:16:13] Ep. 22 : Up. 470000 : Sen. 4,026,704 : Cost 37.96463394 : Time 826.66s : 10763.44 words/s
[2019-07-02 07:23:00] Seen 4220483 samples
[2019-07-02 07:23:00] Starting epoch 23
[2019-07-02 07:23:00] [data] Shuffling data
[2019-07-02 07:23:02] [data] Done reading 4863734 sentences
[2019-07-02 07:23:22] [data] Done shuffling 4863734 sentences to temp files
[2019-07-02 07:30:28] Ep. 23 : Up. 472000 : Sen. 201,283 : Cost 37.30205536 : Time 855.40s : 10416.54 words/s
[2019-07-02 07:44:16] Ep. 23 : Up. 474000 : Sen. 595,674 : Cost 37.26666260 : Time 828.01s : 10758.10 words/s
[2019-07-02 07:58:03] Ep. 23 : Up. 476000 : Sen. 988,920 : Cost 37.34889221 : Time 826.55s : 10743.82 words/s
[2019-07-02 08:11:48] Ep. 23 : Up. 478000 : Sen. 1,382,130 : Cost 37.21446991 : Time 825.61s : 10742.27 words/s
[2019-07-02 08:25:38] Ep. 23 : Up. 480000 : Sen. 1,777,494 : Cost 37.57939911 : Time 829.34s : 10760.48 words/s
[2019-07-02 08:25:38] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-07-02 08:25:46] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter480000.npz
[2019-07-02 08:25:53] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-07-02 08:26:02] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-07-02 08:26:25] [valid] Ep. 23 : Up. 480000 : cross-entropy : 38.7576 : new best
[2019-07-02 08:26:29] [valid] Ep. 23 : Up. 480000 : perplexity : 4.60168 : new best
[2019-07-02 08:27:16] [valid] Ep. 23 : Up. 480000 : translation : 31.77 : stalled 6 times (last best: 31.89)
[2019-07-02 08:41:03] Ep. 23 : Up. 482000 : Sen. 2,170,272 : Cost 37.52487564 : Time 925.44s : 9591.21 words/s
[2019-07-02 08:54:53] Ep. 23 : Up. 484000 : Sen. 2,566,196 : Cost 37.74909210 : Time 829.72s : 10767.28 words/s
[2019-07-02 09:08:41] Ep. 23 : Up. 486000 : Sen. 2,960,733 : Cost 37.84354401 : Time 827.51s : 10771.84 words/s
[2019-07-02 09:22:26] Ep. 23 : Up. 488000 : Sen. 3,354,428 : Cost 37.77458572 : Time 825.96s : 10753.93 words/s
[2019-07-02 09:36:16] Ep. 23 : Up. 490000 : Sen. 3,749,932 : Cost 37.65583801 : Time 829.19s : 10760.38 words/s
[2019-07-02 09:50:04] Ep. 23 : Up. 492000 : Sen. 4,144,786 : Cost 37.82150650 : Time 828.02s : 10767.51 words/s
[2019-07-02 09:52:42] Seen 4220483 samples
[2019-07-02 09:52:42] Starting epoch 24
[2019-07-02 09:52:42] [data] Shuffling data
[2019-07-02 09:52:44] [data] Done reading 4863734 sentences
[2019-07-02 09:53:03] [data] Done shuffling 4863734 sentences to temp files
[2019-07-02 10:04:15] Ep. 24 : Up. 494000 : Sen. 319,844 : Cost 36.96918869 : Time 851.06s : 10479.74 words/s
[2019-07-02 10:18:01] Ep. 24 : Up. 496000 : Sen. 713,432 : Cost 37.00490952 : Time 826.43s : 10750.90 words/s
[2019-07-02 10:31:48] Ep. 24 : Up. 498000 : Sen. 1,107,671 : Cost 37.18425751 : Time 826.51s : 10760.03 words/s
[2019-07-02 10:45:36] Ep. 24 : Up. 500000 : Sen. 1,502,543 : Cost 37.19959259 : Time 828.63s : 10755.27 words/s
[2019-07-02 10:45:36] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-07-02 10:45:46] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter500000.npz
[2019-07-02 10:45:52] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-07-02 10:46:02] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-07-02 10:46:24] [valid] Ep. 24 : Up. 500000 : cross-entropy : 38.7672 : stalled 1 times (last best: 38.7576)
[2019-07-02 10:46:28] [valid] Ep. 24 : Up. 500000 : perplexity : 4.60344 : stalled 1 times (last best: 4.60168)
[2019-07-02 10:47:16] [valid] Ep. 24 : Up. 500000 : translation : 31.69 : stalled 7 times (last best: 31.89)
[2019-07-02 11:01:01] Ep. 24 : Up. 502000 : Sen. 1,895,437 : Cost 37.32240677 : Time 925.02s : 9574.74 words/s
[2019-07-02 11:15:09] Ep. 24 : Up. 504000 : Sen. 2,290,042 : Cost 37.58236313 : Time 848.12s : 10519.70 words/s
[2019-07-02 11:29:06] Ep. 24 : Up. 506000 : Sen. 2,684,632 : Cost 37.55353546 : Time 836.81s : 10623.43 words/s
[2019-07-02 11:42:54] Ep. 24 : Up. 508000 : Sen. 3,079,072 : Cost 37.68671799 : Time 827.39s : 10775.20 words/s
[2019-07-02 11:56:37] Ep. 24 : Up. 510000 : Sen. 3,470,668 : Cost 37.53020477 : Time 822.91s : 10734.41 words/s
[2019-07-02 12:10:23] Ep. 24 : Up. 512000 : Sen. 3,863,710 : Cost 37.79974747 : Time 826.60s : 10754.39 words/s
[2019-07-02 12:22:48] Seen 4220483 samples
[2019-07-02 12:22:48] Starting epoch 25
[2019-07-02 12:22:48] [data] Shuffling data
[2019-07-02 12:22:51] [data] Done reading 4863734 sentences
[2019-07-02 12:23:12] [data] Done shuffling 4863734 sentences to temp files
[2019-07-02 12:24:34] Ep. 25 : Up. 514000 : Sen. 38,863 : Cost 37.55158234 : Time 851.05s : 10485.37 words/s
[2019-07-02 12:38:21] Ep. 25 : Up. 516000 : Sen. 433,080 : Cost 37.00292206 : Time 826.80s : 10764.70 words/s
[2019-07-02 12:52:08] Ep. 25 : Up. 518000 : Sen. 826,748 : Cost 36.92966843 : Time 826.64s : 10752.24 words/s
[2019-07-02 13:05:56] Ep. 25 : Up. 520000 : Sen. 1,222,040 : Cost 37.10660934 : Time 828.00s : 10779.50 words/s
[2019-07-02 13:05:56] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-07-02 13:06:05] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter520000.npz
[2019-07-02 13:06:11] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-07-02 13:06:21] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-07-02 13:06:42] [valid] Ep. 25 : Up. 520000 : cross-entropy : 38.7672 : stalled 2 times (last best: 38.7576)
[2019-07-02 13:06:46] [valid] Ep. 25 : Up. 520000 : perplexity : 4.60343 : stalled 2 times (last best: 4.60168)
[2019-07-02 13:07:34] [valid] Ep. 25 : Up. 520000 : translation : 31.79 : stalled 8 times (last best: 31.89)
[2019-07-02 13:21:23] Ep. 25 : Up. 522000 : Sen. 1,617,542 : Cost 37.13257980 : Time 927.50s : 9617.46 words/s
[2019-07-02 13:35:09] Ep. 25 : Up. 524000 : Sen. 2,010,977 : Cost 37.26764679 : Time 826.08s : 10753.77 words/s
[2019-07-02 13:48:56] Ep. 25 : Up. 526000 : Sen. 2,405,104 : Cost 37.35247421 : Time 826.76s : 10753.98 words/s
[2019-07-02 14:02:43] Ep. 25 : Up. 528000 : Sen. 2,798,974 : Cost 37.43896103 : Time 827.20s : 10762.86 words/s
[2019-07-02 14:16:31] Ep. 25 : Up. 530000 : Sen. 3,195,016 : Cost 37.47003555 : Time 828.19s : 10787.84 words/s
[2019-07-02 14:30:16] Ep. 25 : Up. 532000 : Sen. 3,588,882 : Cost 37.46416855 : Time 824.98s : 10772.12 words/s
[2019-07-02 14:44:04] Ep. 25 : Up. 534000 : Sen. 3,983,724 : Cost 37.49925995 : Time 827.36s : 10760.65 words/s
[2019-07-02 14:52:22] Seen 4220483 samples
[2019-07-02 14:52:22] Starting epoch 26
[2019-07-02 14:52:22] [data] Shuffling data
[2019-07-02 14:52:24] [data] Done reading 4863734 sentences
[2019-07-02 14:52:46] [data] Done shuffling 4863734 sentences to temp files
[2019-07-02 14:58:15] Ep. 26 : Up. 536000 : Sen. 156,928 : Cost 37.11887360 : Time 851.35s : 10423.94 words/s
[2019-07-02 15:12:02] Ep. 26 : Up. 538000 : Sen. 550,556 : Cost 37.01875687 : Time 827.19s : 10758.07 words/s
[2019-07-02 15:25:51] Ep. 26 : Up. 540000 : Sen. 944,255 : Cost 36.96649551 : Time 828.23s : 10734.58 words/s
[2019-07-02 15:25:51] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-07-02 15:26:00] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter540000.npz
[2019-07-02 15:26:06] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-07-02 15:26:16] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-07-02 15:26:39] [valid] Ep. 26 : Up. 540000 : cross-entropy : 38.7539 : new best
[2019-07-02 15:26:43] [valid] Ep. 26 : Up. 540000 : perplexity : 4.60102 : new best
[2019-07-02 15:27:32] [valid] Ep. 26 : Up. 540000 : translation : 31.7 : stalled 9 times (last best: 31.89)
[2019-07-02 15:41:22] Ep. 26 : Up. 542000 : Sen. 1,338,476 : Cost 37.07365036 : Time 931.01s : 9568.18 words/s
[2019-07-02 15:55:09] Ep. 26 : Up. 544000 : Sen. 1,733,146 : Cost 37.10188675 : Time 827.67s : 10764.24 words/s
[2019-07-02 16:08:56] Ep. 26 : Up. 546000 : Sen. 2,128,986 : Cost 37.03602600 : Time 827.21s : 10789.72 words/s
[2019-07-02 16:22:44] Ep. 26 : Up. 548000 : Sen. 2,523,545 : Cost 37.21904373 : Time 827.79s : 10753.15 words/s
[2019-07-02 16:36:31] Ep. 26 : Up. 550000 : Sen. 2,917,048 : Cost 37.27686310 : Time 826.62s : 10741.51 words/s
[2019-07-02 16:50:36] Ep. 26 : Up. 552000 : Sen. 3,310,890 : Cost 37.28149414 : Time 845.36s : 10526.55 words/s
[2019-07-02 17:04:18] Ep. 26 : Up. 554000 : Sen. 3,704,544 : Cost 37.23705673 : Time 821.78s : 10791.81 words/s
[2019-07-02 17:18:05] Ep. 26 : Up. 556000 : Sen. 4,099,120 : Cost 37.54795837 : Time 826.61s : 10788.45 words/s
[2019-07-02 17:22:18] Seen 4220483 samples
[2019-07-02 17:22:18] Starting epoch 27
[2019-07-02 17:22:18] [data] Shuffling data
[2019-07-02 17:22:28] [data] Done reading 4863734 sentences
[2019-07-02 17:22:52] [data] Done shuffling 4863734 sentences to temp files
[2019-07-02 17:32:26] Ep. 27 : Up. 558000 : Sen. 274,058 : Cost 36.98702621 : Time 860.98s : 10377.81 words/s
[2019-07-02 17:46:09] Ep. 27 : Up. 560000 : Sen. 665,912 : Cost 36.80226898 : Time 823.16s : 10740.31 words/s
[2019-07-02 17:46:09] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-07-02 17:46:19] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter560000.npz
[2019-07-02 17:46:26] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-07-02 17:46:35] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-07-02 17:46:58] [valid] Ep. 27 : Up. 560000 : cross-entropy : 38.7332 : new best
[2019-07-02 17:47:02] [valid] Ep. 27 : Up. 560000 : perplexity : 4.59726 : new best
[2019-07-02 17:47:50] [valid] Ep. 27 : Up. 560000 : translation : 31.84 : stalled 10 times (last best: 31.89)
[2019-07-02 18:01:39] Ep. 27 : Up. 562000 : Sen. 1,060,005 : Cost 36.79233170 : Time 930.21s : 9560.55 words/s
[2019-07-02 18:15:26] Ep. 27 : Up. 564000 : Sen. 1,453,883 : Cost 36.79252625 : Time 826.76s : 10742.70 words/s
[2019-07-02 18:29:12] Ep. 27 : Up. 566000 : Sen. 1,848,862 : Cost 36.97568893 : Time 826.60s : 10780.99 words/s
[2019-07-02 18:43:00] Ep. 27 : Up. 568000 : Sen. 2,245,188 : Cost 36.97844315 : Time 827.75s : 10797.76 words/s
[2019-07-02 18:56:44] Ep. 27 : Up. 570000 : Sen. 2,637,774 : Cost 37.13376617 : Time 823.63s : 10770.90 words/s
[2019-07-02 19:10:30] Ep. 27 : Up. 572000 : Sen. 3,031,283 : Cost 37.21654129 : Time 826.15s : 10756.67 words/s
[2019-07-02 19:24:16] Ep. 27 : Up. 574000 : Sen. 3,424,498 : Cost 37.15987778 : Time 826.35s : 10731.25 words/s
[2019-07-02 19:38:03] Ep. 27 : Up. 576000 : Sen. 3,817,961 : Cost 37.44980240 : Time 827.06s : 10767.53 words/s
[2019-07-02 19:52:05] Ep. 27 : Up. 578000 : Sen. 4,212,264 : Cost 37.27783585 : Time 842.25s : 10537.55 words/s
[2019-07-02 19:52:24] Seen 4220483 samples
[2019-07-02 19:52:24] Starting epoch 28
[2019-07-02 19:52:24] [data] Shuffling data
[2019-07-02 19:53:54] [data] Done reading 4863734 sentences
[2019-07-02 19:56:52] [data] Done shuffling 4863734 sentences to temp files
[2019-07-02 20:11:03] Ep. 28 : Up. 580000 : Sen. 385,916 : Cost 36.44449997 : Time 1137.50s : 7815.87 words/s
[2019-07-02 20:11:03] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-07-02 20:11:34] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter580000.npz
[2019-07-02 20:11:51] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-07-02 20:12:02] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-07-02 20:13:01] [valid] Ep. 28 : Up. 580000 : cross-entropy : 38.6943 : new best
[2019-07-02 20:13:13] [valid] Ep. 28 : Up. 580000 : perplexity : 4.59022 : new best
[2019-07-02 20:14:14] [valid] Ep. 28 : Up. 580000 : translation : 31.85 : stalled 11 times (last best: 31.89)
[2019-07-02 20:28:26] Ep. 28 : Up. 582000 : Sen. 781,850 : Cost 36.73658371 : Time 1042.51s : 8588.55 words/s
[2019-07-02 20:42:09] Ep. 28 : Up. 584000 : Sen. 1,176,190 : Cost 36.70510864 : Time 823.48s : 10798.05 words/s
[2019-07-02 20:55:52] Ep. 28 : Up. 586000 : Sen. 1,568,913 : Cost 36.74422073 : Time 823.42s : 10773.70 words/s
[2019-07-02 21:09:37] Ep. 28 : Up. 588000 : Sen. 1,962,344 : Cost 36.96014786 : Time 824.45s : 10773.11 words/s
[2019-07-02 21:23:22] Ep. 28 : Up. 590000 : Sen. 2,356,762 : Cost 36.88372421 : Time 825.27s : 10764.85 words/s
[2019-07-02 21:37:09] Ep. 28 : Up. 592000 : Sen. 2,751,436 : Cost 37.21321487 : Time 826.62s : 10785.67 words/s
[2019-07-02 21:50:57] Ep. 28 : Up. 594000 : Sen. 3,147,072 : Cost 37.06071472 : Time 828.31s : 10793.15 words/s
[2019-07-02 22:04:41] Ep. 28 : Up. 596000 : Sen. 3,540,372 : Cost 37.07330704 : Time 824.29s : 10753.83 words/s
[2019-07-02 22:18:28] Ep. 28 : Up. 598000 : Sen. 3,935,280 : Cost 37.30000305 : Time 826.74s : 10792.10 words/s
[2019-07-02 22:28:27] Seen 4220483 samples
[2019-07-02 22:28:27] Starting epoch 29
[2019-07-02 22:28:27] [data] Shuffling data
[2019-07-02 22:28:45] [data] Done reading 4863734 sentences
[2019-07-02 22:29:08] [data] Done shuffling 4863734 sentences to temp files
[2019-07-02 22:32:56] Ep. 29 : Up. 600000 : Sen. 108,374 : Cost 36.98277283 : Time 868.07s : 10243.39 words/s
[2019-07-02 22:32:56] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-07-02 22:33:06] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter600000.npz
[2019-07-02 22:33:12] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-07-02 22:33:21] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-07-02 22:33:42] [valid] Ep. 29 : Up. 600000 : cross-entropy : 38.6957 : stalled 1 times (last best: 38.6943)
[2019-07-02 22:33:47] [valid] Ep. 29 : Up. 600000 : perplexity : 4.59048 : stalled 1 times (last best: 4.59022)
[2019-07-02 22:34:34] [valid] Ep. 29 : Up. 600000 : translation : 31.91 : new best
[2019-07-02 22:48:23] Ep. 29 : Up. 602000 : Sen. 503,716 : Cost 36.38640213 : Time 927.24s : 9618.43 words/s
[2019-07-02 23:02:08] Ep. 29 : Up. 604000 : Sen. 896,910 : Cost 36.67018509 : Time 824.85s : 10763.70 words/s
[2019-07-02 23:15:56] Ep. 29 : Up. 606000 : Sen. 1,293,070 : Cost 36.59295654 : Time 827.42s : 10795.02 words/s
[2019-07-02 23:29:43] Ep. 29 : Up. 608000 : Sen. 1,687,840 : Cost 36.78362274 : Time 827.10s : 10772.97 words/s
[2019-07-02 23:43:28] Ep. 29 : Up. 610000 : Sen. 2,082,500 : Cost 36.81478500 : Time 825.08s : 10798.58 words/s
[2019-07-02 23:57:14] Ep. 29 : Up. 612000 : Sen. 2,476,530 : Cost 36.76356506 : Time 826.18s : 10766.18 words/s
[2019-07-03 00:11:07] Ep. 29 : Up. 614000 : Sen. 2,870,978 : Cost 36.89665222 : Time 833.05s : 10670.00 words/s
[2019-07-03 00:24:54] Ep. 29 : Up. 616000 : Sen. 3,265,976 : Cost 37.07837677 : Time 827.18s : 10799.61 words/s
[2019-07-03 00:39:09] Ep. 29 : Up. 618000 : Sen. 3,660,800 : Cost 36.98367310 : Time 854.20s : 10422.57 words/s
[2019-07-03 00:52:57] Ep. 29 : Up. 620000 : Sen. 4,054,227 : Cost 37.18669128 : Time 828.45s : 10728.84 words/s
[2019-07-03 00:52:57] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-07-03 00:53:06] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter620000.npz
[2019-07-03 00:53:13] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-07-03 00:53:23] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-07-03 00:53:45] [valid] Ep. 29 : Up. 620000 : cross-entropy : 38.7029 : stalled 2 times (last best: 38.6943)
[2019-07-03 00:53:49] [valid] Ep. 29 : Up. 620000 : perplexity : 4.59179 : stalled 2 times (last best: 4.59022)
[2019-07-03 00:54:36] [valid] Ep. 29 : Up. 620000 : translation : 31.84 : stalled 1 times (last best: 31.91)
[2019-07-03 01:00:26] Seen 4220483 samples
[2019-07-03 01:00:26] Starting epoch 30
[2019-07-03 01:00:26] [data] Shuffling data
[2019-07-03 01:00:34] [data] Done reading 4863734 sentences
[2019-07-03 01:00:54] [data] Done shuffling 4863734 sentences to temp files
[2019-07-03 01:08:57] Ep. 30 : Up. 622000 : Sen. 228,378 : Cost 36.67123032 : Time 960.30s : 9269.12 words/s
[2019-07-03 01:22:42] Ep. 30 : Up. 624000 : Sen. 623,380 : Cost 36.21688843 : Time 824.86s : 10813.88 words/s
[2019-07-03 01:36:29] Ep. 30 : Up. 626000 : Sen. 1,017,600 : Cost 36.32817841 : Time 826.61s : 10769.00 words/s
[2019-07-03 01:50:16] Ep. 30 : Up. 628000 : Sen. 1,412,580 : Cost 36.60699844 : Time 827.72s : 10765.09 words/s
[2019-07-03 02:04:02] Ep. 30 : Up. 630000 : Sen. 1,807,322 : Cost 36.65242004 : Time 825.48s : 10784.69 words/s
[2019-07-03 02:17:48] Ep. 30 : Up. 632000 : Sen. 2,201,444 : Cost 36.65380096 : Time 825.56s : 10775.67 words/s
[2019-07-03 02:31:34] Ep. 30 : Up. 634000 : Sen. 2,595,526 : Cost 36.89225006 : Time 826.82s : 10765.50 words/s
[2019-07-03 02:45:24] Ep. 30 : Up. 636000 : Sen. 2,991,208 : Cost 36.91008759 : Time 830.02s : 10773.50 words/s
[2019-07-03 02:59:09] Ep. 30 : Up. 638000 : Sen. 3,384,706 : Cost 36.97711945 : Time 824.76s : 10761.29 words/s
[2019-07-03 03:12:57] Ep. 30 : Up. 640000 : Sen. 3,778,612 : Cost 36.75656891 : Time 827.39s : 10744.57 words/s
[2019-07-03 03:12:57] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-07-03 03:13:05] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter640000.npz
[2019-07-03 03:13:12] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-07-03 03:13:21] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-07-03 03:13:44] [valid] Ep. 30 : Up. 640000 : cross-entropy : 38.727 : stalled 3 times (last best: 38.6943)
[2019-07-03 03:13:49] [valid] Ep. 30 : Up. 640000 : perplexity : 4.59614 : stalled 3 times (last best: 4.59022)
[2019-07-03 03:14:36] [valid] Ep. 30 : Up. 640000 : translation : 31.71 : stalled 2 times (last best: 31.91)
[2019-07-03 03:28:23] Ep. 30 : Up. 642000 : Sen. 4,172,800 : Cost 36.87760544 : Time 925.98s : 9602.73 words/s
[2019-07-03 03:30:03] Seen 4220483 samples
[2019-07-03 03:30:03] Starting epoch 31
[2019-07-03 03:30:03] [data] Shuffling data
[2019-07-03 03:30:06] [data] Done reading 4863734 sentences
[2019-07-03 03:30:26] [data] Done shuffling 4863734 sentences to temp files
[2019-07-03 03:42:37] Ep. 31 : Up. 644000 : Sen. 345,444 : Cost 36.24529648 : Time 854.24s : 10384.91 words/s
[2019-07-03 03:56:23] Ep. 31 : Up. 646000 : Sen. 739,428 : Cost 36.32836151 : Time 826.37s : 10762.21 words/s
[2019-07-03 04:10:09] Ep. 31 : Up. 648000 : Sen. 1,133,618 : Cost 36.34983063 : Time 825.48s : 10772.36 words/s
[2019-07-03 04:23:55] Ep. 31 : Up. 650000 : Sen. 1,527,152 : Cost 36.59744263 : Time 826.25s : 10760.65 words/s
[2019-07-03 04:37:39] Ep. 31 : Up. 652000 : Sen. 1,920,624 : Cost 36.58098221 : Time 824.45s : 10776.12 words/s
[2019-07-03 04:51:24] Ep. 31 : Up. 654000 : Sen. 2,313,816 : Cost 36.71076965 : Time 824.60s : 10774.59 words/s
[2019-07-03 05:05:12] Ep. 31 : Up. 656000 : Sen. 2,709,781 : Cost 36.61095810 : Time 827.74s : 10783.47 words/s
[2019-07-03 05:18:56] Ep. 31 : Up. 658000 : Sen. 3,104,836 : Cost 36.62473679 : Time 824.05s : 10795.01 words/s
[2019-07-03 05:32:44] Ep. 31 : Up. 660000 : Sen. 3,499,476 : Cost 36.77616882 : Time 828.66s : 10757.12 words/s
[2019-07-03 05:32:44] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-07-03 05:32:53] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter660000.npz
[2019-07-03 05:33:00] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-07-03 05:33:09] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-07-03 05:33:31] [valid] Ep. 31 : Up. 660000 : cross-entropy : 38.7073 : stalled 4 times (last best: 38.6943)
[2019-07-03 05:33:36] [valid] Ep. 31 : Up. 660000 : perplexity : 4.59258 : stalled 4 times (last best: 4.59022)
[2019-07-03 05:34:23] [valid] Ep. 31 : Up. 660000 : translation : 31.73 : stalled 3 times (last best: 31.91)
[2019-07-03 05:48:11] Ep. 31 : Up. 662000 : Sen. 3,892,970 : Cost 36.84852600 : Time 927.10s : 9591.39 words/s
[2019-07-03 05:59:39] Seen 4220483 samples
[2019-07-03 05:59:39] Starting epoch 32
[2019-07-03 05:59:39] [data] Shuffling data
[2019-07-03 05:59:42] [data] Done reading 4863734 sentences
[2019-07-03 05:59:59] [data] Done shuffling 4863734 sentences to temp files
[2019-07-03 06:02:19] Ep. 32 : Up. 664000 : Sen. 64,000 : Cost 36.75183868 : Time 847.37s : 10431.41 words/s
[2019-07-03 06:16:04] Ep. 32 : Up. 666000 : Sen. 457,172 : Cost 36.12690735 : Time 824.86s : 10777.20 words/s
[2019-07-03 06:29:45] Ep. 32 : Up. 668000 : Sen. 850,570 : Cost 36.20457077 : Time 821.27s : 10804.60 words/s
[2019-07-03 06:43:30] Ep. 32 : Up. 670000 : Sen. 1,246,752 : Cost 36.29793549 : Time 825.20s : 10826.92 words/s
[2019-07-03 06:57:14] Ep. 32 : Up. 672000 : Sen. 1,642,098 : Cost 36.43863678 : Time 823.39s : 10839.57 words/s
[2019-07-03 07:11:01] Ep. 32 : Up. 674000 : Sen. 2,038,107 : Cost 36.51686096 : Time 827.62s : 10802.26 words/s
[2019-07-03 07:24:52] Ep. 32 : Up. 676000 : Sen. 2,433,164 : Cost 36.71263885 : Time 830.49s : 10728.48 words/s
[2019-07-03 07:38:42] Ep. 32 : Up. 678000 : Sen. 2,827,184 : Cost 36.71072388 : Time 830.20s : 10711.40 words/s
[2019-07-03 07:52:30] Ep. 32 : Up. 680000 : Sen. 3,221,272 : Cost 36.55030823 : Time 827.85s : 10731.75 words/s
[2019-07-03 07:52:30] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-07-03 07:52:40] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.iter680000.npz
[2019-07-03 07:52:46] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-07-03 07:52:57] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
[2019-07-03 07:53:20] [valid] Ep. 32 : Up. 680000 : cross-entropy : 38.747 : stalled 5 times (last best: 38.6943)
[2019-07-03 07:53:24] [valid] Ep. 32 : Up. 680000 : perplexity : 4.59977 : stalled 5 times (last best: 4.59022)
[2019-07-03 07:54:07] [valid] Ep. 32 : Up. 680000 : translation : 31.58 : stalled 4 times (last best: 31.91)
[2019-07-03 07:54:09] Training finished
[2019-07-03 07:54:13] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz.orig.npz
[2019-07-03 07:54:22] Saving model to ../experiments/100M_fasttext_bc1.1/model/model.npz
[2019-07-03 07:54:32] Saving Adam parameters to ../experiments/100M_fasttext_bc1.1/model/model.npz.optimizer.npz
