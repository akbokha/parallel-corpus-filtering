[2019-08-06 17:45:34] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-06 17:45:34] [marian] Running on hodor as process 184071 with command line:
[2019-08-06 17:45:34] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz -T . --devices 3 --train-sets ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/train.bpe.de ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/train.bpe.en --vocabs ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/train.bpe.de.json ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/dev.bpe.de ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/dev.out --valid-script-path ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/train.log --valid-log ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/valid.log
[2019-08-06 17:45:34] [config] after-batches: 0
[2019-08-06 17:45:34] [config] after-epochs: 0
[2019-08-06 17:45:34] [config] allow-unk: false
[2019-08-06 17:45:34] [config] beam-size: 12
[2019-08-06 17:45:34] [config] bert-class-symbol: "[CLS]"
[2019-08-06 17:45:34] [config] bert-mask-symbol: "[MASK]"
[2019-08-06 17:45:34] [config] bert-masking-fraction: 0.15
[2019-08-06 17:45:34] [config] bert-sep-symbol: "[SEP]"
[2019-08-06 17:45:34] [config] bert-train-type-embeddings: true
[2019-08-06 17:45:34] [config] bert-type-vocab-size: 2
[2019-08-06 17:45:34] [config] best-deep: false
[2019-08-06 17:45:34] [config] clip-gemm: 0
[2019-08-06 17:45:34] [config] clip-norm: 1
[2019-08-06 17:45:34] [config] cost-type: ce-mean
[2019-08-06 17:45:34] [config] cpu-threads: 0
[2019-08-06 17:45:34] [config] data-weighting: ""
[2019-08-06 17:45:34] [config] data-weighting-type: sentence
[2019-08-06 17:45:34] [config] dec-cell: gru
[2019-08-06 17:45:34] [config] dec-cell-base-depth: 2
[2019-08-06 17:45:34] [config] dec-cell-high-depth: 1
[2019-08-06 17:45:34] [config] dec-depth: 1
[2019-08-06 17:45:34] [config] devices:
[2019-08-06 17:45:34] [config]   - 3
[2019-08-06 17:45:34] [config] dim-emb: 512
[2019-08-06 17:45:34] [config] dim-rnn: 1024
[2019-08-06 17:45:34] [config] dim-vocabs:
[2019-08-06 17:45:34] [config]   - 50000
[2019-08-06 17:45:34] [config]   - 50000
[2019-08-06 17:45:34] [config] disp-first: 0
[2019-08-06 17:45:34] [config] disp-freq: 2000
[2019-08-06 17:45:34] [config] disp-label-counts: false
[2019-08-06 17:45:34] [config] dropout-rnn: 0.2
[2019-08-06 17:45:34] [config] dropout-src: 0.1
[2019-08-06 17:45:34] [config] dropout-trg: 0.1
[2019-08-06 17:45:34] [config] dump-config: ""
[2019-08-06 17:45:34] [config] early-stopping: 5
[2019-08-06 17:45:34] [config] embedding-fix-src: false
[2019-08-06 17:45:34] [config] embedding-fix-trg: false
[2019-08-06 17:45:34] [config] embedding-normalization: false
[2019-08-06 17:45:34] [config] embedding-vectors:
[2019-08-06 17:45:34] [config]   []
[2019-08-06 17:45:34] [config] enc-cell: gru
[2019-08-06 17:45:34] [config] enc-cell-depth: 1
[2019-08-06 17:45:34] [config] enc-depth: 1
[2019-08-06 17:45:34] [config] enc-type: bidirectional
[2019-08-06 17:45:34] [config] exponential-smoothing: 0.0001
[2019-08-06 17:45:34] [config] grad-dropping-momentum: 0
[2019-08-06 17:45:34] [config] grad-dropping-rate: 0
[2019-08-06 17:45:34] [config] grad-dropping-warmup: 100
[2019-08-06 17:45:34] [config] guided-alignment: none
[2019-08-06 17:45:34] [config] guided-alignment-cost: mse
[2019-08-06 17:45:34] [config] guided-alignment-weight: 0.1
[2019-08-06 17:45:34] [config] ignore-model-config: false
[2019-08-06 17:45:34] [config] input-types:
[2019-08-06 17:45:34] [config]   []
[2019-08-06 17:45:34] [config] interpolate-env-vars: false
[2019-08-06 17:45:34] [config] keep-best: false
[2019-08-06 17:45:34] [config] label-smoothing: 0
[2019-08-06 17:45:34] [config] layer-normalization: true
[2019-08-06 17:45:34] [config] learn-rate: 0.0001
[2019-08-06 17:45:34] [config] log: ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/train.log
[2019-08-06 17:45:34] [config] log-level: info
[2019-08-06 17:45:34] [config] log-time-zone: ""
[2019-08-06 17:45:34] [config] lr-decay: 0
[2019-08-06 17:45:34] [config] lr-decay-freq: 50000
[2019-08-06 17:45:34] [config] lr-decay-inv-sqrt:
[2019-08-06 17:45:34] [config]   - 0
[2019-08-06 17:45:34] [config] lr-decay-repeat-warmup: false
[2019-08-06 17:45:34] [config] lr-decay-reset-optimizer: false
[2019-08-06 17:45:34] [config] lr-decay-start:
[2019-08-06 17:45:34] [config]   - 10
[2019-08-06 17:45:34] [config]   - 1
[2019-08-06 17:45:34] [config] lr-decay-strategy: epoch+stalled
[2019-08-06 17:45:34] [config] lr-report: false
[2019-08-06 17:45:34] [config] lr-warmup: 0
[2019-08-06 17:45:34] [config] lr-warmup-at-reload: false
[2019-08-06 17:45:34] [config] lr-warmup-cycle: false
[2019-08-06 17:45:34] [config] lr-warmup-start-rate: 0
[2019-08-06 17:45:34] [config] max-length: 50
[2019-08-06 17:45:34] [config] max-length-crop: false
[2019-08-06 17:45:34] [config] max-length-factor: 3
[2019-08-06 17:45:34] [config] maxi-batch: 100
[2019-08-06 17:45:34] [config] maxi-batch-sort: trg
[2019-08-06 17:45:34] [config] mini-batch: 64
[2019-08-06 17:45:34] [config] mini-batch-fit: true
[2019-08-06 17:45:34] [config] mini-batch-fit-step: 10
[2019-08-06 17:45:34] [config] mini-batch-overstuff: 1
[2019-08-06 17:45:34] [config] mini-batch-track-lr: false
[2019-08-06 17:45:34] [config] mini-batch-understuff: 1
[2019-08-06 17:45:34] [config] mini-batch-warmup: 0
[2019-08-06 17:45:34] [config] mini-batch-words: 0
[2019-08-06 17:45:34] [config] mini-batch-words-ref: 0
[2019-08-06 17:45:34] [config] model: ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz
[2019-08-06 17:45:34] [config] multi-loss-type: sum
[2019-08-06 17:45:34] [config] multi-node: false
[2019-08-06 17:45:34] [config] multi-node-overlap: true
[2019-08-06 17:45:34] [config] n-best: false
[2019-08-06 17:45:34] [config] no-nccl: false
[2019-08-06 17:45:34] [config] no-reload: false
[2019-08-06 17:45:34] [config] no-restore-corpus: false
[2019-08-06 17:45:34] [config] no-shuffle: false
[2019-08-06 17:45:34] [config] normalize: 1
[2019-08-06 17:45:34] [config] num-devices: 0
[2019-08-06 17:45:34] [config] optimizer: adam
[2019-08-06 17:45:34] [config] optimizer-delay: 1
[2019-08-06 17:45:34] [config] optimizer-params:
[2019-08-06 17:45:34] [config]   []
[2019-08-06 17:45:34] [config] overwrite: false
[2019-08-06 17:45:34] [config] pretrained-model: ""
[2019-08-06 17:45:34] [config] quiet: false
[2019-08-06 17:45:34] [config] quiet-translation: true
[2019-08-06 17:45:34] [config] relative-paths: false
[2019-08-06 17:45:34] [config] right-left: false
[2019-08-06 17:45:34] [config] save-freq: 20000
[2019-08-06 17:45:34] [config] seed: 1111
[2019-08-06 17:45:34] [config] shuffle-in-ram: false
[2019-08-06 17:45:34] [config] skip: false
[2019-08-06 17:45:34] [config] sqlite: ""
[2019-08-06 17:45:34] [config] sqlite-drop: false
[2019-08-06 17:45:34] [config] sync-sgd: true
[2019-08-06 17:45:34] [config] tempdir: .
[2019-08-06 17:45:34] [config] tied-embeddings: false
[2019-08-06 17:45:34] [config] tied-embeddings-all: false
[2019-08-06 17:45:34] [config] tied-embeddings-src: false
[2019-08-06 17:45:34] [config] train-sets:
[2019-08-06 17:45:34] [config]   - ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/train.bpe.de
[2019-08-06 17:45:34] [config]   - ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/train.bpe.en
[2019-08-06 17:45:34] [config] transformer-aan-activation: swish
[2019-08-06 17:45:34] [config] transformer-aan-depth: 2
[2019-08-06 17:45:34] [config] transformer-aan-nogate: false
[2019-08-06 17:45:34] [config] transformer-decoder-autoreg: self-attention
[2019-08-06 17:45:34] [config] transformer-dim-aan: 2048
[2019-08-06 17:45:34] [config] transformer-dim-ffn: 2048
[2019-08-06 17:45:34] [config] transformer-dropout: 0
[2019-08-06 17:45:34] [config] transformer-dropout-attention: 0
[2019-08-06 17:45:34] [config] transformer-dropout-ffn: 0
[2019-08-06 17:45:34] [config] transformer-ffn-activation: swish
[2019-08-06 17:45:34] [config] transformer-ffn-depth: 2
[2019-08-06 17:45:34] [config] transformer-guided-alignment-layer: last
[2019-08-06 17:45:34] [config] transformer-heads: 8
[2019-08-06 17:45:34] [config] transformer-no-projection: false
[2019-08-06 17:45:34] [config] transformer-postprocess: dan
[2019-08-06 17:45:34] [config] transformer-postprocess-emb: d
[2019-08-06 17:45:34] [config] transformer-preprocess: ""
[2019-08-06 17:45:34] [config] transformer-tied-layers:
[2019-08-06 17:45:34] [config]   []
[2019-08-06 17:45:34] [config] transformer-train-position-embeddings: false
[2019-08-06 17:45:34] [config] type: amun
[2019-08-06 17:45:34] [config] ulr: false
[2019-08-06 17:45:34] [config] ulr-dim-emb: 0
[2019-08-06 17:45:34] [config] ulr-dropout: 0
[2019-08-06 17:45:34] [config] ulr-keys-vectors: ""
[2019-08-06 17:45:34] [config] ulr-query-vectors: ""
[2019-08-06 17:45:34] [config] ulr-softmax-temperature: 1
[2019-08-06 17:45:34] [config] ulr-trainable-transformation: false
[2019-08-06 17:45:34] [config] valid-freq: 20000
[2019-08-06 17:45:34] [config] valid-log: ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/valid.log
[2019-08-06 17:45:34] [config] valid-max-length: 1000
[2019-08-06 17:45:34] [config] valid-metrics:
[2019-08-06 17:45:34] [config]   - cross-entropy
[2019-08-06 17:45:34] [config]   - perplexity
[2019-08-06 17:45:34] [config]   - translation
[2019-08-06 17:45:34] [config] valid-mini-batch: 8
[2019-08-06 17:45:34] [config] valid-script-path: ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/score-dev.sh
[2019-08-06 17:45:34] [config] valid-sets:
[2019-08-06 17:45:34] [config]   - ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/dev.bpe.de
[2019-08-06 17:45:34] [config]   - ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/dev.bpe.en
[2019-08-06 17:45:34] [config] valid-translation-output: ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/dev.out
[2019-08-06 17:45:34] [config] vocabs:
[2019-08-06 17:45:34] [config]   - ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/train.bpe.de.json
[2019-08-06 17:45:34] [config]   - ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/train.bpe.en.json
[2019-08-06 17:45:34] [config] word-penalty: 0
[2019-08-06 17:45:34] [config] workspace: 3000
[2019-08-06 17:45:34] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-06 17:45:34] Using synchronous training
[2019-08-06 17:45:34] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/train.bpe.de.json
[2019-08-06 17:45:35] [data] Using unused word id eos for 0
[2019-08-06 17:45:35] [data] Using unused word id UNK for 1
[2019-08-06 17:45:35] [data] Setting vocabulary size for input 0 to 50000
[2019-08-06 17:45:35] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/train.bpe.en.json
[2019-08-06 17:45:35] [data] Using unused word id eos for 0
[2019-08-06 17:45:35] [data] Using unused word id UNK for 1
[2019-08-06 17:45:35] [data] Setting vocabulary size for input 1 to 50000
[2019-08-06 17:45:35] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-06 17:45:35] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-06 17:45:36] [memory] Extending reserved space to 3072 MB (device gpu3)
[2019-08-06 17:45:36] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-06 17:45:36] [comm] NCCLCommunicator constructed successfully.
[2019-08-06 17:45:36] [training] Using 1 GPUs
[2019-08-06 17:45:36] [memory] Reserving 422 MB, device gpu3
[2019-08-06 17:45:36] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-06 17:45:36] [memory] Reserving 422 MB, device gpu3
[2019-08-06 17:45:44] [batching] Done. Typical MB size is 4042 target words
[2019-08-06 17:45:44] [memory] Extending reserved space to 3072 MB (device gpu3)
[2019-08-06 17:45:44] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-06 17:45:44] [comm] NCCLCommunicator constructed successfully.
[2019-08-06 17:45:44] [training] Using 1 GPUs
[2019-08-06 17:45:44] Training started
[2019-08-06 17:45:44] [data] Shuffling data
[2019-08-06 17:45:47] [data] Done reading 5912239 sentences
[2019-08-06 17:46:20] [data] Done shuffling 5912239 sentences to temp files
[2019-08-06 17:46:22] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-06 17:46:22] [memory] Reserving 422 MB, device gpu3
[2019-08-06 17:46:22] [memory] Reserving 422 MB, device gpu3
[2019-08-06 17:46:22] [memory] Reserving 422 MB, device gpu3
[2019-08-06 17:46:22] [memory] Reserving 844 MB, device gpu3
[2019-08-06 18:02:22] Ep. 1 : Up. 2000 : Sen. 241,234 : Cost 123.89297485 : Time 1007.01s : 4812.98 words/s
[2019-08-06 18:18:05] Ep. 1 : Up. 4000 : Sen. 481,139 : Cost 96.39974213 : Time 942.57s : 5118.54 words/s
[2019-08-06 18:32:16] Ep. 1 : Up. 6000 : Sen. 721,980 : Cost 81.83121490 : Time 851.24s : 5681.02 words/s
[2019-08-06 18:41:36] Ep. 1 : Up. 8000 : Sen. 963,330 : Cost 72.66382599 : Time 560.11s : 8651.05 words/s
[2019-08-06 18:50:53] Ep. 1 : Up. 10000 : Sen. 1,202,995 : Cost 66.86669159 : Time 556.76s : 8662.58 words/s
[2019-08-06 19:00:11] Ep. 1 : Up. 12000 : Sen. 1,444,404 : Cost 62.40823364 : Time 558.80s : 8676.54 words/s
[2019-08-06 19:09:29] Ep. 1 : Up. 14000 : Sen. 1,684,542 : Cost 59.40726471 : Time 557.21s : 8675.33 words/s
[2019-08-06 19:18:47] Ep. 1 : Up. 16000 : Sen. 1,924,695 : Cost 57.22300339 : Time 558.54s : 8635.56 words/s
[2019-08-06 19:28:08] Ep. 1 : Up. 18000 : Sen. 2,165,386 : Cost 55.25482559 : Time 560.38s : 8650.00 words/s
[2019-08-06 19:37:26] Ep. 1 : Up. 20000 : Sen. 2,405,217 : Cost 53.70753098 : Time 558.24s : 8618.02 words/s
[2019-08-06 19:37:26] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz.orig.npz
[2019-08-06 19:37:35] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.iter20000.npz
[2019-08-06 19:37:42] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz
[2019-08-06 19:37:51] Saving Adam parameters to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz.optimizer.npz
[2019-08-06 19:38:14] [valid] Ep. 1 : Up. 20000 : cross-entropy : 70.4792 : new best
[2019-08-06 19:38:22] [valid] Ep. 1 : Up. 20000 : perplexity : 15.8223 : new best
[2019-08-06 19:39:42] [valid] Ep. 1 : Up. 20000 : translation : 16.52 : new best
[2019-08-06 19:49:01] Ep. 1 : Up. 22000 : Sen. 2,644,995 : Cost 52.13532257 : Time 695.02s : 6920.14 words/s
[2019-08-06 19:58:21] Ep. 1 : Up. 24000 : Sen. 2,885,759 : Cost 51.38960266 : Time 560.61s : 8632.38 words/s
[2019-08-06 20:07:39] Ep. 1 : Up. 26000 : Sen. 3,126,198 : Cost 50.25004578 : Time 557.77s : 8651.36 words/s
[2019-08-06 20:16:56] Ep. 1 : Up. 28000 : Sen. 3,365,342 : Cost 49.63852692 : Time 556.26s : 8656.17 words/s
[2019-08-06 20:26:14] Ep. 1 : Up. 30000 : Sen. 3,605,647 : Cost 48.21908569 : Time 558.77s : 8614.11 words/s
[2019-08-06 20:35:33] Ep. 1 : Up. 32000 : Sen. 3,844,958 : Cost 47.98128891 : Time 558.60s : 8624.30 words/s
[2019-08-06 20:44:55] Ep. 1 : Up. 34000 : Sen. 4,086,201 : Cost 47.38787842 : Time 561.61s : 8627.53 words/s
[2019-08-06 20:54:16] Ep. 1 : Up. 36000 : Sen. 4,327,784 : Cost 46.64602661 : Time 561.56s : 8637.42 words/s
[2019-08-06 21:03:34] Ep. 1 : Up. 38000 : Sen. 4,568,629 : Cost 46.24285889 : Time 557.47s : 8674.42 words/s
[2019-08-06 21:12:50] Ep. 1 : Up. 40000 : Sen. 4,807,771 : Cost 45.69819641 : Time 555.99s : 8645.02 words/s
[2019-08-06 21:12:50] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz.orig.npz
[2019-08-06 21:12:58] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.iter40000.npz
[2019-08-06 21:13:05] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz
[2019-08-06 21:13:14] Saving Adam parameters to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz.optimizer.npz
[2019-08-06 21:13:38] [valid] Ep. 1 : Up. 40000 : cross-entropy : 57.9475 : new best
[2019-08-06 21:13:46] [valid] Ep. 1 : Up. 40000 : perplexity : 9.68344 : new best
[2019-08-06 21:15:09] [valid] Ep. 1 : Up. 40000 : translation : 20.05 : new best
[2019-08-06 21:24:32] Ep. 1 : Up. 42000 : Sen. 5,047,512 : Cost 45.11177063 : Time 702.53s : 6856.69 words/s
[2019-08-06 21:33:54] Ep. 1 : Up. 44000 : Sen. 5,288,583 : Cost 44.78362274 : Time 561.89s : 8608.34 words/s
[2019-08-06 21:36:49] Seen 5363666 samples
[2019-08-06 21:36:49] Starting epoch 2
[2019-08-06 21:36:49] [data] Shuffling data
[2019-08-06 21:36:52] [data] Done reading 5912239 sentences
[2019-08-06 21:37:17] [data] Done shuffling 5912239 sentences to temp files
[2019-08-06 21:43:41] Ep. 2 : Up. 46000 : Sen. 164,330 : Cost 44.05061722 : Time 587.52s : 8195.55 words/s
[2019-08-06 21:53:05] Ep. 2 : Up. 48000 : Sen. 405,161 : Cost 43.36556244 : Time 563.30s : 8601.47 words/s
[2019-08-06 22:02:23] Ep. 2 : Up. 50000 : Sen. 645,137 : Cost 42.82930374 : Time 557.82s : 8606.66 words/s
[2019-08-06 22:11:43] Ep. 2 : Up. 52000 : Sen. 885,475 : Cost 42.74308395 : Time 560.50s : 8623.31 words/s
[2019-08-06 22:21:04] Ep. 2 : Up. 54000 : Sen. 1,125,904 : Cost 42.73929214 : Time 561.40s : 8619.22 words/s
[2019-08-06 22:30:23] Ep. 2 : Up. 56000 : Sen. 1,366,108 : Cost 42.34296417 : Time 558.79s : 8636.83 words/s
[2019-08-06 22:39:44] Ep. 2 : Up. 58000 : Sen. 1,606,199 : Cost 42.03874969 : Time 561.16s : 8599.66 words/s
[2019-08-06 22:49:04] Ep. 2 : Up. 60000 : Sen. 1,845,005 : Cost 41.95255661 : Time 559.74s : 8588.12 words/s
[2019-08-06 22:49:04] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz.orig.npz
[2019-08-06 22:49:13] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.iter60000.npz
[2019-08-06 22:49:20] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz
[2019-08-06 22:49:29] Saving Adam parameters to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz.optimizer.npz
[2019-08-06 22:49:53] [valid] Ep. 2 : Up. 60000 : cross-entropy : 52.7905 : new best
[2019-08-06 22:50:01] [valid] Ep. 2 : Up. 60000 : perplexity : 7.91187 : new best
[2019-08-06 22:51:23] [valid] Ep. 2 : Up. 60000 : translation : 22.37 : new best
[2019-08-06 23:00:47] Ep. 2 : Up. 62000 : Sen. 2,085,859 : Cost 41.52420807 : Time 702.38s : 6878.76 words/s
[2019-08-06 23:10:06] Ep. 2 : Up. 64000 : Sen. 2,325,983 : Cost 41.35427094 : Time 559.67s : 8618.52 words/s
[2019-08-06 23:19:24] Ep. 2 : Up. 66000 : Sen. 2,565,683 : Cost 41.17170715 : Time 557.66s : 8642.50 words/s
[2019-08-06 23:28:42] Ep. 2 : Up. 68000 : Sen. 2,806,526 : Cost 40.88094711 : Time 558.39s : 8652.37 words/s
[2019-08-06 23:38:03] Ep. 2 : Up. 70000 : Sen. 3,046,707 : Cost 40.88635635 : Time 560.65s : 8611.75 words/s
[2019-08-06 23:47:20] Ep. 2 : Up. 72000 : Sen. 3,285,425 : Cost 40.49496460 : Time 557.08s : 8626.49 words/s
[2019-08-06 23:56:44] Ep. 2 : Up. 74000 : Sen. 3,526,400 : Cost 40.59217072 : Time 564.27s : 8577.96 words/s
[2019-08-07 00:06:07] Ep. 2 : Up. 76000 : Sen. 3,765,776 : Cost 40.46995926 : Time 562.65s : 8558.62 words/s
[2019-08-07 00:15:31] Ep. 2 : Up. 78000 : Sen. 4,006,478 : Cost 40.06691360 : Time 564.37s : 8550.59 words/s
[2019-08-07 00:24:54] Ep. 2 : Up. 80000 : Sen. 4,247,505 : Cost 39.80924606 : Time 563.07s : 8586.22 words/s
[2019-08-07 00:24:54] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz.orig.npz
[2019-08-07 00:25:04] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.iter80000.npz
[2019-08-07 00:25:10] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz
[2019-08-07 00:25:20] Saving Adam parameters to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz.optimizer.npz
[2019-08-07 00:25:44] [valid] Ep. 2 : Up. 80000 : cross-entropy : 49.7626 : new best
[2019-08-07 00:25:52] [valid] Ep. 2 : Up. 80000 : perplexity : 7.02678 : new best
[2019-08-07 00:27:12] [valid] Ep. 2 : Up. 80000 : translation : 24.65 : new best
[2019-08-07 00:36:34] Ep. 2 : Up. 82000 : Sen. 4,488,413 : Cost 39.97945023 : Time 699.41s : 6929.23 words/s
[2019-08-07 00:45:55] Ep. 2 : Up. 84000 : Sen. 4,728,641 : Cost 39.53976822 : Time 561.22s : 8584.86 words/s
[2019-08-07 00:55:17] Ep. 2 : Up. 86000 : Sen. 4,968,900 : Cost 39.62169647 : Time 562.35s : 8610.58 words/s
[2019-08-07 01:04:36] Ep. 2 : Up. 88000 : Sen. 5,208,965 : Cost 39.43560028 : Time 559.10s : 8629.41 words/s
[2019-08-07 01:10:36] Seen 5363666 samples
[2019-08-07 01:10:36] Starting epoch 3
[2019-08-07 01:10:36] [data] Shuffling data
[2019-08-07 01:10:39] [data] Done reading 5912239 sentences
[2019-08-07 01:11:02] [data] Done shuffling 5912239 sentences to temp files
[2019-08-07 01:14:26] Ep. 3 : Up. 90000 : Sen. 85,760 : Cost 38.86390305 : Time 589.13s : 8184.68 words/s
[2019-08-07 01:23:47] Ep. 3 : Up. 92000 : Sen. 325,597 : Cost 38.34992981 : Time 561.69s : 8595.23 words/s
[2019-08-07 01:33:08] Ep. 3 : Up. 94000 : Sen. 566,039 : Cost 38.19693756 : Time 560.55s : 8627.55 words/s
[2019-08-07 01:42:32] Ep. 3 : Up. 96000 : Sen. 807,841 : Cost 38.05162811 : Time 564.33s : 8594.27 words/s
[2019-08-07 01:51:51] Ep. 3 : Up. 98000 : Sen. 1,047,020 : Cost 38.13124466 : Time 558.98s : 8609.91 words/s
[2019-08-07 02:01:13] Ep. 3 : Up. 100000 : Sen. 1,287,054 : Cost 37.91051102 : Time 561.58s : 8574.72 words/s
[2019-08-07 02:01:13] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz.orig.npz
[2019-08-07 02:01:22] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.iter100000.npz
[2019-08-07 02:01:28] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz
[2019-08-07 02:01:38] Saving Adam parameters to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz.optimizer.npz
[2019-08-07 02:02:02] [valid] Ep. 3 : Up. 100000 : cross-entropy : 47.7409 : new best
[2019-08-07 02:02:10] [valid] Ep. 3 : Up. 100000 : perplexity : 6.49164 : new best
[2019-08-07 02:03:29] [valid] Ep. 3 : Up. 100000 : translation : 25.91 : new best
[2019-08-07 02:12:51] Ep. 3 : Up. 102000 : Sen. 1,527,197 : Cost 37.76670074 : Time 698.45s : 6890.24 words/s
[2019-08-07 02:22:12] Ep. 3 : Up. 104000 : Sen. 1,767,355 : Cost 37.98370743 : Time 560.53s : 8629.12 words/s
[2019-08-07 02:31:33] Ep. 3 : Up. 106000 : Sen. 2,007,091 : Cost 37.93314743 : Time 561.49s : 8578.14 words/s
[2019-08-07 02:40:57] Ep. 3 : Up. 108000 : Sen. 2,248,116 : Cost 37.79447937 : Time 563.73s : 8597.73 words/s
[2019-08-07 02:50:19] Ep. 3 : Up. 110000 : Sen. 2,488,328 : Cost 37.55016708 : Time 561.59s : 8587.43 words/s
[2019-08-07 02:59:39] Ep. 3 : Up. 112000 : Sen. 2,729,068 : Cost 37.66921234 : Time 560.45s : 8618.65 words/s
[2019-08-07 03:08:56] Ep. 3 : Up. 114000 : Sen. 2,968,244 : Cost 37.60021210 : Time 556.58s : 8654.85 words/s
[2019-08-07 03:18:14] Ep. 3 : Up. 116000 : Sen. 3,207,719 : Cost 37.51820755 : Time 558.06s : 8630.13 words/s
[2019-08-07 03:27:35] Ep. 3 : Up. 118000 : Sen. 3,449,522 : Cost 37.27001572 : Time 561.06s : 8633.67 words/s
[2019-08-07 03:36:52] Ep. 3 : Up. 120000 : Sen. 3,689,120 : Cost 37.32907486 : Time 557.15s : 8639.72 words/s
[2019-08-07 03:36:52] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz.orig.npz
[2019-08-07 03:37:00] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.iter120000.npz
[2019-08-07 03:37:07] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz
[2019-08-07 03:37:16] Saving Adam parameters to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz.optimizer.npz
[2019-08-07 03:37:40] [valid] Ep. 3 : Up. 120000 : cross-entropy : 46.2296 : new best
[2019-08-07 03:37:47] [valid] Ep. 3 : Up. 120000 : perplexity : 6.11841 : new best
[2019-08-07 03:39:06] [valid] Ep. 3 : Up. 120000 : translation : 26.53 : new best
[2019-08-07 03:48:28] Ep. 3 : Up. 122000 : Sen. 3,929,420 : Cost 37.45465088 : Time 695.87s : 6945.66 words/s
[2019-08-07 03:57:49] Ep. 3 : Up. 124000 : Sen. 4,170,239 : Cost 37.15262222 : Time 561.32s : 8613.18 words/s
[2019-08-07 04:07:13] Ep. 3 : Up. 126000 : Sen. 4,410,254 : Cost 37.02562332 : Time 563.50s : 8563.67 words/s
[2019-08-07 04:16:36] Ep. 3 : Up. 128000 : Sen. 4,649,582 : Cost 37.17029190 : Time 563.41s : 8548.58 words/s
[2019-08-07 04:25:58] Ep. 3 : Up. 130000 : Sen. 4,889,813 : Cost 36.90940094 : Time 561.92s : 8581.51 words/s
[2019-08-07 04:35:21] Ep. 3 : Up. 132000 : Sen. 5,129,936 : Cost 36.95326996 : Time 563.06s : 8561.92 words/s
[2019-08-07 04:44:26] Seen 5363666 samples
[2019-08-07 04:44:26] Starting epoch 4
[2019-08-07 04:44:26] [data] Shuffling data
[2019-08-07 04:44:29] [data] Done reading 5912239 sentences
[2019-08-07 04:45:01] [data] Done shuffling 5912239 sentences to temp files
[2019-08-07 04:45:14] Ep. 4 : Up. 134000 : Sen. 5,514 : Cost 36.76746750 : Time 593.46s : 8088.37 words/s
[2019-08-07 04:54:35] Ep. 4 : Up. 136000 : Sen. 245,001 : Cost 35.98490906 : Time 560.36s : 8588.73 words/s
[2019-08-07 05:03:53] Ep. 4 : Up. 138000 : Sen. 484,063 : Cost 35.95264053 : Time 558.44s : 8608.14 words/s
[2019-08-07 05:13:16] Ep. 4 : Up. 140000 : Sen. 725,263 : Cost 35.84701157 : Time 563.19s : 8591.89 words/s
[2019-08-07 05:13:16] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz.orig.npz
[2019-08-07 05:13:25] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.iter140000.npz
[2019-08-07 05:13:32] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz
[2019-08-07 05:13:41] Saving Adam parameters to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz.optimizer.npz
[2019-08-07 05:14:05] [valid] Ep. 4 : Up. 140000 : cross-entropy : 45.1032 : new best
[2019-08-07 05:14:12] [valid] Ep. 4 : Up. 140000 : perplexity : 5.85427 : new best
[2019-08-07 05:15:30] [valid] Ep. 4 : Up. 140000 : translation : 26.86 : new best
[2019-08-07 05:24:54] Ep. 4 : Up. 142000 : Sen. 966,265 : Cost 35.70488358 : Time 697.37s : 6939.31 words/s
[2019-08-07 05:34:15] Ep. 4 : Up. 144000 : Sen. 1,206,505 : Cost 35.94136047 : Time 561.10s : 8605.29 words/s
[2019-08-07 05:43:35] Ep. 4 : Up. 146000 : Sen. 1,446,957 : Cost 35.69504166 : Time 559.69s : 8615.44 words/s
[2019-08-07 05:52:54] Ep. 4 : Up. 148000 : Sen. 1,686,215 : Cost 35.82866669 : Time 559.24s : 8605.19 words/s
[2019-08-07 06:02:17] Ep. 4 : Up. 150000 : Sen. 1,926,911 : Cost 35.60761642 : Time 563.09s : 8577.07 words/s
[2019-08-07 06:11:39] Ep. 4 : Up. 152000 : Sen. 2,167,557 : Cost 35.83008575 : Time 561.83s : 8607.81 words/s
[2019-08-07 06:20:59] Ep. 4 : Up. 154000 : Sen. 2,407,208 : Cost 35.89401627 : Time 560.44s : 8614.27 words/s
[2019-08-07 06:30:20] Ep. 4 : Up. 156000 : Sen. 2,647,356 : Cost 35.66453171 : Time 560.94s : 8603.66 words/s
[2019-08-07 06:39:37] Ep. 4 : Up. 158000 : Sen. 2,887,125 : Cost 35.45458603 : Time 557.12s : 8638.62 words/s
[2019-08-07 06:48:58] Ep. 4 : Up. 160000 : Sen. 3,127,390 : Cost 35.71413803 : Time 561.08s : 8612.48 words/s
[2019-08-07 06:48:58] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz.orig.npz
[2019-08-07 06:49:10] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.iter160000.npz
[2019-08-07 06:49:20] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz
[2019-08-07 06:49:29] Saving Adam parameters to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz.optimizer.npz
[2019-08-07 06:49:58] [valid] Ep. 4 : Up. 160000 : cross-entropy : 44.3587 : new best
[2019-08-07 06:50:05] [valid] Ep. 4 : Up. 160000 : perplexity : 5.68595 : new best
[2019-08-07 06:51:24] [valid] Ep. 4 : Up. 160000 : translation : 26.98 : new best
[2019-08-07 07:00:48] Ep. 4 : Up. 162000 : Sen. 3,367,178 : Cost 35.72202682 : Time 710.03s : 6781.98 words/s
[2019-08-07 07:10:11] Ep. 4 : Up. 164000 : Sen. 3,607,069 : Cost 35.56498718 : Time 563.11s : 8570.17 words/s
[2019-08-07 07:19:34] Ep. 4 : Up. 166000 : Sen. 3,848,157 : Cost 35.63043594 : Time 562.25s : 8610.07 words/s
[2019-08-07 07:28:53] Ep. 4 : Up. 168000 : Sen. 4,088,611 : Cost 35.45542908 : Time 559.34s : 8626.18 words/s
[2019-08-07 07:38:14] Ep. 4 : Up. 170000 : Sen. 4,328,292 : Cost 35.42822647 : Time 561.46s : 8585.21 words/s
[2019-08-07 07:47:36] Ep. 4 : Up. 172000 : Sen. 4,569,522 : Cost 35.46388245 : Time 561.13s : 8631.82 words/s
[2019-08-07 07:56:54] Ep. 4 : Up. 174000 : Sen. 4,809,449 : Cost 35.42120743 : Time 558.85s : 8625.55 words/s
[2019-08-07 08:06:17] Ep. 4 : Up. 176000 : Sen. 5,050,038 : Cost 35.39156723 : Time 562.16s : 8606.18 words/s
[2019-08-07 08:15:36] Ep. 4 : Up. 178000 : Sen. 5,290,101 : Cost 35.33530426 : Time 559.78s : 8614.91 words/s
[2019-08-07 08:18:30] Seen 5363666 samples
[2019-08-07 08:18:30] Starting epoch 5
[2019-08-07 08:18:30] [data] Shuffling data
[2019-08-07 08:18:33] [data] Done reading 5912239 sentences
[2019-08-07 08:18:56] [data] Done shuffling 5912239 sentences to temp files
[2019-08-07 08:25:28] Ep. 5 : Up. 180000 : Sen. 165,722 : Cost 34.54715347 : Time 591.20s : 8124.81 words/s
[2019-08-07 08:25:28] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz.orig.npz
[2019-08-07 08:25:37] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.iter180000.npz
[2019-08-07 08:25:43] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz
[2019-08-07 08:25:53] Saving Adam parameters to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz.optimizer.npz
[2019-08-07 08:26:16] [valid] Ep. 5 : Up. 180000 : cross-entropy : 43.6226 : new best
[2019-08-07 08:26:24] [valid] Ep. 5 : Up. 180000 : perplexity : 5.52431 : new best
[2019-08-07 08:27:42] [valid] Ep. 5 : Up. 180000 : translation : 27.44 : new best
[2019-08-07 08:37:03] Ep. 5 : Up. 182000 : Sen. 405,711 : Cost 34.43494797 : Time 695.61s : 6943.59 words/s
[2019-08-07 08:46:24] Ep. 5 : Up. 184000 : Sen. 646,052 : Cost 34.45278168 : Time 560.88s : 8609.39 words/s
[2019-08-07 08:55:43] Ep. 5 : Up. 186000 : Sen. 885,501 : Cost 34.49010468 : Time 558.59s : 8625.78 words/s
[2019-08-07 09:05:01] Ep. 5 : Up. 188000 : Sen. 1,125,188 : Cost 34.30547333 : Time 558.29s : 8623.30 words/s
[2019-08-07 09:14:24] Ep. 5 : Up. 190000 : Sen. 1,365,876 : Cost 34.45392227 : Time 562.95s : 8596.63 words/s
[2019-08-07 09:23:46] Ep. 5 : Up. 192000 : Sen. 1,606,028 : Cost 34.41365814 : Time 561.80s : 8589.99 words/s
[2019-08-07 09:33:08] Ep. 5 : Up. 194000 : Sen. 1,847,688 : Cost 34.38695145 : Time 562.11s : 8609.88 words/s
[2019-08-07 09:42:31] Ep. 5 : Up. 196000 : Sen. 2,087,622 : Cost 34.47045898 : Time 563.31s : 8572.10 words/s
[2019-08-07 09:51:49] Ep. 5 : Up. 198000 : Sen. 2,327,652 : Cost 34.43531418 : Time 558.09s : 8646.50 words/s
[2019-08-07 10:01:12] Ep. 5 : Up. 200000 : Sen. 2,567,764 : Cost 34.61868286 : Time 562.49s : 8590.26 words/s
[2019-08-07 10:01:12] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz.orig.npz
[2019-08-07 10:01:21] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.iter200000.npz
[2019-08-07 10:01:28] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz
[2019-08-07 10:01:38] Saving Adam parameters to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz.optimizer.npz
[2019-08-07 10:02:03] [valid] Ep. 5 : Up. 200000 : cross-entropy : 43.1767 : new best
[2019-08-07 10:02:11] [valid] Ep. 5 : Up. 200000 : perplexity : 5.42863 : new best
[2019-08-07 10:03:28] [valid] Ep. 5 : Up. 200000 : translation : 27.69 : new best
[2019-08-07 10:12:50] Ep. 5 : Up. 202000 : Sen. 2,807,895 : Cost 34.41482162 : Time 698.36s : 6895.97 words/s
[2019-08-07 10:22:13] Ep. 5 : Up. 204000 : Sen. 3,047,500 : Cost 34.34823227 : Time 562.71s : 8582.58 words/s
[2019-08-07 10:31:33] Ep. 5 : Up. 206000 : Sen. 3,287,197 : Cost 34.40391159 : Time 559.76s : 8606.87 words/s
[2019-08-07 10:40:54] Ep. 5 : Up. 208000 : Sen. 3,527,956 : Cost 34.36053085 : Time 561.01s : 8614.62 words/s
[2019-08-07 10:50:14] Ep. 5 : Up. 210000 : Sen. 3,768,388 : Cost 34.31145096 : Time 560.82s : 8602.42 words/s
[2019-08-07 10:59:32] Ep. 5 : Up. 212000 : Sen. 4,008,919 : Cost 34.17687225 : Time 557.91s : 8631.17 words/s
[2019-08-07 11:08:52] Ep. 5 : Up. 214000 : Sen. 4,249,240 : Cost 34.32027435 : Time 559.97s : 8625.13 words/s
[2019-08-07 11:18:17] Ep. 5 : Up. 216000 : Sen. 4,489,949 : Cost 34.31209946 : Time 564.52s : 8562.13 words/s
[2019-08-07 11:27:38] Ep. 5 : Up. 218000 : Sen. 4,729,870 : Cost 34.21858597 : Time 561.06s : 8590.17 words/s
[2019-08-07 11:36:58] Ep. 5 : Up. 220000 : Sen. 4,969,839 : Cost 34.30716705 : Time 560.19s : 8609.02 words/s
[2019-08-07 11:36:58] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz.orig.npz
[2019-08-07 11:37:11] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.iter220000.npz
[2019-08-07 11:37:19] Saving model to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz
[2019-08-07 11:37:28] Saving Adam parameters to ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz.optimizer.npz
[2019-08-07 11:37:52] [valid] Ep. 5 : Up. 220000 : cross-entropy : 42.6516 : new best
[2019-08-07 11:38:00] [valid] Ep. 5 : Up. 220000 : perplexity : 5.3181 : new best
[2019-08-07 11:39:18] [valid] Ep. 5 : Up. 220000 : translation : 27.85 : new best
[2019-08-07 11:48:42] Ep. 5 : Up. 222000 : Sen. 5,209,522 : Cost 34.43022156 : Time 704.01s : 6849.59 words/s
[2019-08-07 11:54:42] Seen 5363666 samples
[2019-08-07 11:54:42] Starting epoch 6
[2019-08-07 11:54:42] [data] Shuffling data
[2019-08-07 11:54:45] [data] Done reading 5912239 sentences
[2019-08-07 11:55:12] [data] Done shuffling 5912239 sentences to temp files
[2019-08-07 11:58:34] Ep. 6 : Up. 224000 : Sen. 85,960 : Cost 33.90007019 : Time 591.85s : 8155.06 words/s
[2019-08-07 15:47:47] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 15:47:47] [marian] Running on hodor as process 51297 with command line:
[2019-08-07 15:47:47] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz -T . --devices 3 --train-sets ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/train.bpe.de ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/train.bpe.en --vocabs ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/train.bpe.de.json ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/dev.bpe.de ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/dev.out --valid-script-path ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/train.log --valid-log ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/valid.log
[2019-08-07 15:47:48] [config] after-batches: 0
[2019-08-07 15:47:48] [config] after-epochs: 0
[2019-08-07 15:47:48] [config] allow-unk: false
[2019-08-07 15:47:48] [config] beam-size: 12
[2019-08-07 15:47:48] [config] bert-class-symbol: "[CLS]"
[2019-08-07 15:47:48] [config] bert-mask-symbol: "[MASK]"
[2019-08-07 15:47:48] [config] bert-masking-fraction: 0.15
[2019-08-07 15:47:48] [config] bert-sep-symbol: "[SEP]"
[2019-08-07 15:47:48] [config] bert-train-type-embeddings: true
[2019-08-07 15:47:48] [config] bert-type-vocab-size: 2
[2019-08-07 15:47:48] [config] best-deep: false
[2019-08-07 15:47:48] [config] clip-gemm: 0
[2019-08-07 15:47:48] [config] clip-norm: 1
[2019-08-07 15:47:48] [config] cost-type: ce-mean
[2019-08-07 15:47:48] [config] cpu-threads: 0
[2019-08-07 15:47:48] [config] data-weighting: ""
[2019-08-07 15:47:48] [config] data-weighting-type: sentence
[2019-08-07 15:47:48] [config] dec-cell: gru
[2019-08-07 15:47:48] [config] dec-cell-base-depth: 2
[2019-08-07 15:47:48] [config] dec-cell-high-depth: 1
[2019-08-07 15:47:48] [config] dec-depth: 1
[2019-08-07 15:47:48] [config] devices:
[2019-08-07 15:47:48] [config]   - 3
[2019-08-07 15:47:48] [config] dim-emb: 512
[2019-08-07 15:47:48] [config] dim-rnn: 1024
[2019-08-07 15:47:48] [config] dim-vocabs:
[2019-08-07 15:47:48] [config]   - 50000
[2019-08-07 15:47:48] [config]   - 50000
[2019-08-07 15:47:48] [config] disp-first: 0
[2019-08-07 15:47:48] [config] disp-freq: 2000
[2019-08-07 15:47:48] [config] disp-label-counts: false
[2019-08-07 15:47:48] [config] dropout-rnn: 0.2
[2019-08-07 15:47:48] [config] dropout-src: 0.1
[2019-08-07 15:47:48] [config] dropout-trg: 0.1
[2019-08-07 15:47:48] [config] dump-config: ""
[2019-08-07 15:47:48] [config] early-stopping: 5
[2019-08-07 15:47:48] [config] embedding-fix-src: false
[2019-08-07 15:47:48] [config] embedding-fix-trg: false
[2019-08-07 15:47:48] [config] embedding-normalization: false
[2019-08-07 15:47:48] [config] embedding-vectors:
[2019-08-07 15:47:48] [config]   []
[2019-08-07 15:47:48] [config] enc-cell: gru
[2019-08-07 15:47:48] [config] enc-cell-depth: 1
[2019-08-07 15:47:48] [config] enc-depth: 1
[2019-08-07 15:47:48] [config] enc-type: bidirectional
[2019-08-07 15:47:48] [config] exponential-smoothing: 0.0001
[2019-08-07 15:47:48] [config] grad-dropping-momentum: 0
[2019-08-07 15:47:48] [config] grad-dropping-rate: 0
[2019-08-07 15:47:48] [config] grad-dropping-warmup: 100
[2019-08-07 15:47:48] [config] guided-alignment: none
[2019-08-07 15:47:48] [config] guided-alignment-cost: mse
[2019-08-07 15:47:48] [config] guided-alignment-weight: 0.1
[2019-08-07 15:47:48] [config] ignore-model-config: false
[2019-08-07 15:47:48] [config] input-types:
[2019-08-07 15:47:48] [config]   []
[2019-08-07 15:47:48] [config] interpolate-env-vars: false
[2019-08-07 15:47:48] [config] keep-best: false
[2019-08-07 15:47:48] [config] label-smoothing: 0
[2019-08-07 15:47:48] [config] layer-normalization: true
[2019-08-07 15:47:48] [config] learn-rate: 0.0001
[2019-08-07 15:47:48] [config] log: ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/train.log
[2019-08-07 15:47:48] [config] log-level: info
[2019-08-07 15:47:48] [config] log-time-zone: ""
[2019-08-07 15:47:48] [config] lr-decay: 0
[2019-08-07 15:47:48] [config] lr-decay-freq: 50000
[2019-08-07 15:47:48] [config] lr-decay-inv-sqrt:
[2019-08-07 15:47:48] [config]   - 0
[2019-08-07 15:47:48] [config] lr-decay-repeat-warmup: false
[2019-08-07 15:47:48] [config] lr-decay-reset-optimizer: false
[2019-08-07 15:47:48] [config] lr-decay-start:
[2019-08-07 15:47:48] [config]   - 10
[2019-08-07 15:47:48] [config]   - 1
[2019-08-07 15:47:48] [config] lr-decay-strategy: epoch+stalled
[2019-08-07 15:47:48] [config] lr-report: false
[2019-08-07 15:47:48] [config] lr-warmup: 0
[2019-08-07 15:47:48] [config] lr-warmup-at-reload: false
[2019-08-07 15:47:48] [config] lr-warmup-cycle: false
[2019-08-07 15:47:48] [config] lr-warmup-start-rate: 0
[2019-08-07 15:47:48] [config] max-length: 50
[2019-08-07 15:47:48] [config] max-length-crop: false
[2019-08-07 15:47:48] [config] max-length-factor: 3
[2019-08-07 15:47:48] [config] maxi-batch: 100
[2019-08-07 15:47:48] [config] maxi-batch-sort: trg
[2019-08-07 15:47:48] [config] mini-batch: 64
[2019-08-07 15:47:48] [config] mini-batch-fit: true
[2019-08-07 15:47:48] [config] mini-batch-fit-step: 10
[2019-08-07 15:47:48] [config] mini-batch-overstuff: 1
[2019-08-07 15:47:48] [config] mini-batch-track-lr: false
[2019-08-07 15:47:48] [config] mini-batch-understuff: 1
[2019-08-07 15:47:48] [config] mini-batch-warmup: 0
[2019-08-07 15:47:48] [config] mini-batch-words: 0
[2019-08-07 15:47:48] [config] mini-batch-words-ref: 0
[2019-08-07 15:47:48] [config] model: ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz
[2019-08-07 15:47:48] [config] multi-loss-type: sum
[2019-08-07 15:47:48] [config] multi-node: false
[2019-08-07 15:47:48] [config] multi-node-overlap: true
[2019-08-07 15:47:48] [config] n-best: false
[2019-08-07 15:47:48] [config] no-nccl: false
[2019-08-07 15:47:48] [config] no-reload: false
[2019-08-07 15:47:48] [config] no-restore-corpus: false
[2019-08-07 15:47:48] [config] no-shuffle: false
[2019-08-07 15:47:48] [config] normalize: 1
[2019-08-07 15:47:48] [config] num-devices: 0
[2019-08-07 15:47:48] [config] optimizer: adam
[2019-08-07 15:47:48] [config] optimizer-delay: 1
[2019-08-07 15:47:48] [config] optimizer-params:
[2019-08-07 15:47:48] [config]   []
[2019-08-07 15:47:48] [config] overwrite: false
[2019-08-07 15:47:48] [config] pretrained-model: ""
[2019-08-07 15:47:48] [config] quiet: false
[2019-08-07 15:47:48] [config] quiet-translation: true
[2019-08-07 15:47:48] [config] relative-paths: false
[2019-08-07 15:47:48] [config] right-left: false
[2019-08-07 15:47:48] [config] save-freq: 20000
[2019-08-07 15:47:48] [config] seed: 1111
[2019-08-07 15:47:48] [config] shuffle-in-ram: false
[2019-08-07 15:47:48] [config] skip: false
[2019-08-07 15:47:48] [config] sqlite: ""
[2019-08-07 15:47:48] [config] sqlite-drop: false
[2019-08-07 15:47:48] [config] sync-sgd: true
[2019-08-07 15:47:48] [config] tempdir: .
[2019-08-07 15:47:48] [config] tied-embeddings: false
[2019-08-07 15:47:48] [config] tied-embeddings-all: false
[2019-08-07 15:47:48] [config] tied-embeddings-src: false
[2019-08-07 15:47:48] [config] train-sets:
[2019-08-07 15:47:48] [config]   - ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/train.bpe.de
[2019-08-07 15:47:48] [config]   - ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/train.bpe.en
[2019-08-07 15:47:48] [config] transformer-aan-activation: swish
[2019-08-07 15:47:48] [config] transformer-aan-depth: 2
[2019-08-07 15:47:48] [config] transformer-aan-nogate: false
[2019-08-07 15:47:48] [config] transformer-decoder-autoreg: self-attention
[2019-08-07 15:47:48] [config] transformer-dim-aan: 2048
[2019-08-07 15:47:48] [config] transformer-dim-ffn: 2048
[2019-08-07 15:47:48] [config] transformer-dropout: 0
[2019-08-07 15:47:48] [config] transformer-dropout-attention: 0
[2019-08-07 15:47:48] [config] transformer-dropout-ffn: 0
[2019-08-07 15:47:48] [config] transformer-ffn-activation: swish
[2019-08-07 15:47:48] [config] transformer-ffn-depth: 2
[2019-08-07 15:47:48] [config] transformer-guided-alignment-layer: last
[2019-08-07 15:47:48] [config] transformer-heads: 8
[2019-08-07 15:47:48] [config] transformer-no-projection: false
[2019-08-07 15:47:48] [config] transformer-postprocess: dan
[2019-08-07 15:47:48] [config] transformer-postprocess-emb: d
[2019-08-07 15:47:48] [config] transformer-preprocess: ""
[2019-08-07 15:47:48] [config] transformer-tied-layers:
[2019-08-07 15:47:48] [config]   []
[2019-08-07 15:47:48] [config] transformer-train-position-embeddings: false
[2019-08-07 15:47:48] [config] type: amun
[2019-08-07 15:47:48] [config] ulr: false
[2019-08-07 15:47:48] [config] ulr-dim-emb: 0
[2019-08-07 15:47:48] [config] ulr-dropout: 0
[2019-08-07 15:47:48] [config] ulr-keys-vectors: ""
[2019-08-07 15:47:48] [config] ulr-query-vectors: ""
[2019-08-07 15:47:48] [config] ulr-softmax-temperature: 1
[2019-08-07 15:47:48] [config] ulr-trainable-transformation: false
[2019-08-07 15:47:48] [config] valid-freq: 20000
[2019-08-07 15:47:48] [config] valid-log: ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/valid.log
[2019-08-07 15:47:48] [config] valid-max-length: 1000
[2019-08-07 15:47:48] [config] valid-metrics:
[2019-08-07 15:47:48] [config]   - cross-entropy
[2019-08-07 15:47:48] [config]   - perplexity
[2019-08-07 15:47:48] [config]   - translation
[2019-08-07 15:47:48] [config] valid-mini-batch: 8
[2019-08-07 15:47:48] [config] valid-script-path: ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/score-dev.sh
[2019-08-07 15:47:48] [config] valid-sets:
[2019-08-07 15:47:48] [config]   - ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/dev.bpe.de
[2019-08-07 15:47:48] [config]   - ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/dev.bpe.en
[2019-08-07 15:47:48] [config] valid-translation-output: ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/dev.out
[2019-08-07 15:47:48] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 15:47:48] [config] vocabs:
[2019-08-07 15:47:48] [config]   - ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/train.bpe.de.json
[2019-08-07 15:47:48] [config]   - ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/train.bpe.en.json
[2019-08-07 15:47:48] [config] word-penalty: 0
[2019-08-07 15:47:48] [config] workspace: 3000
[2019-08-07 15:47:48] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 15:47:48] Using synchronous training
[2019-08-07 15:47:48] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/train.bpe.de.json
[2019-08-07 15:47:48] [data] Using unused word id eos for 0
[2019-08-07 15:47:48] [data] Using unused word id UNK for 1
[2019-08-07 15:47:48] [data] Setting vocabulary size for input 0 to 50000
[2019-08-07 15:47:48] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/data/train.bpe.en.json
[2019-08-07 15:47:48] [data] Using unused word id eos for 0
[2019-08-07 15:47:48] [data] Using unused word id UNK for 1
[2019-08-07 15:47:48] [data] Setting vocabulary size for input 1 to 50000
[2019-08-07 15:47:48] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-07 15:47:48] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-07 15:47:49] [memory] Extending reserved space to 3072 MB (device gpu3)
[2019-08-07 15:47:49] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 15:47:49] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 15:47:49] [training] Using 1 GPUs
[2019-08-07 15:47:49] [memory] Reserving 422 MB, device gpu3
[2019-08-07 15:47:49] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-07 15:47:50] [memory] Reserving 422 MB, device gpu3
[2019-08-07 15:47:54] [batching] Done. Typical MB size is 4042 target words
[2019-08-07 15:47:55] [memory] Extending reserved space to 3072 MB (device gpu3)
[2019-08-07 15:47:55] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 15:47:55] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 15:47:55] [training] Using 1 GPUs
[2019-08-07 15:47:55] Loading model from ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz.orig.npz
[2019-08-07 15:48:06] Loading Adam parameters from ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz.optimizer.npz
[2019-08-07 15:48:23] [memory] Reserving 844 MB, device gpu3
[2019-08-07 15:48:24] [training] Model reloaded from ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz
[2019-08-07 15:48:24] [data] Restoring the corpus state to epoch 5, batch 220000
[2019-08-07 15:48:24] [data] Shuffling data
[2019-08-07 15:48:27] [data] Done reading 5912239 sentences
[2019-08-07 15:48:53] [data] Done shuffling 5912239 sentences to temp files
[2019-08-07 15:50:54] Training started
[2019-08-07 15:50:54] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-07 15:50:54] [memory] Reserving 422 MB, device gpu3
[2019-08-07 15:50:54] [memory] Reserving 422 MB, device gpu3
[2019-08-07 15:50:54] Loading model from ../experiments/100M_fasttext_bic1.1_+_bic1.1_no_lm/model/model.npz
[2019-08-07 15:51:01] [memory] Reserving 422 MB, device cpu0
[2019-08-07 15:51:01] [memory] Reserving 422 MB, device gpu3
