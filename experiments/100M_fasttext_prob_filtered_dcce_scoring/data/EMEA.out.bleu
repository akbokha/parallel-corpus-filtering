MT evaluation scorer began on 2019 Jul 3 at 09:17:49
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/EMEA.de.sgm -r ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/EMEA.en.sgm -t ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/EMEA.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 3000 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 1.01749881387625 (109374/107493), penalty (log): 0
NIST score = 7.2529  BLEU score = 0.2979 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  5.3102   1.5111   0.3268   0.0801   0.0246   0.0100   0.0046   0.0027   0.0025  "Edinburgh"

 BLEU:  0.6015   0.3564   0.2330   0.1578   0.1099   0.0774   0.0557   0.0414   0.0317  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  5.3102   6.8213   7.1481   7.2282   7.2529   7.2629   7.2675   7.2702   7.2727  "Edinburgh"

 BLEU:  0.6015   0.4630   0.3682   0.2979   0.2441   0.2015   0.1677   0.1408   0.1193  "Edinburgh"
MT evaluation scorer ended on 2019 Jul 3 at 09:18:18
