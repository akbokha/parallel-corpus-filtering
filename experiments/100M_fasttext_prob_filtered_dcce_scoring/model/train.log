[2019-06-30 11:53:49] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-06-30 11:53:49] [marian] Running on dagr as process 151156 with command line:
[2019-06-30 11:53:49] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz -T . --devices 2 3 --train-sets ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/train.bpe.de ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/train.bpe.en --vocabs ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/train.bpe.de.json ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/dev.bpe.de ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/dev.out --valid-script-path ../experiments/100M_fasttext_prob_filtered_dcce_scoring/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/train.log --valid-log ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/valid.log
[2019-06-30 11:53:49] [config] after-batches: 0
[2019-06-30 11:53:49] [config] after-epochs: 0
[2019-06-30 11:53:49] [config] allow-unk: false
[2019-06-30 11:53:49] [config] beam-size: 12
[2019-06-30 11:53:49] [config] bert-class-symbol: "[CLS]"
[2019-06-30 11:53:49] [config] bert-mask-symbol: "[MASK]"
[2019-06-30 11:53:49] [config] bert-masking-fraction: 0.15
[2019-06-30 11:53:49] [config] bert-sep-symbol: "[SEP]"
[2019-06-30 11:53:49] [config] bert-train-type-embeddings: true
[2019-06-30 11:53:49] [config] bert-type-vocab-size: 2
[2019-06-30 11:53:49] [config] best-deep: false
[2019-06-30 11:53:49] [config] clip-gemm: 0
[2019-06-30 11:53:49] [config] clip-norm: 1
[2019-06-30 11:53:49] [config] cost-type: ce-mean
[2019-06-30 11:53:49] [config] cpu-threads: 0
[2019-06-30 11:53:49] [config] data-weighting: ""
[2019-06-30 11:53:49] [config] data-weighting-type: sentence
[2019-06-30 11:53:49] [config] dec-cell: gru
[2019-06-30 11:53:49] [config] dec-cell-base-depth: 2
[2019-06-30 11:53:49] [config] dec-cell-high-depth: 1
[2019-06-30 11:53:49] [config] dec-depth: 1
[2019-06-30 11:53:49] [config] devices:
[2019-06-30 11:53:49] [config]   - 2
[2019-06-30 11:53:49] [config]   - 3
[2019-06-30 11:53:49] [config] dim-emb: 512
[2019-06-30 11:53:49] [config] dim-rnn: 1024
[2019-06-30 11:53:49] [config] dim-vocabs:
[2019-06-30 11:53:49] [config]   - 50000
[2019-06-30 11:53:49] [config]   - 50000
[2019-06-30 11:53:49] [config] disp-first: 0
[2019-06-30 11:53:49] [config] disp-freq: 2000
[2019-06-30 11:53:49] [config] disp-label-counts: false
[2019-06-30 11:53:49] [config] dropout-rnn: 0.2
[2019-06-30 11:53:49] [config] dropout-src: 0.1
[2019-06-30 11:53:49] [config] dropout-trg: 0.1
[2019-06-30 11:53:49] [config] dump-config: ""
[2019-06-30 11:53:49] [config] early-stopping: 5
[2019-06-30 11:53:49] [config] embedding-fix-src: false
[2019-06-30 11:53:49] [config] embedding-fix-trg: false
[2019-06-30 11:53:49] [config] embedding-normalization: false
[2019-06-30 11:53:49] [config] embedding-vectors:
[2019-06-30 11:53:49] [config]   []
[2019-06-30 11:53:49] [config] enc-cell: gru
[2019-06-30 11:53:49] [config] enc-cell-depth: 1
[2019-06-30 11:53:49] [config] enc-depth: 1
[2019-06-30 11:53:49] [config] enc-type: bidirectional
[2019-06-30 11:53:49] [config] exponential-smoothing: 0.0001
[2019-06-30 11:53:49] [config] grad-dropping-momentum: 0
[2019-06-30 11:53:49] [config] grad-dropping-rate: 0
[2019-06-30 11:53:49] [config] grad-dropping-warmup: 100
[2019-06-30 11:53:49] [config] guided-alignment: none
[2019-06-30 11:53:49] [config] guided-alignment-cost: mse
[2019-06-30 11:53:49] [config] guided-alignment-weight: 0.1
[2019-06-30 11:53:49] [config] ignore-model-config: false
[2019-06-30 11:53:49] [config] input-types:
[2019-06-30 11:53:49] [config]   []
[2019-06-30 11:53:49] [config] interpolate-env-vars: false
[2019-06-30 11:53:49] [config] keep-best: false
[2019-06-30 11:53:49] [config] label-smoothing: 0
[2019-06-30 11:53:49] [config] layer-normalization: true
[2019-06-30 11:53:49] [config] learn-rate: 0.0001
[2019-06-30 11:53:49] [config] log: ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/train.log
[2019-06-30 11:53:49] [config] log-level: info
[2019-06-30 11:53:49] [config] log-time-zone: ""
[2019-06-30 11:53:49] [config] lr-decay: 0
[2019-06-30 11:53:49] [config] lr-decay-freq: 50000
[2019-06-30 11:53:49] [config] lr-decay-inv-sqrt:
[2019-06-30 11:53:49] [config]   - 0
[2019-06-30 11:53:49] [config] lr-decay-repeat-warmup: false
[2019-06-30 11:53:49] [config] lr-decay-reset-optimizer: false
[2019-06-30 11:53:49] [config] lr-decay-start:
[2019-06-30 11:53:49] [config]   - 10
[2019-06-30 11:53:49] [config]   - 1
[2019-06-30 11:53:49] [config] lr-decay-strategy: epoch+stalled
[2019-06-30 11:53:49] [config] lr-report: false
[2019-06-30 11:53:49] [config] lr-warmup: 0
[2019-06-30 11:53:49] [config] lr-warmup-at-reload: false
[2019-06-30 11:53:49] [config] lr-warmup-cycle: false
[2019-06-30 11:53:49] [config] lr-warmup-start-rate: 0
[2019-06-30 11:53:49] [config] max-length: 50
[2019-06-30 11:53:49] [config] max-length-crop: false
[2019-06-30 11:53:49] [config] max-length-factor: 3
[2019-06-30 11:53:49] [config] maxi-batch: 100
[2019-06-30 11:53:49] [config] maxi-batch-sort: trg
[2019-06-30 11:53:49] [config] mini-batch: 64
[2019-06-30 11:53:49] [config] mini-batch-fit: true
[2019-06-30 11:53:49] [config] mini-batch-fit-step: 10
[2019-06-30 11:53:49] [config] mini-batch-overstuff: 1
[2019-06-30 11:53:49] [config] mini-batch-track-lr: false
[2019-06-30 11:53:49] [config] mini-batch-understuff: 1
[2019-06-30 11:53:49] [config] mini-batch-warmup: 0
[2019-06-30 11:53:49] [config] mini-batch-words: 0
[2019-06-30 11:53:49] [config] mini-batch-words-ref: 0
[2019-06-30 11:53:49] [config] model: ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-06-30 11:53:49] [config] multi-loss-type: sum
[2019-06-30 11:53:49] [config] multi-node: false
[2019-06-30 11:53:49] [config] multi-node-overlap: true
[2019-06-30 11:53:49] [config] n-best: false
[2019-06-30 11:53:49] [config] no-nccl: false
[2019-06-30 11:53:49] [config] no-reload: false
[2019-06-30 11:53:49] [config] no-restore-corpus: false
[2019-06-30 11:53:49] [config] no-shuffle: false
[2019-06-30 11:53:49] [config] normalize: 1
[2019-06-30 11:53:49] [config] num-devices: 0
[2019-06-30 11:53:49] [config] optimizer: adam
[2019-06-30 11:53:49] [config] optimizer-delay: 1
[2019-06-30 11:53:49] [config] optimizer-params:
[2019-06-30 11:53:49] [config]   []
[2019-06-30 11:53:49] [config] overwrite: false
[2019-06-30 11:53:49] [config] pretrained-model: ""
[2019-06-30 11:53:49] [config] quiet: false
[2019-06-30 11:53:49] [config] quiet-translation: true
[2019-06-30 11:53:49] [config] relative-paths: false
[2019-06-30 11:53:49] [config] right-left: false
[2019-06-30 11:53:49] [config] save-freq: 20000
[2019-06-30 11:53:49] [config] seed: 1111
[2019-06-30 11:53:49] [config] shuffle-in-ram: false
[2019-06-30 11:53:49] [config] skip: false
[2019-06-30 11:53:49] [config] sqlite: ""
[2019-06-30 11:53:49] [config] sqlite-drop: false
[2019-06-30 11:53:49] [config] sync-sgd: true
[2019-06-30 11:53:49] [config] tempdir: .
[2019-06-30 11:53:49] [config] tied-embeddings: false
[2019-06-30 11:53:49] [config] tied-embeddings-all: false
[2019-06-30 11:53:49] [config] tied-embeddings-src: false
[2019-06-30 11:53:49] [config] train-sets:
[2019-06-30 11:53:49] [config]   - ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/train.bpe.de
[2019-06-30 11:53:49] [config]   - ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/train.bpe.en
[2019-06-30 11:53:49] [config] transformer-aan-activation: swish
[2019-06-30 11:53:49] [config] transformer-aan-depth: 2
[2019-06-30 11:53:49] [config] transformer-aan-nogate: false
[2019-06-30 11:53:49] [config] transformer-decoder-autoreg: self-attention
[2019-06-30 11:53:49] [config] transformer-dim-aan: 2048
[2019-06-30 11:53:49] [config] transformer-dim-ffn: 2048
[2019-06-30 11:53:49] [config] transformer-dropout: 0
[2019-06-30 11:53:49] [config] transformer-dropout-attention: 0
[2019-06-30 11:53:49] [config] transformer-dropout-ffn: 0
[2019-06-30 11:53:49] [config] transformer-ffn-activation: swish
[2019-06-30 11:53:49] [config] transformer-ffn-depth: 2
[2019-06-30 11:53:49] [config] transformer-guided-alignment-layer: last
[2019-06-30 11:53:49] [config] transformer-heads: 8
[2019-06-30 11:53:49] [config] transformer-no-projection: false
[2019-06-30 11:53:49] [config] transformer-postprocess: dan
[2019-06-30 11:53:49] [config] transformer-postprocess-emb: d
[2019-06-30 11:53:49] [config] transformer-preprocess: ""
[2019-06-30 11:53:49] [config] transformer-tied-layers:
[2019-06-30 11:53:49] [config]   []
[2019-06-30 11:53:49] [config] transformer-train-position-embeddings: false
[2019-06-30 11:53:49] [config] type: amun
[2019-06-30 11:53:49] [config] ulr: false
[2019-06-30 11:53:49] [config] ulr-dim-emb: 0
[2019-06-30 11:53:49] [config] ulr-dropout: 0
[2019-06-30 11:53:49] [config] ulr-keys-vectors: ""
[2019-06-30 11:53:49] [config] ulr-query-vectors: ""
[2019-06-30 11:53:49] [config] ulr-softmax-temperature: 1
[2019-06-30 11:53:49] [config] ulr-trainable-transformation: false
[2019-06-30 11:53:49] [config] valid-freq: 20000
[2019-06-30 11:53:49] [config] valid-log: ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/valid.log
[2019-06-30 11:53:49] [config] valid-max-length: 1000
[2019-06-30 11:53:49] [config] valid-metrics:
[2019-06-30 11:53:49] [config]   - cross-entropy
[2019-06-30 11:53:49] [config]   - perplexity
[2019-06-30 11:53:49] [config]   - translation
[2019-06-30 11:53:49] [config] valid-mini-batch: 8
[2019-06-30 11:53:49] [config] valid-script-path: ../experiments/100M_fasttext_prob_filtered_dcce_scoring/score-dev.sh
[2019-06-30 11:53:49] [config] valid-sets:
[2019-06-30 11:53:49] [config]   - ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/dev.bpe.de
[2019-06-30 11:53:49] [config]   - ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/dev.bpe.en
[2019-06-30 11:53:49] [config] valid-translation-output: ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/dev.out
[2019-06-30 11:53:49] [config] vocabs:
[2019-06-30 11:53:49] [config]   - ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/train.bpe.de.json
[2019-06-30 11:53:49] [config]   - ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/train.bpe.en.json
[2019-06-30 11:53:49] [config] word-penalty: 0
[2019-06-30 11:53:49] [config] workspace: 3000
[2019-06-30 11:53:49] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-06-30 11:53:49] Using synchronous training
[2019-06-30 11:53:49] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/train.bpe.de.json
[2019-06-30 11:53:49] [data] Using unused word id eos for 0
[2019-06-30 11:53:49] [data] Using unused word id UNK for 1
[2019-06-30 11:53:49] [data] Setting vocabulary size for input 0 to 50000
[2019-06-30 11:53:49] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/train.bpe.en.json
[2019-06-30 11:53:50] [data] Using unused word id eos for 0
[2019-06-30 11:53:50] [data] Using unused word id UNK for 1
[2019-06-30 11:53:50] [data] Setting vocabulary size for input 1 to 50000
[2019-06-30 11:53:50] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-06-30 11:53:50] [batching] Collecting statistics for batch fitting with step size 10
[2019-06-30 11:53:51] [memory] Extending reserved space to 3072 MB (device gpu2)
[2019-06-30 11:53:52] [memory] Extending reserved space to 3072 MB (device gpu3)
[2019-06-30 11:53:52] [comm] Using NCCL 2.4.2 for GPU communication
[2019-06-30 11:53:52] [comm] NCCLCommunicator constructed successfully.
[2019-06-30 11:53:52] [training] Using 2 GPUs
[2019-06-30 11:53:52] [memory] Reserving 422 MB, device gpu2
[2019-06-30 11:53:52] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-06-30 11:53:52] [memory] Reserving 422 MB, device gpu2
[2019-06-30 11:53:57] [batching] Done. Typical MB size is 8084 target words
[2019-06-30 11:53:57] [memory] Extending reserved space to 3072 MB (device gpu2)
[2019-06-30 11:53:57] [memory] Extending reserved space to 3072 MB (device gpu3)
[2019-06-30 11:53:57] [comm] Using NCCL 2.4.2 for GPU communication
[2019-06-30 11:53:57] [comm] NCCLCommunicator constructed successfully.
[2019-06-30 11:53:57] [training] Using 2 GPUs
[2019-06-30 11:53:57] Training started
[2019-06-30 11:53:57] [data] Shuffling data
[2019-06-30 11:54:00] [data] Done reading 5861713 sentences
[2019-06-30 11:54:26] [data] Done shuffling 5861713 sentences to temp files
[2019-06-30 11:54:28] [training] Batches are processed as 1 process(es) x 2 devices/process
[2019-06-30 11:54:28] [memory] Reserving 422 MB, device gpu2
[2019-06-30 11:54:28] [memory] Reserving 422 MB, device gpu3
[2019-06-30 11:54:28] [memory] Reserving 422 MB, device gpu2
[2019-06-30 11:54:28] [memory] Reserving 422 MB, device gpu3
[2019-06-30 11:54:28] [memory] Reserving 211 MB, device gpu2
[2019-06-30 11:54:28] [memory] Reserving 211 MB, device gpu3
[2019-06-30 11:54:28] [memory] Reserving 422 MB, device gpu2
[2019-06-30 11:54:28] [memory] Reserving 422 MB, device gpu3
[2019-06-30 12:04:38] Ep. 1 : Up. 2000 : Sen. 401,377 : Cost 110.89480591 : Time 648.70s : 11677.05 words/s
[2019-06-30 12:14:54] Ep. 1 : Up. 4000 : Sen. 803,466 : Cost 86.10842133 : Time 615.80s : 12294.42 words/s
[2019-06-30 12:25:11] Ep. 1 : Up. 6000 : Sen. 1,205,298 : Cost 74.46306610 : Time 616.87s : 12267.57 words/s
[2019-06-30 12:35:27] Ep. 1 : Up. 8000 : Sen. 1,605,399 : Cost 67.48564148 : Time 615.88s : 12256.94 words/s
[2019-06-30 12:45:45] Ep. 1 : Up. 10000 : Sen. 2,007,984 : Cost 62.52058411 : Time 617.67s : 12266.08 words/s
[2019-06-30 12:56:00] Ep. 1 : Up. 12000 : Sen. 2,408,172 : Cost 59.53058243 : Time 615.14s : 12268.11 words/s
[2019-06-30 13:06:17] Ep. 1 : Up. 14000 : Sen. 2,809,600 : Cost 56.89557266 : Time 617.35s : 12266.44 words/s
[2019-06-30 13:16:33] Ep. 1 : Up. 16000 : Sen. 3,210,300 : Cost 55.31628799 : Time 615.64s : 12282.06 words/s
[2019-06-30 13:26:50] Ep. 1 : Up. 18000 : Sen. 3,612,894 : Cost 53.31273651 : Time 616.92s : 12285.03 words/s
[2019-06-30 13:37:06] Ep. 1 : Up. 20000 : Sen. 4,014,888 : Cost 52.25610352 : Time 616.72s : 12270.45 words/s
[2019-06-30 13:37:06] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-06-30 13:37:15] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter20000.npz
[2019-06-30 13:37:22] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-06-30 13:37:32] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-06-30 13:37:53] [valid] Ep. 1 : Up. 20000 : cross-entropy : 73.5671 : new best
[2019-06-30 13:37:57] [valid] Ep. 1 : Up. 20000 : perplexity : 18.1178 : new best
[2019-06-30 13:38:37] [valid] Ep. 1 : Up. 20000 : translation : 22.43 : new best
[2019-06-30 13:48:56] Ep. 1 : Up. 22000 : Sen. 4,416,000 : Cost 51.10086823 : Time 709.33s : 10643.29 words/s
[2019-06-30 13:59:12] Ep. 1 : Up. 24000 : Sen. 4,818,618 : Cost 50.37833786 : Time 616.79s : 12318.06 words/s
[2019-06-30 14:07:16] Seen 5133815 samples
[2019-06-30 14:07:16] Starting epoch 2
[2019-06-30 14:07:16] [data] Shuffling data
[2019-06-30 14:07:19] [data] Done reading 5861713 sentences
[2019-06-30 14:07:41] [data] Done shuffling 5861713 sentences to temp files
[2019-06-30 14:09:57] Ep. 2 : Up. 26000 : Sen. 87,224 : Cost 49.27786255 : Time 644.42s : 11774.69 words/s
[2019-06-30 14:20:13] Ep. 2 : Up. 28000 : Sen. 487,717 : Cost 48.02833939 : Time 616.13s : 12253.86 words/s
[2019-06-30 14:30:30] Ep. 2 : Up. 30000 : Sen. 890,608 : Cost 47.61198807 : Time 617.14s : 12311.41 words/s
[2019-06-30 14:40:48] Ep. 2 : Up. 32000 : Sen. 1,292,236 : Cost 46.95442581 : Time 618.23s : 12239.06 words/s
[2019-06-30 14:51:04] Ep. 2 : Up. 34000 : Sen. 1,692,934 : Cost 46.49763489 : Time 615.78s : 12244.80 words/s
[2019-06-30 15:01:19] Ep. 2 : Up. 36000 : Sen. 2,093,480 : Cost 46.00549698 : Time 615.25s : 12268.43 words/s
[2019-06-30 15:11:37] Ep. 2 : Up. 38000 : Sen. 2,496,566 : Cost 45.47602081 : Time 617.30s : 12283.69 words/s
[2019-06-30 15:21:56] Ep. 2 : Up. 40000 : Sen. 2,899,404 : Cost 45.42062378 : Time 619.52s : 12279.19 words/s
[2019-06-30 15:21:56] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-06-30 15:22:06] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter40000.npz
[2019-06-30 15:22:13] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-06-30 15:22:22] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-06-30 15:22:44] [valid] Ep. 2 : Up. 40000 : cross-entropy : 62.2109 : new best
[2019-06-30 15:22:48] [valid] Ep. 2 : Up. 40000 : perplexity : 11.5851 : new best
[2019-06-30 15:23:28] [valid] Ep. 2 : Up. 40000 : translation : 26.21 : new best
[2019-06-30 15:33:45] Ep. 2 : Up. 42000 : Sen. 3,298,438 : Cost 45.02634430 : Time 708.43s : 10629.58 words/s
[2019-06-30 15:44:02] Ep. 2 : Up. 44000 : Sen. 3,702,611 : Cost 44.47104645 : Time 616.97s : 12334.91 words/s
[2019-06-30 15:54:15] Ep. 2 : Up. 46000 : Sen. 4,102,244 : Cost 44.07776260 : Time 613.19s : 12260.80 words/s
[2019-06-30 16:04:28] Ep. 2 : Up. 48000 : Sen. 4,501,894 : Cost 43.88592911 : Time 613.03s : 12285.76 words/s
[2019-06-30 16:14:45] Ep. 2 : Up. 50000 : Sen. 4,904,997 : Cost 43.78898621 : Time 617.14s : 12324.98 words/s
[2019-06-30 16:20:36] Seen 5133815 samples
[2019-06-30 16:20:36] Starting epoch 3
[2019-06-30 16:20:36] [data] Shuffling data
[2019-06-30 16:20:39] [data] Done reading 5861713 sentences
[2019-06-30 16:21:02] [data] Done shuffling 5861713 sentences to temp files
[2019-06-30 16:25:28] Ep. 3 : Up. 52000 : Sen. 173,804 : Cost 42.99592209 : Time 643.25s : 11787.66 words/s
[2019-06-30 16:35:42] Ep. 3 : Up. 54000 : Sen. 573,346 : Cost 42.49415588 : Time 614.01s : 12274.03 words/s
[2019-06-30 16:45:57] Ep. 3 : Up. 56000 : Sen. 972,800 : Cost 42.50961685 : Time 614.81s : 12261.11 words/s
[2019-06-30 16:56:13] Ep. 3 : Up. 58000 : Sen. 1,375,429 : Cost 42.03166580 : Time 616.00s : 12304.15 words/s
[2019-06-30 17:06:28] Ep. 3 : Up. 60000 : Sen. 1,777,526 : Cost 42.04278946 : Time 615.02s : 12316.89 words/s
[2019-06-30 17:06:28] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-06-30 17:06:38] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter60000.npz
[2019-06-30 17:06:44] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-06-30 17:06:54] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-06-30 17:07:16] [valid] Ep. 3 : Up. 60000 : cross-entropy : 57.6656 : new best
[2019-06-30 17:07:19] [valid] Ep. 3 : Up. 60000 : perplexity : 9.68649 : new best
[2019-06-30 17:08:01] [valid] Ep. 3 : Up. 60000 : translation : 27.67 : new best
[2019-06-30 17:18:17] Ep. 3 : Up. 62000 : Sen. 2,177,968 : Cost 41.77663422 : Time 708.96s : 10643.40 words/s
[2019-06-30 17:28:34] Ep. 3 : Up. 64000 : Sen. 2,580,817 : Cost 41.54007721 : Time 616.74s : 12320.37 words/s
[2019-06-30 17:38:47] Ep. 3 : Up. 66000 : Sen. 2,979,972 : Cost 41.41793442 : Time 613.04s : 12260.34 words/s
[2019-06-30 17:49:01] Ep. 3 : Up. 68000 : Sen. 3,382,150 : Cost 41.28633881 : Time 613.92s : 12326.65 words/s
[2019-06-30 17:59:14] Ep. 3 : Up. 70000 : Sen. 3,781,572 : Cost 41.22577286 : Time 613.72s : 12268.33 words/s
[2019-06-30 18:09:31] Ep. 3 : Up. 72000 : Sen. 4,183,381 : Cost 41.19098282 : Time 616.52s : 12304.63 words/s
[2019-06-30 18:19:47] Ep. 3 : Up. 74000 : Sen. 4,584,532 : Cost 40.84427643 : Time 616.49s : 12255.51 words/s
[2019-06-30 18:30:02] Ep. 3 : Up. 76000 : Sen. 4,986,026 : Cost 40.72272491 : Time 614.67s : 12298.35 words/s
[2019-06-30 18:33:49] Seen 5133815 samples
[2019-06-30 18:33:49] Starting epoch 4
[2019-06-30 18:33:49] [data] Shuffling data
[2019-06-30 18:33:52] [data] Done reading 5861713 sentences
[2019-06-30 18:34:14] [data] Done shuffling 5861713 sentences to temp files
[2019-06-30 18:40:49] Ep. 4 : Up. 78000 : Sen. 252,912 : Cost 40.20656967 : Time 646.52s : 11704.75 words/s
[2019-06-30 18:51:04] Ep. 4 : Up. 80000 : Sen. 653,364 : Cost 39.80571365 : Time 615.33s : 12251.67 words/s
[2019-06-30 18:51:04] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-06-30 18:51:13] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter80000.npz
[2019-06-30 18:51:20] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-06-30 18:51:30] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-06-30 18:51:51] [valid] Ep. 4 : Up. 80000 : cross-entropy : 55.0108 : new best
[2019-06-30 18:51:55] [valid] Ep. 4 : Up. 80000 : perplexity : 8.725 : new best
[2019-06-30 18:52:35] [valid] Ep. 4 : Up. 80000 : translation : 28.22 : new best
[2019-06-30 19:02:53] Ep. 4 : Up. 82000 : Sen. 1,056,156 : Cost 39.59683228 : Time 709.19s : 10693.15 words/s
[2019-06-30 19:13:09] Ep. 4 : Up. 84000 : Sen. 1,457,699 : Cost 39.62813568 : Time 616.05s : 12265.32 words/s
[2019-06-30 19:23:24] Ep. 4 : Up. 86000 : Sen. 1,858,220 : Cost 39.73579025 : Time 614.79s : 12288.41 words/s
[2019-06-30 19:33:41] Ep. 4 : Up. 88000 : Sen. 2,260,488 : Cost 39.48088074 : Time 616.55s : 12277.14 words/s
[2019-06-30 19:43:56] Ep. 4 : Up. 90000 : Sen. 2,661,206 : Cost 39.65281296 : Time 615.89s : 12295.31 words/s
[2019-06-30 19:54:14] Ep. 4 : Up. 92000 : Sen. 3,065,600 : Cost 39.27366257 : Time 617.14s : 12330.96 words/s
[2019-06-30 20:04:29] Ep. 4 : Up. 94000 : Sen. 3,467,332 : Cost 39.32188416 : Time 615.25s : 12307.99 words/s
[2019-06-30 20:14:43] Ep. 4 : Up. 96000 : Sen. 3,867,938 : Cost 39.33408737 : Time 613.82s : 12306.65 words/s
[2019-06-30 20:24:58] Ep. 4 : Up. 98000 : Sen. 4,268,218 : Cost 39.25390244 : Time 614.98s : 12255.95 words/s
[2019-06-30 20:35:13] Ep. 4 : Up. 100000 : Sen. 4,669,272 : Cost 39.10514832 : Time 615.72s : 12299.90 words/s
[2019-06-30 20:35:13] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-06-30 20:35:23] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter100000.npz
[2019-06-30 20:35:32] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-06-30 20:35:43] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-06-30 20:36:04] [valid] Ep. 4 : Up. 100000 : cross-entropy : 53.3295 : new best
[2019-06-30 20:36:08] [valid] Ep. 4 : Up. 100000 : perplexity : 8.16608 : new best
[2019-06-30 20:36:48] [valid] Ep. 4 : Up. 100000 : translation : 28.8 : new best
[2019-06-30 20:47:06] Ep. 4 : Up. 102000 : Sen. 5,069,988 : Cost 39.09322739 : Time 712.88s : 10603.33 words/s
[2019-06-30 20:48:44] Seen 5133815 samples
[2019-06-30 20:48:44] Starting epoch 5
[2019-06-30 20:48:44] [data] Shuffling data
[2019-06-30 20:48:46] [data] Done reading 5861713 sentences
[2019-06-30 20:49:07] [data] Done shuffling 5861713 sentences to temp files
[2019-06-30 20:57:50] Ep. 5 : Up. 104000 : Sen. 339,200 : Cost 38.00387955 : Time 644.10s : 11747.53 words/s
[2019-06-30 21:08:06] Ep. 5 : Up. 106000 : Sen. 740,394 : Cost 38.18092728 : Time 616.04s : 12302.34 words/s
[2019-06-30 21:18:22] Ep. 5 : Up. 108000 : Sen. 1,141,050 : Cost 38.12101746 : Time 615.51s : 12274.68 words/s
[2019-06-30 21:28:39] Ep. 5 : Up. 110000 : Sen. 1,542,916 : Cost 38.08671570 : Time 617.38s : 12259.93 words/s
[2019-06-30 21:38:56] Ep. 5 : Up. 112000 : Sen. 1,944,622 : Cost 38.21873474 : Time 616.37s : 12291.50 words/s
[2019-06-30 21:49:11] Ep. 5 : Up. 114000 : Sen. 2,346,700 : Cost 38.05975723 : Time 615.06s : 12299.05 words/s
[2019-06-30 21:59:24] Ep. 5 : Up. 116000 : Sen. 2,746,224 : Cost 37.98851776 : Time 613.60s : 12266.73 words/s
[2019-06-30 22:09:40] Ep. 5 : Up. 118000 : Sen. 3,148,020 : Cost 37.90493011 : Time 615.97s : 12269.47 words/s
[2019-06-30 22:19:57] Ep. 5 : Up. 120000 : Sen. 3,548,315 : Cost 38.22256470 : Time 617.12s : 12260.85 words/s
[2019-06-30 22:19:57] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-06-30 22:20:07] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter120000.npz
[2019-06-30 22:20:13] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-06-30 22:20:23] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-06-30 22:20:44] [valid] Ep. 5 : Up. 120000 : cross-entropy : 52.1525 : new best
[2019-06-30 22:20:48] [valid] Ep. 5 : Up. 120000 : perplexity : 7.79623 : new best
[2019-06-30 22:21:28] [valid] Ep. 5 : Up. 120000 : translation : 29.33 : new best
[2019-06-30 22:31:47] Ep. 5 : Up. 122000 : Sen. 3,950,976 : Cost 37.94971085 : Time 709.65s : 10679.65 words/s
[2019-06-30 22:42:03] Ep. 5 : Up. 124000 : Sen. 4,353,335 : Cost 37.95983124 : Time 616.06s : 12313.54 words/s
[2019-06-30 22:52:20] Ep. 5 : Up. 126000 : Sen. 4,755,512 : Cost 37.97235107 : Time 617.06s : 12293.52 words/s
[2019-06-30 23:02:03] Seen 5133815 samples
[2019-06-30 23:02:03] Starting epoch 6
[2019-06-30 23:02:03] [data] Shuffling data
[2019-06-30 23:02:06] [data] Done reading 5861713 sentences
[2019-06-30 23:02:27] [data] Done shuffling 5861713 sentences to temp files
[2019-06-30 23:03:03] Ep. 6 : Up. 128000 : Sen. 20,530 : Cost 38.01050949 : Time 642.74s : 11711.36 words/s
[2019-06-30 23:13:21] Ep. 6 : Up. 130000 : Sen. 424,638 : Cost 37.07746124 : Time 618.40s : 12318.83 words/s
[2019-06-30 23:23:38] Ep. 6 : Up. 132000 : Sen. 825,330 : Cost 36.96479797 : Time 616.53s : 12269.46 words/s
[2019-06-30 23:33:52] Ep. 6 : Up. 134000 : Sen. 1,225,974 : Cost 36.95536423 : Time 613.89s : 12272.17 words/s
[2019-06-30 23:44:09] Ep. 6 : Up. 136000 : Sen. 1,626,771 : Cost 37.27412033 : Time 617.57s : 12263.88 words/s
[2019-06-30 23:54:26] Ep. 6 : Up. 138000 : Sen. 2,026,564 : Cost 37.04039001 : Time 616.57s : 12209.13 words/s
[2019-07-01 00:04:40] Ep. 6 : Up. 140000 : Sen. 2,425,912 : Cost 37.09160614 : Time 613.90s : 12242.63 words/s
[2019-07-01 00:04:40] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-01 00:04:49] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter140000.npz
[2019-07-01 00:04:56] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-01 00:05:05] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-07-01 00:05:27] [valid] Ep. 6 : Up. 140000 : cross-entropy : 51.3264 : new best
[2019-07-01 00:05:31] [valid] Ep. 6 : Up. 140000 : perplexity : 7.54672 : new best
[2019-07-01 00:06:13] [valid] Ep. 6 : Up. 140000 : translation : 29.6 : new best
[2019-07-01 00:16:32] Ep. 6 : Up. 142000 : Sen. 2,827,171 : Cost 37.04114532 : Time 711.94s : 10619.76 words/s
[2019-07-01 00:26:48] Ep. 6 : Up. 144000 : Sen. 3,228,992 : Cost 36.90496445 : Time 616.39s : 12263.38 words/s
[2019-07-01 00:37:02] Ep. 6 : Up. 146000 : Sen. 3,628,800 : Cost 37.00320053 : Time 614.27s : 12256.42 words/s
[2019-07-01 00:47:21] Ep. 6 : Up. 148000 : Sen. 4,032,589 : Cost 37.08313370 : Time 618.55s : 12291.33 words/s
[2019-07-01 00:57:37] Ep. 6 : Up. 150000 : Sen. 4,434,258 : Cost 36.87990189 : Time 616.06s : 12311.95 words/s
[2019-07-01 01:07:52] Ep. 6 : Up. 152000 : Sen. 4,835,082 : Cost 37.01164246 : Time 615.23s : 12284.25 words/s
[2019-07-01 01:15:32] Seen 5133815 samples
[2019-07-01 01:15:32] Starting epoch 7
[2019-07-01 01:15:32] [data] Shuffling data
[2019-07-01 01:15:35] [data] Done reading 5861713 sentences
[2019-07-01 01:15:56] [data] Done shuffling 5861713 sentences to temp files
[2019-07-01 01:18:37] Ep. 7 : Up. 154000 : Sen. 102,964 : Cost 36.80985260 : Time 644.38s : 11756.88 words/s
[2019-07-01 01:28:53] Ep. 7 : Up. 156000 : Sen. 505,600 : Cost 36.30989075 : Time 616.44s : 12313.53 words/s
[2019-07-01 01:39:08] Ep. 7 : Up. 158000 : Sen. 906,369 : Cost 36.16516495 : Time 614.73s : 12290.16 words/s
[2019-07-01 01:49:25] Ep. 7 : Up. 160000 : Sen. 1,309,583 : Cost 36.20203781 : Time 617.34s : 12324.34 words/s
[2019-07-01 01:49:25] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-01 01:49:35] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter160000.npz
[2019-07-01 01:49:41] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-01 01:49:51] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-07-01 01:50:12] [valid] Ep. 7 : Up. 160000 : cross-entropy : 50.7281 : new best
[2019-07-01 01:50:16] [valid] Ep. 7 : Up. 160000 : perplexity : 7.371 : new best
[2019-07-01 01:50:57] [valid] Ep. 7 : Up. 160000 : translation : 29.77 : new best
[2019-07-01 02:01:13] Ep. 7 : Up. 162000 : Sen. 1,708,218 : Cost 36.19963455 : Time 708.00s : 10600.06 words/s
[2019-07-01 02:11:29] Ep. 7 : Up. 164000 : Sen. 2,108,232 : Cost 36.43463898 : Time 615.79s : 12264.11 words/s
[2019-07-01 02:21:45] Ep. 7 : Up. 166000 : Sen. 2,510,652 : Cost 36.31980515 : Time 616.18s : 12306.16 words/s
[2019-07-01 02:32:03] Ep. 7 : Up. 168000 : Sen. 2,912,386 : Cost 36.30204773 : Time 618.01s : 12271.51 words/s
[2019-07-01 02:42:18] Ep. 7 : Up. 170000 : Sen. 3,312,131 : Cost 36.38288116 : Time 614.84s : 12249.05 words/s
[2019-07-01 02:52:36] Ep. 7 : Up. 172000 : Sen. 3,715,170 : Cost 36.25473785 : Time 617.96s : 12299.51 words/s
[2019-07-01 03:02:54] Ep. 7 : Up. 174000 : Sen. 4,116,042 : Cost 36.36461639 : Time 617.72s : 12243.37 words/s
[2019-07-01 03:13:10] Ep. 7 : Up. 176000 : Sen. 4,517,188 : Cost 36.15262604 : Time 616.11s : 12244.50 words/s
[2019-07-01 03:23:27] Ep. 7 : Up. 178000 : Sen. 4,920,208 : Cost 36.26588440 : Time 617.72s : 12271.52 words/s
[2019-07-01 03:28:54] Seen 5133815 samples
[2019-07-01 03:28:54] Starting epoch 8
[2019-07-01 03:28:54] [data] Shuffling data
[2019-07-01 03:28:57] [data] Done reading 5861713 sentences
[2019-07-01 03:29:19] [data] Done shuffling 5861713 sentences to temp files
[2019-07-01 03:34:11] Ep. 8 : Up. 180000 : Sen. 189,101 : Cost 35.81523895 : Time 643.64s : 11788.43 words/s
[2019-07-01 03:34:11] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-01 03:34:20] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter180000.npz
[2019-07-01 03:34:27] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-01 03:34:36] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-07-01 03:34:58] [valid] Ep. 8 : Up. 180000 : cross-entropy : 50.2458 : new best
[2019-07-01 03:35:02] [valid] Ep. 8 : Up. 180000 : perplexity : 7.23231 : new best
[2019-07-01 03:35:43] [valid] Ep. 8 : Up. 180000 : translation : 30.02 : new best
[2019-07-01 03:46:01] Ep. 8 : Up. 182000 : Sen. 590,768 : Cost 35.41189194 : Time 709.80s : 10648.66 words/s
[2019-07-01 03:56:19] Ep. 8 : Up. 184000 : Sen. 993,506 : Cost 35.50577927 : Time 617.66s : 12286.37 words/s
[2019-07-01 04:06:36] Ep. 8 : Up. 186000 : Sen. 1,394,586 : Cost 35.67044830 : Time 617.07s : 12264.96 words/s
[2019-07-01 04:16:52] Ep. 8 : Up. 188000 : Sen. 1,794,298 : Cost 35.68891907 : Time 615.96s : 12239.15 words/s
[2019-07-01 04:27:08] Ep. 8 : Up. 190000 : Sen. 2,196,594 : Cost 35.60480499 : Time 616.84s : 12271.34 words/s
[2019-07-01 04:37:26] Ep. 8 : Up. 192000 : Sen. 2,598,244 : Cost 35.68192291 : Time 617.10s : 12253.78 words/s
[2019-07-01 04:47:41] Ep. 8 : Up. 194000 : Sen. 2,996,990 : Cost 35.81637573 : Time 615.94s : 12205.79 words/s
[2019-07-01 04:57:58] Ep. 8 : Up. 196000 : Sen. 3,398,400 : Cost 35.60528946 : Time 616.28s : 12265.00 words/s
[2019-07-01 05:08:11] Ep. 8 : Up. 198000 : Sen. 3,798,176 : Cost 35.59765625 : Time 613.64s : 12277.49 words/s
[2019-07-01 05:18:28] Ep. 8 : Up. 200000 : Sen. 4,200,064 : Cost 35.65619659 : Time 617.01s : 12270.84 words/s
[2019-07-01 05:18:28] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-01 05:18:38] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter200000.npz
[2019-07-01 05:18:44] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-01 05:18:54] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-07-01 05:19:16] [valid] Ep. 8 : Up. 200000 : cross-entropy : 49.8617 : new best
[2019-07-01 05:19:20] [valid] Ep. 8 : Up. 200000 : perplexity : 7.12375 : new best
[2019-07-01 05:20:01] [valid] Ep. 8 : Up. 200000 : translation : 29.99 : stalled 1 times (last best: 30.02)
[2019-07-01 05:30:20] Ep. 8 : Up. 202000 : Sen. 4,602,182 : Cost 35.76200485 : Time 711.75s : 10649.46 words/s
[2019-07-01 05:40:39] Ep. 8 : Up. 204000 : Sen. 5,003,321 : Cost 35.85056686 : Time 618.53s : 12261.04 words/s
[2019-07-01 05:43:58] Seen 5133815 samples
[2019-07-01 05:43:58] Starting epoch 9
[2019-07-01 05:43:58] [data] Shuffling data
[2019-07-01 05:44:01] [data] Done reading 5861713 sentences
[2019-07-01 05:44:22] [data] Done shuffling 5861713 sentences to temp files
[2019-07-01 05:51:22] Ep. 9 : Up. 206000 : Sen. 270,354 : Cost 35.15708160 : Time 643.63s : 11733.59 words/s
[2019-07-01 06:01:38] Ep. 9 : Up. 208000 : Sen. 669,407 : Cost 34.96979904 : Time 615.42s : 12219.70 words/s
[2019-07-01 06:11:57] Ep. 9 : Up. 210000 : Sen. 1,072,158 : Cost 35.01746368 : Time 619.02s : 12263.28 words/s
[2019-07-01 06:22:16] Ep. 9 : Up. 212000 : Sen. 1,474,704 : Cost 34.97391129 : Time 619.61s : 12228.53 words/s
[2019-07-01 06:32:36] Ep. 9 : Up. 214000 : Sen. 1,874,210 : Cost 35.25717163 : Time 619.61s : 12181.67 words/s
[2019-07-01 06:42:54] Ep. 9 : Up. 216000 : Sen. 2,275,383 : Cost 35.17923355 : Time 617.53s : 12248.75 words/s
[2019-07-01 06:53:10] Ep. 9 : Up. 218000 : Sen. 2,676,994 : Cost 35.05649567 : Time 616.32s : 12265.12 words/s
[2019-07-01 07:33:19] Error: Error reading from file '.'
[2019-07-01 07:33:19] Error: Aborted from marian::io::InputFileStream& marian::io::getline(marian::io::InputFileStream&, std::__cxx11::string&) in /fs/bil0/abdel/marian-dev/src/common/file_stream.h:216

[CALL STACK]
[0x727f12]                                                            
[0x728985]          marian::data::Corpus::  next  ()                   + 0x6f5
[0x716e4f]          marian::data::CorpusIterator::  increment  ()      + 0x2f
[0x681a7d]          marian::data::BatchGenerator<marian::data::CorpusBase>::  fetchBatches  () + 0x10dd
[0x682adb]          std::future<std::result_of<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1} ()>::type> marian::ThreadPool::enqueue<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}>(std::result_of&&,(marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}&&)...)::{lambda()#1}::  operator()  () const + 0x2b
[0x6834be]          std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base,std::__future_base::_Result_base::_Deleter> (),std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<std::deque<std::shared_ptr<marian::data::CorpusBatch>,std::allocator<std::shared_ptr<marian::data::CorpusBatch>>>>,std::__future_base::_Result_base::_Deleter>,std::_Bind_simple<std::reference_wrapper<std::future<std::result_of<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1} ()>::type> marian::ThreadPool::enqueue<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}>(std::result_of&&,(marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}&&)...)::{lambda()#1}> ()>,std::deque<std::shared_ptr<marian::data::CorpusBatch>,std::allocator<std::shared_ptr<marian::data::CorpusBatch>>>>>::  _M_invoke  (std::_Any_data const&) + 0x3e
[0x5a5f19]          std::__future_base::_State_baseV2::  _M_do_set  (std::function<std::unique_ptr<std::__future_base::_Result_base,std::__future_base::_Result_base::_Deleter> ()>*,  bool*) + 0x29
[0x7f49ea8eba99]                                                       + 0xea99
[0x59fac2]                                                            
[0x5a7341]          std::__future_base::_Task_state<std::future<std::result_of<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1} ()>::type> marian::ThreadPool::enqueue<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}>(std::result_of&&,(marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}&&)...)::{lambda()#1},std::allocator<int>,std::deque<std::shared_ptr<marian::data::CorpusBatch>,std::allocator<std::shared_ptr>> ()>::  _M_run  () + 0x51
[0x5d00b4]          std::thread::_Impl<std::_Bind_simple<marian::ThreadPool::reserve(unsigned long)::{lambda()#1} ()>>::  _M_run  () + 0x174
[0x7f49ea40bc80]                                                       + 0xb8c80
[0x7f49ea8e46ba]                                                       + 0x76ba
[0x7f49e9b7141d]    clone                                              + 0x6d

[2019-07-01 08:57:42] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-01 08:57:42] [marian] Running on dagr as process 4726 with command line:
[2019-07-01 08:57:42] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz -T . --devices 2 3 --train-sets ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/train.bpe.de ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/train.bpe.en --vocabs ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/train.bpe.de.json ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/dev.bpe.de ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/dev.out --valid-script-path ../experiments/100M_fasttext_prob_filtered_dcce_scoring/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/train.log --valid-log ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/valid.log
[2019-07-01 08:57:43] [config] after-batches: 0
[2019-07-01 08:57:43] [config] after-epochs: 0
[2019-07-01 08:57:43] [config] allow-unk: false
[2019-07-01 08:57:43] [config] beam-size: 12
[2019-07-01 08:57:43] [config] bert-class-symbol: "[CLS]"
[2019-07-01 08:57:43] [config] bert-mask-symbol: "[MASK]"
[2019-07-01 08:57:43] [config] bert-masking-fraction: 0.15
[2019-07-01 08:57:43] [config] bert-sep-symbol: "[SEP]"
[2019-07-01 08:57:43] [config] bert-train-type-embeddings: true
[2019-07-01 08:57:43] [config] bert-type-vocab-size: 2
[2019-07-01 08:57:43] [config] best-deep: false
[2019-07-01 08:57:43] [config] clip-gemm: 0
[2019-07-01 08:57:43] [config] clip-norm: 1
[2019-07-01 08:57:43] [config] cost-type: ce-mean
[2019-07-01 08:57:43] [config] cpu-threads: 0
[2019-07-01 08:57:43] [config] data-weighting: ""
[2019-07-01 08:57:43] [config] data-weighting-type: sentence
[2019-07-01 08:57:43] [config] dec-cell: gru
[2019-07-01 08:57:43] [config] dec-cell-base-depth: 2
[2019-07-01 08:57:43] [config] dec-cell-high-depth: 1
[2019-07-01 08:57:43] [config] dec-depth: 1
[2019-07-01 08:57:43] [config] devices:
[2019-07-01 08:57:43] [config]   - 2
[2019-07-01 08:57:43] [config]   - 3
[2019-07-01 08:57:43] [config] dim-emb: 512
[2019-07-01 08:57:43] [config] dim-rnn: 1024
[2019-07-01 08:57:43] [config] dim-vocabs:
[2019-07-01 08:57:43] [config]   - 50000
[2019-07-01 08:57:43] [config]   - 50000
[2019-07-01 08:57:43] [config] disp-first: 0
[2019-07-01 08:57:43] [config] disp-freq: 2000
[2019-07-01 08:57:43] [config] disp-label-counts: false
[2019-07-01 08:57:43] [config] dropout-rnn: 0.2
[2019-07-01 08:57:43] [config] dropout-src: 0.1
[2019-07-01 08:57:43] [config] dropout-trg: 0.1
[2019-07-01 08:57:43] [config] dump-config: ""
[2019-07-01 08:57:43] [config] early-stopping: 5
[2019-07-01 08:57:43] [config] embedding-fix-src: false
[2019-07-01 08:57:43] [config] embedding-fix-trg: false
[2019-07-01 08:57:43] [config] embedding-normalization: false
[2019-07-01 08:57:43] [config] embedding-vectors:
[2019-07-01 08:57:43] [config]   []
[2019-07-01 08:57:43] [config] enc-cell: gru
[2019-07-01 08:57:43] [config] enc-cell-depth: 1
[2019-07-01 08:57:43] [config] enc-depth: 1
[2019-07-01 08:57:43] [config] enc-type: bidirectional
[2019-07-01 08:57:43] [config] exponential-smoothing: 0.0001
[2019-07-01 08:57:43] [config] grad-dropping-momentum: 0
[2019-07-01 08:57:43] [config] grad-dropping-rate: 0
[2019-07-01 08:57:43] [config] grad-dropping-warmup: 100
[2019-07-01 08:57:43] [config] guided-alignment: none
[2019-07-01 08:57:43] [config] guided-alignment-cost: mse
[2019-07-01 08:57:43] [config] guided-alignment-weight: 0.1
[2019-07-01 08:57:43] [config] ignore-model-config: false
[2019-07-01 08:57:43] [config] input-types:
[2019-07-01 08:57:43] [config]   []
[2019-07-01 08:57:43] [config] interpolate-env-vars: false
[2019-07-01 08:57:43] [config] keep-best: false
[2019-07-01 08:57:43] [config] label-smoothing: 0
[2019-07-01 08:57:43] [config] layer-normalization: true
[2019-07-01 08:57:43] [config] learn-rate: 0.0001
[2019-07-01 08:57:43] [config] log: ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/train.log
[2019-07-01 08:57:43] [config] log-level: info
[2019-07-01 08:57:43] [config] log-time-zone: ""
[2019-07-01 08:57:43] [config] lr-decay: 0
[2019-07-01 08:57:43] [config] lr-decay-freq: 50000
[2019-07-01 08:57:43] [config] lr-decay-inv-sqrt:
[2019-07-01 08:57:43] [config]   - 0
[2019-07-01 08:57:43] [config] lr-decay-repeat-warmup: false
[2019-07-01 08:57:43] [config] lr-decay-reset-optimizer: false
[2019-07-01 08:57:43] [config] lr-decay-start:
[2019-07-01 08:57:43] [config]   - 10
[2019-07-01 08:57:43] [config]   - 1
[2019-07-01 08:57:43] [config] lr-decay-strategy: epoch+stalled
[2019-07-01 08:57:43] [config] lr-report: false
[2019-07-01 08:57:43] [config] lr-warmup: 0
[2019-07-01 08:57:43] [config] lr-warmup-at-reload: false
[2019-07-01 08:57:43] [config] lr-warmup-cycle: false
[2019-07-01 08:57:43] [config] lr-warmup-start-rate: 0
[2019-07-01 08:57:43] [config] max-length: 50
[2019-07-01 08:57:43] [config] max-length-crop: false
[2019-07-01 08:57:43] [config] max-length-factor: 3
[2019-07-01 08:57:43] [config] maxi-batch: 100
[2019-07-01 08:57:43] [config] maxi-batch-sort: trg
[2019-07-01 08:57:43] [config] mini-batch: 64
[2019-07-01 08:57:43] [config] mini-batch-fit: true
[2019-07-01 08:57:43] [config] mini-batch-fit-step: 10
[2019-07-01 08:57:43] [config] mini-batch-overstuff: 1
[2019-07-01 08:57:43] [config] mini-batch-track-lr: false
[2019-07-01 08:57:43] [config] mini-batch-understuff: 1
[2019-07-01 08:57:43] [config] mini-batch-warmup: 0
[2019-07-01 08:57:43] [config] mini-batch-words: 0
[2019-07-01 08:57:43] [config] mini-batch-words-ref: 0
[2019-07-01 08:57:43] [config] model: ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-01 08:57:43] [config] multi-loss-type: sum
[2019-07-01 08:57:43] [config] multi-node: false
[2019-07-01 08:57:43] [config] multi-node-overlap: true
[2019-07-01 08:57:43] [config] n-best: false
[2019-07-01 08:57:43] [config] no-nccl: false
[2019-07-01 08:57:43] [config] no-reload: false
[2019-07-01 08:57:43] [config] no-restore-corpus: false
[2019-07-01 08:57:43] [config] no-shuffle: false
[2019-07-01 08:57:43] [config] normalize: 1
[2019-07-01 08:57:43] [config] num-devices: 0
[2019-07-01 08:57:43] [config] optimizer: adam
[2019-07-01 08:57:43] [config] optimizer-delay: 1
[2019-07-01 08:57:43] [config] optimizer-params:
[2019-07-01 08:57:43] [config]   []
[2019-07-01 08:57:43] [config] overwrite: false
[2019-07-01 08:57:43] [config] pretrained-model: ""
[2019-07-01 08:57:43] [config] quiet: false
[2019-07-01 08:57:43] [config] quiet-translation: true
[2019-07-01 08:57:43] [config] relative-paths: false
[2019-07-01 08:57:43] [config] right-left: false
[2019-07-01 08:57:43] [config] save-freq: 20000
[2019-07-01 08:57:43] [config] seed: 1111
[2019-07-01 08:57:43] [config] shuffle-in-ram: false
[2019-07-01 08:57:43] [config] skip: false
[2019-07-01 08:57:43] [config] sqlite: ""
[2019-07-01 08:57:43] [config] sqlite-drop: false
[2019-07-01 08:57:43] [config] sync-sgd: true
[2019-07-01 08:57:43] [config] tempdir: .
[2019-07-01 08:57:43] [config] tied-embeddings: false
[2019-07-01 08:57:43] [config] tied-embeddings-all: false
[2019-07-01 08:57:43] [config] tied-embeddings-src: false
[2019-07-01 08:57:43] [config] train-sets:
[2019-07-01 08:57:43] [config]   - ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/train.bpe.de
[2019-07-01 08:57:43] [config]   - ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/train.bpe.en
[2019-07-01 08:57:43] [config] transformer-aan-activation: swish
[2019-07-01 08:57:43] [config] transformer-aan-depth: 2
[2019-07-01 08:57:43] [config] transformer-aan-nogate: false
[2019-07-01 08:57:43] [config] transformer-decoder-autoreg: self-attention
[2019-07-01 08:57:43] [config] transformer-dim-aan: 2048
[2019-07-01 08:57:43] [config] transformer-dim-ffn: 2048
[2019-07-01 08:57:43] [config] transformer-dropout: 0
[2019-07-01 08:57:43] [config] transformer-dropout-attention: 0
[2019-07-01 08:57:43] [config] transformer-dropout-ffn: 0
[2019-07-01 08:57:43] [config] transformer-ffn-activation: swish
[2019-07-01 08:57:43] [config] transformer-ffn-depth: 2
[2019-07-01 08:57:43] [config] transformer-guided-alignment-layer: last
[2019-07-01 08:57:43] [config] transformer-heads: 8
[2019-07-01 08:57:43] [config] transformer-no-projection: false
[2019-07-01 08:57:43] [config] transformer-postprocess: dan
[2019-07-01 08:57:43] [config] transformer-postprocess-emb: d
[2019-07-01 08:57:43] [config] transformer-preprocess: ""
[2019-07-01 08:57:43] [config] transformer-tied-layers:
[2019-07-01 08:57:43] [config]   []
[2019-07-01 08:57:43] [config] transformer-train-position-embeddings: false
[2019-07-01 08:57:43] [config] type: amun
[2019-07-01 08:57:43] [config] ulr: false
[2019-07-01 08:57:43] [config] ulr-dim-emb: 0
[2019-07-01 08:57:43] [config] ulr-dropout: 0
[2019-07-01 08:57:43] [config] ulr-keys-vectors: ""
[2019-07-01 08:57:43] [config] ulr-query-vectors: ""
[2019-07-01 08:57:43] [config] ulr-softmax-temperature: 1
[2019-07-01 08:57:43] [config] ulr-trainable-transformation: false
[2019-07-01 08:57:43] [config] valid-freq: 20000
[2019-07-01 08:57:43] [config] valid-log: ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/valid.log
[2019-07-01 08:57:43] [config] valid-max-length: 1000
[2019-07-01 08:57:43] [config] valid-metrics:
[2019-07-01 08:57:43] [config]   - cross-entropy
[2019-07-01 08:57:43] [config]   - perplexity
[2019-07-01 08:57:43] [config]   - translation
[2019-07-01 08:57:43] [config] valid-mini-batch: 8
[2019-07-01 08:57:43] [config] valid-script-path: ../experiments/100M_fasttext_prob_filtered_dcce_scoring/score-dev.sh
[2019-07-01 08:57:43] [config] valid-sets:
[2019-07-01 08:57:43] [config]   - ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/dev.bpe.de
[2019-07-01 08:57:43] [config]   - ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/dev.bpe.en
[2019-07-01 08:57:43] [config] valid-translation-output: ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/dev.out
[2019-07-01 08:57:43] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-01 08:57:43] [config] vocabs:
[2019-07-01 08:57:43] [config]   - ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/train.bpe.de.json
[2019-07-01 08:57:43] [config]   - ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/train.bpe.en.json
[2019-07-01 08:57:43] [config] word-penalty: 0
[2019-07-01 08:57:43] [config] workspace: 3000
[2019-07-01 08:57:43] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-01 08:57:43] Using synchronous training
[2019-07-01 08:57:43] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/train.bpe.de.json
[2019-07-01 08:57:43] [data] Using unused word id eos for 0
[2019-07-01 08:57:43] [data] Using unused word id UNK for 1
[2019-07-01 08:57:43] [data] Setting vocabulary size for input 0 to 50000
[2019-07-01 08:57:43] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_filtered_dcce_scoring/data/train.bpe.en.json
[2019-07-01 08:57:43] [data] Using unused word id eos for 0
[2019-07-01 08:57:43] [data] Using unused word id UNK for 1
[2019-07-01 08:57:43] [data] Setting vocabulary size for input 1 to 50000
[2019-07-01 08:57:43] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-01 08:57:43] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-01 08:57:44] [memory] Extending reserved space to 3072 MB (device gpu2)
[2019-07-01 08:57:45] [memory] Extending reserved space to 3072 MB (device gpu3)
[2019-07-01 08:57:45] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-01 08:57:45] [comm] NCCLCommunicator constructed successfully.
[2019-07-01 08:57:45] [training] Using 2 GPUs
[2019-07-01 08:57:45] [memory] Reserving 422 MB, device gpu2
[2019-07-01 08:57:45] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-01 08:57:45] [memory] Reserving 422 MB, device gpu2
[2019-07-01 08:57:50] [batching] Done. Typical MB size is 8084 target words
[2019-07-01 08:57:50] [memory] Extending reserved space to 3072 MB (device gpu2)
[2019-07-01 08:57:50] [memory] Extending reserved space to 3072 MB (device gpu3)
[2019-07-01 08:57:50] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-01 08:57:50] [comm] NCCLCommunicator constructed successfully.
[2019-07-01 08:57:50] [training] Using 2 GPUs
[2019-07-01 08:57:50] Loading model from ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-01 08:57:57] Loading model from ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-01 08:57:59] Loading Adam parameters from ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-07-01 08:58:08] [memory] Reserving 422 MB, device gpu2
[2019-07-01 08:58:09] [memory] Reserving 422 MB, device gpu3
[2019-07-01 08:58:09] [training] Model reloaded from ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-01 08:58:09] [data] Restoring the corpus state to epoch 8, batch 200000
[2019-07-01 08:58:09] [data] Shuffling data
[2019-07-01 08:58:12] [data] Done reading 5861713 sentences
[2019-07-01 08:58:34] [data] Done shuffling 5861713 sentences to temp files
[2019-07-01 09:00:15] Training started
[2019-07-01 09:00:15] [training] Batches are processed as 1 process(es) x 2 devices/process
[2019-07-01 09:00:15] [memory] Reserving 422 MB, device gpu3
[2019-07-01 09:00:15] [memory] Reserving 422 MB, device gpu2
[2019-07-01 09:00:15] [memory] Reserving 422 MB, device gpu2
[2019-07-01 09:00:15] [memory] Reserving 422 MB, device gpu3
[2019-07-01 09:00:15] Loading model from ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-01 09:00:21] [memory] Reserving 422 MB, device cpu0
[2019-07-01 09:00:21] [memory] Reserving 211 MB, device gpu2
[2019-07-01 09:00:21] [memory] Reserving 211 MB, device gpu3
[2019-07-01 09:10:24] Ep. 8 : Up. 202000 : Sen. 4,602,182 : Cost 35.76055908 : Time 760.68s : 9964.37 words/s
[2019-07-01 09:20:32] Ep. 8 : Up. 204000 : Sen. 5,003,321 : Cost 35.84532928 : Time 608.09s : 12471.61 words/s
[2019-07-01 09:23:48] Seen 5133815 samples
[2019-07-01 09:23:48] Starting epoch 9
[2019-07-01 09:23:48] [data] Shuffling data
[2019-07-01 09:23:50] [data] Done reading 5861713 sentences
[2019-07-01 09:24:11] [data] Done shuffling 5861713 sentences to temp files
[2019-07-01 09:31:04] Ep. 9 : Up. 206000 : Sen. 270,354 : Cost 35.14213943 : Time 632.16s : 11946.38 words/s
[2019-07-01 09:41:09] Ep. 9 : Up. 208000 : Sen. 669,407 : Cost 34.94464874 : Time 605.09s : 12428.35 words/s
[2019-07-01 09:51:19] Ep. 9 : Up. 210000 : Sen. 1,072,158 : Cost 34.94893265 : Time 609.26s : 12459.67 words/s
[2019-07-01 10:01:28] Ep. 9 : Up. 212000 : Sen. 1,474,704 : Cost 35.02321625 : Time 609.56s : 12430.02 words/s
[2019-07-01 10:11:36] Ep. 9 : Up. 214000 : Sen. 1,874,210 : Cost 35.26753235 : Time 608.37s : 12406.70 words/s
[2019-07-01 10:21:43] Ep. 9 : Up. 216000 : Sen. 2,275,383 : Cost 35.20858002 : Time 606.70s : 12467.43 words/s
[2019-07-01 10:31:49] Ep. 9 : Up. 218000 : Sen. 2,676,994 : Cost 35.12310410 : Time 605.99s : 12474.11 words/s
[2019-07-01 10:41:57] Ep. 9 : Up. 220000 : Sen. 3,080,266 : Cost 35.31636047 : Time 608.13s : 12479.96 words/s
[2019-07-01 10:41:57] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-01 10:42:06] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter220000.npz
[2019-07-01 10:42:14] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-01 10:42:25] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-07-01 10:42:48] [valid] Ep. 9 : Up. 220000 : cross-entropy : 49.4969 : new best
[2019-07-01 10:42:52] [valid] Ep. 9 : Up. 220000 : perplexity : 7.02215 : new best
[2019-07-01 10:43:34] [valid] Ep. 9 : Up. 220000 : translation : 30.18 : new best
[2019-07-01 10:53:44] Ep. 9 : Up. 222000 : Sen. 3,481,756 : Cost 35.20735168 : Time 707.03s : 10706.56 words/s
[2019-07-01 11:03:54] Ep. 9 : Up. 224000 : Sen. 3,882,408 : Cost 35.40174103 : Time 609.57s : 12415.86 words/s
[2019-07-01 11:14:01] Ep. 9 : Up. 226000 : Sen. 4,284,360 : Cost 35.17724991 : Time 606.76s : 12465.27 words/s
[2019-07-01 11:24:09] Ep. 9 : Up. 228000 : Sen. 4,685,870 : Cost 35.18946838 : Time 608.76s : 12409.18 words/s
[2019-07-01 11:34:17] Ep. 9 : Up. 230000 : Sen. 5,087,172 : Cost 35.32158661 : Time 607.35s : 12456.84 words/s
[2019-07-01 11:35:28] Seen 5133815 samples
[2019-07-01 11:35:28] Starting epoch 10
[2019-07-01 11:35:28] [data] Shuffling data
[2019-07-01 11:35:31] [data] Done reading 5861713 sentences
[2019-07-01 11:35:52] [data] Done shuffling 5861713 sentences to temp files
[2019-07-01 11:44:51] Ep. 10 : Up. 232000 : Sen. 353,254 : Cost 34.68776703 : Time 634.45s : 11889.24 words/s
[2019-07-01 11:54:55] Ep. 10 : Up. 234000 : Sen. 753,585 : Cost 34.54000092 : Time 604.22s : 12477.84 words/s
[2019-07-01 12:05:01] Ep. 10 : Up. 236000 : Sen. 1,155,276 : Cost 34.52125168 : Time 605.60s : 12483.47 words/s
[2019-07-01 12:15:11] Ep. 10 : Up. 238000 : Sen. 1,557,072 : Cost 34.81516647 : Time 610.00s : 12428.13 words/s
[2019-07-01 12:25:18] Ep. 10 : Up. 240000 : Sen. 1,957,884 : Cost 34.75741577 : Time 607.29s : 12439.93 words/s
[2019-07-01 12:25:18] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-01 12:25:27] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter240000.npz
[2019-07-01 12:25:34] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-01 12:25:43] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-07-01 12:26:05] [valid] Ep. 10 : Up. 240000 : cross-entropy : 49.2809 : new best
[2019-07-01 12:26:09] [valid] Ep. 10 : Up. 240000 : perplexity : 6.96268 : new best
[2019-07-01 12:26:50] [valid] Ep. 10 : Up. 240000 : translation : 30.44 : new best
[2019-07-01 12:37:01] Ep. 10 : Up. 242000 : Sen. 2,359,150 : Cost 34.85927200 : Time 702.67s : 10770.40 words/s
[2019-07-01 12:47:11] Ep. 10 : Up. 244000 : Sen. 2,763,287 : Cost 34.70458221 : Time 610.00s : 12469.10 words/s
[2019-07-01 12:57:19] Ep. 10 : Up. 246000 : Sen. 3,165,878 : Cost 34.75736618 : Time 608.18s : 12467.45 words/s
[2019-07-01 13:07:28] Ep. 10 : Up. 248000 : Sen. 3,568,226 : Cost 34.78129196 : Time 609.07s : 12439.32 words/s
[2019-07-01 13:17:34] Ep. 10 : Up. 250000 : Sen. 3,969,888 : Cost 34.83252716 : Time 605.97s : 12472.33 words/s
[2019-07-01 13:27:45] Ep. 10 : Up. 252000 : Sen. 4,371,872 : Cost 34.98940659 : Time 610.50s : 12439.02 words/s
[2019-07-01 13:37:53] Ep. 10 : Up. 254000 : Sen. 4,773,474 : Cost 34.85627365 : Time 608.46s : 12440.99 words/s
[2019-07-01 13:47:00] Seen 5133815 samples
[2019-07-01 13:47:00] Starting epoch 11
[2019-07-01 13:47:00] [data] Shuffling data
[2019-07-01 13:47:03] [data] Done reading 5861713 sentences
[2019-07-01 13:47:30] [data] Done shuffling 5861713 sentences to temp files
[2019-07-01 13:48:34] Ep. 11 : Up. 256000 : Sen. 39,586 : Cost 34.90183258 : Time 641.18s : 11772.28 words/s
[2019-07-01 13:58:42] Ep. 11 : Up. 258000 : Sen. 439,950 : Cost 34.04896545 : Time 607.55s : 12396.10 words/s
[2019-07-01 14:08:49] Ep. 11 : Up. 260000 : Sen. 841,147 : Cost 34.21580505 : Time 607.58s : 12456.73 words/s
[2019-07-01 14:08:49] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-01 14:08:59] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter260000.npz
[2019-07-01 14:09:05] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-01 14:09:15] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-07-01 14:09:37] [valid] Ep. 11 : Up. 260000 : cross-entropy : 49.0379 : new best
[2019-07-01 14:09:41] [valid] Ep. 11 : Up. 260000 : perplexity : 6.89637 : new best
[2019-07-01 14:10:22] [valid] Ep. 11 : Up. 260000 : translation : 30.44 : stalled 1 times (last best: 30.44)
[2019-07-01 14:20:33] Ep. 11 : Up. 262000 : Sen. 1,242,763 : Cost 34.10873795 : Time 703.55s : 10739.04 words/s
[2019-07-01 14:30:42] Ep. 11 : Up. 264000 : Sen. 1,643,750 : Cost 34.29515839 : Time 609.19s : 12407.41 words/s
[2019-07-01 14:40:52] Ep. 11 : Up. 266000 : Sen. 2,046,396 : Cost 34.41135025 : Time 610.16s : 12457.23 words/s
[2019-07-01 14:51:06] Ep. 11 : Up. 268000 : Sen. 2,451,200 : Cost 34.47529221 : Time 613.67s : 12425.14 words/s
[2019-07-01 15:01:17] Ep. 11 : Up. 270000 : Sen. 2,851,415 : Cost 34.52135849 : Time 610.53s : 12355.09 words/s
[2019-07-01 15:11:25] Ep. 11 : Up. 272000 : Sen. 3,252,697 : Cost 34.52125549 : Time 608.29s : 12433.00 words/s
[2019-07-01 15:21:34] Ep. 11 : Up. 274000 : Sen. 3,653,254 : Cost 34.53510666 : Time 608.61s : 12403.56 words/s
[2019-07-01 15:31:42] Ep. 11 : Up. 276000 : Sen. 4,054,851 : Cost 34.54316330 : Time 608.89s : 12441.99 words/s
[2019-07-01 15:41:52] Ep. 11 : Up. 278000 : Sen. 4,455,759 : Cost 34.50079727 : Time 609.16s : 12422.85 words/s
[2019-07-01 15:52:01] Ep. 11 : Up. 280000 : Sen. 4,858,378 : Cost 34.43735504 : Time 609.25s : 12436.49 words/s
[2019-07-01 15:52:01] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-01 15:52:10] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter280000.npz
[2019-07-01 15:52:17] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-01 15:52:26] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-07-01 15:52:48] [valid] Ep. 11 : Up. 280000 : cross-entropy : 48.888 : new best
[2019-07-01 15:52:52] [valid] Ep. 11 : Up. 280000 : perplexity : 6.85579 : new best
[2019-07-01 15:53:32] [valid] Ep. 11 : Up. 280000 : translation : 30.69 : new best
[2019-07-01 16:00:34] Seen 5133815 samples
[2019-07-01 16:00:34] Starting epoch 12
[2019-07-01 16:00:34] [data] Shuffling data
[2019-07-01 16:00:37] [data] Done reading 5861713 sentences
[2019-07-01 16:00:59] [data] Done shuffling 5861713 sentences to temp files
[2019-07-01 16:04:11] Ep. 12 : Up. 282000 : Sen. 124,892 : Cost 34.11625671 : Time 730.21s : 10315.21 words/s
[2019-07-01 16:14:23] Ep. 12 : Up. 284000 : Sen. 529,506 : Cost 33.75127792 : Time 611.76s : 12457.32 words/s
[2019-07-01 16:24:31] Ep. 12 : Up. 286000 : Sen. 928,156 : Cost 34.02457047 : Time 607.81s : 12361.45 words/s
[2019-07-01 16:34:41] Ep. 12 : Up. 288000 : Sen. 1,329,832 : Cost 33.89062500 : Time 610.48s : 12386.84 words/s
[2019-07-01 16:44:52] Ep. 12 : Up. 290000 : Sen. 1,732,249 : Cost 34.03339005 : Time 611.26s : 12404.02 words/s
[2019-07-01 16:55:01] Ep. 12 : Up. 292000 : Sen. 2,134,246 : Cost 34.02919769 : Time 609.17s : 12423.66 words/s
[2019-07-01 17:05:11] Ep. 12 : Up. 294000 : Sen. 2,535,326 : Cost 34.14710617 : Time 609.94s : 12413.59 words/s
[2019-07-01 17:15:20] Ep. 12 : Up. 296000 : Sen. 2,935,518 : Cost 34.12105942 : Time 608.44s : 12394.78 words/s
[2019-07-01 17:25:29] Ep. 12 : Up. 298000 : Sen. 3,337,310 : Cost 34.14986038 : Time 609.51s : 12431.70 words/s
[2019-07-01 17:35:42] Ep. 12 : Up. 300000 : Sen. 3,742,100 : Cost 34.09365845 : Time 612.77s : 12417.76 words/s
[2019-07-01 17:35:42] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-01 17:35:51] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter300000.npz
[2019-07-01 17:35:58] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-01 17:36:07] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-07-01 17:36:29] [valid] Ep. 12 : Up. 300000 : cross-entropy : 48.8283 : new best
[2019-07-01 17:36:32] [valid] Ep. 12 : Up. 300000 : perplexity : 6.8397 : new best
[2019-07-01 17:37:14] [valid] Ep. 12 : Up. 300000 : translation : 30.46 : stalled 1 times (last best: 30.69)
[2019-07-01 17:47:29] Ep. 12 : Up. 302000 : Sen. 4,145,208 : Cost 34.21757507 : Time 707.17s : 10758.28 words/s
[2019-07-01 17:57:39] Ep. 12 : Up. 304000 : Sen. 4,546,961 : Cost 34.24958801 : Time 609.87s : 12433.63 words/s
[2019-07-01 18:07:48] Ep. 12 : Up. 306000 : Sen. 4,947,512 : Cost 34.35913849 : Time 609.25s : 12410.89 words/s
[2019-07-01 18:12:31] Seen 5133815 samples
[2019-07-01 18:12:31] Starting epoch 13
[2019-07-01 18:12:31] [data] Shuffling data
[2019-07-01 18:12:34] [data] Done reading 5861713 sentences
[2019-07-01 18:12:55] [data] Done shuffling 5861713 sentences to temp files
[2019-07-01 18:18:27] Ep. 13 : Up. 308000 : Sen. 214,676 : Cost 33.85239029 : Time 638.04s : 11837.21 words/s
[2019-07-01 18:28:36] Ep. 13 : Up. 310000 : Sen. 617,211 : Cost 33.52262878 : Time 609.88s : 12415.69 words/s
[2019-07-01 18:38:46] Ep. 13 : Up. 312000 : Sen. 1,018,489 : Cost 33.61774445 : Time 609.93s : 12422.51 words/s
[2019-07-01 18:48:58] Ep. 13 : Up. 314000 : Sen. 1,421,268 : Cost 33.82466125 : Time 611.99s : 12420.05 words/s
[2019-07-01 18:59:07] Ep. 13 : Up. 316000 : Sen. 1,820,647 : Cost 33.80221939 : Time 608.53s : 12377.90 words/s
[2019-07-01 19:09:16] Ep. 13 : Up. 318000 : Sen. 2,221,813 : Cost 33.73585510 : Time 609.30s : 12397.11 words/s
[2019-07-01 19:19:25] Ep. 13 : Up. 320000 : Sen. 2,621,555 : Cost 33.96032333 : Time 608.53s : 12397.15 words/s
[2019-07-01 19:19:25] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-01 19:19:34] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter320000.npz
[2019-07-01 19:19:41] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-01 19:19:51] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-07-01 19:20:12] [valid] Ep. 13 : Up. 320000 : cross-entropy : 48.7502 : new best
[2019-07-01 19:20:16] [valid] Ep. 13 : Up. 320000 : perplexity : 6.81869 : new best
[2019-07-01 19:20:56] [valid] Ep. 13 : Up. 320000 : translation : 30.46 : stalled 2 times (last best: 30.69)
[2019-07-01 19:31:08] Ep. 13 : Up. 322000 : Sen. 3,023,448 : Cost 33.81836319 : Time 703.09s : 10754.58 words/s
[2019-07-01 19:41:18] Ep. 13 : Up. 324000 : Sen. 3,426,349 : Cost 33.72994232 : Time 610.10s : 12428.62 words/s
[2019-07-01 19:51:31] Ep. 13 : Up. 326000 : Sen. 3,829,553 : Cost 33.96864700 : Time 613.28s : 12425.24 words/s
[2019-07-01 20:01:43] Ep. 13 : Up. 328000 : Sen. 4,230,556 : Cost 33.76678085 : Time 611.50s : 12348.83 words/s
[2019-07-01 20:11:54] Ep. 13 : Up. 330000 : Sen. 4,632,028 : Cost 33.93499374 : Time 611.36s : 12375.01 words/s
[2019-07-01 20:22:07] Ep. 13 : Up. 332000 : Sen. 5,035,654 : Cost 34.02599335 : Time 612.73s : 12412.20 words/s
[2019-07-01 20:24:36] Seen 5133815 samples
[2019-07-01 20:24:36] Starting epoch 14
[2019-07-01 20:24:36] [data] Shuffling data
[2019-07-01 20:24:39] [data] Done reading 5861713 sentences
[2019-07-01 20:24:59] [data] Done shuffling 5861713 sentences to temp files
[2019-07-01 20:32:43] Ep. 14 : Up. 334000 : Sen. 301,784 : Cost 33.41648865 : Time 635.88s : 11841.76 words/s
[2019-07-01 20:42:52] Ep. 14 : Up. 336000 : Sen. 704,000 : Cost 33.17824173 : Time 609.30s : 12433.50 words/s
[2019-07-01 20:53:02] Ep. 14 : Up. 338000 : Sen. 1,105,202 : Cost 33.28995514 : Time 609.79s : 12387.65 words/s
[2019-07-01 21:03:07] Ep. 14 : Up. 340000 : Sen. 1,502,986 : Cost 33.53599930 : Time 605.10s : 12396.72 words/s
[2019-07-01 21:03:07] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-01 21:03:17] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter340000.npz
[2019-07-01 21:03:24] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-01 21:03:33] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-07-01 21:03:55] [valid] Ep. 14 : Up. 340000 : cross-entropy : 48.6115 : new best
[2019-07-01 21:03:59] [valid] Ep. 14 : Up. 340000 : perplexity : 6.78154 : new best
[2019-07-01 21:04:35] [valid] Ep. 14 : Up. 340000 : translation : 30.51 : stalled 3 times (last best: 30.69)
[2019-07-01 21:14:48] Ep. 14 : Up. 342000 : Sen. 1,903,874 : Cost 33.47064972 : Time 701.01s : 10784.46 words/s
[2019-07-01 21:24:58] Ep. 14 : Up. 344000 : Sen. 2,304,630 : Cost 33.49340057 : Time 610.00s : 12368.30 words/s
[2019-07-01 21:35:11] Ep. 14 : Up. 346000 : Sen. 2,706,888 : Cost 33.62134171 : Time 613.00s : 12362.94 words/s
[2019-07-01 21:45:24] Ep. 14 : Up. 348000 : Sen. 3,107,802 : Cost 33.76436615 : Time 612.87s : 12349.50 words/s
[2019-07-01 21:55:36] Ep. 14 : Up. 350000 : Sen. 3,510,592 : Cost 33.54613113 : Time 612.02s : 12381.81 words/s
[2019-07-01 22:05:50] Ep. 14 : Up. 352000 : Sen. 3,913,572 : Cost 33.73392105 : Time 614.10s : 12365.55 words/s
[2019-07-01 22:16:01] Ep. 14 : Up. 354000 : Sen. 4,315,237 : Cost 33.70937347 : Time 611.60s : 12366.26 words/s
[2019-07-01 22:26:10] Ep. 14 : Up. 356000 : Sen. 4,713,762 : Cost 33.87196350 : Time 608.27s : 12388.02 words/s
[2019-07-01 22:36:18] Ep. 14 : Up. 358000 : Sen. 5,114,796 : Cost 33.61359406 : Time 608.41s : 12401.60 words/s
[2019-07-01 22:36:47] Seen 5133815 samples
[2019-07-01 22:36:47] Starting epoch 15
[2019-07-01 22:36:47] [data] Shuffling data
[2019-07-01 22:36:50] [data] Done reading 5861713 sentences
[2019-07-01 22:37:11] [data] Done shuffling 5861713 sentences to temp files
[2019-07-01 22:46:55] Ep. 15 : Up. 360000 : Sen. 379,556 : Cost 33.03782272 : Time 637.08s : 11815.89 words/s
[2019-07-01 22:46:55] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-01 22:47:05] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter360000.npz
[2019-07-01 22:47:11] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-01 22:47:21] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-07-01 22:47:43] [valid] Ep. 15 : Up. 360000 : cross-entropy : 48.5049 : new best
[2019-07-01 22:47:47] [valid] Ep. 15 : Up. 360000 : perplexity : 6.75314 : new best
[2019-07-01 22:48:27] [valid] Ep. 15 : Up. 360000 : translation : 30.76 : new best
[2019-07-01 22:58:41] Ep. 15 : Up. 362000 : Sen. 781,112 : Cost 33.14023972 : Time 705.80s : 10734.77 words/s
[2019-07-01 23:08:51] Ep. 15 : Up. 364000 : Sen. 1,183,064 : Cost 32.92116547 : Time 610.07s : 12374.60 words/s
[2019-07-01 23:19:03] Ep. 15 : Up. 366000 : Sen. 1,585,711 : Cost 33.31047821 : Time 612.40s : 12416.59 words/s
[2019-07-01 23:29:14] Ep. 15 : Up. 368000 : Sen. 1,989,162 : Cost 33.24020004 : Time 610.99s : 12433.97 words/s
[2019-07-01 23:39:24] Ep. 15 : Up. 370000 : Sen. 2,389,974 : Cost 33.34796143 : Time 609.27s : 12398.42 words/s
[2019-07-01 23:49:33] Ep. 15 : Up. 372000 : Sen. 2,791,546 : Cost 33.24659729 : Time 609.71s : 12395.90 words/s
[2019-07-01 23:59:44] Ep. 15 : Up. 374000 : Sen. 3,192,928 : Cost 33.29681778 : Time 610.19s : 12373.27 words/s
[2019-07-02 00:09:55] Ep. 15 : Up. 376000 : Sen. 3,594,436 : Cost 33.48649979 : Time 611.16s : 12392.19 words/s
[2019-07-02 00:20:04] Ep. 15 : Up. 378000 : Sen. 3,996,442 : Cost 33.53167343 : Time 609.13s : 12429.45 words/s
[2019-07-02 00:30:14] Ep. 15 : Up. 380000 : Sen. 4,397,066 : Cost 33.54875183 : Time 609.99s : 12392.92 words/s
[2019-07-02 00:30:14] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-02 00:30:23] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter380000.npz
[2019-07-02 00:30:30] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-02 00:30:40] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-07-02 00:31:01] [valid] Ep. 15 : Up. 380000 : cross-entropy : 48.4983 : new best
[2019-07-02 00:31:05] [valid] Ep. 15 : Up. 380000 : perplexity : 6.7514 : new best
[2019-07-02 00:31:45] [valid] Ep. 15 : Up. 380000 : translation : 30.67 : stalled 1 times (last best: 30.76)
[2019-07-02 00:41:55] Ep. 15 : Up. 382000 : Sen. 4,795,420 : Cost 33.57909393 : Time 701.19s : 10710.87 words/s
[2019-07-02 00:50:33] Seen 5133815 samples
[2019-07-02 00:50:33] Starting epoch 16
[2019-07-02 00:50:33] [data] Shuffling data
[2019-07-02 00:50:37] [data] Done reading 5861713 sentences
[2019-07-02 00:51:01] [data] Done shuffling 5861713 sentences to temp files
[2019-07-02 00:52:36] Ep. 16 : Up. 384000 : Sen. 61,647 : Cost 33.37582397 : Time 641.24s : 11769.84 words/s
[2019-07-02 01:02:45] Ep. 16 : Up. 386000 : Sen. 462,578 : Cost 32.65909195 : Time 609.00s : 12403.17 words/s
[2019-07-02 01:12:56] Ep. 16 : Up. 388000 : Sen. 864,938 : Cost 32.90462875 : Time 610.48s : 12409.00 words/s
[2019-07-02 01:23:09] Ep. 16 : Up. 390000 : Sen. 1,270,477 : Cost 32.87431335 : Time 612.95s : 12484.48 words/s
[2019-07-02 01:33:15] Ep. 16 : Up. 392000 : Sen. 1,668,739 : Cost 32.95253754 : Time 606.28s : 12352.85 words/s
[2019-07-02 01:43:24] Ep. 16 : Up. 394000 : Sen. 2,068,816 : Cost 33.19203186 : Time 608.50s : 12396.33 words/s
[2019-07-02 01:53:33] Ep. 16 : Up. 396000 : Sen. 2,469,070 : Cost 33.24875641 : Time 609.82s : 12409.06 words/s
[2019-07-02 02:03:45] Ep. 16 : Up. 398000 : Sen. 2,870,869 : Cost 33.28800583 : Time 611.62s : 12395.84 words/s
[2019-07-02 02:13:54] Ep. 16 : Up. 400000 : Sen. 3,272,530 : Cost 33.13450241 : Time 609.17s : 12413.22 words/s
[2019-07-02 02:13:54] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-02 02:14:04] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter400000.npz
[2019-07-02 02:14:11] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-02 02:14:21] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-07-02 02:14:42] [valid] Ep. 16 : Up. 400000 : cross-entropy : 48.5439 : stalled 1 times (last best: 48.4983)
[2019-07-02 02:14:46] [valid] Ep. 16 : Up. 400000 : perplexity : 6.76351 : stalled 1 times (last best: 6.7514)
[2019-07-02 02:15:27] [valid] Ep. 16 : Up. 400000 : translation : 30.7 : stalled 2 times (last best: 30.76)
[2019-07-02 02:25:41] Ep. 16 : Up. 402000 : Sen. 3,673,600 : Cost 33.19232178 : Time 706.61s : 10691.63 words/s
[2019-07-02 02:35:50] Ep. 16 : Up. 404000 : Sen. 4,073,962 : Cost 33.42453766 : Time 608.82s : 12390.08 words/s
[2019-07-02 02:45:58] Ep. 16 : Up. 406000 : Sen. 4,474,428 : Cost 33.22871017 : Time 608.18s : 12415.46 words/s
[2019-07-02 02:56:08] Ep. 16 : Up. 408000 : Sen. 4,878,236 : Cost 33.17795181 : Time 609.82s : 12456.79 words/s
[2019-07-02 03:02:38] Seen 5133815 samples
[2019-07-02 03:02:38] Starting epoch 17
[2019-07-02 03:02:38] [data] Shuffling data
[2019-07-02 03:02:41] [data] Done reading 5861713 sentences
[2019-07-02 03:03:02] [data] Done shuffling 5861713 sentences to temp files
[2019-07-02 03:06:44] Ep. 17 : Up. 410000 : Sen. 142,882 : Cost 32.82846451 : Time 635.84s : 11798.14 words/s
[2019-07-02 03:16:56] Ep. 17 : Up. 412000 : Sen. 546,654 : Cost 32.58578491 : Time 612.54s : 12429.63 words/s
[2019-07-02 03:27:06] Ep. 17 : Up. 414000 : Sen. 948,507 : Cost 32.59879684 : Time 609.94s : 12419.79 words/s
[2019-07-02 03:37:15] Ep. 17 : Up. 416000 : Sen. 1,349,818 : Cost 32.57510376 : Time 609.12s : 12397.15 words/s
[2019-07-02 03:47:24] Ep. 17 : Up. 418000 : Sen. 1,750,910 : Cost 32.78979492 : Time 608.43s : 12427.60 words/s
[2019-07-02 03:57:33] Ep. 17 : Up. 420000 : Sen. 2,152,640 : Cost 32.97328949 : Time 609.23s : 12428.07 words/s
[2019-07-02 03:57:33] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-02 03:57:42] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter420000.npz
[2019-07-02 03:57:49] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-02 03:57:59] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-07-02 03:58:20] [valid] Ep. 17 : Up. 420000 : cross-entropy : 48.4967 : new best
[2019-07-02 03:58:24] [valid] Ep. 17 : Up. 420000 : perplexity : 6.75097 : new best
[2019-07-02 03:59:06] [valid] Ep. 17 : Up. 420000 : translation : 30.68 : stalled 3 times (last best: 30.76)
[2019-07-02 04:09:18] Ep. 17 : Up. 422000 : Sen. 2,553,288 : Cost 32.88067627 : Time 704.94s : 10723.85 words/s
[2019-07-02 04:19:28] Ep. 17 : Up. 424000 : Sen. 2,955,146 : Cost 33.08423615 : Time 610.71s : 12421.73 words/s
[2019-07-02 04:29:37] Ep. 17 : Up. 426000 : Sen. 3,358,320 : Cost 32.84786987 : Time 608.98s : 12443.33 words/s
[2019-07-02 04:39:49] Ep. 17 : Up. 428000 : Sen. 3,761,054 : Cost 33.08864975 : Time 611.34s : 12421.88 words/s
[2019-07-02 04:50:01] Ep. 17 : Up. 430000 : Sen. 4,163,746 : Cost 33.10504150 : Time 612.30s : 12395.36 words/s
[2019-07-02 05:00:21] Ep. 17 : Up. 432000 : Sen. 4,564,660 : Cost 33.05004883 : Time 620.40s : 12191.05 words/s
[2019-07-02 05:10:37] Ep. 17 : Up. 434000 : Sen. 4,966,400 : Cost 33.00462723 : Time 615.49s : 12287.29 words/s
[2019-07-02 05:14:51] Seen 5133815 samples
[2019-07-02 05:14:51] Starting epoch 18
[2019-07-02 05:14:51] [data] Shuffling data
[2019-07-02 05:14:54] [data] Done reading 5861713 sentences
[2019-07-02 05:15:15] [data] Done shuffling 5861713 sentences to temp files
[2019-07-02 05:21:14] Ep. 18 : Up. 436000 : Sen. 233,034 : Cost 32.69538879 : Time 636.60s : 11876.37 words/s
[2019-07-02 05:31:23] Ep. 18 : Up. 438000 : Sen. 633,600 : Cost 32.44890594 : Time 609.54s : 12388.31 words/s
[2019-07-02 05:41:34] Ep. 18 : Up. 440000 : Sen. 1,036,440 : Cost 32.47076416 : Time 610.97s : 12422.67 words/s
[2019-07-02 05:41:34] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-02 05:41:44] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter440000.npz
[2019-07-02 05:41:54] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-02 05:42:05] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-07-02 05:42:27] [valid] Ep. 18 : Up. 440000 : cross-entropy : 48.4643 : new best
[2019-07-02 05:42:31] [valid] Ep. 18 : Up. 440000 : perplexity : 6.74236 : new best
[2019-07-02 05:43:12] [valid] Ep. 18 : Up. 440000 : translation : 30.66 : stalled 4 times (last best: 30.76)
[2019-07-02 05:53:24] Ep. 18 : Up. 442000 : Sen. 1,438,900 : Cost 32.59349060 : Time 709.69s : 10671.11 words/s
[2019-07-02 06:03:35] Ep. 18 : Up. 444000 : Sen. 1,838,526 : Cost 32.68194580 : Time 611.46s : 12338.38 words/s
[2019-07-02 06:13:45] Ep. 18 : Up. 446000 : Sen. 2,242,077 : Cost 32.60440826 : Time 610.16s : 12442.36 words/s
[2019-07-02 06:23:54] Ep. 18 : Up. 448000 : Sen. 2,643,668 : Cost 32.75943756 : Time 608.79s : 12430.41 words/s
[2019-07-02 06:34:05] Ep. 18 : Up. 450000 : Sen. 3,046,556 : Cost 32.64836121 : Time 610.59s : 12425.05 words/s
[2019-07-02 06:44:14] Ep. 18 : Up. 452000 : Sen. 3,449,828 : Cost 32.83558655 : Time 609.59s : 12463.01 words/s
[2019-07-02 06:54:24] Ep. 18 : Up. 454000 : Sen. 3,851,240 : Cost 32.86590195 : Time 609.97s : 12415.19 words/s
[2019-07-02 07:04:32] Ep. 18 : Up. 456000 : Sen. 4,252,474 : Cost 32.90375900 : Time 607.81s : 12426.96 words/s
[2019-07-02 07:14:43] Ep. 18 : Up. 458000 : Sen. 4,654,372 : Cost 32.99820328 : Time 610.67s : 12417.12 words/s
[2019-07-02 07:24:50] Ep. 18 : Up. 460000 : Sen. 5,054,297 : Cost 33.06230164 : Time 606.95s : 12430.24 words/s
[2019-07-02 07:24:50] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-02 07:24:59] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter460000.npz
[2019-07-02 07:25:06] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-02 07:25:16] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-07-02 07:25:40] [valid] Ep. 18 : Up. 460000 : cross-entropy : 48.4827 : stalled 1 times (last best: 48.4643)
[2019-07-02 07:25:44] [valid] Ep. 18 : Up. 460000 : perplexity : 6.74724 : stalled 1 times (last best: 6.74236)
[2019-07-02 07:26:27] [valid] Ep. 18 : Up. 460000 : translation : 30.59 : stalled 5 times (last best: 30.76)
[2019-07-02 07:28:29] Seen 5133815 samples
[2019-07-02 07:28:29] Starting epoch 19
[2019-07-02 07:28:29] [data] Shuffling data
[2019-07-02 07:28:32] [data] Done reading 5861713 sentences
[2019-07-02 07:28:54] [data] Done shuffling 5861713 sentences to temp files
[2019-07-02 07:37:07] Ep. 19 : Up. 462000 : Sen. 322,998 : Cost 32.40567780 : Time 737.37s : 10289.05 words/s
[2019-07-02 07:47:16] Ep. 19 : Up. 464000 : Sen. 725,795 : Cost 32.37631607 : Time 609.35s : 12485.17 words/s
[2019-07-02 07:57:23] Ep. 19 : Up. 466000 : Sen. 1,125,728 : Cost 32.13825226 : Time 606.67s : 12388.69 words/s
[2019-07-02 08:07:31] Ep. 19 : Up. 468000 : Sen. 1,525,441 : Cost 32.53898239 : Time 607.97s : 12393.17 words/s
[2019-07-02 08:17:39] Ep. 19 : Up. 470000 : Sen. 1,926,982 : Cost 32.57744217 : Time 607.72s : 12465.92 words/s
[2019-07-02 08:27:47] Ep. 19 : Up. 472000 : Sen. 2,325,935 : Cost 32.51638412 : Time 607.80s : 12383.40 words/s
[2019-07-02 08:37:54] Ep. 19 : Up. 474000 : Sen. 2,727,966 : Cost 32.62722015 : Time 607.42s : 12481.31 words/s
[2019-07-02 08:48:02] Ep. 19 : Up. 476000 : Sen. 3,130,224 : Cost 32.57411194 : Time 608.24s : 12470.66 words/s
[2019-07-02 08:58:11] Ep. 19 : Up. 478000 : Sen. 3,532,332 : Cost 32.54444122 : Time 608.43s : 12427.36 words/s
[2019-07-02 09:08:19] Ep. 19 : Up. 480000 : Sen. 3,933,927 : Cost 32.67500687 : Time 608.13s : 12475.62 words/s
[2019-07-02 09:08:19] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-02 09:08:28] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter480000.npz
[2019-07-02 09:08:35] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-02 09:08:44] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-07-02 09:09:06] [valid] Ep. 19 : Up. 480000 : cross-entropy : 48.5084 : stalled 2 times (last best: 48.4643)
[2019-07-02 09:09:10] [valid] Ep. 19 : Up. 480000 : perplexity : 6.75406 : stalled 2 times (last best: 6.74236)
[2019-07-02 09:09:51] [valid] Ep. 19 : Up. 480000 : translation : 30.82 : new best
[2019-07-02 09:20:01] Ep. 19 : Up. 482000 : Sen. 4,335,816 : Cost 32.62550354 : Time 702.27s : 10749.95 words/s
[2019-07-02 09:30:09] Ep. 19 : Up. 484000 : Sen. 4,736,564 : Cost 32.72195053 : Time 607.70s : 12431.61 words/s
[2019-07-02 09:40:09] Seen 5133815 samples
[2019-07-02 09:40:09] Starting epoch 20
[2019-07-02 09:40:09] [data] Shuffling data
[2019-07-02 09:40:12] [data] Done reading 5861713 sentences
[2019-07-02 09:40:33] [data] Done shuffling 5861713 sentences to temp files
[2019-07-02 09:40:43] Ep. 20 : Up. 486000 : Sen. 3,590 : Cost 32.72219467 : Time 634.32s : 11909.33 words/s
[2019-07-02 09:50:49] Ep. 20 : Up. 488000 : Sen. 404,056 : Cost 32.06808090 : Time 606.03s : 12462.23 words/s
[2019-07-02 10:00:58] Ep. 20 : Up. 490000 : Sen. 803,568 : Cost 32.30899811 : Time 608.34s : 12402.52 words/s
[2019-07-02 10:11:06] Ep. 20 : Up. 492000 : Sen. 1,206,292 : Cost 32.05617905 : Time 608.79s : 12457.18 words/s
[2019-07-02 10:21:13] Ep. 20 : Up. 494000 : Sen. 1,607,947 : Cost 32.17192078 : Time 607.16s : 12440.82 words/s
[2019-07-02 10:31:23] Ep. 20 : Up. 496000 : Sen. 2,011,508 : Cost 32.28320694 : Time 609.37s : 12467.01 words/s
[2019-07-02 10:41:32] Ep. 20 : Up. 498000 : Sen. 2,414,237 : Cost 32.48405075 : Time 609.14s : 12462.45 words/s
[2019-07-02 10:51:43] Ep. 20 : Up. 500000 : Sen. 2,817,695 : Cost 32.51566315 : Time 610.85s : 12447.33 words/s
[2019-07-02 10:51:43] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-02 10:51:52] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter500000.npz
[2019-07-02 10:51:59] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-02 10:52:08] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-07-02 10:52:29] [valid] Ep. 20 : Up. 500000 : cross-entropy : 48.4956 : stalled 3 times (last best: 48.4643)
[2019-07-02 10:52:33] [valid] Ep. 20 : Up. 500000 : perplexity : 6.75066 : stalled 3 times (last best: 6.74236)
[2019-07-02 10:53:15] [valid] Ep. 20 : Up. 500000 : translation : 30.67 : stalled 1 times (last best: 30.82)
[2019-07-02 11:03:24] Ep. 20 : Up. 502000 : Sen. 3,218,462 : Cost 32.47941971 : Time 701.62s : 10783.45 words/s
[2019-07-02 11:13:33] Ep. 20 : Up. 504000 : Sen. 3,619,730 : Cost 32.46581268 : Time 608.97s : 12397.77 words/s
[2019-07-02 11:23:52] Ep. 20 : Up. 506000 : Sen. 4,021,068 : Cost 32.53856277 : Time 618.30s : 12238.40 words/s
[2019-07-02 11:33:58] Ep. 20 : Up. 508000 : Sen. 4,421,303 : Cost 32.59950256 : Time 606.45s : 12436.62 words/s
[2019-07-02 11:44:05] Ep. 20 : Up. 510000 : Sen. 4,821,810 : Cost 32.43647003 : Time 606.68s : 12424.73 words/s
[2019-07-02 11:51:57] Seen 5133815 samples
[2019-07-02 11:51:57] Starting epoch 21
[2019-07-02 11:51:57] [data] Shuffling data
[2019-07-02 11:52:00] [data] Done reading 5861713 sentences
[2019-07-02 11:52:22] [data] Done shuffling 5861713 sentences to temp files
[2019-07-02 11:54:40] Ep. 21 : Up. 512000 : Sen. 89,804 : Cost 32.50389481 : Time 634.90s : 11946.98 words/s
[2019-07-02 12:04:49] Ep. 21 : Up. 514000 : Sen. 492,800 : Cost 32.00301743 : Time 609.71s : 12477.43 words/s
[2019-07-02 12:14:57] Ep. 21 : Up. 516000 : Sen. 894,960 : Cost 31.95404243 : Time 607.56s : 12467.52 words/s
[2019-07-02 12:25:04] Ep. 21 : Up. 518000 : Sen. 1,296,594 : Cost 32.09980392 : Time 606.76s : 12461.75 words/s
[2019-07-02 12:35:11] Ep. 21 : Up. 520000 : Sen. 1,697,566 : Cost 32.01526260 : Time 607.18s : 12452.91 words/s
[2019-07-02 12:35:11] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-02 12:35:20] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter520000.npz
[2019-07-02 12:35:27] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-02 12:35:37] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-07-02 12:35:58] [valid] Ep. 21 : Up. 520000 : cross-entropy : 48.4642 : new best
[2019-07-02 12:36:02] [valid] Ep. 21 : Up. 520000 : perplexity : 6.74232 : new best
[2019-07-02 12:36:43] [valid] Ep. 21 : Up. 520000 : translation : 30.8 : stalled 2 times (last best: 30.82)
[2019-07-02 12:46:50] Ep. 21 : Up. 522000 : Sen. 2,097,370 : Cost 32.07014847 : Time 699.27s : 10739.19 words/s
[2019-07-02 12:56:56] Ep. 21 : Up. 524000 : Sen. 2,497,453 : Cost 32.39159775 : Time 605.53s : 12479.15 words/s
[2019-07-02 13:07:02] Ep. 21 : Up. 526000 : Sen. 2,898,338 : Cost 32.37984085 : Time 606.74s : 12457.73 words/s
[2019-07-02 13:17:09] Ep. 21 : Up. 528000 : Sen. 3,297,770 : Cost 32.51253128 : Time 606.02s : 12437.22 words/s
[2019-07-02 13:27:15] Ep. 21 : Up. 530000 : Sen. 3,699,626 : Cost 32.22507477 : Time 606.89s : 12446.58 words/s
[2019-07-02 13:37:25] Ep. 21 : Up. 532000 : Sen. 4,102,130 : Cost 32.46691895 : Time 609.34s : 12451.66 words/s
[2019-07-02 13:47:30] Ep. 21 : Up. 534000 : Sen. 4,502,748 : Cost 32.54285049 : Time 605.58s : 12471.51 words/s
[2019-07-02 13:57:36] Ep. 21 : Up. 536000 : Sen. 4,903,335 : Cost 32.40440750 : Time 605.36s : 12477.46 words/s
[2019-07-02 14:03:26] Seen 5133815 samples
[2019-07-02 14:03:26] Starting epoch 22
[2019-07-02 14:03:26] [data] Shuffling data
[2019-07-02 14:03:29] [data] Done reading 5861713 sentences
[2019-07-02 14:03:50] [data] Done shuffling 5861713 sentences to temp files
[2019-07-02 14:08:13] Ep. 22 : Up. 538000 : Sen. 171,594 : Cost 32.07651520 : Time 637.00s : 11891.57 words/s
[2019-07-02 14:18:22] Ep. 22 : Up. 540000 : Sen. 575,106 : Cost 31.70716667 : Time 609.28s : 12494.35 words/s
[2019-07-02 14:18:22] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-02 14:18:35] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter540000.npz
[2019-07-02 14:18:43] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-02 14:18:53] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-07-02 14:19:15] [valid] Ep. 22 : Up. 540000 : cross-entropy : 48.4412 : new best
[2019-07-02 14:19:19] [valid] Ep. 22 : Up. 540000 : perplexity : 6.73623 : new best
[2019-07-02 14:19:59] [valid] Ep. 22 : Up. 540000 : translation : 30.7 : stalled 3 times (last best: 30.82)
[2019-07-02 14:30:05] Ep. 22 : Up. 542000 : Sen. 974,146 : Cost 31.93204689 : Time 702.75s : 10701.46 words/s
[2019-07-02 14:40:12] Ep. 22 : Up. 544000 : Sen. 1,374,473 : Cost 31.70857620 : Time 607.20s : 12419.14 words/s
[2019-07-02 14:50:19] Ep. 22 : Up. 546000 : Sen. 1,776,928 : Cost 32.05552292 : Time 607.41s : 12469.64 words/s
[2019-07-02 15:00:23] Ep. 22 : Up. 548000 : Sen. 2,176,000 : Cost 32.05075836 : Time 603.74s : 12448.15 words/s
[2019-07-02 15:10:30] Ep. 22 : Up. 550000 : Sen. 2,577,996 : Cost 32.24298859 : Time 606.46s : 12501.86 words/s
[2019-07-02 15:20:36] Ep. 22 : Up. 552000 : Sen. 2,977,981 : Cost 32.25874710 : Time 606.80s : 12415.51 words/s
[2019-07-02 15:30:47] Ep. 22 : Up. 554000 : Sen. 3,381,364 : Cost 32.28385162 : Time 610.94s : 12441.07 words/s
[2019-07-02 15:40:57] Ep. 22 : Up. 556000 : Sen. 3,784,156 : Cost 32.26729584 : Time 609.43s : 12450.34 words/s
[2019-07-02 15:51:05] Ep. 22 : Up. 558000 : Sen. 4,188,027 : Cost 32.33060074 : Time 608.40s : 12521.11 words/s
[2019-07-02 16:01:14] Ep. 22 : Up. 560000 : Sen. 4,591,866 : Cost 32.17782593 : Time 609.18s : 12486.61 words/s
[2019-07-02 16:01:14] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-02 16:01:24] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter560000.npz
[2019-07-02 16:01:31] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-02 16:01:40] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-07-02 16:02:02] [valid] Ep. 22 : Up. 560000 : cross-entropy : 48.4975 : stalled 1 times (last best: 48.4412)
[2019-07-02 16:02:06] [valid] Ep. 22 : Up. 560000 : perplexity : 6.75117 : stalled 1 times (last best: 6.73623)
[2019-07-02 16:02:46] [valid] Ep. 22 : Up. 560000 : translation : 30.69 : stalled 4 times (last best: 30.82)
[2019-07-02 16:12:56] Ep. 22 : Up. 562000 : Sen. 4,992,984 : Cost 32.34843063 : Time 702.03s : 10787.42 words/s
[2019-07-02 16:16:29] Seen 5133815 samples
[2019-07-02 16:16:29] Starting epoch 23
[2019-07-02 16:16:29] [data] Shuffling data
[2019-07-02 16:16:32] [data] Done reading 5861713 sentences
[2019-07-02 16:16:53] [data] Done shuffling 5861713 sentences to temp files
[2019-07-02 16:23:32] Ep. 23 : Up. 564000 : Sen. 262,400 : Cost 31.84469986 : Time 635.82s : 11958.84 words/s
[2019-07-02 16:33:42] Ep. 23 : Up. 566000 : Sen. 663,710 : Cost 31.66282082 : Time 610.24s : 12396.53 words/s
[2019-07-02 16:43:53] Ep. 23 : Up. 568000 : Sen. 1,065,017 : Cost 31.69857025 : Time 610.63s : 12373.57 words/s
[2019-07-02 16:54:00] Ep. 23 : Up. 570000 : Sen. 1,465,192 : Cost 31.90407944 : Time 607.16s : 12421.53 words/s
[2019-07-02 17:04:06] Ep. 23 : Up. 572000 : Sen. 1,866,150 : Cost 31.82835388 : Time 605.51s : 12490.31 words/s
[2019-07-02 17:14:14] Ep. 23 : Up. 574000 : Sen. 2,268,637 : Cost 32.00835800 : Time 608.07s : 12482.07 words/s
[2019-07-02 17:24:19] Ep. 23 : Up. 576000 : Sen. 2,669,608 : Cost 32.04054642 : Time 605.57s : 12489.32 words/s
[2019-07-02 17:34:27] Ep. 23 : Up. 578000 : Sen. 3,072,156 : Cost 32.10929489 : Time 607.64s : 12486.60 words/s
[2019-07-02 17:44:33] Ep. 23 : Up. 580000 : Sen. 3,474,078 : Cost 32.12803650 : Time 605.87s : 12511.14 words/s
[2019-07-02 17:44:33] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-02 17:44:42] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter580000.npz
[2019-07-02 17:44:49] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-02 17:44:59] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-07-02 17:45:20] [valid] Ep. 23 : Up. 580000 : cross-entropy : 48.5652 : stalled 2 times (last best: 48.4412)
[2019-07-02 17:45:24] [valid] Ep. 23 : Up. 580000 : perplexity : 6.76919 : stalled 2 times (last best: 6.73623)
[2019-07-02 17:46:06] [valid] Ep. 23 : Up. 580000 : translation : 30.62 : stalled 5 times (last best: 30.82)
[2019-07-02 17:56:15] Ep. 23 : Up. 582000 : Sen. 3,875,638 : Cost 31.96359444 : Time 702.22s : 10759.66 words/s
[2019-07-02 18:06:21] Ep. 23 : Up. 584000 : Sen. 4,278,024 : Cost 32.15238190 : Time 605.51s : 12491.34 words/s
[2019-07-02 18:16:28] Ep. 23 : Up. 586000 : Sen. 4,681,577 : Cost 32.34947586 : Time 607.88s : 12530.22 words/s
[2019-07-02 18:26:35] Ep. 23 : Up. 588000 : Sen. 5,083,370 : Cost 32.29791641 : Time 606.41s : 12497.87 words/s
[2019-07-02 18:27:51] Seen 5133815 samples
[2019-07-02 18:27:51] Starting epoch 24
[2019-07-02 18:27:51] [data] Shuffling data
[2019-07-02 18:27:54] [data] Done reading 5861713 sentences
[2019-07-02 18:28:15] [data] Done shuffling 5861713 sentences to temp files
[2019-07-02 18:37:08] Ep. 24 : Up. 590000 : Sen. 349,538 : Cost 31.55404091 : Time 633.62s : 11890.96 words/s
[2019-07-02 18:47:17] Ep. 24 : Up. 592000 : Sen. 751,510 : Cost 31.60062408 : Time 608.13s : 12442.67 words/s
[2019-07-02 18:57:24] Ep. 24 : Up. 594000 : Sen. 1,154,582 : Cost 31.65337944 : Time 607.11s : 12501.22 words/s
[2019-07-02 19:07:28] Ep. 24 : Up. 596000 : Sen. 1,554,732 : Cost 31.88042450 : Time 604.20s : 12491.76 words/s
[2019-07-02 19:17:32] Ep. 24 : Up. 598000 : Sen. 1,955,925 : Cost 31.77573967 : Time 604.10s : 12514.59 words/s
[2019-07-02 19:27:37] Ep. 24 : Up. 600000 : Sen. 2,355,713 : Cost 31.93260956 : Time 605.13s : 12427.22 words/s
[2019-07-02 19:27:37] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-02 19:27:47] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter600000.npz
[2019-07-02 19:27:53] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-02 19:28:03] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-07-02 19:28:24] [valid] Ep. 24 : Up. 600000 : cross-entropy : 48.5442 : stalled 3 times (last best: 48.4412)
[2019-07-02 19:28:28] [valid] Ep. 24 : Up. 600000 : perplexity : 6.7636 : stalled 3 times (last best: 6.73623)
[2019-07-02 19:29:11] [valid] Ep. 24 : Up. 600000 : translation : 30.64 : stalled 6 times (last best: 30.82)
[2019-07-02 19:39:23] Ep. 24 : Up. 602000 : Sen. 2,759,456 : Cost 31.85912323 : Time 706.03s : 10768.61 words/s
[2019-07-02 19:49:38] Ep. 24 : Up. 604000 : Sen. 3,164,254 : Cost 31.99844360 : Time 615.08s : 12394.94 words/s
[2019-07-02 19:59:54] Ep. 24 : Up. 606000 : Sen. 3,564,956 : Cost 32.17001343 : Time 616.20s : 12273.73 words/s
[2019-07-02 20:10:09] Ep. 24 : Up. 608000 : Sen. 3,964,454 : Cost 31.89693260 : Time 614.51s : 12251.29 words/s
[2019-07-02 20:20:26] Ep. 24 : Up. 610000 : Sen. 4,367,572 : Cost 31.91745567 : Time 616.54s : 12321.68 words/s
[2019-07-02 20:30:42] Ep. 24 : Up. 612000 : Sen. 4,767,056 : Cost 32.10659027 : Time 616.21s : 12234.42 words/s
[2019-07-02 20:40:07] Seen 5133815 samples
[2019-07-02 20:40:07] Starting epoch 25
[2019-07-02 20:40:07] [data] Shuffling data
[2019-07-02 20:40:31] [data] Done reading 5861713 sentences
[2019-07-02 20:41:11] [data] Done shuffling 5861713 sentences to temp files
[2019-07-02 20:42:05] Ep. 25 : Up. 614000 : Sen. 34,348 : Cost 32.25561523 : Time 683.20s : 11091.46 words/s
[2019-07-02 20:52:21] Ep. 25 : Up. 616000 : Sen. 435,764 : Cost 31.23766136 : Time 616.28s : 12269.12 words/s
[2019-07-02 21:02:44] Ep. 25 : Up. 618000 : Sen. 840,020 : Cost 31.54567146 : Time 622.52s : 12219.30 words/s
[2019-07-02 21:12:48] Ep. 25 : Up. 620000 : Sen. 1,239,669 : Cost 31.74164009 : Time 604.77s : 12453.69 words/s
[2019-07-02 21:12:48] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-02 21:12:58] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter620000.npz
[2019-07-02 21:13:05] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-02 21:13:15] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-07-02 21:13:37] [valid] Ep. 25 : Up. 620000 : cross-entropy : 48.5415 : stalled 4 times (last best: 48.4412)
[2019-07-02 21:13:40] [valid] Ep. 25 : Up. 620000 : perplexity : 6.76288 : stalled 4 times (last best: 6.73623)
[2019-07-02 21:14:22] [valid] Ep. 25 : Up. 620000 : translation : 30.75 : stalled 7 times (last best: 30.82)
[2019-07-02 21:24:29] Ep. 25 : Up. 622000 : Sen. 1,639,736 : Cost 31.65116119 : Time 701.00s : 10747.22 words/s
[2019-07-02 21:34:33] Ep. 25 : Up. 624000 : Sen. 2,037,690 : Cost 32.01162338 : Time 604.00s : 12441.68 words/s
[2019-07-02 21:44:41] Ep. 25 : Up. 626000 : Sen. 2,441,228 : Cost 31.71380234 : Time 607.99s : 12501.06 words/s
[2019-07-02 21:54:48] Ep. 25 : Up. 628000 : Sen. 2,843,310 : Cost 31.89864922 : Time 606.05s : 12508.82 words/s
[2019-07-02 22:04:54] Ep. 25 : Up. 630000 : Sen. 3,244,234 : Cost 31.88984489 : Time 606.79s : 12453.63 words/s
[2019-07-02 22:15:01] Ep. 25 : Up. 632000 : Sen. 3,646,510 : Cost 31.83349991 : Time 606.19s : 12506.92 words/s
[2019-07-02 22:25:08] Ep. 25 : Up. 634000 : Sen. 4,049,050 : Cost 31.92564774 : Time 607.56s : 12500.06 words/s
[2019-07-02 22:35:14] Ep. 25 : Up. 636000 : Sen. 4,449,032 : Cost 32.06746292 : Time 605.96s : 12451.13 words/s
[2019-07-02 22:45:18] Ep. 25 : Up. 638000 : Sen. 4,850,216 : Cost 31.80860329 : Time 604.05s : 12496.08 words/s
[2019-07-02 22:52:28] Seen 5133815 samples
[2019-07-02 22:52:28] Starting epoch 26
[2019-07-02 22:52:28] [data] Shuffling data
[2019-07-02 22:52:32] [data] Done reading 5861713 sentences
[2019-07-02 22:52:53] [data] Done shuffling 5861713 sentences to temp files
[2019-07-02 22:55:54] Ep. 26 : Up. 640000 : Sen. 117,071 : Cost 31.72719002 : Time 635.74s : 11879.00 words/s
[2019-07-02 22:55:54] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-02 22:56:04] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.iter640000.npz
[2019-07-02 22:56:11] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-02 22:56:20] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
[2019-07-02 22:56:42] [valid] Ep. 26 : Up. 640000 : cross-entropy : 48.4518 : stalled 5 times (last best: 48.4412)
[2019-07-02 22:56:46] [valid] Ep. 26 : Up. 640000 : perplexity : 6.73903 : stalled 5 times (last best: 6.73623)
[2019-07-02 22:57:28] [valid] Ep. 26 : Up. 640000 : translation : 30.7 : stalled 8 times (last best: 30.82)
[2019-07-02 22:57:31] Training finished
[2019-07-02 22:57:36] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.orig.npz
[2019-07-02 22:57:46] Saving model to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz
[2019-07-02 22:57:56] Saving Adam parameters to ../experiments/100M_fasttext_prob_filtered_dcce_scoring/model/model.npz.optimizer.npz
