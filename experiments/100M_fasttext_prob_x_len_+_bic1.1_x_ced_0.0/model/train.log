[2019-07-10 19:01:31] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-10 19:01:31] [marian] Running on snotra as process 31951 with command line:
[2019-07-10 19:01:31] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz -T . --devices 1 --train-sets ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.de ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.en --vocabs ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.de.json ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.en.json --mini-batch-fit -w 6000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/dev.bpe.de ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/dev.out --valid-script-path ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/train.log --valid-log ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/valid.log
[2019-07-10 19:01:31] [config] after-batches: 0
[2019-07-10 19:01:31] [config] after-epochs: 0
[2019-07-10 19:01:31] [config] allow-unk: false
[2019-07-10 19:01:31] [config] beam-size: 12
[2019-07-10 19:01:31] [config] bert-class-symbol: "[CLS]"
[2019-07-10 19:01:31] [config] bert-mask-symbol: "[MASK]"
[2019-07-10 19:01:31] [config] bert-masking-fraction: 0.15
[2019-07-10 19:01:31] [config] bert-sep-symbol: "[SEP]"
[2019-07-10 19:01:31] [config] bert-train-type-embeddings: true
[2019-07-10 19:01:31] [config] bert-type-vocab-size: 2
[2019-07-10 19:01:31] [config] best-deep: false
[2019-07-10 19:01:31] [config] clip-gemm: 0
[2019-07-10 19:01:31] [config] clip-norm: 1
[2019-07-10 19:01:31] [config] cost-type: ce-mean
[2019-07-10 19:01:31] [config] cpu-threads: 0
[2019-07-10 19:01:31] [config] data-weighting: ""
[2019-07-10 19:01:31] [config] data-weighting-type: sentence
[2019-07-10 19:01:31] [config] dec-cell: gru
[2019-07-10 19:01:31] [config] dec-cell-base-depth: 2
[2019-07-10 19:01:31] [config] dec-cell-high-depth: 1
[2019-07-10 19:01:31] [config] dec-depth: 1
[2019-07-10 19:01:31] [config] devices:
[2019-07-10 19:01:31] [config]   - 1
[2019-07-10 19:01:31] [config] dim-emb: 512
[2019-07-10 19:01:31] [config] dim-rnn: 1024
[2019-07-10 19:01:31] [config] dim-vocabs:
[2019-07-10 19:01:31] [config]   - 50000
[2019-07-10 19:01:31] [config]   - 50000
[2019-07-10 19:01:31] [config] disp-first: 0
[2019-07-10 19:01:31] [config] disp-freq: 2000
[2019-07-10 19:01:31] [config] disp-label-counts: false
[2019-07-10 19:01:31] [config] dropout-rnn: 0.2
[2019-07-10 19:01:31] [config] dropout-src: 0.1
[2019-07-10 19:01:31] [config] dropout-trg: 0.1
[2019-07-10 19:01:31] [config] dump-config: ""
[2019-07-10 19:01:31] [config] early-stopping: 5
[2019-07-10 19:01:31] [config] embedding-fix-src: false
[2019-07-10 19:01:31] [config] embedding-fix-trg: false
[2019-07-10 19:01:31] [config] embedding-normalization: false
[2019-07-10 19:01:31] [config] embedding-vectors:
[2019-07-10 19:01:31] [config]   []
[2019-07-10 19:01:31] [config] enc-cell: gru
[2019-07-10 19:01:31] [config] enc-cell-depth: 1
[2019-07-10 19:01:31] [config] enc-depth: 1
[2019-07-10 19:01:31] [config] enc-type: bidirectional
[2019-07-10 19:01:31] [config] exponential-smoothing: 0.0001
[2019-07-10 19:01:31] [config] grad-dropping-momentum: 0
[2019-07-10 19:01:31] [config] grad-dropping-rate: 0
[2019-07-10 19:01:31] [config] grad-dropping-warmup: 100
[2019-07-10 19:01:31] [config] guided-alignment: none
[2019-07-10 19:01:31] [config] guided-alignment-cost: mse
[2019-07-10 19:01:31] [config] guided-alignment-weight: 0.1
[2019-07-10 19:01:31] [config] ignore-model-config: false
[2019-07-10 19:01:31] [config] input-types:
[2019-07-10 19:01:31] [config]   []
[2019-07-10 19:01:31] [config] interpolate-env-vars: false
[2019-07-10 19:01:31] [config] keep-best: false
[2019-07-10 19:01:31] [config] label-smoothing: 0
[2019-07-10 19:01:31] [config] layer-normalization: true
[2019-07-10 19:01:31] [config] learn-rate: 0.0001
[2019-07-10 19:01:31] [config] log: ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/train.log
[2019-07-10 19:01:31] [config] log-level: info
[2019-07-10 19:01:31] [config] log-time-zone: ""
[2019-07-10 19:01:31] [config] lr-decay: 0
[2019-07-10 19:01:31] [config] lr-decay-freq: 50000
[2019-07-10 19:01:31] [config] lr-decay-inv-sqrt:
[2019-07-10 19:01:31] [config]   - 0
[2019-07-10 19:01:31] [config] lr-decay-repeat-warmup: false
[2019-07-10 19:01:31] [config] lr-decay-reset-optimizer: false
[2019-07-10 19:01:31] [config] lr-decay-start:
[2019-07-10 19:01:31] [config]   - 10
[2019-07-10 19:01:31] [config]   - 1
[2019-07-10 19:01:31] [config] lr-decay-strategy: epoch+stalled
[2019-07-10 19:01:31] [config] lr-report: false
[2019-07-10 19:01:31] [config] lr-warmup: 0
[2019-07-10 19:01:31] [config] lr-warmup-at-reload: false
[2019-07-10 19:01:31] [config] lr-warmup-cycle: false
[2019-07-10 19:01:31] [config] lr-warmup-start-rate: 0
[2019-07-10 19:01:31] [config] max-length: 50
[2019-07-10 19:01:31] [config] max-length-crop: false
[2019-07-10 19:01:31] [config] max-length-factor: 3
[2019-07-10 19:01:31] [config] maxi-batch: 100
[2019-07-10 19:01:31] [config] maxi-batch-sort: trg
[2019-07-10 19:01:31] [config] mini-batch: 64
[2019-07-10 19:01:31] [config] mini-batch-fit: true
[2019-07-10 19:01:31] [config] mini-batch-fit-step: 10
[2019-07-10 19:01:31] [config] mini-batch-overstuff: 1
[2019-07-10 19:01:31] [config] mini-batch-track-lr: false
[2019-07-10 19:01:31] [config] mini-batch-understuff: 1
[2019-07-10 19:01:31] [config] mini-batch-warmup: 0
[2019-07-10 19:01:31] [config] mini-batch-words: 0
[2019-07-10 19:01:31] [config] mini-batch-words-ref: 0
[2019-07-10 19:01:31] [config] model: ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-10 19:01:31] [config] multi-loss-type: sum
[2019-07-10 19:01:31] [config] multi-node: false
[2019-07-10 19:01:31] [config] multi-node-overlap: true
[2019-07-10 19:01:31] [config] n-best: false
[2019-07-10 19:01:31] [config] no-nccl: false
[2019-07-10 19:01:31] [config] no-reload: false
[2019-07-10 19:01:31] [config] no-restore-corpus: false
[2019-07-10 19:01:31] [config] no-shuffle: false
[2019-07-10 19:01:31] [config] normalize: 1
[2019-07-10 19:01:31] [config] num-devices: 0
[2019-07-10 19:01:31] [config] optimizer: adam
[2019-07-10 19:01:31] [config] optimizer-delay: 1
[2019-07-10 19:01:31] [config] optimizer-params:
[2019-07-10 19:01:31] [config]   []
[2019-07-10 19:01:31] [config] overwrite: false
[2019-07-10 19:01:31] [config] pretrained-model: ""
[2019-07-10 19:01:31] [config] quiet: false
[2019-07-10 19:01:31] [config] quiet-translation: true
[2019-07-10 19:01:31] [config] relative-paths: false
[2019-07-10 19:01:31] [config] right-left: false
[2019-07-10 19:01:31] [config] save-freq: 20000
[2019-07-10 19:01:31] [config] seed: 1111
[2019-07-10 19:01:31] [config] shuffle-in-ram: false
[2019-07-10 19:01:31] [config] skip: false
[2019-07-10 19:01:31] [config] sqlite: ""
[2019-07-10 19:01:31] [config] sqlite-drop: false
[2019-07-10 19:01:31] [config] sync-sgd: true
[2019-07-10 19:01:31] [config] tempdir: .
[2019-07-10 19:01:31] [config] tied-embeddings: false
[2019-07-10 19:01:31] [config] tied-embeddings-all: false
[2019-07-10 19:01:31] [config] tied-embeddings-src: false
[2019-07-10 19:01:31] [config] train-sets:
[2019-07-10 19:01:31] [config]   - ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.de
[2019-07-10 19:01:31] [config]   - ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.en
[2019-07-10 19:01:31] [config] transformer-aan-activation: swish
[2019-07-10 19:01:31] [config] transformer-aan-depth: 2
[2019-07-10 19:01:31] [config] transformer-aan-nogate: false
[2019-07-10 19:01:31] [config] transformer-decoder-autoreg: self-attention
[2019-07-10 19:01:31] [config] transformer-dim-aan: 2048
[2019-07-10 19:01:31] [config] transformer-dim-ffn: 2048
[2019-07-10 19:01:31] [config] transformer-dropout: 0
[2019-07-10 19:01:31] [config] transformer-dropout-attention: 0
[2019-07-10 19:01:31] [config] transformer-dropout-ffn: 0
[2019-07-10 19:01:31] [config] transformer-ffn-activation: swish
[2019-07-10 19:01:31] [config] transformer-ffn-depth: 2
[2019-07-10 19:01:31] [config] transformer-guided-alignment-layer: last
[2019-07-10 19:01:31] [config] transformer-heads: 8
[2019-07-10 19:01:31] [config] transformer-no-projection: false
[2019-07-10 19:01:31] [config] transformer-postprocess: dan
[2019-07-10 19:01:31] [config] transformer-postprocess-emb: d
[2019-07-10 19:01:31] [config] transformer-preprocess: ""
[2019-07-10 19:01:31] [config] transformer-tied-layers:
[2019-07-10 19:01:31] [config]   []
[2019-07-10 19:01:31] [config] transformer-train-position-embeddings: false
[2019-07-10 19:01:31] [config] type: amun
[2019-07-10 19:01:31] [config] ulr: false
[2019-07-10 19:01:31] [config] ulr-dim-emb: 0
[2019-07-10 19:01:31] [config] ulr-dropout: 0
[2019-07-10 19:01:31] [config] ulr-keys-vectors: ""
[2019-07-10 19:01:31] [config] ulr-query-vectors: ""
[2019-07-10 19:01:31] [config] ulr-softmax-temperature: 1
[2019-07-10 19:01:31] [config] ulr-trainable-transformation: false
[2019-07-10 19:01:31] [config] valid-freq: 20000
[2019-07-10 19:01:31] [config] valid-log: ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/valid.log
[2019-07-10 19:01:31] [config] valid-max-length: 1000
[2019-07-10 19:01:31] [config] valid-metrics:
[2019-07-10 19:01:31] [config]   - cross-entropy
[2019-07-10 19:01:31] [config]   - perplexity
[2019-07-10 19:01:31] [config]   - translation
[2019-07-10 19:01:31] [config] valid-mini-batch: 8
[2019-07-10 19:01:31] [config] valid-script-path: ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/score-dev.sh
[2019-07-10 19:01:31] [config] valid-sets:
[2019-07-10 19:01:31] [config]   - ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/dev.bpe.de
[2019-07-10 19:01:31] [config]   - ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/dev.bpe.en
[2019-07-10 19:01:31] [config] valid-translation-output: ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/dev.out
[2019-07-10 19:01:31] [config] vocabs:
[2019-07-10 19:01:31] [config]   - ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.de.json
[2019-07-10 19:01:31] [config]   - ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.en.json
[2019-07-10 19:01:31] [config] word-penalty: 0
[2019-07-10 19:01:31] [config] workspace: 6000
[2019-07-10 19:01:31] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-10 19:01:31] Using synchronous training
[2019-07-10 19:01:31] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.de.json
[2019-07-10 19:01:31] [data] Using unused word id eos for 0
[2019-07-10 19:01:31] [data] Using unused word id UNK for 1
[2019-07-10 19:01:31] [data] Setting vocabulary size for input 0 to 50000
[2019-07-10 19:01:31] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.en.json
[2019-07-10 19:01:32] [data] Using unused word id eos for 0
[2019-07-10 19:01:32] [data] Using unused word id UNK for 1
[2019-07-10 19:01:32] [data] Setting vocabulary size for input 1 to 50000
[2019-07-10 19:01:32] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-10 19:01:32] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-10 19:01:33] [memory] Extending reserved space to 6016 MB (device gpu1)
[2019-07-10 19:01:33] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-10 19:01:33] [comm] NCCLCommunicator constructed successfully.
[2019-07-10 19:01:33] [training] Using 1 GPUs
[2019-07-10 19:01:33] [memory] Reserving 422 MB, device gpu1
[2019-07-10 19:01:33] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-10 19:01:33] [memory] Reserving 422 MB, device gpu1
[2019-07-10 19:01:44] [batching] Done. Typical MB size is 8096 target words
[2019-07-10 19:01:44] [memory] Extending reserved space to 6016 MB (device gpu1)
[2019-07-10 19:01:44] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-10 19:01:44] [comm] NCCLCommunicator constructed successfully.
[2019-07-10 19:01:44] [training] Using 1 GPUs
[2019-07-10 19:01:44] Training started
[2019-07-10 19:01:44] [data] Shuffling data
[2019-07-10 19:01:47] [data] Done reading 4393817 sentences
[2019-07-10 19:02:12] [data] Done shuffling 4393817 sentences to temp files
[2019-07-10 19:02:30] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-07-10 19:02:30] [memory] Reserving 422 MB, device gpu1
[2019-07-10 19:02:30] [memory] Reserving 422 MB, device gpu1
[2019-07-10 19:02:30] [memory] Reserving 422 MB, device gpu1
[2019-07-10 19:02:30] [memory] Reserving 844 MB, device gpu1
[2019-07-10 19:20:35] Ep. 1 : Up. 2000 : Sen. 366,103 : Cost 147.70780945 : Time 1143.39s : 8017.39 words/s
[2019-07-10 19:39:31] Ep. 1 : Up. 4000 : Sen. 732,493 : Cost 117.66608429 : Time 1135.62s : 8078.38 words/s
[2019-07-10 19:58:14] Ep. 1 : Up. 6000 : Sen. 1,097,943 : Cost 102.01087952 : Time 1123.03s : 8138.59 words/s
[2019-07-10 20:16:55] Ep. 1 : Up. 8000 : Sen. 1,462,248 : Cost 92.31896210 : Time 1121.86s : 8127.11 words/s
[2019-07-10 20:35:23] Ep. 1 : Up. 10000 : Sen. 1,827,337 : Cost 86.14345551 : Time 1107.30s : 8255.38 words/s
[2019-07-10 20:53:57] Ep. 1 : Up. 12000 : Sen. 2,193,774 : Cost 81.69496918 : Time 1114.32s : 8226.41 words/s
[2019-07-10 21:12:02] Ep. 1 : Up. 14000 : Sen. 2,560,000 : Cost 78.47298431 : Time 1084.94s : 8453.57 words/s
[2019-07-10 21:30:43] Ep. 1 : Up. 16000 : Sen. 2,925,177 : Cost 75.95338440 : Time 1120.99s : 8149.91 words/s
[2019-07-10 21:49:34] Ep. 1 : Up. 18000 : Sen. 3,290,926 : Cost 74.03479767 : Time 1131.12s : 8090.66 words/s
[2019-07-10 22:03:17] Seen 3567162 samples
[2019-07-10 22:03:17] Starting epoch 2
[2019-07-10 22:03:17] [data] Shuffling data
[2019-07-10 22:03:20] [data] Done reading 4393817 sentences
[2019-07-10 22:03:48] [data] Done shuffling 4393817 sentences to temp files
[2019-07-10 22:08:47] Ep. 2 : Up. 20000 : Sen. 89,282 : Cost 71.97331238 : Time 1152.70s : 7931.80 words/s
[2019-07-10 22:08:47] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-10 22:08:57] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.iter20000.npz
[2019-07-10 22:09:05] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-10 22:09:16] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-10 22:09:47] [valid] Ep. 2 : Up. 20000 : cross-entropy : 63.922 : new best
[2019-07-10 22:09:57] [valid] Ep. 2 : Up. 20000 : perplexity : 12.4816 : new best
[2019-07-10 22:11:23] [valid] Ep. 2 : Up. 20000 : translation : 24.68 : new best
[2019-07-10 22:33:09] Ep. 2 : Up. 22000 : Sen. 454,968 : Cost 70.00180817 : Time 1461.73s : 6258.93 words/s
[2019-07-10 22:56:43] Ep. 2 : Up. 24000 : Sen. 820,149 : Cost 68.88371277 : Time 1414.51s : 6463.93 words/s
[2019-07-10 23:29:02] Ep. 2 : Up. 26000 : Sen. 1,186,717 : Cost 67.57395935 : Time 1938.89s : 4725.61 words/s
[2019-07-11 00:03:39] Ep. 2 : Up. 28000 : Sen. 1,551,444 : Cost 66.98849487 : Time 2076.94s : 4394.81 words/s
[2019-07-11 00:39:45] Ep. 2 : Up. 30000 : Sen. 1,916,942 : Cost 66.49111176 : Time 2165.87s : 4224.66 words/s
[2019-07-11 01:10:06] Ep. 2 : Up. 32000 : Sen. 2,281,460 : Cost 65.65747070 : Time 1821.55s : 5020.13 words/s
[2019-07-11 01:39:31] Ep. 2 : Up. 34000 : Sen. 2,648,810 : Cost 64.89790344 : Time 1765.05s : 5209.47 words/s
[2019-07-11 02:10:40] Ep. 2 : Up. 36000 : Sen. 3,014,003 : Cost 64.28236389 : Time 1868.20s : 4893.15 words/s
[2019-07-11 02:38:37] Ep. 2 : Up. 38000 : Sen. 3,380,634 : Cost 63.50762939 : Time 1677.68s : 5471.82 words/s
[2019-07-11 02:55:42] Seen 3567162 samples
[2019-07-11 02:55:42] Starting epoch 3
[2019-07-11 02:55:42] [data] Shuffling data
[2019-07-11 02:55:52] [data] Done reading 4393817 sentences
[2019-07-11 02:57:12] [data] Done shuffling 4393817 sentences to temp files
[2019-07-11 03:13:20] Ep. 3 : Up. 40000 : Sen. 179,836 : Cost 62.54677963 : Time 2082.44s : 4403.32 words/s
[2019-07-11 03:13:20] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-11 03:13:37] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.iter40000.npz
[2019-07-11 03:13:50] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-11 03:14:07] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-11 03:14:52] [valid] Ep. 3 : Up. 40000 : cross-entropy : 54.4575 : new best
[2019-07-11 03:15:05] [valid] Ep. 3 : Up. 40000 : perplexity : 8.58921 : new best
[2019-07-11 03:17:39] [valid] Ep. 3 : Up. 40000 : translation : 27.7 : new best
[2019-07-11 03:46:11] Ep. 3 : Up. 42000 : Sen. 546,782 : Cost 61.61687088 : Time 1971.60s : 4660.06 words/s
[2019-07-11 04:17:23] Ep. 3 : Up. 44000 : Sen. 912,715 : Cost 61.51372528 : Time 1871.37s : 4898.57 words/s
[2019-07-11 04:43:56] Ep. 3 : Up. 46000 : Sen. 1,278,777 : Cost 60.99953079 : Time 1593.28s : 5741.96 words/s
[2019-07-11 05:08:48] Ep. 3 : Up. 48000 : Sen. 1,644,597 : Cost 60.78819275 : Time 1491.85s : 6138.80 words/s
[2019-07-11 05:37:16] Ep. 3 : Up. 50000 : Sen. 2,010,077 : Cost 60.43497849 : Time 1707.87s : 5359.01 words/s
[2019-07-11 06:01:27] Ep. 3 : Up. 52000 : Sen. 2,375,521 : Cost 60.04124832 : Time 1451.07s : 6294.96 words/s
[2019-07-11 06:22:45] Ep. 3 : Up. 54000 : Sen. 2,740,313 : Cost 60.08911896 : Time 1278.16s : 7145.96 words/s
[2019-07-11 06:42:10] Ep. 3 : Up. 56000 : Sen. 3,106,163 : Cost 59.46632767 : Time 1164.73s : 7856.79 words/s
[2019-07-11 07:01:19] Ep. 3 : Up. 58000 : Sen. 3,471,471 : Cost 59.20803452 : Time 1149.44s : 7961.10 words/s
[2019-07-11 07:06:11] Seen 3567162 samples
[2019-07-11 07:06:11] Starting epoch 4
[2019-07-11 07:06:11] [data] Shuffling data
[2019-07-11 07:06:16] [data] Done reading 4393817 sentences
[2019-07-11 07:06:47] [data] Done shuffling 4393817 sentences to temp files
[2019-07-11 07:21:59] Ep. 4 : Up. 60000 : Sen. 270,588 : Cost 58.15282822 : Time 1239.92s : 7392.36 words/s
[2019-07-11 07:21:59] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-11 07:22:10] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.iter60000.npz
[2019-07-11 07:22:17] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-11 07:22:28] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-11 07:23:00] [valid] Ep. 4 : Up. 60000 : cross-entropy : 51.0542 : new best
[2019-07-11 07:23:09] [valid] Ep. 4 : Up. 60000 : perplexity : 7.50906 : new best
[2019-07-11 07:24:27] [valid] Ep. 4 : Up. 60000 : translation : 29.32 : new best
[2019-07-11 07:42:48] Ep. 4 : Up. 62000 : Sen. 637,835 : Cost 57.77971268 : Time 1248.50s : 7357.32 words/s
[2019-07-11 08:02:39] Ep. 4 : Up. 64000 : Sen. 1,002,840 : Cost 57.69633865 : Time 1191.28s : 7681.80 words/s
[2019-07-11 08:20:52] Ep. 4 : Up. 66000 : Sen. 1,368,362 : Cost 57.68210983 : Time 1092.99s : 8366.25 words/s
[2019-07-11 08:38:41] Ep. 4 : Up. 68000 : Sen. 1,734,241 : Cost 57.55116272 : Time 1069.44s : 8563.60 words/s
[2019-07-11 08:57:18] Ep. 4 : Up. 70000 : Sen. 2,100,154 : Cost 57.40359116 : Time 1117.04s : 8200.30 words/s
[2019-07-11 09:15:03] Ep. 4 : Up. 72000 : Sen. 2,464,954 : Cost 57.19059753 : Time 1064.97s : 8584.59 words/s
[2019-07-11 09:32:43] Ep. 4 : Up. 74000 : Sen. 2,830,975 : Cost 56.90869141 : Time 1059.43s : 8645.95 words/s
[2019-07-11 09:50:24] Ep. 4 : Up. 76000 : Sen. 3,196,954 : Cost 56.79660797 : Time 1060.62s : 8636.48 words/s
[2019-07-11 10:08:05] Ep. 4 : Up. 78000 : Sen. 3,562,049 : Cost 56.64931488 : Time 1061.90s : 8581.33 words/s
[2019-07-11 10:08:21] Seen 3567162 samples
[2019-07-11 10:08:21] Starting epoch 5
[2019-07-11 10:08:21] [data] Shuffling data
[2019-07-11 10:08:25] [data] Done reading 4393817 sentences
[2019-07-11 10:08:45] [data] Done shuffling 4393817 sentences to temp files
[2019-07-11 10:26:18] Ep. 5 : Up. 80000 : Sen. 360,742 : Cost 55.44797897 : Time 1092.57s : 8377.38 words/s
[2019-07-11 10:26:18] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-11 10:26:28] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.iter80000.npz
[2019-07-11 10:26:35] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-11 10:26:46] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-11 10:27:19] [valid] Ep. 5 : Up. 80000 : cross-entropy : 49.5516 : new best
[2019-07-11 10:27:28] [valid] Ep. 5 : Up. 80000 : perplexity : 7.07647 : new best
[2019-07-11 10:28:37] [valid] Ep. 5 : Up. 80000 : translation : 30.34 : new best
[2019-07-11 10:46:25] Ep. 5 : Up. 82000 : Sen. 726,074 : Cost 55.61944199 : Time 1207.26s : 7587.20 words/s
[2019-07-11 11:04:03] Ep. 5 : Up. 84000 : Sen. 1,091,209 : Cost 55.27957535 : Time 1057.79s : 8636.51 words/s
[2019-07-11 11:21:50] Ep. 5 : Up. 86000 : Sen. 1,456,707 : Cost 55.38425446 : Time 1066.72s : 8582.30 words/s
[2019-07-11 11:39:37] Ep. 5 : Up. 88000 : Sen. 1,823,638 : Cost 55.12649155 : Time 1066.95s : 8596.38 words/s
[2019-07-11 11:57:32] Ep. 5 : Up. 90000 : Sen. 2,189,568 : Cost 55.18604660 : Time 1075.65s : 8506.82 words/s
[2019-07-11 12:15:24] Ep. 5 : Up. 92000 : Sen. 2,555,220 : Cost 55.37491989 : Time 1071.18s : 8550.86 words/s
[2019-07-11 12:33:33] Ep. 5 : Up. 94000 : Sen. 2,920,995 : Cost 55.10649872 : Time 1089.06s : 8418.28 words/s
[2019-07-11 12:52:27] Ep. 5 : Up. 96000 : Sen. 3,286,203 : Cost 55.14376068 : Time 1134.22s : 8049.66 words/s
[2019-07-11 13:08:39] Seen 3567162 samples
[2019-07-11 13:08:39] Starting epoch 6
[2019-07-11 13:08:39] [data] Shuffling data
[2019-07-11 13:08:42] [data] Done reading 4393817 sentences
[2019-07-11 13:09:05] [data] Done shuffling 4393817 sentences to temp files
[2019-07-11 13:13:59] Ep. 6 : Up. 98000 : Sen. 85,482 : Cost 54.50614548 : Time 1292.50s : 7091.30 words/s
[2019-07-11 13:33:05] Ep. 6 : Up. 100000 : Sen. 451,024 : Cost 53.96322632 : Time 1145.32s : 8005.85 words/s
[2019-07-11 13:33:05] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-11 13:33:14] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.iter100000.npz
[2019-07-11 13:33:27] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-11 13:33:43] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-11 13:34:16] [valid] Ep. 6 : Up. 100000 : cross-entropy : 48.4189 : new best
[2019-07-11 13:34:24] [valid] Ep. 6 : Up. 100000 : perplexity : 6.76689 : new best
[2019-07-11 13:35:30] [valid] Ep. 6 : Up. 100000 : translation : 30.63 : new best
[2019-07-11 13:53:17] Ep. 6 : Up. 102000 : Sen. 817,028 : Cost 53.68659973 : Time 1212.36s : 7540.79 words/s
[2019-07-11 14:11:02] Ep. 6 : Up. 104000 : Sen. 1,182,530 : Cost 53.89957809 : Time 1064.53s : 8608.77 words/s
[2019-07-11 14:29:18] Ep. 6 : Up. 106000 : Sen. 1,548,597 : Cost 53.83931351 : Time 1096.97s : 8348.50 words/s
[2019-07-11 14:47:31] Ep. 6 : Up. 108000 : Sen. 1,915,092 : Cost 53.72700119 : Time 1092.57s : 8393.31 words/s
[2019-07-11 15:05:24] Ep. 6 : Up. 110000 : Sen. 2,281,504 : Cost 53.70676041 : Time 1073.38s : 8536.35 words/s
[2019-07-11 15:23:19] Ep. 6 : Up. 112000 : Sen. 2,645,942 : Cost 53.86241913 : Time 1074.31s : 8505.81 words/s
[2019-07-11 15:41:12] Ep. 6 : Up. 114000 : Sen. 3,011,475 : Cost 53.46094513 : Time 1072.78s : 8523.47 words/s
[2019-07-11 15:59:03] Ep. 6 : Up. 116000 : Sen. 3,377,505 : Cost 53.82203674 : Time 1071.65s : 8547.18 words/s
[2019-07-11 16:08:21] Seen 3567162 samples
[2019-07-11 16:08:21] Starting epoch 7
[2019-07-11 16:08:21] [data] Shuffling data
[2019-07-11 16:08:26] [data] Done reading 4393817 sentences
[2019-07-11 16:08:55] [data] Done shuffling 4393817 sentences to temp files
[2019-07-11 16:17:42] Ep. 7 : Up. 118000 : Sen. 175,892 : Cost 53.16409683 : Time 1119.10s : 8170.06 words/s
[2019-07-11 16:35:40] Ep. 7 : Up. 120000 : Sen. 542,905 : Cost 52.57011032 : Time 1078.11s : 8529.20 words/s
[2019-07-11 16:35:40] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-11 16:35:50] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.iter120000.npz
[2019-07-11 16:35:57] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-11 16:36:07] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-11 16:36:33] [valid] Ep. 7 : Up. 120000 : cross-entropy : 47.5345 : new best
[2019-07-11 16:36:41] [valid] Ep. 7 : Up. 120000 : perplexity : 6.53464 : new best
[2019-07-11 16:37:42] [valid] Ep. 7 : Up. 120000 : translation : 31 : new best
[2019-07-11 16:55:19] Ep. 7 : Up. 122000 : Sen. 909,118 : Cost 52.36490631 : Time 1178.35s : 7783.23 words/s
[2019-07-11 17:12:57] Ep. 7 : Up. 124000 : Sen. 1,275,081 : Cost 52.59239960 : Time 1057.85s : 8659.28 words/s
[2019-07-11 17:30:27] Ep. 7 : Up. 126000 : Sen. 1,642,089 : Cost 52.64789963 : Time 1050.68s : 8733.95 words/s
[2019-07-11 17:48:03] Ep. 7 : Up. 128000 : Sen. 2,008,152 : Cost 52.64799118 : Time 1055.30s : 8689.65 words/s
[2019-07-11 18:05:36] Ep. 7 : Up. 130000 : Sen. 2,373,605 : Cost 52.67388535 : Time 1053.78s : 8665.79 words/s
[2019-07-11 18:23:17] Ep. 7 : Up. 132000 : Sen. 2,739,200 : Cost 52.64461899 : Time 1061.13s : 8619.10 words/s
[2019-07-11 18:41:11] Ep. 7 : Up. 134000 : Sen. 3,104,318 : Cost 52.64519501 : Time 1073.58s : 8523.84 words/s
[2019-07-11 18:58:56] Ep. 7 : Up. 136000 : Sen. 3,469,228 : Cost 52.38224030 : Time 1064.71s : 8572.84 words/s
[2019-07-11 19:03:42] Seen 3567162 samples
[2019-07-11 19:03:42] Starting epoch 8
[2019-07-11 19:03:42] [data] Shuffling data
[2019-07-11 19:03:45] [data] Done reading 4393817 sentences
[2019-07-11 19:03:58] [data] Done shuffling 4393817 sentences to temp files
[2019-07-11 19:17:03] Ep. 8 : Up. 138000 : Sen. 266,946 : Cost 51.74332809 : Time 1087.68s : 8404.93 words/s
[2019-07-11 19:34:45] Ep. 8 : Up. 140000 : Sen. 632,536 : Cost 51.52022934 : Time 1061.50s : 8607.41 words/s
[2019-07-11 19:34:45] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-11 19:34:54] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.iter140000.npz
[2019-07-11 19:35:01] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-11 19:35:11] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-11 19:35:38] [valid] Ep. 8 : Up. 140000 : cross-entropy : 46.9591 : new best
[2019-07-11 19:35:46] [valid] Ep. 8 : Up. 140000 : perplexity : 6.38785 : new best
[2019-07-11 19:36:50] [valid] Ep. 8 : Up. 140000 : translation : 31.36 : new best
[2019-07-11 19:54:34] Ep. 8 : Up. 142000 : Sen. 998,669 : Cost 51.49998856 : Time 1188.88s : 7715.27 words/s
[2019-07-11 20:12:22] Ep. 8 : Up. 144000 : Sen. 1,365,438 : Cost 51.72287750 : Time 1068.00s : 8602.79 words/s
[2019-07-11 20:30:03] Ep. 8 : Up. 146000 : Sen. 1,731,615 : Cost 51.75543976 : Time 1061.54s : 8645.36 words/s
[2019-07-11 20:47:44] Ep. 8 : Up. 148000 : Sen. 2,097,698 : Cost 51.73805237 : Time 1060.87s : 8620.36 words/s
[2019-07-11 21:05:28] Ep. 8 : Up. 150000 : Sen. 2,463,731 : Cost 51.84663773 : Time 1063.67s : 8619.92 words/s
[2019-07-11 21:23:11] Ep. 8 : Up. 152000 : Sen. 2,829,796 : Cost 51.62149429 : Time 1062.74s : 8597.76 words/s
[2019-07-11 21:40:55] Ep. 8 : Up. 154000 : Sen. 3,195,547 : Cost 51.91754532 : Time 1064.77s : 8618.22 words/s
[2019-07-11 21:58:50] Ep. 8 : Up. 156000 : Sen. 3,561,512 : Cost 51.76658249 : Time 1074.20s : 8524.74 words/s
[2019-07-11 21:59:05] Seen 3567162 samples
[2019-07-11 21:59:05] Starting epoch 9
[2019-07-11 21:59:05] [data] Shuffling data
[2019-07-11 21:59:08] [data] Done reading 4393817 sentences
[2019-07-11 21:59:31] [data] Done shuffling 4393817 sentences to temp files
[2019-07-11 22:17:09] Ep. 9 : Up. 158000 : Sen. 360,295 : Cost 50.58637238 : Time 1099.67s : 8322.54 words/s
[2019-07-11 22:36:14] Ep. 9 : Up. 160000 : Sen. 726,474 : Cost 50.92125320 : Time 1144.38s : 8011.10 words/s
[2019-07-11 22:36:14] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-11 22:36:25] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.iter160000.npz
[2019-07-11 22:36:33] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-11 22:36:46] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-11 22:37:18] [valid] Ep. 9 : Up. 160000 : cross-entropy : 46.5187 : new best
[2019-07-11 22:37:27] [valid] Ep. 9 : Up. 160000 : perplexity : 6.27771 : new best
[2019-07-11 22:38:42] Error: Unknown word id: 49994
[2019-07-11 22:38:42] Error: Aborted from virtual const string& marian::DefaultVocab::operator[](marian::Word) const in /fs/bil0/abdel/marian-dev/src/data/default_vocab.cpp:76

[CALL STACK]
[0x70f3a4]          marian::DefaultVocab::operator[][abi:  cxx11]  (unsigned int) const + 0x234
[0x7053da]          marian::DefaultVocab::decode[abi:  cxx11]  (std::vector<unsigned int,std::allocator<unsigned int>> const&,  bool) const + 0xba
[0x701874]          marian::Vocab::decode[abi:  cxx11]  (std::vector<unsigned int,std::allocator<unsigned int>> const&,  bool) const + 0x24
[0x5e16e1]          void marian::OutputPrinter::  print  <std::__cxx11::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>>(std::shared_ptr<marian::History>,  std::__cxx11::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>&,  std::__cxx11::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>&) + 0x5e1
[0x979c3f]          marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}::  operator()  (unsigned long) const + 0x2cf
[0x97a2d9]          std::future<std::result_of<marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}& (unsigned long&)>::type> marian::ThreadPool::enqueue<marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}&,unsigned long&>(std::result_of&&,(marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}&)...)::{lambda()#1}::  operator()  () const + 0x29
[0x97acdc]          std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base,std::__future_base::_Result_base::_Deleter> (),std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>,std::__future_base::_Result_base::_Deleter>,std::_Bind_simple<std::reference_wrapper<std::future<std::result_of<marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}& (unsigned long&)>::type> marian::ThreadPool::enqueue<marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}&,unsigned long&>(std::result_of&&,(marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}&)...)::{lambda()#1}> ()>,void>>::  _M_invoke [0x5a5f19]          std::__future_base::_State_baseV2::  _M_do_set  (std::function<std::unique_ptr<std::__future_base::_Result_base,std::__future_base::_Result_base::_Deleter> ()>*,  bool*) + 0x29
[0x7f72d3754a99]                                                       + 0xea99
[0x96d04f]          std::__future_base::_Task_state<std::future<std::result_of<marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}& (unsigned long&)>::type> marian::ThreadPool::enqueue<marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}&,unsigned long&>(std::result_of&&,(marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}&)...)::{lambda()#1},std::allocator<int>,void ()>::  _M_run  () + 0xcf
[0x5d00b4]          std::thread::_Impl<std::_Bind_simple<marian::ThreadPool::reserve(unsigned long)::{lambda()#1} ()>>::  _M_run  () + 0x174
[0x7f72d3274c80]                                                       + 0xb8c80
[0x7f72d374d6ba]                                                       + 0x76ba
[0x7f72d29da41d]    clone                                              + 0x6d

[2019-07-12 09:41:38] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-12 09:41:38] [marian] Running on snotra as process 12230 with command line:
[2019-07-12 09:41:38] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz -T . --devices 1 --train-sets ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.de ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.en --vocabs ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.de.json ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.en.json --mini-batch-fit -w 6000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/dev.bpe.de ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/dev.out --valid-script-path ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/train.log --valid-log ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/valid.log
[2019-07-12 09:41:38] [config] after-batches: 0
[2019-07-12 09:41:38] [config] after-epochs: 0
[2019-07-12 09:41:38] [config] allow-unk: false
[2019-07-12 09:41:38] [config] beam-size: 12
[2019-07-12 09:41:38] [config] bert-class-symbol: "[CLS]"
[2019-07-12 09:41:38] [config] bert-mask-symbol: "[MASK]"
[2019-07-12 09:41:38] [config] bert-masking-fraction: 0.15
[2019-07-12 09:41:38] [config] bert-sep-symbol: "[SEP]"
[2019-07-12 09:41:38] [config] bert-train-type-embeddings: true
[2019-07-12 09:41:38] [config] bert-type-vocab-size: 2
[2019-07-12 09:41:38] [config] best-deep: false
[2019-07-12 09:41:38] [config] clip-gemm: 0
[2019-07-12 09:41:38] [config] clip-norm: 1
[2019-07-12 09:41:38] [config] cost-type: ce-mean
[2019-07-12 09:41:38] [config] cpu-threads: 0
[2019-07-12 09:41:38] [config] data-weighting: ""
[2019-07-12 09:41:38] [config] data-weighting-type: sentence
[2019-07-12 09:41:38] [config] dec-cell: gru
[2019-07-12 09:41:38] [config] dec-cell-base-depth: 2
[2019-07-12 09:41:38] [config] dec-cell-high-depth: 1
[2019-07-12 09:41:38] [config] dec-depth: 1
[2019-07-12 09:41:38] [config] devices:
[2019-07-12 09:41:38] [config]   - 1
[2019-07-12 09:41:38] [config] dim-emb: 512
[2019-07-12 09:41:38] [config] dim-rnn: 1024
[2019-07-12 09:41:38] [config] dim-vocabs:
[2019-07-12 09:41:38] [config]   - 50000
[2019-07-12 09:41:38] [config]   - 50000
[2019-07-12 09:41:38] [config] disp-first: 0
[2019-07-12 09:41:38] [config] disp-freq: 2000
[2019-07-12 09:41:38] [config] disp-label-counts: false
[2019-07-12 09:41:38] [config] dropout-rnn: 0.2
[2019-07-12 09:41:38] [config] dropout-src: 0.1
[2019-07-12 09:41:38] [config] dropout-trg: 0.1
[2019-07-12 09:41:38] [config] dump-config: ""
[2019-07-12 09:41:38] [config] early-stopping: 5
[2019-07-12 09:41:38] [config] embedding-fix-src: false
[2019-07-12 09:41:38] [config] embedding-fix-trg: false
[2019-07-12 09:41:38] [config] embedding-normalization: false
[2019-07-12 09:41:38] [config] embedding-vectors:
[2019-07-12 09:41:38] [config]   []
[2019-07-12 09:41:38] [config] enc-cell: gru
[2019-07-12 09:41:38] [config] enc-cell-depth: 1
[2019-07-12 09:41:38] [config] enc-depth: 1
[2019-07-12 09:41:38] [config] enc-type: bidirectional
[2019-07-12 09:41:38] [config] exponential-smoothing: 0.0001
[2019-07-12 09:41:38] [config] grad-dropping-momentum: 0
[2019-07-12 09:41:38] [config] grad-dropping-rate: 0
[2019-07-12 09:41:38] [config] grad-dropping-warmup: 100
[2019-07-12 09:41:38] [config] guided-alignment: none
[2019-07-12 09:41:38] [config] guided-alignment-cost: mse
[2019-07-12 09:41:38] [config] guided-alignment-weight: 0.1
[2019-07-12 09:41:38] [config] ignore-model-config: false
[2019-07-12 09:41:38] [config] input-types:
[2019-07-12 09:41:38] [config]   []
[2019-07-12 09:41:38] [config] interpolate-env-vars: false
[2019-07-12 09:41:38] [config] keep-best: false
[2019-07-12 09:41:38] [config] label-smoothing: 0
[2019-07-12 09:41:38] [config] layer-normalization: true
[2019-07-12 09:41:38] [config] learn-rate: 0.0001
[2019-07-12 09:41:38] [config] log: ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/train.log
[2019-07-12 09:41:38] [config] log-level: info
[2019-07-12 09:41:38] [config] log-time-zone: ""
[2019-07-12 09:41:38] [config] lr-decay: 0
[2019-07-12 09:41:38] [config] lr-decay-freq: 50000
[2019-07-12 09:41:38] [config] lr-decay-inv-sqrt:
[2019-07-12 09:41:38] [config]   - 0
[2019-07-12 09:41:38] [config] lr-decay-repeat-warmup: false
[2019-07-12 09:41:38] [config] lr-decay-reset-optimizer: false
[2019-07-12 09:41:38] [config] lr-decay-start:
[2019-07-12 09:41:38] [config]   - 10
[2019-07-12 09:41:38] [config]   - 1
[2019-07-12 09:41:38] [config] lr-decay-strategy: epoch+stalled
[2019-07-12 09:41:38] [config] lr-report: false
[2019-07-12 09:41:38] [config] lr-warmup: 0
[2019-07-12 09:41:38] [config] lr-warmup-at-reload: false
[2019-07-12 09:41:38] [config] lr-warmup-cycle: false
[2019-07-12 09:41:38] [config] lr-warmup-start-rate: 0
[2019-07-12 09:41:38] [config] max-length: 50
[2019-07-12 09:41:38] [config] max-length-crop: false
[2019-07-12 09:41:38] [config] max-length-factor: 3
[2019-07-12 09:41:38] [config] maxi-batch: 100
[2019-07-12 09:41:38] [config] maxi-batch-sort: trg
[2019-07-12 09:41:38] [config] mini-batch: 64
[2019-07-12 09:41:38] [config] mini-batch-fit: true
[2019-07-12 09:41:38] [config] mini-batch-fit-step: 10
[2019-07-12 09:41:38] [config] mini-batch-overstuff: 1
[2019-07-12 09:41:38] [config] mini-batch-track-lr: false
[2019-07-12 09:41:38] [config] mini-batch-understuff: 1
[2019-07-12 09:41:38] [config] mini-batch-warmup: 0
[2019-07-12 09:41:38] [config] mini-batch-words: 0
[2019-07-12 09:41:38] [config] mini-batch-words-ref: 0
[2019-07-12 09:41:38] [config] model: ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-12 09:41:38] [config] multi-loss-type: sum
[2019-07-12 09:41:38] [config] multi-node: false
[2019-07-12 09:41:38] [config] multi-node-overlap: true
[2019-07-12 09:41:38] [config] n-best: false
[2019-07-12 09:41:38] [config] no-nccl: false
[2019-07-12 09:41:38] [config] no-reload: false
[2019-07-12 09:41:38] [config] no-restore-corpus: false
[2019-07-12 09:41:38] [config] no-shuffle: false
[2019-07-12 09:41:38] [config] normalize: 1
[2019-07-12 09:41:38] [config] num-devices: 0
[2019-07-12 09:41:38] [config] optimizer: adam
[2019-07-12 09:41:38] [config] optimizer-delay: 1
[2019-07-12 09:41:38] [config] optimizer-params:
[2019-07-12 09:41:38] [config]   []
[2019-07-12 09:41:38] [config] overwrite: false
[2019-07-12 09:41:38] [config] pretrained-model: ""
[2019-07-12 09:41:38] [config] quiet: false
[2019-07-12 09:41:38] [config] quiet-translation: true
[2019-07-12 09:41:38] [config] relative-paths: false
[2019-07-12 09:41:38] [config] right-left: false
[2019-07-12 09:41:38] [config] save-freq: 20000
[2019-07-12 09:41:38] [config] seed: 1111
[2019-07-12 09:41:38] [config] shuffle-in-ram: false
[2019-07-12 09:41:38] [config] skip: false
[2019-07-12 09:41:38] [config] sqlite: ""
[2019-07-12 09:41:38] [config] sqlite-drop: false
[2019-07-12 09:41:38] [config] sync-sgd: true
[2019-07-12 09:41:38] [config] tempdir: .
[2019-07-12 09:41:38] [config] tied-embeddings: false
[2019-07-12 09:41:38] [config] tied-embeddings-all: false
[2019-07-12 09:41:38] [config] tied-embeddings-src: false
[2019-07-12 09:41:38] [config] train-sets:
[2019-07-12 09:41:38] [config]   - ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.de
[2019-07-12 09:41:38] [config]   - ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.en
[2019-07-12 09:41:38] [config] transformer-aan-activation: swish
[2019-07-12 09:41:38] [config] transformer-aan-depth: 2
[2019-07-12 09:41:38] [config] transformer-aan-nogate: false
[2019-07-12 09:41:38] [config] transformer-decoder-autoreg: self-attention
[2019-07-12 09:41:38] [config] transformer-dim-aan: 2048
[2019-07-12 09:41:38] [config] transformer-dim-ffn: 2048
[2019-07-12 09:41:38] [config] transformer-dropout: 0
[2019-07-12 09:41:38] [config] transformer-dropout-attention: 0
[2019-07-12 09:41:38] [config] transformer-dropout-ffn: 0
[2019-07-12 09:41:38] [config] transformer-ffn-activation: swish
[2019-07-12 09:41:38] [config] transformer-ffn-depth: 2
[2019-07-12 09:41:38] [config] transformer-guided-alignment-layer: last
[2019-07-12 09:41:38] [config] transformer-heads: 8
[2019-07-12 09:41:38] [config] transformer-no-projection: false
[2019-07-12 09:41:38] [config] transformer-postprocess: dan
[2019-07-12 09:41:38] [config] transformer-postprocess-emb: d
[2019-07-12 09:41:38] [config] transformer-preprocess: ""
[2019-07-12 09:41:38] [config] transformer-tied-layers:
[2019-07-12 09:41:38] [config]   []
[2019-07-12 09:41:38] [config] transformer-train-position-embeddings: false
[2019-07-12 09:41:38] [config] type: amun
[2019-07-12 09:41:38] [config] ulr: false
[2019-07-12 09:41:38] [config] ulr-dim-emb: 0
[2019-07-12 09:41:38] [config] ulr-dropout: 0
[2019-07-12 09:41:38] [config] ulr-keys-vectors: ""
[2019-07-12 09:41:38] [config] ulr-query-vectors: ""
[2019-07-12 09:41:38] [config] ulr-softmax-temperature: 1
[2019-07-12 09:41:38] [config] ulr-trainable-transformation: false
[2019-07-12 09:41:38] [config] valid-freq: 20000
[2019-07-12 09:41:38] [config] valid-log: ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/valid.log
[2019-07-12 09:41:38] [config] valid-max-length: 1000
[2019-07-12 09:41:38] [config] valid-metrics:
[2019-07-12 09:41:38] [config]   - cross-entropy
[2019-07-12 09:41:38] [config]   - perplexity
[2019-07-12 09:41:38] [config]   - translation
[2019-07-12 09:41:38] [config] valid-mini-batch: 8
[2019-07-12 09:41:38] [config] valid-script-path: ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/score-dev.sh
[2019-07-12 09:41:38] [config] valid-sets:
[2019-07-12 09:41:38] [config]   - ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/dev.bpe.de
[2019-07-12 09:41:38] [config]   - ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/dev.bpe.en
[2019-07-12 09:41:38] [config] valid-translation-output: ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/dev.out
[2019-07-12 09:41:38] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-12 09:41:38] [config] vocabs:
[2019-07-12 09:41:38] [config]   - ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.de.json
[2019-07-12 09:41:38] [config]   - ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.en.json
[2019-07-12 09:41:38] [config] word-penalty: 0
[2019-07-12 09:41:38] [config] workspace: 6000
[2019-07-12 09:41:38] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-12 09:41:38] Using synchronous training
[2019-07-12 09:41:38] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.de.json
[2019-07-12 09:41:39] [data] Using unused word id eos for 0
[2019-07-12 09:41:39] [data] Using unused word id UNK for 1
[2019-07-12 09:41:39] [data] Setting vocabulary size for input 0 to 50000
[2019-07-12 09:41:39] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.en.json
[2019-07-12 09:41:39] [data] Using unused word id eos for 0
[2019-07-12 09:41:39] [data] Using unused word id UNK for 1
[2019-07-12 09:41:39] [data] Setting vocabulary size for input 1 to 50000
[2019-07-12 09:41:39] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-12 09:41:39] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-12 09:41:40] [memory] Extending reserved space to 6016 MB (device gpu1)
[2019-07-12 09:41:40] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-12 09:41:40] [comm] NCCLCommunicator constructed successfully.
[2019-07-12 09:41:40] [training] Using 1 GPUs
[2019-07-12 09:41:40] [memory] Reserving 422 MB, device gpu1
[2019-07-12 09:41:40] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-12 09:41:40] [memory] Reserving 422 MB, device gpu1
[2019-07-12 09:41:51] [batching] Done. Typical MB size is 8096 target words
[2019-07-12 09:41:51] [memory] Extending reserved space to 6016 MB (device gpu1)
[2019-07-12 09:41:51] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-12 09:41:51] [comm] NCCLCommunicator constructed successfully.
[2019-07-12 09:41:51] [training] Using 1 GPUs
[2019-07-12 09:41:51] Loading model from ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-12 09:41:58] Loading Adam parameters from ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-12 09:42:08] [memory] Reserving 844 MB, device gpu1
[2019-07-12 09:42:09] [training] Model reloaded from ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-12 09:42:09] [data] Restoring the corpus state to epoch 9, batch 160000
[2019-07-12 09:42:09] [data] Shuffling data
[2019-07-12 09:42:14] [data] Done reading 4393817 sentences
[2019-07-12 09:42:30] [data] Done shuffling 4393817 sentences to temp files
[2019-07-12 09:43:07] Training started
[2019-07-12 09:43:07] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-07-12 09:43:07] [memory] Reserving 422 MB, device gpu1
[2019-07-12 09:43:07] [memory] Reserving 422 MB, device gpu1
[2019-07-12 09:43:07] Loading model from ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-12 09:43:15] [memory] Reserving 422 MB, device cpu0
[2019-07-12 09:43:15] [memory] Reserving 422 MB, device gpu1
[2019-07-12 10:00:33] Ep. 9 : Up. 162000 : Sen. 1,092,881 : Cost 51.21048355 : Time 1134.00s : 8079.13 words/s
[2019-07-12 10:17:56] Ep. 9 : Up. 164000 : Sen. 1,458,808 : Cost 51.00768661 : Time 1043.08s : 8780.42 words/s
[2019-07-12 10:35:20] Ep. 9 : Up. 166000 : Sen. 1,825,015 : Cost 51.07877350 : Time 1043.97s : 8787.30 words/s
[2019-07-12 10:52:40] Ep. 9 : Up. 168000 : Sen. 2,190,758 : Cost 51.11718750 : Time 1039.49s : 8807.74 words/s
[2019-07-12 11:10:00] Ep. 9 : Up. 170000 : Sen. 2,555,448 : Cost 50.84068298 : Time 1040.59s : 8776.18 words/s
[2019-07-12 11:27:28] Ep. 9 : Up. 172000 : Sen. 2,920,555 : Cost 51.00985718 : Time 1047.72s : 8725.59 words/s
[2019-07-12 11:44:46] Ep. 9 : Up. 174000 : Sen. 3,287,111 : Cost 51.15706253 : Time 1038.18s : 8823.72 words/s
[2019-07-12 11:58:06] Seen 3567162 samples
[2019-07-12 11:58:06] Starting epoch 10
[2019-07-12 11:58:06] [data] Shuffling data
[2019-07-12 11:58:08] [data] Done reading 4393817 sentences
[2019-07-12 11:58:22] [data] Done shuffling 4393817 sentences to temp files
[2019-07-12 12:02:32] Ep. 10 : Up. 176000 : Sen. 84,930 : Cost 50.88492966 : Time 1066.30s : 8575.79 words/s
[2019-07-12 12:19:58] Ep. 10 : Up. 178000 : Sen. 450,944 : Cost 50.00498199 : Time 1045.27s : 8761.25 words/s
[2019-07-12 12:37:24] Ep. 10 : Up. 180000 : Sen. 816,658 : Cost 50.42013550 : Time 1046.44s : 8760.88 words/s
[2019-07-12 12:37:24] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-12 12:37:33] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.iter180000.npz
[2019-07-12 12:37:40] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-12 12:37:49] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-12 12:38:17] [valid] Ep. 10 : Up. 180000 : cross-entropy : 46.2543 : new best
[2019-07-12 12:38:26] [valid] Ep. 10 : Up. 180000 : perplexity : 6.21251 : new best
[2019-07-12 12:39:28] [valid] Ep. 10 : Up. 180000 : translation : 31.53 : new best
[2019-07-12 12:57:00] Ep. 10 : Up. 182000 : Sen. 1,183,364 : Cost 50.16630936 : Time 1175.50s : 7804.94 words/s
[2019-07-12 13:14:22] Ep. 10 : Up. 184000 : Sen. 1,548,641 : Cost 49.95129013 : Time 1042.80s : 8759.75 words/s
[2019-07-12 13:31:47] Ep. 10 : Up. 186000 : Sen. 1,914,973 : Cost 50.42381668 : Time 1044.92s : 8776.82 words/s
[2019-07-12 13:49:15] Ep. 10 : Up. 188000 : Sen. 2,280,670 : Cost 50.22446060 : Time 1047.39s : 8753.38 words/s
[2019-07-12 14:06:38] Ep. 10 : Up. 190000 : Sen. 2,646,713 : Cost 50.21445465 : Time 1042.79s : 8765.83 words/s
[2019-07-12 14:24:00] Ep. 10 : Up. 192000 : Sen. 3,012,515 : Cost 50.48056030 : Time 1042.74s : 8778.05 words/s
[2019-07-12 14:41:25] Ep. 10 : Up. 194000 : Sen. 3,379,518 : Cost 50.45863342 : Time 1044.72s : 8795.37 words/s
[2019-07-12 14:50:21] Seen 3567162 samples
[2019-07-12 14:50:21] Starting epoch 11
[2019-07-12 14:50:21] [data] Shuffling data
[2019-07-12 14:50:24] [data] Done reading 4393817 sentences
[2019-07-12 14:50:45] [data] Done shuffling 4393817 sentences to temp files
[2019-07-12 14:59:25] Ep. 11 : Up. 196000 : Sen. 178,756 : Cost 49.76888275 : Time 1079.97s : 8493.30 words/s
[2019-07-12 15:16:47] Ep. 11 : Up. 198000 : Sen. 544,159 : Cost 49.42354202 : Time 1041.77s : 8782.76 words/s
[2019-07-12 15:34:12] Ep. 11 : Up. 200000 : Sen. 910,462 : Cost 49.48942184 : Time 1044.75s : 8783.43 words/s
[2019-07-12 15:34:12] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-12 15:34:21] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.iter200000.npz
[2019-07-12 15:34:32] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-12 15:34:43] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-12 15:35:09] [valid] Ep. 11 : Up. 200000 : cross-entropy : 45.9543 : new best
[2019-07-12 15:35:17] [valid] Ep. 11 : Up. 200000 : perplexity : 6.13934 : new best
[2019-07-12 15:36:19] [valid] Ep. 11 : Up. 200000 : translation : 31.65 : new best
[2019-07-12 15:53:45] Ep. 11 : Up. 202000 : Sen. 1,275,621 : Cost 49.52100754 : Time 1173.09s : 7771.73 words/s
[2019-07-12 16:11:10] Ep. 11 : Up. 204000 : Sen. 1,642,125 : Cost 49.62295151 : Time 1045.23s : 8776.08 words/s
[2019-07-12 16:28:34] Ep. 11 : Up. 206000 : Sen. 2,008,492 : Cost 49.57437897 : Time 1043.64s : 8792.91 words/s
[2019-07-12 16:45:51] Ep. 11 : Up. 208000 : Sen. 2,374,197 : Cost 49.88919067 : Time 1037.09s : 8831.64 words/s
[2019-07-12 17:03:10] Ep. 11 : Up. 210000 : Sen. 2,739,041 : Cost 50.02927399 : Time 1039.84s : 8789.28 words/s
[2019-07-12 17:20:30] Ep. 11 : Up. 212000 : Sen. 3,104,573 : Cost 49.80851364 : Time 1039.94s : 8791.91 words/s
[2019-07-12 17:37:58] Ep. 11 : Up. 214000 : Sen. 3,471,189 : Cost 49.86694336 : Time 1047.93s : 8759.84 words/s
[2019-07-12 17:42:32] Seen 3567162 samples
[2019-07-12 17:42:32] Starting epoch 12
[2019-07-12 17:42:32] [data] Shuffling data
[2019-07-12 17:42:34] [data] Done reading 4393817 sentences
[2019-07-12 17:42:49] [data] Done shuffling 4393817 sentences to temp files
[2019-07-12 17:55:57] Ep. 12 : Up. 216000 : Sen. 270,172 : Cost 48.93392563 : Time 1078.21s : 8480.95 words/s
[2019-07-12 18:13:22] Ep. 12 : Up. 218000 : Sen. 636,176 : Cost 48.75828552 : Time 1045.74s : 8756.42 words/s
[2019-07-12 18:30:48] Ep. 12 : Up. 220000 : Sen. 1,001,669 : Cost 49.11504745 : Time 1045.97s : 8756.51 words/s
[2019-07-12 18:30:48] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-12 18:30:59] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.iter220000.npz
[2019-07-12 18:31:07] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-12 18:31:16] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-12 18:31:42] [valid] Ep. 12 : Up. 220000 : cross-entropy : 45.7856 : new best
[2019-07-12 18:31:50] [valid] Ep. 12 : Up. 220000 : perplexity : 6.09858 : new best
[2019-07-12 18:32:52] [valid] Ep. 12 : Up. 220000 : translation : 31.74 : new best
[2019-07-12 18:50:19] Ep. 12 : Up. 222000 : Sen. 1,367,149 : Cost 49.04436493 : Time 1170.86s : 7816.47 words/s
[2019-07-12 19:07:43] Ep. 12 : Up. 224000 : Sen. 1,733,722 : Cost 49.14141083 : Time 1044.03s : 8790.50 words/s
[2019-07-12 19:25:08] Ep. 12 : Up. 226000 : Sen. 2,098,029 : Cost 49.34598541 : Time 1044.57s : 8737.37 words/s
[2019-07-12 19:42:41] Ep. 12 : Up. 228000 : Sen. 2,464,000 : Cost 49.36248398 : Time 1052.81s : 8685.37 words/s
[2019-07-12 20:00:07] Ep. 12 : Up. 230000 : Sen. 2,830,079 : Cost 49.41170502 : Time 1046.21s : 8768.19 words/s
[2019-07-12 20:17:32] Ep. 12 : Up. 232000 : Sen. 3,195,029 : Cost 49.38835526 : Time 1044.77s : 8731.08 words/s
[2019-07-12 20:34:49] Ep. 12 : Up. 234000 : Sen. 3,560,448 : Cost 49.68546295 : Time 1037.37s : 8819.51 words/s
[2019-07-12 20:35:08] Seen 3567162 samples
[2019-07-12 20:35:08] Starting epoch 13
[2019-07-12 20:35:08] [data] Shuffling data
[2019-07-12 20:35:11] [data] Done reading 4393817 sentences
[2019-07-12 20:35:32] [data] Done shuffling 4393817 sentences to temp files
[2019-07-12 20:57:01] Ep. 13 : Up. 236000 : Sen. 358,877 : Cost 48.19696808 : Time 1331.88s : 6872.88 words/s
[2019-07-12 21:26:29] Ep. 13 : Up. 238000 : Sen. 724,511 : Cost 48.54106522 : Time 1768.39s : 5175.41 words/s
[2019-07-12 21:56:29] Ep. 13 : Up. 240000 : Sen. 1,090,896 : Cost 48.57201767 : Time 1800.14s : 5096.18 words/s
[2019-07-12 21:56:29] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-12 21:56:41] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.iter240000.npz
[2019-07-12 21:56:51] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-12 21:57:10] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-12 21:58:12] [valid] Ep. 13 : Up. 240000 : cross-entropy : 45.6079 : new best
[2019-07-12 21:58:26] [valid] Ep. 13 : Up. 240000 : perplexity : 6.05595 : new best
[2019-07-12 22:00:52] [valid] Ep. 13 : Up. 240000 : translation : 31.76 : new best
[2019-07-12 22:25:28] Ep. 13 : Up. 242000 : Sen. 1,457,132 : Cost 48.79001999 : Time 1738.36s : 5261.31 words/s
[2019-07-12 22:50:22] Ep. 13 : Up. 244000 : Sen. 1,823,006 : Cost 48.89470291 : Time 1494.53s : 6134.44 words/s
[2019-07-12 23:15:40] Ep. 13 : Up. 246000 : Sen. 2,188,959 : Cost 48.95822144 : Time 1517.40s : 6036.72 words/s
[2019-07-12 23:46:47] Ep. 13 : Up. 248000 : Sen. 2,553,759 : Cost 48.74560165 : Time 1867.63s : 4889.38 words/s
[2019-07-13 00:14:57] Ep. 13 : Up. 250000 : Sen. 2,920,577 : Cost 49.12076950 : Time 1689.29s : 5438.15 words/s
[2019-07-13 00:44:09] Ep. 13 : Up. 252000 : Sen. 3,286,545 : Cost 48.85338974 : Time 1752.83s : 5217.91 words/s
[2019-07-13 01:06:17] Seen 3567162 samples
[2019-07-13 01:06:17] Starting epoch 14
[2019-07-13 01:06:17] [data] Shuffling data
[2019-07-13 01:06:23] [data] Done reading 4393817 sentences
[2019-07-13 01:07:07] [data] Done shuffling 4393817 sentences to temp files
[2019-07-13 01:12:34] Ep. 14 : Up. 254000 : Sen. 86,456 : Cost 48.82560730 : Time 1704.06s : 5391.75 words/s
[2019-07-13 01:30:30] Ep. 14 : Up. 256000 : Sen. 450,874 : Cost 48.14112854 : Time 1076.42s : 8481.42 words/s
[2019-07-13 01:47:53] Ep. 14 : Up. 258000 : Sen. 816,671 : Cost 48.16777802 : Time 1042.99s : 8765.59 words/s
[2019-07-13 02:05:17] Ep. 14 : Up. 260000 : Sen. 1,182,733 : Cost 48.32759094 : Time 1043.79s : 8768.63 words/s
[2019-07-13 02:05:17] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-13 02:05:26] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.iter260000.npz
[2019-07-13 02:05:33] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-13 02:05:42] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-13 02:06:08] [valid] Ep. 14 : Up. 260000 : cross-entropy : 45.4556 : new best
[2019-07-13 02:06:16] [valid] Ep. 14 : Up. 260000 : perplexity : 6.01962 : new best
[2019-07-13 02:07:21] [valid] Ep. 14 : Up. 260000 : translation : 31.89 : new best
[2019-07-13 02:24:47] Ep. 14 : Up. 262000 : Sen. 1,549,387 : Cost 48.43952179 : Time 1170.79s : 7845.68 words/s
[2019-07-13 02:42:08] Ep. 14 : Up. 264000 : Sen. 1,914,598 : Cost 48.28220367 : Time 1040.93s : 8781.58 words/s
[2019-07-13 02:59:30] Ep. 14 : Up. 266000 : Sen. 2,280,122 : Cost 48.60437775 : Time 1041.30s : 8788.68 words/s
[2019-07-13 03:16:49] Ep. 14 : Up. 268000 : Sen. 2,646,239 : Cost 48.41898727 : Time 1038.83s : 8820.39 words/s
[2019-07-13 03:34:08] Ep. 14 : Up. 270000 : Sen. 3,011,738 : Cost 48.77967453 : Time 1039.38s : 8814.05 words/s
[2019-07-13 03:51:29] Ep. 14 : Up. 272000 : Sen. 3,377,767 : Cost 48.59449005 : Time 1041.15s : 8800.40 words/s
[2019-07-13 04:00:27] Seen 3567162 samples
[2019-07-13 04:00:27] Starting epoch 15
[2019-07-13 04:00:27] [data] Shuffling data
[2019-07-13 04:00:30] [data] Done reading 4393817 sentences
[2019-07-13 04:00:54] [data] Done shuffling 4393817 sentences to temp files
[2019-07-13 04:09:25] Ep. 15 : Up. 274000 : Sen. 176,263 : Cost 47.99084473 : Time 1075.48s : 8496.74 words/s
[2019-07-13 04:26:47] Ep. 15 : Up. 276000 : Sen. 541,964 : Cost 47.85258484 : Time 1042.30s : 8792.38 words/s
[2019-07-13 04:44:12] Ep. 15 : Up. 278000 : Sen. 907,895 : Cost 47.80025101 : Time 1045.19s : 8757.68 words/s
[2019-07-13 05:01:38] Ep. 15 : Up. 280000 : Sen. 1,274,327 : Cost 48.03097534 : Time 1046.43s : 8773.87 words/s
[2019-07-13 05:01:38] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-13 05:01:48] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.iter280000.npz
[2019-07-13 05:01:55] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-13 05:02:04] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-13 05:02:30] [valid] Ep. 15 : Up. 280000 : cross-entropy : 45.3749 : new best
[2019-07-13 05:02:38] [valid] Ep. 15 : Up. 280000 : perplexity : 6.00047 : new best
[2019-07-13 05:03:42] [valid] Ep. 15 : Up. 280000 : translation : 32.02 : new best
[2019-07-13 05:21:06] Ep. 15 : Up. 282000 : Sen. 1,640,347 : Cost 47.79319763 : Time 1167.72s : 7845.24 words/s
[2019-07-13 05:38:25] Ep. 15 : Up. 284000 : Sen. 2,005,527 : Cost 47.90554428 : Time 1038.98s : 8778.51 words/s
[2019-07-13 05:55:46] Ep. 15 : Up. 286000 : Sen. 2,372,184 : Cost 48.26594925 : Time 1040.54s : 8816.59 words/s
[2019-07-13 06:13:07] Ep. 15 : Up. 288000 : Sen. 2,737,407 : Cost 48.35288620 : Time 1041.27s : 8776.75 words/s
[2019-07-13 06:30:29] Ep. 15 : Up. 290000 : Sen. 3,102,915 : Cost 48.33806229 : Time 1042.45s : 8795.94 words/s
[2019-07-13 06:47:47] Ep. 15 : Up. 292000 : Sen. 3,469,228 : Cost 48.28450012 : Time 1037.78s : 8831.76 words/s
[2019-07-13 06:52:27] Seen 3567162 samples
[2019-07-13 06:52:27] Starting epoch 16
[2019-07-13 06:52:27] [data] Shuffling data
[2019-07-13 06:52:30] [data] Done reading 4393817 sentences
[2019-07-13 06:52:44] [data] Done shuffling 4393817 sentences to temp files
[2019-07-13 07:05:35] Ep. 16 : Up. 294000 : Sen. 268,054 : Cost 47.48927689 : Time 1067.38s : 8575.22 words/s
[2019-07-13 07:22:52] Ep. 16 : Up. 296000 : Sen. 633,600 : Cost 47.37796021 : Time 1037.69s : 8819.03 words/s
[2019-07-13 07:40:12] Ep. 16 : Up. 298000 : Sen. 998,828 : Cost 47.39951324 : Time 1039.73s : 8796.61 words/s
[2019-07-13 07:57:37] Ep. 16 : Up. 300000 : Sen. 1,365,571 : Cost 47.79849625 : Time 1045.18s : 8784.23 words/s
[2019-07-13 07:57:37] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-13 07:57:46] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.iter300000.npz
[2019-07-13 07:57:53] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-13 07:58:03] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-13 07:58:29] [valid] Ep. 16 : Up. 300000 : cross-entropy : 45.3134 : new best
[2019-07-13 07:58:37] [valid] Ep. 16 : Up. 300000 : perplexity : 5.98592 : new best
[2019-07-13 07:59:41] [valid] Ep. 16 : Up. 300000 : translation : 31.99 : stalled 1 times (last best: 32.02)
[2019-07-13 08:17:08] Ep. 16 : Up. 302000 : Sen. 1,731,448 : Cost 47.89960480 : Time 1171.05s : 7832.92 words/s
[2019-07-13 08:34:28] Ep. 16 : Up. 304000 : Sen. 2,096,635 : Cost 47.64246368 : Time 1039.32s : 8769.39 words/s
[2019-07-13 08:51:52] Ep. 16 : Up. 306000 : Sen. 2,462,892 : Cost 48.08398056 : Time 1044.75s : 8794.77 words/s
[2019-07-13 09:09:10] Ep. 16 : Up. 308000 : Sen. 2,827,198 : Cost 48.02436447 : Time 1037.73s : 8789.65 words/s
[2019-07-13 09:26:34] Ep. 16 : Up. 310000 : Sen. 3,193,238 : Cost 47.94406509 : Time 1044.12s : 8765.00 words/s
[2019-07-13 09:43:58] Ep. 16 : Up. 312000 : Sen. 3,558,872 : Cost 47.91249847 : Time 1043.31s : 8766.23 words/s
[2019-07-13 09:44:22] Seen 3567162 samples
[2019-07-13 09:44:22] Starting epoch 17
[2019-07-13 09:44:22] [data] Shuffling data
[2019-07-13 09:44:24] [data] Done reading 4393817 sentences
[2019-07-13 09:44:38] [data] Done shuffling 4393817 sentences to temp files
[2019-07-13 10:01:46] Ep. 17 : Up. 314000 : Sen. 356,378 : Cost 46.95652390 : Time 1068.32s : 8562.37 words/s
[2019-07-13 10:19:13] Ep. 17 : Up. 316000 : Sen. 722,295 : Cost 46.92015457 : Time 1047.35s : 8729.25 words/s
[2019-07-13 10:36:42] Ep. 17 : Up. 318000 : Sen. 1,088,746 : Cost 47.14322662 : Time 1048.80s : 8748.57 words/s
[2019-07-13 10:54:05] Ep. 17 : Up. 320000 : Sen. 1,453,518 : Cost 47.31031418 : Time 1042.80s : 8742.90 words/s
[2019-07-13 10:54:05] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-13 10:54:13] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.iter320000.npz
[2019-07-13 10:54:20] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-13 10:54:29] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-13 10:54:56] [valid] Ep. 17 : Up. 320000 : cross-entropy : 45.2217 : new best
[2019-07-13 10:55:03] [valid] Ep. 17 : Up. 320000 : perplexity : 5.96428 : new best
[2019-07-13 10:56:07] [valid] Ep. 17 : Up. 320000 : translation : 32.11 : new best
[2019-07-13 11:13:37] Ep. 17 : Up. 322000 : Sen. 1,818,642 : Cost 47.49866867 : Time 1172.55s : 7809.63 words/s
[2019-07-13 11:31:06] Ep. 17 : Up. 324000 : Sen. 2,184,010 : Cost 47.79800797 : Time 1048.59s : 8736.27 words/s
[2019-07-13 11:48:25] Ep. 17 : Up. 326000 : Sen. 2,550,899 : Cost 47.51707077 : Time 1039.17s : 8805.65 words/s
[2019-07-13 12:05:49] Ep. 17 : Up. 328000 : Sen. 2,917,185 : Cost 47.85376358 : Time 1044.22s : 8788.95 words/s
[2019-07-13 12:23:08] Ep. 17 : Up. 330000 : Sen. 3,282,344 : Cost 47.73827362 : Time 1039.08s : 8795.12 words/s
[2019-07-13 12:36:41] Seen 3567162 samples
[2019-07-13 12:36:41] Starting epoch 18
[2019-07-13 12:36:41] [data] Shuffling data
[2019-07-13 12:36:44] [data] Done reading 4393817 sentences
[2019-07-13 12:37:04] [data] Done shuffling 4393817 sentences to temp files
[2019-07-13 12:41:03] Ep. 18 : Up. 332000 : Sen. 80,530 : Cost 47.36978531 : Time 1074.18s : 8512.09 words/s
[2019-07-13 12:58:29] Ep. 18 : Up. 334000 : Sen. 446,395 : Cost 46.84656906 : Time 1046.73s : 8754.46 words/s
[2019-07-13 13:15:51] Ep. 18 : Up. 336000 : Sen. 812,959 : Cost 46.91392517 : Time 1041.45s : 8804.75 words/s
[2019-07-13 13:33:11] Ep. 18 : Up. 338000 : Sen. 1,180,055 : Cost 46.88185501 : Time 1040.66s : 8816.11 words/s
[2019-07-13 13:50:33] Ep. 18 : Up. 340000 : Sen. 1,545,570 : Cost 47.10010910 : Time 1041.97s : 8790.48 words/s
[2019-07-13 13:50:33] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-13 13:50:42] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.iter340000.npz
[2019-07-13 13:50:49] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-13 13:50:58] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-13 13:51:24] [valid] Ep. 18 : Up. 340000 : cross-entropy : 45.1933 : new best
[2019-07-13 13:51:31] [valid] Ep. 18 : Up. 340000 : perplexity : 5.95759 : new best
[2019-07-13 13:52:34] [valid] Ep. 18 : Up. 340000 : translation : 32.11 : stalled 1 times (last best: 32.11)
[2019-07-13 14:10:00] Ep. 18 : Up. 342000 : Sen. 1,910,938 : Cost 47.15272141 : Time 1166.79s : 7837.59 words/s
[2019-07-13 14:27:24] Ep. 18 : Up. 344000 : Sen. 2,277,672 : Cost 47.10802460 : Time 1043.43s : 8794.16 words/s
[2019-07-13 14:44:47] Ep. 18 : Up. 346000 : Sen. 2,643,672 : Cost 47.57759094 : Time 1043.27s : 8780.37 words/s
[2019-07-13 15:02:10] Ep. 18 : Up. 348000 : Sen. 3,008,406 : Cost 47.36307526 : Time 1042.73s : 8760.14 words/s
[2019-07-13 15:19:32] Ep. 18 : Up. 350000 : Sen. 3,373,700 : Cost 47.36310577 : Time 1042.70s : 8761.80 words/s
[2019-07-13 15:28:45] Seen 3567162 samples
[2019-07-13 15:28:45] Starting epoch 19
[2019-07-13 15:28:45] [data] Shuffling data
[2019-07-13 15:28:48] [data] Done reading 4393817 sentences
[2019-07-13 15:29:09] [data] Done shuffling 4393817 sentences to temp files
[2019-07-13 15:37:28] Ep. 19 : Up. 352000 : Sen. 171,704 : Cost 47.07065201 : Time 1075.75s : 8500.25 words/s
[2019-07-13 15:54:50] Ep. 19 : Up. 354000 : Sen. 537,869 : Cost 46.42561722 : Time 1042.06s : 8784.84 words/s
[2019-07-13 16:12:11] Ep. 19 : Up. 356000 : Sen. 903,647 : Cost 46.51371002 : Time 1041.08s : 8798.66 words/s
[2019-07-13 16:29:32] Ep. 19 : Up. 358000 : Sen. 1,269,980 : Cost 46.65987396 : Time 1040.91s : 8814.29 words/s
[2019-07-13 16:46:57] Ep. 19 : Up. 360000 : Sen. 1,635,540 : Cost 47.09521866 : Time 1044.59s : 8759.02 words/s
[2019-07-13 16:46:57] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-13 16:47:10] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.iter360000.npz
[2019-07-13 16:47:20] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-13 16:47:32] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-13 16:48:01] [valid] Ep. 19 : Up. 360000 : cross-entropy : 45.1333 : new best
[2019-07-13 16:48:08] [valid] Ep. 19 : Up. 360000 : perplexity : 5.94348 : new best
[2019-07-13 16:48:15] Error: Unknown word id: 49994
[2019-07-13 16:48:15] Error: Aborted from virtual const string& marian::DefaultVocab::operator[](marian::Word) const in /fs/bil0/abdel/marian-dev/src/data/default_vocab.cpp:76

[CALL STACK]
[0x70f3a4]          marian::DefaultVocab::operator[][abi:  cxx11]  (unsigned int) const + 0x234
[0x7053da]          marian::DefaultVocab::decode[abi:  cxx11]  (std::vector<unsigned int,std::allocator<unsigned int>> const&,  bool) const + 0xba
[0x701874]          marian::Vocab::decode[abi:  cxx11]  (std::vector<unsigned int,std::allocator<unsigned int>> const&,  bool) const + 0x24
[0x5e16e1]          void marian::OutputPrinter::  print  <std::__cxx11::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>>(std::shared_ptr<marian::History>,  std::__cxx11::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>&,  std::__cxx11::basic_stringstream<char,std::char_traits<char>,std::allocator<char>>&) + 0x5e1
[0x979c3f]          marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}::  operator()  (unsigned long) const + 0x2cf
[0x97a2d9]          std::future<std::result_of<marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}& (unsigned long&)>::type> marian::ThreadPool::enqueue<marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}&,unsigned long&>(std::result_of&&,(marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}&)...)::{lambda()#1}::  operator()  () const + 0x29
[0x97acdc]          std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base,std::__future_base::_Result_base::_Deleter> (),std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>,std::__future_base::_Result_base::_Deleter>,std::_Bind_simple<std::reference_wrapper<std::future<std::result_of<marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}& (unsigned long&)>::type> marian::ThreadPool::enqueue<marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}&,unsigned long&>(std::result_of&&,(marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}&)...)::{lambda()#1}> ()>,void>>::  _M_invoke [0x5a5f19]          std::__future_base::_State_baseV2::  _M_do_set  (std::function<std::unique_ptr<std::__future_base::_Result_base,std::__future_base::_Result_base::_Deleter> ()>*,  bool*) + 0x29
[0x7f5336d73a99]                                                       + 0xea99
[0x96d04f]          std::__future_base::_Task_state<std::future<std::result_of<marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}& (unsigned long&)>::type> marian::ThreadPool::enqueue<marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}&,unsigned long&>(std::result_of&&,(marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}&)...)::{lambda()#1},std::allocator<int>,void ()>::  _M_run  () + 0xcf
[0x5d00b4]          std::thread::_Impl<std::_Bind_simple<marian::ThreadPool::reserve(unsigned long)::{lambda()#1} ()>>::  _M_run  () + 0x174
[0x7f5336893c80]                                                       + 0xb8c80
[0x7f5336d6c6ba]                                                       + 0x76ba
[0x7f5335ff941d]    clone                                              + 0x6d

[2019-07-15 14:33:50] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-15 14:33:50] [marian] Running on hodor as process 62817 with command line:
[2019-07-15 14:33:50] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz -T . --devices 2 --train-sets ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.de ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.en --vocabs ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.de.json ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.en.json --mini-batch-fit -w 5000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/dev.bpe.de ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/dev.out --valid-script-path ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/train.log --valid-log ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/valid.log
[2019-07-15 14:33:51] [config] after-batches: 0
[2019-07-15 14:33:51] [config] after-epochs: 0
[2019-07-15 14:33:51] [config] allow-unk: false
[2019-07-15 14:33:51] [config] beam-size: 12
[2019-07-15 14:33:51] [config] bert-class-symbol: "[CLS]"
[2019-07-15 14:33:51] [config] bert-mask-symbol: "[MASK]"
[2019-07-15 14:33:51] [config] bert-masking-fraction: 0.15
[2019-07-15 14:33:51] [config] bert-sep-symbol: "[SEP]"
[2019-07-15 14:33:51] [config] bert-train-type-embeddings: true
[2019-07-15 14:33:51] [config] bert-type-vocab-size: 2
[2019-07-15 14:33:51] [config] best-deep: false
[2019-07-15 14:33:51] [config] clip-gemm: 0
[2019-07-15 14:33:51] [config] clip-norm: 1
[2019-07-15 14:33:51] [config] cost-type: ce-mean
[2019-07-15 14:33:51] [config] cpu-threads: 0
[2019-07-15 14:33:51] [config] data-weighting: ""
[2019-07-15 14:33:51] [config] data-weighting-type: sentence
[2019-07-15 14:33:51] [config] dec-cell: gru
[2019-07-15 14:33:51] [config] dec-cell-base-depth: 2
[2019-07-15 14:33:51] [config] dec-cell-high-depth: 1
[2019-07-15 14:33:51] [config] dec-depth: 1
[2019-07-15 14:33:51] [config] devices:
[2019-07-15 14:33:51] [config]   - 2
[2019-07-15 14:33:51] [config] dim-emb: 512
[2019-07-15 14:33:51] [config] dim-rnn: 1024
[2019-07-15 14:33:51] [config] dim-vocabs:
[2019-07-15 14:33:51] [config]   - 50000
[2019-07-15 14:33:51] [config]   - 50000
[2019-07-15 14:33:51] [config] disp-first: 0
[2019-07-15 14:33:51] [config] disp-freq: 2000
[2019-07-15 14:33:51] [config] disp-label-counts: false
[2019-07-15 14:33:51] [config] dropout-rnn: 0.2
[2019-07-15 14:33:51] [config] dropout-src: 0.1
[2019-07-15 14:33:51] [config] dropout-trg: 0.1
[2019-07-15 14:33:51] [config] dump-config: ""
[2019-07-15 14:33:51] [config] early-stopping: 5
[2019-07-15 14:33:51] [config] embedding-fix-src: false
[2019-07-15 14:33:51] [config] embedding-fix-trg: false
[2019-07-15 14:33:51] [config] embedding-normalization: false
[2019-07-15 14:33:51] [config] embedding-vectors:
[2019-07-15 14:33:51] [config]   []
[2019-07-15 14:33:51] [config] enc-cell: gru
[2019-07-15 14:33:51] [config] enc-cell-depth: 1
[2019-07-15 14:33:51] [config] enc-depth: 1
[2019-07-15 14:33:51] [config] enc-type: bidirectional
[2019-07-15 14:33:51] [config] exponential-smoothing: 0.0001
[2019-07-15 14:33:51] [config] grad-dropping-momentum: 0
[2019-07-15 14:33:51] [config] grad-dropping-rate: 0
[2019-07-15 14:33:51] [config] grad-dropping-warmup: 100
[2019-07-15 14:33:51] [config] guided-alignment: none
[2019-07-15 14:33:51] [config] guided-alignment-cost: mse
[2019-07-15 14:33:51] [config] guided-alignment-weight: 0.1
[2019-07-15 14:33:51] [config] ignore-model-config: false
[2019-07-15 14:33:51] [config] input-types:
[2019-07-15 14:33:51] [config]   []
[2019-07-15 14:33:51] [config] interpolate-env-vars: false
[2019-07-15 14:33:51] [config] keep-best: false
[2019-07-15 14:33:51] [config] label-smoothing: 0
[2019-07-15 14:33:51] [config] layer-normalization: true
[2019-07-15 14:33:51] [config] learn-rate: 0.0001
[2019-07-15 14:33:51] [config] log: ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/train.log
[2019-07-15 14:33:51] [config] log-level: info
[2019-07-15 14:33:51] [config] log-time-zone: ""
[2019-07-15 14:33:51] [config] lr-decay: 0
[2019-07-15 14:33:51] [config] lr-decay-freq: 50000
[2019-07-15 14:33:51] [config] lr-decay-inv-sqrt:
[2019-07-15 14:33:51] [config]   - 0
[2019-07-15 14:33:51] [config] lr-decay-repeat-warmup: false
[2019-07-15 14:33:51] [config] lr-decay-reset-optimizer: false
[2019-07-15 14:33:51] [config] lr-decay-start:
[2019-07-15 14:33:51] [config]   - 10
[2019-07-15 14:33:51] [config]   - 1
[2019-07-15 14:33:51] [config] lr-decay-strategy: epoch+stalled
[2019-07-15 14:33:51] [config] lr-report: false
[2019-07-15 14:33:51] [config] lr-warmup: 0
[2019-07-15 14:33:51] [config] lr-warmup-at-reload: false
[2019-07-15 14:33:51] [config] lr-warmup-cycle: false
[2019-07-15 14:33:51] [config] lr-warmup-start-rate: 0
[2019-07-15 14:33:51] [config] max-length: 50
[2019-07-15 14:33:51] [config] max-length-crop: false
[2019-07-15 14:33:51] [config] max-length-factor: 3
[2019-07-15 14:33:51] [config] maxi-batch: 100
[2019-07-15 14:33:51] [config] maxi-batch-sort: trg
[2019-07-15 14:33:51] [config] mini-batch: 64
[2019-07-15 14:33:51] [config] mini-batch-fit: true
[2019-07-15 14:33:51] [config] mini-batch-fit-step: 10
[2019-07-15 14:33:51] [config] mini-batch-overstuff: 1
[2019-07-15 14:33:51] [config] mini-batch-track-lr: false
[2019-07-15 14:33:51] [config] mini-batch-understuff: 1
[2019-07-15 14:33:51] [config] mini-batch-warmup: 0
[2019-07-15 14:33:51] [config] mini-batch-words: 0
[2019-07-15 14:33:51] [config] mini-batch-words-ref: 0
[2019-07-15 14:33:51] [config] model: ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-15 14:33:51] [config] multi-loss-type: sum
[2019-07-15 14:33:51] [config] multi-node: false
[2019-07-15 14:33:51] [config] multi-node-overlap: true
[2019-07-15 14:33:51] [config] n-best: false
[2019-07-15 14:33:51] [config] no-nccl: false
[2019-07-15 14:33:51] [config] no-reload: false
[2019-07-15 14:33:51] [config] no-restore-corpus: false
[2019-07-15 14:33:51] [config] no-shuffle: false
[2019-07-15 14:33:51] [config] normalize: 1
[2019-07-15 14:33:51] [config] num-devices: 0
[2019-07-15 14:33:51] [config] optimizer: adam
[2019-07-15 14:33:51] [config] optimizer-delay: 1
[2019-07-15 14:33:51] [config] optimizer-params:
[2019-07-15 14:33:51] [config]   []
[2019-07-15 14:33:51] [config] overwrite: false
[2019-07-15 14:33:51] [config] pretrained-model: ""
[2019-07-15 14:33:51] [config] quiet: false
[2019-07-15 14:33:51] [config] quiet-translation: true
[2019-07-15 14:33:51] [config] relative-paths: false
[2019-07-15 14:33:51] [config] right-left: false
[2019-07-15 14:33:51] [config] save-freq: 20000
[2019-07-15 14:33:51] [config] seed: 1111
[2019-07-15 14:33:51] [config] shuffle-in-ram: false
[2019-07-15 14:33:51] [config] skip: false
[2019-07-15 14:33:51] [config] sqlite: ""
[2019-07-15 14:33:51] [config] sqlite-drop: false
[2019-07-15 14:33:51] [config] sync-sgd: true
[2019-07-15 14:33:51] [config] tempdir: .
[2019-07-15 14:33:51] [config] tied-embeddings: false
[2019-07-15 14:33:51] [config] tied-embeddings-all: false
[2019-07-15 14:33:51] [config] tied-embeddings-src: false
[2019-07-15 14:33:51] [config] train-sets:
[2019-07-15 14:33:51] [config]   - ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.de
[2019-07-15 14:33:51] [config]   - ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.en
[2019-07-15 14:33:51] [config] transformer-aan-activation: swish
[2019-07-15 14:33:51] [config] transformer-aan-depth: 2
[2019-07-15 14:33:51] [config] transformer-aan-nogate: false
[2019-07-15 14:33:51] [config] transformer-decoder-autoreg: self-attention
[2019-07-15 14:33:51] [config] transformer-dim-aan: 2048
[2019-07-15 14:33:51] [config] transformer-dim-ffn: 2048
[2019-07-15 14:33:51] [config] transformer-dropout: 0
[2019-07-15 14:33:51] [config] transformer-dropout-attention: 0
[2019-07-15 14:33:51] [config] transformer-dropout-ffn: 0
[2019-07-15 14:33:51] [config] transformer-ffn-activation: swish
[2019-07-15 14:33:51] [config] transformer-ffn-depth: 2
[2019-07-15 14:33:51] [config] transformer-guided-alignment-layer: last
[2019-07-15 14:33:51] [config] transformer-heads: 8
[2019-07-15 14:33:51] [config] transformer-no-projection: false
[2019-07-15 14:33:51] [config] transformer-postprocess: dan
[2019-07-15 14:33:51] [config] transformer-postprocess-emb: d
[2019-07-15 14:33:51] [config] transformer-preprocess: ""
[2019-07-15 14:33:51] [config] transformer-tied-layers:
[2019-07-15 14:33:51] [config]   []
[2019-07-15 14:33:51] [config] transformer-train-position-embeddings: false
[2019-07-15 14:33:51] [config] type: amun
[2019-07-15 14:33:51] [config] ulr: false
[2019-07-15 14:33:51] [config] ulr-dim-emb: 0
[2019-07-15 14:33:51] [config] ulr-dropout: 0
[2019-07-15 14:33:51] [config] ulr-keys-vectors: ""
[2019-07-15 14:33:51] [config] ulr-query-vectors: ""
[2019-07-15 14:33:51] [config] ulr-softmax-temperature: 1
[2019-07-15 14:33:51] [config] ulr-trainable-transformation: false
[2019-07-15 14:33:51] [config] valid-freq: 20000
[2019-07-15 14:33:51] [config] valid-log: ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/valid.log
[2019-07-15 14:33:51] [config] valid-max-length: 1000
[2019-07-15 14:33:51] [config] valid-metrics:
[2019-07-15 14:33:51] [config]   - cross-entropy
[2019-07-15 14:33:51] [config]   - perplexity
[2019-07-15 14:33:51] [config]   - translation
[2019-07-15 14:33:51] [config] valid-mini-batch: 8
[2019-07-15 14:33:51] [config] valid-script-path: ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/score-dev.sh
[2019-07-15 14:33:51] [config] valid-sets:
[2019-07-15 14:33:51] [config]   - ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/dev.bpe.de
[2019-07-15 14:33:51] [config]   - ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/dev.bpe.en
[2019-07-15 14:33:51] [config] valid-translation-output: ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/dev.out
[2019-07-15 14:33:51] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-15 14:33:51] [config] vocabs:
[2019-07-15 14:33:51] [config]   - ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.de.json
[2019-07-15 14:33:51] [config]   - ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.en.json
[2019-07-15 14:33:51] [config] word-penalty: 0
[2019-07-15 14:33:51] [config] workspace: 5000
[2019-07-15 14:33:51] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-15 14:33:51] Using synchronous training
[2019-07-15 14:33:51] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.de.json
[2019-07-15 14:33:51] [data] Using unused word id eos for 0
[2019-07-15 14:33:51] [data] Using unused word id UNK for 1
[2019-07-15 14:33:51] [data] Setting vocabulary size for input 0 to 50000
[2019-07-15 14:33:51] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/data/train.bpe.en.json
[2019-07-15 14:33:52] [data] Using unused word id eos for 0
[2019-07-15 14:33:52] [data] Using unused word id UNK for 1
[2019-07-15 14:33:52] [data] Setting vocabulary size for input 1 to 50000
[2019-07-15 14:33:52] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-15 14:33:52] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-15 14:33:52] [memory] Extending reserved space to 5120 MB (device gpu2)
[2019-07-15 14:33:53] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-15 14:33:53] [comm] NCCLCommunicator constructed successfully.
[2019-07-15 14:33:53] [training] Using 1 GPUs
[2019-07-15 14:33:53] [memory] Reserving 422 MB, device gpu2
[2019-07-15 14:33:53] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-15 14:33:53] [memory] Reserving 422 MB, device gpu2
[2019-07-15 14:34:01] [batching] Done. Typical MB size is 6880 target words
[2019-07-15 14:34:02] [memory] Extending reserved space to 5120 MB (device gpu2)
[2019-07-15 14:34:02] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-15 14:34:02] [comm] NCCLCommunicator constructed successfully.
[2019-07-15 14:34:02] [training] Using 1 GPUs
[2019-07-15 14:34:02] Loading model from ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-15 14:34:08] Loading Adam parameters from ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-15 14:34:19] [memory] Reserving 844 MB, device gpu2
[2019-07-15 14:34:20] [training] Model reloaded from ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-15 14:34:20] [data] Restoring the corpus state to epoch 19, batch 360000
[2019-07-15 14:34:20] [data] Shuffling data
[2019-07-15 14:34:34] [data] Done reading 4393817 sentences
[2019-07-15 14:34:59] [data] Done shuffling 4393817 sentences to temp files
[2019-07-15 14:35:52] Training started
[2019-07-15 14:35:52] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-07-15 14:35:52] [memory] Reserving 422 MB, device gpu2
[2019-07-15 14:35:53] [memory] Reserving 422 MB, device gpu2
[2019-07-15 14:35:53] Loading model from ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-15 14:35:59] [memory] Reserving 422 MB, device cpu0
[2019-07-15 14:36:00] [memory] Reserving 422 MB, device gpu2
[2019-07-15 14:51:26] Ep. 19 : Up. 362000 : Sen. 1,948,212 : Cost 45.76142502 : Time 1054.23s : 7427.86 words/s
[2019-07-15 15:06:53] Ep. 19 : Up. 364000 : Sen. 2,258,903 : Cost 47.26333618 : Time 926.91s : 8397.17 words/s
[2019-07-15 15:22:27] Ep. 19 : Up. 366000 : Sen. 2,571,308 : Cost 47.40256500 : Time 934.24s : 8385.16 words/s
[2019-07-15 15:37:58] Ep. 19 : Up. 368000 : Sen. 2,882,769 : Cost 47.22972870 : Time 931.41s : 8357.74 words/s
[2019-07-15 15:53:29] Ep. 19 : Up. 370000 : Sen. 3,193,579 : Cost 47.36118698 : Time 930.63s : 8357.57 words/s
[2019-07-15 16:09:01] Ep. 19 : Up. 372000 : Sen. 3,504,196 : Cost 47.16107178 : Time 931.61s : 8331.23 words/s
[2019-07-15 16:24:21] Seen 3810954 samples
[2019-07-15 16:24:21] Starting epoch 20
[2019-07-15 16:24:21] [data] Shuffling data
[2019-07-15 16:24:35] [data] Done reading 4393817 sentences
[2019-07-15 16:24:59] [data] Done shuffling 4393817 sentences to temp files
[2019-07-15 16:25:18] Ep. 20 : Up. 374000 : Sen. 5,134 : Cost 47.57036591 : Time 976.79s : 7997.50 words/s
[2019-07-15 16:40:49] Ep. 20 : Up. 376000 : Sen. 316,411 : Cost 46.22487640 : Time 931.22s : 8361.23 words/s
[2019-07-15 16:56:21] Ep. 20 : Up. 378000 : Sen. 628,416 : Cost 46.60251999 : Time 932.12s : 8384.29 words/s
[2019-07-15 17:11:57] Ep. 20 : Up. 380000 : Sen. 938,633 : Cost 46.61921692 : Time 936.12s : 8286.06 words/s
[2019-07-15 17:11:57] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-15 17:12:06] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.iter380000.npz
[2019-07-15 17:12:16] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-15 17:12:26] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-15 17:12:53] [valid] Ep. 20 : Up. 380000 : cross-entropy : 45.1666 : new best
[2019-07-15 17:13:01] [valid] Ep. 20 : Up. 380000 : perplexity : 5.95132 : new best
[2019-07-15 17:14:11] [valid] Ep. 20 : Up. 380000 : translation : 31.87 : stalled 2 times (last best: 32.11)
[2019-07-15 17:29:58] Ep. 20 : Up. 382000 : Sen. 1,249,066 : Cost 46.77267456 : Time 1080.81s : 7200.95 words/s
[2019-07-15 17:45:46] Ep. 20 : Up. 384000 : Sen. 1,562,672 : Cost 46.69864273 : Time 948.20s : 8267.62 words/s
[2019-07-15 18:01:36] Ep. 20 : Up. 386000 : Sen. 1,874,936 : Cost 46.77676392 : Time 949.60s : 8237.54 words/s
[2019-07-15 18:17:22] Ep. 20 : Up. 388000 : Sen. 2,185,907 : Cost 46.94634628 : Time 946.06s : 8231.83 words/s
[2019-07-15 18:33:08] Ep. 20 : Up. 390000 : Sen. 2,497,663 : Cost 46.92897034 : Time 946.49s : 8236.22 words/s
[2019-07-15 18:48:57] Ep. 20 : Up. 392000 : Sen. 2,810,698 : Cost 47.00044250 : Time 948.90s : 8255.65 words/s
[2019-07-15 19:04:45] Ep. 20 : Up. 394000 : Sen. 3,122,633 : Cost 47.02618027 : Time 947.91s : 8246.10 words/s
[2019-07-15 19:20:34] Ep. 20 : Up. 396000 : Sen. 3,434,621 : Cost 46.95457840 : Time 949.07s : 8221.44 words/s
[2019-07-15 19:27:17] Seen 3567162 samples
[2019-07-15 19:27:17] Starting epoch 21
[2019-07-15 19:27:17] [data] Shuffling data
[2019-07-15 19:27:21] [data] Done reading 4393817 sentences
[2019-07-15 19:27:43] [data] Done shuffling 4393817 sentences to temp files
[2019-07-15 19:36:51] Ep. 21 : Up. 398000 : Sen. 179,562 : Cost 46.40023804 : Time 977.14s : 7991.71 words/s
[2019-07-15 19:52:39] Ep. 21 : Up. 400000 : Sen. 491,298 : Cost 46.14049530 : Time 947.81s : 8233.56 words/s
[2019-07-15 19:52:39] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-15 19:52:48] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.iter400000.npz
[2019-07-15 19:52:55] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-15 19:53:05] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-15 19:53:30] [valid] Ep. 21 : Up. 400000 : cross-entropy : 45.0538 : new best
[2019-07-15 19:53:38] [valid] Ep. 21 : Up. 400000 : perplexity : 5.92487 : new best
[2019-07-15 19:54:49] [valid] Ep. 21 : Up. 400000 : translation : 32.02 : stalled 3 times (last best: 32.11)
[2019-07-15 20:10:35] Ep. 21 : Up. 402000 : Sen. 802,961 : Cost 46.39200211 : Time 1076.41s : 7245.53 words/s
[2019-07-15 20:26:20] Ep. 21 : Up. 404000 : Sen. 1,115,103 : Cost 46.18824768 : Time 944.40s : 8254.64 words/s
[2019-07-15 20:42:05] Ep. 21 : Up. 406000 : Sen. 1,426,357 : Cost 46.64256668 : Time 945.23s : 8252.02 words/s
[2019-07-15 20:57:49] Ep. 21 : Up. 408000 : Sen. 1,737,593 : Cost 46.36340332 : Time 943.85s : 8246.90 words/s
[2019-07-15 21:13:34] Ep. 21 : Up. 410000 : Sen. 2,050,393 : Cost 46.53376007 : Time 945.42s : 8279.37 words/s
[2019-07-15 21:29:15] Ep. 21 : Up. 412000 : Sen. 2,362,038 : Cost 46.48055267 : Time 940.65s : 8285.27 words/s
[2019-07-15 21:45:00] Ep. 21 : Up. 414000 : Sen. 2,675,200 : Cost 46.83182907 : Time 945.49s : 8284.50 words/s
[2019-07-15 22:00:45] Ep. 21 : Up. 416000 : Sen. 2,987,520 : Cost 46.94273376 : Time 944.42s : 8290.28 words/s
[2019-07-15 22:16:28] Ep. 21 : Up. 418000 : Sen. 3,298,747 : Cost 46.96361923 : Time 942.95s : 8278.64 words/s
[2019-07-15 22:29:56] Seen 3567162 samples
[2019-07-15 22:29:56] Starting epoch 22
[2019-07-15 22:29:56] [data] Shuffling data
[2019-07-15 22:30:00] [data] Done reading 4393817 sentences
[2019-07-15 22:30:21] [data] Done shuffling 4393817 sentences to temp files
[2019-07-15 22:32:38] Ep. 22 : Up. 420000 : Sen. 44,438 : Cost 46.91167068 : Time 969.88s : 8070.29 words/s
[2019-07-15 22:32:38] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-15 22:32:49] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.iter420000.npz
[2019-07-15 22:32:58] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-15 22:33:10] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-15 22:33:39] [valid] Ep. 22 : Up. 420000 : cross-entropy : 45.0346 : new best
[2019-07-15 22:33:47] [valid] Ep. 22 : Up. 420000 : perplexity : 5.92038 : new best
[2019-07-15 22:34:58] [valid] Ep. 22 : Up. 420000 : translation : 32.01 : stalled 4 times (last best: 32.11)
[2019-07-15 22:50:46] Ep. 22 : Up. 422000 : Sen. 358,136 : Cost 45.59883881 : Time 1087.92s : 7208.30 words/s
[2019-07-15 23:06:30] Ep. 22 : Up. 424000 : Sen. 670,862 : Cost 45.97152328 : Time 944.55s : 8294.18 words/s
[2019-07-15 23:22:10] Ep. 22 : Up. 426000 : Sen. 982,415 : Cost 46.09725571 : Time 939.80s : 8295.66 words/s
[2019-07-15 23:37:53] Ep. 22 : Up. 428000 : Sen. 1,294,541 : Cost 46.27581024 : Time 942.66s : 8291.36 words/s
[2019-07-15 23:53:34] Ep. 22 : Up. 430000 : Sen. 1,606,549 : Cost 46.26958466 : Time 941.58s : 8292.76 words/s
[2019-07-16 00:09:19] Ep. 22 : Up. 432000 : Sen. 1,918,542 : Cost 46.41786575 : Time 944.78s : 8273.89 words/s
[2019-07-16 00:24:59] Ep. 22 : Up. 434000 : Sen. 2,230,259 : Cost 46.34934235 : Time 940.50s : 8282.12 words/s
[2019-07-16 00:40:40] Ep. 22 : Up. 436000 : Sen. 2,542,490 : Cost 46.46496582 : Time 940.53s : 8303.00 words/s
[2019-07-16 00:56:22] Ep. 22 : Up. 438000 : Sen. 2,854,268 : Cost 46.63876343 : Time 941.96s : 8276.43 words/s
[2019-07-16 01:12:04] Ep. 22 : Up. 440000 : Sen. 3,166,491 : Cost 46.76617813 : Time 941.76s : 8294.20 words/s
[2019-07-16 01:12:04] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-16 01:12:13] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.iter440000.npz
[2019-07-16 01:12:20] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-16 01:12:29] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-16 01:12:55] [valid] Ep. 22 : Up. 440000 : cross-entropy : 45.016 : new best
[2019-07-16 01:13:02] [valid] Ep. 22 : Up. 440000 : perplexity : 5.91602 : new best
[2019-07-16 01:14:14] [valid] Ep. 22 : Up. 440000 : translation : 32.17 : new best
[2019-07-16 01:29:58] Ep. 22 : Up. 442000 : Sen. 3,477,500 : Cost 46.87532425 : Time 1074.44s : 7265.06 words/s
[2019-07-16 01:34:31] Seen 3567162 samples
[2019-07-16 01:34:31] Starting epoch 23
[2019-07-16 01:34:31] [data] Shuffling data
[2019-07-16 01:34:34] [data] Done reading 4393817 sentences
[2019-07-16 01:34:55] [data] Done shuffling 4393817 sentences to temp files
[2019-07-16 01:46:06] Ep. 23 : Up. 444000 : Sen. 220,891 : Cost 45.80240250 : Time 967.79s : 8039.22 words/s
[2019-07-16 02:01:44] Ep. 23 : Up. 446000 : Sen. 531,955 : Cost 45.81056213 : Time 938.20s : 8288.16 words/s
[2019-07-16 02:17:26] Ep. 23 : Up. 448000 : Sen. 844,188 : Cost 45.87047958 : Time 942.18s : 8298.16 words/s
[2019-07-16 02:33:11] Ep. 23 : Up. 450000 : Sen. 1,156,327 : Cost 46.11014938 : Time 944.79s : 8290.22 words/s
[2019-07-16 02:48:52] Ep. 23 : Up. 452000 : Sen. 1,468,794 : Cost 45.98933792 : Time 941.20s : 8289.56 words/s
[2019-07-16 03:04:34] Ep. 23 : Up. 454000 : Sen. 1,780,880 : Cost 46.08865356 : Time 941.92s : 8289.76 words/s
[2019-07-16 03:20:17] Ep. 23 : Up. 456000 : Sen. 2,091,414 : Cost 46.35483932 : Time 942.57s : 8263.42 words/s
[2019-07-16 03:35:59] Ep. 23 : Up. 458000 : Sen. 2,403,919 : Cost 46.16130447 : Time 942.05s : 8289.41 words/s
[2019-07-16 03:51:42] Ep. 23 : Up. 460000 : Sen. 2,715,939 : Cost 46.29458237 : Time 943.43s : 8285.23 words/s
[2019-07-16 03:51:42] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-16 03:51:51] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.iter460000.npz
[2019-07-16 03:51:58] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-16 03:52:07] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-16 03:52:33] [valid] Ep. 23 : Up. 460000 : cross-entropy : 45.0544 : stalled 1 times (last best: 45.016)
[2019-07-16 03:52:41] [valid] Ep. 23 : Up. 460000 : perplexity : 5.925 : stalled 1 times (last best: 5.91602)
[2019-07-16 03:53:52] [valid] Ep. 23 : Up. 460000 : translation : 32.26 : new best
[2019-07-16 04:09:35] Ep. 23 : Up. 462000 : Sen. 3,027,464 : Cost 46.62976456 : Time 1072.88s : 7260.51 words/s
[2019-07-16 04:25:15] Ep. 23 : Up. 464000 : Sen. 3,339,185 : Cost 46.13773346 : Time 939.64s : 8283.44 words/s
[2019-07-16 04:36:45] Seen 3567162 samples
[2019-07-16 04:36:45] Starting epoch 24
[2019-07-16 04:36:45] [data] Shuffling data
[2019-07-16 04:36:48] [data] Done reading 4393817 sentences
[2019-07-16 04:37:14] [data] Done shuffling 4393817 sentences to temp files
[2019-07-16 04:41:30] Ep. 24 : Up. 466000 : Sen. 84,354 : Cost 46.44657516 : Time 975.25s : 8033.03 words/s
[2019-07-16 04:57:09] Ep. 24 : Up. 468000 : Sen. 395,355 : Cost 45.38796616 : Time 939.31s : 8282.37 words/s
[2019-07-16 05:12:53] Ep. 24 : Up. 470000 : Sen. 707,620 : Cost 45.67660141 : Time 943.21s : 8283.80 words/s
[2019-07-16 05:28:37] Ep. 24 : Up. 472000 : Sen. 1,020,502 : Cost 45.64879990 : Time 944.82s : 8291.78 words/s
[2019-07-16 05:44:21] Ep. 24 : Up. 474000 : Sen. 1,332,570 : Cost 45.87317657 : Time 943.11s : 8277.48 words/s
[2019-07-16 06:00:03] Ep. 24 : Up. 476000 : Sen. 1,644,000 : Cost 46.22756958 : Time 942.88s : 8280.23 words/s
[2019-07-16 06:15:46] Ep. 24 : Up. 478000 : Sen. 1,955,709 : Cost 45.99101257 : Time 942.53s : 8275.47 words/s
[2019-07-16 06:31:25] Ep. 24 : Up. 480000 : Sen. 2,267,623 : Cost 45.84590530 : Time 938.84s : 8278.92 words/s
[2019-07-16 06:31:25] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-16 06:31:39] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.iter480000.npz
[2019-07-16 06:31:46] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-16 06:31:56] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-16 06:32:21] [valid] Ep. 24 : Up. 480000 : cross-entropy : 45.091 : stalled 2 times (last best: 45.016)
[2019-07-16 06:32:29] [valid] Ep. 24 : Up. 480000 : perplexity : 5.93356 : stalled 2 times (last best: 5.91602)
[2019-07-16 06:33:40] [valid] Ep. 24 : Up. 480000 : translation : 32.25 : stalled 1 times (last best: 32.26)
[2019-07-16 06:49:24] Ep. 24 : Up. 482000 : Sen. 2,578,486 : Cost 46.35910797 : Time 1079.56s : 7222.41 words/s
[2019-07-16 07:05:09] Ep. 24 : Up. 484000 : Sen. 2,891,110 : Cost 46.25982285 : Time 944.18s : 8288.04 words/s
[2019-07-16 07:20:49] Ep. 24 : Up. 486000 : Sen. 3,201,710 : Cost 46.48657227 : Time 940.10s : 8286.31 words/s
[2019-07-16 07:36:29] Ep. 24 : Up. 488000 : Sen. 3,512,489 : Cost 46.33104706 : Time 940.10s : 8278.07 words/s
[2019-07-16 07:39:13] Seen 3567162 samples
[2019-07-16 07:39:13] Starting epoch 25
[2019-07-16 07:39:13] [data] Shuffling data
[2019-07-16 07:39:17] [data] Done reading 4393817 sentences
[2019-07-16 07:39:42] [data] Done shuffling 4393817 sentences to temp files
[2019-07-16 07:52:39] Ep. 25 : Up. 490000 : Sen. 256,480 : Cost 45.58460236 : Time 970.22s : 8024.13 words/s
[2019-07-16 08:08:22] Ep. 25 : Up. 492000 : Sen. 568,021 : Cost 45.59381485 : Time 942.76s : 8273.74 words/s
[2019-07-16 08:24:06] Ep. 25 : Up. 494000 : Sen. 879,303 : Cost 45.54309082 : Time 943.77s : 8258.44 words/s
[2019-07-16 08:39:45] Ep. 25 : Up. 496000 : Sen. 1,190,136 : Cost 45.61044693 : Time 939.56s : 8261.67 words/s
[2019-07-16 08:55:27] Ep. 25 : Up. 498000 : Sen. 1,501,633 : Cost 45.75297546 : Time 942.36s : 8282.47 words/s
[2019-07-16 09:11:09] Ep. 25 : Up. 500000 : Sen. 1,813,434 : Cost 45.73189163 : Time 941.27s : 8265.52 words/s
[2019-07-16 09:11:09] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-16 09:11:18] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.iter500000.npz
[2019-07-16 09:11:25] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-16 09:11:34] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-16 09:11:59] [valid] Ep. 25 : Up. 500000 : cross-entropy : 45.0505 : stalled 3 times (last best: 45.016)
[2019-07-16 09:12:07] [valid] Ep. 25 : Up. 500000 : perplexity : 5.9241 : stalled 3 times (last best: 5.91602)
[2019-07-16 09:13:18] [valid] Ep. 25 : Up. 500000 : translation : 32.33 : new best
[2019-07-16 09:29:03] Ep. 25 : Up. 502000 : Sen. 2,123,992 : Cost 45.98697281 : Time 1073.88s : 7248.19 words/s
[2019-07-16 09:44:48] Ep. 25 : Up. 504000 : Sen. 2,435,631 : Cost 46.04295349 : Time 945.41s : 8268.24 words/s
[2019-07-16 10:00:33] Ep. 25 : Up. 506000 : Sen. 2,748,200 : Cost 45.89278030 : Time 945.30s : 8276.61 words/s
[2019-07-16 10:16:17] Ep. 25 : Up. 508000 : Sen. 3,060,240 : Cost 46.13256073 : Time 943.99s : 8264.87 words/s
[2019-07-16 10:31:59] Ep. 25 : Up. 510000 : Sen. 3,371,900 : Cost 45.91847229 : Time 941.73s : 8280.83 words/s
[2019-07-16 10:41:53] Seen 3567162 samples
[2019-07-16 10:41:53] Starting epoch 26
[2019-07-16 10:41:53] [data] Shuffling data
[2019-07-16 10:41:56] [data] Done reading 4393817 sentences
[2019-07-16 10:42:18] [data] Done shuffling 4393817 sentences to temp files
[2019-07-16 10:48:11] Ep. 26 : Up. 512000 : Sen. 115,200 : Cost 45.66510391 : Time 971.62s : 8002.98 words/s
[2019-07-16 11:03:54] Ep. 26 : Up. 514000 : Sen. 426,543 : Cost 45.14839172 : Time 942.83s : 8261.83 words/s
[2019-07-16 11:19:36] Ep. 26 : Up. 516000 : Sen. 738,062 : Cost 45.29788971 : Time 942.96s : 8291.12 words/s
[2019-07-16 11:35:21] Ep. 26 : Up. 518000 : Sen. 1,050,741 : Cost 45.23972702 : Time 944.61s : 8280.76 words/s
[2019-07-16 11:51:04] Ep. 26 : Up. 520000 : Sen. 1,361,983 : Cost 45.22679520 : Time 942.55s : 8263.05 words/s
[2019-07-16 11:51:04] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-16 11:51:13] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.iter520000.npz
[2019-07-16 11:51:20] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-16 11:51:29] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-16 11:51:54] [valid] Ep. 26 : Up. 520000 : cross-entropy : 45.0826 : stalled 4 times (last best: 45.016)
[2019-07-16 11:52:02] [valid] Ep. 26 : Up. 520000 : perplexity : 5.93161 : stalled 4 times (last best: 5.91602)
[2019-07-16 11:53:12] [valid] Ep. 26 : Up. 520000 : translation : 32.33 : stalled 1 times (last best: 32.33)
[2019-07-16 12:08:56] Ep. 26 : Up. 522000 : Sen. 1,673,948 : Cost 45.61784363 : Time 1072.57s : 7274.63 words/s
[2019-07-16 12:24:38] Ep. 26 : Up. 524000 : Sen. 1,985,842 : Cost 45.81331253 : Time 941.90s : 8284.12 words/s
[2019-07-16 12:40:23] Ep. 26 : Up. 526000 : Sen. 2,297,600 : Cost 45.76485062 : Time 944.69s : 8261.24 words/s
[2019-07-16 12:56:05] Ep. 26 : Up. 528000 : Sen. 2,609,729 : Cost 45.90809631 : Time 942.35s : 8276.21 words/s
[2019-07-16 13:11:48] Ep. 26 : Up. 530000 : Sen. 2,921,098 : Cost 46.01734924 : Time 942.96s : 8276.37 words/s
[2019-07-16 13:27:33] Ep. 26 : Up. 532000 : Sen. 3,234,173 : Cost 46.05093765 : Time 945.31s : 8277.15 words/s
[2019-07-16 13:43:18] Ep. 26 : Up. 534000 : Sen. 3,546,452 : Cost 46.11344528 : Time 944.51s : 8277.28 words/s
[2019-07-16 13:44:22] Seen 3567162 samples
[2019-07-16 13:44:22] Starting epoch 27
[2019-07-16 13:44:22] [data] Shuffling data
[2019-07-16 13:44:25] [data] Done reading 4393817 sentences
[2019-07-16 13:44:47] [data] Done shuffling 4393817 sentences to temp files
[2019-07-16 13:59:28] Ep. 27 : Up. 536000 : Sen. 290,771 : Cost 45.07093048 : Time 970.41s : 8034.99 words/s
[2019-07-16 14:15:15] Ep. 27 : Up. 538000 : Sen. 602,796 : Cost 45.16725159 : Time 946.52s : 8257.59 words/s
[2019-07-16 14:31:00] Ep. 27 : Up. 540000 : Sen. 914,894 : Cost 45.32088470 : Time 944.82s : 8261.72 words/s
[2019-07-16 14:31:00] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-16 14:31:09] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.iter540000.npz
[2019-07-16 14:31:16] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-16 14:31:25] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
[2019-07-16 14:31:50] [valid] Ep. 27 : Up. 540000 : cross-entropy : 45.0818 : stalled 5 times (last best: 45.016)
[2019-07-16 14:31:58] [valid] Ep. 27 : Up. 540000 : perplexity : 5.93141 : stalled 5 times (last best: 5.91602)
[2019-07-16 14:33:10] [valid] Ep. 27 : Up. 540000 : translation : 32.31 : stalled 2 times (last best: 32.33)
[2019-07-16 14:33:11] Training finished
[2019-07-16 14:33:15] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.orig.npz
[2019-07-16 14:33:24] Saving model to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz
[2019-07-16 14:33:34] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_bic1.1_x_ced_0.0/model/model.npz.optimizer.npz
