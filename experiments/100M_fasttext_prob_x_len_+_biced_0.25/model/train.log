[2019-07-17 20:36:36] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-17 20:36:36] [marian] Running on hretha as process 21975 with command line:
[2019-07-17 20:36:36] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz -T . --devices 2 --train-sets ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.de ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.en --vocabs ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.de.json ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.en.json --mini-batch-fit -w 5000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/data/dev.bpe.de ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/dev.out --valid-script-path ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/train.log --valid-log ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/valid.log
[2019-07-17 20:36:36] [config] after-batches: 0
[2019-07-17 20:36:36] [config] after-epochs: 0
[2019-07-17 20:36:36] [config] allow-unk: false
[2019-07-17 20:36:36] [config] beam-size: 12
[2019-07-17 20:36:36] [config] bert-class-symbol: "[CLS]"
[2019-07-17 20:36:36] [config] bert-mask-symbol: "[MASK]"
[2019-07-17 20:36:36] [config] bert-masking-fraction: 0.15
[2019-07-17 20:36:36] [config] bert-sep-symbol: "[SEP]"
[2019-07-17 20:36:36] [config] bert-train-type-embeddings: true
[2019-07-17 20:36:36] [config] bert-type-vocab-size: 2
[2019-07-17 20:36:36] [config] best-deep: false
[2019-07-17 20:36:36] [config] clip-gemm: 0
[2019-07-17 20:36:36] [config] clip-norm: 1
[2019-07-17 20:36:36] [config] cost-type: ce-mean
[2019-07-17 20:36:36] [config] cpu-threads: 0
[2019-07-17 20:36:36] [config] data-weighting: ""
[2019-07-17 20:36:36] [config] data-weighting-type: sentence
[2019-07-17 20:36:36] [config] dec-cell: gru
[2019-07-17 20:36:36] [config] dec-cell-base-depth: 2
[2019-07-17 20:36:36] [config] dec-cell-high-depth: 1
[2019-07-17 20:36:36] [config] dec-depth: 1
[2019-07-17 20:36:36] [config] devices:
[2019-07-17 20:36:36] [config]   - 2
[2019-07-17 20:36:36] [config] dim-emb: 512
[2019-07-17 20:36:36] [config] dim-rnn: 1024
[2019-07-17 20:36:36] [config] dim-vocabs:
[2019-07-17 20:36:36] [config]   - 50000
[2019-07-17 20:36:36] [config]   - 50000
[2019-07-17 20:36:36] [config] disp-first: 0
[2019-07-17 20:36:36] [config] disp-freq: 2000
[2019-07-17 20:36:36] [config] disp-label-counts: false
[2019-07-17 20:36:36] [config] dropout-rnn: 0.2
[2019-07-17 20:36:36] [config] dropout-src: 0.1
[2019-07-17 20:36:36] [config] dropout-trg: 0.1
[2019-07-17 20:36:36] [config] dump-config: ""
[2019-07-17 20:36:36] [config] early-stopping: 5
[2019-07-17 20:36:36] [config] embedding-fix-src: false
[2019-07-17 20:36:36] [config] embedding-fix-trg: false
[2019-07-17 20:36:36] [config] embedding-normalization: false
[2019-07-17 20:36:36] [config] embedding-vectors:
[2019-07-17 20:36:36] [config]   []
[2019-07-17 20:36:36] [config] enc-cell: gru
[2019-07-17 20:36:36] [config] enc-cell-depth: 1
[2019-07-17 20:36:36] [config] enc-depth: 1
[2019-07-17 20:36:36] [config] enc-type: bidirectional
[2019-07-17 20:36:36] [config] exponential-smoothing: 0.0001
[2019-07-17 20:36:36] [config] grad-dropping-momentum: 0
[2019-07-17 20:36:36] [config] grad-dropping-rate: 0
[2019-07-17 20:36:36] [config] grad-dropping-warmup: 100
[2019-07-17 20:36:36] [config] guided-alignment: none
[2019-07-17 20:36:36] [config] guided-alignment-cost: mse
[2019-07-17 20:36:36] [config] guided-alignment-weight: 0.1
[2019-07-17 20:36:36] [config] ignore-model-config: false
[2019-07-17 20:36:36] [config] input-types:
[2019-07-17 20:36:36] [config]   []
[2019-07-17 20:36:36] [config] interpolate-env-vars: false
[2019-07-17 20:36:36] [config] keep-best: false
[2019-07-17 20:36:36] [config] label-smoothing: 0
[2019-07-17 20:36:36] [config] layer-normalization: true
[2019-07-17 20:36:36] [config] learn-rate: 0.0001
[2019-07-17 20:36:36] [config] log: ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/train.log
[2019-07-17 20:36:36] [config] log-level: info
[2019-07-17 20:36:36] [config] log-time-zone: ""
[2019-07-17 20:36:36] [config] lr-decay: 0
[2019-07-17 20:36:36] [config] lr-decay-freq: 50000
[2019-07-17 20:36:36] [config] lr-decay-inv-sqrt:
[2019-07-17 20:36:36] [config]   - 0
[2019-07-17 20:36:36] [config] lr-decay-repeat-warmup: false
[2019-07-17 20:36:36] [config] lr-decay-reset-optimizer: false
[2019-07-17 20:36:36] [config] lr-decay-start:
[2019-07-17 20:36:36] [config]   - 10
[2019-07-17 20:36:36] [config]   - 1
[2019-07-17 20:36:36] [config] lr-decay-strategy: epoch+stalled
[2019-07-17 20:36:36] [config] lr-report: false
[2019-07-17 20:36:36] [config] lr-warmup: 0
[2019-07-17 20:36:36] [config] lr-warmup-at-reload: false
[2019-07-17 20:36:36] [config] lr-warmup-cycle: false
[2019-07-17 20:36:36] [config] lr-warmup-start-rate: 0
[2019-07-17 20:36:36] [config] max-length: 50
[2019-07-17 20:36:36] [config] max-length-crop: false
[2019-07-17 20:36:36] [config] max-length-factor: 3
[2019-07-17 20:36:36] [config] maxi-batch: 100
[2019-07-17 20:36:36] [config] maxi-batch-sort: trg
[2019-07-17 20:36:36] [config] mini-batch: 64
[2019-07-17 20:36:36] [config] mini-batch-fit: true
[2019-07-17 20:36:36] [config] mini-batch-fit-step: 10
[2019-07-17 20:36:36] [config] mini-batch-overstuff: 1
[2019-07-17 20:36:36] [config] mini-batch-track-lr: false
[2019-07-17 20:36:36] [config] mini-batch-understuff: 1
[2019-07-17 20:36:36] [config] mini-batch-warmup: 0
[2019-07-17 20:36:36] [config] mini-batch-words: 0
[2019-07-17 20:36:36] [config] mini-batch-words-ref: 0
[2019-07-17 20:36:36] [config] model: ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-17 20:36:36] [config] multi-loss-type: sum
[2019-07-17 20:36:36] [config] multi-node: false
[2019-07-17 20:36:36] [config] multi-node-overlap: true
[2019-07-17 20:36:36] [config] n-best: false
[2019-07-17 20:36:36] [config] no-nccl: false
[2019-07-17 20:36:36] [config] no-reload: false
[2019-07-17 20:36:36] [config] no-restore-corpus: false
[2019-07-17 20:36:36] [config] no-shuffle: false
[2019-07-17 20:36:36] [config] normalize: 1
[2019-07-17 20:36:36] [config] num-devices: 0
[2019-07-17 20:36:36] [config] optimizer: adam
[2019-07-17 20:36:36] [config] optimizer-delay: 1
[2019-07-17 20:36:36] [config] optimizer-params:
[2019-07-17 20:36:36] [config]   []
[2019-07-17 20:36:36] [config] overwrite: false
[2019-07-17 20:36:36] [config] pretrained-model: ""
[2019-07-17 20:36:36] [config] quiet: false
[2019-07-17 20:36:36] [config] quiet-translation: true
[2019-07-17 20:36:36] [config] relative-paths: false
[2019-07-17 20:36:36] [config] right-left: false
[2019-07-17 20:36:36] [config] save-freq: 20000
[2019-07-17 20:36:36] [config] seed: 1111
[2019-07-17 20:36:36] [config] shuffle-in-ram: false
[2019-07-17 20:36:36] [config] skip: false
[2019-07-17 20:36:36] [config] sqlite: ""
[2019-07-17 20:36:36] [config] sqlite-drop: false
[2019-07-17 20:36:36] [config] sync-sgd: true
[2019-07-17 20:36:36] [config] tempdir: .
[2019-07-17 20:36:36] [config] tied-embeddings: false
[2019-07-17 20:36:36] [config] tied-embeddings-all: false
[2019-07-17 20:36:36] [config] tied-embeddings-src: false
[2019-07-17 20:36:36] [config] train-sets:
[2019-07-17 20:36:36] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.de
[2019-07-17 20:36:36] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.en
[2019-07-17 20:36:36] [config] transformer-aan-activation: swish
[2019-07-17 20:36:36] [config] transformer-aan-depth: 2
[2019-07-17 20:36:36] [config] transformer-aan-nogate: false
[2019-07-17 20:36:36] [config] transformer-decoder-autoreg: self-attention
[2019-07-17 20:36:36] [config] transformer-dim-aan: 2048
[2019-07-17 20:36:36] [config] transformer-dim-ffn: 2048
[2019-07-17 20:36:36] [config] transformer-dropout: 0
[2019-07-17 20:36:36] [config] transformer-dropout-attention: 0
[2019-07-17 20:36:36] [config] transformer-dropout-ffn: 0
[2019-07-17 20:36:36] [config] transformer-ffn-activation: swish
[2019-07-17 20:36:36] [config] transformer-ffn-depth: 2
[2019-07-17 20:36:36] [config] transformer-guided-alignment-layer: last
[2019-07-17 20:36:36] [config] transformer-heads: 8
[2019-07-17 20:36:36] [config] transformer-no-projection: false
[2019-07-17 20:36:36] [config] transformer-postprocess: dan
[2019-07-17 20:36:36] [config] transformer-postprocess-emb: d
[2019-07-17 20:36:36] [config] transformer-preprocess: ""
[2019-07-17 20:36:36] [config] transformer-tied-layers:
[2019-07-17 20:36:36] [config]   []
[2019-07-17 20:36:36] [config] transformer-train-position-embeddings: false
[2019-07-17 20:36:36] [config] type: amun
[2019-07-17 20:36:36] [config] ulr: false
[2019-07-17 20:36:36] [config] ulr-dim-emb: 0
[2019-07-17 20:36:36] [config] ulr-dropout: 0
[2019-07-17 20:36:36] [config] ulr-keys-vectors: ""
[2019-07-17 20:36:36] [config] ulr-query-vectors: ""
[2019-07-17 20:36:36] [config] ulr-softmax-temperature: 1
[2019-07-17 20:36:36] [config] ulr-trainable-transformation: false
[2019-07-17 20:36:36] [config] valid-freq: 20000
[2019-07-17 20:36:36] [config] valid-log: ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/valid.log
[2019-07-17 20:36:36] [config] valid-max-length: 1000
[2019-07-17 20:36:36] [config] valid-metrics:
[2019-07-17 20:36:36] [config]   - cross-entropy
[2019-07-17 20:36:36] [config]   - perplexity
[2019-07-17 20:36:36] [config]   - translation
[2019-07-17 20:36:36] [config] valid-mini-batch: 8
[2019-07-17 20:36:36] [config] valid-script-path: ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/score-dev.sh
[2019-07-17 20:36:36] [config] valid-sets:
[2019-07-17 20:36:36] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/data/dev.bpe.de
[2019-07-17 20:36:36] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/data/dev.bpe.en
[2019-07-17 20:36:36] [config] valid-translation-output: ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/dev.out
[2019-07-17 20:36:36] [config] vocabs:
[2019-07-17 20:36:36] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.de.json
[2019-07-17 20:36:36] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.en.json
[2019-07-17 20:36:36] [config] word-penalty: 0
[2019-07-17 20:36:36] [config] workspace: 5000
[2019-07-17 20:36:36] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-17 20:36:36] Using synchronous training
[2019-07-17 20:36:36] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.de.json
[2019-07-17 20:36:37] [data] Using unused word id eos for 0
[2019-07-17 20:36:37] [data] Using unused word id UNK for 1
[2019-07-17 20:36:37] [data] Setting vocabulary size for input 0 to 50000
[2019-07-17 20:36:37] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.en.json
[2019-07-17 20:36:38] [data] Using unused word id eos for 0
[2019-07-17 20:36:38] [data] Using unused word id UNK for 1
[2019-07-17 20:36:38] [data] Setting vocabulary size for input 1 to 50000
[2019-07-17 20:36:38] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-17 20:36:38] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-17 20:36:39] [memory] Extending reserved space to 5120 MB (device gpu2)
[2019-07-17 20:36:39] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-17 20:36:39] [comm] NCCLCommunicator constructed successfully.
[2019-07-17 20:36:39] [training] Using 1 GPUs
[2019-07-17 20:36:39] [memory] Reserving 422 MB, device gpu2
[2019-07-17 20:36:39] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-17 20:36:39] [memory] Reserving 422 MB, device gpu2
[2019-07-17 20:36:48] [batching] Done. Typical MB size is 6880 target words
[2019-07-17 20:36:48] [memory] Extending reserved space to 5120 MB (device gpu2)
[2019-07-17 20:36:48] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-17 20:36:48] [comm] NCCLCommunicator constructed successfully.
[2019-07-17 20:36:48] [training] Using 1 GPUs
[2019-07-17 20:36:48] Training started
[2019-07-17 20:36:48] [data] Shuffling data
[2019-07-17 20:36:55] [data] Done reading 12702121 sentences
[2019-07-17 20:38:10] [data] Done shuffling 12702121 sentences to temp files
[2019-07-17 20:38:20] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-07-17 20:38:20] [memory] Reserving 422 MB, device gpu2
[2019-07-17 20:38:20] [memory] Reserving 422 MB, device gpu2
[2019-07-17 20:38:20] [memory] Reserving 422 MB, device gpu2
[2019-07-17 20:38:20] [memory] Reserving 844 MB, device gpu2
[2019-07-17 20:51:25] Ep. 1 : Up. 2000 : Sen. 286,121 : Cost 140.17210388 : Time 887.36s : 6966.37 words/s
[2019-07-17 21:04:34] Ep. 1 : Up. 4000 : Sen. 572,421 : Cost 121.06793213 : Time 788.61s : 7825.46 words/s
[2019-07-17 21:17:49] Ep. 1 : Up. 6000 : Sen. 860,763 : Cost 112.65117645 : Time 795.54s : 7815.24 words/s
[2019-07-17 21:31:02] Ep. 1 : Up. 8000 : Sen. 1,148,237 : Cost 107.00216675 : Time 793.10s : 7827.65 words/s
[2019-07-17 21:44:15] Ep. 1 : Up. 10000 : Sen. 1,435,362 : Cost 102.52039337 : Time 792.62s : 7811.74 words/s
[2019-07-17 21:57:26] Ep. 1 : Up. 12000 : Sen. 1,723,197 : Cost 99.10121918 : Time 790.88s : 7841.29 words/s
[2019-07-17 22:10:37] Ep. 1 : Up. 14000 : Sen. 2,008,624 : Cost 96.75973511 : Time 791.65s : 7797.23 words/s
[2019-07-17 22:23:50] Ep. 1 : Up. 16000 : Sen. 2,295,470 : Cost 94.24720001 : Time 792.32s : 7807.90 words/s
[2019-07-17 22:37:00] Ep. 1 : Up. 18000 : Sen. 2,581,855 : Cost 92.52490997 : Time 790.70s : 7818.82 words/s
[2019-07-17 22:50:14] Ep. 1 : Up. 20000 : Sen. 2,869,353 : Cost 90.52343750 : Time 793.35s : 7818.41 words/s
[2019-07-17 22:50:14] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-17 22:50:22] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.iter20000.npz
[2019-07-17 22:50:29] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-17 22:50:38] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-17 22:51:07] [valid] Ep. 1 : Up. 20000 : cross-entropy : 90.1782 : new best
[2019-07-17 22:51:14] [valid] Ep. 1 : Up. 20000 : perplexity : 35.5631 : new best
[2019-07-17 22:52:32] [valid] Ep. 1 : Up. 20000 : translation : 12.53 : new best
[2019-07-17 23:05:49] Ep. 1 : Up. 22000 : Sen. 3,156,520 : Cost 89.54291534 : Time 935.62s : 6628.06 words/s
[2019-07-17 23:19:03] Ep. 1 : Up. 24000 : Sen. 3,443,200 : Cost 88.35102844 : Time 793.90s : 7804.14 words/s
[2019-07-17 23:32:13] Ep. 1 : Up. 26000 : Sen. 3,729,486 : Cost 86.93456268 : Time 789.55s : 7810.64 words/s
[2019-07-17 23:45:25] Ep. 1 : Up. 28000 : Sen. 4,015,973 : Cost 86.28114319 : Time 792.51s : 7814.61 words/s
[2019-07-17 23:58:40] Ep. 1 : Up. 30000 : Sen. 4,302,958 : Cost 85.32727051 : Time 794.43s : 7803.78 words/s
[2019-07-18 00:11:52] Ep. 1 : Up. 32000 : Sen. 4,590,111 : Cost 84.24634552 : Time 792.68s : 7805.21 words/s
[2019-07-18 00:25:05] Ep. 1 : Up. 34000 : Sen. 4,877,064 : Cost 83.61348724 : Time 792.93s : 7802.55 words/s
[2019-07-18 00:38:18] Ep. 1 : Up. 36000 : Sen. 5,165,287 : Cost 83.00153351 : Time 792.96s : 7837.34 words/s
[2019-07-18 00:51:35] Ep. 1 : Up. 38000 : Sen. 5,452,404 : Cost 82.55944061 : Time 796.27s : 7795.79 words/s
[2019-07-18 01:04:48] Ep. 1 : Up. 40000 : Sen. 5,739,192 : Cost 81.75556946 : Time 793.15s : 7800.43 words/s
[2019-07-18 01:04:48] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-18 01:04:57] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.iter40000.npz
[2019-07-18 01:05:04] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-18 01:05:13] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-18 01:05:38] [valid] Ep. 1 : Up. 40000 : cross-entropy : 73.1207 : new best
[2019-07-18 01:05:46] [valid] Ep. 1 : Up. 40000 : perplexity : 18.0976 : new best
[2019-07-18 01:06:53] [valid] Ep. 1 : Up. 40000 : translation : 19.61 : new best
[2019-07-18 01:20:10] Ep. 1 : Up. 42000 : Sen. 6,026,307 : Cost 81.16045380 : Time 922.42s : 6713.62 words/s
[2019-07-18 01:33:19] Ep. 1 : Up. 44000 : Sen. 6,312,486 : Cost 80.51115417 : Time 789.07s : 7816.21 words/s
[2019-07-18 01:46:33] Ep. 1 : Up. 46000 : Sen. 6,598,802 : Cost 80.52626038 : Time 793.37s : 7805.10 words/s
[2019-07-18 01:59:48] Ep. 1 : Up. 48000 : Sen. 6,886,136 : Cost 79.80469513 : Time 795.01s : 7793.97 words/s
[2019-07-18 02:13:03] Ep. 1 : Up. 50000 : Sen. 7,173,722 : Cost 79.31571960 : Time 795.80s : 7794.58 words/s
[2019-07-18 02:26:14] Ep. 1 : Up. 52000 : Sen. 7,460,760 : Cost 78.87940979 : Time 790.71s : 7808.62 words/s
[2019-07-18 02:39:26] Ep. 1 : Up. 54000 : Sen. 7,747,597 : Cost 78.69183350 : Time 792.12s : 7801.81 words/s
[2019-07-18 02:52:37] Ep. 1 : Up. 56000 : Sen. 8,034,934 : Cost 78.13930511 : Time 790.98s : 7817.44 words/s
[2019-07-18 03:05:50] Ep. 1 : Up. 58000 : Sen. 8,322,012 : Cost 78.15557098 : Time 792.55s : 7823.11 words/s
[2019-07-18 03:19:02] Ep. 1 : Up. 60000 : Sen. 8,608,000 : Cost 77.79688263 : Time 791.97s : 7797.48 words/s
[2019-07-18 03:19:02] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-18 03:19:12] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.iter60000.npz
[2019-07-18 03:19:19] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-18 03:19:28] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-18 03:19:52] [valid] Ep. 1 : Up. 60000 : cross-entropy : 65.877 : new best
[2019-07-18 03:20:00] [valid] Ep. 1 : Up. 60000 : perplexity : 13.5843 : new best
[2019-07-18 03:21:06] [valid] Ep. 1 : Up. 60000 : translation : 22.03 : new best
[2019-07-18 03:34:22] Ep. 1 : Up. 62000 : Sen. 8,895,231 : Cost 77.45586395 : Time 920.00s : 6730.17 words/s
[2019-07-18 03:47:34] Ep. 1 : Up. 64000 : Sen. 9,181,694 : Cost 77.17855835 : Time 792.05s : 7792.79 words/s
[2019-07-18 04:00:46] Ep. 1 : Up. 66000 : Sen. 9,467,408 : Cost 76.79156494 : Time 792.09s : 7786.02 words/s
[2019-07-18 04:14:01] Ep. 1 : Up. 68000 : Sen. 9,754,607 : Cost 76.52159119 : Time 795.35s : 7796.12 words/s
[2019-07-18 04:27:16] Ep. 1 : Up. 70000 : Sen. 10,041,732 : Cost 76.50239563 : Time 794.68s : 7807.98 words/s
[2019-07-18 04:40:34] Ep. 1 : Up. 72000 : Sen. 10,329,468 : Cost 76.10294342 : Time 797.89s : 7784.89 words/s
[2019-07-18 04:53:47] Ep. 1 : Up. 74000 : Sen. 10,616,485 : Cost 75.72208405 : Time 793.65s : 7787.67 words/s
[2019-07-18 04:54:17] Seen 10627008 samples
[2019-07-18 04:54:17] Starting epoch 2
[2019-07-18 04:54:17] [data] Shuffling data
[2019-07-18 04:54:30] [data] Done reading 12702121 sentences
[2019-07-18 04:55:39] [data] Done shuffling 12702121 sentences to temp files
[2019-07-18 05:08:27] Ep. 2 : Up. 76000 : Sen. 275,860 : Cost 75.17615509 : Time 879.38s : 7046.04 words/s
[2019-07-18 05:21:39] Ep. 2 : Up. 78000 : Sen. 562,498 : Cost 74.84290314 : Time 792.13s : 7804.76 words/s
[2019-07-18 05:34:51] Ep. 2 : Up. 80000 : Sen. 849,625 : Cost 74.54535675 : Time 792.12s : 7812.31 words/s
[2019-07-18 05:34:51] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-18 05:35:00] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.iter80000.npz
[2019-07-18 05:35:07] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-18 05:35:16] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-18 05:35:41] [valid] Ep. 2 : Up. 80000 : cross-entropy : 62.073 : new best
[2019-07-18 05:35:48] [valid] Ep. 2 : Up. 80000 : perplexity : 11.6845 : new best
[2019-07-18 05:36:54] [valid] Ep. 2 : Up. 80000 : translation : 22.96 : new best
[2019-07-18 05:50:08] Ep. 2 : Up. 82000 : Sen. 1,135,560 : Cost 74.39658356 : Time 916.52s : 6741.07 words/s
[2019-07-18 06:03:19] Ep. 2 : Up. 84000 : Sen. 1,423,206 : Cost 74.16881561 : Time 791.81s : 7821.66 words/s
[2019-07-18 06:16:31] Ep. 2 : Up. 86000 : Sen. 1,710,324 : Cost 74.06234741 : Time 791.67s : 7815.06 words/s
[2019-07-18 06:29:45] Ep. 2 : Up. 88000 : Sen. 1,997,468 : Cost 74.03844452 : Time 793.91s : 7799.78 words/s
[2019-07-18 06:42:56] Ep. 2 : Up. 90000 : Sen. 2,284,668 : Cost 73.75402832 : Time 791.32s : 7832.36 words/s
[2019-07-18 06:56:08] Ep. 2 : Up. 92000 : Sen. 2,572,174 : Cost 73.70320892 : Time 792.01s : 7838.32 words/s
[2019-07-18 07:09:21] Ep. 2 : Up. 94000 : Sen. 2,859,250 : Cost 73.69623566 : Time 793.13s : 7818.92 words/s
[2019-07-18 07:22:34] Ep. 2 : Up. 96000 : Sen. 3,146,068 : Cost 73.43928528 : Time 792.11s : 7819.63 words/s
[2019-07-18 07:35:51] Ep. 2 : Up. 98000 : Sen. 3,432,877 : Cost 73.10722351 : Time 797.49s : 7751.86 words/s
[2019-07-18 07:49:02] Ep. 2 : Up. 100000 : Sen. 3,718,970 : Cost 73.09833527 : Time 791.20s : 7798.37 words/s
[2019-07-18 07:49:02] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-18 07:49:19] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.iter100000.npz
[2019-07-18 07:49:26] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-18 07:49:39] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-18 07:50:04] [valid] Ep. 2 : Up. 100000 : cross-entropy : 59.5328 : new best
[2019-07-18 07:50:12] [valid] Ep. 2 : Up. 100000 : perplexity : 10.5663 : new best
[2019-07-18 07:51:17] [valid] Ep. 2 : Up. 100000 : translation : 23.63 : new best
[2019-07-18 08:04:31] Ep. 2 : Up. 102000 : Sen. 4,006,400 : Cost 72.95227051 : Time 928.40s : 6665.81 words/s
[2019-07-18 08:17:42] Ep. 2 : Up. 104000 : Sen. 4,292,615 : Cost 72.88261414 : Time 791.80s : 7797.77 words/s
[2019-07-18 08:30:54] Ep. 2 : Up. 106000 : Sen. 4,578,743 : Cost 72.72869110 : Time 791.20s : 7801.67 words/s
[2019-07-18 08:44:04] Ep. 2 : Up. 108000 : Sen. 4,865,734 : Cost 72.91990662 : Time 790.57s : 7855.76 words/s
[2019-07-18 08:57:11] Ep. 2 : Up. 110000 : Sen. 5,152,132 : Cost 72.30241394 : Time 786.70s : 7848.23 words/s
[2019-07-18 09:10:20] Ep. 2 : Up. 112000 : Sen. 5,438,944 : Cost 72.28447723 : Time 789.10s : 7832.60 words/s
[2019-07-18 09:23:27] Ep. 2 : Up. 114000 : Sen. 5,725,804 : Cost 72.07905579 : Time 786.72s : 7850.72 words/s
[2019-07-18 09:36:33] Ep. 2 : Up. 116000 : Sen. 6,011,356 : Cost 72.29532623 : Time 786.45s : 7840.74 words/s
[2019-07-18 09:49:39] Ep. 2 : Up. 118000 : Sen. 6,297,600 : Cost 71.94682312 : Time 785.99s : 7850.63 words/s
[2019-07-18 10:02:47] Ep. 2 : Up. 120000 : Sen. 6,583,966 : Cost 72.21026611 : Time 787.85s : 7851.67 words/s
[2019-07-18 10:02:47] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-18 10:02:56] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.iter120000.npz
[2019-07-18 10:03:03] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-18 10:03:12] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-18 10:03:37] [valid] Ep. 2 : Up. 120000 : cross-entropy : 57.7766 : new best
[2019-07-18 10:03:45] [valid] Ep. 2 : Up. 120000 : perplexity : 9.85635 : new best
[2019-07-18 10:04:49] [valid] Ep. 2 : Up. 120000 : translation : 23.85 : new best
[2019-07-18 10:18:00] Ep. 2 : Up. 122000 : Sen. 6,870,221 : Cost 71.91745758 : Time 912.52s : 6771.35 words/s
[2019-07-18 10:31:07] Ep. 2 : Up. 124000 : Sen. 7,156,562 : Cost 71.83803558 : Time 787.83s : 7841.03 words/s
[2019-07-18 10:44:17] Ep. 2 : Up. 126000 : Sen. 7,443,068 : Cost 71.61227417 : Time 789.55s : 7819.29 words/s
[2019-07-18 10:57:30] Ep. 2 : Up. 128000 : Sen. 7,729,880 : Cost 71.68206024 : Time 792.61s : 7818.70 words/s
[2019-07-18 11:10:42] Ep. 2 : Up. 130000 : Sen. 8,017,108 : Cost 71.52070618 : Time 792.00s : 7821.90 words/s
[2019-07-18 11:23:52] Ep. 2 : Up. 132000 : Sen. 8,304,043 : Cost 71.23514557 : Time 790.59s : 7818.81 words/s
[2019-07-18 11:37:01] Ep. 2 : Up. 134000 : Sen. 8,590,734 : Cost 71.17983246 : Time 788.85s : 7839.31 words/s
[2019-07-18 11:50:10] Ep. 2 : Up. 136000 : Sen. 8,877,808 : Cost 71.31077576 : Time 789.27s : 7854.49 words/s
[2019-07-18 12:03:16] Ep. 2 : Up. 138000 : Sen. 9,165,066 : Cost 71.09099579 : Time 785.98s : 7893.57 words/s
[2019-07-18 12:16:22] Ep. 2 : Up. 140000 : Sen. 9,451,633 : Cost 70.97797394 : Time 785.93s : 7867.56 words/s
[2019-07-18 12:16:22] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-18 12:16:31] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.iter140000.npz
[2019-07-18 12:16:38] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-18 12:16:47] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-18 12:17:11] [valid] Ep. 2 : Up. 140000 : cross-entropy : 56.5397 : new best
[2019-07-18 12:17:18] [valid] Ep. 2 : Up. 140000 : perplexity : 9.38515 : new best
[2019-07-18 12:18:21] [valid] Ep. 2 : Up. 140000 : translation : 24.3 : new best
[2019-07-18 12:31:33] Ep. 2 : Up. 142000 : Sen. 9,739,096 : Cost 70.93112183 : Time 910.50s : 6806.48 words/s
[2019-07-18 12:44:43] Ep. 2 : Up. 144000 : Sen. 10,027,076 : Cost 70.86460876 : Time 790.19s : 7856.87 words/s
[2019-07-18 12:57:54] Ep. 2 : Up. 146000 : Sen. 10,314,399 : Cost 71.18514252 : Time 791.38s : 7852.72 words/s
[2019-07-18 13:11:05] Ep. 2 : Up. 148000 : Sen. 10,601,318 : Cost 70.69651031 : Time 790.86s : 7821.72 words/s
[2019-07-18 13:12:16] Seen 10627008 samples
[2019-07-18 13:12:16] Starting epoch 3
[2019-07-18 13:12:16] [data] Shuffling data
[2019-07-18 13:12:34] [data] Done reading 12702121 sentences
[2019-07-18 13:13:37] [data] Done shuffling 12702121 sentences to temp files
[2019-07-18 13:25:37] Ep. 3 : Up. 150000 : Sen. 261,138 : Cost 69.71086884 : Time 871.53s : 7088.36 words/s
[2019-07-18 13:38:47] Ep. 3 : Up. 152000 : Sen. 548,226 : Cost 69.90384674 : Time 789.83s : 7853.32 words/s
[2019-07-18 13:51:55] Ep. 3 : Up. 154000 : Sen. 833,801 : Cost 69.33602905 : Time 788.31s : 7795.53 words/s
[2019-07-18 14:05:09] Ep. 3 : Up. 156000 : Sen. 1,121,114 : Cost 69.87092590 : Time 794.65s : 7822.06 words/s
[2019-07-18 14:18:16] Ep. 3 : Up. 158000 : Sen. 1,407,025 : Cost 69.56865692 : Time 786.64s : 7831.23 words/s
[2019-07-18 14:31:32] Ep. 3 : Up. 160000 : Sen. 1,693,903 : Cost 69.56614685 : Time 795.67s : 7769.29 words/s
[2019-07-18 14:31:32] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-18 14:31:41] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.iter160000.npz
[2019-07-18 14:31:48] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-18 14:31:58] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-18 14:32:23] [valid] Ep. 3 : Up. 160000 : cross-entropy : 55.536 : new best
[2019-07-18 14:32:31] [valid] Ep. 3 : Up. 160000 : perplexity : 9.01943 : new best
[2019-07-18 14:33:40] [valid] Ep. 3 : Up. 160000 : translation : 24.47 : new best
[2019-07-18 14:46:56] Ep. 3 : Up. 162000 : Sen. 1,980,741 : Cost 69.67745209 : Time 924.02s : 6699.22 words/s
[2019-07-18 15:00:12] Ep. 3 : Up. 164000 : Sen. 2,268,157 : Cost 69.65637970 : Time 796.42s : 7796.52 words/s
[2019-07-18 15:13:24] Ep. 3 : Up. 166000 : Sen. 2,555,009 : Cost 69.70182037 : Time 791.65s : 7829.09 words/s
[2019-07-18 15:26:36] Ep. 3 : Up. 168000 : Sen. 2,841,790 : Cost 69.27546692 : Time 792.12s : 7810.83 words/s
[2019-07-18 15:39:53] Ep. 3 : Up. 170000 : Sen. 3,128,433 : Cost 69.69941711 : Time 797.32s : 7761.54 words/s
[2019-07-18 15:53:05] Ep. 3 : Up. 172000 : Sen. 3,415,714 : Cost 69.36598969 : Time 792.17s : 7820.32 words/s
[2019-07-18 16:06:17] Ep. 3 : Up. 174000 : Sen. 3,701,740 : Cost 69.33873749 : Time 791.88s : 7784.75 words/s
[2019-07-18 16:19:30] Ep. 3 : Up. 176000 : Sen. 3,988,745 : Cost 69.22906494 : Time 793.03s : 7807.04 words/s
[2019-07-18 16:32:42] Ep. 3 : Up. 178000 : Sen. 4,274,630 : Cost 69.13128662 : Time 791.41s : 7796.57 words/s
[2019-07-18 16:45:56] Ep. 3 : Up. 180000 : Sen. 4,561,806 : Cost 69.12577820 : Time 794.10s : 7799.46 words/s
[2019-07-18 16:45:56] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-18 16:46:05] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.iter180000.npz
[2019-07-18 16:46:12] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-18 16:46:22] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-18 16:46:47] [valid] Ep. 3 : Up. 180000 : cross-entropy : 54.8471 : new best
[2019-07-18 16:46:54] [valid] Ep. 3 : Up. 180000 : perplexity : 8.77668 : new best
[2019-07-18 16:48:01] [valid] Ep. 3 : Up. 180000 : translation : 24.76 : new best
[2019-07-18 17:01:22] Ep. 3 : Up. 182000 : Sen. 4,848,826 : Cost 69.14289093 : Time 926.52s : 6687.76 words/s
[2019-07-18 17:14:35] Ep. 3 : Up. 184000 : Sen. 5,136,114 : Cost 69.20999908 : Time 792.18s : 7832.79 words/s
[2019-07-18 17:27:43] Ep. 3 : Up. 186000 : Sen. 5,423,245 : Cost 68.94400787 : Time 788.27s : 7841.36 words/s
[2019-07-18 17:40:55] Ep. 3 : Up. 188000 : Sen. 5,710,705 : Cost 69.19833374 : Time 792.01s : 7847.68 words/s
[2019-07-18 17:54:07] Ep. 3 : Up. 190000 : Sen. 5,997,824 : Cost 69.04886627 : Time 792.59s : 7821.24 words/s
[2019-07-18 18:07:17] Ep. 3 : Up. 192000 : Sen. 6,284,932 : Cost 68.70825958 : Time 789.29s : 7824.97 words/s
[2019-07-18 18:20:24] Ep. 3 : Up. 194000 : Sen. 6,571,428 : Cost 68.57719421 : Time 787.60s : 7847.71 words/s
[2019-07-18 18:33:33] Ep. 3 : Up. 196000 : Sen. 6,858,174 : Cost 68.58318329 : Time 788.82s : 7822.29 words/s
[2019-07-18 18:46:43] Ep. 3 : Up. 198000 : Sen. 7,144,362 : Cost 68.96134186 : Time 790.20s : 7827.37 words/s
[2019-07-18 18:59:54] Ep. 3 : Up. 200000 : Sen. 7,431,588 : Cost 68.78708649 : Time 790.81s : 7837.45 words/s
[2019-07-18 18:59:54] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-18 19:00:09] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.iter200000.npz
[2019-07-18 19:00:16] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-18 19:00:28] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-18 19:00:55] [valid] Ep. 3 : Up. 200000 : cross-entropy : 54.2033 : new best
[2019-07-18 19:01:02] [valid] Ep. 3 : Up. 200000 : perplexity : 8.55574 : new best
[2019-07-18 19:02:06] [valid] Ep. 3 : Up. 200000 : translation : 25.07 : new best
[2019-07-18 19:15:18] Ep. 3 : Up. 202000 : Sen. 7,719,242 : Cost 68.66259003 : Time 924.17s : 6716.50 words/s
[2019-07-18 19:28:27] Ep. 3 : Up. 204000 : Sen. 8,006,268 : Cost 68.32396698 : Time 788.96s : 7830.60 words/s
[2019-07-18 19:41:37] Ep. 3 : Up. 206000 : Sen. 8,292,432 : Cost 68.59637451 : Time 790.08s : 7822.45 words/s
[2019-07-18 19:54:48] Ep. 3 : Up. 208000 : Sen. 8,579,283 : Cost 68.68717957 : Time 790.52s : 7843.39 words/s
[2019-07-18 20:07:55] Ep. 3 : Up. 210000 : Sen. 8,866,002 : Cost 68.34935760 : Time 786.69s : 7855.47 words/s
[2019-07-18 20:21:03] Ep. 3 : Up. 212000 : Sen. 9,151,868 : Cost 68.62551117 : Time 788.64s : 7824.31 words/s
[2019-07-18 20:34:16] Ep. 3 : Up. 214000 : Sen. 9,438,770 : Cost 68.44322205 : Time 792.91s : 7814.60 words/s
[2019-07-18 20:47:24] Ep. 3 : Up. 216000 : Sen. 9,724,528 : Cost 68.49102020 : Time 787.42s : 7826.24 words/s
[2019-07-18 21:00:32] Ep. 3 : Up. 218000 : Sen. 10,010,656 : Cost 68.26032257 : Time 787.89s : 7840.58 words/s
[2019-07-18 21:13:39] Ep. 3 : Up. 220000 : Sen. 10,296,193 : Cost 68.38184357 : Time 787.10s : 7823.68 words/s
[2019-07-18 21:13:39] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-18 21:13:48] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.iter220000.npz
[2019-07-18 21:13:55] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-18 21:14:05] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-18 21:14:29] [valid] Ep. 3 : Up. 220000 : cross-entropy : 53.5491 : new best
[2019-07-18 21:14:36] [valid] Ep. 3 : Up. 220000 : perplexity : 8.33691 : new best
[2019-07-18 21:15:41] [valid] Ep. 3 : Up. 220000 : translation : 24.59 : stalled 1 times (last best: 25.07)
[2019-07-18 21:28:53] Ep. 3 : Up. 222000 : Sen. 10,583,663 : Cost 68.28818512 : Time 914.24s : 6779.58 words/s
[2019-07-18 21:30:54] Seen 10627008 samples
[2019-07-18 21:30:54] Starting epoch 4
[2019-07-18 21:30:54] [data] Shuffling data
[2019-07-18 21:31:03] [data] Done reading 12702121 sentences
[2019-07-18 21:32:17] [data] Done shuffling 12702121 sentences to temp files
[2019-07-18 21:43:29] Ep. 4 : Up. 224000 : Sen. 243,200 : Cost 67.50973511 : Time 876.07s : 7061.88 words/s
[2019-07-18 21:56:38] Ep. 4 : Up. 226000 : Sen. 530,804 : Cost 67.45866394 : Time 789.12s : 7859.07 words/s
[2019-07-18 22:09:48] Ep. 4 : Up. 228000 : Sen. 818,672 : Cost 67.63981628 : Time 789.96s : 7869.88 words/s
[2019-07-18 22:22:58] Ep. 4 : Up. 230000 : Sen. 1,106,341 : Cost 67.34215546 : Time 790.33s : 7861.84 words/s
[2019-07-18 22:36:10] Ep. 4 : Up. 232000 : Sen. 1,393,384 : Cost 67.50817871 : Time 791.43s : 7834.55 words/s
[2019-07-18 22:49:20] Ep. 4 : Up. 234000 : Sen. 1,681,130 : Cost 67.52365112 : Time 790.12s : 7859.42 words/s
[2019-07-18 23:02:32] Ep. 4 : Up. 236000 : Sen. 1,967,787 : Cost 67.56239319 : Time 792.13s : 7832.10 words/s
[2019-07-18 23:15:43] Ep. 4 : Up. 238000 : Sen. 2,255,236 : Cost 67.46226501 : Time 790.92s : 7837.02 words/s
[2019-07-18 23:28:53] Ep. 4 : Up. 240000 : Sen. 2,542,600 : Cost 67.56649780 : Time 790.42s : 7856.25 words/s
[2019-07-18 23:28:53] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-18 23:29:03] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.iter240000.npz
[2019-07-18 23:29:09] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-18 23:29:19] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-18 23:29:42] [valid] Ep. 4 : Up. 240000 : cross-entropy : 53.1939 : new best
[2019-07-18 23:29:50] [valid] Ep. 4 : Up. 240000 : perplexity : 8.22047 : new best
[2019-07-18 23:30:55] [valid] Ep. 4 : Up. 240000 : translation : 24.9 : stalled 2 times (last best: 25.07)
[2019-07-18 23:44:06] Ep. 4 : Up. 242000 : Sen. 2,829,954 : Cost 67.47269440 : Time 912.60s : 6798.44 words/s
[2019-07-18 23:57:17] Ep. 4 : Up. 244000 : Sen. 3,116,932 : Cost 67.35847473 : Time 791.13s : 7827.17 words/s
[2019-07-19 00:10:23] Ep. 4 : Up. 246000 : Sen. 3,403,460 : Cost 67.14857483 : Time 786.31s : 7845.97 words/s
[2019-07-19 00:23:39] Ep. 4 : Up. 248000 : Sen. 3,691,516 : Cost 67.45820618 : Time 795.60s : 7812.84 words/s
[2019-07-19 00:36:49] Ep. 4 : Up. 250000 : Sen. 3,978,534 : Cost 67.13887024 : Time 789.55s : 7843.45 words/s
[2019-07-19 00:49:56] Ep. 4 : Up. 252000 : Sen. 4,266,020 : Cost 67.23813629 : Time 787.36s : 7866.38 words/s
[2019-07-19 01:03:05] Ep. 4 : Up. 254000 : Sen. 4,552,333 : Cost 67.40728760 : Time 788.73s : 7832.03 words/s
[2019-07-19 01:16:11] Ep. 4 : Up. 256000 : Sen. 4,839,736 : Cost 67.34371185 : Time 786.78s : 7874.92 words/s
[2019-07-19 01:29:21] Ep. 4 : Up. 258000 : Sen. 5,126,268 : Cost 67.26405334 : Time 789.54s : 7830.13 words/s
[2019-07-19 01:42:31] Ep. 4 : Up. 260000 : Sen. 5,412,956 : Cost 67.49299622 : Time 790.43s : 7845.64 words/s
[2019-07-19 01:42:31] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-19 01:42:43] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.iter260000.npz
[2019-07-19 01:42:51] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 01:43:00] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-19 01:43:23] [valid] Ep. 4 : Up. 260000 : cross-entropy : 52.8756 : new best
[2019-07-19 01:43:31] [valid] Ep. 4 : Up. 260000 : perplexity : 8.1175 : new best
[2019-07-19 01:44:34] [valid] Ep. 4 : Up. 260000 : translation : 25.23 : new best
[2019-07-19 01:57:45] Ep. 4 : Up. 262000 : Sen. 5,699,697 : Cost 66.93771362 : Time 913.74s : 6755.67 words/s
[2019-07-19 02:10:53] Ep. 4 : Up. 264000 : Sen. 5,986,585 : Cost 67.08539581 : Time 788.20s : 7835.79 words/s
[2019-07-19 02:24:01] Ep. 4 : Up. 266000 : Sen. 6,272,967 : Cost 67.24964905 : Time 787.48s : 7847.43 words/s
[2019-07-19 02:37:11] Ep. 4 : Up. 268000 : Sen. 6,559,536 : Cost 67.14400482 : Time 790.65s : 7824.70 words/s
[2019-07-19 02:50:27] Ep. 4 : Up. 270000 : Sen. 6,847,344 : Cost 67.11943817 : Time 795.83s : 7796.96 words/s
[2019-07-19 03:03:41] Ep. 4 : Up. 272000 : Sen. 7,134,478 : Cost 67.20304871 : Time 794.08s : 7809.15 words/s
[2019-07-19 03:16:54] Ep. 4 : Up. 274000 : Sen. 7,421,715 : Cost 66.83740997 : Time 792.12s : 7813.70 words/s
[2019-07-19 03:30:02] Ep. 4 : Up. 276000 : Sen. 7,707,420 : Cost 66.79799652 : Time 788.42s : 7800.09 words/s
[2019-07-19 03:43:19] Ep. 4 : Up. 278000 : Sen. 7,994,384 : Cost 67.20847321 : Time 796.97s : 7773.75 words/s
[2019-07-19 03:56:39] Ep. 4 : Up. 280000 : Sen. 8,282,869 : Cost 66.90425110 : Time 800.54s : 7769.26 words/s
[2019-07-19 03:56:39] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-19 03:56:49] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.iter280000.npz
[2019-07-19 03:56:56] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 03:57:06] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-19 03:57:31] [valid] Ep. 4 : Up. 280000 : cross-entropy : 52.4747 : new best
[2019-07-19 03:57:39] [valid] Ep. 4 : Up. 280000 : perplexity : 7.98964 : new best
[2019-07-19 03:58:48] [valid] Ep. 4 : Up. 280000 : translation : 25.02 : stalled 1 times (last best: 25.23)
[2019-07-19 04:12:05] Ep. 4 : Up. 282000 : Sen. 8,569,322 : Cost 66.99164581 : Time 925.26s : 6680.78 words/s
[2019-07-19 04:25:19] Ep. 4 : Up. 284000 : Sen. 8,855,677 : Cost 66.97175598 : Time 794.48s : 7784.91 words/s
[2019-07-19 04:38:33] Ep. 4 : Up. 286000 : Sen. 9,143,099 : Cost 67.02468109 : Time 794.24s : 7811.30 words/s
[2019-07-19 04:51:46] Ep. 4 : Up. 288000 : Sen. 9,428,988 : Cost 66.68572235 : Time 793.01s : 7774.43 words/s
[2019-07-19 05:05:02] Ep. 4 : Up. 290000 : Sen. 9,715,728 : Cost 67.03910065 : Time 795.81s : 7787.73 words/s
[2019-07-19 05:18:13] Ep. 4 : Up. 292000 : Sen. 10,003,200 : Cost 66.39094543 : Time 790.86s : 7817.56 words/s
[2019-07-19 05:31:28] Ep. 4 : Up. 294000 : Sen. 10,290,408 : Cost 67.03801727 : Time 794.38s : 7805.44 words/s
[2019-07-19 05:44:45] Ep. 4 : Up. 296000 : Sen. 10,577,875 : Cost 66.90179443 : Time 797.33s : 7776.98 words/s
[2019-07-19 05:47:03] Seen 10627008 samples
[2019-07-19 05:47:03] Starting epoch 5
[2019-07-19 05:47:03] [data] Shuffling data
[2019-07-19 05:47:11] [data] Done reading 12702121 sentences
[2019-07-19 05:48:17] [data] Done shuffling 12702121 sentences to temp files
[2019-07-19 05:59:20] Ep. 5 : Up. 298000 : Sen. 237,671 : Cost 65.97220612 : Time 875.15s : 7065.25 words/s
[2019-07-19 06:12:33] Ep. 5 : Up. 300000 : Sen. 524,115 : Cost 65.96477509 : Time 792.89s : 7793.51 words/s
[2019-07-19 06:12:33] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-19 06:12:42] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.iter300000.npz
[2019-07-19 06:12:49] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 06:12:58] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-19 06:13:22] [valid] Ep. 5 : Up. 300000 : cross-entropy : 52.179 : new best
[2019-07-19 06:13:30] [valid] Ep. 5 : Up. 300000 : perplexity : 7.89661 : new best
[2019-07-19 06:14:38] [valid] Ep. 5 : Up. 300000 : translation : 24.96 : stalled 2 times (last best: 25.23)
[2019-07-19 06:27:56] Ep. 5 : Up. 302000 : Sen. 811,560 : Cost 65.68307495 : Time 923.34s : 6707.32 words/s
[2019-07-19 06:41:10] Ep. 5 : Up. 304000 : Sen. 1,097,532 : Cost 66.02656555 : Time 794.16s : 7774.00 words/s
[2019-07-19 06:54:24] Ep. 5 : Up. 306000 : Sen. 1,384,034 : Cost 65.77063751 : Time 793.41s : 7790.64 words/s
[2019-07-19 07:07:39] Ep. 5 : Up. 308000 : Sen. 1,671,732 : Cost 66.03784943 : Time 794.98s : 7798.03 words/s
[2019-07-19 07:20:56] Ep. 5 : Up. 310000 : Sen. 1,958,268 : Cost 66.16933441 : Time 797.23s : 7762.38 words/s
[2019-07-19 07:34:11] Ep. 5 : Up. 312000 : Sen. 2,245,626 : Cost 66.15864563 : Time 795.09s : 7811.03 words/s
[2019-07-19 07:47:23] Ep. 5 : Up. 314000 : Sen. 2,531,316 : Cost 66.06332397 : Time 791.53s : 7793.59 words/s
[2019-07-19 08:00:32] Ep. 5 : Up. 316000 : Sen. 2,817,844 : Cost 66.00189209 : Time 789.11s : 7838.89 words/s
[2019-07-19 08:13:46] Ep. 5 : Up. 318000 : Sen. 3,105,944 : Cost 65.70522308 : Time 794.52s : 7801.76 words/s
[2019-07-19 08:27:01] Ep. 5 : Up. 320000 : Sen. 3,393,943 : Cost 66.03582001 : Time 794.81s : 7804.41 words/s
[2019-07-19 08:27:01] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-19 08:27:10] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.iter320000.npz
[2019-07-19 08:27:17] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 08:27:26] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-19 08:27:50] [valid] Ep. 5 : Up. 320000 : cross-entropy : 52.0345 : new best
[2019-07-19 08:27:57] [valid] Ep. 5 : Up. 320000 : perplexity : 7.85153 : new best
[2019-07-19 08:29:06] [valid] Ep. 5 : Up. 320000 : translation : 24.8 : stalled 3 times (last best: 25.23)
[2019-07-19 08:42:23] Ep. 5 : Up. 322000 : Sen. 3,681,188 : Cost 66.30972290 : Time 921.51s : 6735.99 words/s
[2019-07-19 08:55:37] Ep. 5 : Up. 324000 : Sen. 3,969,557 : Cost 66.12908936 : Time 794.16s : 7825.63 words/s
[2019-07-19 09:08:51] Ep. 5 : Up. 326000 : Sen. 4,255,868 : Cost 66.31195068 : Time 794.42s : 7797.16 words/s
[2019-07-19 09:22:11] Ep. 5 : Up. 328000 : Sen. 4,543,243 : Cost 65.93540192 : Time 799.45s : 7752.28 words/s
[2019-07-19 09:35:23] Ep. 5 : Up. 330000 : Sen. 4,830,134 : Cost 65.88842773 : Time 792.85s : 7801.86 words/s
[2019-07-19 09:48:36] Ep. 5 : Up. 332000 : Sen. 5,116,936 : Cost 66.10709381 : Time 792.32s : 7805.39 words/s
[2019-07-19 10:01:51] Ep. 5 : Up. 334000 : Sen. 5,405,173 : Cost 65.65971375 : Time 795.05s : 7808.20 words/s
[2019-07-19 10:15:04] Ep. 5 : Up. 336000 : Sen. 5,692,291 : Cost 66.04977417 : Time 793.42s : 7823.50 words/s
[2019-07-19 10:28:13] Ep. 5 : Up. 338000 : Sen. 5,978,260 : Cost 65.87020874 : Time 788.29s : 7814.13 words/s
[2019-07-19 10:41:23] Ep. 5 : Up. 340000 : Sen. 6,264,544 : Cost 65.95137787 : Time 790.00s : 7806.77 words/s
[2019-07-19 10:41:23] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-19 10:41:31] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.iter340000.npz
[2019-07-19 10:41:38] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 10:41:48] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-19 10:42:13] [valid] Ep. 5 : Up. 340000 : cross-entropy : 51.8194 : new best
[2019-07-19 10:42:21] [valid] Ep. 5 : Up. 340000 : perplexity : 7.78496 : new best
[2019-07-19 10:43:28] [valid] Ep. 5 : Up. 340000 : translation : 24.9 : stalled 4 times (last best: 25.23)
[2019-07-19 10:56:44] Ep. 5 : Up. 342000 : Sen. 6,551,480 : Cost 65.87002563 : Time 921.44s : 6716.03 words/s
[2019-07-19 11:09:57] Ep. 5 : Up. 344000 : Sen. 6,837,943 : Cost 66.11752319 : Time 793.49s : 7804.20 words/s
[2019-07-19 11:23:11] Ep. 5 : Up. 346000 : Sen. 7,125,081 : Cost 65.78617096 : Time 793.84s : 7785.47 words/s
[2019-07-19 11:36:26] Ep. 5 : Up. 348000 : Sen. 7,411,068 : Cost 65.96717834 : Time 795.16s : 7764.28 words/s
[2019-07-19 11:49:40] Ep. 5 : Up. 350000 : Sen. 7,698,366 : Cost 65.80867004 : Time 793.52s : 7812.51 words/s
[2019-07-19 12:02:56] Ep. 5 : Up. 352000 : Sen. 7,986,456 : Cost 65.94168091 : Time 796.47s : 7815.02 words/s
[2019-07-19 12:16:05] Ep. 5 : Up. 354000 : Sen. 8,272,533 : Cost 66.08554840 : Time 789.00s : 7836.46 words/s
[2019-07-19 12:29:20] Ep. 5 : Up. 356000 : Sen. 8,559,696 : Cost 66.03999329 : Time 794.48s : 7798.10 words/s
[2019-07-19 12:42:29] Ep. 5 : Up. 358000 : Sen. 8,845,935 : Cost 65.79642487 : Time 789.06s : 7818.26 words/s
[2019-07-19 12:55:43] Ep. 5 : Up. 360000 : Sen. 9,131,614 : Cost 65.92208099 : Time 793.75s : 7762.90 words/s
[2019-07-19 12:55:43] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-19 12:55:52] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.iter360000.npz
[2019-07-19 12:56:04] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 12:56:15] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-19 12:56:39] [valid] Ep. 5 : Up. 360000 : cross-entropy : 51.5942 : new best
[2019-07-19 12:56:46] [valid] Ep. 5 : Up. 360000 : perplexity : 7.71583 : new best
[2019-07-19 12:57:54] [valid] Ep. 5 : Up. 360000 : translation : 25.24 : new best
[2019-07-19 13:11:12] Ep. 5 : Up. 362000 : Sen. 9,418,293 : Cost 65.71430969 : Time 928.75s : 6649.97 words/s
[2019-07-19 13:24:27] Ep. 5 : Up. 364000 : Sen. 9,705,669 : Cost 66.02917480 : Time 795.94s : 7826.47 words/s
[2019-07-19 13:37:45] Ep. 5 : Up. 366000 : Sen. 9,993,174 : Cost 65.75345612 : Time 797.62s : 7757.59 words/s
[2019-07-19 13:51:00] Ep. 5 : Up. 368000 : Sen. 10,280,549 : Cost 65.76908875 : Time 794.89s : 7796.64 words/s
[2019-07-19 14:04:15] Ep. 5 : Up. 370000 : Sen. 10,566,970 : Cost 65.83773804 : Time 795.39s : 7782.71 words/s
[2019-07-19 14:07:03] Seen 10627008 samples
[2019-07-19 14:07:03] Starting epoch 6
[2019-07-19 14:07:03] [data] Shuffling data
[2019-07-19 14:07:10] [data] Done reading 12702121 sentences
[2019-07-19 14:08:17] [data] Done shuffling 12702121 sentences to temp files
[2019-07-19 14:18:45] Ep. 6 : Up. 372000 : Sen. 226,183 : Cost 65.26742554 : Time 869.32s : 7116.66 words/s
[2019-07-19 14:32:02] Ep. 6 : Up. 374000 : Sen. 513,589 : Cost 64.82467651 : Time 796.88s : 7772.89 words/s
[2019-07-19 14:45:14] Ep. 6 : Up. 376000 : Sen. 800,531 : Cost 64.91615295 : Time 791.99s : 7809.43 words/s
[2019-07-19 14:58:26] Ep. 6 : Up. 378000 : Sen. 1,086,867 : Cost 64.87306213 : Time 792.05s : 7786.34 words/s
[2019-07-19 15:11:41] Ep. 6 : Up. 380000 : Sen. 1,374,203 : Cost 65.01611328 : Time 795.35s : 7798.33 words/s
[2019-07-19 15:11:41] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-19 15:11:50] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.iter380000.npz
[2019-07-19 15:11:57] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 15:12:06] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-19 15:12:30] [valid] Ep. 6 : Up. 380000 : cross-entropy : 51.3996 : new best
[2019-07-19 15:12:38] [valid] Ep. 6 : Up. 380000 : perplexity : 7.65659 : new best
[2019-07-19 15:13:44] [valid] Ep. 6 : Up. 380000 : translation : 25.27 : new best
[2019-07-19 15:27:03] Ep. 6 : Up. 382000 : Sen. 1,660,719 : Cost 65.24607849 : Time 922.10s : 6711.17 words/s
[2019-07-19 15:40:20] Ep. 6 : Up. 384000 : Sen. 1,948,308 : Cost 65.14760590 : Time 796.89s : 7777.48 words/s
[2019-07-19 15:53:36] Ep. 6 : Up. 386000 : Sen. 2,234,392 : Cost 65.28695679 : Time 796.11s : 7757.77 words/s
[2019-07-19 16:06:49] Ep. 6 : Up. 388000 : Sen. 2,521,468 : Cost 65.01608276 : Time 792.53s : 7805.04 words/s
[2019-07-19 16:20:05] Ep. 6 : Up. 390000 : Sen. 2,808,267 : Cost 65.17546844 : Time 796.53s : 7778.96 words/s
[2019-07-19 16:33:18] Ep. 6 : Up. 392000 : Sen. 3,093,918 : Cost 65.24476624 : Time 792.87s : 7782.24 words/s
[2019-07-19 16:46:32] Ep. 6 : Up. 394000 : Sen. 3,381,057 : Cost 64.95767975 : Time 794.12s : 7799.54 words/s
[2019-07-19 16:59:43] Ep. 6 : Up. 396000 : Sen. 3,668,298 : Cost 64.89057922 : Time 791.21s : 7837.67 words/s
[2019-07-19 17:12:57] Ep. 6 : Up. 398000 : Sen. 3,954,936 : Cost 65.09989929 : Time 793.28s : 7787.25 words/s
[2019-07-19 17:26:12] Ep. 6 : Up. 400000 : Sen. 4,241,425 : Cost 65.38626862 : Time 794.98s : 7798.30 words/s
[2019-07-19 17:26:12] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-19 17:26:21] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.iter400000.npz
[2019-07-19 17:26:28] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 17:26:38] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-19 17:27:01] [valid] Ep. 6 : Up. 400000 : cross-entropy : 51.3652 : new best
[2019-07-19 17:27:09] [valid] Ep. 6 : Up. 400000 : perplexity : 7.64616 : new best
[2019-07-19 17:28:15] [valid] Ep. 6 : Up. 400000 : translation : 25.31 : new best
[2019-07-19 17:41:28] Ep. 6 : Up. 402000 : Sen. 4,527,995 : Cost 65.11171722 : Time 916.77s : 6740.43 words/s
[2019-07-19 17:54:43] Ep. 6 : Up. 404000 : Sen. 4,814,294 : Cost 65.04054260 : Time 794.29s : 7760.88 words/s
[2019-07-19 18:08:00] Ep. 6 : Up. 406000 : Sen. 5,101,442 : Cost 65.36726379 : Time 797.01s : 7785.64 words/s
[2019-07-19 18:21:16] Ep. 6 : Up. 408000 : Sen. 5,388,536 : Cost 65.32810974 : Time 796.62s : 7789.29 words/s
[2019-07-19 18:34:27] Ep. 6 : Up. 410000 : Sen. 5,674,546 : Cost 65.16271973 : Time 790.47s : 7794.12 words/s
[2019-07-19 18:47:44] Ep. 6 : Up. 412000 : Sen. 5,962,331 : Cost 65.06114960 : Time 797.21s : 7775.83 words/s
[2019-07-19 19:00:58] Ep. 6 : Up. 414000 : Sen. 6,248,823 : Cost 65.40067291 : Time 793.85s : 7803.10 words/s
[2019-07-19 19:14:15] Ep. 6 : Up. 416000 : Sen. 6,536,316 : Cost 65.13543701 : Time 797.05s : 7786.67 words/s
[2019-07-19 19:27:30] Ep. 6 : Up. 418000 : Sen. 6,822,400 : Cost 65.10234070 : Time 794.99s : 7763.21 words/s
[2019-07-19 19:40:42] Ep. 6 : Up. 420000 : Sen. 7,108,727 : Cost 64.69380951 : Time 792.42s : 7776.44 words/s
[2019-07-19 19:40:42] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-19 19:40:52] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.iter420000.npz
[2019-07-19 19:40:59] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 19:41:08] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-19 19:41:33] [valid] Ep. 6 : Up. 420000 : cross-entropy : 51.2717 : new best
[2019-07-19 19:41:41] [valid] Ep. 6 : Up. 420000 : perplexity : 7.6179 : new best
[2019-07-19 19:42:49] [valid] Ep. 6 : Up. 420000 : translation : 25.1 : stalled 1 times (last best: 25.31)
[2019-07-19 19:56:05] Ep. 6 : Up. 422000 : Sen. 7,395,846 : Cost 64.86061859 : Time 922.38s : 6709.55 words/s
[2019-07-19 20:09:17] Ep. 6 : Up. 424000 : Sen. 7,682,311 : Cost 65.22987366 : Time 792.55s : 7792.47 words/s
[2019-07-19 20:22:32] Ep. 6 : Up. 426000 : Sen. 7,969,362 : Cost 65.28373718 : Time 795.23s : 7795.30 words/s
[2019-07-19 20:35:44] Ep. 6 : Up. 428000 : Sen. 8,256,230 : Cost 64.83238983 : Time 791.34s : 7796.85 words/s
[2019-07-19 20:48:57] Ep. 6 : Up. 430000 : Sen. 8,542,698 : Cost 65.14130402 : Time 793.01s : 7802.57 words/s
[2019-07-19 21:02:06] Ep. 6 : Up. 432000 : Sen. 8,827,843 : Cost 65.24086761 : Time 789.71s : 7785.83 words/s
[2019-07-19 21:15:18] Ep. 6 : Up. 434000 : Sen. 9,114,736 : Cost 65.10640717 : Time 791.57s : 7819.70 words/s
[2019-07-19 21:28:31] Ep. 6 : Up. 436000 : Sen. 9,401,204 : Cost 65.22095490 : Time 792.93s : 7796.14 words/s
[2019-07-19 21:41:49] Ep. 6 : Up. 438000 : Sen. 9,689,732 : Cost 65.26246643 : Time 798.43s : 7810.88 words/s
[2019-07-19 21:55:04] Ep. 6 : Up. 440000 : Sen. 9,977,054 : Cost 65.17182922 : Time 794.14s : 7809.20 words/s
[2019-07-19 21:55:04] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-19 21:55:13] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.iter440000.npz
[2019-07-19 21:55:20] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 21:55:29] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-19 21:55:58] [valid] Ep. 6 : Up. 440000 : cross-entropy : 51.0804 : new best
[2019-07-19 21:56:05] [valid] Ep. 6 : Up. 440000 : perplexity : 7.56042 : new best
[2019-07-19 21:57:15] [valid] Ep. 6 : Up. 440000 : translation : 25.11 : stalled 2 times (last best: 25.31)
[2019-07-19 22:10:28] Ep. 6 : Up. 442000 : Sen. 10,263,083 : Cost 65.19460297 : Time 924.64s : 6682.02 words/s
[2019-07-19 22:23:43] Ep. 6 : Up. 444000 : Sen. 10,549,362 : Cost 64.84665680 : Time 795.04s : 7763.62 words/s
[2019-07-19 22:27:20] Seen 10627008 samples
[2019-07-19 22:27:20] Starting epoch 7
[2019-07-19 22:27:20] [data] Shuffling data
[2019-07-19 22:27:27] [data] Done reading 12702121 sentences
[2019-07-19 22:28:34] [data] Done shuffling 12702121 sentences to temp files
[2019-07-19 22:38:16] Ep. 7 : Up. 446000 : Sen. 209,242 : Cost 64.45847321 : Time 872.98s : 7088.21 words/s
[2019-07-19 22:51:31] Ep. 7 : Up. 448000 : Sen. 495,862 : Cost 64.48806763 : Time 795.14s : 7796.04 words/s
[2019-07-19 23:04:43] Ep. 7 : Up. 450000 : Sen. 782,327 : Cost 64.44971466 : Time 791.93s : 7797.79 words/s
[2019-07-19 23:18:01] Ep. 7 : Up. 452000 : Sen. 1,068,932 : Cost 64.41622925 : Time 798.12s : 7748.23 words/s
[2019-07-19 23:31:19] Ep. 7 : Up. 454000 : Sen. 1,355,265 : Cost 64.56837463 : Time 797.90s : 7748.05 words/s
[2019-07-19 23:44:36] Ep. 7 : Up. 456000 : Sen. 1,642,330 : Cost 64.47834778 : Time 796.87s : 7772.57 words/s
[2019-07-19 23:57:55] Ep. 7 : Up. 458000 : Sen. 1,929,235 : Cost 64.45484161 : Time 798.71s : 7751.53 words/s
[2019-07-20 00:11:08] Ep. 7 : Up. 460000 : Sen. 2,215,401 : Cost 64.23474121 : Time 792.81s : 7783.37 words/s
[2019-07-20 00:11:08] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-20 00:11:20] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.iter460000.npz
[2019-07-20 00:11:30] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-20 00:11:43] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-20 00:12:20] [valid] Ep. 7 : Up. 460000 : cross-entropy : 51.0333 : new best
[2019-07-20 00:12:28] [valid] Ep. 7 : Up. 460000 : perplexity : 7.54632 : new best
[2019-07-20 00:13:40] [valid] Ep. 7 : Up. 460000 : translation : 25.29 : stalled 3 times (last best: 25.31)
[2019-07-20 00:26:56] Ep. 7 : Up. 462000 : Sen. 2,501,834 : Cost 64.51955414 : Time 948.51s : 6519.83 words/s
[2019-07-20 00:40:08] Ep. 7 : Up. 464000 : Sen. 2,788,017 : Cost 64.36458588 : Time 791.46s : 7790.93 words/s
[2019-07-20 00:53:22] Ep. 7 : Up. 466000 : Sen. 3,074,018 : Cost 64.55098724 : Time 794.68s : 7762.68 words/s
[2019-07-20 01:06:38] Ep. 7 : Up. 468000 : Sen. 3,361,634 : Cost 64.26033020 : Time 795.65s : 7794.96 words/s
[2019-07-20 01:19:52] Ep. 7 : Up. 470000 : Sen. 3,648,284 : Cost 64.41490936 : Time 793.87s : 7803.41 words/s
[2019-07-20 01:33:05] Ep. 7 : Up. 472000 : Sen. 3,934,541 : Cost 64.28710175 : Time 792.93s : 7782.34 words/s
[2019-07-20 01:46:19] Ep. 7 : Up. 474000 : Sen. 4,221,975 : Cost 64.61066437 : Time 794.69s : 7816.66 words/s
[2019-07-20 01:59:36] Ep. 7 : Up. 476000 : Sen. 4,509,650 : Cost 64.35839081 : Time 796.61s : 7799.51 words/s
[2019-07-20 02:12:53] Ep. 7 : Up. 478000 : Sen. 4,795,622 : Cost 64.47787476 : Time 797.22s : 7749.85 words/s
[2019-07-20 02:26:12] Ep. 7 : Up. 480000 : Sen. 5,083,400 : Cost 64.44636536 : Time 798.89s : 7764.40 words/s
[2019-07-20 02:26:12] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-20 02:26:21] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.iter480000.npz
[2019-07-20 02:26:28] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-20 02:26:38] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-20 02:27:02] [valid] Ep. 7 : Up. 480000 : cross-entropy : 50.8797 : new best
[2019-07-20 02:27:10] [valid] Ep. 7 : Up. 480000 : perplexity : 7.50055 : new best
[2019-07-20 02:28:15] [valid] Ep. 7 : Up. 480000 : translation : 25.46 : new best
[2019-07-20 02:41:33] Ep. 7 : Up. 482000 : Sen. 5,369,460 : Cost 64.36870575 : Time 921.14s : 6698.22 words/s
[2019-07-20 02:54:46] Ep. 7 : Up. 484000 : Sen. 5,656,307 : Cost 64.67134094 : Time 792.28s : 7802.57 words/s
[2019-07-20 03:08:00] Ep. 7 : Up. 486000 : Sen. 5,942,778 : Cost 64.61995697 : Time 794.33s : 7777.85 words/s
[2019-07-20 03:21:21] Ep. 7 : Up. 488000 : Sen. 6,229,823 : Cost 64.84683990 : Time 801.30s : 7753.51 words/s
[2019-07-20 03:34:40] Ep. 7 : Up. 490000 : Sen. 6,518,064 : Cost 64.22830963 : Time 798.95s : 7773.67 words/s
[2019-07-20 03:48:02] Ep. 7 : Up. 492000 : Sen. 6,806,117 : Cost 64.58283997 : Time 801.42s : 7760.38 words/s
[2019-07-20 04:01:17] Ep. 7 : Up. 494000 : Sen. 7,093,205 : Cost 64.41294861 : Time 795.19s : 7790.57 words/s
[2019-07-20 04:14:31] Ep. 7 : Up. 496000 : Sen. 7,379,541 : Cost 64.50063324 : Time 793.83s : 7775.41 words/s
[2019-07-20 04:27:41] Ep. 7 : Up. 498000 : Sen. 7,664,760 : Cost 64.50814056 : Time 790.67s : 7790.23 words/s
[2019-07-20 04:41:00] Ep. 7 : Up. 500000 : Sen. 7,951,808 : Cost 64.65069580 : Time 798.27s : 7754.93 words/s
[2019-07-20 04:41:00] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-20 04:41:09] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.iter500000.npz
[2019-07-20 04:41:15] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-20 04:41:25] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-20 04:41:49] [valid] Ep. 7 : Up. 500000 : cross-entropy : 50.7293 : new best
[2019-07-20 04:41:57] [valid] Ep. 7 : Up. 500000 : perplexity : 7.45602 : new best
[2019-07-20 04:43:05] [valid] Ep. 7 : Up. 500000 : translation : 25.35 : stalled 1 times (last best: 25.46)
[2019-07-20 04:56:27] Ep. 7 : Up. 502000 : Sen. 8,239,884 : Cost 64.37214661 : Time 927.42s : 6696.56 words/s
[2019-07-20 05:09:42] Ep. 7 : Up. 504000 : Sen. 8,527,263 : Cost 64.36174774 : Time 795.04s : 7790.61 words/s
[2019-07-20 05:22:58] Ep. 7 : Up. 506000 : Sen. 8,814,512 : Cost 64.46609497 : Time 795.85s : 7784.23 words/s
[2019-07-20 05:36:13] Ep. 7 : Up. 508000 : Sen. 9,101,245 : Cost 64.36712646 : Time 794.94s : 7787.74 words/s
[2019-07-20 05:49:32] Ep. 7 : Up. 510000 : Sen. 9,389,507 : Cost 64.42723846 : Time 799.41s : 7769.64 words/s
[2019-07-20 06:02:51] Ep. 7 : Up. 512000 : Sen. 9,676,800 : Cost 64.60500336 : Time 798.88s : 7766.14 words/s
[2019-07-20 06:16:06] Ep. 7 : Up. 514000 : Sen. 9,964,800 : Cost 64.38510895 : Time 795.13s : 7812.18 words/s
[2019-07-20 06:29:18] Ep. 7 : Up. 516000 : Sen. 10,251,227 : Cost 64.50743103 : Time 791.32s : 7793.43 words/s
[2019-07-20 06:42:32] Ep. 7 : Up. 518000 : Sen. 10,538,000 : Cost 64.42712402 : Time 794.07s : 7787.51 words/s
[2019-07-20 06:46:39] Seen 10627008 samples
[2019-07-20 06:46:39] Starting epoch 8
[2019-07-20 06:46:39] [data] Shuffling data
[2019-07-20 06:46:46] [data] Done reading 12702121 sentences
[2019-07-20 06:47:53] [data] Done shuffling 12702121 sentences to temp files
[2019-07-20 06:57:05] Ep. 8 : Up. 520000 : Sen. 198,136 : Cost 64.01419067 : Time 872.99s : 7101.00 words/s
[2019-07-20 06:57:05] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-20 06:57:14] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.iter520000.npz
[2019-07-20 06:57:21] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-20 06:57:30] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-20 06:57:54] [valid] Ep. 8 : Up. 520000 : cross-entropy : 50.5683 : new best
[2019-07-20 06:58:01] [valid] Ep. 8 : Up. 520000 : perplexity : 7.40864 : new best
[2019-07-20 06:59:08] [valid] Ep. 8 : Up. 520000 : translation : 25.6 : new best
[2019-07-20 07:12:23] Ep. 8 : Up. 522000 : Sen. 483,817 : Cost 63.96561050 : Time 918.46s : 6726.38 words/s
