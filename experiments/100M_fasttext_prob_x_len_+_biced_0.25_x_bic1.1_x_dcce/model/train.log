[2019-07-17 23:34:18] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-17 23:34:18] [marian] Running on hodor as process 10501 with command line:
[2019-07-17 23:34:18] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz -T . --devices 0 --train-sets ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.de ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.en --vocabs ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.de.json ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.en.json --mini-batch-fit -w 5000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/dev.bpe.de ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/dev.out --valid-script-path ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/train.log --valid-log ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/valid.log
[2019-07-17 23:34:18] [config] after-batches: 0
[2019-07-17 23:34:18] [config] after-epochs: 0
[2019-07-17 23:34:18] [config] allow-unk: false
[2019-07-17 23:34:18] [config] beam-size: 12
[2019-07-17 23:34:18] [config] bert-class-symbol: "[CLS]"
[2019-07-17 23:34:18] [config] bert-mask-symbol: "[MASK]"
[2019-07-17 23:34:18] [config] bert-masking-fraction: 0.15
[2019-07-17 23:34:18] [config] bert-sep-symbol: "[SEP]"
[2019-07-17 23:34:18] [config] bert-train-type-embeddings: true
[2019-07-17 23:34:18] [config] bert-type-vocab-size: 2
[2019-07-17 23:34:18] [config] best-deep: false
[2019-07-17 23:34:18] [config] clip-gemm: 0
[2019-07-17 23:34:18] [config] clip-norm: 1
[2019-07-17 23:34:18] [config] cost-type: ce-mean
[2019-07-17 23:34:18] [config] cpu-threads: 0
[2019-07-17 23:34:18] [config] data-weighting: ""
[2019-07-17 23:34:18] [config] data-weighting-type: sentence
[2019-07-17 23:34:18] [config] dec-cell: gru
[2019-07-17 23:34:18] [config] dec-cell-base-depth: 2
[2019-07-17 23:34:18] [config] dec-cell-high-depth: 1
[2019-07-17 23:34:18] [config] dec-depth: 1
[2019-07-17 23:34:18] [config] devices:
[2019-07-17 23:34:18] [config]   - 0
[2019-07-17 23:34:18] [config] dim-emb: 512
[2019-07-17 23:34:18] [config] dim-rnn: 1024
[2019-07-17 23:34:18] [config] dim-vocabs:
[2019-07-17 23:34:18] [config]   - 50000
[2019-07-17 23:34:18] [config]   - 50000
[2019-07-17 23:34:18] [config] disp-first: 0
[2019-07-17 23:34:18] [config] disp-freq: 2000
[2019-07-17 23:34:18] [config] disp-label-counts: false
[2019-07-17 23:34:18] [config] dropout-rnn: 0.2
[2019-07-17 23:34:18] [config] dropout-src: 0.1
[2019-07-17 23:34:18] [config] dropout-trg: 0.1
[2019-07-17 23:34:18] [config] dump-config: ""
[2019-07-17 23:34:18] [config] early-stopping: 5
[2019-07-17 23:34:18] [config] embedding-fix-src: false
[2019-07-17 23:34:18] [config] embedding-fix-trg: false
[2019-07-17 23:34:18] [config] embedding-normalization: false
[2019-07-17 23:34:18] [config] embedding-vectors:
[2019-07-17 23:34:18] [config]   []
[2019-07-17 23:34:18] [config] enc-cell: gru
[2019-07-17 23:34:18] [config] enc-cell-depth: 1
[2019-07-17 23:34:18] [config] enc-depth: 1
[2019-07-17 23:34:18] [config] enc-type: bidirectional
[2019-07-17 23:34:18] [config] exponential-smoothing: 0.0001
[2019-07-17 23:34:18] [config] grad-dropping-momentum: 0
[2019-07-17 23:34:18] [config] grad-dropping-rate: 0
[2019-07-17 23:34:18] [config] grad-dropping-warmup: 100
[2019-07-17 23:34:18] [config] guided-alignment: none
[2019-07-17 23:34:18] [config] guided-alignment-cost: mse
[2019-07-17 23:34:18] [config] guided-alignment-weight: 0.1
[2019-07-17 23:34:18] [config] ignore-model-config: false
[2019-07-17 23:34:18] [config] input-types:
[2019-07-17 23:34:18] [config]   []
[2019-07-17 23:34:18] [config] interpolate-env-vars: false
[2019-07-17 23:34:18] [config] keep-best: false
[2019-07-17 23:34:18] [config] label-smoothing: 0
[2019-07-17 23:34:18] [config] layer-normalization: true
[2019-07-17 23:34:18] [config] learn-rate: 0.0001
[2019-07-17 23:34:18] [config] log: ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/train.log
[2019-07-17 23:34:18] [config] log-level: info
[2019-07-17 23:34:18] [config] log-time-zone: ""
[2019-07-17 23:34:18] [config] lr-decay: 0
[2019-07-17 23:34:18] [config] lr-decay-freq: 50000
[2019-07-17 23:34:18] [config] lr-decay-inv-sqrt:
[2019-07-17 23:34:18] [config]   - 0
[2019-07-17 23:34:18] [config] lr-decay-repeat-warmup: false
[2019-07-17 23:34:18] [config] lr-decay-reset-optimizer: false
[2019-07-17 23:34:18] [config] lr-decay-start:
[2019-07-17 23:34:18] [config]   - 10
[2019-07-17 23:34:18] [config]   - 1
[2019-07-17 23:34:18] [config] lr-decay-strategy: epoch+stalled
[2019-07-17 23:34:18] [config] lr-report: false
[2019-07-17 23:34:18] [config] lr-warmup: 0
[2019-07-17 23:34:18] [config] lr-warmup-at-reload: false
[2019-07-17 23:34:18] [config] lr-warmup-cycle: false
[2019-07-17 23:34:18] [config] lr-warmup-start-rate: 0
[2019-07-17 23:34:18] [config] max-length: 50
[2019-07-17 23:34:18] [config] max-length-crop: false
[2019-07-17 23:34:18] [config] max-length-factor: 3
[2019-07-17 23:34:18] [config] maxi-batch: 100
[2019-07-17 23:34:18] [config] maxi-batch-sort: trg
[2019-07-17 23:34:18] [config] mini-batch: 64
[2019-07-17 23:34:18] [config] mini-batch-fit: true
[2019-07-17 23:34:18] [config] mini-batch-fit-step: 10
[2019-07-17 23:34:18] [config] mini-batch-overstuff: 1
[2019-07-17 23:34:18] [config] mini-batch-track-lr: false
[2019-07-17 23:34:18] [config] mini-batch-understuff: 1
[2019-07-17 23:34:18] [config] mini-batch-warmup: 0
[2019-07-17 23:34:18] [config] mini-batch-words: 0
[2019-07-17 23:34:18] [config] mini-batch-words-ref: 0
[2019-07-17 23:34:18] [config] model: ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-17 23:34:18] [config] multi-loss-type: sum
[2019-07-17 23:34:18] [config] multi-node: false
[2019-07-17 23:34:18] [config] multi-node-overlap: true
[2019-07-17 23:34:18] [config] n-best: false
[2019-07-17 23:34:18] [config] no-nccl: false
[2019-07-17 23:34:18] [config] no-reload: false
[2019-07-17 23:34:18] [config] no-restore-corpus: false
[2019-07-17 23:34:18] [config] no-shuffle: false
[2019-07-17 23:34:18] [config] normalize: 1
[2019-07-17 23:34:18] [config] num-devices: 0
[2019-07-17 23:34:18] [config] optimizer: adam
[2019-07-17 23:34:18] [config] optimizer-delay: 1
[2019-07-17 23:34:18] [config] optimizer-params:
[2019-07-17 23:34:18] [config]   []
[2019-07-17 23:34:18] [config] overwrite: false
[2019-07-17 23:34:18] [config] pretrained-model: ""
[2019-07-17 23:34:18] [config] quiet: false
[2019-07-17 23:34:18] [config] quiet-translation: true
[2019-07-17 23:34:18] [config] relative-paths: false
[2019-07-17 23:34:18] [config] right-left: false
[2019-07-17 23:34:18] [config] save-freq: 20000
[2019-07-17 23:34:18] [config] seed: 1111
[2019-07-17 23:34:18] [config] shuffle-in-ram: false
[2019-07-17 23:34:18] [config] skip: false
[2019-07-17 23:34:18] [config] sqlite: ""
[2019-07-17 23:34:18] [config] sqlite-drop: false
[2019-07-17 23:34:18] [config] sync-sgd: true
[2019-07-17 23:34:18] [config] tempdir: .
[2019-07-17 23:34:18] [config] tied-embeddings: false
[2019-07-17 23:34:18] [config] tied-embeddings-all: false
[2019-07-17 23:34:18] [config] tied-embeddings-src: false
[2019-07-17 23:34:18] [config] train-sets:
[2019-07-17 23:34:18] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.de
[2019-07-17 23:34:18] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.en
[2019-07-17 23:34:18] [config] transformer-aan-activation: swish
[2019-07-17 23:34:18] [config] transformer-aan-depth: 2
[2019-07-17 23:34:18] [config] transformer-aan-nogate: false
[2019-07-17 23:34:18] [config] transformer-decoder-autoreg: self-attention
[2019-07-17 23:34:18] [config] transformer-dim-aan: 2048
[2019-07-17 23:34:18] [config] transformer-dim-ffn: 2048
[2019-07-17 23:34:18] [config] transformer-dropout: 0
[2019-07-17 23:34:18] [config] transformer-dropout-attention: 0
[2019-07-17 23:34:18] [config] transformer-dropout-ffn: 0
[2019-07-17 23:34:18] [config] transformer-ffn-activation: swish
[2019-07-17 23:34:18] [config] transformer-ffn-depth: 2
[2019-07-17 23:34:18] [config] transformer-guided-alignment-layer: last
[2019-07-17 23:34:18] [config] transformer-heads: 8
[2019-07-17 23:34:18] [config] transformer-no-projection: false
[2019-07-17 23:34:18] [config] transformer-postprocess: dan
[2019-07-17 23:34:18] [config] transformer-postprocess-emb: d
[2019-07-17 23:34:18] [config] transformer-preprocess: ""
[2019-07-17 23:34:18] [config] transformer-tied-layers:
[2019-07-17 23:34:18] [config]   []
[2019-07-17 23:34:18] [config] transformer-train-position-embeddings: false
[2019-07-17 23:34:18] [config] type: amun
[2019-07-17 23:34:18] [config] ulr: false
[2019-07-17 23:34:18] [config] ulr-dim-emb: 0
[2019-07-17 23:34:18] [config] ulr-dropout: 0
[2019-07-17 23:34:18] [config] ulr-keys-vectors: ""
[2019-07-17 23:34:18] [config] ulr-query-vectors: ""
[2019-07-17 23:34:18] [config] ulr-softmax-temperature: 1
[2019-07-17 23:34:18] [config] ulr-trainable-transformation: false
[2019-07-17 23:34:18] [config] valid-freq: 20000
[2019-07-17 23:34:18] [config] valid-log: ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/valid.log
[2019-07-17 23:34:18] [config] valid-max-length: 1000
[2019-07-17 23:34:18] [config] valid-metrics:
[2019-07-17 23:34:18] [config]   - cross-entropy
[2019-07-17 23:34:18] [config]   - perplexity
[2019-07-17 23:34:18] [config]   - translation
[2019-07-17 23:34:18] [config] valid-mini-batch: 8
[2019-07-17 23:34:18] [config] valid-script-path: ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/score-dev.sh
[2019-07-17 23:34:18] [config] valid-sets:
[2019-07-17 23:34:18] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/dev.bpe.de
[2019-07-17 23:34:18] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/dev.bpe.en
[2019-07-17 23:34:18] [config] valid-translation-output: ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/dev.out
[2019-07-17 23:34:18] [config] vocabs:
[2019-07-17 23:34:18] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.de.json
[2019-07-17 23:34:18] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.en.json
[2019-07-17 23:34:18] [config] word-penalty: 0
[2019-07-17 23:34:18] [config] workspace: 5000
[2019-07-17 23:34:18] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-17 23:34:18] Using synchronous training
[2019-07-17 23:34:18] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.de.json
[2019-07-17 23:34:19] [data] Using unused word id eos for 0
[2019-07-17 23:34:19] [data] Using unused word id UNK for 1
[2019-07-17 23:34:19] [data] Setting vocabulary size for input 0 to 50000
[2019-07-17 23:34:19] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.en.json
[2019-07-17 23:34:19] [data] Using unused word id eos for 0
[2019-07-17 23:34:19] [data] Using unused word id UNK for 1
[2019-07-17 23:34:19] [data] Setting vocabulary size for input 1 to 50000
[2019-07-17 23:34:19] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-17 23:34:19] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-17 23:34:20] [memory] Extending reserved space to 5120 MB (device gpu0)
[2019-07-17 23:34:20] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-17 23:34:20] [comm] NCCLCommunicator constructed successfully.
[2019-07-17 23:34:20] [training] Using 1 GPUs
[2019-07-17 23:34:20] [memory] Reserving 422 MB, device gpu0
[2019-07-17 23:34:20] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-17 23:34:20] [memory] Reserving 422 MB, device gpu0
[2019-07-17 23:34:29] [batching] Done. Typical MB size is 6880 target words
[2019-07-17 23:34:29] [memory] Extending reserved space to 5120 MB (device gpu0)
[2019-07-17 23:34:29] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-17 23:34:29] [comm] NCCLCommunicator constructed successfully.
[2019-07-17 23:34:29] [training] Using 1 GPUs
[2019-07-17 23:34:29] Training started
[2019-07-17 23:34:29] [data] Shuffling data
[2019-07-17 23:34:32] [data] Done reading 4266183 sentences
[2019-07-17 23:34:54] [data] Done shuffling 4266183 sentences to temp files
[2019-07-17 23:34:55] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-07-17 23:34:55] [memory] Reserving 422 MB, device gpu0
[2019-07-17 23:34:56] [memory] Reserving 422 MB, device gpu0
[2019-07-17 23:34:56] [memory] Reserving 422 MB, device gpu0
[2019-07-17 23:34:56] [memory] Reserving 844 MB, device gpu0
[2019-07-17 23:49:56] Ep. 1 : Up. 2000 : Sen. 308,528 : Cost 149.68579102 : Time 937.00s : 8316.08 words/s
[2019-07-18 00:05:03] Ep. 1 : Up. 4000 : Sen. 616,761 : Cost 120.27428436 : Time 907.42s : 8572.83 words/s
[2019-07-18 00:20:11] Ep. 1 : Up. 6000 : Sen. 924,324 : Cost 105.38127136 : Time 907.96s : 8572.92 words/s
[2019-07-18 00:35:17] Ep. 1 : Up. 8000 : Sen. 1,231,726 : Cost 95.48800659 : Time 905.90s : 8567.16 words/s
[2019-07-18 00:50:26] Ep. 1 : Up. 10000 : Sen. 1,539,248 : Cost 88.96898651 : Time 908.78s : 8562.21 words/s
[2019-07-18 01:05:30] Ep. 1 : Up. 12000 : Sen. 1,847,223 : Cost 84.30452728 : Time 903.70s : 8591.97 words/s
[2019-07-18 01:20:34] Ep. 1 : Up. 14000 : Sen. 2,153,531 : Cost 81.40742493 : Time 904.68s : 8570.06 words/s
[2019-07-18 01:35:42] Ep. 1 : Up. 16000 : Sen. 2,460,980 : Cost 78.31149292 : Time 907.39s : 8551.26 words/s
[2019-07-18 01:50:47] Ep. 1 : Up. 18000 : Sen. 2,768,294 : Cost 76.51263428 : Time 905.14s : 8591.81 words/s
[2019-07-18 02:05:51] Ep. 1 : Up. 20000 : Sen. 3,075,391 : Cost 74.46057892 : Time 903.77s : 8567.63 words/s
[2019-07-18 02:05:51] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-18 02:05:59] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.iter20000.npz
[2019-07-18 02:06:06] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-18 02:06:15] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-07-18 02:06:39] [valid] Ep. 1 : Up. 20000 : cross-entropy : 67.1561 : new best
[2019-07-18 02:06:46] [valid] Ep. 1 : Up. 20000 : perplexity : 14.2003 : new best
[2019-07-18 02:07:48] [valid] Ep. 1 : Up. 20000 : translation : 24.02 : new best
[2019-07-18 02:22:57] Ep. 1 : Up. 22000 : Sen. 3,383,538 : Cost 72.96664429 : Time 1026.59s : 7568.12 words/s
[2019-07-18 02:24:57] Seen 3423702 samples
[2019-07-18 02:24:57] Starting epoch 2
[2019-07-18 02:24:57] [data] Shuffling data
[2019-07-18 02:25:00] [data] Done reading 4266183 sentences
[2019-07-18 02:25:19] [data] Done shuffling 4266183 sentences to temp files
[2019-07-18 02:38:31] Ep. 2 : Up. 24000 : Sen. 266,759 : Cost 71.13395691 : Time 933.92s : 8312.60 words/s
[2019-07-18 02:53:35] Ep. 2 : Up. 26000 : Sen. 573,679 : Cost 70.12511444 : Time 904.20s : 8580.41 words/s
[2019-07-18 03:08:43] Ep. 2 : Up. 28000 : Sen. 881,906 : Cost 69.07781982 : Time 907.76s : 8566.74 words/s
[2019-07-18 03:23:51] Ep. 2 : Up. 30000 : Sen. 1,190,038 : Cost 68.42407990 : Time 908.04s : 8579.79 words/s
[2019-07-18 03:38:56] Ep. 2 : Up. 32000 : Sen. 1,497,774 : Cost 67.48533630 : Time 905.24s : 8589.00 words/s
[2019-07-18 03:54:09] Ep. 2 : Up. 34000 : Sen. 1,805,514 : Cost 66.97106934 : Time 912.23s : 8525.87 words/s
[2019-07-18 04:09:15] Ep. 2 : Up. 36000 : Sen. 2,113,222 : Cost 66.25175476 : Time 906.10s : 8579.59 words/s
[2019-07-18 04:24:20] Ep. 2 : Up. 38000 : Sen. 2,420,192 : Cost 65.68926239 : Time 904.95s : 8568.89 words/s
[2019-07-18 04:39:25] Ep. 2 : Up. 40000 : Sen. 2,727,397 : Cost 65.16963959 : Time 905.39s : 8561.54 words/s
[2019-07-18 04:39:25] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-18 04:39:34] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.iter40000.npz
[2019-07-18 04:39:41] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-18 04:39:50] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-07-18 04:40:14] [valid] Ep. 2 : Up. 40000 : cross-entropy : 56.9815 : new best
[2019-07-18 04:40:21] [valid] Ep. 2 : Up. 40000 : perplexity : 9.49983 : new best
[2019-07-18 04:41:21] [valid] Ep. 2 : Up. 40000 : translation : 27.61 : new best
[2019-07-18 04:56:29] Ep. 2 : Up. 42000 : Sen. 3,034,740 : Cost 64.64331055 : Time 1024.03s : 7577.13 words/s
[2019-07-18 05:11:34] Ep. 2 : Up. 44000 : Sen. 3,341,808 : Cost 64.32328033 : Time 905.03s : 8587.62 words/s
[2019-07-18 05:15:35] Seen 3423702 samples
[2019-07-18 05:15:35] Starting epoch 3
[2019-07-18 05:15:35] [data] Shuffling data
[2019-07-18 05:15:38] [data] Done reading 4266183 sentences
[2019-07-18 05:15:57] [data] Done shuffling 4266183 sentences to temp files
[2019-07-18 05:27:07] Ep. 3 : Up. 46000 : Sen. 226,199 : Cost 62.81358719 : Time 933.05s : 8336.39 words/s
[2019-07-18 05:42:12] Ep. 3 : Up. 48000 : Sen. 532,868 : Cost 62.40942383 : Time 905.39s : 8567.57 words/s
[2019-07-18 05:57:20] Ep. 3 : Up. 50000 : Sen. 840,942 : Cost 62.32312393 : Time 907.79s : 8582.73 words/s
[2019-07-18 06:12:25] Ep. 3 : Up. 52000 : Sen. 1,148,453 : Cost 61.60890579 : Time 904.61s : 8577.83 words/s
[2019-07-18 06:27:29] Ep. 3 : Up. 54000 : Sen. 1,455,355 : Cost 61.29222870 : Time 904.38s : 8563.34 words/s
[2019-07-18 06:42:33] Ep. 3 : Up. 56000 : Sen. 1,761,546 : Cost 61.10274124 : Time 903.84s : 8554.43 words/s
[2019-07-18 06:57:40] Ep. 3 : Up. 58000 : Sen. 2,068,698 : Cost 61.16330719 : Time 907.04s : 8558.40 words/s
[2019-07-18 07:12:47] Ep. 3 : Up. 60000 : Sen. 2,374,828 : Cost 60.91533661 : Time 907.07s : 8525.41 words/s
[2019-07-18 07:12:47] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-18 07:12:56] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.iter60000.npz
[2019-07-18 07:13:03] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-18 07:13:12] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-07-18 07:13:36] [valid] Ep. 3 : Up. 60000 : cross-entropy : 52.9545 : new best
[2019-07-18 07:13:43] [valid] Ep. 3 : Up. 60000 : perplexity : 8.1025 : new best
[2019-07-18 07:14:43] [valid] Ep. 3 : Up. 60000 : translation : 29 : new best
[2019-07-18 07:29:55] Ep. 3 : Up. 62000 : Sen. 2,681,996 : Cost 60.76692963 : Time 1027.34s : 7559.32 words/s
[2019-07-18 07:45:01] Ep. 3 : Up. 64000 : Sen. 2,989,378 : Cost 60.20740128 : Time 906.87s : 8549.42 words/s
[2019-07-18 08:00:08] Ep. 3 : Up. 66000 : Sen. 3,296,809 : Cost 60.11825180 : Time 907.00s : 8573.43 words/s
[2019-07-18 08:06:21] Seen 3423702 samples
[2019-07-18 08:06:21] Starting epoch 4
[2019-07-18 08:06:21] [data] Shuffling data
[2019-07-18 08:06:23] [data] Done reading 4266183 sentences
[2019-07-18 08:06:43] [data] Done shuffling 4266183 sentences to temp files
[2019-07-18 08:15:48] Ep. 4 : Up. 68000 : Sen. 181,829 : Cost 59.01670074 : Time 939.38s : 8284.01 words/s
[2019-07-18 08:30:56] Ep. 4 : Up. 70000 : Sen. 489,775 : Cost 58.76879883 : Time 907.99s : 8577.77 words/s
[2019-07-18 08:46:05] Ep. 4 : Up. 72000 : Sen. 797,706 : Cost 59.04126740 : Time 908.75s : 8574.77 words/s
[2019-07-18 09:01:10] Ep. 4 : Up. 74000 : Sen. 1,105,381 : Cost 58.64321136 : Time 905.23s : 8578.79 words/s
[2019-07-18 09:16:13] Ep. 4 : Up. 76000 : Sen. 1,411,894 : Cost 58.31261444 : Time 903.20s : 8562.48 words/s
[2019-07-18 09:31:20] Ep. 4 : Up. 78000 : Sen. 1,719,134 : Cost 58.24690628 : Time 907.12s : 8553.82 words/s
[2019-07-18 09:46:23] Ep. 4 : Up. 80000 : Sen. 2,026,471 : Cost 58.30375671 : Time 903.31s : 8598.85 words/s
[2019-07-18 09:46:23] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-18 09:46:32] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.iter80000.npz
[2019-07-18 09:46:39] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-18 09:46:48] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-07-18 09:47:13] [valid] Ep. 4 : Up. 80000 : cross-entropy : 50.7978 : new best
[2019-07-18 09:47:21] [valid] Ep. 4 : Up. 80000 : perplexity : 7.44071 : new best
[2019-07-18 09:48:21] [valid] Ep. 4 : Up. 80000 : translation : 29.85 : new best
[2019-07-18 10:03:26] Ep. 4 : Up. 82000 : Sen. 2,332,604 : Cost 57.79797745 : Time 1022.61s : 7563.55 words/s
[2019-07-18 10:18:32] Ep. 4 : Up. 84000 : Sen. 2,640,133 : Cost 57.94578552 : Time 906.05s : 8572.92 words/s
[2019-07-18 10:33:39] Ep. 4 : Up. 86000 : Sen. 2,948,001 : Cost 57.97912598 : Time 907.13s : 8576.57 words/s
[2019-07-18 10:48:43] Ep. 4 : Up. 88000 : Sen. 3,255,372 : Cost 57.81287003 : Time 903.54s : 8592.56 words/s
[2019-07-18 10:57:00] Seen 3423702 samples
[2019-07-18 10:57:00] Starting epoch 5
[2019-07-18 10:57:00] [data] Shuffling data
[2019-07-18 10:57:03] [data] Done reading 4266183 sentences
[2019-07-18 10:57:21] [data] Done shuffling 4266183 sentences to temp files
[2019-07-18 11:04:11] Ep. 5 : Up. 90000 : Sen. 137,673 : Cost 57.00361252 : Time 928.10s : 8339.19 words/s
[2019-07-18 11:19:18] Ep. 5 : Up. 92000 : Sen. 445,010 : Cost 56.38240814 : Time 906.86s : 8545.36 words/s
[2019-07-18 11:34:25] Ep. 5 : Up. 94000 : Sen. 752,482 : Cost 56.09346008 : Time 907.75s : 8550.56 words/s
[2019-07-18 11:49:36] Ep. 5 : Up. 96000 : Sen. 1,060,515 : Cost 56.43908310 : Time 910.09s : 8561.93 words/s
[2019-07-18 12:04:42] Ep. 5 : Up. 98000 : Sen. 1,368,966 : Cost 56.27909851 : Time 905.98s : 8593.78 words/s
[2019-07-18 12:19:50] Ep. 5 : Up. 100000 : Sen. 1,676,088 : Cost 56.37153244 : Time 908.12s : 8554.87 words/s
[2019-07-18 12:19:50] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-18 12:20:01] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.iter100000.npz
[2019-07-18 12:20:09] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-18 12:20:18] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-07-18 12:20:42] [valid] Ep. 5 : Up. 100000 : cross-entropy : 49.3387 : new best
[2019-07-18 12:20:49] [valid] Ep. 5 : Up. 100000 : perplexity : 7.02389 : new best
[2019-07-18 12:21:50] [valid] Ep. 5 : Up. 100000 : translation : 30.32 : new best
[2019-07-18 12:36:55] Ep. 5 : Up. 102000 : Sen. 1,982,526 : Cost 56.23091125 : Time 1025.13s : 7550.99 words/s
[2019-07-18 12:52:03] Ep. 5 : Up. 104000 : Sen. 2,290,189 : Cost 56.22343826 : Time 907.87s : 8572.26 words/s
[2019-07-18 13:07:07] Ep. 5 : Up. 106000 : Sen. 2,596,929 : Cost 56.15244293 : Time 904.67s : 8559.79 words/s
[2019-07-18 13:22:17] Ep. 5 : Up. 108000 : Sen. 2,904,728 : Cost 55.84842682 : Time 910.04s : 8542.45 words/s
[2019-07-18 13:37:21] Ep. 5 : Up. 110000 : Sen. 3,211,496 : Cost 55.92807770 : Time 903.37s : 8565.26 words/s
[2019-07-18 13:47:48] Seen 3423702 samples
[2019-07-18 13:47:48] Starting epoch 6
[2019-07-18 13:47:48] [data] Shuffling data
[2019-07-18 13:47:51] [data] Done reading 4266183 sentences
[2019-07-18 13:48:16] [data] Done shuffling 4266183 sentences to temp files
[2019-07-18 13:52:59] Ep. 6 : Up. 112000 : Sen. 95,638 : Cost 55.61126328 : Time 937.96s : 8299.99 words/s
[2019-07-18 14:08:05] Ep. 6 : Up. 114000 : Sen. 403,332 : Cost 54.93688583 : Time 906.73s : 8578.76 words/s
[2019-07-18 14:23:11] Ep. 6 : Up. 116000 : Sen. 710,532 : Cost 54.73969269 : Time 906.00s : 8560.11 words/s
[2019-07-18 14:38:16] Ep. 6 : Up. 118000 : Sen. 1,017,600 : Cost 54.92737198 : Time 905.05s : 8578.56 words/s
[2019-07-18 14:53:27] Ep. 6 : Up. 120000 : Sen. 1,325,460 : Cost 54.91581345 : Time 910.59s : 8558.62 words/s
[2019-07-18 14:53:27] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-18 14:53:36] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.iter120000.npz
[2019-07-18 14:53:43] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-18 14:53:52] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-07-18 14:54:16] [valid] Ep. 6 : Up. 120000 : cross-entropy : 48.3465 : new best
[2019-07-18 14:54:24] [valid] Ep. 6 : Up. 120000 : perplexity : 6.75386 : new best
[2019-07-18 14:55:25] [valid] Ep. 6 : Up. 120000 : translation : 30.71 : new best
[2019-07-18 15:10:28] Ep. 6 : Up. 122000 : Sen. 1,631,770 : Cost 54.71313477 : Time 1020.64s : 7575.60 words/s
[2019-07-18 15:25:36] Ep. 6 : Up. 124000 : Sen. 1,938,532 : Cost 54.72801590 : Time 908.23s : 8529.54 words/s
[2019-07-18 15:40:44] Ep. 6 : Up. 126000 : Sen. 2,246,094 : Cost 54.76378632 : Time 907.99s : 8551.25 words/s
[2019-07-18 15:55:46] Ep. 6 : Up. 128000 : Sen. 2,553,336 : Cost 54.52584457 : Time 902.30s : 8586.54 words/s
[2019-07-18 16:10:49] Ep. 6 : Up. 130000 : Sen. 2,860,140 : Cost 54.72843933 : Time 902.87s : 8583.46 words/s
[2019-07-18 16:25:56] Ep. 6 : Up. 132000 : Sen. 3,167,345 : Cost 54.72732544 : Time 907.37s : 8565.62 words/s
[2019-07-18 16:38:31] Seen 3423702 samples
[2019-07-18 16:38:31] Starting epoch 7
[2019-07-18 16:38:31] [data] Shuffling data
[2019-07-18 16:38:34] [data] Done reading 4266183 sentences
[2019-07-18 16:38:52] [data] Done shuffling 4266183 sentences to temp files
[2019-07-18 16:41:28] Ep. 7 : Up. 134000 : Sen. 50,838 : Cost 54.50352859 : Time 931.46s : 8327.24 words/s
[2019-07-18 16:56:34] Ep. 7 : Up. 136000 : Sen. 357,962 : Cost 53.05407333 : Time 906.24s : 8543.01 words/s
[2019-07-18 17:11:43] Ep. 7 : Up. 138000 : Sen. 665,962 : Cost 53.52464676 : Time 909.03s : 8561.47 words/s
[2019-07-18 17:26:54] Ep. 7 : Up. 140000 : Sen. 974,024 : Cost 53.42333984 : Time 910.92s : 8543.10 words/s
[2019-07-18 17:26:54] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-18 17:27:03] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.iter140000.npz
[2019-07-18 17:27:10] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-18 17:27:19] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-07-18 17:27:43] [valid] Ep. 7 : Up. 140000 : cross-entropy : 47.7019 : new best
[2019-07-18 17:27:51] [valid] Ep. 7 : Up. 140000 : perplexity : 6.58405 : new best
[2019-07-18 17:28:53] [valid] Ep. 7 : Up. 140000 : translation : 30.92 : new best
[2019-07-18 17:44:00] Ep. 7 : Up. 142000 : Sen. 1,280,702 : Cost 53.67726135 : Time 1025.56s : 7564.86 words/s
[2019-07-18 17:59:08] Ep. 7 : Up. 144000 : Sen. 1,588,034 : Cost 53.79003525 : Time 908.80s : 8538.80 words/s
[2019-07-18 18:14:19] Ep. 7 : Up. 146000 : Sen. 1,896,396 : Cost 53.69555283 : Time 910.03s : 8559.95 words/s
[2019-07-18 18:29:25] Ep. 7 : Up. 148000 : Sen. 2,204,179 : Cost 53.29764175 : Time 906.44s : 8566.24 words/s
[2019-07-18 18:44:32] Ep. 7 : Up. 150000 : Sen. 2,510,446 : Cost 53.66188812 : Time 907.08s : 8538.20 words/s
[2019-07-18 18:59:39] Ep. 7 : Up. 152000 : Sen. 2,817,458 : Cost 53.80797958 : Time 907.20s : 8554.59 words/s
[2019-07-18 19:14:45] Ep. 7 : Up. 154000 : Sen. 3,124,736 : Cost 53.65354919 : Time 906.24s : 8571.58 words/s
[2019-07-18 19:29:28] Seen 3423702 samples
[2019-07-18 19:29:28] Starting epoch 8
[2019-07-18 19:29:28] [data] Shuffling data
[2019-07-18 19:29:31] [data] Done reading 4266183 sentences
[2019-07-18 19:29:51] [data] Done shuffling 4266183 sentences to temp files
[2019-07-18 19:30:25] Ep. 8 : Up. 156000 : Sen. 9,931 : Cost 53.64431000 : Time 939.89s : 8290.88 words/s
[2019-07-18 19:45:37] Ep. 8 : Up. 158000 : Sen. 318,107 : Cost 52.48994064 : Time 911.13s : 8544.69 words/s
[2019-07-18 20:00:41] Ep. 8 : Up. 160000 : Sen. 624,289 : Cost 52.54745483 : Time 904.59s : 8536.86 words/s
[2019-07-18 20:00:41] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-18 20:00:51] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.iter160000.npz
[2019-07-18 20:00:58] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-18 20:01:07] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-07-18 20:01:31] [valid] Ep. 8 : Up. 160000 : cross-entropy : 47.1981 : new best
[2019-07-18 20:01:39] [valid] Ep. 8 : Up. 160000 : perplexity : 6.45428 : new best
[2019-07-18 20:02:40] [valid] Ep. 8 : Up. 160000 : translation : 31.07 : new best
[2019-07-18 20:17:48] Ep. 8 : Up. 162000 : Sen. 931,156 : Cost 52.54182816 : Time 1026.50s : 7554.67 words/s
[2019-07-18 20:32:56] Ep. 8 : Up. 164000 : Sen. 1,239,332 : Cost 52.74577332 : Time 908.14s : 8572.35 words/s
[2019-07-18 20:48:04] Ep. 8 : Up. 166000 : Sen. 1,547,834 : Cost 52.75045395 : Time 908.10s : 8569.85 words/s
[2019-07-18 21:03:06] Ep. 8 : Up. 168000 : Sen. 1,854,037 : Cost 52.80957031 : Time 902.39s : 8595.22 words/s
[2019-07-18 21:18:16] Ep. 8 : Up. 170000 : Sen. 2,161,378 : Cost 52.75111771 : Time 909.30s : 8542.03 words/s
[2019-07-18 21:33:20] Ep. 8 : Up. 172000 : Sen. 2,468,567 : Cost 52.81534576 : Time 904.87s : 8574.72 words/s
[2019-07-18 21:48:30] Ep. 8 : Up. 174000 : Sen. 2,776,140 : Cost 52.89552307 : Time 909.56s : 8535.95 words/s
[2019-07-18 22:03:38] Ep. 8 : Up. 176000 : Sen. 3,083,902 : Cost 52.81181335 : Time 907.95s : 8570.04 words/s
[2019-07-18 22:19:17] Ep. 8 : Up. 178000 : Sen. 3,391,868 : Cost 52.58979034 : Time 938.61s : 8290.34 words/s
[2019-07-18 22:20:51] Seen 3423702 samples
[2019-07-18 22:20:51] Starting epoch 9
[2019-07-18 22:20:51] [data] Shuffling data
[2019-07-18 22:20:54] [data] Done reading 4266183 sentences
[2019-07-18 22:21:14] [data] Done shuffling 4266183 sentences to temp files
[2019-07-18 22:34:55] Ep. 9 : Up. 180000 : Sen. 275,200 : Cost 51.67877579 : Time 938.08s : 8277.13 words/s
[2019-07-18 22:34:55] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-18 22:35:04] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.iter180000.npz
[2019-07-18 22:35:11] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-18 22:35:20] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-07-18 22:35:44] [valid] Ep. 9 : Up. 180000 : cross-entropy : 46.8389 : new best
[2019-07-18 22:35:52] [valid] Ep. 9 : Up. 180000 : perplexity : 6.36334 : new best
[2019-07-18 22:36:53] [valid] Ep. 9 : Up. 180000 : translation : 31.24 : new best
[2019-07-18 22:51:59] Ep. 9 : Up. 182000 : Sen. 582,827 : Cost 51.68644333 : Time 1024.81s : 7584.22 words/s
[2019-07-18 23:07:05] Ep. 9 : Up. 184000 : Sen. 890,664 : Cost 51.87881088 : Time 905.93s : 8586.76 words/s
[2019-07-18 23:22:14] Ep. 9 : Up. 186000 : Sen. 1,198,518 : Cost 51.92923737 : Time 908.47s : 8556.80 words/s
[2019-07-18 23:37:21] Ep. 9 : Up. 188000 : Sen. 1,505,805 : Cost 52.11026001 : Time 907.49s : 8552.46 words/s
[2019-07-18 23:52:31] Ep. 9 : Up. 190000 : Sen. 1,813,503 : Cost 51.88386536 : Time 909.49s : 8556.79 words/s
[2019-07-19 00:07:36] Ep. 9 : Up. 192000 : Sen. 2,120,936 : Cost 51.82832336 : Time 905.10s : 8572.54 words/s
[2019-07-19 00:22:44] Ep. 9 : Up. 194000 : Sen. 2,427,713 : Cost 51.87152100 : Time 908.20s : 8544.40 words/s
[2019-07-19 00:37:51] Ep. 9 : Up. 196000 : Sen. 2,735,514 : Cost 52.17946243 : Time 907.38s : 8557.55 words/s
[2019-07-19 00:53:00] Ep. 9 : Up. 198000 : Sen. 3,042,877 : Cost 52.08255386 : Time 908.11s : 8546.15 words/s
[2019-07-19 01:08:08] Ep. 9 : Up. 200000 : Sen. 3,350,527 : Cost 52.16852570 : Time 908.66s : 8557.33 words/s
[2019-07-19 01:08:08] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-19 01:08:17] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.iter200000.npz
[2019-07-19 01:08:24] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-19 01:08:33] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-07-19 01:08:57] [valid] Ep. 9 : Up. 200000 : cross-entropy : 46.5806 : new best
[2019-07-19 01:09:05] [valid] Ep. 9 : Up. 200000 : perplexity : 6.29872 : new best
[2019-07-19 01:10:06] [valid] Ep. 9 : Up. 200000 : translation : 31.37 : new best
[2019-07-19 01:13:44] Seen 3423702 samples
[2019-07-19 01:13:44] Starting epoch 10
[2019-07-19 01:13:44] [data] Shuffling data
[2019-07-19 01:13:47] [data] Done reading 4266183 sentences
[2019-07-19 01:14:05] [data] Done shuffling 4266183 sentences to temp files
[2019-07-19 01:25:42] Ep. 10 : Up. 202000 : Sen. 233,925 : Cost 51.03358078 : Time 1053.79s : 7347.38 words/s
[2019-07-19 01:40:54] Ep. 10 : Up. 204000 : Sen. 541,442 : Cost 50.94982529 : Time 911.78s : 8523.50 words/s
[2019-07-19 01:56:04] Ep. 10 : Up. 206000 : Sen. 847,445 : Cost 51.05207062 : Time 910.36s : 8500.84 words/s
[2019-07-19 02:11:16] Ep. 10 : Up. 208000 : Sen. 1,155,715 : Cost 51.25576782 : Time 912.14s : 8531.34 words/s
[2019-07-19 02:26:27] Ep. 10 : Up. 210000 : Sen. 1,462,952 : Cost 51.36746216 : Time 910.43s : 8510.32 words/s
[2019-07-19 02:41:37] Ep. 10 : Up. 212000 : Sen. 1,769,480 : Cost 51.40305710 : Time 910.56s : 8503.23 words/s
[2019-07-19 02:56:48] Ep. 10 : Up. 214000 : Sen. 2,075,139 : Cost 51.55865479 : Time 910.45s : 8493.28 words/s
[2019-07-19 03:12:00] Ep. 10 : Up. 216000 : Sen. 2,382,624 : Cost 51.49949265 : Time 912.41s : 8515.76 words/s
[2019-07-19 03:27:13] Ep. 10 : Up. 218000 : Sen. 2,691,142 : Cost 51.43796158 : Time 912.88s : 8525.02 words/s
[2019-07-19 03:42:28] Ep. 10 : Up. 220000 : Sen. 2,998,910 : Cost 51.59016418 : Time 915.25s : 8505.11 words/s
[2019-07-19 03:42:28] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-19 03:42:38] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.iter220000.npz
[2019-07-19 03:42:45] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-19 03:42:55] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-07-19 03:43:19] [valid] Ep. 10 : Up. 220000 : cross-entropy : 46.4466 : new best
[2019-07-19 03:43:26] [valid] Ep. 10 : Up. 220000 : perplexity : 6.26546 : new best
[2019-07-19 03:44:30] [valid] Ep. 10 : Up. 220000 : translation : 31.47 : new best
[2019-07-19 03:59:41] Ep. 10 : Up. 222000 : Sen. 3,306,082 : Cost 51.20521545 : Time 1032.29s : 7517.79 words/s
[2019-07-19 04:05:32] Seen 3423702 samples
[2019-07-19 04:05:32] Starting epoch 11
[2019-07-19 04:05:32] [data] Shuffling data
[2019-07-19 04:05:34] [data] Done reading 4266183 sentences
[2019-07-19 04:05:53] [data] Done shuffling 4266183 sentences to temp files
[2019-07-19 04:15:14] Ep. 11 : Up. 224000 : Sen. 189,280 : Cost 50.75420380 : Time 933.46s : 8308.54 words/s
[2019-07-19 04:30:29] Ep. 11 : Up. 226000 : Sen. 497,055 : Cost 50.39794540 : Time 915.22s : 8499.34 words/s
[2019-07-19 04:45:39] Ep. 11 : Up. 228000 : Sen. 804,106 : Cost 50.59909439 : Time 909.55s : 8530.99 words/s
[2019-07-19 05:00:50] Ep. 11 : Up. 230000 : Sen. 1,111,273 : Cost 50.77048492 : Time 910.79s : 8518.46 words/s
[2019-07-19 05:15:58] Ep. 11 : Up. 232000 : Sen. 1,418,052 : Cost 50.86719894 : Time 908.79s : 8538.86 words/s
[2019-07-19 05:31:08] Ep. 11 : Up. 234000 : Sen. 1,725,236 : Cost 50.83006668 : Time 909.84s : 8521.29 words/s
[2019-07-19 05:46:21] Ep. 11 : Up. 236000 : Sen. 2,032,626 : Cost 50.50876236 : Time 912.46s : 8496.21 words/s
[2019-07-19 06:01:29] Ep. 11 : Up. 238000 : Sen. 2,339,272 : Cost 50.95197296 : Time 907.98s : 8545.33 words/s
[2019-07-19 06:16:44] Ep. 11 : Up. 240000 : Sen. 2,647,279 : Cost 50.92136002 : Time 915.35s : 8495.48 words/s
[2019-07-19 06:16:44] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-19 06:16:53] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.iter240000.npz
[2019-07-19 06:17:00] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-19 06:17:09] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-07-19 06:17:34] [valid] Ep. 11 : Up. 240000 : cross-entropy : 46.319 : new best
[2019-07-19 06:17:42] [valid] Ep. 11 : Up. 240000 : perplexity : 6.23395 : new best
[2019-07-19 06:18:44] [valid] Ep. 11 : Up. 240000 : translation : 31.57 : new best
[2019-07-19 06:33:59] Ep. 11 : Up. 242000 : Sen. 2,955,427 : Cost 51.12415695 : Time 1034.83s : 7523.71 words/s
[2019-07-19 06:49:12] Ep. 11 : Up. 244000 : Sen. 3,262,959 : Cost 51.05429840 : Time 912.90s : 8522.05 words/s
[2019-07-19 06:57:06] Seen 3423702 samples
[2019-07-19 06:57:07] Starting epoch 12
[2019-07-19 06:57:07] [data] Shuffling data
[2019-07-19 06:57:09] [data] Done reading 4266183 sentences
[2019-07-19 06:57:29] [data] Done shuffling 4266183 sentences to temp files
[2019-07-19 07:04:53] Ep. 12 : Up. 246000 : Sen. 147,541 : Cost 50.20912170 : Time 940.78s : 8268.79 words/s
[2019-07-19 07:20:03] Ep. 12 : Up. 248000 : Sen. 454,400 : Cost 49.86370468 : Time 910.67s : 8506.22 words/s
[2019-07-19 07:35:18] Ep. 12 : Up. 250000 : Sen. 761,336 : Cost 50.03885651 : Time 915.05s : 8483.72 words/s
[2019-07-19 07:50:31] Ep. 12 : Up. 252000 : Sen. 1,068,230 : Cost 50.33579636 : Time 912.30s : 8502.81 words/s
[2019-07-19 08:05:42] Ep. 12 : Up. 254000 : Sen. 1,376,230 : Cost 50.22268677 : Time 911.63s : 8526.10 words/s
[2019-07-19 08:20:54] Ep. 12 : Up. 256000 : Sen. 1,683,653 : Cost 50.28737259 : Time 911.97s : 8519.44 words/s
[2019-07-19 08:36:07] Ep. 12 : Up. 258000 : Sen. 1,991,301 : Cost 50.12722397 : Time 912.61s : 8514.00 words/s
[2019-07-19 08:51:17] Ep. 12 : Up. 260000 : Sen. 2,298,622 : Cost 50.44789505 : Time 910.39s : 8525.77 words/s
[2019-07-19 08:51:17] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-19 08:51:26] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.iter260000.npz
[2019-07-19 08:51:33] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-19 08:51:43] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-07-19 08:52:10] [valid] Ep. 12 : Up. 260000 : cross-entropy : 46.1807 : new best
[2019-07-19 08:52:17] [valid] Ep. 12 : Up. 260000 : perplexity : 6.19998 : new best
[2019-07-19 08:53:27] [valid] Ep. 12 : Up. 260000 : translation : 31.59 : new best
[2019-07-19 09:08:34] Ep. 12 : Up. 262000 : Sen. 2,606,022 : Cost 50.39023590 : Time 1036.52s : 7485.81 words/s
[2019-07-19 09:23:42] Ep. 12 : Up. 264000 : Sen. 2,912,952 : Cost 50.53713608 : Time 908.30s : 8534.44 words/s
[2019-07-19 09:38:50] Ep. 12 : Up. 266000 : Sen. 3,220,741 : Cost 50.53440857 : Time 907.75s : 8565.27 words/s
[2019-07-19 09:48:49] Seen 3423702 samples
[2019-07-19 09:48:49] Starting epoch 13
[2019-07-19 09:48:49] [data] Shuffling data
[2019-07-19 09:48:51] [data] Done reading 4266183 sentences
[2019-07-19 09:49:09] [data] Done shuffling 4266183 sentences to temp files
[2019-07-19 09:54:22] Ep. 13 : Up. 268000 : Sen. 103,906 : Cost 50.31570053 : Time 932.22s : 8338.28 words/s
[2019-07-19 10:09:30] Ep. 13 : Up. 270000 : Sen. 412,168 : Cost 49.42333603 : Time 908.24s : 8577.58 words/s
[2019-07-19 10:24:34] Ep. 13 : Up. 272000 : Sen. 719,730 : Cost 49.40845108 : Time 903.45s : 8585.65 words/s
[2019-07-19 10:39:38] Ep. 13 : Up. 274000 : Sen. 1,027,591 : Cost 49.63181686 : Time 904.01s : 8616.62 words/s
[2019-07-19 10:54:43] Ep. 13 : Up. 276000 : Sen. 1,334,777 : Cost 49.42844391 : Time 905.12s : 8570.61 words/s
[2019-07-19 11:09:50] Ep. 13 : Up. 278000 : Sen. 1,642,877 : Cost 49.60375595 : Time 907.44s : 8576.07 words/s
[2019-07-19 11:24:58] Ep. 13 : Up. 280000 : Sen. 1,950,978 : Cost 49.85820389 : Time 907.64s : 8570.91 words/s
[2019-07-19 11:24:58] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-19 11:25:07] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.iter280000.npz
[2019-07-19 11:25:14] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-19 11:25:23] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-07-19 11:25:47] [valid] Ep. 13 : Up. 280000 : cross-entropy : 46.1286 : new best
[2019-07-19 11:25:54] [valid] Ep. 13 : Up. 280000 : perplexity : 6.18724 : new best
[2019-07-19 11:26:54] [valid] Ep. 13 : Up. 280000 : translation : 31.67 : new best
[2019-07-19 11:41:58] Ep. 13 : Up. 282000 : Sen. 2,257,338 : Cost 49.95212936 : Time 1020.27s : 7586.35 words/s
[2019-07-19 11:57:06] Ep. 13 : Up. 284000 : Sen. 2,564,587 : Cost 50.02962494 : Time 907.76s : 8556.49 words/s
[2019-07-19 12:12:12] Ep. 13 : Up. 286000 : Sen. 2,871,963 : Cost 49.96656799 : Time 906.43s : 8558.21 words/s
[2019-07-19 12:27:16] Ep. 13 : Up. 288000 : Sen. 3,179,042 : Cost 49.94378662 : Time 903.53s : 8568.91 words/s
[2019-07-19 12:39:16] Seen 3423702 samples
[2019-07-19 12:39:16] Starting epoch 14
[2019-07-19 12:39:16] [data] Shuffling data
[2019-07-19 12:39:18] [data] Done reading 4266183 sentences
[2019-07-19 12:39:36] [data] Done shuffling 4266183 sentences to temp files
[2019-07-19 12:42:47] Ep. 14 : Up. 290000 : Sen. 63,165 : Cost 49.71958923 : Time 930.80s : 8355.23 words/s
[2019-07-19 12:57:54] Ep. 14 : Up. 292000 : Sen. 370,407 : Cost 48.93169403 : Time 907.78s : 8549.52 words/s
[2019-07-19 13:13:05] Ep. 14 : Up. 294000 : Sen. 678,532 : Cost 49.26165771 : Time 910.29s : 8547.46 words/s
[2019-07-19 13:28:11] Ep. 14 : Up. 296000 : Sen. 985,072 : Cost 49.15748215 : Time 906.27s : 8543.16 words/s
[2019-07-19 13:43:19] Ep. 14 : Up. 298000 : Sen. 1,292,174 : Cost 49.16058350 : Time 908.46s : 8545.88 words/s
[2019-07-19 13:58:24] Ep. 14 : Up. 300000 : Sen. 1,599,464 : Cost 49.44544601 : Time 904.42s : 8584.05 words/s
[2019-07-19 13:58:24] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-19 13:58:34] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.iter300000.npz
[2019-07-19 13:58:41] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-19 13:58:50] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-07-19 13:59:14] [valid] Ep. 14 : Up. 300000 : cross-entropy : 46.0886 : new best
[2019-07-19 13:59:21] [valid] Ep. 14 : Up. 300000 : perplexity : 6.17746 : new best
[2019-07-19 14:00:21] [valid] Ep. 14 : Up. 300000 : translation : 31.73 : new best
[2019-07-19 14:15:29] Ep. 14 : Up. 302000 : Sen. 1,907,200 : Cost 49.55497742 : Time 1024.87s : 7580.40 words/s
[2019-07-19 14:30:33] Ep. 14 : Up. 304000 : Sen. 2,214,532 : Cost 49.53692245 : Time 904.56s : 8578.83 words/s
[2019-07-19 14:45:37] Ep. 14 : Up. 306000 : Sen. 2,521,426 : Cost 49.62107849 : Time 903.89s : 8578.87 words/s
[2019-07-19 15:00:45] Ep. 14 : Up. 308000 : Sen. 2,828,933 : Cost 49.48114014 : Time 907.33s : 8560.64 words/s
[2019-07-19 15:15:54] Ep. 14 : Up. 310000 : Sen. 3,137,233 : Cost 49.71191788 : Time 909.08s : 8574.40 words/s
[2019-07-19 15:29:57] Seen 3423702 samples
[2019-07-19 15:29:57] Starting epoch 15
[2019-07-19 15:29:57] [data] Shuffling data
[2019-07-19 15:30:00] [data] Done reading 4266183 sentences
[2019-07-19 15:30:26] [data] Done shuffling 4266183 sentences to temp files
[2019-07-19 15:31:29] Ep. 15 : Up. 312000 : Sen. 20,217 : Cost 49.59543610 : Time 935.27s : 8277.17 words/s
[2019-07-19 15:46:35] Ep. 15 : Up. 314000 : Sen. 325,864 : Cost 48.65486908 : Time 906.20s : 8536.34 words/s
[2019-07-19 16:01:42] Ep. 15 : Up. 316000 : Sen. 633,600 : Cost 48.81011581 : Time 906.66s : 8566.99 words/s
[2019-07-19 16:16:48] Ep. 15 : Up. 318000 : Sen. 940,668 : Cost 48.75484085 : Time 906.67s : 8554.14 words/s
[2019-07-19 16:31:56] Ep. 15 : Up. 320000 : Sen. 1,248,574 : Cost 49.15608978 : Time 907.84s : 8569.34 words/s
[2019-07-19 16:31:56] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-19 16:32:06] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.iter320000.npz
[2019-07-19 16:32:13] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-19 16:32:22] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-07-19 16:32:46] [valid] Ep. 15 : Up. 320000 : cross-entropy : 46.0253 : new best
[2019-07-19 16:32:53] [valid] Ep. 15 : Up. 320000 : perplexity : 6.16203 : new best
[2019-07-19 16:33:54] [valid] Ep. 15 : Up. 320000 : translation : 31.78 : new best
[2019-07-19 16:49:06] Ep. 15 : Up. 322000 : Sen. 1,556,000 : Cost 48.95653915 : Time 1029.67s : 7548.74 words/s
[2019-07-19 17:04:13] Ep. 15 : Up. 324000 : Sen. 1,863,583 : Cost 49.02006149 : Time 907.34s : 8545.56 words/s
[2019-07-19 17:19:20] Ep. 15 : Up. 326000 : Sen. 2,171,042 : Cost 49.38864517 : Time 906.63s : 8578.12 words/s
[2019-07-19 17:34:26] Ep. 15 : Up. 328000 : Sen. 2,478,526 : Cost 49.23632050 : Time 906.28s : 8562.25 words/s
[2019-07-19 17:49:37] Ep. 15 : Up. 330000 : Sen. 2,785,325 : Cost 49.42500305 : Time 910.36s : 8523.83 words/s
[2019-07-19 18:04:46] Ep. 15 : Up. 332000 : Sen. 3,093,822 : Cost 49.57477188 : Time 909.89s : 8572.03 words/s
[2019-07-19 18:19:52] Ep. 15 : Up. 334000 : Sen. 3,401,440 : Cost 49.30168533 : Time 906.01s : 8573.13 words/s
[2019-07-19 18:20:58] Seen 3423702 samples
[2019-07-19 18:20:58] Starting epoch 16
[2019-07-19 18:20:58] [data] Shuffling data
[2019-07-19 18:21:01] [data] Done reading 4266183 sentences
[2019-07-19 18:21:38] [data] Done shuffling 4266183 sentences to temp files
[2019-07-19 18:35:44] Ep. 16 : Up. 336000 : Sen. 285,381 : Cost 48.47825241 : Time 951.42s : 8173.21 words/s
[2019-07-19 18:50:51] Ep. 16 : Up. 338000 : Sen. 593,490 : Cost 48.52216721 : Time 907.15s : 8578.89 words/s
[2019-07-19 19:05:56] Ep. 16 : Up. 340000 : Sen. 899,697 : Cost 48.53034973 : Time 904.91s : 8543.04 words/s
[2019-07-19 19:05:56] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-19 19:06:06] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.iter340000.npz
[2019-07-19 19:06:13] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-19 19:06:30] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-07-19 19:06:53] [valid] Ep. 16 : Up. 340000 : cross-entropy : 45.9343 : new best
[2019-07-19 19:07:01] [valid] Ep. 16 : Up. 340000 : perplexity : 6.13992 : new best
[2019-07-19 19:08:01] [valid] Ep. 16 : Up. 340000 : translation : 31.72 : stalled 1 times (last best: 31.78)
[2019-07-19 19:23:12] Ep. 16 : Up. 342000 : Sen. 1,208,060 : Cost 48.63075256 : Time 1035.89s : 7538.36 words/s
[2019-07-19 19:38:18] Ep. 16 : Up. 344000 : Sen. 1,514,718 : Cost 48.85231400 : Time 905.66s : 8556.24 words/s
[2019-07-19 19:53:25] Ep. 16 : Up. 346000 : Sen. 1,823,026 : Cost 48.62640381 : Time 907.53s : 8576.00 words/s
[2019-07-19 20:08:32] Ep. 16 : Up. 348000 : Sen. 2,131,026 : Cost 48.98609161 : Time 907.14s : 8573.61 words/s
[2019-07-19 20:23:40] Ep. 16 : Up. 350000 : Sen. 2,438,400 : Cost 48.90182114 : Time 907.43s : 8553.14 words/s
[2019-07-19 20:38:43] Ep. 16 : Up. 352000 : Sen. 2,745,111 : Cost 48.82295990 : Time 903.38s : 8564.27 words/s
[2019-07-19 20:53:52] Ep. 16 : Up. 354000 : Sen. 3,052,194 : Cost 49.06723785 : Time 908.91s : 8542.51 words/s
[2019-07-19 21:09:00] Ep. 16 : Up. 356000 : Sen. 3,360,528 : Cost 49.01511383 : Time 908.00s : 8579.08 words/s
[2019-07-19 21:12:06] Seen 3423702 samples
[2019-07-19 21:12:06] Starting epoch 17
[2019-07-19 21:12:06] [data] Shuffling data
[2019-07-19 21:12:08] [data] Done reading 4266183 sentences
[2019-07-19 21:12:31] [data] Done shuffling 4266183 sentences to temp files
[2019-07-19 21:24:29] Ep. 17 : Up. 358000 : Sen. 243,638 : Cost 48.35114670 : Time 928.83s : 8346.99 words/s
[2019-07-19 21:39:31] Ep. 17 : Up. 360000 : Sen. 550,136 : Cost 48.09404373 : Time 902.75s : 8575.60 words/s
[2019-07-19 21:39:31] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-19 21:39:40] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.iter360000.npz
[2019-07-19 21:39:47] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-19 21:39:57] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-07-19 21:40:21] [valid] Ep. 17 : Up. 360000 : cross-entropy : 45.8678 : new best
[2019-07-19 21:40:28] [valid] Ep. 17 : Up. 360000 : perplexity : 6.12381 : new best
[2019-07-19 21:41:31] [valid] Ep. 17 : Up. 360000 : translation : 31.79 : new best
[2019-07-19 21:56:41] Ep. 17 : Up. 362000 : Sen. 857,732 : Cost 48.00569534 : Time 1029.21s : 7547.12 words/s
[2019-07-19 22:11:46] Ep. 17 : Up. 364000 : Sen. 1,164,614 : Cost 48.24324036 : Time 905.78s : 8559.40 words/s
[2019-07-19 22:26:57] Ep. 17 : Up. 366000 : Sen. 1,472,736 : Cost 48.54492569 : Time 910.63s : 8548.16 words/s
[2019-07-19 22:42:01] Ep. 17 : Up. 368000 : Sen. 1,779,728 : Cost 48.68083572 : Time 904.00s : 8590.80 words/s
[2019-07-19 22:57:06] Ep. 17 : Up. 370000 : Sen. 2,086,400 : Cost 48.59884644 : Time 905.06s : 8555.36 words/s
[2019-07-19 23:12:13] Ep. 17 : Up. 372000 : Sen. 2,394,268 : Cost 48.62790298 : Time 906.54s : 8578.01 words/s
[2019-07-19 23:27:17] Ep. 17 : Up. 374000 : Sen. 2,700,626 : Cost 48.83580017 : Time 904.31s : 8561.68 words/s
[2019-07-19 23:42:24] Ep. 17 : Up. 376000 : Sen. 3,008,132 : Cost 48.94512558 : Time 907.33s : 8560.46 words/s
[2019-07-19 23:57:31] Ep. 17 : Up. 378000 : Sen. 3,316,222 : Cost 48.74216461 : Time 907.02s : 8565.76 words/s
[2019-07-20 00:02:50] Seen 3423702 samples
[2019-07-20 00:02:50] Starting epoch 18
[2019-07-20 00:02:50] [data] Shuffling data
[2019-07-20 00:02:53] [data] Done reading 4266183 sentences
[2019-07-20 00:03:11] [data] Done shuffling 4266183 sentences to temp files
[2019-07-20 00:13:01] Ep. 18 : Up. 380000 : Sen. 199,487 : Cost 47.96922302 : Time 929.29s : 8343.92 words/s
[2019-07-20 00:13:01] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-20 00:13:10] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.iter380000.npz
[2019-07-20 00:13:17] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-20 00:13:26] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-07-20 00:13:50] [valid] Ep. 18 : Up. 380000 : cross-entropy : 45.8534 : new best
[2019-07-20 00:13:58] [valid] Ep. 18 : Up. 380000 : perplexity : 6.12032 : new best
[2019-07-20 00:14:59] [valid] Ep. 18 : Up. 380000 : translation : 31.86 : new best
[2019-07-20 00:30:09] Ep. 18 : Up. 382000 : Sen. 506,532 : Cost 47.90208435 : Time 1028.48s : 7544.39 words/s
[2019-07-20 00:45:17] Ep. 18 : Up. 384000 : Sen. 814,220 : Cost 47.98289108 : Time 907.52s : 8567.47 words/s
[2019-07-20 01:00:22] Ep. 18 : Up. 386000 : Sen. 1,121,172 : Cost 47.94324112 : Time 905.60s : 8567.14 words/s
[2019-07-20 01:15:31] Ep. 18 : Up. 388000 : Sen. 1,429,315 : Cost 47.93861771 : Time 908.27s : 8568.31 words/s
[2019-07-20 01:30:37] Ep. 18 : Up. 390000 : Sen. 1,737,361 : Cost 48.10726929 : Time 906.72s : 8582.01 words/s
[2019-07-20 01:45:46] Ep. 18 : Up. 392000 : Sen. 2,044,346 : Cost 48.24351501 : Time 908.94s : 8536.13 words/s
[2019-07-20 02:00:52] Ep. 18 : Up. 394000 : Sen. 2,352,514 : Cost 48.18607330 : Time 905.57s : 8581.10 words/s
[2019-07-20 02:16:00] Ep. 18 : Up. 396000 : Sen. 2,659,932 : Cost 48.50003433 : Time 908.62s : 8540.83 words/s
[2019-07-20 02:31:09] Ep. 18 : Up. 398000 : Sen. 2,966,785 : Cost 48.73429489 : Time 908.48s : 8568.01 words/s
[2019-07-20 02:46:14] Ep. 18 : Up. 400000 : Sen. 3,274,108 : Cost 48.27497101 : Time 904.83s : 8555.74 words/s
[2019-07-20 02:46:14] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-20 02:46:23] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.iter400000.npz
[2019-07-20 02:46:30] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-20 02:46:39] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-07-20 02:47:04] [valid] Ep. 18 : Up. 400000 : cross-entropy : 45.8558 : stalled 1 times (last best: 45.8534)
[2019-07-20 02:47:11] [valid] Ep. 18 : Up. 400000 : perplexity : 6.1209 : stalled 1 times (last best: 6.12032)
[2019-07-20 02:48:13] [valid] Ep. 18 : Up. 400000 : translation : 31.81 : stalled 1 times (last best: 31.86)
[2019-07-20 02:55:39] Seen 3423702 samples
[2019-07-20 02:55:39] Starting epoch 19
[2019-07-20 02:55:39] [data] Shuffling data
[2019-07-20 02:55:42] [data] Done reading 4266183 sentences
[2019-07-20 02:56:01] [data] Done shuffling 4266183 sentences to temp files
[2019-07-20 03:03:52] Ep. 19 : Up. 402000 : Sen. 157,751 : Cost 47.89812851 : Time 1058.16s : 7344.69 words/s
[2019-07-20 03:18:56] Ep. 19 : Up. 404000 : Sen. 464,655 : Cost 47.42611694 : Time 904.53s : 8568.64 words/s
[2019-07-20 03:34:03] Ep. 19 : Up. 406000 : Sen. 772,842 : Cost 47.52429581 : Time 906.98s : 8579.34 words/s
[2019-07-20 03:49:10] Ep. 19 : Up. 408000 : Sen. 1,079,043 : Cost 47.68232346 : Time 907.03s : 8532.59 words/s
[2019-07-20 04:04:16] Ep. 19 : Up. 410000 : Sen. 1,386,065 : Cost 48.11408234 : Time 905.78s : 8569.23 words/s
[2019-07-20 04:19:23] Ep. 19 : Up. 412000 : Sen. 1,692,853 : Cost 47.95034409 : Time 907.19s : 8539.47 words/s
[2019-07-20 04:34:34] Ep. 19 : Up. 414000 : Sen. 2,000,575 : Cost 48.08350372 : Time 910.18s : 8557.31 words/s
[2019-07-20 04:49:41] Ep. 19 : Up. 416000 : Sen. 2,307,571 : Cost 48.08640671 : Time 907.11s : 8545.11 words/s
[2019-07-20 05:04:49] Ep. 19 : Up. 418000 : Sen. 2,615,702 : Cost 48.03511810 : Time 908.07s : 8554.65 words/s
[2019-07-20 05:19:53] Ep. 19 : Up. 420000 : Sen. 2,922,089 : Cost 48.13078308 : Time 904.17s : 8561.92 words/s
[2019-07-20 05:19:53] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-20 05:20:02] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.iter420000.npz
[2019-07-20 05:20:08] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-20 05:20:18] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-07-20 05:20:42] [valid] Ep. 19 : Up. 420000 : cross-entropy : 45.8525 : new best
[2019-07-20 05:20:49] [valid] Ep. 19 : Up. 420000 : perplexity : 6.1201 : new best
[2019-07-20 05:21:51] [valid] Ep. 19 : Up. 420000 : translation : 31.81 : stalled 2 times (last best: 31.86)
[2019-07-20 05:37:03] Ep. 19 : Up. 422000 : Sen. 3,230,024 : Cost 48.54463577 : Time 1030.04s : 7554.97 words/s
[2019-07-20 05:46:36] Seen 3423702 samples
[2019-07-20 05:46:36] Starting epoch 20
[2019-07-20 05:46:36] [data] Shuffling data
[2019-07-20 05:46:39] [data] Done reading 4266183 sentences
[2019-07-20 05:46:58] [data] Done shuffling 4266183 sentences to temp files
[2019-07-20 05:52:41] Ep. 20 : Up. 424000 : Sen. 114,498 : Cost 47.80919647 : Time 937.95s : 8291.89 words/s
[2019-07-20 06:07:49] Ep. 20 : Up. 426000 : Sen. 422,268 : Cost 47.26624298 : Time 908.23s : 8564.85 words/s
[2019-07-25 20:35:18] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-25 20:35:18] [marian] Running on fulla as process 3155 with command line:
[2019-07-25 20:35:18] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz -T . --devices 6 7 --train-sets ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.de ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.en --vocabs ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.de.json ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.en.json --mini-batch-fit -w 5000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/dev.bpe.de ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/dev.out --valid-script-path ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/train.log --valid-log ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/valid.log
[2019-07-25 20:35:19] [config] after-batches: 0
[2019-07-25 20:35:19] [config] after-epochs: 0
[2019-07-25 20:35:19] [config] allow-unk: false
[2019-07-25 20:35:19] [config] beam-size: 12
[2019-07-25 20:35:19] [config] bert-class-symbol: "[CLS]"
[2019-07-25 20:35:19] [config] bert-mask-symbol: "[MASK]"
[2019-07-25 20:35:19] [config] bert-masking-fraction: 0.15
[2019-07-25 20:35:19] [config] bert-sep-symbol: "[SEP]"
[2019-07-25 20:35:19] [config] bert-train-type-embeddings: true
[2019-07-25 20:35:19] [config] bert-type-vocab-size: 2
[2019-07-25 20:35:19] [config] best-deep: false
[2019-07-25 20:35:19] [config] clip-gemm: 0
[2019-07-25 20:35:19] [config] clip-norm: 1
[2019-07-25 20:35:19] [config] cost-type: ce-mean
[2019-07-25 20:35:19] [config] cpu-threads: 0
[2019-07-25 20:35:19] [config] data-weighting: ""
[2019-07-25 20:35:19] [config] data-weighting-type: sentence
[2019-07-25 20:35:19] [config] dec-cell: gru
[2019-07-25 20:35:19] [config] dec-cell-base-depth: 2
[2019-07-25 20:35:19] [config] dec-cell-high-depth: 1
[2019-07-25 20:35:19] [config] dec-depth: 1
[2019-07-25 20:35:19] [config] devices:
[2019-07-25 20:35:19] [config]   - 6
[2019-07-25 20:35:19] [config]   - 7
[2019-07-25 20:35:19] [config] dim-emb: 512
[2019-07-25 20:35:19] [config] dim-rnn: 1024
[2019-07-25 20:35:19] [config] dim-vocabs:
[2019-07-25 20:35:19] [config]   - 50000
[2019-07-25 20:35:19] [config]   - 50000
[2019-07-25 20:35:19] [config] disp-first: 0
[2019-07-25 20:35:19] [config] disp-freq: 2000
[2019-07-25 20:35:19] [config] disp-label-counts: false
[2019-07-25 20:35:19] [config] dropout-rnn: 0.2
[2019-07-25 20:35:19] [config] dropout-src: 0.1
[2019-07-25 20:35:19] [config] dropout-trg: 0.1
[2019-07-25 20:35:19] [config] dump-config: ""
[2019-07-25 20:35:19] [config] early-stopping: 5
[2019-07-25 20:35:19] [config] embedding-fix-src: false
[2019-07-25 20:35:19] [config] embedding-fix-trg: false
[2019-07-25 20:35:19] [config] embedding-normalization: false
[2019-07-25 20:35:19] [config] embedding-vectors:
[2019-07-25 20:35:19] [config]   []
[2019-07-25 20:35:19] [config] enc-cell: gru
[2019-07-25 20:35:19] [config] enc-cell-depth: 1
[2019-07-25 20:35:19] [config] enc-depth: 1
[2019-07-25 20:35:19] [config] enc-type: bidirectional
[2019-07-25 20:35:19] [config] exponential-smoothing: 0.0001
[2019-07-25 20:35:19] [config] grad-dropping-momentum: 0
[2019-07-25 20:35:19] [config] grad-dropping-rate: 0
[2019-07-25 20:35:19] [config] grad-dropping-warmup: 100
[2019-07-25 20:35:19] [config] guided-alignment: none
[2019-07-25 20:35:19] [config] guided-alignment-cost: mse
[2019-07-25 20:35:19] [config] guided-alignment-weight: 0.1
[2019-07-25 20:35:19] [config] ignore-model-config: false
[2019-07-25 20:35:19] [config] input-types:
[2019-07-25 20:35:19] [config]   []
[2019-07-25 20:35:19] [config] interpolate-env-vars: false
[2019-07-25 20:35:19] [config] keep-best: false
[2019-07-25 20:35:19] [config] label-smoothing: 0
[2019-07-25 20:35:19] [config] layer-normalization: true
[2019-07-25 20:35:19] [config] learn-rate: 0.0001
[2019-07-25 20:35:19] [config] log: ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/train.log
[2019-07-25 20:35:19] [config] log-level: info
[2019-07-25 20:35:19] [config] log-time-zone: ""
[2019-07-25 20:35:19] [config] lr-decay: 0
[2019-07-25 20:35:19] [config] lr-decay-freq: 50000
[2019-07-25 20:35:19] [config] lr-decay-inv-sqrt:
[2019-07-25 20:35:19] [config]   - 0
[2019-07-25 20:35:19] [config] lr-decay-repeat-warmup: false
[2019-07-25 20:35:19] [config] lr-decay-reset-optimizer: false
[2019-07-25 20:35:19] [config] lr-decay-start:
[2019-07-25 20:35:19] [config]   - 10
[2019-07-25 20:35:19] [config]   - 1
[2019-07-25 20:35:19] [config] lr-decay-strategy: epoch+stalled
[2019-07-25 20:35:19] [config] lr-report: false
[2019-07-25 20:35:19] [config] lr-warmup: 0
[2019-07-25 20:35:19] [config] lr-warmup-at-reload: false
[2019-07-25 20:35:19] [config] lr-warmup-cycle: false
[2019-07-25 20:35:19] [config] lr-warmup-start-rate: 0
[2019-07-25 20:35:19] [config] max-length: 50
[2019-07-25 20:35:19] [config] max-length-crop: false
[2019-07-25 20:35:19] [config] max-length-factor: 3
[2019-07-25 20:35:19] [config] maxi-batch: 100
[2019-07-25 20:35:19] [config] maxi-batch-sort: trg
[2019-07-25 20:35:19] [config] mini-batch: 64
[2019-07-25 20:35:19] [config] mini-batch-fit: true
[2019-07-25 20:35:19] [config] mini-batch-fit-step: 10
[2019-07-25 20:35:19] [config] mini-batch-overstuff: 1
[2019-07-25 20:35:19] [config] mini-batch-track-lr: false
[2019-07-25 20:35:19] [config] mini-batch-understuff: 1
[2019-07-25 20:35:19] [config] mini-batch-warmup: 0
[2019-07-25 20:35:19] [config] mini-batch-words: 0
[2019-07-25 20:35:19] [config] mini-batch-words-ref: 0
[2019-07-25 20:35:19] [config] model: ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-25 20:35:19] [config] multi-loss-type: sum
[2019-07-25 20:35:19] [config] multi-node: false
[2019-07-25 20:35:19] [config] multi-node-overlap: true
[2019-07-25 20:35:19] [config] n-best: false
[2019-07-25 20:35:19] [config] no-nccl: false
[2019-07-25 20:35:19] [config] no-reload: false
[2019-07-25 20:35:19] [config] no-restore-corpus: false
[2019-07-25 20:35:19] [config] no-shuffle: false
[2019-07-25 20:35:19] [config] normalize: 1
[2019-07-25 20:35:19] [config] num-devices: 0
[2019-07-25 20:35:19] [config] optimizer: adam
[2019-07-25 20:35:19] [config] optimizer-delay: 1
[2019-07-25 20:35:19] [config] optimizer-params:
[2019-07-25 20:35:19] [config]   []
[2019-07-25 20:35:19] [config] overwrite: false
[2019-07-25 20:35:19] [config] pretrained-model: ""
[2019-07-25 20:35:19] [config] quiet: false
[2019-07-25 20:35:19] [config] quiet-translation: true
[2019-07-25 20:35:19] [config] relative-paths: false
[2019-07-25 20:35:19] [config] right-left: false
[2019-07-25 20:35:19] [config] save-freq: 20000
[2019-07-25 20:35:19] [config] seed: 1111
[2019-07-25 20:35:19] [config] shuffle-in-ram: false
[2019-07-25 20:35:19] [config] skip: false
[2019-07-25 20:35:19] [config] sqlite: ""
[2019-07-25 20:35:19] [config] sqlite-drop: false
[2019-07-25 20:35:19] [config] sync-sgd: true
[2019-07-25 20:35:19] [config] tempdir: .
[2019-07-25 20:35:19] [config] tied-embeddings: false
[2019-07-25 20:35:19] [config] tied-embeddings-all: false
[2019-07-25 20:35:19] [config] tied-embeddings-src: false
[2019-07-25 20:35:19] [config] train-sets:
[2019-07-25 20:35:19] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.de
[2019-07-25 20:35:19] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.en
[2019-07-25 20:35:19] [config] transformer-aan-activation: swish
[2019-07-25 20:35:19] [config] transformer-aan-depth: 2
[2019-07-25 20:35:19] [config] transformer-aan-nogate: false
[2019-07-25 20:35:19] [config] transformer-decoder-autoreg: self-attention
[2019-07-25 20:35:19] [config] transformer-dim-aan: 2048
[2019-07-25 20:35:19] [config] transformer-dim-ffn: 2048
[2019-07-25 20:35:19] [config] transformer-dropout: 0
[2019-07-25 20:35:19] [config] transformer-dropout-attention: 0
[2019-07-25 20:35:19] [config] transformer-dropout-ffn: 0
[2019-07-25 20:35:19] [config] transformer-ffn-activation: swish
[2019-07-25 20:35:19] [config] transformer-ffn-depth: 2
[2019-07-25 20:35:19] [config] transformer-guided-alignment-layer: last
[2019-07-25 20:35:19] [config] transformer-heads: 8
[2019-07-25 20:35:19] [config] transformer-no-projection: false
[2019-07-25 20:35:19] [config] transformer-postprocess: dan
[2019-07-25 20:35:19] [config] transformer-postprocess-emb: d
[2019-07-25 20:35:19] [config] transformer-preprocess: ""
[2019-07-25 20:35:19] [config] transformer-tied-layers:
[2019-07-25 20:35:19] [config]   []
[2019-07-25 20:35:19] [config] transformer-train-position-embeddings: false
[2019-07-25 20:35:19] [config] type: amun
[2019-07-25 20:35:19] [config] ulr: false
[2019-07-25 20:35:19] [config] ulr-dim-emb: 0
[2019-07-25 20:35:19] [config] ulr-dropout: 0
[2019-07-25 20:35:19] [config] ulr-keys-vectors: ""
[2019-07-25 20:35:19] [config] ulr-query-vectors: ""
[2019-07-25 20:35:19] [config] ulr-softmax-temperature: 1
[2019-07-25 20:35:19] [config] ulr-trainable-transformation: false
[2019-07-25 20:35:19] [config] valid-freq: 20000
[2019-07-25 20:35:19] [config] valid-log: ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/valid.log
[2019-07-25 20:35:19] [config] valid-max-length: 1000
[2019-07-25 20:35:19] [config] valid-metrics:
[2019-07-25 20:35:19] [config]   - cross-entropy
[2019-07-25 20:35:19] [config]   - perplexity
[2019-07-25 20:35:19] [config]   - translation
[2019-07-25 20:35:19] [config] valid-mini-batch: 8
[2019-07-25 20:35:19] [config] valid-script-path: ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/score-dev.sh
[2019-07-25 20:35:19] [config] valid-sets:
[2019-07-25 20:35:19] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/dev.bpe.de
[2019-07-25 20:35:19] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/dev.bpe.en
[2019-07-25 20:35:19] [config] valid-translation-output: ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/dev.out
[2019-07-25 20:35:19] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-25 20:35:19] [config] vocabs:
[2019-07-25 20:35:19] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.de.json
[2019-07-25 20:35:19] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.en.json
[2019-07-25 20:35:19] [config] word-penalty: 0
[2019-07-25 20:35:19] [config] workspace: 5000
[2019-07-25 20:35:19] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-25 20:35:19] Using synchronous training
[2019-07-25 20:35:19] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.de.json
[2019-07-25 20:35:19] [data] Using unused word id eos for 0
[2019-07-25 20:35:19] [data] Using unused word id UNK for 1
[2019-07-25 20:35:19] [data] Setting vocabulary size for input 0 to 50000
[2019-07-25 20:35:19] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.en.json
[2019-07-25 20:35:20] [data] Using unused word id eos for 0
[2019-07-25 20:35:20] [data] Using unused word id UNK for 1
[2019-07-25 20:35:20] [data] Setting vocabulary size for input 1 to 50000
[2019-07-25 20:35:20] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-25 20:35:20] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-25 20:35:21] [memory] Extending reserved space to 5120 MB (device gpu6)
[2019-07-25 20:35:22] [memory] Extending reserved space to 5120 MB (device gpu7)
[2019-07-25 20:35:22] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-25 20:35:22] [comm] NCCLCommunicator constructed successfully.
[2019-07-25 20:35:22] [training] Using 2 GPUs
[2019-07-25 20:35:22] [memory] Reserving 422 MB, device gpu6
[2019-07-25 20:35:22] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-25 20:35:22] [memory] Reserving 422 MB, device gpu6
[2019-07-25 20:35:27] [batching] Done. Typical MB size is 13760 target words
[2019-07-25 20:35:27] [memory] Extending reserved space to 5120 MB (device gpu6)
[2019-07-25 20:35:27] [memory] Extending reserved space to 5120 MB (device gpu7)
[2019-07-25 20:35:27] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-25 20:35:27] [comm] NCCLCommunicator constructed successfully.
[2019-07-25 20:35:27] [training] Using 2 GPUs
[2019-07-25 20:35:27] Loading model from ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-25 20:35:37] Loading model from ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-25 20:35:40] Loading Adam parameters from ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-07-25 20:35:55] [memory] Reserving 422 MB, device gpu6
[2019-07-25 20:35:55] [memory] Reserving 422 MB, device gpu7
[2019-07-25 20:35:56] [training] Model reloaded from ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-25 20:35:56] [data] Restoring the corpus state to epoch 19, batch 420000
[2019-07-25 20:35:56] [data] Shuffling data
[2019-07-25 20:36:11] [data] Done reading 4266183 sentences
[2019-07-25 20:36:26] [data] Done shuffling 4266183 sentences to temp files
[2019-07-25 20:39:01] Error: attempted to wait for futureBufferedBatches_ when none pending
[2019-07-25 20:39:01] Error: Aborted from marian::data::BatchGenerator<DataSet>::BatchPtr marian::data::BatchGenerator<DataSet>::next() [with DataSet = marian::data::CorpusBase; marian::data::BatchGenerator<DataSet>::BatchPtr = std::shared_ptr<marian::data::CorpusBatch>] in /fs/bil0/abdel/marian-dev/src/data/batch_generator.h:236

[CALL STACK]
[0x627611]          marian::data::BatchGenerator<marian::data::CorpusBase>::  next  () + 0x631
[0x63f87c]          marian::data::BatchGenerator<marian::data::CorpusBase>::  restore  (std::shared_ptr<marian::TrainingState>,  bool) + 0x27c
[0x670192]          marian::Train<marian::SyncGraphGroup>::  run  ()   + 0x12a2
[0x5a13aa]          mainTrainer  (int,  char**)                        + 0x2ca
[0x57dd1a]          main                                               + 0x8a
[0x7efdcfd6e830]    __libc_start_main                                  + 0xf0
[0x59edc9]          _start                                             + 0x29

[2019-07-25 22:02:09] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-25 22:02:09] [marian] Running on fulla as process 66344 with command line:
[2019-07-25 22:02:09] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz -T . --devices 6 --train-sets ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.de ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.en --vocabs ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.de.json ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.en.json --mini-batch-fit -w 5000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/dev.bpe.de ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/dev.out --valid-script-path ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/train.log --valid-log ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/valid.log
[2019-07-25 22:02:09] [config] after-batches: 0
[2019-07-25 22:02:09] [config] after-epochs: 0
[2019-07-25 22:02:09] [config] allow-unk: false
[2019-07-25 22:02:09] [config] beam-size: 12
[2019-07-25 22:02:09] [config] bert-class-symbol: "[CLS]"
[2019-07-25 22:02:09] [config] bert-mask-symbol: "[MASK]"
[2019-07-25 22:02:09] [config] bert-masking-fraction: 0.15
[2019-07-25 22:02:09] [config] bert-sep-symbol: "[SEP]"
[2019-07-25 22:02:09] [config] bert-train-type-embeddings: true
[2019-07-25 22:02:09] [config] bert-type-vocab-size: 2
[2019-07-25 22:02:09] [config] best-deep: false
[2019-07-25 22:02:09] [config] clip-gemm: 0
[2019-07-25 22:02:09] [config] clip-norm: 1
[2019-07-25 22:02:09] [config] cost-type: ce-mean
[2019-07-25 22:02:09] [config] cpu-threads: 0
[2019-07-25 22:02:09] [config] data-weighting: ""
[2019-07-25 22:02:09] [config] data-weighting-type: sentence
[2019-07-25 22:02:09] [config] dec-cell: gru
[2019-07-25 22:02:09] [config] dec-cell-base-depth: 2
[2019-07-25 22:02:09] [config] dec-cell-high-depth: 1
[2019-07-25 22:02:09] [config] dec-depth: 1
[2019-07-25 22:02:09] [config] devices:
[2019-07-25 22:02:09] [config]   - 6
[2019-07-25 22:02:09] [config] dim-emb: 512
[2019-07-25 22:02:09] [config] dim-rnn: 1024
[2019-07-25 22:02:09] [config] dim-vocabs:
[2019-07-25 22:02:09] [config]   - 50000
[2019-07-25 22:02:09] [config]   - 50000
[2019-07-25 22:02:09] [config] disp-first: 0
[2019-07-25 22:02:09] [config] disp-freq: 2000
[2019-07-25 22:02:09] [config] disp-label-counts: false
[2019-07-25 22:02:09] [config] dropout-rnn: 0.2
[2019-07-25 22:02:09] [config] dropout-src: 0.1
[2019-07-25 22:02:09] [config] dropout-trg: 0.1
[2019-07-25 22:02:09] [config] dump-config: ""
[2019-07-25 22:02:09] [config] early-stopping: 5
[2019-07-25 22:02:09] [config] embedding-fix-src: false
[2019-07-25 22:02:09] [config] embedding-fix-trg: false
[2019-07-25 22:02:09] [config] embedding-normalization: false
[2019-07-25 22:02:09] [config] embedding-vectors:
[2019-07-25 22:02:09] [config]   []
[2019-07-25 22:02:09] [config] enc-cell: gru
[2019-07-25 22:02:09] [config] enc-cell-depth: 1
[2019-07-25 22:02:09] [config] enc-depth: 1
[2019-07-25 22:02:09] [config] enc-type: bidirectional
[2019-07-25 22:02:09] [config] exponential-smoothing: 0.0001
[2019-07-25 22:02:09] [config] grad-dropping-momentum: 0
[2019-07-25 22:02:09] [config] grad-dropping-rate: 0
[2019-07-25 22:02:09] [config] grad-dropping-warmup: 100
[2019-07-25 22:02:09] [config] guided-alignment: none
[2019-07-25 22:02:09] [config] guided-alignment-cost: mse
[2019-07-25 22:02:09] [config] guided-alignment-weight: 0.1
[2019-07-25 22:02:09] [config] ignore-model-config: false
[2019-07-25 22:02:09] [config] input-types:
[2019-07-25 22:02:09] [config]   []
[2019-07-25 22:02:09] [config] interpolate-env-vars: false
[2019-07-25 22:02:09] [config] keep-best: false
[2019-07-25 22:02:09] [config] label-smoothing: 0
[2019-07-25 22:02:09] [config] layer-normalization: true
[2019-07-25 22:02:09] [config] learn-rate: 0.0001
[2019-07-25 22:02:09] [config] log: ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/train.log
[2019-07-25 22:02:09] [config] log-level: info
[2019-07-25 22:02:09] [config] log-time-zone: ""
[2019-07-25 22:02:09] [config] lr-decay: 0
[2019-07-25 22:02:09] [config] lr-decay-freq: 50000
[2019-07-25 22:02:09] [config] lr-decay-inv-sqrt:
[2019-07-25 22:02:09] [config]   - 0
[2019-07-25 22:02:09] [config] lr-decay-repeat-warmup: false
[2019-07-25 22:02:09] [config] lr-decay-reset-optimizer: false
[2019-07-25 22:02:09] [config] lr-decay-start:
[2019-07-25 22:02:09] [config]   - 10
[2019-07-25 22:02:09] [config]   - 1
[2019-07-25 22:02:09] [config] lr-decay-strategy: epoch+stalled
[2019-07-25 22:02:09] [config] lr-report: false
[2019-07-25 22:02:09] [config] lr-warmup: 0
[2019-07-25 22:02:09] [config] lr-warmup-at-reload: false
[2019-07-25 22:02:09] [config] lr-warmup-cycle: false
[2019-07-25 22:02:09] [config] lr-warmup-start-rate: 0
[2019-07-25 22:02:09] [config] max-length: 50
[2019-07-25 22:02:09] [config] max-length-crop: false
[2019-07-25 22:02:09] [config] max-length-factor: 3
[2019-07-25 22:02:09] [config] maxi-batch: 100
[2019-07-25 22:02:09] [config] maxi-batch-sort: trg
[2019-07-25 22:02:09] [config] mini-batch: 64
[2019-07-25 22:02:09] [config] mini-batch-fit: true
[2019-07-25 22:02:09] [config] mini-batch-fit-step: 10
[2019-07-25 22:02:09] [config] mini-batch-overstuff: 1
[2019-07-25 22:02:09] [config] mini-batch-track-lr: false
[2019-07-25 22:02:09] [config] mini-batch-understuff: 1
[2019-07-25 22:02:09] [config] mini-batch-warmup: 0
[2019-07-25 22:02:09] [config] mini-batch-words: 0
[2019-07-25 22:02:09] [config] mini-batch-words-ref: 0
[2019-07-25 22:02:09] [config] model: ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-25 22:02:09] [config] multi-loss-type: sum
[2019-07-25 22:02:09] [config] multi-node: false
[2019-07-25 22:02:09] [config] multi-node-overlap: true
[2019-07-25 22:02:09] [config] n-best: false
[2019-07-25 22:02:09] [config] no-nccl: false
[2019-07-25 22:02:09] [config] no-reload: false
[2019-07-25 22:02:09] [config] no-restore-corpus: false
[2019-07-25 22:02:09] [config] no-shuffle: false
[2019-07-25 22:02:09] [config] normalize: 1
[2019-07-25 22:02:09] [config] num-devices: 0
[2019-07-25 22:02:09] [config] optimizer: adam
[2019-07-25 22:02:09] [config] optimizer-delay: 1
[2019-07-25 22:02:09] [config] optimizer-params:
[2019-07-25 22:02:09] [config]   []
[2019-07-25 22:02:09] [config] overwrite: false
[2019-07-25 22:02:09] [config] pretrained-model: ""
[2019-07-25 22:02:09] [config] quiet: false
[2019-07-25 22:02:09] [config] quiet-translation: true
[2019-07-25 22:02:09] [config] relative-paths: false
[2019-07-25 22:02:09] [config] right-left: false
[2019-07-25 22:02:09] [config] save-freq: 20000
[2019-07-25 22:02:09] [config] seed: 1111
[2019-07-25 22:02:09] [config] shuffle-in-ram: false
[2019-07-25 22:02:09] [config] skip: false
[2019-07-25 22:02:09] [config] sqlite: ""
[2019-07-25 22:02:09] [config] sqlite-drop: false
[2019-07-25 22:02:09] [config] sync-sgd: true
[2019-07-25 22:02:09] [config] tempdir: .
[2019-07-25 22:02:09] [config] tied-embeddings: false
[2019-07-25 22:02:09] [config] tied-embeddings-all: false
[2019-07-25 22:02:09] [config] tied-embeddings-src: false
[2019-07-25 22:02:09] [config] train-sets:
[2019-07-25 22:02:09] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.de
[2019-07-25 22:02:09] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.en
[2019-07-25 22:02:09] [config] transformer-aan-activation: swish
[2019-07-25 22:02:09] [config] transformer-aan-depth: 2
[2019-07-25 22:02:09] [config] transformer-aan-nogate: false
[2019-07-25 22:02:09] [config] transformer-decoder-autoreg: self-attention
[2019-07-25 22:02:09] [config] transformer-dim-aan: 2048
[2019-07-25 22:02:09] [config] transformer-dim-ffn: 2048
[2019-07-25 22:02:09] [config] transformer-dropout: 0
[2019-07-25 22:02:09] [config] transformer-dropout-attention: 0
[2019-07-25 22:02:09] [config] transformer-dropout-ffn: 0
[2019-07-25 22:02:09] [config] transformer-ffn-activation: swish
[2019-07-25 22:02:09] [config] transformer-ffn-depth: 2
[2019-07-25 22:02:09] [config] transformer-guided-alignment-layer: last
[2019-07-25 22:02:09] [config] transformer-heads: 8
[2019-07-25 22:02:09] [config] transformer-no-projection: false
[2019-07-25 22:02:09] [config] transformer-postprocess: dan
[2019-07-25 22:02:09] [config] transformer-postprocess-emb: d
[2019-07-25 22:02:09] [config] transformer-preprocess: ""
[2019-07-25 22:02:09] [config] transformer-tied-layers:
[2019-07-25 22:02:09] [config]   []
[2019-07-25 22:02:09] [config] transformer-train-position-embeddings: false
[2019-07-25 22:02:09] [config] type: amun
[2019-07-25 22:02:09] [config] ulr: false
[2019-07-25 22:02:09] [config] ulr-dim-emb: 0
[2019-07-25 22:02:09] [config] ulr-dropout: 0
[2019-07-25 22:02:09] [config] ulr-keys-vectors: ""
[2019-07-25 22:02:09] [config] ulr-query-vectors: ""
[2019-07-25 22:02:09] [config] ulr-softmax-temperature: 1
[2019-07-25 22:02:09] [config] ulr-trainable-transformation: false
[2019-07-25 22:02:09] [config] valid-freq: 20000
[2019-07-25 22:02:09] [config] valid-log: ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/valid.log
[2019-07-25 22:02:09] [config] valid-max-length: 1000
[2019-07-25 22:02:09] [config] valid-metrics:
[2019-07-25 22:02:09] [config]   - cross-entropy
[2019-07-25 22:02:09] [config]   - perplexity
[2019-07-25 22:02:09] [config]   - translation
[2019-07-25 22:02:09] [config] valid-mini-batch: 8
[2019-07-25 22:02:09] [config] valid-script-path: ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/score-dev.sh
[2019-07-25 22:02:09] [config] valid-sets:
[2019-07-25 22:02:09] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/dev.bpe.de
[2019-07-25 22:02:09] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/dev.bpe.en
[2019-07-25 22:02:09] [config] valid-translation-output: ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/dev.out
[2019-07-25 22:02:09] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-25 22:02:09] [config] vocabs:
[2019-07-25 22:02:09] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.de.json
[2019-07-25 22:02:09] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.en.json
[2019-07-25 22:02:09] [config] word-penalty: 0
[2019-07-25 22:02:09] [config] workspace: 5000
[2019-07-25 22:02:09] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-25 22:02:09] Using synchronous training
[2019-07-25 22:02:09] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.de.json
[2019-07-25 22:02:09] [data] Using unused word id eos for 0
[2019-07-25 22:02:09] [data] Using unused word id UNK for 1
[2019-07-25 22:02:09] [data] Setting vocabulary size for input 0 to 50000
[2019-07-25 22:02:09] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/data/train.bpe.en.json
[2019-07-25 22:02:09] [data] Using unused word id eos for 0
[2019-07-25 22:02:09] [data] Using unused word id UNK for 1
[2019-07-25 22:02:09] [data] Setting vocabulary size for input 1 to 50000
[2019-07-25 22:02:09] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-25 22:02:09] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-25 22:02:10] [memory] Extending reserved space to 5120 MB (device gpu6)
[2019-07-25 22:02:11] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-25 22:02:11] [comm] NCCLCommunicator constructed successfully.
[2019-07-25 22:02:11] [training] Using 1 GPUs
[2019-07-25 22:02:11] [memory] Reserving 422 MB, device gpu6
[2019-07-25 22:02:11] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-25 22:02:11] [memory] Reserving 422 MB, device gpu6
[2019-07-25 22:02:15] [batching] Done. Typical MB size is 6880 target words
[2019-07-25 22:02:15] [memory] Extending reserved space to 5120 MB (device gpu6)
[2019-07-25 22:02:15] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-25 22:02:15] [comm] NCCLCommunicator constructed successfully.
[2019-07-25 22:02:15] [training] Using 1 GPUs
[2019-07-25 22:02:15] Loading model from ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-25 22:02:18] Loading Adam parameters from ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-07-25 22:02:21] [memory] Reserving 844 MB, device gpu6
[2019-07-25 22:02:22] [training] Model reloaded from ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-25 22:02:22] [data] Restoring the corpus state to epoch 19, batch 420000
[2019-07-25 22:02:22] [data] Shuffling data
[2019-07-25 22:02:25] [data] Done reading 4266183 sentences
[2019-07-25 22:02:47] [data] Done shuffling 4266183 sentences to temp files
[2019-07-25 22:04:53] Training started
[2019-07-25 22:04:53] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-07-25 22:04:53] [memory] Reserving 422 MB, device gpu6
[2019-07-25 22:04:53] [memory] Reserving 422 MB, device gpu6
[2019-07-25 22:04:53] Loading model from ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-25 22:05:00] [memory] Reserving 422 MB, device cpu0
[2019-07-25 22:05:00] [memory] Reserving 422 MB, device gpu6
[2019-07-25 22:12:26] Ep. 19 : Up. 422000 : Sen. 3,230,024 : Cost 48.81542206 : Time 616.57s : 12621.38 words/s
[2019-07-25 22:17:07] Seen 3423702 samples
[2019-07-25 22:17:07] Starting epoch 20
[2019-07-25 22:17:07] [data] Shuffling data
[2019-07-25 22:17:10] [data] Done reading 4266183 sentences
[2019-07-25 22:17:25] [data] Done shuffling 4266183 sentences to temp files
[2019-07-25 22:20:20] Ep. 20 : Up. 424000 : Sen. 114,498 : Cost 47.91933441 : Time 473.96s : 16409.14 words/s
[2019-07-25 22:27:46] Ep. 20 : Up. 426000 : Sen. 422,268 : Cost 47.30090332 : Time 446.47s : 17423.01 words/s
[2019-07-25 22:35:12] Ep. 20 : Up. 428000 : Sen. 730,081 : Cost 47.47470856 : Time 446.00s : 17423.76 words/s
[2019-07-25 22:42:38] Ep. 20 : Up. 430000 : Sen. 1,036,668 : Cost 47.54747009 : Time 445.66s : 17397.91 words/s
[2019-07-25 22:50:05] Ep. 20 : Up. 432000 : Sen. 1,344,440 : Cost 47.60765839 : Time 446.96s : 17412.25 words/s
[2019-07-25 22:57:32] Ep. 20 : Up. 434000 : Sen. 1,652,112 : Cost 47.58508301 : Time 446.75s : 17416.87 words/s
[2019-07-25 23:04:57] Ep. 20 : Up. 436000 : Sen. 1,959,279 : Cost 47.71664429 : Time 445.52s : 17381.14 words/s
[2019-07-25 23:12:23] Ep. 20 : Up. 438000 : Sen. 2,265,732 : Cost 47.87747955 : Time 446.29s : 17355.49 words/s
[2019-07-25 23:19:51] Ep. 20 : Up. 440000 : Sen. 2,572,974 : Cost 48.13035583 : Time 447.34s : 17361.64 words/s
[2019-07-25 23:19:51] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-25 23:20:00] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.iter440000.npz
[2019-07-25 23:20:07] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-25 23:20:17] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-07-25 23:20:43] [valid] Ep. 20 : Up. 440000 : cross-entropy : 45.891 : stalled 2 times (last best: 45.8534)
[2019-07-25 23:20:49] [valid] Ep. 20 : Up. 440000 : perplexity : 6.12942 : stalled 2 times (last best: 6.12032)
[2019-07-25 23:21:37] [valid] Ep. 20 : Up. 440000 : translation : 31.7 : stalled 2 times (last best: 31.86)
[2019-07-25 23:29:05] Ep. 20 : Up. 442000 : Sen. 2,880,167 : Cost 48.01860046 : Time 554.40s : 13977.73 words/s
[2019-07-25 23:36:32] Ep. 20 : Up. 444000 : Sen. 3,186,785 : Cost 48.07876205 : Time 447.33s : 17320.02 words/s
[2019-07-25 23:42:18] Seen 3423702 samples
[2019-07-25 23:42:18] Starting epoch 21
[2019-07-25 23:42:18] [data] Shuffling data
[2019-07-25 23:42:20] [data] Done reading 4266183 sentences
[2019-07-25 23:42:35] [data] Done shuffling 4266183 sentences to temp files
[2019-07-25 23:44:26] Ep. 21 : Up. 446000 : Sen. 70,400 : Cost 47.99554062 : Time 473.57s : 16388.89 words/s
[2019-07-25 23:51:54] Ep. 21 : Up. 448000 : Sen. 378,236 : Cost 46.97351837 : Time 448.25s : 17346.06 words/s
[2019-07-25 23:59:21] Ep. 21 : Up. 450000 : Sen. 685,162 : Cost 47.06010818 : Time 446.81s : 17338.80 words/s
[2019-07-26 00:06:48] Ep. 21 : Up. 452000 : Sen. 992,230 : Cost 47.31377029 : Time 447.23s : 17325.78 words/s
[2019-07-26 00:14:17] Ep. 21 : Up. 454000 : Sen. 1,300,686 : Cost 47.27158356 : Time 448.92s : 17337.10 words/s
[2019-07-26 00:21:47] Ep. 21 : Up. 456000 : Sen. 1,607,736 : Cost 47.73562241 : Time 449.69s : 17286.06 words/s
[2019-07-26 00:29:15] Ep. 21 : Up. 458000 : Sen. 1,914,524 : Cost 47.71923828 : Time 448.08s : 17321.08 words/s
[2019-07-26 00:36:43] Ep. 21 : Up. 460000 : Sen. 2,221,941 : Cost 47.62994003 : Time 448.27s : 17316.83 words/s
[2019-07-26 00:36:43] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-26 00:36:53] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.iter460000.npz
[2019-07-26 00:37:01] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-26 00:37:10] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-07-26 00:37:36] [valid] Ep. 21 : Up. 460000 : cross-entropy : 45.9895 : stalled 3 times (last best: 45.8534)
[2019-07-26 00:37:42] [valid] Ep. 21 : Up. 460000 : perplexity : 6.15333 : stalled 3 times (last best: 6.12032)
[2019-07-26 00:38:30] [valid] Ep. 21 : Up. 460000 : translation : 31.71 : stalled 3 times (last best: 31.86)
[2019-07-26 00:45:59] Ep. 21 : Up. 462000 : Sen. 2,528,890 : Cost 47.65669632 : Time 555.72s : 13946.67 words/s
[2019-07-26 00:53:29] Ep. 21 : Up. 464000 : Sen. 2,837,530 : Cost 47.99084854 : Time 450.23s : 17353.31 words/s
[2019-07-26 01:00:57] Ep. 21 : Up. 466000 : Sen. 3,144,710 : Cost 47.79359436 : Time 447.69s : 17299.95 words/s
[2019-07-26 01:07:44] Seen 3423702 samples
[2019-07-26 01:07:44] Starting epoch 22
[2019-07-26 01:07:44] [data] Shuffling data
[2019-07-26 01:07:47] [data] Done reading 4266183 sentences
[2019-07-26 01:08:01] [data] Done shuffling 4266183 sentences to temp files
[2019-07-26 01:08:49] Ep. 22 : Up. 468000 : Sen. 27,308 : Cost 47.74258423 : Time 472.11s : 16409.64 words/s
[2019-07-26 01:16:16] Ep. 22 : Up. 470000 : Sen. 333,851 : Cost 46.87235641 : Time 447.14s : 17320.27 words/s
[2019-07-26 01:23:44] Ep. 22 : Up. 472000 : Sen. 641,247 : Cost 46.71661758 : Time 448.10s : 17330.01 words/s
[2019-07-26 01:31:12] Ep. 22 : Up. 474000 : Sen. 948,395 : Cost 46.80913925 : Time 448.17s : 17281.99 words/s
[2019-07-26 01:38:40] Ep. 22 : Up. 476000 : Sen. 1,254,664 : Cost 47.14534760 : Time 447.44s : 17298.53 words/s
[2019-07-26 01:46:09] Ep. 22 : Up. 478000 : Sen. 1,561,864 : Cost 47.31146622 : Time 448.90s : 17291.29 words/s
[2019-07-26 01:53:39] Ep. 22 : Up. 480000 : Sen. 1,870,432 : Cost 47.33366394 : Time 450.63s : 17326.29 words/s
[2019-07-26 01:53:39] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-26 01:53:49] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.iter480000.npz
[2019-07-26 01:53:56] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-26 01:54:05] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-07-26 01:54:31] [valid] Ep. 22 : Up. 480000 : cross-entropy : 45.9948 : stalled 4 times (last best: 45.8534)
[2019-07-26 01:54:37] [valid] Ep. 22 : Up. 480000 : perplexity : 6.15462 : stalled 4 times (last best: 6.12032)
[2019-07-26 01:55:25] [valid] Ep. 22 : Up. 480000 : translation : 31.76 : stalled 4 times (last best: 31.86)
[2019-07-26 02:02:55] Ep. 22 : Up. 482000 : Sen. 2,177,263 : Cost 47.22674561 : Time 555.11s : 13944.32 words/s
[2019-07-26 02:10:24] Ep. 22 : Up. 484000 : Sen. 2,486,166 : Cost 47.37672043 : Time 449.23s : 17355.29 words/s
[2019-07-26 02:17:54] Ep. 22 : Up. 486000 : Sen. 2,794,238 : Cost 47.71667862 : Time 449.86s : 17308.86 words/s
[2019-07-26 02:25:22] Ep. 22 : Up. 488000 : Sen. 3,102,234 : Cost 47.63182831 : Time 448.47s : 17338.24 words/s
[2019-07-26 02:32:51] Ep. 22 : Up. 490000 : Sen. 3,409,686 : Cost 47.66408539 : Time 448.97s : 17305.61 words/s
[2019-07-26 02:33:12] Seen 3423702 samples
[2019-07-26 02:33:12] Starting epoch 23
[2019-07-26 02:33:12] [data] Shuffling data
[2019-07-26 02:33:15] [data] Done reading 4266183 sentences
[2019-07-26 02:33:35] [data] Done shuffling 4266183 sentences to temp files
[2019-07-26 02:40:52] Ep. 23 : Up. 492000 : Sen. 293,122 : Cost 46.85058212 : Time 481.19s : 16157.08 words/s
[2019-07-26 02:48:19] Ep. 23 : Up. 494000 : Sen. 599,530 : Cost 46.69060135 : Time 446.56s : 17307.04 words/s
[2019-07-26 02:55:48] Ep. 23 : Up. 496000 : Sen. 906,757 : Cost 46.79668427 : Time 449.24s : 17279.92 words/s
[2019-07-26 03:03:16] Ep. 23 : Up. 498000 : Sen. 1,213,626 : Cost 46.96474457 : Time 447.85s : 17288.41 words/s
[2019-07-26 03:10:47] Ep. 23 : Up. 500000 : Sen. 1,522,303 : Cost 47.45216370 : Time 450.94s : 17308.97 words/s
[2019-07-26 03:10:47] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-26 03:10:56] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.iter500000.npz
[2019-07-26 03:11:03] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-26 03:11:13] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-07-26 03:11:40] [valid] Ep. 23 : Up. 500000 : cross-entropy : 45.971 : stalled 5 times (last best: 45.8534)
[2019-07-26 03:11:46] [valid] Ep. 23 : Up. 500000 : perplexity : 6.14883 : stalled 5 times (last best: 6.12032)
[2019-07-26 03:12:34] [valid] Ep. 23 : Up. 500000 : translation : 31.77 : stalled 5 times (last best: 31.86)
[2019-07-26 03:12:36] Training finished
[2019-07-26 03:12:41] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-07-26 03:12:50] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz
[2019-07-26 03:12:59] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
