MT evaluation scorer began on 2019 Jul 26 at 22:38:56
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_dcce/data/KDE4.de.sgm -r ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_dcce/data/KDE4.en.sgm -t ../experiments/100M_fasttext_prob_x_len_+_biced_0.25_x_dcce/data/KDE4.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 3000 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 0.914791260882829 (116946/127839), penalty (log): -0.0931455543584219
NIST score = 6.5570  BLEU score = 0.2252 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.7374   1.4046   0.3289   0.0707   0.0153   0.0046   0.0019   0.0013   0.0007  "Edinburgh"

 BLEU:  0.5843   0.3039   0.1832   0.1148   0.0746   0.0503   0.0351   0.0253   0.0189  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.7374   6.1420   6.4709   6.5416   6.5570   6.5616   6.5636   6.5648   6.5655  "Edinburgh"

 BLEU:  0.5323   0.3839   0.2908   0.2252   0.1772   0.1414   0.1144   0.0936   0.0775  "Edinburgh"
MT evaluation scorer ended on 2019 Jul 26 at 22:39:29
