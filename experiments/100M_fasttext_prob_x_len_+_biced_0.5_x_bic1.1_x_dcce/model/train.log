[2019-08-05 12:45:42] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-05 12:45:42] [marian] Running on lofn as process 8990 with command line:
[2019-08-05 12:45:42] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz -T . --devices 1 --train-sets ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.de ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.en --vocabs ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.de.json ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/dev.bpe.de ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/dev.out --valid-script-path ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/train.log --valid-log ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/valid.log
[2019-08-05 12:45:42] [config] after-batches: 0
[2019-08-05 12:45:42] [config] after-epochs: 0
[2019-08-05 12:45:42] [config] allow-unk: false
[2019-08-05 12:45:42] [config] beam-size: 12
[2019-08-05 12:45:42] [config] bert-class-symbol: "[CLS]"
[2019-08-05 12:45:42] [config] bert-mask-symbol: "[MASK]"
[2019-08-05 12:45:42] [config] bert-masking-fraction: 0.15
[2019-08-05 12:45:42] [config] bert-sep-symbol: "[SEP]"
[2019-08-05 12:45:42] [config] bert-train-type-embeddings: true
[2019-08-05 12:45:42] [config] bert-type-vocab-size: 2
[2019-08-05 12:45:42] [config] best-deep: false
[2019-08-05 12:45:42] [config] clip-gemm: 0
[2019-08-05 12:45:42] [config] clip-norm: 1
[2019-08-05 12:45:42] [config] cost-type: ce-mean
[2019-08-05 12:45:42] [config] cpu-threads: 0
[2019-08-05 12:45:42] [config] data-weighting: ""
[2019-08-05 12:45:42] [config] data-weighting-type: sentence
[2019-08-05 12:45:42] [config] dec-cell: gru
[2019-08-05 12:45:42] [config] dec-cell-base-depth: 2
[2019-08-05 12:45:42] [config] dec-cell-high-depth: 1
[2019-08-05 12:45:42] [config] dec-depth: 1
[2019-08-05 12:45:42] [config] devices:
[2019-08-05 12:45:42] [config]   - 1
[2019-08-05 12:45:42] [config] dim-emb: 512
[2019-08-05 12:45:42] [config] dim-rnn: 1024
[2019-08-05 12:45:42] [config] dim-vocabs:
[2019-08-05 12:45:42] [config]   - 50000
[2019-08-05 12:45:42] [config]   - 50000
[2019-08-05 12:45:42] [config] disp-first: 0
[2019-08-05 12:45:42] [config] disp-freq: 2000
[2019-08-05 12:45:42] [config] disp-label-counts: false
[2019-08-05 12:45:42] [config] dropout-rnn: 0.2
[2019-08-05 12:45:42] [config] dropout-src: 0.1
[2019-08-05 12:45:42] [config] dropout-trg: 0.1
[2019-08-05 12:45:42] [config] dump-config: ""
[2019-08-05 12:45:42] [config] early-stopping: 5
[2019-08-05 12:45:42] [config] embedding-fix-src: false
[2019-08-05 12:45:42] [config] embedding-fix-trg: false
[2019-08-05 12:45:42] [config] embedding-normalization: false
[2019-08-05 12:45:42] [config] embedding-vectors:
[2019-08-05 12:45:42] [config]   []
[2019-08-05 12:45:42] [config] enc-cell: gru
[2019-08-05 12:45:42] [config] enc-cell-depth: 1
[2019-08-05 12:45:42] [config] enc-depth: 1
[2019-08-05 12:45:42] [config] enc-type: bidirectional
[2019-08-05 12:45:42] [config] exponential-smoothing: 0.0001
[2019-08-05 12:45:42] [config] grad-dropping-momentum: 0
[2019-08-05 12:45:42] [config] grad-dropping-rate: 0
[2019-08-05 12:45:42] [config] grad-dropping-warmup: 100
[2019-08-05 12:45:42] [config] guided-alignment: none
[2019-08-05 12:45:42] [config] guided-alignment-cost: mse
[2019-08-05 12:45:42] [config] guided-alignment-weight: 0.1
[2019-08-05 12:45:42] [config] ignore-model-config: false
[2019-08-05 12:45:42] [config] input-types:
[2019-08-05 12:45:42] [config]   []
[2019-08-05 12:45:42] [config] interpolate-env-vars: false
[2019-08-05 12:45:42] [config] keep-best: false
[2019-08-05 12:45:42] [config] label-smoothing: 0
[2019-08-05 12:45:42] [config] layer-normalization: true
[2019-08-05 12:45:42] [config] learn-rate: 0.0001
[2019-08-05 12:45:42] [config] log: ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/train.log
[2019-08-05 12:45:42] [config] log-level: info
[2019-08-05 12:45:42] [config] log-time-zone: ""
[2019-08-05 12:45:42] [config] lr-decay: 0
[2019-08-05 12:45:42] [config] lr-decay-freq: 50000
[2019-08-05 12:45:42] [config] lr-decay-inv-sqrt:
[2019-08-05 12:45:42] [config]   - 0
[2019-08-05 12:45:42] [config] lr-decay-repeat-warmup: false
[2019-08-05 12:45:42] [config] lr-decay-reset-optimizer: false
[2019-08-05 12:45:42] [config] lr-decay-start:
[2019-08-05 12:45:42] [config]   - 10
[2019-08-05 12:45:42] [config]   - 1
[2019-08-05 12:45:42] [config] lr-decay-strategy: epoch+stalled
[2019-08-05 12:45:42] [config] lr-report: false
[2019-08-05 12:45:42] [config] lr-warmup: 0
[2019-08-05 12:45:42] [config] lr-warmup-at-reload: false
[2019-08-05 12:45:42] [config] lr-warmup-cycle: false
[2019-08-05 12:45:42] [config] lr-warmup-start-rate: 0
[2019-08-05 12:45:42] [config] max-length: 50
[2019-08-05 12:45:42] [config] max-length-crop: false
[2019-08-05 12:45:42] [config] max-length-factor: 3
[2019-08-05 12:45:42] [config] maxi-batch: 100
[2019-08-05 12:45:42] [config] maxi-batch-sort: trg
[2019-08-05 12:45:42] [config] mini-batch: 64
[2019-08-05 12:45:42] [config] mini-batch-fit: true
[2019-08-05 12:45:42] [config] mini-batch-fit-step: 10
[2019-08-05 12:45:42] [config] mini-batch-overstuff: 1
[2019-08-05 12:45:42] [config] mini-batch-track-lr: false
[2019-08-05 12:45:42] [config] mini-batch-understuff: 1
[2019-08-05 12:45:42] [config] mini-batch-warmup: 0
[2019-08-05 12:45:42] [config] mini-batch-words: 0
[2019-08-05 12:45:42] [config] mini-batch-words-ref: 0
[2019-08-05 12:45:42] [config] model: ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-05 12:45:42] [config] multi-loss-type: sum
[2019-08-05 12:45:42] [config] multi-node: false
[2019-08-05 12:45:42] [config] multi-node-overlap: true
[2019-08-05 12:45:42] [config] n-best: false
[2019-08-05 12:45:42] [config] no-nccl: false
[2019-08-05 12:45:42] [config] no-reload: false
[2019-08-05 12:45:42] [config] no-restore-corpus: false
[2019-08-05 12:45:42] [config] no-shuffle: false
[2019-08-05 12:45:42] [config] normalize: 1
[2019-08-05 12:45:42] [config] num-devices: 0
[2019-08-05 12:45:42] [config] optimizer: adam
[2019-08-05 12:45:42] [config] optimizer-delay: 1
[2019-08-05 12:45:42] [config] optimizer-params:
[2019-08-05 12:45:42] [config]   []
[2019-08-05 12:45:42] [config] overwrite: false
[2019-08-05 12:45:42] [config] pretrained-model: ""
[2019-08-05 12:45:42] [config] quiet: false
[2019-08-05 12:45:42] [config] quiet-translation: true
[2019-08-05 12:45:42] [config] relative-paths: false
[2019-08-05 12:45:42] [config] right-left: false
[2019-08-05 12:45:42] [config] save-freq: 20000
[2019-08-05 12:45:42] [config] seed: 1111
[2019-08-05 12:45:42] [config] shuffle-in-ram: false
[2019-08-05 12:45:42] [config] skip: false
[2019-08-05 12:45:42] [config] sqlite: ""
[2019-08-05 12:45:42] [config] sqlite-drop: false
[2019-08-05 12:45:42] [config] sync-sgd: true
[2019-08-05 12:45:42] [config] tempdir: .
[2019-08-05 12:45:42] [config] tied-embeddings: false
[2019-08-05 12:45:42] [config] tied-embeddings-all: false
[2019-08-05 12:45:42] [config] tied-embeddings-src: false
[2019-08-05 12:45:42] [config] train-sets:
[2019-08-05 12:45:42] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.de
[2019-08-05 12:45:42] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.en
[2019-08-05 12:45:42] [config] transformer-aan-activation: swish
[2019-08-05 12:45:42] [config] transformer-aan-depth: 2
[2019-08-05 12:45:42] [config] transformer-aan-nogate: false
[2019-08-05 12:45:42] [config] transformer-decoder-autoreg: self-attention
[2019-08-05 12:45:42] [config] transformer-dim-aan: 2048
[2019-08-05 12:45:42] [config] transformer-dim-ffn: 2048
[2019-08-05 12:45:42] [config] transformer-dropout: 0
[2019-08-05 12:45:42] [config] transformer-dropout-attention: 0
[2019-08-05 12:45:42] [config] transformer-dropout-ffn: 0
[2019-08-05 12:45:42] [config] transformer-ffn-activation: swish
[2019-08-05 12:45:42] [config] transformer-ffn-depth: 2
[2019-08-05 12:45:42] [config] transformer-guided-alignment-layer: last
[2019-08-05 12:45:42] [config] transformer-heads: 8
[2019-08-05 12:45:42] [config] transformer-no-projection: false
[2019-08-05 12:45:42] [config] transformer-postprocess: dan
[2019-08-05 12:45:42] [config] transformer-postprocess-emb: d
[2019-08-05 12:45:42] [config] transformer-preprocess: ""
[2019-08-05 12:45:42] [config] transformer-tied-layers:
[2019-08-05 12:45:42] [config]   []
[2019-08-05 12:45:42] [config] transformer-train-position-embeddings: false
[2019-08-05 12:45:42] [config] type: amun
[2019-08-05 12:45:42] [config] ulr: false
[2019-08-05 12:45:42] [config] ulr-dim-emb: 0
[2019-08-05 12:45:42] [config] ulr-dropout: 0
[2019-08-05 12:45:42] [config] ulr-keys-vectors: ""
[2019-08-05 12:45:42] [config] ulr-query-vectors: ""
[2019-08-05 12:45:42] [config] ulr-softmax-temperature: 1
[2019-08-05 12:45:42] [config] ulr-trainable-transformation: false
[2019-08-05 12:45:42] [config] valid-freq: 20000
[2019-08-05 12:45:42] [config] valid-log: ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/valid.log
[2019-08-05 12:45:42] [config] valid-max-length: 1000
[2019-08-05 12:45:42] [config] valid-metrics:
[2019-08-05 12:45:42] [config]   - cross-entropy
[2019-08-05 12:45:42] [config]   - perplexity
[2019-08-05 12:45:42] [config]   - translation
[2019-08-05 12:45:42] [config] valid-mini-batch: 8
[2019-08-05 12:45:42] [config] valid-script-path: ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/score-dev.sh
[2019-08-05 12:45:42] [config] valid-sets:
[2019-08-05 12:45:42] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/dev.bpe.de
[2019-08-05 12:45:42] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/dev.bpe.en
[2019-08-05 12:45:42] [config] valid-translation-output: ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/dev.out
[2019-08-05 12:45:42] [config] vocabs:
[2019-08-05 12:45:42] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.de.json
[2019-08-05 12:45:42] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.en.json
[2019-08-05 12:45:42] [config] word-penalty: 0
[2019-08-05 12:45:42] [config] workspace: 3000
[2019-08-05 12:45:42] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-05 12:45:42] Using synchronous training
[2019-08-05 12:45:42] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.de.json
[2019-08-05 12:45:42] [data] Using unused word id eos for 0
[2019-08-05 12:45:42] [data] Using unused word id UNK for 1
[2019-08-05 12:45:42] [data] Setting vocabulary size for input 0 to 50000
[2019-08-05 12:45:42] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.en.json
[2019-08-05 12:45:42] [data] Using unused word id eos for 0
[2019-08-05 12:45:42] [data] Using unused word id UNK for 1
[2019-08-05 12:45:42] [data] Setting vocabulary size for input 1 to 50000
[2019-08-05 12:45:42] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-05 12:45:42] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-05 12:45:43] [memory] Extending reserved space to 3072 MB (device gpu1)
[2019-08-05 12:45:43] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-05 12:45:43] [comm] NCCLCommunicator constructed successfully.
[2019-08-05 12:45:43] [training] Using 1 GPUs
[2019-08-05 12:45:43] [memory] Reserving 422 MB, device gpu1
[2019-08-05 12:45:43] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-05 12:45:43] [memory] Reserving 422 MB, device gpu1
[2019-08-05 12:45:48] [batching] Done. Typical MB size is 4042 target words
[2019-08-05 12:45:49] [memory] Extending reserved space to 3072 MB (device gpu1)
[2019-08-05 12:45:49] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-05 12:45:49] [comm] NCCLCommunicator constructed successfully.
[2019-08-05 12:45:49] [training] Using 1 GPUs
[2019-08-05 12:45:49] Training started
[2019-08-05 12:45:49] [data] Shuffling data
[2019-08-05 12:45:51] [data] Done reading 4189884 sentences
[2019-08-05 12:46:04] [data] Done shuffling 4189884 sentences to temp files
[2019-08-05 12:46:22] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-05 12:46:22] [memory] Reserving 422 MB, device gpu1
[2019-08-05 12:46:22] [memory] Reserving 422 MB, device gpu1
[2019-08-05 12:46:22] [memory] Reserving 422 MB, device gpu1
[2019-08-05 12:46:22] [memory] Reserving 844 MB, device gpu1
[2019-08-05 13:07:47] Ep. 1 : Up. 2000 : Sen. 193,048 : Cost 156.68226624 : Time 1324.66s : 3748.75 words/s
[2019-08-05 13:29:48] Ep. 1 : Up. 4000 : Sen. 387,112 : Cost 130.77404785 : Time 1320.93s : 3780.51 words/s
[2019-08-05 13:51:48] Ep. 1 : Up. 6000 : Sen. 581,025 : Cost 116.98160553 : Time 1320.04s : 3790.09 words/s
[2019-08-05 14:13:56] Ep. 1 : Up. 8000 : Sen. 775,530 : Cost 106.68051910 : Time 1328.34s : 3769.78 words/s
[2019-08-05 14:16:33] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-05 14:16:33] [marian] Running on lofn as process 13178 with command line:
[2019-08-05 14:16:33] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz -T . --devices 0 --train-sets ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.de ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.en --vocabs ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.de.json ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/dev.bpe.de ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/dev.out --valid-script-path ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/train.log --valid-log ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/valid.log
[2019-08-05 14:16:33] [config] after-batches: 0
[2019-08-05 14:16:33] [config] after-epochs: 0
[2019-08-05 14:16:33] [config] allow-unk: false
[2019-08-05 14:16:33] [config] beam-size: 12
[2019-08-05 14:16:33] [config] bert-class-symbol: "[CLS]"
[2019-08-05 14:16:33] [config] bert-mask-symbol: "[MASK]"
[2019-08-05 14:16:33] [config] bert-masking-fraction: 0.15
[2019-08-05 14:16:33] [config] bert-sep-symbol: "[SEP]"
[2019-08-05 14:16:33] [config] bert-train-type-embeddings: true
[2019-08-05 14:16:33] [config] bert-type-vocab-size: 2
[2019-08-05 14:16:33] [config] best-deep: false
[2019-08-05 14:16:33] [config] clip-gemm: 0
[2019-08-05 14:16:33] [config] clip-norm: 1
[2019-08-05 14:16:33] [config] cost-type: ce-mean
[2019-08-05 14:16:33] [config] cpu-threads: 0
[2019-08-05 14:16:33] [config] data-weighting: ""
[2019-08-05 14:16:33] [config] data-weighting-type: sentence
[2019-08-05 14:16:33] [config] dec-cell: gru
[2019-08-05 14:16:33] [config] dec-cell-base-depth: 2
[2019-08-05 14:16:33] [config] dec-cell-high-depth: 1
[2019-08-05 14:16:33] [config] dec-depth: 1
[2019-08-05 14:16:33] [config] devices:
[2019-08-05 14:16:33] [config]   - 0
[2019-08-05 14:16:33] [config] dim-emb: 512
[2019-08-05 14:16:33] [config] dim-rnn: 1024
[2019-08-05 14:16:33] [config] dim-vocabs:
[2019-08-05 14:16:33] [config]   - 50000
[2019-08-05 14:16:33] [config]   - 50000
[2019-08-05 14:16:33] [config] disp-first: 0
[2019-08-05 14:16:33] [config] disp-freq: 2000
[2019-08-05 14:16:33] [config] disp-label-counts: false
[2019-08-05 14:16:33] [config] dropout-rnn: 0.2
[2019-08-05 14:16:33] [config] dropout-src: 0.1
[2019-08-05 14:16:33] [config] dropout-trg: 0.1
[2019-08-05 14:16:33] [config] dump-config: ""
[2019-08-05 14:16:33] [config] early-stopping: 5
[2019-08-05 14:16:33] [config] embedding-fix-src: false
[2019-08-05 14:16:33] [config] embedding-fix-trg: false
[2019-08-05 14:16:33] [config] embedding-normalization: false
[2019-08-05 14:16:33] [config] embedding-vectors:
[2019-08-05 14:16:33] [config]   []
[2019-08-05 14:16:33] [config] enc-cell: gru
[2019-08-05 14:16:33] [config] enc-cell-depth: 1
[2019-08-05 14:16:33] [config] enc-depth: 1
[2019-08-05 14:16:33] [config] enc-type: bidirectional
[2019-08-05 14:16:33] [config] exponential-smoothing: 0.0001
[2019-08-05 14:16:33] [config] grad-dropping-momentum: 0
[2019-08-05 14:16:33] [config] grad-dropping-rate: 0
[2019-08-05 14:16:33] [config] grad-dropping-warmup: 100
[2019-08-05 14:16:33] [config] guided-alignment: none
[2019-08-05 14:16:33] [config] guided-alignment-cost: mse
[2019-08-05 14:16:33] [config] guided-alignment-weight: 0.1
[2019-08-05 14:16:33] [config] ignore-model-config: false
[2019-08-05 14:16:33] [config] input-types:
[2019-08-05 14:16:33] [config]   []
[2019-08-05 14:16:33] [config] interpolate-env-vars: false
[2019-08-05 14:16:33] [config] keep-best: false
[2019-08-05 14:16:33] [config] label-smoothing: 0
[2019-08-05 14:16:33] [config] layer-normalization: true
[2019-08-05 14:16:33] [config] learn-rate: 0.0001
[2019-08-05 14:16:33] [config] log: ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/train.log
[2019-08-05 14:16:33] [config] log-level: info
[2019-08-05 14:16:33] [config] log-time-zone: ""
[2019-08-05 14:16:33] [config] lr-decay: 0
[2019-08-05 14:16:33] [config] lr-decay-freq: 50000
[2019-08-05 14:16:33] [config] lr-decay-inv-sqrt:
[2019-08-05 14:16:33] [config]   - 0
[2019-08-05 14:16:33] [config] lr-decay-repeat-warmup: false
[2019-08-05 14:16:33] [config] lr-decay-reset-optimizer: false
[2019-08-05 14:16:33] [config] lr-decay-start:
[2019-08-05 14:16:33] [config]   - 10
[2019-08-05 14:16:33] [config]   - 1
[2019-08-05 14:16:33] [config] lr-decay-strategy: epoch+stalled
[2019-08-05 14:16:33] [config] lr-report: false
[2019-08-05 14:16:33] [config] lr-warmup: 0
[2019-08-05 14:16:33] [config] lr-warmup-at-reload: false
[2019-08-05 14:16:33] [config] lr-warmup-cycle: false
[2019-08-05 14:16:33] [config] lr-warmup-start-rate: 0
[2019-08-05 14:16:33] [config] max-length: 50
[2019-08-05 14:16:33] [config] max-length-crop: false
[2019-08-05 14:16:33] [config] max-length-factor: 3
[2019-08-05 14:16:33] [config] maxi-batch: 100
[2019-08-05 14:16:33] [config] maxi-batch-sort: trg
[2019-08-05 14:16:33] [config] mini-batch: 64
[2019-08-05 14:16:33] [config] mini-batch-fit: true
[2019-08-05 14:16:33] [config] mini-batch-fit-step: 10
[2019-08-05 14:16:33] [config] mini-batch-overstuff: 1
[2019-08-05 14:16:33] [config] mini-batch-track-lr: false
[2019-08-05 14:16:33] [config] mini-batch-understuff: 1
[2019-08-05 14:16:33] [config] mini-batch-warmup: 0
[2019-08-05 14:16:33] [config] mini-batch-words: 0
[2019-08-05 14:16:33] [config] mini-batch-words-ref: 0
[2019-08-05 14:16:33] [config] model: ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-05 14:16:33] [config] multi-loss-type: sum
[2019-08-05 14:16:33] [config] multi-node: false
[2019-08-05 14:16:33] [config] multi-node-overlap: true
[2019-08-05 14:16:33] [config] n-best: false
[2019-08-05 14:16:33] [config] no-nccl: false
[2019-08-05 14:16:33] [config] no-reload: false
[2019-08-05 14:16:33] [config] no-restore-corpus: false
[2019-08-05 14:16:33] [config] no-shuffle: false
[2019-08-05 14:16:33] [config] normalize: 1
[2019-08-05 14:16:33] [config] num-devices: 0
[2019-08-05 14:16:33] [config] optimizer: adam
[2019-08-05 14:16:33] [config] optimizer-delay: 1
[2019-08-05 14:16:33] [config] optimizer-params:
[2019-08-05 14:16:33] [config]   []
[2019-08-05 14:16:33] [config] overwrite: false
[2019-08-05 14:16:33] [config] pretrained-model: ""
[2019-08-05 14:16:33] [config] quiet: false
[2019-08-05 14:16:33] [config] quiet-translation: true
[2019-08-05 14:16:33] [config] relative-paths: false
[2019-08-05 14:16:33] [config] right-left: false
[2019-08-05 14:16:33] [config] save-freq: 20000
[2019-08-05 14:16:33] [config] seed: 1111
[2019-08-05 14:16:33] [config] shuffle-in-ram: false
[2019-08-05 14:16:33] [config] skip: false
[2019-08-05 14:16:33] [config] sqlite: ""
[2019-08-05 14:16:33] [config] sqlite-drop: false
[2019-08-05 14:16:33] [config] sync-sgd: true
[2019-08-05 14:16:33] [config] tempdir: .
[2019-08-05 14:16:33] [config] tied-embeddings: false
[2019-08-05 14:16:33] [config] tied-embeddings-all: false
[2019-08-05 14:16:33] [config] tied-embeddings-src: false
[2019-08-05 14:16:33] [config] train-sets:
[2019-08-05 14:16:33] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.de
[2019-08-05 14:16:33] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.en
[2019-08-05 14:16:33] [config] transformer-aan-activation: swish
[2019-08-05 14:16:33] [config] transformer-aan-depth: 2
[2019-08-05 14:16:33] [config] transformer-aan-nogate: false
[2019-08-05 14:16:33] [config] transformer-decoder-autoreg: self-attention
[2019-08-05 14:16:33] [config] transformer-dim-aan: 2048
[2019-08-05 14:16:33] [config] transformer-dim-ffn: 2048
[2019-08-05 14:16:33] [config] transformer-dropout: 0
[2019-08-05 14:16:33] [config] transformer-dropout-attention: 0
[2019-08-05 14:16:33] [config] transformer-dropout-ffn: 0
[2019-08-05 14:16:33] [config] transformer-ffn-activation: swish
[2019-08-05 14:16:33] [config] transformer-ffn-depth: 2
[2019-08-05 14:16:33] [config] transformer-guided-alignment-layer: last
[2019-08-05 14:16:33] [config] transformer-heads: 8
[2019-08-05 14:16:33] [config] transformer-no-projection: false
[2019-08-05 14:16:33] [config] transformer-postprocess: dan
[2019-08-05 14:16:33] [config] transformer-postprocess-emb: d
[2019-08-05 14:16:33] [config] transformer-preprocess: ""
[2019-08-05 14:16:33] [config] transformer-tied-layers:
[2019-08-05 14:16:33] [config]   []
[2019-08-05 14:16:33] [config] transformer-train-position-embeddings: false
[2019-08-05 14:16:33] [config] type: amun
[2019-08-05 14:16:33] [config] ulr: false
[2019-08-05 14:16:33] [config] ulr-dim-emb: 0
[2019-08-05 14:16:33] [config] ulr-dropout: 0
[2019-08-05 14:16:33] [config] ulr-keys-vectors: ""
[2019-08-05 14:16:33] [config] ulr-query-vectors: ""
[2019-08-05 14:16:33] [config] ulr-softmax-temperature: 1
[2019-08-05 14:16:33] [config] ulr-trainable-transformation: false
[2019-08-05 14:16:33] [config] valid-freq: 20000
[2019-08-05 14:16:33] [config] valid-log: ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/valid.log
[2019-08-05 14:16:33] [config] valid-max-length: 1000
[2019-08-05 14:16:33] [config] valid-metrics:
[2019-08-05 14:16:33] [config]   - cross-entropy
[2019-08-05 14:16:33] [config]   - perplexity
[2019-08-05 14:16:33] [config]   - translation
[2019-08-05 14:16:33] [config] valid-mini-batch: 8
[2019-08-05 14:16:33] [config] valid-script-path: ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/score-dev.sh
[2019-08-05 14:16:33] [config] valid-sets:
[2019-08-05 14:16:33] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/dev.bpe.de
[2019-08-05 14:16:33] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/dev.bpe.en
[2019-08-05 14:16:33] [config] valid-translation-output: ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/dev.out
[2019-08-05 14:16:33] [config] vocabs:
[2019-08-05 14:16:33] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.de.json
[2019-08-05 14:16:33] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.en.json
[2019-08-05 14:16:33] [config] word-penalty: 0
[2019-08-05 14:16:33] [config] workspace: 3000
[2019-08-05 14:16:33] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-05 14:16:33] Using synchronous training
[2019-08-05 14:16:33] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.de.json
[2019-08-05 14:16:33] [data] Using unused word id eos for 0
[2019-08-05 14:16:33] [data] Using unused word id UNK for 1
[2019-08-05 14:16:33] [data] Setting vocabulary size for input 0 to 50000
[2019-08-05 14:16:33] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.en.json
[2019-08-05 14:16:34] [data] Using unused word id eos for 0
[2019-08-05 14:16:34] [data] Using unused word id UNK for 1
[2019-08-05 14:16:34] [data] Setting vocabulary size for input 1 to 50000
[2019-08-05 14:16:34] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-05 14:16:34] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-05 14:16:35] [memory] Extending reserved space to 3072 MB (device gpu0)
[2019-08-05 14:16:35] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-05 14:16:35] [comm] NCCLCommunicator constructed successfully.
[2019-08-05 14:16:35] [training] Using 1 GPUs
[2019-08-05 14:16:35] [memory] Reserving 422 MB, device gpu0
[2019-08-05 14:16:35] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-05 14:16:35] [memory] Reserving 422 MB, device gpu0
[2019-08-05 14:16:40] [batching] Done. Typical MB size is 4042 target words
[2019-08-05 14:16:40] [memory] Extending reserved space to 3072 MB (device gpu0)
[2019-08-05 14:16:40] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-05 14:16:40] [comm] NCCLCommunicator constructed successfully.
[2019-08-05 14:16:40] [training] Using 1 GPUs
[2019-08-05 14:16:40] Training started
[2019-08-05 14:16:40] [data] Shuffling data
[2019-08-05 14:16:42] [data] Done reading 4189884 sentences
[2019-08-05 14:16:56] [data] Done shuffling 4189884 sentences to temp files
[2019-08-05 14:17:06] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-05 14:17:06] [memory] Reserving 422 MB, device gpu0
[2019-08-05 14:17:06] [memory] Reserving 422 MB, device gpu0
[2019-08-05 14:17:06] [memory] Reserving 422 MB, device gpu0
[2019-08-05 14:17:06] [memory] Reserving 844 MB, device gpu0
[2019-08-05 14:26:59] Ep. 1 : Up. 2000 : Sen. 193,048 : Cost 156.68713379 : Time 625.39s : 7940.38 words/s
[2019-08-05 14:36:59] Ep. 1 : Up. 4000 : Sen. 387,112 : Cost 130.79113770 : Time 600.06s : 8322.13 words/s
[2019-08-05 14:47:01] Ep. 1 : Up. 6000 : Sen. 581,025 : Cost 117.01486969 : Time 601.63s : 8315.78 words/s
[2019-08-05 14:57:03] Ep. 1 : Up. 8000 : Sen. 775,530 : Cost 106.71642303 : Time 602.04s : 8317.58 words/s
[2019-08-05 15:07:02] Ep. 1 : Up. 10000 : Sen. 969,059 : Cost 99.32308960 : Time 599.11s : 8308.73 words/s
[2019-08-05 15:17:04] Ep. 1 : Up. 12000 : Sen. 1,164,013 : Cost 94.06176758 : Time 601.98s : 8319.77 words/s
[2019-08-05 15:27:06] Ep. 1 : Up. 14000 : Sen. 1,357,633 : Cost 90.60197449 : Time 601.91s : 8283.43 words/s
[2019-08-05 15:37:08] Ep. 1 : Up. 16000 : Sen. 1,550,860 : Cost 87.61631775 : Time 601.97s : 8281.04 words/s
[2019-08-05 15:47:08] Ep. 1 : Up. 18000 : Sen. 1,745,433 : Cost 84.80384064 : Time 600.01s : 8323.25 words/s
[2019-08-05 15:57:09] Ep. 1 : Up. 20000 : Sen. 1,939,044 : Cost 82.87567902 : Time 601.42s : 8292.83 words/s
[2019-08-05 15:57:09] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-05 15:57:18] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.iter20000.npz
[2019-08-05 15:57:25] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-05 15:57:34] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-05 15:57:59] [valid] Ep. 1 : Up. 20000 : cross-entropy : 71.6344 : new best
[2019-08-05 15:58:08] [valid] Ep. 1 : Up. 20000 : perplexity : 16.9823 : new best
[2019-08-05 15:59:16] [valid] Ep. 1 : Up. 20000 : translation : 22.27 : new best
[2019-08-05 16:09:21] Ep. 1 : Up. 22000 : Sen. 2,133,129 : Cost 81.36056519 : Time 731.97s : 6838.39 words/s
[2019-08-05 16:19:21] Ep. 1 : Up. 24000 : Sen. 2,326,940 : Cost 79.51955414 : Time 599.88s : 8293.84 words/s
[2019-08-05 16:29:23] Ep. 1 : Up. 26000 : Sen. 2,520,692 : Cost 78.30435944 : Time 601.60s : 8281.84 words/s
[2019-08-05 16:39:23] Ep. 1 : Up. 28000 : Sen. 2,714,525 : Cost 77.08428192 : Time 600.16s : 8310.81 words/s
[2019-08-05 16:49:24] Ep. 1 : Up. 30000 : Sen. 2,908,652 : Cost 76.10482788 : Time 600.74s : 8311.95 words/s
[2019-08-05 16:59:25] Ep. 1 : Up. 32000 : Sen. 3,102,189 : Cost 75.13556671 : Time 601.45s : 8278.14 words/s
[2019-08-05 17:09:25] Ep. 1 : Up. 34000 : Sen. 3,295,865 : Cost 74.48369598 : Time 600.21s : 8305.86 words/s
[2019-08-05 17:10:33] Seen 3317282 samples
[2019-08-05 17:10:33] Starting epoch 2
[2019-08-05 17:10:33] [data] Shuffling data
[2019-08-05 17:10:35] [data] Done reading 4189884 sentences
[2019-08-05 17:10:47] [data] Done shuffling 4189884 sentences to temp files
[2019-08-05 17:19:54] Ep. 2 : Up. 36000 : Sen. 172,464 : Cost 72.73868561 : Time 628.91s : 7939.14 words/s
[2019-08-05 17:29:57] Ep. 2 : Up. 38000 : Sen. 367,117 : Cost 71.76355743 : Time 603.01s : 8315.50 words/s
[2019-08-05 17:39:59] Ep. 2 : Up. 40000 : Sen. 561,876 : Cost 71.27012634 : Time 602.28s : 8312.36 words/s
[2019-08-05 17:39:59] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-05 17:40:08] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.iter40000.npz
[2019-08-05 17:40:15] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-05 17:40:24] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-05 17:40:50] [valid] Ep. 2 : Up. 40000 : cross-entropy : 59.4114 : new best
[2019-08-05 17:40:59] [valid] Ep. 2 : Up. 40000 : perplexity : 10.4742 : new best
[2019-08-05 17:42:03] [valid] Ep. 2 : Up. 40000 : translation : 26.42 : new best
[2019-08-05 17:52:06] Ep. 2 : Up. 42000 : Sen. 755,638 : Cost 70.92193604 : Time 726.53s : 6862.97 words/s
[2019-08-05 18:02:07] Ep. 2 : Up. 44000 : Sen. 949,760 : Cost 70.55922699 : Time 600.74s : 8322.90 words/s
[2019-08-05 18:12:08] Ep. 2 : Up. 46000 : Sen. 1,143,610 : Cost 70.13943481 : Time 601.50s : 8307.00 words/s
[2019-08-05 18:22:11] Ep. 2 : Up. 48000 : Sen. 1,337,910 : Cost 69.18447113 : Time 602.76s : 8273.56 words/s
[2019-08-05 18:32:13] Ep. 2 : Up. 50000 : Sen. 1,531,905 : Cost 69.30416107 : Time 602.20s : 8293.35 words/s
[2019-08-05 18:42:14] Ep. 2 : Up. 52000 : Sen. 1,725,622 : Cost 68.78379822 : Time 600.96s : 8312.44 words/s
[2019-08-05 18:52:16] Ep. 2 : Up. 54000 : Sen. 1,920,078 : Cost 68.18255615 : Time 601.53s : 8302.69 words/s
[2019-08-05 19:02:16] Ep. 2 : Up. 56000 : Sen. 2,114,185 : Cost 67.96012115 : Time 600.14s : 8311.40 words/s
[2019-08-05 19:12:19] Ep. 2 : Up. 58000 : Sen. 2,308,260 : Cost 67.77655792 : Time 602.85s : 8289.22 words/s
[2019-08-05 19:22:23] Ep. 2 : Up. 60000 : Sen. 2,502,478 : Cost 67.33141327 : Time 604.27s : 8288.24 words/s
[2019-08-05 19:22:23] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-05 19:22:32] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.iter60000.npz
[2019-08-05 19:22:38] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-05 19:22:47] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-05 19:23:13] [valid] Ep. 2 : Up. 60000 : cross-entropy : 54.751 : new best
[2019-08-05 19:23:22] [valid] Ep. 2 : Up. 60000 : perplexity : 8.71164 : new best
[2019-08-05 19:24:26] [valid] Ep. 2 : Up. 60000 : translation : 28.21 : new best
[2019-08-05 19:34:28] Ep. 2 : Up. 62000 : Sen. 2,696,461 : Cost 67.09015656 : Time 724.55s : 6873.76 words/s
[2019-08-05 19:44:27] Ep. 2 : Up. 64000 : Sen. 2,890,444 : Cost 66.69763184 : Time 599.86s : 8313.83 words/s
[2019-08-05 19:54:30] Ep. 2 : Up. 66000 : Sen. 3,084,398 : Cost 66.72587585 : Time 602.27s : 8298.54 words/s
[2019-08-05 20:04:31] Ep. 2 : Up. 68000 : Sen. 3,278,372 : Cost 66.14100647 : Time 601.56s : 8295.66 words/s
[2019-08-05 20:06:33] Seen 3317282 samples
[2019-08-05 20:06:33] Starting epoch 3
[2019-08-05 20:06:33] [data] Shuffling data
[2019-08-05 20:06:35] [data] Done reading 4189884 sentences
[2019-08-05 20:06:47] [data] Done shuffling 4189884 sentences to temp files
[2019-08-05 20:14:59] Ep. 3 : Up. 70000 : Sen. 154,937 : Cost 64.94215393 : Time 628.05s : 7944.21 words/s
[2019-08-05 20:25:04] Ep. 3 : Up. 72000 : Sen. 349,003 : Cost 64.52039337 : Time 604.30s : 8283.42 words/s
[2019-08-05 20:35:06] Ep. 3 : Up. 74000 : Sen. 543,652 : Cost 64.32749939 : Time 602.63s : 8307.21 words/s
[2019-08-05 20:45:09] Ep. 3 : Up. 76000 : Sen. 738,078 : Cost 64.44042206 : Time 603.01s : 8297.39 words/s
[2019-08-05 20:55:09] Ep. 3 : Up. 78000 : Sen. 932,365 : Cost 63.84826660 : Time 600.10s : 8300.60 words/s
[2019-08-05 21:05:11] Ep. 3 : Up. 80000 : Sen. 1,126,771 : Cost 63.99232483 : Time 602.00s : 8306.04 words/s
[2019-08-05 21:05:11] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-05 21:05:21] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.iter80000.npz
[2019-08-05 21:05:27] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-05 21:05:36] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-05 21:06:02] [valid] Ep. 3 : Up. 80000 : cross-entropy : 52.3126 : new best
[2019-08-05 21:06:11] [valid] Ep. 3 : Up. 80000 : perplexity : 7.91102 : new best
[2019-08-05 21:07:15] [valid] Ep. 3 : Up. 80000 : translation : 29.15 : new best
[2019-08-05 21:17:20] Ep. 3 : Up. 82000 : Sen. 1,320,929 : Cost 63.74501801 : Time 728.49s : 6862.91 words/s
[2019-08-05 21:27:21] Ep. 3 : Up. 84000 : Sen. 1,514,628 : Cost 63.58063889 : Time 601.36s : 8290.52 words/s
[2019-08-05 21:37:22] Ep. 3 : Up. 86000 : Sen. 1,708,317 : Cost 63.54512787 : Time 601.24s : 8288.86 words/s
[2019-08-05 21:47:24] Ep. 3 : Up. 88000 : Sen. 1,902,287 : Cost 63.44055939 : Time 601.09s : 8293.98 words/s
[2019-08-05 21:57:25] Ep. 3 : Up. 90000 : Sen. 2,096,755 : Cost 63.37178802 : Time 601.75s : 8314.68 words/s
[2019-08-05 22:07:29] Ep. 3 : Up. 92000 : Sen. 2,290,996 : Cost 63.45103836 : Time 604.09s : 8297.67 words/s
[2019-08-05 22:17:30] Ep. 3 : Up. 94000 : Sen. 2,484,414 : Cost 63.03966904 : Time 600.16s : 8278.12 words/s
[2019-08-05 22:27:31] Ep. 3 : Up. 96000 : Sen. 2,678,006 : Cost 63.06588745 : Time 601.89s : 8306.06 words/s
[2019-08-05 22:37:33] Ep. 3 : Up. 98000 : Sen. 2,871,659 : Cost 62.50547791 : Time 601.77s : 8275.07 words/s
[2019-08-05 22:47:32] Ep. 3 : Up. 100000 : Sen. 3,065,522 : Cost 62.63193512 : Time 599.09s : 8317.80 words/s
[2019-08-05 22:47:32] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-05 22:47:41] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.iter100000.npz
[2019-08-05 22:47:48] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-05 22:47:57] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-05 22:48:23] [valid] Ep. 3 : Up. 100000 : cross-entropy : 50.6441 : new best
[2019-08-05 22:48:31] [valid] Ep. 3 : Up. 100000 : perplexity : 7.40598 : new best
[2019-08-05 22:49:35] [valid] Ep. 3 : Up. 100000 : translation : 29.83 : new best
[2019-08-05 22:59:40] Ep. 3 : Up. 102000 : Sen. 3,259,397 : Cost 62.67171097 : Time 728.20s : 6863.97 words/s
[2019-08-05 23:02:41] Seen 3317282 samples
[2019-08-05 23:02:41] Starting epoch 4
[2019-08-05 23:02:41] [data] Shuffling data
[2019-08-05 23:02:43] [data] Done reading 4189884 sentences
[2019-08-05 23:02:55] [data] Done shuffling 4189884 sentences to temp files
[2019-08-05 23:10:09] Ep. 4 : Up. 104000 : Sen. 136,025 : Cost 61.22018814 : Time 628.24s : 7933.33 words/s
[2019-08-05 23:20:08] Ep. 4 : Up. 106000 : Sen. 329,535 : Cost 60.80596161 : Time 599.10s : 8304.44 words/s
[2019-08-05 23:30:09] Ep. 4 : Up. 108000 : Sen. 523,320 : Cost 60.95713806 : Time 600.79s : 8299.80 words/s
[2019-08-05 23:40:10] Ep. 4 : Up. 110000 : Sen. 717,231 : Cost 60.91187668 : Time 601.05s : 8295.64 words/s
[2019-08-05 23:50:10] Ep. 4 : Up. 112000 : Sen. 911,537 : Cost 60.57386780 : Time 600.22s : 8303.73 words/s
[2019-08-06 00:00:16] Ep. 4 : Up. 114000 : Sen. 1,106,110 : Cost 61.09011078 : Time 605.80s : 8280.90 words/s
[2019-08-06 00:10:19] Ep. 4 : Up. 116000 : Sen. 1,300,182 : Cost 60.84465027 : Time 603.22s : 8276.56 words/s
[2019-08-06 00:20:20] Ep. 4 : Up. 118000 : Sen. 1,493,255 : Cost 60.94650650 : Time 600.79s : 8272.59 words/s
[2019-08-06 00:30:22] Ep. 4 : Up. 120000 : Sen. 1,687,755 : Cost 60.74993134 : Time 602.57s : 8319.08 words/s
[2019-08-06 00:30:22] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-06 00:30:32] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.iter120000.npz
[2019-08-06 00:30:38] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-06 00:30:48] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 00:31:13] [valid] Ep. 4 : Up. 120000 : cross-entropy : 49.4528 : new best
[2019-08-06 00:31:22] [valid] Ep. 4 : Up. 120000 : perplexity : 7.06526 : new best
[2019-08-06 00:32:26] [valid] Ep. 4 : Up. 120000 : translation : 30.22 : new best
[2019-08-06 00:42:28] Ep. 4 : Up. 122000 : Sen. 1,881,366 : Cost 60.76220703 : Time 725.52s : 6871.89 words/s
[2019-08-06 00:52:30] Ep. 4 : Up. 124000 : Sen. 2,075,663 : Cost 60.66267776 : Time 602.29s : 8304.28 words/s
[2019-08-06 01:02:32] Ep. 4 : Up. 126000 : Sen. 2,270,194 : Cost 60.71585083 : Time 602.31s : 8298.43 words/s
[2019-08-06 01:12:34] Ep. 4 : Up. 128000 : Sen. 2,463,843 : Cost 60.55855179 : Time 602.09s : 8262.33 words/s
[2019-08-06 01:22:35] Ep. 4 : Up. 130000 : Sen. 2,657,530 : Cost 60.27520752 : Time 600.52s : 8293.87 words/s
[2019-08-06 01:32:37] Ep. 4 : Up. 132000 : Sen. 2,851,175 : Cost 60.64332199 : Time 602.26s : 8297.27 words/s
[2019-08-06 01:42:42] Ep. 4 : Up. 134000 : Sen. 3,045,633 : Cost 60.19079590 : Time 605.20s : 8275.30 words/s
[2019-08-06 01:52:45] Ep. 4 : Up. 136000 : Sen. 3,238,931 : Cost 60.39755630 : Time 602.65s : 8267.30 words/s
[2019-08-06 01:56:49] Seen 3317282 samples
[2019-08-06 01:56:49] Starting epoch 5
[2019-08-06 01:56:49] [data] Shuffling data
[2019-08-06 01:56:51] [data] Done reading 4189884 sentences
[2019-08-06 01:57:04] [data] Done shuffling 4189884 sentences to temp files
[2019-08-06 02:03:21] Ep. 5 : Up. 138000 : Sen. 115,356 : Cost 59.22653961 : Time 635.45s : 7852.82 words/s
[2019-08-06 02:13:22] Ep. 5 : Up. 140000 : Sen. 309,593 : Cost 58.77921295 : Time 601.90s : 8288.41 words/s
[2019-08-06 02:13:22] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-06 02:13:32] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.iter140000.npz
[2019-08-06 02:13:39] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-06 02:13:48] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 02:14:14] [valid] Ep. 5 : Up. 140000 : cross-entropy : 48.5709 : new best
[2019-08-06 02:14:23] [valid] Ep. 5 : Up. 140000 : perplexity : 6.82316 : new best
[2019-08-06 02:15:28] [valid] Ep. 5 : Up. 140000 : translation : 30.59 : new best
[2019-08-06 02:25:33] Ep. 5 : Up. 142000 : Sen. 503,660 : Cost 58.88349915 : Time 730.28s : 6852.21 words/s
[2019-08-06 02:35:36] Ep. 5 : Up. 144000 : Sen. 698,456 : Cost 58.52403641 : Time 603.27s : 8294.98 words/s
[2019-08-06 02:45:37] Ep. 5 : Up. 146000 : Sen. 892,222 : Cost 58.76033020 : Time 601.48s : 8292.36 words/s
[2019-08-06 02:55:40] Ep. 5 : Up. 148000 : Sen. 1,085,570 : Cost 59.06973267 : Time 602.26s : 8290.49 words/s
[2019-08-06 03:05:40] Ep. 5 : Up. 150000 : Sen. 1,279,425 : Cost 58.69931030 : Time 600.49s : 8296.70 words/s
[2019-08-06 03:15:41] Ep. 5 : Up. 152000 : Sen. 1,473,084 : Cost 58.91344070 : Time 600.66s : 8300.49 words/s
[2019-08-06 03:25:43] Ep. 5 : Up. 154000 : Sen. 1,666,610 : Cost 58.64528656 : Time 601.71s : 8267.77 words/s
[2019-08-06 03:35:44] Ep. 5 : Up. 156000 : Sen. 1,861,025 : Cost 58.83289337 : Time 601.84s : 8326.45 words/s
[2019-08-06 03:45:49] Ep. 5 : Up. 158000 : Sen. 2,055,443 : Cost 58.75625229 : Time 604.78s : 8266.21 words/s
[2019-08-06 03:55:54] Ep. 5 : Up. 160000 : Sen. 2,249,424 : Cost 58.64442444 : Time 605.10s : 8248.75 words/s
[2019-08-06 03:55:54] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-06 03:56:03] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.iter160000.npz
[2019-08-06 03:56:10] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-06 03:56:19] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 03:56:45] [valid] Ep. 5 : Up. 160000 : cross-entropy : 47.9955 : new best
[2019-08-06 03:56:54] [valid] Ep. 5 : Up. 160000 : perplexity : 6.66968 : new best
[2019-08-06 03:57:59] [valid] Ep. 5 : Up. 160000 : translation : 30.72 : new best
[2019-08-06 04:08:04] Ep. 5 : Up. 162000 : Sen. 2,444,133 : Cost 58.86385727 : Time 729.58s : 6859.88 words/s
[2019-08-06 04:18:09] Ep. 5 : Up. 164000 : Sen. 2,638,516 : Cost 58.65065765 : Time 604.62s : 8278.37 words/s
[2019-08-06 04:28:12] Ep. 5 : Up. 166000 : Sen. 2,832,965 : Cost 58.53621292 : Time 603.10s : 8282.04 words/s
[2019-08-06 04:38:14] Ep. 5 : Up. 168000 : Sen. 3,026,753 : Cost 58.63480377 : Time 602.18s : 8289.54 words/s
[2019-08-06 04:48:17] Ep. 5 : Up. 170000 : Sen. 3,220,745 : Cost 58.67876434 : Time 602.81s : 8280.20 words/s
[2019-08-06 04:53:18] Seen 3317282 samples
[2019-08-06 04:53:18] Starting epoch 6
[2019-08-06 04:53:18] [data] Shuffling data
[2019-08-06 04:53:21] [data] Done reading 4189884 sentences
[2019-08-06 04:53:32] [data] Done shuffling 4189884 sentences to temp files
[2019-08-06 04:58:46] Ep. 6 : Up. 172000 : Sen. 97,164 : Cost 57.79426193 : Time 629.39s : 7925.78 words/s
[2019-08-06 05:08:50] Ep. 6 : Up. 174000 : Sen. 291,411 : Cost 57.31743240 : Time 604.06s : 8274.88 words/s
[2019-08-06 05:18:52] Ep. 6 : Up. 176000 : Sen. 485,432 : Cost 57.16427231 : Time 601.83s : 8280.61 words/s
[2019-08-06 05:28:54] Ep. 6 : Up. 178000 : Sen. 679,765 : Cost 57.20601654 : Time 601.82s : 8299.40 words/s
[2019-08-06 05:38:58] Ep. 6 : Up. 180000 : Sen. 873,968 : Cost 57.37330627 : Time 603.95s : 8289.01 words/s
[2019-08-06 05:38:58] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-06 05:39:11] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.iter180000.npz
[2019-08-06 05:39:20] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-06 05:39:29] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 05:39:56] [valid] Ep. 6 : Up. 180000 : cross-entropy : 47.4982 : new best
[2019-08-06 05:40:05] [valid] Ep. 6 : Up. 180000 : perplexity : 6.53983 : new best
[2019-08-06 05:41:10] [valid] Ep. 6 : Up. 180000 : translation : 30.86 : new best
[2019-08-06 05:51:16] Ep. 6 : Up. 182000 : Sen. 1,068,148 : Cost 57.35049438 : Time 738.80s : 6754.47 words/s
[2019-08-06 06:01:18] Ep. 6 : Up. 184000 : Sen. 1,261,935 : Cost 57.39749908 : Time 601.62s : 8287.66 words/s
[2019-08-06 06:11:21] Ep. 6 : Up. 186000 : Sen. 1,455,838 : Cost 57.30943680 : Time 602.89s : 8276.11 words/s
[2019-08-06 06:21:28] Ep. 6 : Up. 188000 : Sen. 1,650,363 : Cost 57.42838669 : Time 607.44s : 8251.96 words/s
[2019-08-06 06:31:33] Ep. 6 : Up. 190000 : Sen. 1,844,186 : Cost 57.48289490 : Time 604.35s : 8259.01 words/s
[2019-08-06 06:41:35] Ep. 6 : Up. 192000 : Sen. 2,038,377 : Cost 57.14635468 : Time 602.64s : 8279.86 words/s
[2019-08-06 06:51:38] Ep. 6 : Up. 194000 : Sen. 2,232,498 : Cost 57.33303833 : Time 602.86s : 8289.14 words/s
[2019-08-06 07:01:40] Ep. 6 : Up. 196000 : Sen. 2,425,756 : Cost 57.39928818 : Time 601.23s : 8282.17 words/s
[2019-08-06 07:11:43] Ep. 6 : Up. 198000 : Sen. 2,620,244 : Cost 57.30419540 : Time 603.17s : 8288.28 words/s
[2019-08-06 07:21:48] Ep. 6 : Up. 200000 : Sen. 2,814,254 : Cost 57.41118622 : Time 605.47s : 8265.45 words/s
[2019-08-06 07:21:48] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-06 07:21:57] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.iter200000.npz
[2019-08-06 07:22:04] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-06 07:22:13] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 07:22:38] [valid] Ep. 6 : Up. 200000 : cross-entropy : 47.0987 : new best
[2019-08-06 07:22:47] [valid] Ep. 6 : Up. 200000 : perplexity : 6.43735 : new best
[2019-08-06 07:23:52] [valid] Ep. 6 : Up. 200000 : translation : 31.29 : new best
[2019-08-06 07:33:58] Ep. 6 : Up. 202000 : Sen. 3,008,814 : Cost 57.32012177 : Time 730.11s : 6847.88 words/s
[2019-08-06 07:44:03] Ep. 6 : Up. 204000 : Sen. 3,203,371 : Cost 57.44698334 : Time 604.65s : 8279.91 words/s
[2019-08-06 07:49:58] Seen 3317282 samples
[2019-08-06 07:49:58] Starting epoch 7
[2019-08-06 07:49:58] [data] Shuffling data
[2019-08-06 07:50:00] [data] Done reading 4189884 sentences
[2019-08-06 07:50:12] [data] Done shuffling 4189884 sentences to temp files
[2019-08-06 07:54:35] Ep. 7 : Up. 206000 : Sen. 79,581 : Cost 56.72799301 : Time 632.02s : 7888.73 words/s
[2019-08-06 08:04:35] Ep. 7 : Up. 208000 : Sen. 273,142 : Cost 55.78934479 : Time 600.03s : 8289.72 words/s
[2019-08-06 08:14:37] Ep. 7 : Up. 210000 : Sen. 467,487 : Cost 55.92113113 : Time 602.06s : 8310.91 words/s
[2019-08-06 08:24:42] Ep. 7 : Up. 212000 : Sen. 661,604 : Cost 56.05443954 : Time 604.96s : 8263.51 words/s
[2019-08-06 08:34:51] Ep. 7 : Up. 214000 : Sen. 856,333 : Cost 56.11393356 : Time 609.25s : 8216.80 words/s
[2019-08-06 08:44:53] Ep. 7 : Up. 216000 : Sen. 1,049,960 : Cost 55.98563385 : Time 601.43s : 8277.51 words/s
[2019-08-06 08:54:59] Ep. 7 : Up. 218000 : Sen. 1,244,340 : Cost 56.32527161 : Time 605.94s : 8279.36 words/s
[2019-08-06 09:04:59] Ep. 7 : Up. 220000 : Sen. 1,438,033 : Cost 56.18068314 : Time 600.03s : 8286.30 words/s
[2019-08-06 09:04:59] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-06 09:05:09] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.iter220000.npz
[2019-08-06 09:05:18] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-06 09:05:27] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 09:05:53] [valid] Ep. 7 : Up. 220000 : cross-entropy : 46.8732 : new best
[2019-08-06 09:06:01] [valid] Ep. 7 : Up. 220000 : perplexity : 6.38021 : new best
[2019-08-06 09:07:07] [valid] Ep. 7 : Up. 220000 : translation : 31.33 : new best
[2019-08-06 09:17:09] Ep. 7 : Up. 222000 : Sen. 1,631,301 : Cost 56.15900040 : Time 730.43s : 6809.32 words/s
[2019-08-06 09:27:12] Ep. 7 : Up. 224000 : Sen. 1,824,986 : Cost 56.57138062 : Time 603.14s : 8290.92 words/s
[2019-08-06 09:37:13] Ep. 7 : Up. 226000 : Sen. 2,018,163 : Cost 56.31086349 : Time 601.12s : 8266.23 words/s
[2019-08-06 09:47:19] Ep. 7 : Up. 228000 : Sen. 2,212,903 : Cost 56.46542740 : Time 605.39s : 8272.63 words/s
[2019-08-06 09:57:22] Ep. 7 : Up. 230000 : Sen. 2,407,199 : Cost 56.54553986 : Time 603.09s : 8289.24 words/s
[2019-08-06 10:07:26] Ep. 7 : Up. 232000 : Sen. 2,601,237 : Cost 56.02480316 : Time 603.78s : 8257.39 words/s
[2019-08-06 10:17:30] Ep. 7 : Up. 234000 : Sen. 2,795,846 : Cost 56.15515137 : Time 604.04s : 8287.73 words/s
[2019-08-06 10:27:35] Ep. 7 : Up. 236000 : Sen. 2,989,639 : Cost 56.54976654 : Time 605.05s : 8260.68 words/s
[2019-08-06 10:37:40] Ep. 7 : Up. 238000 : Sen. 3,184,387 : Cost 56.08488464 : Time 605.72s : 8254.38 words/s
[2019-08-06 10:44:37] Seen 3317282 samples
[2019-08-06 10:44:37] Starting epoch 8
[2019-08-06 10:44:37] [data] Shuffling data
[2019-08-06 10:44:39] [data] Done reading 4189884 sentences
[2019-08-06 10:44:52] [data] Done shuffling 4189884 sentences to temp files
[2019-08-06 10:48:17] Ep. 8 : Up. 240000 : Sen. 60,245 : Cost 55.98376465 : Time 636.84s : 7822.35 words/s
[2019-08-06 10:48:17] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-06 10:48:26] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.iter240000.npz
[2019-08-06 10:48:33] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-06 10:48:42] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 10:49:09] [valid] Ep. 8 : Up. 240000 : cross-entropy : 46.5703 : new best
[2019-08-06 10:49:18] [valid] Ep. 8 : Up. 240000 : perplexity : 6.30426 : new best
[2019-08-06 10:50:24] [valid] Ep. 8 : Up. 240000 : translation : 31.28 : stalled 1 times (last best: 31.33)
[2019-08-06 11:00:29] Ep. 8 : Up. 242000 : Sen. 253,690 : Cost 54.70330429 : Time 731.63s : 6791.92 words/s
[2019-08-06 11:10:36] Ep. 8 : Up. 244000 : Sen. 448,519 : Cost 54.80416489 : Time 606.71s : 8254.03 words/s
[2019-08-06 11:20:41] Ep. 8 : Up. 246000 : Sen. 642,350 : Cost 55.39048386 : Time 605.30s : 8252.64 words/s
[2019-08-06 11:30:46] Ep. 8 : Up. 248000 : Sen. 836,024 : Cost 55.07634354 : Time 605.27s : 8232.65 words/s
[2019-08-06 11:40:50] Ep. 8 : Up. 250000 : Sen. 1,030,244 : Cost 55.13928986 : Time 603.60s : 8264.90 words/s
[2019-08-06 11:50:52] Ep. 8 : Up. 252000 : Sen. 1,224,327 : Cost 55.51155090 : Time 602.65s : 8284.31 words/s
[2019-08-06 12:00:54] Ep. 8 : Up. 254000 : Sen. 1,418,004 : Cost 55.36557388 : Time 601.66s : 8286.34 words/s
[2019-08-06 12:10:57] Ep. 8 : Up. 256000 : Sen. 1,612,287 : Cost 55.59129333 : Time 602.63s : 8296.22 words/s
[2019-08-06 12:21:00] Ep. 8 : Up. 258000 : Sen. 1,805,898 : Cost 55.56445312 : Time 602.82s : 8285.22 words/s
[2019-08-06 12:31:05] Ep. 8 : Up. 260000 : Sen. 1,999,800 : Cost 55.53267288 : Time 605.26s : 8253.79 words/s
[2019-08-06 12:31:05] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-06 12:31:14] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.iter260000.npz
[2019-08-06 12:31:21] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-06 12:31:34] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 12:32:04] [valid] Ep. 8 : Up. 260000 : cross-entropy : 46.4925 : new best
[2019-08-06 12:32:13] [valid] Ep. 8 : Up. 260000 : perplexity : 6.28489 : new best
[2019-08-06 12:33:18] [valid] Ep. 8 : Up. 260000 : translation : 31.26 : stalled 2 times (last best: 31.33)
[2019-08-06 12:43:24] Ep. 8 : Up. 262000 : Sen. 2,194,033 : Cost 55.28052521 : Time 738.77s : 6755.04 words/s
[2019-08-06 12:53:25] Ep. 8 : Up. 264000 : Sen. 2,387,728 : Cost 55.44837952 : Time 600.99s : 8293.59 words/s
[2019-08-06 13:03:27] Ep. 8 : Up. 266000 : Sen. 2,581,250 : Cost 55.47924423 : Time 602.10s : 8275.17 words/s
[2019-08-06 13:13:30] Ep. 8 : Up. 268000 : Sen. 2,775,320 : Cost 55.47201920 : Time 603.68s : 8263.60 words/s
[2019-08-06 13:23:34] Ep. 8 : Up. 270000 : Sen. 2,969,522 : Cost 55.56944275 : Time 603.48s : 8278.11 words/s
[2019-08-06 13:33:39] Ep. 8 : Up. 272000 : Sen. 3,163,623 : Cost 55.88237000 : Time 605.44s : 8258.23 words/s
[2019-08-06 13:41:39] Seen 3317282 samples
[2019-08-06 13:41:39] Starting epoch 9
[2019-08-06 13:41:39] [data] Shuffling data
[2019-08-06 13:41:41] [data] Done reading 4189884 sentences
[2019-08-06 13:41:53] [data] Done shuffling 4189884 sentences to temp files
[2019-08-06 13:44:11] Ep. 9 : Up. 274000 : Sen. 40,658 : Cost 55.39466858 : Time 631.85s : 7924.91 words/s
[2019-08-06 13:54:15] Ep. 9 : Up. 276000 : Sen. 234,728 : Cost 54.11654663 : Time 603.47s : 8270.72 words/s
[2019-08-06 14:04:18] Ep. 9 : Up. 278000 : Sen. 427,887 : Cost 54.54447556 : Time 603.02s : 8264.60 words/s
[2019-08-06 14:14:24] Ep. 9 : Up. 280000 : Sen. 622,188 : Cost 54.19935608 : Time 606.70s : 8225.02 words/s
[2019-08-06 14:14:24] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-06 14:14:38] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.iter280000.npz
[2019-08-06 14:14:47] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-06 14:15:00] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 14:15:29] [valid] Ep. 9 : Up. 280000 : cross-entropy : 46.3376 : new best
[2019-08-06 14:15:37] [valid] Ep. 9 : Up. 280000 : perplexity : 6.24654 : new best
[2019-08-06 14:16:43] [valid] Ep. 9 : Up. 280000 : translation : 31.48 : new best
[2019-08-06 14:26:50] Ep. 9 : Up. 282000 : Sen. 816,100 : Cost 54.55627823 : Time 745.48s : 6707.06 words/s
[2019-08-06 14:36:54] Ep. 9 : Up. 284000 : Sen. 1,010,563 : Cost 54.47397614 : Time 604.11s : 8270.10 words/s
[2019-08-06 14:47:00] Ep. 9 : Up. 286000 : Sen. 1,204,789 : Cost 54.66057205 : Time 605.67s : 8250.79 words/s
[2019-08-06 14:57:02] Ep. 9 : Up. 288000 : Sen. 1,398,983 : Cost 54.45582199 : Time 602.45s : 8274.53 words/s
[2019-08-06 15:07:05] Ep. 9 : Up. 290000 : Sen. 1,592,762 : Cost 54.51501846 : Time 602.65s : 8279.27 words/s
[2019-08-06 15:17:11] Ep. 9 : Up. 292000 : Sen. 1,787,543 : Cost 54.58586884 : Time 606.40s : 8262.36 words/s
[2019-08-06 15:27:15] Ep. 9 : Up. 294000 : Sen. 1,980,829 : Cost 54.96994781 : Time 603.46s : 8260.89 words/s
[2019-08-06 15:37:19] Ep. 9 : Up. 296000 : Sen. 2,175,128 : Cost 54.80926895 : Time 604.33s : 8265.17 words/s
[2019-08-06 15:47:24] Ep. 9 : Up. 298000 : Sen. 2,369,983 : Cost 54.72117615 : Time 605.12s : 8281.61 words/s
[2019-08-06 15:57:32] Ep. 9 : Up. 300000 : Sen. 2,563,554 : Cost 54.85564804 : Time 607.85s : 8218.44 words/s
[2019-08-06 15:57:32] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-06 15:57:41] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.iter300000.npz
[2019-08-06 15:57:48] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-06 15:57:57] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 15:58:24] [valid] Ep. 9 : Up. 300000 : cross-entropy : 46.1915 : new best
[2019-08-06 15:58:32] [valid] Ep. 9 : Up. 300000 : perplexity : 6.21055 : new best
[2019-08-06 15:59:38] [valid] Ep. 9 : Up. 300000 : translation : 31.48 : stalled 1 times (last best: 31.48)
[2019-08-06 16:09:45] Ep. 9 : Up. 302000 : Sen. 2,757,131 : Cost 54.79302216 : Time 733.17s : 6798.01 words/s
[2019-08-06 16:19:49] Ep. 9 : Up. 304000 : Sen. 2,950,929 : Cost 54.87773514 : Time 603.62s : 8261.05 words/s
[2019-08-06 16:29:52] Ep. 9 : Up. 306000 : Sen. 3,144,842 : Cost 54.88740158 : Time 603.44s : 8259.39 words/s
[2019-08-06 16:38:50] Seen 3317282 samples
[2019-08-06 16:38:50] Starting epoch 10
[2019-08-06 16:38:50] [data] Shuffling data
[2019-08-06 16:38:52] [data] Done reading 4189884 sentences
[2019-08-06 16:39:04] [data] Done shuffling 4189884 sentences to temp files
[2019-08-06 16:40:21] Ep. 10 : Up. 308000 : Sen. 21,244 : Cost 54.60536575 : Time 629.37s : 7915.11 words/s
[2019-08-06 16:50:27] Ep. 10 : Up. 310000 : Sen. 214,691 : Cost 53.66494751 : Time 605.67s : 8242.03 words/s
[2019-08-06 17:00:28] Ep. 10 : Up. 312000 : Sen. 408,177 : Cost 53.50182343 : Time 600.75s : 8269.68 words/s
[2019-08-06 17:10:31] Ep. 10 : Up. 314000 : Sen. 601,780 : Cost 53.81325531 : Time 603.50s : 8254.85 words/s
[2019-08-06 17:20:35] Ep. 10 : Up. 316000 : Sen. 795,125 : Cost 53.72075653 : Time 603.52s : 8247.76 words/s
[2019-08-06 17:30:40] Ep. 10 : Up. 318000 : Sen. 988,956 : Cost 54.03224564 : Time 605.34s : 8255.71 words/s
[2019-08-06 17:40:44] Ep. 10 : Up. 320000 : Sen. 1,182,598 : Cost 54.07720947 : Time 603.32s : 8256.73 words/s
[2019-08-06 17:40:44] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-06 17:40:54] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.iter320000.npz
[2019-08-06 17:41:02] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-06 17:41:12] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 17:41:38] [valid] Ep. 10 : Up. 320000 : cross-entropy : 46.1646 : new best
[2019-08-06 17:41:47] [valid] Ep. 10 : Up. 320000 : perplexity : 6.20394 : new best
[2019-08-06 17:42:52] [valid] Ep. 10 : Up. 320000 : translation : 31.59 : new best
[2019-08-06 17:52:58] Ep. 10 : Up. 322000 : Sen. 1,376,809 : Cost 53.81858444 : Time 734.81s : 6798.34 words/s
[2019-08-06 18:03:04] Ep. 10 : Up. 324000 : Sen. 1,571,354 : Cost 53.92792892 : Time 605.50s : 8271.57 words/s
[2019-08-06 18:13:07] Ep. 10 : Up. 326000 : Sen. 1,764,765 : Cost 54.08284378 : Time 603.08s : 8267.33 words/s
[2019-08-06 18:23:12] Ep. 10 : Up. 328000 : Sen. 1,959,542 : Cost 53.93449020 : Time 604.94s : 8265.75 words/s
[2019-08-06 18:33:16] Ep. 10 : Up. 330000 : Sen. 2,153,779 : Cost 54.17245102 : Time 604.53s : 8267.69 words/s
[2019-08-06 18:43:22] Ep. 10 : Up. 332000 : Sen. 2,348,302 : Cost 54.28237915 : Time 605.81s : 8272.66 words/s
[2019-08-06 18:53:24] Ep. 10 : Up. 334000 : Sen. 2,542,463 : Cost 54.00781250 : Time 602.30s : 8287.91 words/s
[2019-08-06 19:03:29] Ep. 10 : Up. 336000 : Sen. 2,736,267 : Cost 54.40485382 : Time 604.06s : 8252.26 words/s
[2019-08-06 19:13:35] Ep. 10 : Up. 338000 : Sen. 2,930,732 : Cost 54.40963745 : Time 606.19s : 8249.35 words/s
[2019-08-06 19:23:41] Ep. 10 : Up. 340000 : Sen. 3,124,964 : Cost 54.26445770 : Time 605.86s : 8261.57 words/s
[2019-08-06 19:23:41] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-06 19:23:50] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.iter340000.npz
[2019-08-06 19:23:56] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-06 19:24:05] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 19:24:31] [valid] Ep. 10 : Up. 340000 : cross-entropy : 46.0299 : new best
[2019-08-06 19:24:40] [valid] Ep. 10 : Up. 340000 : perplexity : 6.171 : new best
[2019-08-06 19:25:45] [valid] Ep. 10 : Up. 340000 : translation : 31.48 : stalled 1 times (last best: 31.59)
[2019-08-06 19:35:46] Seen 3317282 samples
[2019-08-06 19:35:46] Starting epoch 11
[2019-08-06 19:35:46] [data] Shuffling data
[2019-08-06 19:35:49] [data] Done reading 4189884 sentences
[2019-08-06 19:36:00] [data] Done shuffling 4189884 sentences to temp files
[2019-08-06 19:36:18] Ep. 11 : Up. 342000 : Sen. 1,621 : Cost 54.25744629 : Time 757.25s : 6584.59 words/s
[2019-08-06 19:46:26] Ep. 11 : Up. 344000 : Sen. 196,433 : Cost 53.08868027 : Time 607.76s : 8250.38 words/s
[2019-08-06 19:56:33] Ep. 11 : Up. 346000 : Sen. 390,706 : Cost 52.91590881 : Time 606.99s : 8238.47 words/s
[2019-08-06 20:06:38] Ep. 11 : Up. 348000 : Sen. 584,681 : Cost 53.22887421 : Time 605.73s : 8243.55 words/s
[2019-08-06 20:16:40] Ep. 11 : Up. 350000 : Sen. 778,137 : Cost 53.52583694 : Time 602.01s : 8263.36 words/s
[2019-08-06 20:26:45] Ep. 11 : Up. 352000 : Sen. 972,327 : Cost 53.12170029 : Time 604.99s : 8254.62 words/s
[2019-08-06 20:36:52] Ep. 11 : Up. 354000 : Sen. 1,166,336 : Cost 53.48145294 : Time 606.44s : 8248.00 words/s
[2019-08-06 20:46:57] Ep. 11 : Up. 356000 : Sen. 1,360,793 : Cost 53.30824280 : Time 605.45s : 8250.52 words/s
[2019-08-06 20:57:01] Ep. 11 : Up. 358000 : Sen. 1,554,203 : Cost 53.60168457 : Time 604.08s : 8247.56 words/s
[2019-08-06 21:07:05] Ep. 11 : Up. 360000 : Sen. 1,747,739 : Cost 53.59955597 : Time 603.93s : 8250.60 words/s
[2019-08-06 21:07:05] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-06 21:07:14] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.iter360000.npz
[2019-08-06 21:07:21] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-06 21:07:30] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 21:07:56] [valid] Ep. 11 : Up. 360000 : cross-entropy : 46.0469 : stalled 1 times (last best: 46.0299)
[2019-08-06 21:08:05] [valid] Ep. 11 : Up. 360000 : perplexity : 6.17516 : stalled 1 times (last best: 6.171)
[2019-08-06 21:09:10] [valid] Ep. 11 : Up. 360000 : translation : 31.66 : new best
[2019-08-06 21:19:17] Ep. 11 : Up. 362000 : Sen. 1,941,521 : Cost 53.60422516 : Time 731.81s : 6821.77 words/s
[2019-08-06 21:29:23] Ep. 11 : Up. 364000 : Sen. 2,136,115 : Cost 53.63428116 : Time 606.18s : 8253.43 words/s
[2019-08-06 21:39:27] Ep. 11 : Up. 366000 : Sen. 2,330,446 : Cost 53.49420166 : Time 603.42s : 8279.99 words/s
[2019-08-06 21:49:35] Ep. 11 : Up. 368000 : Sen. 2,524,980 : Cost 53.59658813 : Time 608.70s : 8227.23 words/s
[2019-08-06 21:59:39] Ep. 11 : Up. 370000 : Sen. 2,719,068 : Cost 53.59708023 : Time 603.63s : 8260.17 words/s
[2019-08-06 22:09:42] Ep. 11 : Up. 372000 : Sen. 2,913,427 : Cost 53.77362061 : Time 603.46s : 8266.75 words/s
[2019-08-06 22:19:50] Ep. 11 : Up. 374000 : Sen. 3,107,917 : Cost 54.03855133 : Time 607.85s : 8265.35 words/s
[2019-08-06 22:29:55] Ep. 11 : Up. 376000 : Sen. 3,301,710 : Cost 53.72031403 : Time 604.89s : 8252.93 words/s
[2019-08-06 22:30:44] Seen 3317282 samples
[2019-08-06 22:30:44] Starting epoch 12
[2019-08-06 22:30:44] [data] Shuffling data
[2019-08-06 22:30:46] [data] Done reading 4189884 sentences
[2019-08-06 22:30:59] [data] Done shuffling 4189884 sentences to temp files
[2019-08-06 22:40:28] Ep. 12 : Up. 378000 : Sen. 178,846 : Cost 52.59928513 : Time 632.87s : 7901.64 words/s
[2019-08-06 22:50:31] Ep. 12 : Up. 380000 : Sen. 372,374 : Cost 52.45690536 : Time 602.79s : 8258.26 words/s
[2019-08-06 22:50:31] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-06 22:50:40] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.iter380000.npz
[2019-08-06 22:50:47] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-06 22:50:56] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 22:51:22] [valid] Ep. 12 : Up. 380000 : cross-entropy : 45.9986 : new best
[2019-08-06 22:51:30] [valid] Ep. 12 : Up. 380000 : perplexity : 6.16336 : new best
[2019-08-06 22:52:36] [valid] Ep. 12 : Up. 380000 : translation : 31.76 : new best
[2019-08-06 23:02:44] Ep. 12 : Up. 382000 : Sen. 566,422 : Cost 52.52985764 : Time 733.40s : 6805.58 words/s
[2019-08-06 23:12:54] Ep. 12 : Up. 384000 : Sen. 760,691 : Cost 52.86223602 : Time 609.37s : 8224.50 words/s
[2019-08-06 23:22:59] Ep. 12 : Up. 386000 : Sen. 954,783 : Cost 52.95257568 : Time 605.43s : 8253.04 words/s
[2019-08-06 23:33:03] Ep. 12 : Up. 388000 : Sen. 1,148,593 : Cost 52.98847198 : Time 604.39s : 8244.58 words/s
[2019-08-06 23:43:07] Ep. 12 : Up. 390000 : Sen. 1,343,164 : Cost 52.83617783 : Time 603.86s : 8280.96 words/s
[2019-08-06 23:53:16] Ep. 12 : Up. 392000 : Sen. 1,537,797 : Cost 53.11134338 : Time 608.68s : 8239.09 words/s
[2019-08-07 00:03:23] Ep. 12 : Up. 394000 : Sen. 1,732,729 : Cost 52.93072510 : Time 607.27s : 8251.58 words/s
[2019-08-07 00:13:29] Ep. 12 : Up. 396000 : Sen. 1,926,637 : Cost 53.07218552 : Time 605.76s : 8233.73 words/s
[2019-08-07 00:23:32] Ep. 12 : Up. 398000 : Sen. 2,119,547 : Cost 53.24867630 : Time 603.42s : 8238.21 words/s
[2019-08-07 00:33:38] Ep. 12 : Up. 400000 : Sen. 2,313,421 : Cost 53.21915817 : Time 605.62s : 8254.22 words/s
[2019-08-07 00:33:38] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-07 00:33:47] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.iter400000.npz
[2019-08-07 00:33:54] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-07 00:34:03] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-07 00:34:28] [valid] Ep. 12 : Up. 400000 : cross-entropy : 45.8611 : new best
[2019-08-07 00:34:37] [valid] Ep. 12 : Up. 400000 : perplexity : 6.12994 : new best
[2019-08-07 00:35:42] [valid] Ep. 12 : Up. 400000 : translation : 31.54 : stalled 1 times (last best: 31.76)
[2019-08-07 00:45:49] Ep. 12 : Up. 402000 : Sen. 2,507,497 : Cost 53.25587463 : Time 731.11s : 6830.40 words/s
[2019-08-07 00:55:54] Ep. 12 : Up. 404000 : Sen. 2,701,836 : Cost 53.13019180 : Time 604.89s : 8264.93 words/s
[2019-08-07 01:06:02] Ep. 12 : Up. 406000 : Sen. 2,896,300 : Cost 53.20887756 : Time 607.47s : 8242.72 words/s
[2019-08-07 01:16:42] Ep. 12 : Up. 408000 : Sen. 3,090,620 : Cost 53.18574905 : Time 640.17s : 7790.22 words/s
[2019-08-07 01:26:46] Ep. 12 : Up. 410000 : Sen. 3,284,312 : Cost 53.28245926 : Time 604.30s : 8246.67 words/s
[2019-08-07 01:28:29] Seen 3317282 samples
[2019-08-07 01:28:29] Starting epoch 13
[2019-08-07 01:28:29] [data] Shuffling data
[2019-08-07 01:28:31] [data] Done reading 4189884 sentences
[2019-08-07 01:28:43] [data] Done shuffling 4189884 sentences to temp files
[2019-08-07 01:37:18] Ep. 13 : Up. 412000 : Sen. 161,261 : Cost 52.40795898 : Time 632.13s : 7921.55 words/s
[2019-08-07 01:47:22] Ep. 13 : Up. 414000 : Sen. 354,513 : Cost 52.19004059 : Time 603.99s : 8227.67 words/s
[2019-08-07 01:57:28] Ep. 13 : Up. 416000 : Sen. 548,734 : Cost 52.06436539 : Time 605.68s : 8251.41 words/s
[2019-08-07 02:07:33] Ep. 13 : Up. 418000 : Sen. 742,924 : Cost 52.28372574 : Time 604.83s : 8256.96 words/s
[2019-08-07 02:17:38] Ep. 13 : Up. 420000 : Sen. 937,212 : Cost 52.35504913 : Time 605.59s : 8246.31 words/s
[2019-08-07 02:17:38] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-07 02:17:48] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.iter420000.npz
[2019-08-07 02:17:55] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-07 02:18:04] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-07 02:18:29] [valid] Ep. 13 : Up. 420000 : cross-entropy : 45.8547 : new best
[2019-08-07 02:18:38] [valid] Ep. 13 : Up. 420000 : perplexity : 6.12839 : new best
[2019-08-07 02:19:43] [valid] Ep. 13 : Up. 420000 : translation : 31.67 : stalled 2 times (last best: 31.76)
[2019-08-07 02:29:48] Ep. 13 : Up. 422000 : Sen. 1,130,751 : Cost 52.49686813 : Time 729.65s : 6835.70 words/s
[2019-08-07 02:39:51] Ep. 13 : Up. 424000 : Sen. 1,324,509 : Cost 52.45003510 : Time 603.14s : 8260.56 words/s
[2019-08-07 02:49:58] Ep. 13 : Up. 426000 : Sen. 1,519,063 : Cost 52.44322586 : Time 606.69s : 8243.75 words/s
[2019-08-07 03:00:03] Ep. 13 : Up. 428000 : Sen. 1,713,490 : Cost 52.45890808 : Time 605.50s : 8254.83 words/s
[2019-08-07 03:10:11] Ep. 13 : Up. 430000 : Sen. 1,907,307 : Cost 52.96240616 : Time 607.43s : 8231.41 words/s
[2019-08-07 03:20:18] Ep. 13 : Up. 432000 : Sen. 2,101,560 : Cost 52.64703369 : Time 606.96s : 8234.39 words/s
[2019-08-07 03:30:21] Ep. 13 : Up. 434000 : Sen. 2,295,567 : Cost 52.74700546 : Time 603.64s : 8260.85 words/s
[2019-08-07 03:40:26] Ep. 13 : Up. 436000 : Sen. 2,489,826 : Cost 52.51348114 : Time 605.18s : 8257.80 words/s
[2019-08-07 03:50:31] Ep. 13 : Up. 438000 : Sen. 2,683,183 : Cost 52.84061432 : Time 604.32s : 8236.71 words/s
[2019-08-07 04:00:37] Ep. 13 : Up. 440000 : Sen. 2,877,438 : Cost 52.93194962 : Time 606.67s : 8253.90 words/s
[2019-08-07 04:00:37] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-07 04:00:46] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.iter440000.npz
[2019-08-07 04:00:53] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-07 04:01:02] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-07 04:01:28] [valid] Ep. 13 : Up. 440000 : cross-entropy : 45.7845 : new best
[2019-08-07 04:01:37] [valid] Ep. 13 : Up. 440000 : perplexity : 6.11141 : new best
[2019-08-07 04:02:42] [valid] Ep. 13 : Up. 440000 : translation : 31.68 : stalled 3 times (last best: 31.76)
[2019-08-07 04:12:50] Ep. 13 : Up. 442000 : Sen. 3,071,922 : Cost 52.74237823 : Time 733.05s : 6820.00 words/s
[2019-08-07 04:22:54] Ep. 13 : Up. 444000 : Sen. 3,265,063 : Cost 53.04116821 : Time 603.78s : 8226.89 words/s
[2019-08-07 04:25:38] Seen 3317282 samples
[2019-08-07 04:25:38] Starting epoch 14
[2019-08-07 04:25:38] [data] Shuffling data
[2019-08-07 04:25:41] [data] Done reading 4189884 sentences
[2019-08-07 04:25:52] [data] Done shuffling 4189884 sentences to temp files
[2019-08-07 04:33:24] Ep. 14 : Up. 446000 : Sen. 141,758 : Cost 52.30106735 : Time 630.20s : 7921.67 words/s
[2019-08-07 04:43:32] Ep. 14 : Up. 448000 : Sen. 336,199 : Cost 51.74484253 : Time 608.03s : 8243.54 words/s
[2019-08-07 04:53:35] Ep. 14 : Up. 450000 : Sen. 529,048 : Cost 51.80102158 : Time 602.98s : 8238.85 words/s
[2019-08-07 05:03:42] Ep. 14 : Up. 452000 : Sen. 723,838 : Cost 51.49024200 : Time 606.87s : 8244.02 words/s
[2019-08-07 05:13:49] Ep. 14 : Up. 454000 : Sen. 917,742 : Cost 52.13241959 : Time 606.96s : 8240.23 words/s
[2019-08-07 05:23:55] Ep. 14 : Up. 456000 : Sen. 1,111,920 : Cost 52.03004837 : Time 605.93s : 8234.98 words/s
[2019-08-07 05:34:00] Ep. 14 : Up. 458000 : Sen. 1,305,444 : Cost 52.09011841 : Time 604.31s : 8238.16 words/s
[2019-08-07 05:44:04] Ep. 14 : Up. 460000 : Sen. 1,498,846 : Cost 52.34397125 : Time 604.18s : 8243.35 words/s
[2019-08-07 05:44:04] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-07 05:44:12] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.iter460000.npz
[2019-08-07 05:44:19] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-07 05:44:28] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-07 05:44:58] [valid] Ep. 14 : Up. 460000 : cross-entropy : 45.8133 : stalled 1 times (last best: 45.7845)
[2019-08-07 05:45:07] [valid] Ep. 14 : Up. 460000 : perplexity : 6.11838 : stalled 1 times (last best: 6.11141)
[2019-08-07 05:46:14] [valid] Ep. 14 : Up. 460000 : translation : 31.65 : stalled 4 times (last best: 31.76)
[2019-08-07 05:56:22] Ep. 14 : Up. 462000 : Sen. 1,692,928 : Cost 51.98159027 : Time 737.96s : 6749.88 words/s
[2019-08-07 06:06:25] Ep. 14 : Up. 464000 : Sen. 1,886,372 : Cost 52.31960678 : Time 603.00s : 8250.30 words/s
[2019-08-07 06:16:34] Ep. 14 : Up. 466000 : Sen. 2,081,283 : Cost 52.55857468 : Time 608.96s : 8248.28 words/s
[2019-08-07 06:26:37] Ep. 14 : Up. 468000 : Sen. 2,274,105 : Cost 52.36380768 : Time 603.52s : 8237.25 words/s
[2019-08-07 06:36:45] Ep. 14 : Up. 470000 : Sen. 2,468,515 : Cost 52.42091370 : Time 607.67s : 8234.50 words/s
[2019-08-07 06:46:49] Ep. 14 : Up. 472000 : Sen. 2,662,187 : Cost 52.44099808 : Time 604.35s : 8237.05 words/s
[2019-08-07 06:56:58] Ep. 14 : Up. 474000 : Sen. 2,856,989 : Cost 52.58526611 : Time 609.19s : 8226.57 words/s
[2019-08-07 07:07:07] Ep. 14 : Up. 476000 : Sen. 3,051,389 : Cost 52.82551575 : Time 608.57s : 8225.80 words/s
[2019-08-07 07:17:12] Ep. 14 : Up. 478000 : Sen. 3,245,185 : Cost 52.55073547 : Time 604.76s : 8250.40 words/s
[2019-08-07 07:20:58] Seen 3317282 samples
[2019-08-07 07:20:58] Starting epoch 15
[2019-08-07 07:20:58] [data] Shuffling data
[2019-08-07 07:21:00] [data] Done reading 4189884 sentences
[2019-08-07 07:21:13] [data] Done shuffling 4189884 sentences to temp files
[2019-08-07 07:27:42] Ep. 15 : Up. 480000 : Sen. 121,757 : Cost 51.66068268 : Time 629.90s : 7909.22 words/s
[2019-08-07 07:27:42] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-07 07:27:51] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.iter480000.npz
[2019-08-07 07:27:58] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-07 07:28:07] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-07 07:28:33] [valid] Ep. 15 : Up. 480000 : cross-entropy : 45.6909 : new best
[2019-08-07 07:28:42] [valid] Ep. 15 : Up. 480000 : perplexity : 6.08884 : new best
[2019-08-07 07:29:48] [valid] Ep. 15 : Up. 480000 : translation : 31.65 : stalled 5 times (last best: 31.76)
[2019-08-07 07:39:55] Ep. 15 : Up. 482000 : Sen. 315,667 : Cost 51.47620010 : Time 733.79s : 6818.46 words/s
[2019-08-07 07:50:00] Ep. 15 : Up. 484000 : Sen. 509,387 : Cost 51.39180374 : Time 604.95s : 8236.21 words/s
[2019-08-07 08:00:09] Ep. 15 : Up. 486000 : Sen. 704,090 : Cost 51.57654572 : Time 608.37s : 8238.90 words/s
[2019-08-07 08:10:14] Ep. 15 : Up. 488000 : Sen. 898,586 : Cost 51.53970337 : Time 605.48s : 8253.41 words/s
[2019-08-07 08:20:20] Ep. 15 : Up. 490000 : Sen. 1,092,696 : Cost 51.86662292 : Time 605.38s : 8250.22 words/s
[2019-08-07 08:30:25] Ep. 15 : Up. 492000 : Sen. 1,286,767 : Cost 51.62570953 : Time 605.38s : 8245.45 words/s
[2019-08-07 08:40:33] Ep. 15 : Up. 494000 : Sen. 1,481,035 : Cost 51.88603973 : Time 607.60s : 8226.10 words/s
[2019-08-07 08:50:38] Ep. 15 : Up. 496000 : Sen. 1,674,325 : Cost 51.85809326 : Time 605.63s : 8221.26 words/s
[2019-08-07 09:00:44] Ep. 15 : Up. 498000 : Sen. 1,868,002 : Cost 51.99692154 : Time 605.55s : 8231.98 words/s
[2019-08-07 09:10:49] Ep. 15 : Up. 500000 : Sen. 2,061,444 : Cost 52.13084030 : Time 605.52s : 8244.97 words/s
[2019-08-07 09:10:49] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-07 09:10:58] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.iter500000.npz
[2019-08-07 09:11:05] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-07 09:11:15] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-07 09:11:40] [valid] Ep. 15 : Up. 500000 : cross-entropy : 45.8472 : stalled 1 times (last best: 45.6909)
[2019-08-07 09:11:49] [valid] Ep. 15 : Up. 500000 : perplexity : 6.12659 : stalled 1 times (last best: 6.08884)
[2019-08-07 09:12:54] [valid] Ep. 15 : Up. 500000 : translation : 31.69 : stalled 6 times (last best: 31.76)
[2019-08-07 09:23:04] Ep. 15 : Up. 502000 : Sen. 2,255,140 : Cost 51.86815262 : Time 734.30s : 6785.36 words/s
[2019-08-07 09:33:11] Ep. 15 : Up. 504000 : Sen. 2,449,073 : Cost 52.24226761 : Time 607.14s : 8216.94 words/s
[2019-08-07 09:43:16] Ep. 15 : Up. 506000 : Sen. 2,642,815 : Cost 52.17137146 : Time 605.53s : 8245.69 words/s
[2019-08-07 09:53:21] Ep. 15 : Up. 508000 : Sen. 2,836,941 : Cost 51.88521194 : Time 604.58s : 8251.96 words/s
[2019-08-07 10:03:25] Ep. 15 : Up. 510000 : Sen. 3,031,369 : Cost 52.04489136 : Time 604.18s : 8278.76 words/s
[2019-08-07 10:13:33] Ep. 15 : Up. 512000 : Sen. 3,226,558 : Cost 52.14767075 : Time 607.85s : 8243.41 words/s
[2019-08-07 10:18:17] Seen 3317282 samples
[2019-08-07 10:18:17] Starting epoch 16
[2019-08-07 10:18:17] [data] Shuffling data
[2019-08-07 10:18:19] [data] Done reading 4189884 sentences
[2019-08-07 10:18:31] [data] Done shuffling 4189884 sentences to temp files
[2019-08-07 10:24:21] Ep. 16 : Up. 514000 : Sen. 103,107 : Cost 51.48380661 : Time 648.66s : 7687.87 words/s
[2019-08-07 10:34:28] Ep. 16 : Up. 516000 : Sen. 296,699 : Cost 50.94287872 : Time 606.41s : 8226.85 words/s
[2019-08-07 10:44:36] Ep. 16 : Up. 518000 : Sen. 490,675 : Cost 51.09117126 : Time 607.67s : 8202.18 words/s
[2019-08-07 10:54:41] Ep. 16 : Up. 520000 : Sen. 684,447 : Cost 51.43912506 : Time 605.24s : 8245.62 words/s
[2019-08-07 10:54:41] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-07 10:54:50] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.iter520000.npz
[2019-08-07 10:54:57] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-07 10:55:06] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-07 10:55:33] [valid] Ep. 16 : Up. 520000 : cross-entropy : 45.8025 : stalled 2 times (last best: 45.6909)
[2019-08-07 10:55:42] [valid] Ep. 16 : Up. 520000 : perplexity : 6.11577 : stalled 2 times (last best: 6.08884)
[2019-08-07 10:56:47] [valid] Ep. 16 : Up. 520000 : translation : 31.74 : stalled 7 times (last best: 31.76)
[2019-08-07 11:06:54] Ep. 16 : Up. 522000 : Sen. 878,231 : Cost 51.47573090 : Time 732.78s : 6816.79 words/s
[2019-08-07 11:16:58] Ep. 16 : Up. 524000 : Sen. 1,072,118 : Cost 51.23433304 : Time 604.71s : 8247.04 words/s
[2019-08-07 11:28:40] Ep. 16 : Up. 526000 : Sen. 1,266,533 : Cost 51.34996796 : Time 701.65s : 7113.48 words/s
[2019-08-07 11:38:46] Ep. 16 : Up. 528000 : Sen. 1,461,217 : Cost 51.58117676 : Time 606.06s : 8276.50 words/s
[2019-08-07 11:48:50] Ep. 16 : Up. 530000 : Sen. 1,655,552 : Cost 51.63758469 : Time 604.15s : 8270.67 words/s
[2019-08-07 11:58:57] Ep. 16 : Up. 532000 : Sen. 1,849,858 : Cost 51.63943481 : Time 606.79s : 8251.61 words/s
[2019-08-07 12:09:00] Ep. 16 : Up. 534000 : Sen. 2,043,438 : Cost 51.80699921 : Time 602.96s : 8260.14 words/s
[2019-08-07 12:19:05] Ep. 16 : Up. 536000 : Sen. 2,237,421 : Cost 51.37389755 : Time 604.84s : 8241.71 words/s
[2019-08-07 12:29:10] Ep. 16 : Up. 538000 : Sen. 2,431,533 : Cost 51.91954041 : Time 605.08s : 8251.36 words/s
[2019-08-07 12:39:17] Ep. 16 : Up. 540000 : Sen. 2,625,617 : Cost 51.89298630 : Time 606.99s : 8234.41 words/s
[2019-08-07 12:39:17] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-07 12:39:26] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.iter540000.npz
[2019-08-07 12:39:33] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-07 12:39:43] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-07 12:40:10] [valid] Ep. 16 : Up. 540000 : cross-entropy : 45.8403 : stalled 3 times (last best: 45.6909)
[2019-08-07 12:40:18] [valid] Ep. 16 : Up. 540000 : perplexity : 6.12491 : stalled 3 times (last best: 6.08884)
[2019-08-07 12:41:24] [valid] Ep. 16 : Up. 540000 : translation : 31.82 : new best
[2019-08-07 12:51:29] Ep. 16 : Up. 542000 : Sen. 2,820,141 : Cost 51.70001602 : Time 732.23s : 6821.25 words/s
[2019-08-07 13:01:35] Ep. 16 : Up. 544000 : Sen. 3,014,218 : Cost 51.98849869 : Time 605.55s : 8266.30 words/s
[2019-08-07 16:12:05] Error: Aborted from marian::io::InputFileStream& marian::io::getline(marian::io::InputFileStream&, std::__cxx11::string&) in /fs/bil0/abdel/marian-dev/src/common/file_stream.h:216

[CALL STACK]
[0x727f12]                                                            
[0x728ff8]          marian::data::Corpus::  next  ()                   + 0xd68
[0x716e4f]          marian::data::CorpusIterator::  increment  ()      + 0x2f
[0x681a7d]          marian::data::BatchGenerator<marian::data::CorpusBase>::  fetchBatches  () + 0x10dd
[0x682adb]          std::future<std::result_of<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1} ()>::type> marian::ThreadPool::enqueue<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}>(std::result_of&&,(marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}&&)...)::{lambda()#1}::  operator()  () const + 0x2b
[0x6834be]          std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base,std::__future_base::_Result_base::_Deleter> (),std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<std::deque<std::shared_ptr<marian::data::CorpusBatch>,std::allocator<std::shared_ptr<marian::data::CorpusBatch>>>>,std::__future_base::_Result_base::_Deleter>,std::_Bind_simple<std::reference_wrapper<std::future<std::result_of<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1} ()>::type> marian::ThreadPool::enqueue<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}>(std::result_of&&,(marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}&&)...)::{lambda()#1}> ()>,std::deque<std::shared_ptr<marian::data::CorpusBatch>,std::allocator<std::shared_ptr<marian::data::CorpusBatch>>>>>::  _M_invoke  (std::_Any_data const&) + 0x3e
[0x5a5f19]          std::__future_base::_State_baseV2::  _M_do_set  (std::function<std::unique_ptr<std::__future_base::_Result_base,std::__future_base::_Result_base::_Deleter> ()>*,  bool*) + 0x29
[0x7f47b6185a99]                                                       + 0xea99
[0x59fac2]                                                            
[0x5a7341]          std::__future_base::_Task_state<std::future<std::result_of<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1} ()>::type> marian::ThreadPool::enqueue<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}>(std::result_of&&,(marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}&&)...)::{lambda()#1},std::allocator<int>,std::deque<std::shared_ptr<marian::data::CorpusBatch>,std::allocator<std::shared_ptr>> ()>::  _M_run  () + 0x51
[0x5d00b4]          std::thread::_Impl<std::_Bind_simple<marian::ThreadPool::reserve(unsigned long)::{lambda()#1} ()>>::  _M_run  () + 0x174
[0x7f47b5ca5c80]                                                       + 0xb8c80
[0x7f47b617e6ba]                                                       + 0x76ba
[0x7f47b540b41d]    clone                                              + 0x6d

[2019-08-07 15:49:10] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 15:49:10] [marian] Running on hodor as process 51651 with command line:
[2019-08-07 15:49:10] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz -T . --devices 2 --train-sets ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.de ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.en --vocabs ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.de.json ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/dev.bpe.de ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/dev.out --valid-script-path ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/train.log --valid-log ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/valid.log
[2019-08-07 15:49:10] [config] after-batches: 0
[2019-08-07 15:49:10] [config] after-epochs: 0
[2019-08-07 15:49:10] [config] allow-unk: false
[2019-08-07 15:49:10] [config] beam-size: 12
[2019-08-07 15:49:10] [config] bert-class-symbol: "[CLS]"
[2019-08-07 15:49:10] [config] bert-mask-symbol: "[MASK]"
[2019-08-07 15:49:10] [config] bert-masking-fraction: 0.15
[2019-08-07 15:49:10] [config] bert-sep-symbol: "[SEP]"
[2019-08-07 15:49:10] [config] bert-train-type-embeddings: true
[2019-08-07 15:49:10] [config] bert-type-vocab-size: 2
[2019-08-07 15:49:10] [config] best-deep: false
[2019-08-07 15:49:10] [config] clip-gemm: 0
[2019-08-07 15:49:10] [config] clip-norm: 1
[2019-08-07 15:49:10] [config] cost-type: ce-mean
[2019-08-07 15:49:10] [config] cpu-threads: 0
[2019-08-07 15:49:10] [config] data-weighting: ""
[2019-08-07 15:49:10] [config] data-weighting-type: sentence
[2019-08-07 15:49:10] [config] dec-cell: gru
[2019-08-07 15:49:10] [config] dec-cell-base-depth: 2
[2019-08-07 15:49:10] [config] dec-cell-high-depth: 1
[2019-08-07 15:49:10] [config] dec-depth: 1
[2019-08-07 15:49:10] [config] devices:
[2019-08-07 15:49:10] [config]   - 2
[2019-08-07 15:49:10] [config] dim-emb: 512
[2019-08-07 15:49:10] [config] dim-rnn: 1024
[2019-08-07 15:49:10] [config] dim-vocabs:
[2019-08-07 15:49:10] [config]   - 50000
[2019-08-07 15:49:10] [config]   - 50000
[2019-08-07 15:49:10] [config] disp-first: 0
[2019-08-07 15:49:10] [config] disp-freq: 2000
[2019-08-07 15:49:10] [config] disp-label-counts: false
[2019-08-07 15:49:10] [config] dropout-rnn: 0.2
[2019-08-07 15:49:10] [config] dropout-src: 0.1
[2019-08-07 15:49:10] [config] dropout-trg: 0.1
[2019-08-07 15:49:10] [config] dump-config: ""
[2019-08-07 15:49:10] [config] early-stopping: 5
[2019-08-07 15:49:10] [config] embedding-fix-src: false
[2019-08-07 15:49:10] [config] embedding-fix-trg: false
[2019-08-07 15:49:10] [config] embedding-normalization: false
[2019-08-07 15:49:10] [config] embedding-vectors:
[2019-08-07 15:49:10] [config]   []
[2019-08-07 15:49:10] [config] enc-cell: gru
[2019-08-07 15:49:10] [config] enc-cell-depth: 1
[2019-08-07 15:49:10] [config] enc-depth: 1
[2019-08-07 15:49:10] [config] enc-type: bidirectional
[2019-08-07 15:49:10] [config] exponential-smoothing: 0.0001
[2019-08-07 15:49:10] [config] grad-dropping-momentum: 0
[2019-08-07 15:49:10] [config] grad-dropping-rate: 0
[2019-08-07 15:49:10] [config] grad-dropping-warmup: 100
[2019-08-07 15:49:10] [config] guided-alignment: none
[2019-08-07 15:49:10] [config] guided-alignment-cost: mse
[2019-08-07 15:49:10] [config] guided-alignment-weight: 0.1
[2019-08-07 15:49:10] [config] ignore-model-config: false
[2019-08-07 15:49:10] [config] input-types:
[2019-08-07 15:49:10] [config]   []
[2019-08-07 15:49:10] [config] interpolate-env-vars: false
[2019-08-07 15:49:10] [config] keep-best: false
[2019-08-07 15:49:10] [config] label-smoothing: 0
[2019-08-07 15:49:10] [config] layer-normalization: true
[2019-08-07 15:49:10] [config] learn-rate: 0.0001
[2019-08-07 15:49:10] [config] log: ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/train.log
[2019-08-07 15:49:10] [config] log-level: info
[2019-08-07 15:49:10] [config] log-time-zone: ""
[2019-08-07 15:49:10] [config] lr-decay: 0
[2019-08-07 15:49:10] [config] lr-decay-freq: 50000
[2019-08-07 15:49:10] [config] lr-decay-inv-sqrt:
[2019-08-07 15:49:10] [config]   - 0
[2019-08-07 15:49:10] [config] lr-decay-repeat-warmup: false
[2019-08-07 15:49:10] [config] lr-decay-reset-optimizer: false
[2019-08-07 15:49:10] [config] lr-decay-start:
[2019-08-07 15:49:10] [config]   - 10
[2019-08-07 15:49:10] [config]   - 1
[2019-08-07 15:49:10] [config] lr-decay-strategy: epoch+stalled
[2019-08-07 15:49:10] [config] lr-report: false
[2019-08-07 15:49:10] [config] lr-warmup: 0
[2019-08-07 15:49:10] [config] lr-warmup-at-reload: false
[2019-08-07 15:49:10] [config] lr-warmup-cycle: false
[2019-08-07 15:49:10] [config] lr-warmup-start-rate: 0
[2019-08-07 15:49:10] [config] max-length: 50
[2019-08-07 15:49:10] [config] max-length-crop: false
[2019-08-07 15:49:10] [config] max-length-factor: 3
[2019-08-07 15:49:10] [config] maxi-batch: 100
[2019-08-07 15:49:10] [config] maxi-batch-sort: trg
[2019-08-07 15:49:10] [config] mini-batch: 64
[2019-08-07 15:49:10] [config] mini-batch-fit: true
[2019-08-07 15:49:10] [config] mini-batch-fit-step: 10
[2019-08-07 15:49:10] [config] mini-batch-overstuff: 1
[2019-08-07 15:49:10] [config] mini-batch-track-lr: false
[2019-08-07 15:49:10] [config] mini-batch-understuff: 1
[2019-08-07 15:49:10] [config] mini-batch-warmup: 0
[2019-08-07 15:49:10] [config] mini-batch-words: 0
[2019-08-07 15:49:10] [config] mini-batch-words-ref: 0
[2019-08-07 15:49:10] [config] model: ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-07 15:49:10] [config] multi-loss-type: sum
[2019-08-07 15:49:10] [config] multi-node: false
[2019-08-07 15:49:10] [config] multi-node-overlap: true
[2019-08-07 15:49:10] [config] n-best: false
[2019-08-07 15:49:10] [config] no-nccl: false
[2019-08-07 15:49:10] [config] no-reload: false
[2019-08-07 15:49:10] [config] no-restore-corpus: false
[2019-08-07 15:49:10] [config] no-shuffle: false
[2019-08-07 15:49:10] [config] normalize: 1
[2019-08-07 15:49:10] [config] num-devices: 0
[2019-08-07 15:49:10] [config] optimizer: adam
[2019-08-07 15:49:10] [config] optimizer-delay: 1
[2019-08-07 15:49:10] [config] optimizer-params:
[2019-08-07 15:49:10] [config]   []
[2019-08-07 15:49:10] [config] overwrite: false
[2019-08-07 15:49:10] [config] pretrained-model: ""
[2019-08-07 15:49:10] [config] quiet: false
[2019-08-07 15:49:10] [config] quiet-translation: true
[2019-08-07 15:49:10] [config] relative-paths: false
[2019-08-07 15:49:10] [config] right-left: false
[2019-08-07 15:49:10] [config] save-freq: 20000
[2019-08-07 15:49:10] [config] seed: 1111
[2019-08-07 15:49:10] [config] shuffle-in-ram: false
[2019-08-07 15:49:10] [config] skip: false
[2019-08-07 15:49:10] [config] sqlite: ""
[2019-08-07 15:49:10] [config] sqlite-drop: false
[2019-08-07 15:49:10] [config] sync-sgd: true
[2019-08-07 15:49:10] [config] tempdir: .
[2019-08-07 15:49:10] [config] tied-embeddings: false
[2019-08-07 15:49:10] [config] tied-embeddings-all: false
[2019-08-07 15:49:10] [config] tied-embeddings-src: false
[2019-08-07 15:49:10] [config] train-sets:
[2019-08-07 15:49:10] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.de
[2019-08-07 15:49:10] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.en
[2019-08-07 15:49:10] [config] transformer-aan-activation: swish
[2019-08-07 15:49:10] [config] transformer-aan-depth: 2
[2019-08-07 15:49:10] [config] transformer-aan-nogate: false
[2019-08-07 15:49:10] [config] transformer-decoder-autoreg: self-attention
[2019-08-07 15:49:10] [config] transformer-dim-aan: 2048
[2019-08-07 15:49:10] [config] transformer-dim-ffn: 2048
[2019-08-07 15:49:10] [config] transformer-dropout: 0
[2019-08-07 15:49:10] [config] transformer-dropout-attention: 0
[2019-08-07 15:49:10] [config] transformer-dropout-ffn: 0
[2019-08-07 15:49:10] [config] transformer-ffn-activation: swish
[2019-08-07 15:49:10] [config] transformer-ffn-depth: 2
[2019-08-07 15:49:10] [config] transformer-guided-alignment-layer: last
[2019-08-07 15:49:10] [config] transformer-heads: 8
[2019-08-07 15:49:10] [config] transformer-no-projection: false
[2019-08-07 15:49:10] [config] transformer-postprocess: dan
[2019-08-07 15:49:10] [config] transformer-postprocess-emb: d
[2019-08-07 15:49:10] [config] transformer-preprocess: ""
[2019-08-07 15:49:10] [config] transformer-tied-layers:
[2019-08-07 15:49:10] [config]   []
[2019-08-07 15:49:10] [config] transformer-train-position-embeddings: false
[2019-08-07 15:49:10] [config] type: amun
[2019-08-07 15:49:10] [config] ulr: false
[2019-08-07 15:49:10] [config] ulr-dim-emb: 0
[2019-08-07 15:49:10] [config] ulr-dropout: 0
[2019-08-07 15:49:10] [config] ulr-keys-vectors: ""
[2019-08-07 15:49:10] [config] ulr-query-vectors: ""
[2019-08-07 15:49:10] [config] ulr-softmax-temperature: 1
[2019-08-07 15:49:10] [config] ulr-trainable-transformation: false
[2019-08-07 15:49:10] [config] valid-freq: 20000
[2019-08-07 15:49:10] [config] valid-log: ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/valid.log
[2019-08-07 15:49:10] [config] valid-max-length: 1000
[2019-08-07 15:49:10] [config] valid-metrics:
[2019-08-07 15:49:10] [config]   - cross-entropy
[2019-08-07 15:49:10] [config]   - perplexity
[2019-08-07 15:49:10] [config]   - translation
[2019-08-07 15:49:10] [config] valid-mini-batch: 8
[2019-08-07 15:49:10] [config] valid-script-path: ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/score-dev.sh
[2019-08-07 15:49:10] [config] valid-sets:
[2019-08-07 15:49:10] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/dev.bpe.de
[2019-08-07 15:49:10] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/dev.bpe.en
[2019-08-07 15:49:10] [config] valid-translation-output: ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/dev.out
[2019-08-07 15:49:10] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 15:49:10] [config] vocabs:
[2019-08-07 15:49:10] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.de.json
[2019-08-07 15:49:10] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.en.json
[2019-08-07 15:49:10] [config] word-penalty: 0
[2019-08-07 15:49:10] [config] workspace: 3000
[2019-08-07 15:49:10] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 15:49:10] Using synchronous training
[2019-08-07 15:49:10] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.de.json
[2019-08-07 15:49:11] [data] Using unused word id eos for 0
[2019-08-07 15:49:11] [data] Using unused word id UNK for 1
[2019-08-07 15:49:11] [data] Setting vocabulary size for input 0 to 50000
[2019-08-07 15:49:11] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/data/train.bpe.en.json
[2019-08-07 15:49:11] [data] Using unused word id eos for 0
[2019-08-07 15:49:11] [data] Using unused word id UNK for 1
[2019-08-07 15:49:11] [data] Setting vocabulary size for input 1 to 50000
[2019-08-07 15:49:11] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-07 15:49:11] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-07 15:49:12] [memory] Extending reserved space to 3072 MB (device gpu2)
[2019-08-07 15:49:12] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 15:49:12] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 15:49:12] [training] Using 1 GPUs
[2019-08-07 15:49:12] [memory] Reserving 422 MB, device gpu2
[2019-08-07 15:49:12] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-07 15:49:12] [memory] Reserving 422 MB, device gpu2
[2019-08-07 15:49:17] [batching] Done. Typical MB size is 4042 target words
[2019-08-07 15:49:17] [memory] Extending reserved space to 3072 MB (device gpu2)
[2019-08-07 15:49:17] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 15:49:17] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 15:49:17] [training] Using 1 GPUs
[2019-08-07 15:49:17] Loading model from ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.orig.npz
[2019-08-07 15:49:24] Loading Adam parameters from ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz.optimizer.npz
[2019-08-07 15:49:35] [memory] Reserving 844 MB, device gpu2
[2019-08-07 15:49:36] [training] Model reloaded from ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-07 15:49:36] [data] Restoring the corpus state to epoch 16, batch 540000
[2019-08-07 15:49:36] [data] Shuffling data
[2019-08-07 15:49:50] [data] Done reading 4189884 sentences
[2019-08-07 15:50:11] [data] Done shuffling 4189884 sentences to temp files
[2019-08-07 15:51:56] Training started
[2019-08-07 15:51:56] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-07 15:51:56] [memory] Reserving 422 MB, device gpu2
[2019-08-07 15:51:56] [memory] Reserving 422 MB, device gpu2
[2019-08-07 15:51:56] Loading model from ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_bic1.1_x_dcce/model/model.npz
[2019-08-07 15:52:06] [memory] Reserving 422 MB, device cpu0
[2019-08-07 15:52:06] [memory] Reserving 422 MB, device gpu2
