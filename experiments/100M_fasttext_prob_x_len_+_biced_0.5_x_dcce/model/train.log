[2019-08-05 15:50:58] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-05 15:50:58] [marian] Running on fulla as process 138213 with command line:
[2019-08-05 15:50:58] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz -T . --devices 3 --train-sets ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/train.bpe.de ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/train.bpe.en --vocabs ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/train.bpe.de.json ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/dev.bpe.de ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/dev.out --valid-script-path ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/train.log --valid-log ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/valid.log
[2019-08-05 15:50:58] [config] after-batches: 0
[2019-08-05 15:50:58] [config] after-epochs: 0
[2019-08-05 15:50:58] [config] allow-unk: false
[2019-08-05 15:50:58] [config] beam-size: 12
[2019-08-05 15:50:58] [config] bert-class-symbol: "[CLS]"
[2019-08-05 15:50:58] [config] bert-mask-symbol: "[MASK]"
[2019-08-05 15:50:58] [config] bert-masking-fraction: 0.15
[2019-08-05 15:50:58] [config] bert-sep-symbol: "[SEP]"
[2019-08-05 15:50:58] [config] bert-train-type-embeddings: true
[2019-08-05 15:50:58] [config] bert-type-vocab-size: 2
[2019-08-05 15:50:58] [config] best-deep: false
[2019-08-05 15:50:58] [config] clip-gemm: 0
[2019-08-05 15:50:58] [config] clip-norm: 1
[2019-08-05 15:50:58] [config] cost-type: ce-mean
[2019-08-05 15:50:58] [config] cpu-threads: 0
[2019-08-05 15:50:58] [config] data-weighting: ""
[2019-08-05 15:50:58] [config] data-weighting-type: sentence
[2019-08-05 15:50:58] [config] dec-cell: gru
[2019-08-05 15:50:58] [config] dec-cell-base-depth: 2
[2019-08-05 15:50:58] [config] dec-cell-high-depth: 1
[2019-08-05 15:50:58] [config] dec-depth: 1
[2019-08-05 15:50:58] [config] devices:
[2019-08-05 15:50:58] [config]   - 3
[2019-08-05 15:50:58] [config] dim-emb: 512
[2019-08-05 15:50:58] [config] dim-rnn: 1024
[2019-08-05 15:50:58] [config] dim-vocabs:
[2019-08-05 15:50:58] [config]   - 50000
[2019-08-05 15:50:58] [config]   - 50000
[2019-08-05 15:50:58] [config] disp-first: 0
[2019-08-05 15:50:58] [config] disp-freq: 2000
[2019-08-05 15:50:58] [config] disp-label-counts: false
[2019-08-05 15:50:58] [config] dropout-rnn: 0.2
[2019-08-05 15:50:58] [config] dropout-src: 0.1
[2019-08-05 15:50:58] [config] dropout-trg: 0.1
[2019-08-05 15:50:58] [config] dump-config: ""
[2019-08-05 15:50:58] [config] early-stopping: 5
[2019-08-05 15:50:58] [config] embedding-fix-src: false
[2019-08-05 15:50:58] [config] embedding-fix-trg: false
[2019-08-05 15:50:58] [config] embedding-normalization: false
[2019-08-05 15:50:58] [config] embedding-vectors:
[2019-08-05 15:50:58] [config]   []
[2019-08-05 15:50:58] [config] enc-cell: gru
[2019-08-05 15:50:58] [config] enc-cell-depth: 1
[2019-08-05 15:50:58] [config] enc-depth: 1
[2019-08-05 15:50:58] [config] enc-type: bidirectional
[2019-08-05 15:50:58] [config] exponential-smoothing: 0.0001
[2019-08-05 15:50:58] [config] grad-dropping-momentum: 0
[2019-08-05 15:50:58] [config] grad-dropping-rate: 0
[2019-08-05 15:50:58] [config] grad-dropping-warmup: 100
[2019-08-05 15:50:58] [config] guided-alignment: none
[2019-08-05 15:50:58] [config] guided-alignment-cost: mse
[2019-08-05 15:50:58] [config] guided-alignment-weight: 0.1
[2019-08-05 15:50:58] [config] ignore-model-config: false
[2019-08-05 15:50:58] [config] input-types:
[2019-08-05 15:50:58] [config]   []
[2019-08-05 15:50:58] [config] interpolate-env-vars: false
[2019-08-05 15:50:58] [config] keep-best: false
[2019-08-05 15:50:58] [config] label-smoothing: 0
[2019-08-05 15:50:58] [config] layer-normalization: true
[2019-08-05 15:50:58] [config] learn-rate: 0.0001
[2019-08-05 15:50:58] [config] log: ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/train.log
[2019-08-05 15:50:58] [config] log-level: info
[2019-08-05 15:50:58] [config] log-time-zone: ""
[2019-08-05 15:50:58] [config] lr-decay: 0
[2019-08-05 15:50:58] [config] lr-decay-freq: 50000
[2019-08-05 15:50:58] [config] lr-decay-inv-sqrt:
[2019-08-05 15:50:58] [config]   - 0
[2019-08-05 15:50:58] [config] lr-decay-repeat-warmup: false
[2019-08-05 15:50:58] [config] lr-decay-reset-optimizer: false
[2019-08-05 15:50:58] [config] lr-decay-start:
[2019-08-05 15:50:58] [config]   - 10
[2019-08-05 15:50:58] [config]   - 1
[2019-08-05 15:50:58] [config] lr-decay-strategy: epoch+stalled
[2019-08-05 15:50:58] [config] lr-report: false
[2019-08-05 15:50:58] [config] lr-warmup: 0
[2019-08-05 15:50:58] [config] lr-warmup-at-reload: false
[2019-08-05 15:50:58] [config] lr-warmup-cycle: false
[2019-08-05 15:50:58] [config] lr-warmup-start-rate: 0
[2019-08-05 15:50:58] [config] max-length: 50
[2019-08-05 15:50:58] [config] max-length-crop: false
[2019-08-05 15:50:58] [config] max-length-factor: 3
[2019-08-05 15:50:58] [config] maxi-batch: 100
[2019-08-05 15:50:58] [config] maxi-batch-sort: trg
[2019-08-05 15:50:58] [config] mini-batch: 64
[2019-08-05 15:50:58] [config] mini-batch-fit: true
[2019-08-05 15:50:58] [config] mini-batch-fit-step: 10
[2019-08-05 15:50:58] [config] mini-batch-overstuff: 1
[2019-08-05 15:50:58] [config] mini-batch-track-lr: false
[2019-08-05 15:50:58] [config] mini-batch-understuff: 1
[2019-08-05 15:50:58] [config] mini-batch-warmup: 0
[2019-08-05 15:50:58] [config] mini-batch-words: 0
[2019-08-05 15:50:58] [config] mini-batch-words-ref: 0
[2019-08-05 15:50:58] [config] model: ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-05 15:50:58] [config] multi-loss-type: sum
[2019-08-05 15:50:58] [config] multi-node: false
[2019-08-05 15:50:58] [config] multi-node-overlap: true
[2019-08-05 15:50:58] [config] n-best: false
[2019-08-05 15:50:58] [config] no-nccl: false
[2019-08-05 15:50:58] [config] no-reload: false
[2019-08-05 15:50:58] [config] no-restore-corpus: false
[2019-08-05 15:50:58] [config] no-shuffle: false
[2019-08-05 15:50:58] [config] normalize: 1
[2019-08-05 15:50:58] [config] num-devices: 0
[2019-08-05 15:50:58] [config] optimizer: adam
[2019-08-05 15:50:58] [config] optimizer-delay: 1
[2019-08-05 15:50:58] [config] optimizer-params:
[2019-08-05 15:50:58] [config]   []
[2019-08-05 15:50:58] [config] overwrite: false
[2019-08-05 15:50:58] [config] pretrained-model: ""
[2019-08-05 15:50:58] [config] quiet: false
[2019-08-05 15:50:58] [config] quiet-translation: true
[2019-08-05 15:50:58] [config] relative-paths: false
[2019-08-05 15:50:58] [config] right-left: false
[2019-08-05 15:50:58] [config] save-freq: 20000
[2019-08-05 15:50:58] [config] seed: 1111
[2019-08-05 15:50:58] [config] shuffle-in-ram: false
[2019-08-05 15:50:58] [config] skip: false
[2019-08-05 15:50:58] [config] sqlite: ""
[2019-08-05 15:50:58] [config] sqlite-drop: false
[2019-08-05 15:50:58] [config] sync-sgd: true
[2019-08-05 15:50:58] [config] tempdir: .
[2019-08-05 15:50:58] [config] tied-embeddings: false
[2019-08-05 15:50:58] [config] tied-embeddings-all: false
[2019-08-05 15:50:58] [config] tied-embeddings-src: false
[2019-08-05 15:50:58] [config] train-sets:
[2019-08-05 15:50:58] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/train.bpe.de
[2019-08-05 15:50:58] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/train.bpe.en
[2019-08-05 15:50:58] [config] transformer-aan-activation: swish
[2019-08-05 15:50:58] [config] transformer-aan-depth: 2
[2019-08-05 15:50:58] [config] transformer-aan-nogate: false
[2019-08-05 15:50:58] [config] transformer-decoder-autoreg: self-attention
[2019-08-05 15:50:58] [config] transformer-dim-aan: 2048
[2019-08-05 15:50:58] [config] transformer-dim-ffn: 2048
[2019-08-05 15:50:58] [config] transformer-dropout: 0
[2019-08-05 15:50:58] [config] transformer-dropout-attention: 0
[2019-08-05 15:50:58] [config] transformer-dropout-ffn: 0
[2019-08-05 15:50:58] [config] transformer-ffn-activation: swish
[2019-08-05 15:50:58] [config] transformer-ffn-depth: 2
[2019-08-05 15:50:58] [config] transformer-guided-alignment-layer: last
[2019-08-05 15:50:58] [config] transformer-heads: 8
[2019-08-05 15:50:58] [config] transformer-no-projection: false
[2019-08-05 15:50:58] [config] transformer-postprocess: dan
[2019-08-05 15:50:58] [config] transformer-postprocess-emb: d
[2019-08-05 15:50:58] [config] transformer-preprocess: ""
[2019-08-05 15:50:58] [config] transformer-tied-layers:
[2019-08-05 15:50:58] [config]   []
[2019-08-05 15:50:58] [config] transformer-train-position-embeddings: false
[2019-08-05 15:50:58] [config] type: amun
[2019-08-05 15:50:58] [config] ulr: false
[2019-08-05 15:50:58] [config] ulr-dim-emb: 0
[2019-08-05 15:50:58] [config] ulr-dropout: 0
[2019-08-05 15:50:58] [config] ulr-keys-vectors: ""
[2019-08-05 15:50:58] [config] ulr-query-vectors: ""
[2019-08-05 15:50:58] [config] ulr-softmax-temperature: 1
[2019-08-05 15:50:58] [config] ulr-trainable-transformation: false
[2019-08-05 15:50:58] [config] valid-freq: 20000
[2019-08-05 15:50:58] [config] valid-log: ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/valid.log
[2019-08-05 15:50:58] [config] valid-max-length: 1000
[2019-08-05 15:50:58] [config] valid-metrics:
[2019-08-05 15:50:58] [config]   - cross-entropy
[2019-08-05 15:50:58] [config]   - perplexity
[2019-08-05 15:50:58] [config]   - translation
[2019-08-05 15:50:58] [config] valid-mini-batch: 8
[2019-08-05 15:50:58] [config] valid-script-path: ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/score-dev.sh
[2019-08-05 15:50:58] [config] valid-sets:
[2019-08-05 15:50:58] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/dev.bpe.de
[2019-08-05 15:50:58] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/dev.bpe.en
[2019-08-05 15:50:58] [config] valid-translation-output: ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/dev.out
[2019-08-05 15:50:58] [config] vocabs:
[2019-08-05 15:50:58] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/train.bpe.de.json
[2019-08-05 15:50:58] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/train.bpe.en.json
[2019-08-05 15:50:58] [config] word-penalty: 0
[2019-08-05 15:50:58] [config] workspace: 3000
[2019-08-05 15:50:58] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-05 15:50:58] Using synchronous training
[2019-08-05 15:50:58] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/train.bpe.de.json
[2019-08-05 15:50:58] [data] Using unused word id eos for 0
[2019-08-05 15:50:58] [data] Using unused word id UNK for 1
[2019-08-05 15:50:58] [data] Setting vocabulary size for input 0 to 50000
[2019-08-05 15:50:58] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/train.bpe.en.json
[2019-08-05 15:50:58] [data] Using unused word id eos for 0
[2019-08-05 15:50:58] [data] Using unused word id UNK for 1
[2019-08-05 15:50:58] [data] Setting vocabulary size for input 1 to 50000
[2019-08-05 15:50:58] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-05 15:50:58] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-05 15:51:00] [memory] Extending reserved space to 3072 MB (device gpu3)
[2019-08-05 15:51:00] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-05 15:51:00] [comm] NCCLCommunicator constructed successfully.
[2019-08-05 15:51:00] [training] Using 1 GPUs
[2019-08-05 15:51:00] [memory] Reserving 422 MB, device gpu3
[2019-08-05 15:51:00] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-05 15:51:00] [memory] Reserving 422 MB, device gpu3
[2019-08-05 15:51:06] [batching] Done. Typical MB size is 4042 target words
[2019-08-05 15:51:06] [memory] Extending reserved space to 3072 MB (device gpu3)
[2019-08-05 15:51:06] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-05 15:51:06] [comm] NCCLCommunicator constructed successfully.
[2019-08-05 15:51:06] [training] Using 1 GPUs
[2019-08-05 15:51:06] Training started
[2019-08-05 15:51:06] [data] Shuffling data
[2019-08-05 15:51:10] [data] Done reading 5059895 sentences
[2019-08-05 15:51:33] [data] Done shuffling 5059895 sentences to temp files
[2019-08-05 15:51:55] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-05 15:51:55] [memory] Reserving 422 MB, device gpu3
[2019-08-05 15:51:55] [memory] Reserving 422 MB, device gpu3
[2019-08-05 15:51:55] [memory] Reserving 422 MB, device gpu3
[2019-08-05 15:51:55] [memory] Reserving 844 MB, device gpu3
[2019-08-05 16:04:31] Ep. 1 : Up. 2000 : Sen. 201,502 : Cost 133.58508301 : Time 812.57s : 5441.03 words/s
[2019-08-05 16:17:03] Ep. 1 : Up. 4000 : Sen. 402,392 : Cost 108.33274078 : Time 752.56s : 5824.94 words/s
[2019-08-05 16:28:11] Ep. 1 : Up. 6000 : Sen. 603,412 : Cost 96.76021576 : Time 667.13s : 6603.87 words/s
[2019-08-05 16:33:25] Ep. 1 : Up. 8000 : Sen. 805,075 : Cost 88.00578308 : Time 314.81s : 13997.58 words/s
[2019-08-05 16:38:40] Ep. 1 : Up. 10000 : Sen. 1,005,961 : Cost 82.16535187 : Time 314.98s : 13977.70 words/s
[2019-08-05 16:43:54] Ep. 1 : Up. 12000 : Sen. 1,206,776 : Cost 77.37131500 : Time 314.07s : 13960.62 words/s
[2019-08-05 16:49:11] Ep. 1 : Up. 14000 : Sen. 1,408,078 : Cost 74.32394409 : Time 316.18s : 13941.25 words/s
[2019-08-05 16:54:27] Ep. 1 : Up. 16000 : Sen. 1,608,886 : Cost 71.97195435 : Time 315.89s : 13947.70 words/s
[2019-08-05 16:59:42] Ep. 1 : Up. 18000 : Sen. 1,809,055 : Cost 69.96463776 : Time 315.09s : 13937.13 words/s
[2019-08-05 17:04:57] Ep. 1 : Up. 20000 : Sen. 2,010,038 : Cost 68.07788849 : Time 315.73s : 13929.45 words/s
[2019-08-05 17:04:57] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-05 17:05:07] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter20000.npz
[2019-08-05 17:05:16] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-05 17:05:27] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-05 17:05:53] [valid] Ep. 1 : Up. 20000 : cross-entropy : 77.0828 : new best
[2019-08-05 17:05:59] [valid] Ep. 1 : Up. 20000 : perplexity : 21.0196 : new best
[2019-08-05 17:06:56] [valid] Ep. 1 : Up. 20000 : translation : 20.63 : new best
[2019-08-05 17:12:13] Ep. 1 : Up. 22000 : Sen. 2,210,970 : Cost 66.43064880 : Time 435.67s : 10098.90 words/s
[2019-08-05 17:17:29] Ep. 1 : Up. 24000 : Sen. 2,412,125 : Cost 65.28513336 : Time 316.17s : 13932.91 words/s
[2019-08-05 17:22:45] Ep. 1 : Up. 26000 : Sen. 2,612,889 : Cost 64.35875702 : Time 316.29s : 13921.36 words/s
[2019-08-05 17:28:02] Ep. 1 : Up. 28000 : Sen. 2,815,300 : Cost 63.31194305 : Time 316.58s : 13970.16 words/s
[2019-08-05 17:33:19] Ep. 1 : Up. 30000 : Sen. 3,015,949 : Cost 62.85815048 : Time 317.06s : 13935.14 words/s
[2019-08-05 17:38:36] Ep. 1 : Up. 32000 : Sen. 3,217,012 : Cost 61.54544449 : Time 316.46s : 13909.52 words/s
[2019-08-05 17:43:52] Ep. 1 : Up. 34000 : Sen. 3,418,882 : Cost 60.79216003 : Time 316.73s : 13968.22 words/s
[2019-08-05 17:49:09] Ep. 1 : Up. 36000 : Sen. 3,620,618 : Cost 60.39935303 : Time 316.95s : 13936.47 words/s
[2019-08-05 17:54:26] Ep. 1 : Up. 38000 : Sen. 3,822,562 : Cost 59.84487915 : Time 316.89s : 13961.22 words/s
[2019-08-05 17:59:42] Ep. 1 : Up. 40000 : Sen. 4,024,098 : Cost 58.97918320 : Time 316.04s : 13963.21 words/s
[2019-08-05 17:59:42] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-05 17:59:52] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter40000.npz
[2019-08-05 17:59:59] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-05 18:00:09] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-05 18:00:37] [valid] Ep. 1 : Up. 40000 : cross-entropy : 64.0216 : new best
[2019-08-05 18:00:43] [valid] Ep. 1 : Up. 40000 : perplexity : 12.5462 : new best
[2019-08-05 18:01:34] [valid] Ep. 1 : Up. 40000 : translation : 25.27 : new best
[2019-08-05 18:06:34] Seen 4212135 samples
[2019-08-05 18:06:34] Starting epoch 2
[2019-08-05 18:06:34] [data] Shuffling data
[2019-08-05 18:06:37] [data] Done reading 5059895 sentences
[2019-08-05 18:07:01] [data] Done shuffling 5059895 sentences to temp files
[2019-08-05 18:07:28] Ep. 2 : Up. 42000 : Sen. 11,088 : Cost 58.94849396 : Time 465.86s : 9371.40 words/s
[2019-08-05 18:12:44] Ep. 2 : Up. 44000 : Sen. 212,157 : Cost 57.00558472 : Time 315.97s : 13916.03 words/s
[2019-08-05 18:18:01] Ep. 2 : Up. 46000 : Sen. 413,559 : Cost 57.14517593 : Time 317.24s : 13916.07 words/s
[2019-08-05 18:23:18] Ep. 2 : Up. 48000 : Sen. 615,146 : Cost 56.31244659 : Time 316.52s : 13923.23 words/s
[2019-08-05 18:28:34] Ep. 2 : Up. 50000 : Sen. 816,146 : Cost 56.17823029 : Time 315.93s : 13911.02 words/s
[2019-08-05 18:33:50] Ep. 2 : Up. 52000 : Sen. 1,016,747 : Cost 56.21349716 : Time 316.16s : 13922.76 words/s
[2019-08-05 18:39:07] Ep. 2 : Up. 54000 : Sen. 1,218,844 : Cost 55.62334061 : Time 317.28s : 13953.87 words/s
[2019-08-05 18:44:22] Ep. 2 : Up. 56000 : Sen. 1,419,558 : Cost 55.66705322 : Time 315.19s : 13958.48 words/s
[2019-08-05 18:49:38] Ep. 2 : Up. 58000 : Sen. 1,621,263 : Cost 55.01616669 : Time 316.08s : 13947.75 words/s
[2019-08-05 18:54:55] Ep. 2 : Up. 60000 : Sen. 1,823,232 : Cost 54.73316574 : Time 316.18s : 13958.58 words/s
[2019-08-05 18:54:55] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-05 18:55:04] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter60000.npz
[2019-08-05 18:55:11] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-05 18:55:21] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-05 18:55:49] [valid] Ep. 2 : Up. 60000 : cross-entropy : 58.8166 : new best
[2019-08-05 18:55:55] [valid] Ep. 2 : Up. 60000 : perplexity : 10.2142 : new best
[2019-08-05 18:56:45] [valid] Ep. 2 : Up. 60000 : translation : 26.79 : new best
[2019-08-05 19:02:02] Ep. 2 : Up. 62000 : Sen. 2,023,560 : Cost 54.99472427 : Time 427.84s : 10287.49 words/s
[2019-08-05 19:07:17] Ep. 2 : Up. 64000 : Sen. 2,224,754 : Cost 54.04895782 : Time 314.19s : 13958.40 words/s
[2019-08-05 19:12:33] Ep. 2 : Up. 66000 : Sen. 2,426,757 : Cost 54.04547501 : Time 316.09s : 14018.62 words/s
[2019-08-05 19:17:49] Ep. 2 : Up. 68000 : Sen. 2,628,398 : Cost 53.96692657 : Time 316.56s : 13972.92 words/s
[2019-08-05 19:23:05] Ep. 2 : Up. 70000 : Sen. 2,830,614 : Cost 53.58845901 : Time 315.60s : 14001.29 words/s
[2019-08-05 19:28:20] Ep. 2 : Up. 72000 : Sen. 3,032,099 : Cost 53.60277557 : Time 315.28s : 13969.47 words/s
[2019-08-05 19:33:36] Ep. 2 : Up. 74000 : Sen. 3,233,431 : Cost 53.35135651 : Time 315.79s : 13956.84 words/s
[2019-08-05 19:38:52] Ep. 2 : Up. 76000 : Sen. 3,434,633 : Cost 53.31576157 : Time 315.76s : 13976.40 words/s
[2019-08-05 19:44:07] Ep. 2 : Up. 78000 : Sen. 3,634,467 : Cost 53.28701782 : Time 314.91s : 13944.18 words/s
[2019-08-05 19:46:33] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-05 19:46:33] [marian] Running on fulla as process 160093 with command line:
[2019-08-05 19:46:33] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz -T . --devices 2 --train-sets ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/train.bpe.de ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/train.bpe.en --vocabs ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/train.bpe.de.json ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/dev.bpe.de ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/dev.out --valid-script-path ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/train.log --valid-log ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/valid.log
[2019-08-05 19:46:33] [config] after-batches: 0
[2019-08-05 19:46:33] [config] after-epochs: 0
[2019-08-05 19:46:33] [config] allow-unk: false
[2019-08-05 19:46:33] [config] beam-size: 12
[2019-08-05 19:46:33] [config] bert-class-symbol: "[CLS]"
[2019-08-05 19:46:33] [config] bert-mask-symbol: "[MASK]"
[2019-08-05 19:46:33] [config] bert-masking-fraction: 0.15
[2019-08-05 19:46:33] [config] bert-sep-symbol: "[SEP]"
[2019-08-05 19:46:33] [config] bert-train-type-embeddings: true
[2019-08-05 19:46:33] [config] bert-type-vocab-size: 2
[2019-08-05 19:46:33] [config] best-deep: false
[2019-08-05 19:46:33] [config] clip-gemm: 0
[2019-08-05 19:46:33] [config] clip-norm: 1
[2019-08-05 19:46:33] [config] cost-type: ce-mean
[2019-08-05 19:46:33] [config] cpu-threads: 0
[2019-08-05 19:46:33] [config] data-weighting: ""
[2019-08-05 19:46:33] [config] data-weighting-type: sentence
[2019-08-05 19:46:33] [config] dec-cell: gru
[2019-08-05 19:46:33] [config] dec-cell-base-depth: 2
[2019-08-05 19:46:33] [config] dec-cell-high-depth: 1
[2019-08-05 19:46:33] [config] dec-depth: 1
[2019-08-05 19:46:33] [config] devices:
[2019-08-05 19:46:33] [config]   - 2
[2019-08-05 19:46:33] [config] dim-emb: 512
[2019-08-05 19:46:33] [config] dim-rnn: 1024
[2019-08-05 19:46:33] [config] dim-vocabs:
[2019-08-05 19:46:33] [config]   - 50000
[2019-08-05 19:46:33] [config]   - 50000
[2019-08-05 19:46:33] [config] disp-first: 0
[2019-08-05 19:46:33] [config] disp-freq: 2000
[2019-08-05 19:46:33] [config] disp-label-counts: false
[2019-08-05 19:46:33] [config] dropout-rnn: 0.2
[2019-08-05 19:46:33] [config] dropout-src: 0.1
[2019-08-05 19:46:33] [config] dropout-trg: 0.1
[2019-08-05 19:46:33] [config] dump-config: ""
[2019-08-05 19:46:33] [config] early-stopping: 5
[2019-08-05 19:46:33] [config] embedding-fix-src: false
[2019-08-05 19:46:33] [config] embedding-fix-trg: false
[2019-08-05 19:46:33] [config] embedding-normalization: false
[2019-08-05 19:46:33] [config] embedding-vectors:
[2019-08-05 19:46:33] [config]   []
[2019-08-05 19:46:33] [config] enc-cell: gru
[2019-08-05 19:46:33] [config] enc-cell-depth: 1
[2019-08-05 19:46:33] [config] enc-depth: 1
[2019-08-05 19:46:33] [config] enc-type: bidirectional
[2019-08-05 19:46:33] [config] exponential-smoothing: 0.0001
[2019-08-05 19:46:33] [config] grad-dropping-momentum: 0
[2019-08-05 19:46:33] [config] grad-dropping-rate: 0
[2019-08-05 19:46:33] [config] grad-dropping-warmup: 100
[2019-08-05 19:46:33] [config] guided-alignment: none
[2019-08-05 19:46:33] [config] guided-alignment-cost: mse
[2019-08-05 19:46:33] [config] guided-alignment-weight: 0.1
[2019-08-05 19:46:33] [config] ignore-model-config: false
[2019-08-05 19:46:33] [config] input-types:
[2019-08-05 19:46:33] [config]   []
[2019-08-05 19:46:33] [config] interpolate-env-vars: false
[2019-08-05 19:46:33] [config] keep-best: false
[2019-08-05 19:46:33] [config] label-smoothing: 0
[2019-08-05 19:46:33] [config] layer-normalization: true
[2019-08-05 19:46:33] [config] learn-rate: 0.0001
[2019-08-05 19:46:33] [config] log: ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/train.log
[2019-08-05 19:46:33] [config] log-level: info
[2019-08-05 19:46:33] [config] log-time-zone: ""
[2019-08-05 19:46:33] [config] lr-decay: 0
[2019-08-05 19:46:33] [config] lr-decay-freq: 50000
[2019-08-05 19:46:33] [config] lr-decay-inv-sqrt:
[2019-08-05 19:46:33] [config]   - 0
[2019-08-05 19:46:33] [config] lr-decay-repeat-warmup: false
[2019-08-05 19:46:33] [config] lr-decay-reset-optimizer: false
[2019-08-05 19:46:33] [config] lr-decay-start:
[2019-08-05 19:46:33] [config]   - 10
[2019-08-05 19:46:33] [config]   - 1
[2019-08-05 19:46:33] [config] lr-decay-strategy: epoch+stalled
[2019-08-05 19:46:33] [config] lr-report: false
[2019-08-05 19:46:33] [config] lr-warmup: 0
[2019-08-05 19:46:33] [config] lr-warmup-at-reload: false
[2019-08-05 19:46:33] [config] lr-warmup-cycle: false
[2019-08-05 19:46:33] [config] lr-warmup-start-rate: 0
[2019-08-05 19:46:33] [config] max-length: 50
[2019-08-05 19:46:33] [config] max-length-crop: false
[2019-08-05 19:46:33] [config] max-length-factor: 3
[2019-08-05 19:46:33] [config] maxi-batch: 100
[2019-08-05 19:46:33] [config] maxi-batch-sort: trg
[2019-08-05 19:46:33] [config] mini-batch: 64
[2019-08-05 19:46:33] [config] mini-batch-fit: true
[2019-08-05 19:46:33] [config] mini-batch-fit-step: 10
[2019-08-05 19:46:33] [config] mini-batch-overstuff: 1
[2019-08-05 19:46:33] [config] mini-batch-track-lr: false
[2019-08-05 19:46:33] [config] mini-batch-understuff: 1
[2019-08-05 19:46:33] [config] mini-batch-warmup: 0
[2019-08-05 19:46:33] [config] mini-batch-words: 0
[2019-08-05 19:46:33] [config] mini-batch-words-ref: 0
[2019-08-05 19:46:33] [config] model: ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-05 19:46:33] [config] multi-loss-type: sum
[2019-08-05 19:46:33] [config] multi-node: false
[2019-08-05 19:46:33] [config] multi-node-overlap: true
[2019-08-05 19:46:33] [config] n-best: false
[2019-08-05 19:46:33] [config] no-nccl: false
[2019-08-05 19:46:33] [config] no-reload: false
[2019-08-05 19:46:33] [config] no-restore-corpus: false
[2019-08-05 19:46:33] [config] no-shuffle: false
[2019-08-05 19:46:33] [config] normalize: 1
[2019-08-05 19:46:33] [config] num-devices: 0
[2019-08-05 19:46:33] [config] optimizer: adam
[2019-08-05 19:46:33] [config] optimizer-delay: 1
[2019-08-05 19:46:33] [config] optimizer-params:
[2019-08-05 19:46:33] [config]   []
[2019-08-05 19:46:33] [config] overwrite: false
[2019-08-05 19:46:33] [config] pretrained-model: ""
[2019-08-05 19:46:33] [config] quiet: false
[2019-08-05 19:46:33] [config] quiet-translation: true
[2019-08-05 19:46:33] [config] relative-paths: false
[2019-08-05 19:46:33] [config] right-left: false
[2019-08-05 19:46:33] [config] save-freq: 20000
[2019-08-05 19:46:33] [config] seed: 1111
[2019-08-05 19:46:33] [config] shuffle-in-ram: false
[2019-08-05 19:46:33] [config] skip: false
[2019-08-05 19:46:33] [config] sqlite: ""
[2019-08-05 19:46:33] [config] sqlite-drop: false
[2019-08-05 19:46:33] [config] sync-sgd: true
[2019-08-05 19:46:33] [config] tempdir: .
[2019-08-05 19:46:33] [config] tied-embeddings: false
[2019-08-05 19:46:33] [config] tied-embeddings-all: false
[2019-08-05 19:46:33] [config] tied-embeddings-src: false
[2019-08-05 19:46:33] [config] train-sets:
[2019-08-05 19:46:33] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/train.bpe.de
[2019-08-05 19:46:33] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/train.bpe.en
[2019-08-05 19:46:33] [config] transformer-aan-activation: swish
[2019-08-05 19:46:33] [config] transformer-aan-depth: 2
[2019-08-05 19:46:33] [config] transformer-aan-nogate: false
[2019-08-05 19:46:33] [config] transformer-decoder-autoreg: self-attention
[2019-08-05 19:46:33] [config] transformer-dim-aan: 2048
[2019-08-05 19:46:33] [config] transformer-dim-ffn: 2048
[2019-08-05 19:46:33] [config] transformer-dropout: 0
[2019-08-05 19:46:33] [config] transformer-dropout-attention: 0
[2019-08-05 19:46:33] [config] transformer-dropout-ffn: 0
[2019-08-05 19:46:33] [config] transformer-ffn-activation: swish
[2019-08-05 19:46:33] [config] transformer-ffn-depth: 2
[2019-08-05 19:46:33] [config] transformer-guided-alignment-layer: last
[2019-08-05 19:46:33] [config] transformer-heads: 8
[2019-08-05 19:46:33] [config] transformer-no-projection: false
[2019-08-05 19:46:33] [config] transformer-postprocess: dan
[2019-08-05 19:46:33] [config] transformer-postprocess-emb: d
[2019-08-05 19:46:33] [config] transformer-preprocess: ""
[2019-08-05 19:46:33] [config] transformer-tied-layers:
[2019-08-05 19:46:33] [config]   []
[2019-08-05 19:46:33] [config] transformer-train-position-embeddings: false
[2019-08-05 19:46:33] [config] type: amun
[2019-08-05 19:46:33] [config] ulr: false
[2019-08-05 19:46:33] [config] ulr-dim-emb: 0
[2019-08-05 19:46:33] [config] ulr-dropout: 0
[2019-08-05 19:46:33] [config] ulr-keys-vectors: ""
[2019-08-05 19:46:33] [config] ulr-query-vectors: ""
[2019-08-05 19:46:33] [config] ulr-softmax-temperature: 1
[2019-08-05 19:46:33] [config] ulr-trainable-transformation: false
[2019-08-05 19:46:33] [config] valid-freq: 20000
[2019-08-05 19:46:33] [config] valid-log: ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/valid.log
[2019-08-05 19:46:33] [config] valid-max-length: 1000
[2019-08-05 19:46:33] [config] valid-metrics:
[2019-08-05 19:46:33] [config]   - cross-entropy
[2019-08-05 19:46:33] [config]   - perplexity
[2019-08-05 19:46:33] [config]   - translation
[2019-08-05 19:46:33] [config] valid-mini-batch: 8
[2019-08-05 19:46:33] [config] valid-script-path: ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/score-dev.sh
[2019-08-05 19:46:33] [config] valid-sets:
[2019-08-05 19:46:33] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/dev.bpe.de
[2019-08-05 19:46:33] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/dev.bpe.en
[2019-08-05 19:46:33] [config] valid-translation-output: ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/dev.out
[2019-08-05 19:46:33] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-05 19:46:33] [config] vocabs:
[2019-08-05 19:46:33] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/train.bpe.de.json
[2019-08-05 19:46:33] [config]   - ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/train.bpe.en.json
[2019-08-05 19:46:33] [config] word-penalty: 0
[2019-08-05 19:46:33] [config] workspace: 3000
[2019-08-05 19:46:33] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-05 19:46:33] Using synchronous training
[2019-08-05 19:46:33] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/train.bpe.de.json
[2019-08-05 19:46:34] [data] Using unused word id eos for 0
[2019-08-05 19:46:34] [data] Using unused word id UNK for 1
[2019-08-05 19:46:34] [data] Setting vocabulary size for input 0 to 50000
[2019-08-05 19:46:34] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/data/train.bpe.en.json
[2019-08-05 19:46:34] [data] Using unused word id eos for 0
[2019-08-05 19:46:34] [data] Using unused word id UNK for 1
[2019-08-05 19:46:34] [data] Setting vocabulary size for input 1 to 50000
[2019-08-05 19:46:34] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-05 19:46:34] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-05 19:46:35] [memory] Extending reserved space to 3072 MB (device gpu2)
[2019-08-05 19:46:36] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-05 19:46:36] [comm] NCCLCommunicator constructed successfully.
[2019-08-05 19:46:36] [training] Using 1 GPUs
[2019-08-05 19:46:36] [memory] Reserving 422 MB, device gpu2
[2019-08-05 19:46:36] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-05 19:46:36] [memory] Reserving 422 MB, device gpu2
[2019-08-05 19:46:41] [batching] Done. Typical MB size is 4042 target words
[2019-08-05 19:46:41] [memory] Extending reserved space to 3072 MB (device gpu2)
[2019-08-05 19:46:41] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-05 19:46:41] [comm] NCCLCommunicator constructed successfully.
[2019-08-05 19:46:41] [training] Using 1 GPUs
[2019-08-05 19:46:41] Loading model from ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-05 19:46:48] Loading Adam parameters from ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-05 19:49:23] Ep. 2 : Up. 80000 : Sen. 3,836,231 : Cost 52.70859528 : Time 316.23s : 13971.98 words/s
[2019-08-05 19:49:23] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-05 19:49:33] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter80000.npz
[2019-08-05 19:49:40] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-05 19:49:50] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-05 19:50:17] [valid] Ep. 2 : Up. 80000 : cross-entropy : 55.7531 : new best
[2019-08-05 19:50:24] [valid] Ep. 2 : Up. 80000 : perplexity : 9.0498 : new best
[2019-08-05 19:51:15] [valid] Ep. 2 : Up. 80000 : translation : 27.7 : new best
[2019-08-05 19:56:32] Ep. 2 : Up. 82000 : Sen. 4,036,840 : Cost 52.62061691 : Time 428.74s : 10244.25 words/s
[2019-08-05 20:01:08] Seen 4212135 samples
[2019-08-05 20:01:08] Starting epoch 3
[2019-08-05 20:01:08] [data] Shuffling data
[2019-08-05 20:01:11] [data] Done reading 5059895 sentences
[2019-08-05 20:01:29] [data] Done shuffling 5059895 sentences to temp files
[2019-08-05 20:02:28] Ep. 3 : Up. 84000 : Sen. 26,079 : Cost 52.35037613 : Time 356.02s : 12409.53 words/s
[2019-08-05 20:07:44] Ep. 3 : Up. 86000 : Sen. 226,652 : Cost 51.27019119 : Time 316.34s : 13902.21 words/s
[2019-08-05 20:13:01] Ep. 3 : Up. 88000 : Sen. 427,622 : Cost 50.85000610 : Time 316.54s : 13904.51 words/s
[2019-08-05 20:18:18] Ep. 3 : Up. 90000 : Sen. 629,484 : Cost 51.10846329 : Time 317.69s : 13896.33 words/s
[2019-08-05 20:23:34] Ep. 3 : Up. 92000 : Sen. 830,734 : Cost 50.82392502 : Time 316.22s : 13914.27 words/s
[2019-08-05 20:28:51] Ep. 3 : Up. 94000 : Sen. 1,032,195 : Cost 50.98973846 : Time 317.00s : 13929.03 words/s
[2019-08-05 20:34:07] Ep. 3 : Up. 96000 : Sen. 1,232,621 : Cost 51.02467728 : Time 315.81s : 13897.53 words/s
[2019-08-05 20:39:24] Ep. 3 : Up. 98000 : Sen. 1,433,600 : Cost 50.76615524 : Time 316.83s : 13900.99 words/s
[2019-08-05 20:44:40] Ep. 3 : Up. 100000 : Sen. 1,633,922 : Cost 50.63453293 : Time 316.13s : 13877.71 words/s
[2019-08-05 20:44:40] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-05 20:44:50] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter100000.npz
[2019-08-05 20:44:57] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-05 20:45:07] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-05 20:45:34] [valid] Ep. 3 : Up. 100000 : cross-entropy : 53.8772 : new best
[2019-08-05 20:45:40] [valid] Ep. 3 : Up. 100000 : perplexity : 8.40331 : new best
[2019-08-05 20:46:31] [valid] Ep. 3 : Up. 100000 : translation : 28.44 : new best
[2019-08-05 20:51:51] Ep. 3 : Up. 102000 : Sen. 1,835,652 : Cost 50.46214294 : Time 430.60s : 10274.41 words/s
[2019-08-05 20:57:07] Ep. 3 : Up. 104000 : Sen. 2,035,977 : Cost 50.53716660 : Time 316.29s : 13910.23 words/s
[2019-08-05 21:02:24] Ep. 3 : Up. 106000 : Sen. 2,238,227 : Cost 50.29484177 : Time 317.32s : 13935.36 words/s
[2019-08-05 21:07:41] Ep. 3 : Up. 108000 : Sen. 2,439,294 : Cost 50.56846237 : Time 316.38s : 13947.36 words/s
[2019-08-05 21:12:59] Ep. 3 : Up. 110000 : Sen. 2,641,643 : Cost 50.04279709 : Time 317.97s : 13902.57 words/s
[2019-08-05 21:18:15] Ep. 3 : Up. 112000 : Sen. 2,842,809 : Cost 50.18117523 : Time 316.57s : 13924.93 words/s
[2019-08-05 21:23:33] Ep. 3 : Up. 114000 : Sen. 3,044,672 : Cost 50.03456116 : Time 317.47s : 13901.01 words/s
[2019-08-05 21:28:49] Ep. 3 : Up. 116000 : Sen. 3,245,317 : Cost 50.09981155 : Time 316.31s : 13886.56 words/s
[2019-08-05 21:34:06] Ep. 3 : Up. 118000 : Sen. 3,446,969 : Cost 49.58571625 : Time 316.53s : 13931.15 words/s
[2019-08-05 21:39:23] Ep. 3 : Up. 120000 : Sen. 3,648,705 : Cost 49.69611740 : Time 316.87s : 13932.75 words/s
[2019-08-05 21:39:23] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-05 21:39:32] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter120000.npz
[2019-08-05 21:39:40] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-05 21:39:50] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-05 21:40:17] [valid] Ep. 3 : Up. 120000 : cross-entropy : 52.3786 : new best
[2019-08-05 21:40:23] [valid] Ep. 3 : Up. 120000 : perplexity : 7.92023 : new best
[2019-08-05 21:41:14] [valid] Ep. 3 : Up. 120000 : translation : 28.85 : new best
[2019-08-05 21:46:34] Ep. 3 : Up. 122000 : Sen. 3,849,419 : Cost 50.05120850 : Time 431.09s : 10237.88 words/s
[2019-08-05 21:51:50] Ep. 3 : Up. 124000 : Sen. 4,050,740 : Cost 49.51593781 : Time 316.79s : 13923.23 words/s
[2019-08-05 21:56:05] Seen 4212135 samples
[2019-08-05 21:56:05] Starting epoch 4
[2019-08-05 21:56:05] [data] Shuffling data
[2019-08-05 21:56:08] [data] Done reading 5059895 sentences
[2019-08-05 21:56:31] [data] Done shuffling 5059895 sentences to temp files
[2019-08-05 21:57:42] Ep. 4 : Up. 126000 : Sen. 39,112 : Cost 49.39416504 : Time 351.89s : 12496.18 words/s
[2019-08-05 22:02:58] Ep. 4 : Up. 128000 : Sen. 240,475 : Cost 48.12400055 : Time 315.75s : 13897.79 words/s
[2019-08-05 22:08:18] Ep. 4 : Up. 130000 : Sen. 443,066 : Cost 48.52042770 : Time 320.20s : 13880.04 words/s
[2019-08-05 22:13:38] Ep. 4 : Up. 132000 : Sen. 646,400 : Cost 48.33314514 : Time 319.51s : 13928.72 words/s
[2019-08-05 22:18:56] Ep. 4 : Up. 134000 : Sen. 848,184 : Cost 48.25452423 : Time 317.73s : 13884.46 words/s
[2019-08-05 22:24:13] Ep. 4 : Up. 136000 : Sen. 1,048,978 : Cost 48.60909271 : Time 317.66s : 13877.88 words/s
[2019-08-05 22:29:30] Ep. 4 : Up. 138000 : Sen. 1,249,785 : Cost 48.32635498 : Time 316.71s : 13877.62 words/s
[2019-08-05 22:34:47] Ep. 4 : Up. 140000 : Sen. 1,450,794 : Cost 48.30653000 : Time 316.69s : 13890.72 words/s
[2019-08-05 22:34:47] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-05 22:34:57] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter140000.npz
[2019-08-05 22:35:05] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-05 22:35:16] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-05 22:35:48] [valid] Ep. 4 : Up. 140000 : cross-entropy : 51.4618 : new best
[2019-08-05 22:35:54] [valid] Ep. 4 : Up. 140000 : perplexity : 7.63847 : new best
[2019-08-05 22:36:46] [valid] Ep. 4 : Up. 140000 : translation : 29.05 : new best
[2019-08-05 22:42:06] Ep. 4 : Up. 142000 : Sen. 1,651,958 : Cost 48.18120956 : Time 439.39s : 10035.50 words/s
[2019-08-05 22:47:23] Ep. 4 : Up. 144000 : Sen. 1,852,093 : Cost 48.46364212 : Time 317.21s : 13861.62 words/s
[2019-08-05 22:52:41] Ep. 4 : Up. 146000 : Sen. 2,052,515 : Cost 48.30031967 : Time 317.68s : 13836.67 words/s
[2019-08-05 22:57:59] Ep. 4 : Up. 148000 : Sen. 2,254,017 : Cost 48.08228683 : Time 318.27s : 13851.07 words/s
[2019-08-05 23:03:15] Ep. 4 : Up. 150000 : Sen. 2,454,738 : Cost 48.06681061 : Time 316.25s : 13874.55 words/s
[2019-08-05 23:08:33] Ep. 4 : Up. 152000 : Sen. 2,655,898 : Cost 48.09969330 : Time 317.99s : 13906.17 words/s
[2019-08-05 23:13:51] Ep. 4 : Up. 154000 : Sen. 2,857,681 : Cost 48.02283096 : Time 317.30s : 13937.39 words/s
[2019-08-05 23:19:08] Ep. 4 : Up. 156000 : Sen. 3,059,548 : Cost 47.90663528 : Time 317.24s : 13922.54 words/s
[2019-08-05 23:24:25] Ep. 4 : Up. 158000 : Sen. 3,260,742 : Cost 47.79049683 : Time 317.13s : 13892.88 words/s
[2019-08-05 23:29:43] Ep. 4 : Up. 160000 : Sen. 3,461,781 : Cost 47.93464279 : Time 317.60s : 13856.27 words/s
[2019-08-05 23:29:43] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-05 23:29:52] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter160000.npz
[2019-08-05 23:29:59] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-05 23:30:09] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-05 23:30:36] [valid] Ep. 4 : Up. 160000 : cross-entropy : 50.7835 : new best
[2019-08-05 23:30:43] [valid] Ep. 4 : Up. 160000 : perplexity : 7.43649 : new best
[2019-08-05 23:31:34] [valid] Ep. 4 : Up. 160000 : translation : 29.41 : new best
[2019-08-05 23:36:52] Ep. 4 : Up. 162000 : Sen. 3,662,117 : Cost 47.76780319 : Time 428.85s : 10223.36 words/s
[2019-08-05 23:42:09] Ep. 4 : Up. 164000 : Sen. 3,863,575 : Cost 47.90566635 : Time 317.35s : 13904.49 words/s
[2019-08-05 23:47:26] Ep. 4 : Up. 166000 : Sen. 4,065,245 : Cost 47.83385849 : Time 317.06s : 13907.13 words/s
[2019-08-05 23:51:17] Seen 4212135 samples
[2019-08-05 23:51:17] Starting epoch 5
[2019-08-05 23:51:17] [data] Shuffling data
[2019-08-05 23:51:20] [data] Done reading 5059895 sentences
[2019-08-05 23:51:43] [data] Done shuffling 5059895 sentences to temp files
[2019-08-05 23:53:16] Ep. 5 : Up. 168000 : Sen. 53,647 : Cost 47.39379120 : Time 350.03s : 12558.50 words/s
[2019-08-05 23:58:33] Ep. 5 : Up. 170000 : Sen. 255,189 : Cost 46.41918182 : Time 316.96s : 13912.40 words/s
[2019-08-06 00:03:50] Ep. 5 : Up. 172000 : Sen. 456,457 : Cost 46.73788071 : Time 317.29s : 13923.20 words/s
[2019-08-06 00:09:08] Ep. 5 : Up. 174000 : Sen. 657,845 : Cost 46.73688126 : Time 317.60s : 13885.88 words/s
[2019-08-06 00:14:26] Ep. 5 : Up. 176000 : Sen. 859,180 : Cost 46.74657822 : Time 318.03s : 13871.96 words/s
[2019-08-06 00:19:44] Ep. 5 : Up. 178000 : Sen. 1,061,091 : Cost 46.66701508 : Time 317.67s : 13908.12 words/s
[2019-08-06 00:25:02] Ep. 5 : Up. 180000 : Sen. 1,262,736 : Cost 46.87726974 : Time 318.48s : 13914.23 words/s
[2019-08-06 00:25:02] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-06 00:25:12] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter180000.npz
[2019-08-06 00:25:19] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-06 00:25:29] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 00:25:55] [valid] Ep. 5 : Up. 180000 : cross-entropy : 50.3169 : new best
[2019-08-06 00:26:02] [valid] Ep. 5 : Up. 180000 : perplexity : 7.30066 : new best
[2019-08-06 00:26:53] [valid] Ep. 5 : Up. 180000 : translation : 29.6 : new best
[2019-08-06 00:32:11] Ep. 5 : Up. 182000 : Sen. 1,462,304 : Cost 46.74160004 : Time 428.95s : 10183.62 words/s
[2019-08-06 00:37:28] Ep. 5 : Up. 184000 : Sen. 1,664,082 : Cost 46.69535446 : Time 317.03s : 13937.09 words/s
[2019-08-06 00:42:45] Ep. 5 : Up. 186000 : Sen. 1,864,918 : Cost 46.84116364 : Time 317.02s : 13924.53 words/s
[2019-08-06 00:48:02] Ep. 5 : Up. 188000 : Sen. 2,066,241 : Cost 46.53208923 : Time 316.53s : 13911.70 words/s
[2019-08-06 00:53:19] Ep. 5 : Up. 190000 : Sen. 2,267,897 : Cost 46.83623123 : Time 317.75s : 13905.43 words/s
[2019-08-06 00:58:37] Ep. 5 : Up. 192000 : Sen. 2,469,920 : Cost 46.62826920 : Time 317.52s : 13910.79 words/s
[2019-08-06 01:03:55] Ep. 5 : Up. 194000 : Sen. 2,671,974 : Cost 46.74235153 : Time 318.55s : 13895.87 words/s
[2019-08-06 01:09:12] Ep. 5 : Up. 196000 : Sen. 2,874,264 : Cost 46.49181747 : Time 316.68s : 13949.02 words/s
[2019-08-06 01:14:29] Ep. 5 : Up. 198000 : Sen. 3,076,026 : Cost 46.22311783 : Time 316.46s : 13904.27 words/s
[2019-08-06 01:19:46] Ep. 5 : Up. 200000 : Sen. 3,277,511 : Cost 46.57059479 : Time 317.54s : 13913.01 words/s
[2019-08-06 01:19:46] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-06 01:19:56] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter200000.npz
[2019-08-06 01:20:03] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-06 01:20:13] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 01:20:40] [valid] Ep. 5 : Up. 200000 : cross-entropy : 49.8229 : new best
[2019-08-06 01:20:46] [valid] Ep. 5 : Up. 200000 : perplexity : 7.15955 : new best
[2019-08-06 01:21:38] [valid] Ep. 5 : Up. 200000 : translation : 29.73 : new best
[2019-08-06 01:26:56] Ep. 5 : Up. 202000 : Sen. 3,478,455 : Cost 46.59663391 : Time 430.28s : 10239.88 words/s
[2019-08-06 01:32:13] Ep. 5 : Up. 204000 : Sen. 3,679,381 : Cost 46.40417862 : Time 316.66s : 13898.11 words/s
[2019-08-06 01:37:30] Ep. 5 : Up. 206000 : Sen. 3,881,106 : Cost 46.53760910 : Time 317.10s : 13928.71 words/s
[2019-08-06 01:42:48] Ep. 5 : Up. 208000 : Sen. 4,083,301 : Cost 46.53088760 : Time 317.58s : 13929.75 words/s
[2019-08-06 01:46:11] Seen 4212135 samples
[2019-08-06 01:46:11] Starting epoch 6
[2019-08-06 01:46:11] [data] Shuffling data
[2019-08-06 01:46:14] [data] Done reading 5059895 sentences
[2019-08-06 01:46:32] [data] Done shuffling 5059895 sentences to temp files
[2019-08-06 01:48:43] Ep. 6 : Up. 210000 : Sen. 72,921 : Cost 46.13893127 : Time 355.32s : 12458.38 words/s
[2019-08-06 01:54:01] Ep. 6 : Up. 212000 : Sen. 275,200 : Cost 45.43245697 : Time 317.56s : 13928.17 words/s
[2019-08-06 01:59:16] Ep. 6 : Up. 214000 : Sen. 475,458 : Cost 45.37473297 : Time 315.63s : 13891.13 words/s
[2019-08-06 02:04:34] Ep. 6 : Up. 216000 : Sen. 677,273 : Cost 45.27412796 : Time 317.86s : 13901.10 words/s
[2019-08-06 02:09:51] Ep. 6 : Up. 218000 : Sen. 879,178 : Cost 45.30126953 : Time 317.18s : 13922.99 words/s
[2019-08-06 02:15:09] Ep. 6 : Up. 220000 : Sen. 1,080,069 : Cost 45.70940781 : Time 317.35s : 13882.51 words/s
[2019-08-06 02:15:09] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-06 02:15:18] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter220000.npz
[2019-08-06 02:15:25] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-06 02:15:35] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 02:16:01] [valid] Ep. 6 : Up. 220000 : cross-entropy : 49.5349 : new best
[2019-08-06 02:16:08] [valid] Ep. 6 : Up. 220000 : perplexity : 7.07854 : new best
[2019-08-06 02:17:00] [valid] Ep. 6 : Up. 220000 : translation : 29.79 : new best
[2019-08-06 02:22:18] Ep. 6 : Up. 222000 : Sen. 1,280,841 : Cost 45.36499023 : Time 429.55s : 10227.92 words/s
[2019-08-06 02:27:35] Ep. 6 : Up. 224000 : Sen. 1,481,558 : Cost 45.33961105 : Time 316.73s : 13841.55 words/s
[2019-08-06 02:32:52] Ep. 6 : Up. 226000 : Sen. 1,683,389 : Cost 45.53014755 : Time 317.57s : 13903.20 words/s
[2019-08-06 02:38:09] Ep. 6 : Up. 228000 : Sen. 1,885,073 : Cost 45.30772400 : Time 317.01s : 13887.85 words/s
[2019-08-06 02:43:28] Ep. 6 : Up. 230000 : Sen. 2,086,715 : Cost 45.82971954 : Time 318.67s : 13909.69 words/s
[2019-08-06 02:48:46] Ep. 6 : Up. 232000 : Sen. 2,288,193 : Cost 45.62320328 : Time 318.02s : 13912.60 words/s
[2019-08-06 02:54:03] Ep. 6 : Up. 234000 : Sen. 2,489,858 : Cost 45.41991425 : Time 316.72s : 13913.22 words/s
[2019-08-06 02:59:21] Ep. 6 : Up. 236000 : Sen. 2,690,712 : Cost 45.92718124 : Time 317.78s : 13922.74 words/s
[2019-08-06 03:04:37] Ep. 6 : Up. 238000 : Sen. 2,891,489 : Cost 45.39873505 : Time 316.25s : 13888.15 words/s
[2019-08-06 03:09:53] Ep. 6 : Up. 240000 : Sen. 3,091,917 : Cost 45.82838821 : Time 316.55s : 13902.27 words/s
[2019-08-06 03:09:53] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-06 03:10:03] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter240000.npz
[2019-08-06 03:10:10] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-06 03:10:20] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 03:10:46] [valid] Ep. 6 : Up. 240000 : cross-entropy : 49.1993 : new best
[2019-08-06 03:10:53] [valid] Ep. 6 : Up. 240000 : perplexity : 6.98531 : new best
[2019-08-06 03:11:44] [valid] Ep. 6 : Up. 240000 : translation : 29.91 : new best
[2019-08-06 03:17:03] Ep. 6 : Up. 242000 : Sen. 3,293,844 : Cost 45.51554871 : Time 430.00s : 10250.86 words/s
[2019-08-06 03:22:20] Ep. 6 : Up. 244000 : Sen. 3,495,699 : Cost 45.59069061 : Time 316.21s : 13983.06 words/s
[2019-08-06 03:27:37] Ep. 6 : Up. 246000 : Sen. 3,697,878 : Cost 45.45148468 : Time 317.29s : 13937.35 words/s
[2019-08-06 03:32:55] Ep. 6 : Up. 248000 : Sen. 3,899,390 : Cost 45.52127457 : Time 317.60s : 13936.76 words/s
[2019-08-06 03:38:12] Ep. 6 : Up. 250000 : Sen. 4,101,723 : Cost 45.51454163 : Time 317.85s : 13932.01 words/s
[2019-08-06 03:41:06] Seen 4212135 samples
[2019-08-06 03:41:06] Starting epoch 7
[2019-08-06 03:41:06] [data] Shuffling data
[2019-08-06 03:41:10] [data] Done reading 5059895 sentences
[2019-08-06 03:41:32] [data] Done shuffling 5059895 sentences to temp files
[2019-08-06 03:44:02] Ep. 7 : Up. 252000 : Sen. 90,482 : Cost 45.27838898 : Time 349.46s : 12602.07 words/s
[2019-08-06 03:49:19] Ep. 7 : Up. 254000 : Sen. 292,309 : Cost 44.23889160 : Time 316.68s : 13955.33 words/s
[2019-08-06 03:54:36] Ep. 7 : Up. 256000 : Sen. 494,262 : Cost 44.47075272 : Time 317.69s : 13919.86 words/s
[2019-08-06 03:59:53] Ep. 7 : Up. 258000 : Sen. 695,853 : Cost 44.30706406 : Time 316.21s : 13923.38 words/s
[2019-08-06 04:05:09] Ep. 7 : Up. 260000 : Sen. 896,996 : Cost 44.58193970 : Time 316.82s : 13913.77 words/s
[2019-08-06 04:05:09] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-06 04:05:19] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter260000.npz
[2019-08-06 04:05:26] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-06 04:05:37] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 04:06:03] [valid] Ep. 7 : Up. 260000 : cross-entropy : 48.9288 : new best
[2019-08-06 04:06:10] [valid] Ep. 7 : Up. 260000 : perplexity : 6.91106 : new best
[2019-08-06 04:07:01] [valid] Ep. 7 : Up. 260000 : translation : 29.95 : new best
[2019-08-06 04:12:19] Ep. 7 : Up. 262000 : Sen. 1,097,218 : Cost 44.51396942 : Time 429.77s : 10216.63 words/s
[2019-08-06 04:17:37] Ep. 7 : Up. 264000 : Sen. 1,299,200 : Cost 44.76699829 : Time 317.64s : 13916.98 words/s
[2019-08-06 04:22:54] Ep. 7 : Up. 266000 : Sen. 1,500,823 : Cost 44.85470581 : Time 317.39s : 13936.24 words/s
[2019-08-06 04:28:10] Ep. 7 : Up. 268000 : Sen. 1,700,892 : Cost 44.48180389 : Time 315.79s : 13879.71 words/s
[2019-08-06 04:33:26] Ep. 7 : Up. 270000 : Sen. 1,901,911 : Cost 44.63999939 : Time 316.50s : 13927.32 words/s
[2019-08-06 04:38:43] Ep. 7 : Up. 272000 : Sen. 2,103,397 : Cost 44.68513870 : Time 317.05s : 13903.25 words/s
[2019-08-06 04:43:59] Ep. 7 : Up. 274000 : Sen. 2,303,844 : Cost 44.59086990 : Time 315.35s : 13909.59 words/s
[2019-08-06 04:49:17] Ep. 7 : Up. 276000 : Sen. 2,505,565 : Cost 44.89688110 : Time 317.73s : 13937.75 words/s
[2019-08-06 04:54:33] Ep. 7 : Up. 278000 : Sen. 2,707,200 : Cost 44.71186066 : Time 316.85s : 13943.70 words/s
[2019-08-06 04:59:49] Ep. 7 : Up. 280000 : Sen. 2,907,796 : Cost 44.68429947 : Time 315.67s : 13893.27 words/s
[2019-08-06 04:59:49] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-06 05:00:03] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter280000.npz
[2019-08-06 05:00:13] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-06 05:00:25] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 05:00:57] [valid] Ep. 7 : Up. 280000 : cross-entropy : 48.7936 : new best
[2019-08-06 05:01:04] [valid] Ep. 7 : Up. 280000 : perplexity : 6.87423 : new best
[2019-08-06 05:01:55] [valid] Ep. 7 : Up. 280000 : translation : 30.19 : new best
[2019-08-06 05:07:13] Ep. 7 : Up. 282000 : Sen. 3,108,454 : Cost 45.01295853 : Time 444.41s : 9916.90 words/s
[2019-08-06 05:12:31] Ep. 7 : Up. 284000 : Sen. 3,310,122 : Cost 44.58423615 : Time 317.22s : 13906.23 words/s
[2019-08-06 05:17:48] Ep. 7 : Up. 286000 : Sen. 3,512,066 : Cost 44.65682220 : Time 316.89s : 13936.86 words/s
[2019-08-06 05:23:04] Ep. 7 : Up. 288000 : Sen. 3,713,933 : Cost 44.65728760 : Time 316.70s : 13957.36 words/s
[2019-08-06 05:28:21] Ep. 7 : Up. 290000 : Sen. 3,915,163 : Cost 44.92087173 : Time 316.92s : 13918.15 words/s
[2019-08-06 05:33:37] Ep. 7 : Up. 292000 : Sen. 4,116,218 : Cost 44.81539536 : Time 315.64s : 13924.20 words/s
[2019-08-06 05:36:08] Seen 4212135 samples
[2019-08-06 05:36:08] Starting epoch 8
[2019-08-06 05:36:08] [data] Shuffling data
[2019-08-06 05:36:11] [data] Done reading 5059895 sentences
[2019-08-06 05:36:35] [data] Done shuffling 5059895 sentences to temp files
[2019-08-06 05:39:29] Ep. 8 : Up. 294000 : Sen. 105,640 : Cost 44.21476364 : Time 352.28s : 12521.59 words/s
[2019-08-06 05:44:46] Ep. 8 : Up. 296000 : Sen. 307,122 : Cost 43.55926132 : Time 316.49s : 13936.45 words/s
[2019-08-06 05:50:01] Ep. 8 : Up. 298000 : Sen. 507,548 : Cost 43.61479187 : Time 315.23s : 13940.87 words/s
[2019-08-06 05:55:17] Ep. 8 : Up. 300000 : Sen. 707,510 : Cost 43.94794846 : Time 315.68s : 13897.81 words/s
[2019-08-06 05:55:17] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-06 05:55:26] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter300000.npz
[2019-08-06 05:55:33] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-06 05:55:43] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 05:56:09] [valid] Ep. 8 : Up. 300000 : cross-entropy : 48.534 : new best
[2019-08-06 05:56:16] [valid] Ep. 8 : Up. 300000 : perplexity : 6.80409 : new best
[2019-08-06 05:57:07] [valid] Ep. 8 : Up. 300000 : translation : 30.14 : stalled 1 times (last best: 30.19)
[2019-08-06 06:02:26] Ep. 8 : Up. 302000 : Sen. 908,527 : Cost 43.79527283 : Time 429.35s : 10262.55 words/s
[2019-08-06 06:07:44] Ep. 8 : Up. 304000 : Sen. 1,110,289 : Cost 44.02573395 : Time 317.73s : 13919.29 words/s
[2019-08-06 06:13:01] Ep. 8 : Up. 306000 : Sen. 1,312,340 : Cost 44.00868607 : Time 317.38s : 13963.69 words/s
[2019-08-06 06:18:18] Ep. 8 : Up. 308000 : Sen. 1,514,044 : Cost 43.88222504 : Time 317.04s : 13922.36 words/s
[2019-08-06 06:23:35] Ep. 8 : Up. 310000 : Sen. 1,715,691 : Cost 43.92482376 : Time 316.47s : 13938.72 words/s
[2019-08-06 06:28:54] Ep. 8 : Up. 312000 : Sen. 1,916,861 : Cost 43.91629410 : Time 319.46s : 13767.65 words/s
[2019-08-06 06:34:11] Ep. 8 : Up. 314000 : Sen. 2,118,322 : Cost 44.16801834 : Time 317.12s : 13940.82 words/s
[2019-08-06 06:39:28] Ep. 8 : Up. 316000 : Sen. 2,319,287 : Cost 43.94877243 : Time 316.67s : 13914.96 words/s
[2019-08-06 06:44:46] Ep. 8 : Up. 318000 : Sen. 2,521,813 : Cost 44.01032639 : Time 317.91s : 13941.78 words/s
[2019-08-06 06:50:01] Ep. 8 : Up. 320000 : Sen. 2,722,375 : Cost 44.11493683 : Time 315.39s : 13952.83 words/s
[2019-08-06 06:50:01] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-06 06:50:11] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter320000.npz
[2019-08-06 06:50:21] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-06 06:50:32] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 06:51:01] [valid] Ep. 8 : Up. 320000 : cross-entropy : 48.4457 : new best
[2019-08-06 06:51:08] [valid] Ep. 8 : Up. 320000 : perplexity : 6.78039 : new best
[2019-08-06 06:52:00] [valid] Ep. 8 : Up. 320000 : translation : 30.21 : new best
[2019-08-06 06:57:18] Ep. 8 : Up. 322000 : Sen. 2,923,701 : Cost 43.98212814 : Time 436.71s : 10073.39 words/s
[2019-08-06 07:02:34] Ep. 8 : Up. 324000 : Sen. 3,124,479 : Cost 44.31840515 : Time 315.99s : 13925.35 words/s
[2019-08-06 07:07:51] Ep. 8 : Up. 326000 : Sen. 3,325,571 : Cost 44.00520706 : Time 316.99s : 13897.35 words/s
[2019-08-06 07:13:08] Ep. 8 : Up. 328000 : Sen. 3,527,021 : Cost 44.35423660 : Time 316.80s : 13917.33 words/s
[2019-08-06 07:18:24] Ep. 8 : Up. 330000 : Sen. 3,728,627 : Cost 43.99105835 : Time 316.35s : 13925.09 words/s
[2019-08-06 07:23:40] Ep. 8 : Up. 332000 : Sen. 3,929,387 : Cost 44.32341766 : Time 315.75s : 13910.62 words/s
[2019-08-06 07:28:55] Ep. 8 : Up. 334000 : Sen. 4,129,350 : Cost 44.29885864 : Time 315.27s : 13902.61 words/s
[2019-08-06 07:31:05] Seen 4212135 samples
[2019-08-06 07:31:05] Starting epoch 9
[2019-08-06 07:31:05] [data] Shuffling data
[2019-08-06 07:31:09] [data] Done reading 5059895 sentences
[2019-08-06 07:31:32] [data] Done shuffling 5059895 sentences to temp files
[2019-08-06 07:34:45] Ep. 9 : Up. 336000 : Sen. 117,082 : Cost 43.40748596 : Time 350.12s : 12483.43 words/s
[2019-08-06 07:40:01] Ep. 9 : Up. 338000 : Sen. 317,453 : Cost 43.15336990 : Time 315.67s : 13921.62 words/s
[2019-08-06 07:45:19] Ep. 9 : Up. 340000 : Sen. 520,129 : Cost 43.00376892 : Time 318.19s : 13949.60 words/s
[2019-08-06 07:45:19] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-06 07:45:30] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter340000.npz
[2019-08-06 07:45:38] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-06 07:45:49] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 07:46:19] [valid] Ep. 9 : Up. 340000 : cross-entropy : 48.283 : new best
[2019-08-06 07:46:26] [valid] Ep. 9 : Up. 340000 : perplexity : 6.73694 : new best
[2019-08-06 07:47:18] [valid] Ep. 9 : Up. 340000 : translation : 30.13 : stalled 1 times (last best: 30.21)
[2019-08-06 07:52:37] Ep. 9 : Up. 342000 : Sen. 721,969 : Cost 43.14038849 : Time 438.10s : 10088.53 words/s
[2019-08-06 07:57:54] Ep. 9 : Up. 344000 : Sen. 922,660 : Cost 43.30379868 : Time 316.63s : 13911.86 words/s
[2019-08-06 08:03:10] Ep. 9 : Up. 346000 : Sen. 1,123,939 : Cost 43.44068146 : Time 316.40s : 13944.48 words/s
[2019-08-06 08:08:26] Ep. 9 : Up. 348000 : Sen. 1,325,113 : Cost 43.31423187 : Time 315.62s : 13945.46 words/s
[2019-08-06 08:13:41] Ep. 9 : Up. 350000 : Sen. 1,525,288 : Cost 43.47168732 : Time 315.66s : 13906.49 words/s
[2019-08-06 08:18:58] Ep. 9 : Up. 352000 : Sen. 1,727,228 : Cost 43.27187347 : Time 316.94s : 13945.52 words/s
[2019-08-06 08:24:14] Ep. 9 : Up. 354000 : Sen. 1,927,831 : Cost 43.42811966 : Time 315.65s : 13913.36 words/s
[2019-08-06 08:29:30] Ep. 9 : Up. 356000 : Sen. 2,128,193 : Cost 43.58651352 : Time 315.84s : 13924.86 words/s
[2019-08-06 08:34:46] Ep. 9 : Up. 358000 : Sen. 2,330,196 : Cost 43.44414139 : Time 316.49s : 13955.02 words/s
[2019-08-06 08:40:03] Ep. 9 : Up. 360000 : Sen. 2,532,142 : Cost 43.36755753 : Time 317.06s : 13942.59 words/s
[2019-08-06 08:40:03] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-06 08:40:14] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter360000.npz
[2019-08-06 08:40:21] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-06 08:40:31] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 08:40:59] [valid] Ep. 9 : Up. 360000 : cross-entropy : 48.2133 : new best
[2019-08-06 08:41:05] [valid] Ep. 9 : Up. 360000 : perplexity : 6.71841 : new best
[2019-08-06 08:41:57] [valid] Ep. 9 : Up. 360000 : translation : 30.2 : stalled 2 times (last best: 30.21)
[2019-08-06 08:47:17] Ep. 9 : Up. 362000 : Sen. 2,734,260 : Cost 43.53053284 : Time 433.69s : 10194.12 words/s
[2019-08-06 08:52:33] Ep. 9 : Up. 364000 : Sen. 2,934,682 : Cost 43.68888092 : Time 316.01s : 13926.47 words/s
[2019-08-06 08:57:51] Ep. 9 : Up. 366000 : Sen. 3,136,681 : Cost 43.60929489 : Time 317.44s : 13948.54 words/s
[2019-08-06 09:03:06] Ep. 9 : Up. 368000 : Sen. 3,337,568 : Cost 43.49886703 : Time 315.76s : 13916.73 words/s
[2019-08-06 09:08:24] Ep. 9 : Up. 370000 : Sen. 3,539,974 : Cost 43.72311020 : Time 317.61s : 13966.49 words/s
[2019-08-06 09:13:40] Ep. 9 : Up. 372000 : Sen. 3,741,297 : Cost 43.58044052 : Time 316.35s : 13905.64 words/s
[2019-08-06 09:18:57] Ep. 9 : Up. 374000 : Sen. 3,942,400 : Cost 43.48578644 : Time 316.24s : 13900.61 words/s
[2019-08-06 09:24:15] Ep. 9 : Up. 376000 : Sen. 4,144,275 : Cost 43.48583603 : Time 318.37s : 13890.65 words/s
[2019-08-06 09:26:02] Seen 4212135 samples
[2019-08-06 09:26:02] Starting epoch 10
[2019-08-06 09:26:02] [data] Shuffling data
[2019-08-06 09:26:05] [data] Done reading 5059895 sentences
[2019-08-06 09:26:25] [data] Done shuffling 5059895 sentences to temp files
[2019-08-06 09:30:12] Ep. 10 : Up. 378000 : Sen. 133,691 : Cost 42.74324036 : Time 357.12s : 12351.45 words/s
[2019-08-06 09:35:29] Ep. 10 : Up. 380000 : Sen. 335,584 : Cost 42.50960159 : Time 317.15s : 13927.85 words/s
[2019-08-06 09:35:29] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-06 09:35:39] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter380000.npz
[2019-08-06 09:35:47] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-06 09:35:57] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 09:36:29] [valid] Ep. 10 : Up. 380000 : cross-entropy : 48.0398 : new best
[2019-08-06 09:36:35] [valid] Ep. 10 : Up. 380000 : perplexity : 6.67253 : new best
[2019-08-06 09:37:27] [valid] Ep. 10 : Up. 380000 : translation : 30.26 : new best
[2019-08-06 09:42:48] Ep. 10 : Up. 382000 : Sen. 538,772 : Cost 42.39831161 : Time 438.39s : 10140.18 words/s
[2019-08-06 09:48:03] Ep. 10 : Up. 384000 : Sen. 740,233 : Cost 42.61379623 : Time 315.81s : 13961.99 words/s
[2019-08-06 09:53:19] Ep. 10 : Up. 386000 : Sen. 941,083 : Cost 42.78836823 : Time 315.22s : 13931.67 words/s
[2019-08-06 09:58:35] Ep. 10 : Up. 388000 : Sen. 1,142,006 : Cost 42.92253113 : Time 316.44s : 13927.85 words/s
[2019-08-06 10:03:53] Ep. 10 : Up. 390000 : Sen. 1,344,407 : Cost 43.01047516 : Time 318.34s : 13943.45 words/s
[2019-08-06 10:09:10] Ep. 10 : Up. 392000 : Sen. 1,546,057 : Cost 42.67097473 : Time 316.82s : 13932.48 words/s
[2019-08-06 10:14:27] Ep. 10 : Up. 394000 : Sen. 1,746,812 : Cost 43.04227066 : Time 316.87s : 13910.15 words/s
[2019-08-06 10:19:44] Ep. 10 : Up. 396000 : Sen. 1,948,050 : Cost 42.88506699 : Time 316.97s : 13931.50 words/s
[2019-08-06 10:25:00] Ep. 10 : Up. 398000 : Sen. 2,149,662 : Cost 42.86713409 : Time 315.88s : 13962.67 words/s
[2019-08-06 10:30:16] Ep. 10 : Up. 400000 : Sen. 2,350,781 : Cost 43.06178284 : Time 316.09s : 13949.23 words/s
[2019-08-06 10:30:16] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-06 10:30:27] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter400000.npz
[2019-08-06 10:30:37] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-06 10:30:47] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 10:31:14] [valid] Ep. 10 : Up. 400000 : cross-entropy : 48.0508 : stalled 1 times (last best: 48.0398)
[2019-08-06 10:31:21] [valid] Ep. 10 : Up. 400000 : perplexity : 6.67543 : stalled 1 times (last best: 6.67253)
[2019-08-06 10:32:13] [valid] Ep. 10 : Up. 400000 : translation : 30.31 : new best
[2019-08-06 10:37:31] Ep. 10 : Up. 402000 : Sen. 2,552,409 : Cost 42.97577667 : Time 435.27s : 10129.10 words/s
[2019-08-06 10:42:48] Ep. 10 : Up. 404000 : Sen. 2,753,823 : Cost 42.94955826 : Time 316.50s : 13939.32 words/s
[2019-08-06 10:48:06] Ep. 10 : Up. 406000 : Sen. 2,955,445 : Cost 43.21752548 : Time 318.10s : 13906.40 words/s
[2019-08-06 10:53:24] Ep. 10 : Up. 408000 : Sen. 3,158,089 : Cost 43.05810547 : Time 318.34s : 13944.91 words/s
[2019-08-06 10:58:40] Ep. 10 : Up. 410000 : Sen. 3,359,417 : Cost 42.83386230 : Time 316.18s : 13902.00 words/s
[2019-08-06 11:03:55] Ep. 10 : Up. 412000 : Sen. 3,559,298 : Cost 43.12918091 : Time 314.59s : 13921.44 words/s
[2019-08-06 11:09:13] Ep. 10 : Up. 414000 : Sen. 3,761,650 : Cost 43.10235977 : Time 317.64s : 13950.02 words/s
[2019-08-06 11:14:29] Ep. 10 : Up. 416000 : Sen. 3,962,803 : Cost 43.08135986 : Time 316.48s : 13933.99 words/s
[2019-08-06 11:19:45] Ep. 10 : Up. 418000 : Sen. 4,163,622 : Cost 42.96795273 : Time 315.75s : 13900.51 words/s
[2019-08-06 11:21:02] Seen 4212135 samples
[2019-08-06 11:21:02] Starting epoch 11
[2019-08-06 11:21:02] [data] Shuffling data
[2019-08-06 11:21:05] [data] Done reading 5059895 sentences
[2019-08-06 11:21:29] [data] Done shuffling 5059895 sentences to temp files
[2019-08-06 11:25:38] Ep. 11 : Up. 420000 : Sen. 152,691 : Cost 42.49241257 : Time 352.82s : 12508.93 words/s
[2019-08-06 11:25:38] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-06 11:25:47] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter420000.npz
[2019-08-06 11:25:54] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-06 11:26:05] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 11:26:31] [valid] Ep. 11 : Up. 420000 : cross-entropy : 47.9095 : new best
[2019-08-06 11:26:38] [valid] Ep. 11 : Up. 420000 : perplexity : 6.63825 : new best
[2019-08-06 11:27:30] [valid] Ep. 11 : Up. 420000 : translation : 30.34 : new best
[2019-08-06 11:32:49] Ep. 11 : Up. 422000 : Sen. 354,505 : Cost 42.20301437 : Time 431.27s : 10263.91 words/s
[2019-08-06 11:38:06] Ep. 11 : Up. 424000 : Sen. 556,269 : Cost 42.06561661 : Time 316.64s : 13925.90 words/s
[2019-08-06 11:43:22] Ep. 11 : Up. 426000 : Sen. 757,774 : Cost 42.04470444 : Time 316.35s : 13943.67 words/s
[2019-08-06 11:48:39] Ep. 11 : Up. 428000 : Sen. 958,861 : Cost 42.19165421 : Time 316.74s : 13944.26 words/s
[2019-08-06 11:53:54] Ep. 11 : Up. 430000 : Sen. 1,159,838 : Cost 42.49807358 : Time 315.70s : 13952.99 words/s
[2019-08-06 11:59:11] Ep. 11 : Up. 432000 : Sen. 1,361,140 : Cost 42.54367447 : Time 316.70s : 13952.58 words/s
[2019-08-06 12:04:27] Ep. 11 : Up. 434000 : Sen. 1,562,461 : Cost 42.38288498 : Time 315.59s : 13956.04 words/s
[2019-08-06 12:09:42] Ep. 11 : Up. 436000 : Sen. 1,763,964 : Cost 42.20104980 : Time 315.62s : 13931.39 words/s
[2019-08-06 12:14:58] Ep. 11 : Up. 438000 : Sen. 1,964,356 : Cost 42.39679337 : Time 315.47s : 13927.06 words/s
[2019-08-06 12:20:14] Ep. 11 : Up. 440000 : Sen. 2,165,378 : Cost 42.55230713 : Time 315.99s : 13926.68 words/s
[2019-08-06 12:20:14] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-06 12:20:24] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter440000.npz
[2019-08-06 12:20:32] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-06 12:20:44] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 12:21:16] [valid] Ep. 11 : Up. 440000 : cross-entropy : 47.9343 : stalled 1 times (last best: 47.9095)
[2019-08-06 12:21:23] [valid] Ep. 11 : Up. 440000 : perplexity : 6.64476 : stalled 1 times (last best: 6.63825)
[2019-08-06 12:22:15] [valid] Ep. 11 : Up. 440000 : translation : 30.06 : stalled 1 times (last best: 30.34)
[2019-08-06 12:27:34] Ep. 11 : Up. 442000 : Sen. 2,366,325 : Cost 42.62104416 : Time 439.72s : 10016.58 words/s
[2019-08-06 12:32:50] Ep. 11 : Up. 444000 : Sen. 2,568,228 : Cost 42.35071182 : Time 316.70s : 13956.76 words/s
[2019-08-06 12:38:06] Ep. 11 : Up. 446000 : Sen. 2,770,026 : Cost 42.52873993 : Time 315.86s : 13960.66 words/s
[2019-08-06 12:43:22] Ep. 11 : Up. 448000 : Sen. 2,970,350 : Cost 42.68936157 : Time 315.74s : 13910.99 words/s
[2019-08-06 12:48:38] Ep. 11 : Up. 450000 : Sen. 3,171,296 : Cost 42.87190628 : Time 315.84s : 13969.25 words/s
[2019-08-06 12:53:53] Ep. 11 : Up. 452000 : Sen. 3,372,903 : Cost 42.48965073 : Time 315.65s : 13974.90 words/s
[2019-08-06 12:59:10] Ep. 11 : Up. 454000 : Sen. 3,574,659 : Cost 42.99865341 : Time 316.25s : 13987.81 words/s
[2019-08-06 13:04:28] Ep. 11 : Up. 456000 : Sen. 3,777,556 : Cost 42.81577682 : Time 317.95s : 13979.35 words/s
[2019-08-06 13:09:43] Ep. 11 : Up. 458000 : Sen. 3,979,673 : Cost 42.65438843 : Time 315.74s : 13994.54 words/s
[2019-08-06 13:14:59] Ep. 11 : Up. 460000 : Sen. 4,181,226 : Cost 42.67155075 : Time 315.89s : 13946.04 words/s
[2019-08-06 13:14:59] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-06 13:15:10] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter460000.npz
[2019-08-06 13:15:23] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-06 13:15:33] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 13:16:01] [valid] Ep. 11 : Up. 460000 : cross-entropy : 47.7966 : new best
[2019-08-06 13:16:07] [valid] Ep. 11 : Up. 460000 : perplexity : 6.60873 : new best
[2019-08-06 13:16:59] [valid] Ep. 11 : Up. 460000 : translation : 30.29 : stalled 2 times (last best: 30.34)
[2019-08-06 13:17:50] Seen 4212135 samples
[2019-08-06 13:17:50] Starting epoch 12
[2019-08-06 13:17:50] [data] Shuffling data
[2019-08-06 13:17:54] [data] Done reading 5059895 sentences
[2019-08-06 13:18:14] [data] Done shuffling 5059895 sentences to temp files
[2019-08-06 13:22:46] Ep. 12 : Up. 462000 : Sen. 169,344 : Cost 41.71808243 : Time 466.43s : 9400.98 words/s
[2019-08-06 13:28:02] Ep. 12 : Up. 464000 : Sen. 370,463 : Cost 41.70259476 : Time 316.05s : 13954.80 words/s
[2019-08-06 13:33:18] Ep. 12 : Up. 466000 : Sen. 571,542 : Cost 41.82015610 : Time 316.59s : 13933.91 words/s
[2019-08-06 13:38:36] Ep. 12 : Up. 468000 : Sen. 773,893 : Cost 42.07646942 : Time 317.54s : 13981.84 words/s
[2019-08-06 13:43:52] Ep. 12 : Up. 470000 : Sen. 975,238 : Cost 41.97985077 : Time 316.06s : 13952.77 words/s
[2019-08-06 13:49:08] Ep. 12 : Up. 472000 : Sen. 1,175,885 : Cost 42.07951736 : Time 315.70s : 13931.65 words/s
[2019-08-06 13:54:23] Ep. 12 : Up. 474000 : Sen. 1,376,166 : Cost 42.11357498 : Time 315.05s : 13932.68 words/s
[2019-08-06 13:59:36] Ep. 12 : Up. 476000 : Sen. 1,577,218 : Cost 41.98510361 : Time 313.12s : 14046.16 words/s
[2019-08-06 14:04:51] Ep. 12 : Up. 478000 : Sen. 1,777,505 : Cost 42.32126999 : Time 315.43s : 13923.54 words/s
[2019-08-06 14:10:08] Ep. 12 : Up. 480000 : Sen. 1,978,753 : Cost 42.21913910 : Time 316.34s : 13955.58 words/s
[2019-08-06 14:10:08] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-06 14:10:17] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter480000.npz
[2019-08-06 14:10:24] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-06 14:10:34] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 14:11:01] [valid] Ep. 12 : Up. 480000 : cross-entropy : 47.881 : stalled 1 times (last best: 47.7966)
[2019-08-06 14:11:07] [valid] Ep. 12 : Up. 480000 : perplexity : 6.6308 : stalled 1 times (last best: 6.60873)
[2019-08-06 14:11:59] [valid] Ep. 12 : Up. 480000 : translation : 30.3 : stalled 3 times (last best: 30.34)
[2019-08-06 14:17:17] Ep. 12 : Up. 482000 : Sen. 2,179,643 : Cost 42.09808731 : Time 429.31s : 10250.01 words/s
[2019-08-06 14:22:34] Ep. 12 : Up. 484000 : Sen. 2,381,222 : Cost 42.00515366 : Time 317.58s : 13910.35 words/s
[2019-08-06 14:27:50] Ep. 12 : Up. 486000 : Sen. 2,581,734 : Cost 42.21413803 : Time 315.17s : 13918.74 words/s
[2019-08-06 14:33:07] Ep. 12 : Up. 488000 : Sen. 2,783,365 : Cost 42.07312393 : Time 317.06s : 13902.35 words/s
[2019-08-06 14:38:23] Ep. 12 : Up. 490000 : Sen. 2,984,496 : Cost 42.05516815 : Time 316.82s : 13898.29 words/s
[2019-08-06 14:43:41] Ep. 12 : Up. 492000 : Sen. 3,186,141 : Cost 42.22484207 : Time 317.21s : 13908.71 words/s
[2019-08-06 14:48:58] Ep. 12 : Up. 494000 : Sen. 3,386,848 : Cost 42.42852020 : Time 316.92s : 13877.80 words/s
[2019-08-06 14:54:15] Ep. 12 : Up. 496000 : Sen. 3,589,419 : Cost 42.27711868 : Time 317.29s : 13943.15 words/s
[2019-08-06 14:59:32] Ep. 12 : Up. 498000 : Sen. 3,790,509 : Cost 42.49942398 : Time 317.47s : 13897.49 words/s
[2019-08-06 15:04:49] Ep. 12 : Up. 500000 : Sen. 3,992,082 : Cost 42.40516281 : Time 316.82s : 13915.94 words/s
[2019-08-06 15:04:49] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-06 15:04:59] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter500000.npz
[2019-08-06 15:05:06] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-06 15:05:16] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 15:05:42] [valid] Ep. 12 : Up. 500000 : cross-entropy : 47.7668 : new best
[2019-08-06 15:05:49] [valid] Ep. 12 : Up. 500000 : perplexity : 6.60096 : new best
[2019-08-06 15:06:41] [valid] Ep. 12 : Up. 500000 : translation : 30.36 : new best
[2019-08-06 15:12:00] Ep. 12 : Up. 502000 : Sen. 4,193,912 : Cost 42.21409225 : Time 430.94s : 10223.11 words/s
[2019-08-06 15:12:29] Seen 4212135 samples
[2019-08-06 15:12:29] Starting epoch 13
[2019-08-06 15:12:29] [data] Shuffling data
[2019-08-06 15:12:32] [data] Done reading 5059895 sentences
[2019-08-06 15:12:54] [data] Done shuffling 5059895 sentences to temp files
[2019-08-06 15:17:45] Ep. 13 : Up. 504000 : Sen. 184,803 : Cost 41.37455368 : Time 345.37s : 12876.93 words/s
[2019-08-06 15:23:02] Ep. 13 : Up. 506000 : Sen. 385,127 : Cost 41.41004181 : Time 316.05s : 13890.36 words/s
[2019-08-06 15:28:18] Ep. 13 : Up. 508000 : Sen. 585,969 : Cost 41.70240402 : Time 316.85s : 13892.07 words/s
[2019-08-06 15:33:35] Ep. 13 : Up. 510000 : Sen. 788,219 : Cost 41.29417419 : Time 317.04s : 13956.07 words/s
[2019-08-06 15:38:52] Ep. 13 : Up. 512000 : Sen. 989,703 : Cost 41.49125671 : Time 316.96s : 13903.72 words/s
[2019-08-06 15:44:09] Ep. 13 : Up. 514000 : Sen. 1,190,400 : Cost 41.74864197 : Time 316.96s : 13902.15 words/s
[2019-08-06 15:49:26] Ep. 13 : Up. 516000 : Sen. 1,391,922 : Cost 41.53366470 : Time 316.85s : 13902.04 words/s
[2019-08-06 15:54:43] Ep. 13 : Up. 518000 : Sen. 1,592,816 : Cost 41.90700531 : Time 316.95s : 13907.07 words/s
[2019-08-06 16:00:00] Ep. 13 : Up. 520000 : Sen. 1,794,438 : Cost 41.62925720 : Time 317.26s : 13907.52 words/s
[2019-08-06 16:00:00] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-06 16:00:15] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter520000.npz
[2019-08-06 16:00:22] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-06 16:00:32] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 16:00:58] [valid] Ep. 13 : Up. 520000 : cross-entropy : 47.8398 : stalled 1 times (last best: 47.7668)
[2019-08-06 16:01:05] [valid] Ep. 13 : Up. 520000 : perplexity : 6.62002 : stalled 1 times (last best: 6.60096)
[2019-08-06 16:01:59] [valid] Ep. 13 : Up. 520000 : translation : 30.33 : stalled 1 times (last best: 30.36)
[2019-08-06 16:07:18] Ep. 13 : Up. 522000 : Sen. 1,995,309 : Cost 41.79470825 : Time 437.72s : 10046.69 words/s
[2019-08-06 16:12:36] Ep. 13 : Up. 524000 : Sen. 2,196,714 : Cost 41.72751236 : Time 318.12s : 13847.70 words/s
[2019-08-06 16:17:54] Ep. 13 : Up. 526000 : Sen. 2,398,913 : Cost 41.68762589 : Time 317.57s : 13913.43 words/s
[2019-08-06 16:23:11] Ep. 13 : Up. 528000 : Sen. 2,599,813 : Cost 42.09543610 : Time 317.44s : 13872.70 words/s
[2019-08-06 16:28:30] Ep. 13 : Up. 530000 : Sen. 2,801,623 : Cost 42.03694534 : Time 318.74s : 13906.96 words/s
[2019-08-06 16:33:48] Ep. 13 : Up. 532000 : Sen. 3,003,795 : Cost 41.95257187 : Time 317.94s : 13909.74 words/s
[2019-08-06 16:39:06] Ep. 13 : Up. 534000 : Sen. 3,205,233 : Cost 42.06684113 : Time 317.71s : 13879.88 words/s
[2019-08-06 16:44:22] Ep. 13 : Up. 536000 : Sen. 3,406,079 : Cost 41.90033722 : Time 316.22s : 13877.53 words/s
[2019-08-06 16:49:41] Ep. 13 : Up. 538000 : Sen. 3,607,640 : Cost 42.16626740 : Time 318.90s : 13878.27 words/s
[2019-08-06 16:54:59] Ep. 13 : Up. 540000 : Sen. 3,809,225 : Cost 42.01008987 : Time 318.35s : 13866.78 words/s
[2019-08-06 16:54:59] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-06 16:55:10] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter540000.npz
[2019-08-06 16:55:17] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-06 16:55:28] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 16:55:55] [valid] Ep. 13 : Up. 540000 : cross-entropy : 47.7355 : new best
[2019-08-06 16:56:02] [valid] Ep. 13 : Up. 540000 : perplexity : 6.59279 : new best
[2019-08-06 16:56:54] [valid] Ep. 13 : Up. 540000 : translation : 30.48 : new best
[2019-08-06 17:02:15] Ep. 13 : Up. 542000 : Sen. 4,010,363 : Cost 42.29436874 : Time 435.68s : 10143.34 words/s
[2019-08-06 17:07:33] Ep. 13 : Up. 544000 : Sen. 4,211,380 : Cost 42.13869858 : Time 317.77s : 13857.60 words/s
[2019-08-06 17:07:34] Seen 4212135 samples
[2019-08-06 17:07:34] Starting epoch 14
[2019-08-06 17:07:34] [data] Shuffling data
[2019-08-06 17:07:37] [data] Done reading 5059895 sentences
[2019-08-06 17:08:03] [data] Done shuffling 5059895 sentences to temp files
[2019-08-06 17:13:29] Ep. 14 : Up. 546000 : Sen. 200,686 : Cost 40.91252899 : Time 356.23s : 12361.86 words/s
[2019-08-06 17:18:46] Ep. 14 : Up. 548000 : Sen. 401,458 : Cost 41.21711349 : Time 317.56s : 13862.11 words/s
[2019-08-06 17:24:05] Ep. 14 : Up. 550000 : Sen. 602,784 : Cost 41.22060013 : Time 318.85s : 13821.18 words/s
[2019-08-06 17:29:24] Ep. 14 : Up. 552000 : Sen. 804,435 : Cost 41.29966736 : Time 318.48s : 13875.53 words/s
[2019-08-06 17:34:43] Ep. 14 : Up. 554000 : Sen. 1,007,178 : Cost 41.24737167 : Time 319.67s : 13898.65 words/s
[2019-08-06 17:40:02] Ep. 14 : Up. 556000 : Sen. 1,208,805 : Cost 41.30955505 : Time 318.55s : 13882.07 words/s
[2019-08-06 17:45:19] Ep. 14 : Up. 558000 : Sen. 1,409,481 : Cost 41.36140823 : Time 317.45s : 13840.70 words/s
[2019-08-06 17:50:37] Ep. 14 : Up. 560000 : Sen. 1,611,568 : Cost 41.34187698 : Time 317.84s : 13898.06 words/s
[2019-08-06 17:50:37] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-06 17:50:49] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter560000.npz
[2019-08-06 17:50:56] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-06 17:51:06] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 17:51:36] [valid] Ep. 14 : Up. 560000 : cross-entropy : 47.8236 : stalled 1 times (last best: 47.7355)
[2019-08-06 17:51:42] [valid] Ep. 14 : Up. 560000 : perplexity : 6.61576 : stalled 1 times (last best: 6.59279)
[2019-08-06 17:52:34] [valid] Ep. 14 : Up. 560000 : translation : 30.38 : stalled 1 times (last best: 30.48)
[2019-08-06 17:57:53] Ep. 14 : Up. 562000 : Sen. 1,812,200 : Cost 41.43110657 : Time 435.82s : 10067.88 words/s
[2019-08-06 18:03:11] Ep. 14 : Up. 564000 : Sen. 2,013,133 : Cost 41.49053574 : Time 317.57s : 13850.00 words/s
[2019-08-06 18:08:29] Ep. 14 : Up. 566000 : Sen. 2,214,293 : Cost 41.56445312 : Time 318.23s : 13839.40 words/s
[2019-08-06 18:13:47] Ep. 14 : Up. 568000 : Sen. 2,414,295 : Cost 41.71162415 : Time 318.40s : 13810.47 words/s
[2019-08-06 18:19:05] Ep. 14 : Up. 570000 : Sen. 2,615,621 : Cost 41.68668365 : Time 317.89s : 13844.18 words/s
[2019-08-06 18:24:23] Ep. 14 : Up. 572000 : Sen. 2,816,368 : Cost 41.72402191 : Time 317.46s : 13853.01 words/s
[2019-08-06 18:29:42] Ep. 14 : Up. 574000 : Sen. 3,019,041 : Cost 41.72070694 : Time 319.47s : 13883.06 words/s
[2019-08-06 18:35:01] Ep. 14 : Up. 576000 : Sen. 3,220,221 : Cost 41.89067078 : Time 318.50s : 13836.45 words/s
[2019-08-06 18:40:20] Ep. 14 : Up. 578000 : Sen. 3,421,601 : Cost 41.78727341 : Time 319.38s : 13821.20 words/s
[2019-08-06 18:45:40] Ep. 14 : Up. 580000 : Sen. 3,624,345 : Cost 41.45675659 : Time 319.72s : 13855.33 words/s
[2019-08-06 18:45:40] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-06 18:45:50] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter580000.npz
[2019-08-06 18:45:58] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-06 18:46:08] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 18:46:37] [valid] Ep. 14 : Up. 580000 : cross-entropy : 47.6501 : new best
[2019-08-06 18:46:43] [valid] Ep. 14 : Up. 580000 : perplexity : 6.57058 : new best
[2019-08-06 18:47:36] [valid] Ep. 14 : Up. 580000 : translation : 30.59 : new best
[2019-08-06 18:52:56] Ep. 14 : Up. 582000 : Sen. 3,825,197 : Cost 41.85606384 : Time 436.57s : 10107.96 words/s
[2019-08-06 18:58:16] Ep. 14 : Up. 584000 : Sen. 4,026,738 : Cost 41.63877487 : Time 319.54s : 13789.89 words/s
[2019-08-06 19:03:11] Seen 4212135 samples
[2019-08-06 19:03:11] Starting epoch 15
[2019-08-06 19:03:11] [data] Shuffling data
[2019-08-06 19:03:14] [data] Done reading 5059895 sentences
[2019-08-06 19:03:37] [data] Done shuffling 5059895 sentences to temp files
[2019-08-06 19:04:11] Ep. 15 : Up. 586000 : Sen. 15,270 : Cost 41.85817337 : Time 355.20s : 12402.68 words/s
[2019-08-06 19:09:27] Ep. 15 : Up. 588000 : Sen. 215,526 : Cost 40.50617599 : Time 316.46s : 13850.15 words/s
[2019-08-06 19:14:47] Ep. 15 : Up. 590000 : Sen. 417,224 : Cost 40.76446152 : Time 319.28s : 13846.79 words/s
[2019-08-06 19:20:05] Ep. 15 : Up. 592000 : Sen. 618,364 : Cost 40.83320999 : Time 317.93s : 13837.69 words/s
[2019-08-06 19:25:24] Ep. 15 : Up. 594000 : Sen. 819,406 : Cost 41.13154602 : Time 318.98s : 13808.59 words/s
[2019-08-06 19:30:43] Ep. 15 : Up. 596000 : Sen. 1,021,162 : Cost 41.02930832 : Time 319.50s : 13837.76 words/s
[2019-08-06 19:36:02] Ep. 15 : Up. 598000 : Sen. 1,222,151 : Cost 40.94548798 : Time 318.38s : 13812.54 words/s
[2019-08-06 19:41:20] Ep. 15 : Up. 600000 : Sen. 1,423,529 : Cost 41.07961273 : Time 318.66s : 13843.63 words/s
[2019-08-06 19:41:20] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-06 19:41:30] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter600000.npz
[2019-08-06 19:41:38] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-06 19:41:48] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 19:42:14] [valid] Ep. 15 : Up. 600000 : cross-entropy : 47.719 : stalled 1 times (last best: 47.6501)
[2019-08-06 19:42:21] [valid] Ep. 15 : Up. 600000 : perplexity : 6.58849 : stalled 1 times (last best: 6.57058)
[2019-08-06 19:43:14] [valid] Ep. 15 : Up. 600000 : translation : 30.41 : stalled 1 times (last best: 30.59)
[2019-08-06 19:48:35] Ep. 15 : Up. 602000 : Sen. 1,624,841 : Cost 41.25066757 : Time 434.98s : 10131.78 words/s
[2019-08-06 19:53:54] Ep. 15 : Up. 604000 : Sen. 1,826,599 : Cost 41.31444168 : Time 319.17s : 13867.60 words/s
[2019-08-06 19:59:13] Ep. 15 : Up. 606000 : Sen. 2,029,156 : Cost 41.22569656 : Time 318.99s : 13881.91 words/s
[2019-08-06 20:04:32] Ep. 15 : Up. 608000 : Sen. 2,230,749 : Cost 41.33995056 : Time 318.48s : 13858.30 words/s
[2019-08-06 20:09:50] Ep. 15 : Up. 610000 : Sen. 2,432,210 : Cost 41.29409027 : Time 318.49s : 13855.16 words/s
[2019-08-06 20:15:09] Ep. 15 : Up. 612000 : Sen. 2,633,396 : Cost 41.51281357 : Time 318.35s : 13845.21 words/s
[2019-08-06 20:20:27] Ep. 15 : Up. 614000 : Sen. 2,834,516 : Cost 41.48648453 : Time 317.96s : 13849.66 words/s
[2019-08-06 20:25:46] Ep. 15 : Up. 616000 : Sen. 3,036,252 : Cost 41.69110489 : Time 319.77s : 13861.96 words/s
[2019-08-06 20:31:05] Ep. 15 : Up. 618000 : Sen. 3,237,046 : Cost 41.53696442 : Time 318.87s : 13804.92 words/s
[2019-08-06 20:36:24] Ep. 15 : Up. 620000 : Sen. 3,438,496 : Cost 41.37955093 : Time 318.46s : 13829.52 words/s
[2019-08-06 20:36:24] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-06 20:36:34] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter620000.npz
[2019-08-06 20:36:41] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-06 20:36:51] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 20:37:18] [valid] Ep. 15 : Up. 620000 : cross-entropy : 47.6596 : stalled 2 times (last best: 47.6501)
[2019-08-06 20:37:24] [valid] Ep. 15 : Up. 620000 : perplexity : 6.57305 : stalled 2 times (last best: 6.57058)
[2019-08-06 20:38:17] [valid] Ep. 15 : Up. 620000 : translation : 30.33 : stalled 2 times (last best: 30.59)
[2019-08-06 20:43:37] Ep. 15 : Up. 622000 : Sen. 3,639,046 : Cost 41.51915359 : Time 432.98s : 10152.58 words/s
[2019-08-06 20:48:53] Ep. 15 : Up. 624000 : Sen. 3,839,844 : Cost 41.36889648 : Time 316.61s : 13848.23 words/s
[2019-08-06 20:54:13] Ep. 15 : Up. 626000 : Sen. 4,040,886 : Cost 41.65044785 : Time 319.13s : 13819.29 words/s
[2019-08-06 20:58:43] Seen 4212135 samples
[2019-08-06 20:58:43] Starting epoch 16
[2019-08-06 20:58:43] [data] Shuffling data
[2019-08-06 20:58:46] [data] Done reading 5059895 sentences
[2019-08-06 20:59:10] [data] Done shuffling 5059895 sentences to temp files
[2019-08-06 21:00:07] Ep. 16 : Up. 628000 : Sen. 29,046 : Cost 41.23364639 : Time 354.34s : 12357.94 words/s
[2019-08-06 21:05:25] Ep. 16 : Up. 630000 : Sen. 229,968 : Cost 40.42986679 : Time 318.10s : 13839.40 words/s
[2019-08-06 21:10:42] Ep. 16 : Up. 632000 : Sen. 430,249 : Cost 40.52910233 : Time 317.06s : 13833.50 words/s
[2019-08-06 21:16:00] Ep. 16 : Up. 634000 : Sen. 631,605 : Cost 40.91608810 : Time 317.69s : 13889.79 words/s
[2019-08-06 21:21:18] Ep. 16 : Up. 636000 : Sen. 833,436 : Cost 40.57735062 : Time 318.24s : 13863.09 words/s
[2019-08-06 21:26:36] Ep. 16 : Up. 638000 : Sen. 1,035,385 : Cost 40.66473389 : Time 318.42s : 13869.79 words/s
[2019-08-06 21:31:53] Ep. 16 : Up. 640000 : Sen. 1,235,569 : Cost 40.72548294 : Time 316.99s : 13828.07 words/s
[2019-08-06 21:31:53] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-06 21:32:03] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter640000.npz
[2019-08-06 21:32:10] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-06 21:32:21] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 21:32:48] [valid] Ep. 16 : Up. 640000 : cross-entropy : 47.7145 : stalled 3 times (last best: 47.6501)
[2019-08-06 21:32:54] [valid] Ep. 16 : Up. 640000 : perplexity : 6.58731 : stalled 3 times (last best: 6.57058)
[2019-08-06 21:33:47] [valid] Ep. 16 : Up. 640000 : translation : 30.41 : stalled 3 times (last best: 30.59)
[2019-08-06 21:39:07] Ep. 16 : Up. 642000 : Sen. 1,437,437 : Cost 40.87594604 : Time 434.13s : 10169.57 words/s
[2019-08-06 21:44:26] Ep. 16 : Up. 644000 : Sen. 1,639,377 : Cost 40.96949005 : Time 318.70s : 13862.64 words/s
[2019-08-06 21:49:46] Ep. 16 : Up. 646000 : Sen. 1,840,590 : Cost 41.16645432 : Time 319.32s : 13845.21 words/s
[2019-08-06 21:55:04] Ep. 16 : Up. 648000 : Sen. 2,042,014 : Cost 40.90060425 : Time 318.13s : 13853.52 words/s
[2019-08-06 22:00:22] Ep. 16 : Up. 650000 : Sen. 2,244,144 : Cost 40.93421936 : Time 318.28s : 13892.52 words/s
[2019-08-06 22:05:41] Ep. 16 : Up. 652000 : Sen. 2,445,293 : Cost 41.21871948 : Time 318.97s : 13826.93 words/s
[2019-08-06 22:10:59] Ep. 16 : Up. 654000 : Sen. 2,646,205 : Cost 41.25019073 : Time 318.29s : 13830.97 words/s
[2019-08-06 22:16:18] Ep. 16 : Up. 656000 : Sen. 2,847,424 : Cost 40.91621780 : Time 318.56s : 13808.92 words/s
[2019-08-06 22:21:36] Ep. 16 : Up. 658000 : Sen. 3,048,923 : Cost 41.09560013 : Time 318.13s : 13851.73 words/s
[2019-08-06 22:26:55] Ep. 16 : Up. 660000 : Sen. 3,249,942 : Cost 41.14314651 : Time 318.71s : 13840.12 words/s
[2019-08-06 22:26:55] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-06 22:27:08] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter660000.npz
[2019-08-06 22:27:20] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-06 22:27:40] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 22:28:16] [valid] Ep. 16 : Up. 660000 : cross-entropy : 47.7001 : stalled 4 times (last best: 47.6501)
[2019-08-06 22:28:22] [valid] Ep. 16 : Up. 660000 : perplexity : 6.58356 : stalled 4 times (last best: 6.57058)
[2019-08-06 22:29:17] [valid] Ep. 16 : Up. 660000 : translation : 30.56 : stalled 4 times (last best: 30.59)
[2019-08-06 22:34:38] Ep. 16 : Up. 662000 : Sen. 3,450,980 : Cost 41.27873993 : Time 463.64s : 9519.10 words/s
[2019-08-06 22:39:56] Ep. 16 : Up. 664000 : Sen. 3,651,155 : Cost 41.25140381 : Time 317.94s : 13799.70 words/s
[2019-08-06 22:45:14] Ep. 16 : Up. 666000 : Sen. 3,852,431 : Cost 41.09843063 : Time 318.07s : 13845.00 words/s
[2019-08-06 22:50:33] Ep. 16 : Up. 668000 : Sen. 4,053,391 : Cost 41.47848892 : Time 319.11s : 13816.90 words/s
[2019-08-06 22:54:46] Seen 4212135 samples
[2019-08-06 22:54:46] Starting epoch 17
[2019-08-06 22:54:46] [data] Shuffling data
[2019-08-06 22:54:49] [data] Done reading 5059895 sentences
[2019-08-06 22:55:08] [data] Done shuffling 5059895 sentences to temp files
[2019-08-06 22:56:36] Ep. 17 : Up. 670000 : Sen. 42,615 : Cost 41.13236237 : Time 362.19s : 12203.96 words/s
[2019-08-06 23:01:54] Ep. 17 : Up. 672000 : Sen. 243,608 : Cost 40.23807907 : Time 318.14s : 13818.74 words/s
[2019-08-06 23:07:11] Ep. 17 : Up. 674000 : Sen. 443,703 : Cost 40.17342377 : Time 316.87s : 13789.22 words/s
[2019-08-06 23:12:28] Ep. 17 : Up. 676000 : Sen. 643,938 : Cost 40.41786957 : Time 317.63s : 13808.30 words/s
[2019-08-06 23:17:47] Ep. 17 : Up. 678000 : Sen. 844,878 : Cost 40.62491608 : Time 318.78s : 13824.82 words/s
[2019-08-06 23:23:05] Ep. 17 : Up. 680000 : Sen. 1,046,419 : Cost 40.41329956 : Time 318.24s : 13839.10 words/s
[2019-08-06 23:23:05] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-06 23:23:15] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.iter680000.npz
[2019-08-06 23:23:22] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-06 23:23:33] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
[2019-08-06 23:24:00] [valid] Ep. 17 : Up. 680000 : cross-entropy : 47.6674 : stalled 5 times (last best: 47.6501)
[2019-08-06 23:24:07] [valid] Ep. 17 : Up. 680000 : perplexity : 6.57507 : stalled 5 times (last best: 6.57058)
[2019-08-06 23:25:00] [valid] Ep. 17 : Up. 680000 : translation : 30.45 : stalled 5 times (last best: 30.59)
[2019-08-06 23:25:02] Training finished
[2019-08-06 23:25:07] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.orig.npz
[2019-08-06 23:25:17] Saving model to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz
[2019-08-06 23:25:27] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_biced_0.5_x_dcce/model/model.npz.optimizer.npz
