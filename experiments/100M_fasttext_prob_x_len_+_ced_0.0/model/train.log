[2019-07-16 19:26:24] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-16 19:26:24] [marian] Running on fulla as process 81914 with command line:
[2019-07-16 19:26:24] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz -T . --devices 4 --train-sets ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/data/train.bpe.de ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/data/train.bpe.en --vocabs ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/data/train.bpe.de.json ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/data/train.bpe.en.json --mini-batch-fit -w 5000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/data/dev.bpe.de ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/dev.out --valid-script-path ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/train.log --valid-log ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/valid.log
[2019-07-16 19:26:24] [config] after-batches: 0
[2019-07-16 19:26:24] [config] after-epochs: 0
[2019-07-16 19:26:24] [config] allow-unk: false
[2019-07-16 19:26:24] [config] beam-size: 12
[2019-07-16 19:26:24] [config] bert-class-symbol: "[CLS]"
[2019-07-16 19:26:24] [config] bert-mask-symbol: "[MASK]"
[2019-07-16 19:26:24] [config] bert-masking-fraction: 0.15
[2019-07-16 19:26:24] [config] bert-sep-symbol: "[SEP]"
[2019-07-16 19:26:24] [config] bert-train-type-embeddings: true
[2019-07-16 19:26:24] [config] bert-type-vocab-size: 2
[2019-07-16 19:26:24] [config] best-deep: false
[2019-07-16 19:26:24] [config] clip-gemm: 0
[2019-07-16 19:26:24] [config] clip-norm: 1
[2019-07-16 19:26:24] [config] cost-type: ce-mean
[2019-07-16 19:26:24] [config] cpu-threads: 0
[2019-07-16 19:26:24] [config] data-weighting: ""
[2019-07-16 19:26:24] [config] data-weighting-type: sentence
[2019-07-16 19:26:24] [config] dec-cell: gru
[2019-07-16 19:26:24] [config] dec-cell-base-depth: 2
[2019-07-16 19:26:24] [config] dec-cell-high-depth: 1
[2019-07-16 19:26:24] [config] dec-depth: 1
[2019-07-16 19:26:24] [config] devices:
[2019-07-16 19:26:24] [config]   - 4
[2019-07-16 19:26:24] [config] dim-emb: 512
[2019-07-16 19:26:24] [config] dim-rnn: 1024
[2019-07-16 19:26:24] [config] dim-vocabs:
[2019-07-16 19:26:24] [config]   - 50000
[2019-07-16 19:26:24] [config]   - 50000
[2019-07-16 19:26:24] [config] disp-first: 0
[2019-07-16 19:26:24] [config] disp-freq: 2000
[2019-07-16 19:26:24] [config] disp-label-counts: false
[2019-07-16 19:26:24] [config] dropout-rnn: 0.2
[2019-07-16 19:26:24] [config] dropout-src: 0.1
[2019-07-16 19:26:24] [config] dropout-trg: 0.1
[2019-07-16 19:26:24] [config] dump-config: ""
[2019-07-16 19:26:24] [config] early-stopping: 5
[2019-07-16 19:26:24] [config] embedding-fix-src: false
[2019-07-16 19:26:24] [config] embedding-fix-trg: false
[2019-07-16 19:26:24] [config] embedding-normalization: false
[2019-07-16 19:26:24] [config] embedding-vectors:
[2019-07-16 19:26:24] [config]   []
[2019-07-16 19:26:24] [config] enc-cell: gru
[2019-07-16 19:26:24] [config] enc-cell-depth: 1
[2019-07-16 19:26:24] [config] enc-depth: 1
[2019-07-16 19:26:24] [config] enc-type: bidirectional
[2019-07-16 19:26:24] [config] exponential-smoothing: 0.0001
[2019-07-16 19:26:24] [config] grad-dropping-momentum: 0
[2019-07-16 19:26:24] [config] grad-dropping-rate: 0
[2019-07-16 19:26:24] [config] grad-dropping-warmup: 100
[2019-07-16 19:26:24] [config] guided-alignment: none
[2019-07-16 19:26:24] [config] guided-alignment-cost: mse
[2019-07-16 19:26:24] [config] guided-alignment-weight: 0.1
[2019-07-16 19:26:24] [config] ignore-model-config: false
[2019-07-16 19:26:24] [config] input-types:
[2019-07-16 19:26:24] [config]   []
[2019-07-16 19:26:24] [config] interpolate-env-vars: false
[2019-07-16 19:26:24] [config] keep-best: false
[2019-07-16 19:26:24] [config] label-smoothing: 0
[2019-07-16 19:26:24] [config] layer-normalization: true
[2019-07-16 19:26:24] [config] learn-rate: 0.0001
[2019-07-16 19:26:24] [config] log: ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/train.log
[2019-07-16 19:26:24] [config] log-level: info
[2019-07-16 19:26:24] [config] log-time-zone: ""
[2019-07-16 19:26:24] [config] lr-decay: 0
[2019-07-16 19:26:24] [config] lr-decay-freq: 50000
[2019-07-16 19:26:24] [config] lr-decay-inv-sqrt:
[2019-07-16 19:26:24] [config]   - 0
[2019-07-16 19:26:24] [config] lr-decay-repeat-warmup: false
[2019-07-16 19:26:24] [config] lr-decay-reset-optimizer: false
[2019-07-16 19:26:24] [config] lr-decay-start:
[2019-07-16 19:26:24] [config]   - 10
[2019-07-16 19:26:24] [config]   - 1
[2019-07-16 19:26:24] [config] lr-decay-strategy: epoch+stalled
[2019-07-16 19:26:24] [config] lr-report: false
[2019-07-16 19:26:24] [config] lr-warmup: 0
[2019-07-16 19:26:24] [config] lr-warmup-at-reload: false
[2019-07-16 19:26:24] [config] lr-warmup-cycle: false
[2019-07-16 19:26:24] [config] lr-warmup-start-rate: 0
[2019-07-16 19:26:24] [config] max-length: 50
[2019-07-16 19:26:24] [config] max-length-crop: false
[2019-07-16 19:26:24] [config] max-length-factor: 3
[2019-07-16 19:26:24] [config] maxi-batch: 100
[2019-07-16 19:26:24] [config] maxi-batch-sort: trg
[2019-07-16 19:26:24] [config] mini-batch: 64
[2019-07-16 19:26:24] [config] mini-batch-fit: true
[2019-07-16 19:26:24] [config] mini-batch-fit-step: 10
[2019-07-16 19:26:24] [config] mini-batch-overstuff: 1
[2019-07-16 19:26:24] [config] mini-batch-track-lr: false
[2019-07-16 19:26:24] [config] mini-batch-understuff: 1
[2019-07-16 19:26:24] [config] mini-batch-warmup: 0
[2019-07-16 19:26:24] [config] mini-batch-words: 0
[2019-07-16 19:26:24] [config] mini-batch-words-ref: 0
[2019-07-16 19:26:24] [config] model: ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz
[2019-07-16 19:26:24] [config] multi-loss-type: sum
[2019-07-16 19:26:24] [config] multi-node: false
[2019-07-16 19:26:24] [config] multi-node-overlap: true
[2019-07-16 19:26:24] [config] n-best: false
[2019-07-16 19:26:24] [config] no-nccl: false
[2019-07-16 19:26:24] [config] no-reload: false
[2019-07-16 19:26:24] [config] no-restore-corpus: false
[2019-07-16 19:26:24] [config] no-shuffle: false
[2019-07-16 19:26:24] [config] normalize: 1
[2019-07-16 19:26:24] [config] num-devices: 0
[2019-07-16 19:26:24] [config] optimizer: adam
[2019-07-16 19:26:24] [config] optimizer-delay: 1
[2019-07-16 19:26:24] [config] optimizer-params:
[2019-07-16 19:26:24] [config]   []
[2019-07-16 19:26:24] [config] overwrite: false
[2019-07-16 19:26:24] [config] pretrained-model: ""
[2019-07-16 19:26:24] [config] quiet: false
[2019-07-16 19:26:24] [config] quiet-translation: true
[2019-07-16 19:26:24] [config] relative-paths: false
[2019-07-16 19:26:24] [config] right-left: false
[2019-07-16 19:26:24] [config] save-freq: 20000
[2019-07-16 19:26:24] [config] seed: 1111
[2019-07-16 19:26:24] [config] shuffle-in-ram: false
[2019-07-16 19:26:24] [config] skip: false
[2019-07-16 19:26:24] [config] sqlite: ""
[2019-07-16 19:26:24] [config] sqlite-drop: false
[2019-07-16 19:26:24] [config] sync-sgd: true
[2019-07-16 19:26:24] [config] tempdir: .
[2019-07-16 19:26:24] [config] tied-embeddings: false
[2019-07-16 19:26:24] [config] tied-embeddings-all: false
[2019-07-16 19:26:24] [config] tied-embeddings-src: false
[2019-07-16 19:26:24] [config] train-sets:
[2019-07-16 19:26:24] [config]   - ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/data/train.bpe.de
[2019-07-16 19:26:24] [config]   - ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/data/train.bpe.en
[2019-07-16 19:26:24] [config] transformer-aan-activation: swish
[2019-07-16 19:26:24] [config] transformer-aan-depth: 2
[2019-07-16 19:26:24] [config] transformer-aan-nogate: false
[2019-07-16 19:26:24] [config] transformer-decoder-autoreg: self-attention
[2019-07-16 19:26:24] [config] transformer-dim-aan: 2048
[2019-07-16 19:26:24] [config] transformer-dim-ffn: 2048
[2019-07-16 19:26:24] [config] transformer-dropout: 0
[2019-07-16 19:26:24] [config] transformer-dropout-attention: 0
[2019-07-16 19:26:24] [config] transformer-dropout-ffn: 0
[2019-07-16 19:26:24] [config] transformer-ffn-activation: swish
[2019-07-16 19:26:24] [config] transformer-ffn-depth: 2
[2019-07-16 19:26:24] [config] transformer-guided-alignment-layer: last
[2019-07-16 19:26:24] [config] transformer-heads: 8
[2019-07-16 19:26:24] [config] transformer-no-projection: false
[2019-07-16 19:26:24] [config] transformer-postprocess: dan
[2019-07-16 19:26:24] [config] transformer-postprocess-emb: d
[2019-07-16 19:26:24] [config] transformer-preprocess: ""
[2019-07-16 19:26:24] [config] transformer-tied-layers:
[2019-07-16 19:26:24] [config]   []
[2019-07-16 19:26:24] [config] transformer-train-position-embeddings: false
[2019-07-16 19:26:24] [config] type: amun
[2019-07-16 19:26:24] [config] ulr: false
[2019-07-16 19:26:24] [config] ulr-dim-emb: 0
[2019-07-16 19:26:24] [config] ulr-dropout: 0
[2019-07-16 19:26:24] [config] ulr-keys-vectors: ""
[2019-07-16 19:26:24] [config] ulr-query-vectors: ""
[2019-07-16 19:26:24] [config] ulr-softmax-temperature: 1
[2019-07-16 19:26:24] [config] ulr-trainable-transformation: false
[2019-07-16 19:26:24] [config] valid-freq: 20000
[2019-07-16 19:26:24] [config] valid-log: ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/valid.log
[2019-07-16 19:26:24] [config] valid-max-length: 1000
[2019-07-16 19:26:24] [config] valid-metrics:
[2019-07-16 19:26:24] [config]   - cross-entropy
[2019-07-16 19:26:24] [config]   - perplexity
[2019-07-16 19:26:24] [config]   - translation
[2019-07-16 19:26:24] [config] valid-mini-batch: 8
[2019-07-16 19:26:24] [config] valid-script-path: ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/score-dev.sh
[2019-07-16 19:26:24] [config] valid-sets:
[2019-07-16 19:26:24] [config]   - ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/data/dev.bpe.de
[2019-07-16 19:26:24] [config]   - ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/data/dev.bpe.en
[2019-07-16 19:26:24] [config] valid-translation-output: ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/dev.out
[2019-07-16 19:26:24] [config] vocabs:
[2019-07-16 19:26:24] [config]   - ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/data/train.bpe.de.json
[2019-07-16 19:26:24] [config]   - ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/data/train.bpe.en.json
[2019-07-16 19:26:24] [config] word-penalty: 0
[2019-07-16 19:26:24] [config] workspace: 5000
[2019-07-16 19:26:24] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-16 19:26:24] Using synchronous training
[2019-07-16 19:26:24] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/data/train.bpe.de.json
[2019-07-16 19:26:24] [data] Using unused word id eos for 0
[2019-07-16 19:26:24] [data] Using unused word id UNK for 1
[2019-07-16 19:26:24] [data] Setting vocabulary size for input 0 to 50000
[2019-07-16 19:26:24] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/data/train.bpe.en.json
[2019-07-16 19:26:25] [data] Using unused word id eos for 0
[2019-07-16 19:26:25] [data] Using unused word id UNK for 1
[2019-07-16 19:26:25] [data] Setting vocabulary size for input 1 to 50000
[2019-07-16 19:26:25] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-16 19:26:25] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-16 19:26:26] [memory] Extending reserved space to 5120 MB (device gpu4)
[2019-07-16 19:26:27] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-16 19:26:27] [comm] NCCLCommunicator constructed successfully.
[2019-07-16 19:26:27] [training] Using 1 GPUs
[2019-07-16 19:26:27] [memory] Reserving 422 MB, device gpu4
[2019-07-16 19:26:27] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-16 19:26:27] [memory] Reserving 422 MB, device gpu4
[2019-07-16 19:26:31] [batching] Done. Typical MB size is 6880 target words
[2019-07-16 19:26:31] [memory] Extending reserved space to 5120 MB (device gpu4)
[2019-07-16 19:26:31] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-16 19:26:31] [comm] NCCLCommunicator constructed successfully.
[2019-07-16 19:26:31] [training] Using 1 GPUs
[2019-07-16 19:26:31] Training started
[2019-07-16 19:26:31] [data] Shuffling data
[2019-07-16 19:26:41] [data] Done reading 13926791 sentences
[2019-07-16 19:28:00] [data] Done shuffling 13926791 sentences to temp files
[2019-07-16 19:28:03] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-07-16 19:28:04] [memory] Reserving 422 MB, device gpu4
[2019-07-16 19:28:04] [memory] Reserving 422 MB, device gpu4
[2019-07-16 19:28:04] [memory] Reserving 422 MB, device gpu4
[2019-07-16 19:28:04] [memory] Reserving 844 MB, device gpu4
[2019-07-16 19:34:31] Ep. 1 : Up. 2000 : Sen. 288,980 : Cost 136.54823303 : Time 486.26s : 12516.92 words/s
[2019-07-16 19:41:02] Ep. 1 : Up. 4000 : Sen. 578,204 : Cost 119.03137970 : Time 390.55s : 15680.35 words/s
[2019-07-16 19:47:31] Ep. 1 : Up. 6000 : Sen. 867,195 : Cost 110.39547729 : Time 389.32s : 15669.04 words/s
[2019-07-16 19:54:01] Ep. 1 : Up. 8000 : Sen. 1,156,773 : Cost 104.51309967 : Time 389.84s : 15647.58 words/s
[2019-07-16 20:00:32] Ep. 1 : Up. 10000 : Sen. 1,446,400 : Cost 100.97905731 : Time 391.20s : 15657.00 words/s
[2019-07-16 20:07:02] Ep. 1 : Up. 12000 : Sen. 1,735,510 : Cost 97.38353729 : Time 389.68s : 15660.12 words/s
[2019-07-16 20:13:32] Ep. 1 : Up. 14000 : Sen. 2,024,931 : Cost 94.71213531 : Time 390.04s : 15666.52 words/s
[2019-07-16 20:20:02] Ep. 1 : Up. 16000 : Sen. 2,313,959 : Cost 92.62760925 : Time 389.88s : 15650.33 words/s
[2019-07-16 20:26:33] Ep. 1 : Up. 18000 : Sen. 2,603,553 : Cost 90.79666138 : Time 390.96s : 15666.29 words/s
[2019-07-16 20:33:03] Ep. 1 : Up. 20000 : Sen. 2,893,081 : Cost 89.25976562 : Time 390.61s : 15667.41 words/s
[2019-07-16 20:33:03] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.orig.npz
[2019-07-16 20:33:13] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.iter20000.npz
[2019-07-16 20:33:21] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz
[2019-07-16 20:33:31] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.optimizer.npz
[2019-07-16 20:33:58] [valid] Ep. 1 : Up. 20000 : cross-entropy : 90.0682 : new best
[2019-07-16 20:34:05] [valid] Ep. 1 : Up. 20000 : perplexity : 35.4786 : new best
[2019-07-16 20:35:07] [valid] Ep. 1 : Up. 20000 : translation : 12.18 : new best
[2019-07-16 20:41:41] Ep. 1 : Up. 22000 : Sen. 3,182,468 : Cost 87.54048920 : Time 517.32s : 11802.88 words/s
[2019-07-16 20:48:10] Ep. 1 : Up. 24000 : Sen. 3,470,162 : Cost 86.80567169 : Time 389.89s : 15601.71 words/s
[2019-07-16 20:54:41] Ep. 1 : Up. 26000 : Sen. 3,759,351 : Cost 85.22851562 : Time 390.38s : 15623.64 words/s
[2019-07-16 21:01:09] Ep. 1 : Up. 28000 : Sen. 4,047,724 : Cost 84.36366272 : Time 388.16s : 15674.49 words/s
[2019-07-16 21:07:40] Ep. 1 : Up. 30000 : Sen. 4,336,489 : Cost 84.11270905 : Time 390.93s : 15646.42 words/s
[2019-07-16 21:14:12] Ep. 1 : Up. 32000 : Sen. 4,626,838 : Cost 82.67533112 : Time 392.11s : 15627.60 words/s
[2019-07-16 21:20:42] Ep. 1 : Up. 34000 : Sen. 4,916,461 : Cost 82.17559052 : Time 389.84s : 15675.11 words/s
[2019-07-16 21:27:13] Ep. 1 : Up. 36000 : Sen. 5,205,922 : Cost 81.59806824 : Time 391.38s : 15632.19 words/s
[2019-07-16 21:33:42] Ep. 1 : Up. 38000 : Sen. 5,493,183 : Cost 80.86783600 : Time 388.98s : 15579.43 words/s
[2019-07-16 21:40:12] Ep. 1 : Up. 40000 : Sen. 5,782,326 : Cost 80.24402618 : Time 389.92s : 15663.41 words/s
[2019-07-16 21:40:12] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.orig.npz
[2019-07-16 21:40:23] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.iter40000.npz
[2019-07-16 21:40:31] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz
[2019-07-16 21:40:42] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.optimizer.npz
[2019-07-16 21:41:10] [valid] Ep. 1 : Up. 40000 : cross-entropy : 72.7446 : new best
[2019-07-16 21:41:16] [valid] Ep. 1 : Up. 40000 : perplexity : 17.8586 : new best
[2019-07-16 21:42:10] [valid] Ep. 1 : Up. 40000 : translation : 19.88 : new best
[2019-07-16 21:48:40] Ep. 1 : Up. 42000 : Sen. 6,070,898 : Cost 79.50328064 : Time 508.11s : 11968.17 words/s
[2019-07-16 21:55:09] Ep. 1 : Up. 44000 : Sen. 6,359,472 : Cost 79.28231049 : Time 388.79s : 15670.04 words/s
[2019-07-16 22:01:37] Ep. 1 : Up. 46000 : Sen. 6,647,230 : Cost 78.82022858 : Time 387.74s : 15684.34 words/s
[2019-07-16 22:08:04] Ep. 1 : Up. 48000 : Sen. 6,936,280 : Cost 78.35556793 : Time 387.32s : 15716.96 words/s
[2019-07-16 22:14:33] Ep. 1 : Up. 50000 : Sen. 7,225,336 : Cost 78.04203033 : Time 389.23s : 15691.99 words/s
[2019-07-16 22:21:03] Ep. 1 : Up. 52000 : Sen. 7,514,758 : Cost 77.95377350 : Time 389.93s : 15713.00 words/s
[2019-07-16 22:27:32] Ep. 1 : Up. 54000 : Sen. 7,804,147 : Cost 77.29322815 : Time 388.56s : 15695.13 words/s
[2019-07-16 22:34:01] Ep. 1 : Up. 56000 : Sen. 8,092,765 : Cost 77.26585388 : Time 389.20s : 15694.90 words/s
[2019-07-16 22:40:29] Ep. 1 : Up. 58000 : Sen. 8,381,837 : Cost 76.44075775 : Time 387.97s : 15677.55 words/s
[2019-07-16 22:46:57] Ep. 1 : Up. 60000 : Sen. 8,670,303 : Cost 76.67464447 : Time 388.05s : 15763.77 words/s
[2019-07-16 22:46:57] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.orig.npz
[2019-07-16 22:47:07] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.iter60000.npz
[2019-07-16 22:47:15] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz
[2019-07-16 22:47:25] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.optimizer.npz
[2019-07-16 22:47:53] [valid] Ep. 1 : Up. 60000 : cross-entropy : 65.9587 : new best
[2019-07-16 22:48:00] [valid] Ep. 1 : Up. 60000 : perplexity : 13.6481 : new best
[2019-07-16 22:48:52] [valid] Ep. 1 : Up. 60000 : translation : 22.15 : new best
[2019-07-16 22:55:24] Ep. 1 : Up. 62000 : Sen. 8,958,900 : Cost 76.21266937 : Time 506.48s : 12052.25 words/s
[2019-07-16 23:01:54] Ep. 1 : Up. 64000 : Sen. 9,248,264 : Cost 75.76342010 : Time 390.67s : 15639.12 words/s
[2019-07-16 23:08:24] Ep. 1 : Up. 66000 : Sen. 9,537,737 : Cost 75.60873413 : Time 390.05s : 15686.99 words/s
[2019-07-16 23:14:52] Ep. 1 : Up. 68000 : Sen. 9,827,260 : Cost 75.07115936 : Time 387.79s : 15711.36 words/s
[2019-07-16 23:21:24] Ep. 1 : Up. 70000 : Sen. 10,118,400 : Cost 75.22036743 : Time 391.50s : 15726.59 words/s
[2019-07-16 23:27:55] Ep. 1 : Up. 72000 : Sen. 10,408,572 : Cost 74.89627838 : Time 391.06s : 15648.70 words/s
[2019-07-16 23:34:23] Ep. 1 : Up. 74000 : Sen. 10,697,499 : Cost 74.48617554 : Time 388.72s : 15683.95 words/s
[2019-07-16 23:40:54] Ep. 1 : Up. 76000 : Sen. 10,988,042 : Cost 74.53586578 : Time 390.53s : 15734.06 words/s
[2019-07-16 23:47:25] Ep. 1 : Up. 78000 : Sen. 11,278,510 : Cost 74.08660126 : Time 391.57s : 15640.15 words/s
[2019-07-16 23:53:57] Ep. 1 : Up. 80000 : Sen. 11,568,046 : Cost 74.05547333 : Time 391.18s : 15667.24 words/s
[2019-07-16 23:53:57] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.orig.npz
[2019-07-16 23:54:08] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.iter80000.npz
[2019-07-16 23:54:16] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz
[2019-07-16 23:54:27] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.optimizer.npz
[2019-07-16 23:54:56] [valid] Ep. 1 : Up. 80000 : cross-entropy : 62.1534 : new best
[2019-07-16 23:55:03] [valid] Ep. 1 : Up. 80000 : perplexity : 11.7378 : new best
[2019-07-16 23:55:56] [valid] Ep. 1 : Up. 80000 : translation : 22.97 : new best
[2019-07-17 00:01:05] Seen 11795638 samples
[2019-07-17 00:01:05] Starting epoch 2
[2019-07-17 00:01:05] [data] Shuffling data
[2019-07-17 00:01:15] [data] Done reading 13926791 sentences
[2019-07-17 00:02:45] [data] Done shuffling 13926791 sentences to temp files
[2019-07-17 00:04:17] Ep. 2 : Up. 82000 : Sen. 60,755 : Cost 73.37213135 : Time 620.27s : 9799.10 words/s
[2019-07-17 00:10:47] Ep. 2 : Up. 84000 : Sen. 350,018 : Cost 72.80702972 : Time 390.03s : 15634.53 words/s
[2019-07-17 00:17:18] Ep. 2 : Up. 86000 : Sen. 639,208 : Cost 72.88005066 : Time 391.21s : 15604.00 words/s
[2019-07-17 00:23:48] Ep. 2 : Up. 88000 : Sen. 927,604 : Cost 72.72686005 : Time 390.08s : 15648.57 words/s
[2019-07-17 00:30:18] Ep. 2 : Up. 90000 : Sen. 1,216,264 : Cost 72.74986267 : Time 389.63s : 15660.68 words/s
[2019-07-17 00:36:49] Ep. 2 : Up. 92000 : Sen. 1,505,714 : Cost 72.33419037 : Time 391.52s : 15616.25 words/s
[2019-07-17 00:43:21] Ep. 2 : Up. 94000 : Sen. 1,795,593 : Cost 72.06813049 : Time 391.11s : 15625.95 words/s
[2019-07-17 00:49:51] Ep. 2 : Up. 96000 : Sen. 2,084,660 : Cost 72.26400757 : Time 390.76s : 15648.52 words/s
[2019-07-17 00:56:22] Ep. 2 : Up. 98000 : Sen. 2,374,532 : Cost 71.79778290 : Time 390.49s : 15650.01 words/s
[2019-07-17 01:02:52] Ep. 2 : Up. 100000 : Sen. 2,663,950 : Cost 71.91909027 : Time 390.02s : 15667.23 words/s
[2019-07-17 01:02:52] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.orig.npz
[2019-07-17 01:03:03] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.iter100000.npz
[2019-07-17 01:03:11] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz
[2019-07-17 01:03:21] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.optimizer.npz
[2019-07-17 01:03:49] [valid] Ep. 2 : Up. 100000 : cross-entropy : 59.7796 : new best
[2019-07-17 01:03:56] [valid] Ep. 2 : Up. 100000 : perplexity : 10.6841 : new best
[2019-07-17 01:04:48] [valid] Ep. 2 : Up. 100000 : translation : 23.67 : new best
[2019-07-17 01:11:21] Ep. 2 : Up. 102000 : Sen. 2,953,177 : Cost 71.98661804 : Time 509.34s : 11995.82 words/s
[2019-07-17 01:17:53] Ep. 2 : Up. 104000 : Sen. 3,242,991 : Cost 71.77878571 : Time 392.02s : 15631.47 words/s
[2019-07-17 01:24:24] Ep. 2 : Up. 106000 : Sen. 3,531,467 : Cost 71.84743500 : Time 391.26s : 15615.05 words/s
[2019-07-17 01:30:55] Ep. 2 : Up. 108000 : Sen. 3,820,800 : Cost 71.34513092 : Time 390.17s : 15631.87 words/s
[2019-07-17 01:37:27] Ep. 2 : Up. 110000 : Sen. 4,111,004 : Cost 71.39752960 : Time 392.92s : 15603.34 words/s
[2019-07-17 01:43:59] Ep. 2 : Up. 112000 : Sen. 4,399,927 : Cost 71.38674927 : Time 391.49s : 15617.14 words/s
[2019-07-17 01:50:29] Ep. 2 : Up. 114000 : Sen. 4,688,954 : Cost 71.01167297 : Time 389.98s : 15616.66 words/s
[2019-07-17 01:57:00] Ep. 2 : Up. 116000 : Sen. 4,978,672 : Cost 70.73120880 : Time 390.97s : 15615.37 words/s
[2019-07-17 02:03:31] Ep. 2 : Up. 118000 : Sen. 5,267,944 : Cost 71.16926575 : Time 391.46s : 15638.91 words/s
[2019-07-17 02:10:03] Ep. 2 : Up. 120000 : Sen. 5,557,872 : Cost 70.79637909 : Time 391.72s : 15632.03 words/s
[2019-07-17 02:10:03] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.orig.npz
[2019-07-17 02:10:14] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.iter120000.npz
[2019-07-17 02:10:26] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz
[2019-07-17 02:10:40] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.optimizer.npz
[2019-07-17 02:11:10] [valid] Ep. 2 : Up. 120000 : cross-entropy : 58.0373 : new best
[2019-07-17 02:11:17] [valid] Ep. 2 : Up. 120000 : perplexity : 9.97134 : new best
[2019-07-17 02:12:10] [valid] Ep. 2 : Up. 120000 : translation : 23.7 : new best
[2019-07-17 02:18:42] Ep. 2 : Up. 122000 : Sen. 5,847,308 : Cost 70.54518890 : Time 518.76s : 11774.73 words/s
[2019-07-17 02:25:12] Ep. 2 : Up. 124000 : Sen. 6,136,091 : Cost 70.80124664 : Time 390.37s : 15649.36 words/s
[2019-07-17 02:31:42] Ep. 2 : Up. 126000 : Sen. 6,424,898 : Cost 70.52343750 : Time 389.43s : 15657.32 words/s
[2019-07-17 02:38:10] Ep. 2 : Up. 128000 : Sen. 6,713,774 : Cost 70.48297882 : Time 388.74s : 15690.69 words/s
[2019-07-17 02:44:41] Ep. 2 : Up. 130000 : Sen. 7,002,877 : Cost 70.40260315 : Time 390.48s : 15648.34 words/s
[2019-07-17 02:51:12] Ep. 2 : Up. 132000 : Sen. 7,293,267 : Cost 70.09525299 : Time 391.04s : 15667.81 words/s
[2019-07-17 02:57:42] Ep. 2 : Up. 134000 : Sen. 7,582,527 : Cost 70.11315918 : Time 390.52s : 15639.57 words/s
[2019-07-17 03:04:11] Ep. 2 : Up. 136000 : Sen. 7,871,868 : Cost 70.04023743 : Time 388.82s : 15709.08 words/s
[2019-07-17 03:10:42] Ep. 2 : Up. 138000 : Sen. 8,161,607 : Cost 69.94534302 : Time 390.51s : 15655.86 words/s
[2019-07-17 03:17:12] Ep. 2 : Up. 140000 : Sen. 8,449,902 : Cost 69.89675140 : Time 389.73s : 15621.26 words/s
[2019-07-17 03:17:12] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.orig.npz
[2019-07-17 03:17:22] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.iter140000.npz
[2019-07-17 03:17:30] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz
[2019-07-17 03:17:46] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.optimizer.npz
[2019-07-17 03:18:18] [valid] Ep. 2 : Up. 140000 : cross-entropy : 56.721 : new best
[2019-07-17 03:18:25] [valid] Ep. 2 : Up. 140000 : perplexity : 9.46457 : new best
[2019-07-17 03:19:18] [valid] Ep. 2 : Up. 140000 : translation : 23.95 : new best
[2019-07-17 03:25:50] Ep. 2 : Up. 142000 : Sen. 8,739,677 : Cost 69.72516632 : Time 518.34s : 11815.04 words/s
[2019-07-17 03:32:20] Ep. 2 : Up. 144000 : Sen. 9,029,164 : Cost 69.43276978 : Time 389.62s : 15666.41 words/s
[2019-07-17 03:38:49] Ep. 2 : Up. 146000 : Sen. 9,317,608 : Cost 69.60349274 : Time 389.90s : 15640.98 words/s
[2019-07-17 03:45:19] Ep. 2 : Up. 148000 : Sen. 9,606,616 : Cost 69.58483124 : Time 389.88s : 15644.31 words/s
[2019-07-17 03:51:49] Ep. 2 : Up. 150000 : Sen. 9,895,565 : Cost 69.69332123 : Time 389.74s : 15676.33 words/s
[2019-07-17 03:58:18] Ep. 2 : Up. 152000 : Sen. 10,184,934 : Cost 69.16806793 : Time 389.36s : 15672.77 words/s
[2019-07-17 04:04:49] Ep. 2 : Up. 154000 : Sen. 10,474,463 : Cost 69.44702911 : Time 390.36s : 15658.63 words/s
[2019-07-17 04:11:17] Ep. 2 : Up. 156000 : Sen. 10,763,604 : Cost 69.26524353 : Time 388.54s : 15696.68 words/s
[2019-07-17 04:17:47] Ep. 2 : Up. 158000 : Sen. 11,053,064 : Cost 69.12272644 : Time 389.78s : 15677.99 words/s
[2019-07-17 04:24:17] Ep. 2 : Up. 160000 : Sen. 11,343,392 : Cost 68.98027802 : Time 389.84s : 15723.67 words/s
[2019-07-17 04:24:17] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.orig.npz
[2019-07-17 04:24:28] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.iter160000.npz
[2019-07-17 04:24:36] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz
[2019-07-17 04:24:48] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.optimizer.npz
[2019-07-17 04:25:18] [valid] Ep. 2 : Up. 160000 : cross-entropy : 55.7049 : new best
[2019-07-17 04:25:24] [valid] Ep. 2 : Up. 160000 : perplexity : 9.09109 : new best
[2019-07-17 04:26:18] [valid] Ep. 2 : Up. 160000 : translation : 24.41 : new best
[2019-07-17 04:32:50] Ep. 2 : Up. 162000 : Sen. 11,632,765 : Cost 68.83521271 : Time 513.36s : 11869.63 words/s
[2019-07-17 04:36:30] Seen 11795638 samples
[2019-07-17 04:36:30] Starting epoch 3
[2019-07-17 04:36:30] [data] Shuffling data
[2019-07-17 04:36:40] [data] Done reading 13926791 sentences
[2019-07-17 04:38:06] [data] Done shuffling 13926791 sentences to temp files
[2019-07-17 04:41:15] Ep. 3 : Up. 164000 : Sen. 125,956 : Cost 68.57050323 : Time 504.90s : 12057.87 words/s
[2019-07-17 04:47:44] Ep. 3 : Up. 166000 : Sen. 414,902 : Cost 68.26393127 : Time 388.89s : 15715.60 words/s
[2019-07-17 04:54:14] Ep. 3 : Up. 168000 : Sen. 704,132 : Cost 68.22153473 : Time 390.29s : 15681.69 words/s
[2019-07-17 05:00:44] Ep. 3 : Up. 170000 : Sen. 993,140 : Cost 68.27187347 : Time 389.60s : 15676.74 words/s
[2019-07-17 05:07:16] Ep. 3 : Up. 172000 : Sen. 1,283,106 : Cost 68.12208557 : Time 391.56s : 15647.09 words/s
[2019-07-17 05:13:46] Ep. 3 : Up. 174000 : Sen. 1,572,850 : Cost 68.30783844 : Time 390.71s : 15665.73 words/s
[2019-07-17 05:20:15] Ep. 3 : Up. 176000 : Sen. 1,862,664 : Cost 67.98125458 : Time 388.67s : 15717.94 words/s
[2019-07-17 05:26:45] Ep. 3 : Up. 178000 : Sen. 2,152,664 : Cost 68.02260590 : Time 389.88s : 15685.93 words/s
[2019-07-17 05:33:15] Ep. 3 : Up. 180000 : Sen. 2,441,819 : Cost 68.08524323 : Time 389.80s : 15676.31 words/s
[2019-07-17 05:33:15] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.orig.npz
[2019-07-17 05:33:25] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.iter180000.npz
[2019-07-17 05:33:32] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz
[2019-07-17 05:33:42] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.optimizer.npz
[2019-07-17 05:34:09] [valid] Ep. 3 : Up. 180000 : cross-entropy : 54.9489 : new best
[2019-07-17 05:34:16] [valid] Ep. 3 : Up. 180000 : perplexity : 8.82278 : new best
[2019-07-17 05:35:09] [valid] Ep. 3 : Up. 180000 : translation : 24.49 : new best
[2019-07-17 05:41:41] Ep. 3 : Up. 182000 : Sen. 2,730,166 : Cost 68.05201721 : Time 506.14s : 12045.45 words/s
[2019-07-17 05:48:10] Ep. 3 : Up. 184000 : Sen. 3,019,118 : Cost 67.99405670 : Time 389.54s : 15661.16 words/s
[2019-07-17 05:54:40] Ep. 3 : Up. 186000 : Sen. 3,307,876 : Cost 68.06251526 : Time 389.35s : 15662.59 words/s
[2019-07-17 06:01:09] Ep. 3 : Up. 188000 : Sen. 3,597,602 : Cost 67.85914612 : Time 389.84s : 15716.84 words/s
[2019-07-17 06:07:41] Ep. 3 : Up. 190000 : Sen. 3,887,736 : Cost 67.69761658 : Time 391.49s : 15647.07 words/s
[2019-07-17 06:14:11] Ep. 3 : Up. 192000 : Sen. 4,177,716 : Cost 67.52059174 : Time 389.93s : 15668.04 words/s
[2019-07-17 06:20:41] Ep. 3 : Up. 194000 : Sen. 4,467,200 : Cost 67.61111450 : Time 389.80s : 15672.77 words/s
[2019-07-17 06:27:10] Ep. 3 : Up. 196000 : Sen. 4,756,553 : Cost 67.93978119 : Time 389.73s : 15686.72 words/s
[2019-07-17 06:33:39] Ep. 3 : Up. 198000 : Sen. 5,045,569 : Cost 67.58380890 : Time 388.89s : 15691.37 words/s
[2019-07-17 06:40:09] Ep. 3 : Up. 200000 : Sen. 5,335,164 : Cost 67.44156647 : Time 389.52s : 15675.26 words/s
[2019-07-17 06:40:09] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.orig.npz
[2019-07-17 06:40:19] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.iter200000.npz
[2019-07-17 06:40:27] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz
[2019-07-17 06:40:38] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.optimizer.npz
[2019-07-17 06:41:06] [valid] Ep. 3 : Up. 200000 : cross-entropy : 54.4548 : new best
[2019-07-17 06:41:12] [valid] Ep. 3 : Up. 200000 : perplexity : 8.65173 : new best
[2019-07-17 06:42:06] [valid] Ep. 3 : Up. 200000 : translation : 24.93 : new best
[2019-07-17 06:48:39] Ep. 3 : Up. 202000 : Sen. 5,624,433 : Cost 67.67546082 : Time 510.44s : 11977.70 words/s
[2019-07-17 06:55:10] Ep. 3 : Up. 204000 : Sen. 5,913,600 : Cost 67.65158844 : Time 390.73s : 15655.72 words/s
[2019-07-17 07:01:40] Ep. 3 : Up. 206000 : Sen. 6,202,763 : Cost 67.51335907 : Time 389.68s : 15665.31 words/s
[2019-07-17 07:08:10] Ep. 3 : Up. 208000 : Sen. 6,492,937 : Cost 67.16235352 : Time 390.01s : 15667.41 words/s
[2019-07-17 07:14:40] Ep. 3 : Up. 210000 : Sen. 6,782,812 : Cost 67.75170135 : Time 390.54s : 15711.11 words/s
[2019-07-17 07:21:11] Ep. 3 : Up. 212000 : Sen. 7,072,660 : Cost 67.47720337 : Time 390.37s : 15703.92 words/s
[2019-07-17 07:27:41] Ep. 3 : Up. 214000 : Sen. 7,362,241 : Cost 67.24948883 : Time 389.98s : 15650.80 words/s
[2019-07-17 07:34:09] Ep. 3 : Up. 216000 : Sen. 7,650,574 : Cost 67.41145325 : Time 388.06s : 15702.57 words/s
[2019-07-17 07:40:38] Ep. 3 : Up. 218000 : Sen. 7,939,928 : Cost 67.22263336 : Time 389.78s : 15672.06 words/s
[2019-07-17 07:47:09] Ep. 3 : Up. 220000 : Sen. 8,230,136 : Cost 67.09268188 : Time 390.79s : 15638.67 words/s
[2019-07-17 07:47:09] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.orig.npz
[2019-07-17 07:47:19] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.iter220000.npz
[2019-07-17 07:47:26] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz
[2019-07-17 07:47:36] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.optimizer.npz
[2019-07-17 07:48:03] [valid] Ep. 3 : Up. 220000 : cross-entropy : 53.957 : new best
[2019-07-17 07:48:09] [valid] Ep. 3 : Up. 220000 : perplexity : 8.48273 : new best
[2019-07-17 07:49:02] [valid] Ep. 3 : Up. 220000 : translation : 24.87 : stalled 1 times (last best: 24.93)
[2019-07-17 07:55:34] Ep. 3 : Up. 222000 : Sen. 8,518,796 : Cost 67.12641907 : Time 504.42s : 12096.33 words/s
[2019-07-17 08:02:04] Ep. 3 : Up. 224000 : Sen. 8,808,009 : Cost 67.09148407 : Time 390.58s : 15624.73 words/s
[2019-07-17 08:08:33] Ep. 3 : Up. 226000 : Sen. 9,097,432 : Cost 66.94676971 : Time 388.73s : 15688.78 words/s
[2019-07-17 08:15:03] Ep. 3 : Up. 228000 : Sen. 9,385,677 : Cost 67.10898590 : Time 389.63s : 15617.31 words/s
[2019-07-17 08:21:34] Ep. 3 : Up. 230000 : Sen. 9,675,744 : Cost 67.20398712 : Time 391.56s : 15668.47 words/s
[2019-07-17 08:28:05] Ep. 3 : Up. 232000 : Sen. 9,965,426 : Cost 67.09176636 : Time 391.18s : 15629.12 words/s
[2019-07-17 08:34:34] Ep. 3 : Up. 234000 : Sen. 10,254,422 : Cost 67.22776031 : Time 389.18s : 15689.35 words/s
[2019-07-17 08:41:05] Ep. 3 : Up. 236000 : Sen. 10,544,007 : Cost 67.09194183 : Time 390.44s : 15658.74 words/s
[2019-07-17 08:47:34] Ep. 3 : Up. 238000 : Sen. 10,832,586 : Cost 66.88773346 : Time 389.40s : 15663.90 words/s
[2019-07-17 08:54:04] Ep. 3 : Up. 240000 : Sen. 11,121,424 : Cost 67.00627136 : Time 389.22s : 15710.68 words/s
[2019-07-17 08:54:04] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.orig.npz
[2019-07-17 08:54:14] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.iter240000.npz
[2019-07-17 08:54:21] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz
[2019-07-17 08:54:31] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.optimizer.npz
[2019-07-17 08:54:59] [valid] Ep. 3 : Up. 240000 : cross-entropy : 53.4536 : new best
[2019-07-17 08:55:06] [valid] Ep. 3 : Up. 240000 : perplexity : 8.3152 : new best
[2019-07-17 08:55:59] [valid] Ep. 3 : Up. 240000 : translation : 24.87 : stalled 2 times (last best: 24.93)
[2019-07-17 09:02:30] Ep. 3 : Up. 242000 : Sen. 11,409,579 : Cost 66.70398712 : Time 506.49s : 12001.00 words/s
[2019-07-17 09:08:58] Ep. 3 : Up. 244000 : Sen. 11,697,802 : Cost 66.80021667 : Time 388.15s : 15655.75 words/s
[2019-07-17 09:11:11] Seen 11795638 samples
[2019-07-17 09:11:11] Starting epoch 4
[2019-07-17 09:11:11] [data] Shuffling data
[2019-07-17 09:11:22] [data] Done reading 13926791 sentences
[2019-07-17 09:12:58] [data] Done shuffling 13926791 sentences to temp files
[2019-07-17 09:17:18] Ep. 4 : Up. 246000 : Sen. 190,422 : Cost 66.33839417 : Time 500.16s : 12174.54 words/s
[2019-07-17 09:23:48] Ep. 4 : Up. 248000 : Sen. 480,132 : Cost 65.86878967 : Time 389.91s : 15684.45 words/s
[2019-07-17 09:30:19] Ep. 4 : Up. 250000 : Sen. 769,668 : Cost 65.93839264 : Time 390.25s : 15648.18 words/s
[2019-07-17 09:36:49] Ep. 4 : Up. 252000 : Sen. 1,059,020 : Cost 65.96595764 : Time 390.04s : 15665.46 words/s
[2019-07-17 09:43:19] Ep. 4 : Up. 254000 : Sen. 1,348,680 : Cost 65.97662354 : Time 390.37s : 15659.19 words/s
[2019-07-17 09:49:48] Ep. 4 : Up. 256000 : Sen. 1,637,868 : Cost 66.00415802 : Time 388.73s : 15701.96 words/s
[2019-07-17 09:56:19] Ep. 4 : Up. 258000 : Sen. 1,927,944 : Cost 65.88840485 : Time 391.22s : 15629.25 words/s
[2019-07-17 10:02:48] Ep. 4 : Up. 260000 : Sen. 2,216,862 : Cost 66.16165924 : Time 388.74s : 15721.32 words/s
[2019-07-17 10:02:48] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.orig.npz
[2019-07-17 10:02:58] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.iter260000.npz
[2019-07-17 10:03:06] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz
[2019-07-17 10:03:17] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.optimizer.npz
[2019-07-17 10:03:45] [valid] Ep. 4 : Up. 260000 : cross-entropy : 53.1411 : new best
[2019-07-17 10:03:51] [valid] Ep. 4 : Up. 260000 : perplexity : 8.21287 : new best
[2019-07-17 10:04:44] [valid] Ep. 4 : Up. 260000 : translation : 24.98 : new best
[2019-07-17 10:11:15] Ep. 4 : Up. 262000 : Sen. 2,504,912 : Cost 65.93958282 : Time 507.11s : 11983.75 words/s
[2019-07-17 10:17:45] Ep. 4 : Up. 264000 : Sen. 2,794,246 : Cost 65.97788239 : Time 390.24s : 15654.18 words/s
[2019-07-17 10:24:16] Ep. 4 : Up. 266000 : Sen. 3,083,039 : Cost 66.20192719 : Time 391.12s : 15589.77 words/s
[2019-07-17 10:30:49] Ep. 4 : Up. 268000 : Sen. 3,371,607 : Cost 66.17957306 : Time 392.65s : 15533.20 words/s
[2019-07-17 10:37:20] Ep. 4 : Up. 270000 : Sen. 3,660,800 : Cost 65.85982513 : Time 391.47s : 15593.75 words/s
[2019-07-17 10:43:53] Ep. 4 : Up. 272000 : Sen. 3,950,938 : Cost 65.84016418 : Time 392.83s : 15592.07 words/s
[2019-07-17 10:50:23] Ep. 4 : Up. 274000 : Sen. 4,239,970 : Cost 65.89180756 : Time 390.11s : 15637.88 words/s
[2019-07-17 10:56:54] Ep. 4 : Up. 276000 : Sen. 4,529,122 : Cost 65.95967865 : Time 390.83s : 15601.23 words/s
[2019-07-17 11:03:25] Ep. 4 : Up. 278000 : Sen. 4,817,657 : Cost 66.04623413 : Time 390.88s : 15611.37 words/s
[2019-07-17 11:09:55] Ep. 4 : Up. 280000 : Sen. 5,106,178 : Cost 65.88745880 : Time 390.20s : 15600.79 words/s
[2019-07-17 11:09:55] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.orig.npz
[2019-07-17 11:10:05] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.iter280000.npz
[2019-07-17 11:10:13] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz
[2019-07-17 11:10:24] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.optimizer.npz
[2019-07-17 11:10:52] [valid] Ep. 4 : Up. 280000 : cross-entropy : 52.8464 : new best
[2019-07-17 11:10:59] [valid] Ep. 4 : Up. 280000 : perplexity : 8.11751 : new best
[2019-07-17 11:11:52] [valid] Ep. 4 : Up. 280000 : translation : 24.92 : stalled 1 times (last best: 24.98)
[2019-07-17 11:18:25] Ep. 4 : Up. 282000 : Sen. 5,394,936 : Cost 65.95413208 : Time 509.92s : 11959.63 words/s
[2019-07-17 11:24:56] Ep. 4 : Up. 284000 : Sen. 5,684,610 : Cost 65.83468628 : Time 390.69s : 15662.53 words/s
[2019-07-17 11:31:25] Ep. 4 : Up. 286000 : Sen. 5,973,244 : Cost 65.90083313 : Time 389.66s : 15650.78 words/s
[2019-07-17 11:37:56] Ep. 4 : Up. 288000 : Sen. 6,262,877 : Cost 65.91026306 : Time 390.61s : 15693.92 words/s
[2019-07-17 11:44:26] Ep. 4 : Up. 290000 : Sen. 6,551,838 : Cost 65.60709381 : Time 390.19s : 15589.49 words/s
[2019-07-17 11:50:57] Ep. 4 : Up. 292000 : Sen. 6,841,398 : Cost 65.85195923 : Time 390.74s : 15641.88 words/s
[2019-07-17 11:57:28] Ep. 4 : Up. 294000 : Sen. 7,130,733 : Cost 65.97481537 : Time 391.21s : 15642.09 words/s
[2019-07-17 12:04:00] Ep. 4 : Up. 296000 : Sen. 7,421,079 : Cost 65.84267426 : Time 392.10s : 15659.64 words/s
[2019-07-17 12:10:30] Ep. 4 : Up. 298000 : Sen. 7,710,574 : Cost 65.62186432 : Time 390.00s : 15670.96 words/s
[2019-07-17 12:17:01] Ep. 4 : Up. 300000 : Sen. 8,000,396 : Cost 65.85354614 : Time 390.99s : 15668.50 words/s
[2019-07-17 12:17:01] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.orig.npz
[2019-07-17 12:17:12] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.iter300000.npz
[2019-07-17 12:17:19] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz
[2019-07-17 12:17:30] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.optimizer.npz
[2019-07-17 12:17:59] [valid] Ep. 4 : Up. 300000 : cross-entropy : 52.4878 : new best
[2019-07-17 12:18:05] [valid] Ep. 4 : Up. 300000 : perplexity : 8.00299 : new best
[2019-07-17 12:18:59] [valid] Ep. 4 : Up. 300000 : translation : 25.06 : new best
[2019-07-17 12:25:30] Ep. 4 : Up. 302000 : Sen. 8,289,802 : Cost 65.60852051 : Time 508.31s : 11997.53 words/s
[2019-07-17 12:32:00] Ep. 4 : Up. 304000 : Sen. 8,578,230 : Cost 65.98316193 : Time 390.24s : 15633.16 words/s
[2019-07-17 12:38:31] Ep. 4 : Up. 306000 : Sen. 8,868,640 : Cost 65.79898834 : Time 391.30s : 15661.94 words/s
[2019-07-17 12:45:01] Ep. 4 : Up. 308000 : Sen. 9,157,822 : Cost 65.86038208 : Time 389.44s : 15718.65 words/s
[2019-07-17 12:51:29] Ep. 4 : Up. 310000 : Sen. 9,447,310 : Cost 65.47158051 : Time 388.51s : 15704.33 words/s
[2019-07-17 12:57:59] Ep. 4 : Up. 312000 : Sen. 9,736,079 : Cost 65.55233002 : Time 390.10s : 15628.02 words/s
[2019-07-17 13:04:29] Ep. 4 : Up. 314000 : Sen. 10,024,933 : Cost 65.58744049 : Time 389.69s : 15645.40 words/s
[2019-07-17 13:10:59] Ep. 4 : Up. 316000 : Sen. 10,315,596 : Cost 65.51184082 : Time 390.20s : 15714.69 words/s
[2019-07-17 13:17:30] Ep. 4 : Up. 318000 : Sen. 10,605,959 : Cost 65.50737000 : Time 390.72s : 15680.07 words/s
[2019-07-17 13:23:58] Ep. 4 : Up. 320000 : Sen. 10,894,008 : Cost 65.54723358 : Time 388.64s : 15663.69 words/s
[2019-07-17 13:23:58] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.orig.npz
[2019-07-17 13:24:10] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.iter320000.npz
[2019-07-17 13:24:21] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz
[2019-07-17 13:24:32] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.optimizer.npz
[2019-07-17 13:25:00] [valid] Ep. 4 : Up. 320000 : cross-entropy : 52.2429 : new best
[2019-07-17 13:25:07] [valid] Ep. 4 : Up. 320000 : perplexity : 7.9257 : new best
[2019-07-17 13:26:00] [valid] Ep. 4 : Up. 320000 : translation : 24.88 : stalled 1 times (last best: 25.06)
[2019-07-17 13:32:33] Ep. 4 : Up. 322000 : Sen. 11,182,400 : Cost 65.84759521 : Time 514.26s : 11876.58 words/s
[2019-07-17 13:39:04] Ep. 4 : Up. 324000 : Sen. 11,472,846 : Cost 65.37387848 : Time 391.59s : 15674.05 words/s
[2019-07-17 13:45:36] Ep. 4 : Up. 326000 : Sen. 11,762,804 : Cost 65.22597504 : Time 391.62s : 15603.01 words/s
[2019-07-17 13:46:21] Seen 11795638 samples
[2019-07-17 13:46:21] Starting epoch 5
[2019-07-17 13:46:21] [data] Shuffling data
[2019-07-17 13:46:31] [data] Done reading 13926791 sentences
[2019-07-17 13:48:09] [data] Done shuffling 13926791 sentences to temp files
[2019-07-17 13:53:58] Ep. 5 : Up. 328000 : Sen. 256,151 : Cost 64.91810608 : Time 501.96s : 12173.62 words/s
[2019-07-17 14:00:28] Ep. 5 : Up. 330000 : Sen. 545,501 : Cost 64.68311310 : Time 390.53s : 15642.75 words/s
[2019-07-17 14:06:59] Ep. 5 : Up. 332000 : Sen. 834,575 : Cost 64.71049500 : Time 390.74s : 15615.21 words/s
[2019-07-17 14:13:30] Ep. 5 : Up. 334000 : Sen. 1,123,613 : Cost 64.87316895 : Time 390.38s : 15659.46 words/s
[2019-07-17 14:19:59] Ep. 5 : Up. 336000 : Sen. 1,412,899 : Cost 64.44874573 : Time 389.71s : 15619.42 words/s
[2019-07-17 14:26:31] Ep. 5 : Up. 338000 : Sen. 1,701,872 : Cost 64.67454529 : Time 391.48s : 15592.86 words/s
[2019-07-17 14:33:01] Ep. 5 : Up. 340000 : Sen. 1,990,675 : Cost 64.63799286 : Time 390.05s : 15631.95 words/s
[2019-07-17 14:33:01] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.orig.npz
[2019-07-17 14:33:11] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.iter340000.npz
[2019-07-17 14:33:18] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz
[2019-07-17 14:33:29] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.optimizer.npz
[2019-07-17 14:33:58] [valid] Ep. 5 : Up. 340000 : cross-entropy : 52.0874 : new best
[2019-07-17 14:34:04] [valid] Ep. 5 : Up. 340000 : perplexity : 7.87702 : new best
[2019-07-17 14:34:57] [valid] Ep. 5 : Up. 340000 : translation : 25.04 : stalled 2 times (last best: 25.06)
[2019-07-17 14:41:31] Ep. 5 : Up. 342000 : Sen. 2,280,734 : Cost 64.89152527 : Time 509.81s : 12013.93 words/s
[2019-07-17 14:48:01] Ep. 5 : Up. 344000 : Sen. 2,568,943 : Cost 64.44595337 : Time 389.90s : 15598.85 words/s
[2019-07-17 14:54:32] Ep. 5 : Up. 346000 : Sen. 2,858,516 : Cost 64.79621887 : Time 391.21s : 15632.52 words/s
[2019-07-17 15:01:03] Ep. 5 : Up. 348000 : Sen. 3,148,668 : Cost 64.79655457 : Time 391.56s : 15647.64 words/s
[2019-07-17 15:07:34] Ep. 5 : Up. 350000 : Sen. 3,437,502 : Cost 64.69677734 : Time 390.73s : 15594.18 words/s
