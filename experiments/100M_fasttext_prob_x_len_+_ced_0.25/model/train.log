[2019-07-16 18:47:46] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-16 18:47:46] [marian] Running on bil as process 107084 with command line:
[2019-07-16 18:47:46] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz -T . --devices 0 --train-sets ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.de ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.en --vocabs ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.de.json ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.en.json --mini-batch-fit -w 5000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/data/dev.bpe.de ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/dev.out --valid-script-path ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/train.log --valid-log ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/valid.log
[2019-07-16 18:47:46] [config] after-batches: 0
[2019-07-16 18:47:46] [config] after-epochs: 0
[2019-07-16 18:47:46] [config] allow-unk: false
[2019-07-16 18:47:46] [config] beam-size: 12
[2019-07-16 18:47:46] [config] bert-class-symbol: "[CLS]"
[2019-07-16 18:47:46] [config] bert-mask-symbol: "[MASK]"
[2019-07-16 18:47:46] [config] bert-masking-fraction: 0.15
[2019-07-16 18:47:46] [config] bert-sep-symbol: "[SEP]"
[2019-07-16 18:47:46] [config] bert-train-type-embeddings: true
[2019-07-16 18:47:46] [config] bert-type-vocab-size: 2
[2019-07-16 18:47:46] [config] best-deep: false
[2019-07-16 18:47:46] [config] clip-gemm: 0
[2019-07-16 18:47:46] [config] clip-norm: 1
[2019-07-16 18:47:46] [config] cost-type: ce-mean
[2019-07-16 18:47:46] [config] cpu-threads: 0
[2019-07-16 18:47:46] [config] data-weighting: ""
[2019-07-16 18:47:46] [config] data-weighting-type: sentence
[2019-07-16 18:47:46] [config] dec-cell: gru
[2019-07-16 18:47:46] [config] dec-cell-base-depth: 2
[2019-07-16 18:47:46] [config] dec-cell-high-depth: 1
[2019-07-16 18:47:46] [config] dec-depth: 1
[2019-07-16 18:47:46] [config] devices:
[2019-07-16 18:47:46] [config]   - 0
[2019-07-16 18:47:46] [config] dim-emb: 512
[2019-07-16 18:47:46] [config] dim-rnn: 1024
[2019-07-16 18:47:46] [config] dim-vocabs:
[2019-07-16 18:47:46] [config]   - 50000
[2019-07-16 18:47:46] [config]   - 50000
[2019-07-16 18:47:46] [config] disp-first: 0
[2019-07-16 18:47:46] [config] disp-freq: 2000
[2019-07-16 18:47:46] [config] disp-label-counts: false
[2019-07-16 18:47:46] [config] dropout-rnn: 0.2
[2019-07-16 18:47:46] [config] dropout-src: 0.1
[2019-07-16 18:47:46] [config] dropout-trg: 0.1
[2019-07-16 18:47:46] [config] dump-config: ""
[2019-07-16 18:47:46] [config] early-stopping: 5
[2019-07-16 18:47:46] [config] embedding-fix-src: false
[2019-07-16 18:47:46] [config] embedding-fix-trg: false
[2019-07-16 18:47:46] [config] embedding-normalization: false
[2019-07-16 18:47:46] [config] embedding-vectors:
[2019-07-16 18:47:46] [config]   []
[2019-07-16 18:47:46] [config] enc-cell: gru
[2019-07-16 18:47:46] [config] enc-cell-depth: 1
[2019-07-16 18:47:46] [config] enc-depth: 1
[2019-07-16 18:47:46] [config] enc-type: bidirectional
[2019-07-16 18:47:46] [config] exponential-smoothing: 0.0001
[2019-07-16 18:47:46] [config] grad-dropping-momentum: 0
[2019-07-16 18:47:46] [config] grad-dropping-rate: 0
[2019-07-16 18:47:46] [config] grad-dropping-warmup: 100
[2019-07-16 18:47:46] [config] guided-alignment: none
[2019-07-16 18:47:46] [config] guided-alignment-cost: mse
[2019-07-16 18:47:46] [config] guided-alignment-weight: 0.1
[2019-07-16 18:47:46] [config] ignore-model-config: false
[2019-07-16 18:47:46] [config] input-types:
[2019-07-16 18:47:46] [config]   []
[2019-07-16 18:47:46] [config] interpolate-env-vars: false
[2019-07-16 18:47:46] [config] keep-best: false
[2019-07-16 18:47:46] [config] label-smoothing: 0
[2019-07-16 18:47:46] [config] layer-normalization: true
[2019-07-16 18:47:46] [config] learn-rate: 0.0001
[2019-07-16 18:47:46] [config] log: ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/train.log
[2019-07-16 18:47:46] [config] log-level: info
[2019-07-16 18:47:46] [config] log-time-zone: ""
[2019-07-16 18:47:46] [config] lr-decay: 0
[2019-07-16 18:47:46] [config] lr-decay-freq: 50000
[2019-07-16 18:47:46] [config] lr-decay-inv-sqrt:
[2019-07-16 18:47:46] [config]   - 0
[2019-07-16 18:47:46] [config] lr-decay-repeat-warmup: false
[2019-07-16 18:47:46] [config] lr-decay-reset-optimizer: false
[2019-07-16 18:47:46] [config] lr-decay-start:
[2019-07-16 18:47:46] [config]   - 10
[2019-07-16 18:47:46] [config]   - 1
[2019-07-16 18:47:46] [config] lr-decay-strategy: epoch+stalled
[2019-07-16 18:47:46] [config] lr-report: false
[2019-07-16 18:47:46] [config] lr-warmup: 0
[2019-07-16 18:47:46] [config] lr-warmup-at-reload: false
[2019-07-16 18:47:46] [config] lr-warmup-cycle: false
[2019-07-16 18:47:46] [config] lr-warmup-start-rate: 0
[2019-07-16 18:47:46] [config] max-length: 50
[2019-07-16 18:47:46] [config] max-length-crop: false
[2019-07-16 18:47:46] [config] max-length-factor: 3
[2019-07-16 18:47:46] [config] maxi-batch: 100
[2019-07-16 18:47:46] [config] maxi-batch-sort: trg
[2019-07-16 18:47:46] [config] mini-batch: 64
[2019-07-16 18:47:46] [config] mini-batch-fit: true
[2019-07-16 18:47:46] [config] mini-batch-fit-step: 10
[2019-07-16 18:47:46] [config] mini-batch-overstuff: 1
[2019-07-16 18:47:46] [config] mini-batch-track-lr: false
[2019-07-16 18:47:46] [config] mini-batch-understuff: 1
[2019-07-16 18:47:46] [config] mini-batch-warmup: 0
[2019-07-16 18:47:46] [config] mini-batch-words: 0
[2019-07-16 18:47:46] [config] mini-batch-words-ref: 0
[2019-07-16 18:47:46] [config] model: ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-16 18:47:46] [config] multi-loss-type: sum
[2019-07-16 18:47:46] [config] multi-node: false
[2019-07-16 18:47:46] [config] multi-node-overlap: true
[2019-07-16 18:47:46] [config] n-best: false
[2019-07-16 18:47:46] [config] no-nccl: false
[2019-07-16 18:47:46] [config] no-reload: false
[2019-07-16 18:47:46] [config] no-restore-corpus: false
[2019-07-16 18:47:46] [config] no-shuffle: false
[2019-07-16 18:47:46] [config] normalize: 1
[2019-07-16 18:47:46] [config] num-devices: 0
[2019-07-16 18:47:46] [config] optimizer: adam
[2019-07-16 18:47:46] [config] optimizer-delay: 1
[2019-07-16 18:47:46] [config] optimizer-params:
[2019-07-16 18:47:46] [config]   []
[2019-07-16 18:47:46] [config] overwrite: false
[2019-07-16 18:47:46] [config] pretrained-model: ""
[2019-07-16 18:47:46] [config] quiet: false
[2019-07-16 18:47:46] [config] quiet-translation: true
[2019-07-16 18:47:46] [config] relative-paths: false
[2019-07-16 18:47:46] [config] right-left: false
[2019-07-16 18:47:46] [config] save-freq: 20000
[2019-07-16 18:47:46] [config] seed: 1111
[2019-07-16 18:47:46] [config] shuffle-in-ram: false
[2019-07-16 18:47:46] [config] skip: false
[2019-07-16 18:47:46] [config] sqlite: ""
[2019-07-16 18:47:46] [config] sqlite-drop: false
[2019-07-16 18:47:46] [config] sync-sgd: true
[2019-07-16 18:47:46] [config] tempdir: .
[2019-07-16 18:47:46] [config] tied-embeddings: false
[2019-07-16 18:47:46] [config] tied-embeddings-all: false
[2019-07-16 18:47:46] [config] tied-embeddings-src: false
[2019-07-16 18:47:46] [config] train-sets:
[2019-07-16 18:47:46] [config]   - ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.de
[2019-07-16 18:47:46] [config]   - ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.en
[2019-07-16 18:47:46] [config] transformer-aan-activation: swish
[2019-07-16 18:47:46] [config] transformer-aan-depth: 2
[2019-07-16 18:47:46] [config] transformer-aan-nogate: false
[2019-07-16 18:47:46] [config] transformer-decoder-autoreg: self-attention
[2019-07-16 18:47:46] [config] transformer-dim-aan: 2048
[2019-07-16 18:47:46] [config] transformer-dim-ffn: 2048
[2019-07-16 18:47:46] [config] transformer-dropout: 0
[2019-07-16 18:47:46] [config] transformer-dropout-attention: 0
[2019-07-16 18:47:46] [config] transformer-dropout-ffn: 0
[2019-07-16 18:47:46] [config] transformer-ffn-activation: swish
[2019-07-16 18:47:46] [config] transformer-ffn-depth: 2
[2019-07-16 18:47:46] [config] transformer-guided-alignment-layer: last
[2019-07-16 18:47:46] [config] transformer-heads: 8
[2019-07-16 18:47:46] [config] transformer-no-projection: false
[2019-07-16 18:47:46] [config] transformer-postprocess: dan
[2019-07-16 18:47:46] [config] transformer-postprocess-emb: d
[2019-07-16 18:47:46] [config] transformer-preprocess: ""
[2019-07-16 18:47:46] [config] transformer-tied-layers:
[2019-07-16 18:47:46] [config]   []
[2019-07-16 18:47:46] [config] transformer-train-position-embeddings: false
[2019-07-16 18:47:46] [config] type: amun
[2019-07-16 18:47:46] [config] ulr: false
[2019-07-16 18:47:46] [config] ulr-dim-emb: 0
[2019-07-16 18:47:46] [config] ulr-dropout: 0
[2019-07-16 18:47:46] [config] ulr-keys-vectors: ""
[2019-07-16 18:47:46] [config] ulr-query-vectors: ""
[2019-07-16 18:47:46] [config] ulr-softmax-temperature: 1
[2019-07-16 18:47:46] [config] ulr-trainable-transformation: false
[2019-07-16 18:47:46] [config] valid-freq: 20000
[2019-07-16 18:47:46] [config] valid-log: ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/valid.log
[2019-07-16 18:47:46] [config] valid-max-length: 1000
[2019-07-16 18:47:46] [config] valid-metrics:
[2019-07-16 18:47:46] [config]   - cross-entropy
[2019-07-16 18:47:46] [config]   - perplexity
[2019-07-16 18:47:46] [config]   - translation
[2019-07-16 18:47:46] [config] valid-mini-batch: 8
[2019-07-16 18:47:46] [config] valid-script-path: ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/score-dev.sh
[2019-07-16 18:47:46] [config] valid-sets:
[2019-07-16 18:47:46] [config]   - ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/data/dev.bpe.de
[2019-07-16 18:47:46] [config]   - ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/data/dev.bpe.en
[2019-07-16 18:47:46] [config] valid-translation-output: ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/dev.out
[2019-07-16 18:47:46] [config] vocabs:
[2019-07-16 18:47:46] [config]   - ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.de.json
[2019-07-16 18:47:46] [config]   - ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.en.json
[2019-07-16 18:47:46] [config] word-penalty: 0
[2019-07-16 18:47:46] [config] workspace: 5000
[2019-07-16 18:47:46] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-16 18:47:46] Using synchronous training
[2019-07-16 18:47:46] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.de.json
[2019-07-16 18:47:46] [data] Using unused word id eos for 0
[2019-07-16 18:47:46] [data] Using unused word id UNK for 1
[2019-07-16 18:47:46] [data] Setting vocabulary size for input 0 to 50000
[2019-07-16 18:47:46] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.en.json
[2019-07-16 18:47:47] [data] Using unused word id eos for 0
[2019-07-16 18:47:47] [data] Using unused word id UNK for 1
[2019-07-16 18:47:47] [data] Setting vocabulary size for input 1 to 50000
[2019-07-16 18:47:47] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-16 18:47:47] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-16 18:47:49] [memory] Extending reserved space to 5120 MB (device gpu0)
[2019-07-16 18:47:49] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-16 18:47:49] [comm] NCCLCommunicator constructed successfully.
[2019-07-16 18:47:49] [training] Using 1 GPUs
[2019-07-16 18:47:49] [memory] Reserving 422 MB, device gpu0
[2019-07-16 18:47:49] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-16 18:47:49] [memory] Reserving 422 MB, device gpu0
[2019-07-16 18:47:54] [batching] Done. Typical MB size is 6880 target words
[2019-07-16 18:47:54] [memory] Extending reserved space to 5120 MB (device gpu0)
[2019-07-16 18:47:54] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-16 18:47:54] [comm] NCCLCommunicator constructed successfully.
[2019-07-16 18:47:54] [training] Using 1 GPUs
[2019-07-16 18:47:54] Training started
[2019-07-16 18:47:54] [data] Shuffling data
[2019-07-16 18:48:02] [data] Done reading 13926791 sentences
[2019-07-16 18:49:23] [data] Done shuffling 13926791 sentences to temp files
[2019-07-16 18:49:26] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-07-16 18:49:26] [memory] Reserving 422 MB, device gpu0
[2019-07-16 18:49:26] [memory] Reserving 422 MB, device gpu0
[2019-07-16 18:49:26] [memory] Reserving 422 MB, device gpu0
[2019-07-16 18:49:27] [memory] Reserving 844 MB, device gpu0
[2019-07-16 18:55:44] Ep. 1 : Up. 2000 : Sen. 288,797 : Cost 136.78027344 : Time 477.35s : 12748.64 words/s
[2019-07-16 19:02:06] Ep. 1 : Up. 4000 : Sen. 578,204 : Cost 119.10513306 : Time 381.61s : 16051.28 words/s
[2019-07-16 19:08:26] Ep. 1 : Up. 6000 : Sen. 867,193 : Cost 110.57600403 : Time 380.25s : 16042.70 words/s
[2019-07-16 19:14:47] Ep. 1 : Up. 8000 : Sen. 1,156,624 : Cost 104.63689423 : Time 380.60s : 16028.22 words/s
[2019-07-16 19:21:08] Ep. 1 : Up. 10000 : Sen. 1,446,268 : Cost 100.92620087 : Time 381.17s : 16059.12 words/s
[2019-07-16 19:27:28] Ep. 1 : Up. 12000 : Sen. 1,735,282 : Cost 97.36447144 : Time 379.75s : 16067.25 words/s
[2019-07-16 19:33:48] Ep. 1 : Up. 14000 : Sen. 2,024,337 : Cost 94.72069550 : Time 380.36s : 16042.98 words/s
[2019-07-16 19:40:08] Ep. 1 : Up. 16000 : Sen. 2,313,416 : Cost 92.59864044 : Time 380.51s : 16050.90 words/s
[2019-07-16 19:46:30] Ep. 1 : Up. 18000 : Sen. 2,603,093 : Cost 90.72177887 : Time 381.31s : 16045.31 words/s
[2019-07-16 19:52:51] Ep. 1 : Up. 20000 : Sen. 2,892,668 : Cost 89.10700226 : Time 381.18s : 16057.64 words/s
[2019-07-16 19:52:51] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-16 19:52:56] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.iter20000.npz
[2019-07-16 19:52:58] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-16 19:53:03] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-16 19:53:22] [valid] Ep. 1 : Up. 20000 : cross-entropy : 89.9219 : new best
[2019-07-16 19:53:28] [valid] Ep. 1 : Up. 20000 : perplexity : 35.2719 : new best
[2019-07-16 19:54:26] [valid] Ep. 1 : Up. 20000 : translation : 12.76 : new best
[2019-07-16 20:00:49] Ep. 1 : Up. 22000 : Sen. 3,182,201 : Cost 87.58217621 : Time 478.58s : 12760.84 words/s
[2019-07-16 20:07:09] Ep. 1 : Up. 24000 : Sen. 3,469,606 : Cost 86.72005463 : Time 379.15s : 16038.34 words/s
[2019-07-16 20:13:28] Ep. 1 : Up. 26000 : Sen. 3,758,588 : Cost 85.35770416 : Time 379.71s : 16062.71 words/s
[2019-07-16 20:19:46] Ep. 1 : Up. 28000 : Sen. 4,047,139 : Cost 84.14634705 : Time 377.98s : 16073.21 words/s
[2019-07-16 20:26:07] Ep. 1 : Up. 30000 : Sen. 4,335,959 : Cost 83.99696350 : Time 381.00s : 16064.16 words/s
[2019-07-16 20:32:28] Ep. 1 : Up. 32000 : Sen. 4,625,906 : Cost 82.72394562 : Time 380.97s : 16067.30 words/s
[2019-07-16 20:38:49] Ep. 1 : Up. 34000 : Sen. 4,915,694 : Cost 82.30670929 : Time 380.79s : 16060.61 words/s
[2019-07-16 20:45:09] Ep. 1 : Up. 36000 : Sen. 5,204,785 : Cost 81.59246063 : Time 380.31s : 16059.86 words/s
[2019-07-16 20:51:28] Ep. 1 : Up. 38000 : Sen. 5,491,927 : Cost 81.03488922 : Time 378.38s : 16035.26 words/s
[2019-07-16 20:57:47] Ep. 1 : Up. 40000 : Sen. 5,780,968 : Cost 80.16825104 : Time 379.64s : 16056.25 words/s
[2019-07-16 20:57:47] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-16 20:57:53] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.iter40000.npz
[2019-07-16 20:57:55] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-16 20:58:01] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-16 20:58:21] [valid] Ep. 1 : Up. 40000 : cross-entropy : 72.544 : new best
[2019-07-16 20:58:27] [valid] Ep. 1 : Up. 40000 : perplexity : 17.7165 : new best
[2019-07-16 20:59:22] [valid] Ep. 1 : Up. 40000 : translation : 19.99 : new best
[2019-07-16 21:05:44] Ep. 1 : Up. 42000 : Sen. 6,069,923 : Cost 79.68537903 : Time 476.43s : 12801.71 words/s
[2019-07-16 21:12:03] Ep. 1 : Up. 44000 : Sen. 6,358,133 : Cost 79.50292969 : Time 379.52s : 16039.51 words/s
[2019-07-16 21:18:23] Ep. 1 : Up. 46000 : Sen. 6,646,144 : Cost 78.99950409 : Time 379.48s : 16019.67 words/s
[2019-07-16 21:24:43] Ep. 1 : Up. 48000 : Sen. 6,935,179 : Cost 78.56484985 : Time 380.17s : 16047.93 words/s
[2019-07-16 21:31:04] Ep. 1 : Up. 50000 : Sen. 7,224,478 : Cost 77.83973694 : Time 380.98s : 16002.77 words/s
[2019-07-16 21:37:26] Ep. 1 : Up. 52000 : Sen. 7,513,916 : Cost 77.74333954 : Time 382.03s : 16038.51 words/s
[2019-07-16 21:43:47] Ep. 1 : Up. 54000 : Sen. 7,803,532 : Cost 77.26873779 : Time 380.92s : 16032.58 words/s
[2019-07-16 21:50:08] Ep. 1 : Up. 56000 : Sen. 8,092,214 : Cost 77.41613770 : Time 381.14s : 16025.79 words/s
[2019-07-16 21:56:28] Ep. 1 : Up. 58000 : Sen. 8,381,528 : Cost 76.51219940 : Time 380.42s : 16029.40 words/s
[2019-07-16 22:02:49] Ep. 1 : Up. 60000 : Sen. 8,670,240 : Cost 76.70173645 : Time 380.94s : 16038.40 words/s
[2019-07-16 22:02:49] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-16 22:02:55] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.iter60000.npz
[2019-07-16 22:02:58] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-16 22:03:03] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-16 22:03:22] [valid] Ep. 1 : Up. 60000 : cross-entropy : 65.3772 : new best
[2019-07-16 22:03:29] [valid] Ep. 1 : Up. 60000 : perplexity : 13.3367 : new best
[2019-07-16 22:04:22] [valid] Ep. 1 : Up. 60000 : translation : 22.01 : new best
[2019-07-16 22:10:45] Ep. 1 : Up. 62000 : Sen. 8,958,900 : Cost 76.23905945 : Time 475.61s : 12852.58 words/s
[2019-07-16 22:17:05] Ep. 1 : Up. 64000 : Sen. 9,248,264 : Cost 75.88126373 : Time 380.35s : 16063.48 words/s
[2019-07-16 22:23:26] Ep. 1 : Up. 66000 : Sen. 9,537,669 : Cost 75.64531708 : Time 380.63s : 16072.61 words/s
[2019-07-16 22:29:45] Ep. 1 : Up. 68000 : Sen. 9,826,689 : Cost 75.04283142 : Time 379.30s : 16034.20 words/s
[2019-07-16 22:36:08] Ep. 1 : Up. 70000 : Sen. 10,118,004 : Cost 75.23857117 : Time 382.25s : 16116.11 words/s
[2019-07-16 22:42:28] Ep. 1 : Up. 72000 : Sen. 10,408,041 : Cost 74.75734711 : Time 380.19s : 16071.56 words/s
[2019-07-16 22:48:48] Ep. 1 : Up. 74000 : Sen. 10,697,156 : Cost 74.55647278 : Time 379.88s : 16071.50 words/s
[2019-07-16 22:55:10] Ep. 1 : Up. 76000 : Sen. 10,987,340 : Cost 74.57411194 : Time 382.21s : 16064.34 words/s
[2019-07-16 23:01:31] Ep. 1 : Up. 78000 : Sen. 11,277,871 : Cost 74.01261139 : Time 380.73s : 16092.01 words/s
[2019-07-16 23:07:51] Ep. 1 : Up. 80000 : Sen. 11,567,597 : Cost 73.97684479 : Time 380.81s : 16085.65 words/s
[2019-07-16 23:07:51] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-16 23:07:57] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.iter80000.npz
[2019-07-16 23:08:00] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-16 23:08:05] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-16 23:08:25] [valid] Ep. 1 : Up. 80000 : cross-entropy : 61.4603 : new best
[2019-07-16 23:08:32] [valid] Ep. 1 : Up. 80000 : perplexity : 11.4194 : new best
[2019-07-16 23:09:24] [valid] Ep. 1 : Up. 80000 : translation : 23.4 : new best
[2019-07-16 23:14:26] Seen 11795626 samples
[2019-07-16 23:14:26] Starting epoch 2
[2019-07-16 23:14:26] [data] Shuffling data
[2019-07-16 23:14:36] [data] Done reading 13926791 sentences
[2019-07-16 23:15:56] [data] Done shuffling 13926791 sentences to temp files
[2019-07-16 23:17:20] Ep. 2 : Up. 82000 : Sen. 60,754 : Cost 73.57028198 : Time 568.39s : 10719.46 words/s
[2019-07-16 23:23:39] Ep. 2 : Up. 84000 : Sen. 350,018 : Cost 72.87860107 : Time 379.53s : 16067.15 words/s
[2019-07-16 23:30:00] Ep. 2 : Up. 86000 : Sen. 639,208 : Cost 72.85738373 : Time 380.60s : 16039.26 words/s
[2019-07-16 23:36:20] Ep. 2 : Up. 88000 : Sen. 927,562 : Cost 72.69333649 : Time 379.60s : 16078.43 words/s
[2019-07-16 23:42:39] Ep. 2 : Up. 90000 : Sen. 1,216,264 : Cost 72.63395691 : Time 379.66s : 16074.52 words/s
[2019-07-16 23:49:00] Ep. 2 : Up. 92000 : Sen. 1,505,526 : Cost 72.32595825 : Time 380.92s : 16031.81 words/s
[2019-07-16 23:55:21] Ep. 2 : Up. 94000 : Sen. 1,795,157 : Cost 72.12468719 : Time 380.67s : 16061.50 words/s
[2019-07-17 00:01:41] Ep. 2 : Up. 96000 : Sen. 2,083,870 : Cost 72.03063202 : Time 380.36s : 16037.44 words/s
[2019-07-17 00:08:02] Ep. 2 : Up. 98000 : Sen. 2,373,872 : Cost 71.70303345 : Time 380.70s : 16064.23 words/s
[2019-07-17 00:14:22] Ep. 2 : Up. 100000 : Sen. 2,663,200 : Cost 71.96030426 : Time 380.48s : 16061.19 words/s
[2019-07-17 00:14:22] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-17 00:14:28] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.iter100000.npz
[2019-07-17 00:14:31] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-17 00:14:37] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-17 00:14:57] [valid] Ep. 2 : Up. 100000 : cross-entropy : 58.9128 : new best
[2019-07-17 00:15:03] [valid] Ep. 2 : Up. 100000 : perplexity : 10.323 : new best
[2019-07-17 00:15:56] [valid] Ep. 2 : Up. 100000 : translation : 23.81 : new best
[2019-07-17 00:22:19] Ep. 2 : Up. 102000 : Sen. 2,952,647 : Cost 71.91693878 : Time 476.63s : 12825.96 words/s
[2019-07-17 00:28:40] Ep. 2 : Up. 104000 : Sen. 3,242,412 : Cost 71.79253387 : Time 381.19s : 16074.09 words/s
[2019-07-17 00:35:01] Ep. 2 : Up. 106000 : Sen. 3,531,063 : Cost 71.72140503 : Time 380.67s : 16054.55 words/s
[2019-07-17 00:41:22] Ep. 2 : Up. 108000 : Sen. 3,820,668 : Cost 71.41957092 : Time 380.72s : 16040.59 words/s
[2019-07-17 00:47:42] Ep. 2 : Up. 110000 : Sen. 4,110,269 : Cost 71.26216888 : Time 380.88s : 16049.69 words/s
[2019-07-17 00:54:03] Ep. 2 : Up. 112000 : Sen. 4,399,018 : Cost 71.08213043 : Time 380.29s : 16031.58 words/s
[2019-07-17 01:00:23] Ep. 2 : Up. 114000 : Sen. 4,687,785 : Cost 71.07786560 : Time 380.34s : 16048.60 words/s
[2019-07-17 01:06:44] Ep. 2 : Up. 116000 : Sen. 4,977,368 : Cost 70.91172791 : Time 381.39s : 16018.40 words/s
[2019-07-17 01:13:05] Ep. 2 : Up. 118000 : Sen. 5,266,936 : Cost 70.99040985 : Time 380.41s : 16084.56 words/s
[2019-07-17 01:19:27] Ep. 2 : Up. 120000 : Sen. 5,556,831 : Cost 70.94153595 : Time 381.76s : 16047.71 words/s
[2019-07-17 01:19:27] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-17 01:19:32] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.iter120000.npz
[2019-07-17 01:19:35] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-17 01:19:40] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-17 01:20:02] [valid] Ep. 2 : Up. 120000 : cross-entropy : 57.0837 : new best
[2019-07-17 01:20:09] [valid] Ep. 2 : Up. 120000 : perplexity : 9.60131 : new best
[2019-07-17 01:21:02] [valid] Ep. 2 : Up. 120000 : translation : 23.84 : new best
[2019-07-17 01:27:26] Ep. 2 : Up. 122000 : Sen. 5,846,022 : Cost 70.75028992 : Time 479.75s : 12737.01 words/s
[2019-07-17 01:33:47] Ep. 2 : Up. 124000 : Sen. 6,135,247 : Cost 70.57390594 : Time 380.71s : 16027.37 words/s
[2019-07-17 01:40:08] Ep. 2 : Up. 126000 : Sen. 6,423,918 : Cost 70.24903107 : Time 381.10s : 15984.62 words/s
[2019-07-17 01:46:30] Ep. 2 : Up. 128000 : Sen. 6,712,686 : Cost 70.43827057 : Time 382.17s : 15982.76 words/s
[2019-07-17 01:52:53] Ep. 2 : Up. 130000 : Sen. 7,002,245 : Cost 70.30568695 : Time 382.81s : 15969.47 words/s
[2019-07-17 01:59:16] Ep. 2 : Up. 132000 : Sen. 7,292,561 : Cost 70.19308472 : Time 382.49s : 16036.84 words/s
[2019-07-17 02:05:37] Ep. 2 : Up. 134000 : Sen. 7,581,722 : Cost 70.11529541 : Time 381.38s : 16014.99 words/s
[2019-07-17 02:11:58] Ep. 2 : Up. 136000 : Sen. 7,870,860 : Cost 70.20631409 : Time 381.04s : 16017.60 words/s
[2019-07-17 02:18:20] Ep. 2 : Up. 138000 : Sen. 8,160,575 : Cost 69.95307159 : Time 382.26s : 15986.26 words/s
[2019-07-17 02:24:40] Ep. 2 : Up. 140000 : Sen. 8,449,140 : Cost 69.89705658 : Time 380.15s : 16009.46 words/s
[2019-07-17 02:24:40] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-17 02:24:46] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.iter140000.npz
[2019-07-17 02:24:49] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-17 02:24:54] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-17 02:25:14] [valid] Ep. 2 : Up. 140000 : cross-entropy : 55.7259 : new best
[2019-07-17 02:25:20] [valid] Ep. 2 : Up. 140000 : perplexity : 9.09838 : new best
[2019-07-17 02:26:13] [valid] Ep. 2 : Up. 140000 : translation : 24.19 : new best
[2019-07-17 02:32:35] Ep. 2 : Up. 142000 : Sen. 8,738,697 : Cost 69.83265686 : Time 474.99s : 12887.60 words/s
[2019-07-17 02:38:57] Ep. 2 : Up. 144000 : Sen. 9,027,984 : Cost 69.48461151 : Time 381.15s : 16018.41 words/s
[2019-07-17 02:45:16] Ep. 2 : Up. 146000 : Sen. 9,316,139 : Cost 69.57076263 : Time 379.35s : 16048.29 words/s
[2019-07-17 02:51:37] Ep. 2 : Up. 148000 : Sen. 9,605,225 : Cost 69.70208740 : Time 381.04s : 16025.68 words/s
[2019-07-17 02:57:57] Ep. 2 : Up. 150000 : Sen. 9,894,136 : Cost 69.66178894 : Time 380.52s : 16038.01 words/s
[2019-07-17 03:04:19] Ep. 2 : Up. 152000 : Sen. 10,183,588 : Cost 69.42060089 : Time 381.46s : 16029.13 words/s
[2019-07-17 03:10:40] Ep. 2 : Up. 154000 : Sen. 10,473,059 : Cost 69.49910736 : Time 380.92s : 16030.77 words/s
[2019-07-17 03:17:01] Ep. 2 : Up. 156000 : Sen. 10,762,568 : Cost 69.17830658 : Time 381.26s : 16016.89 words/s
[2019-07-17 03:23:21] Ep. 2 : Up. 158000 : Sen. 11,051,396 : Cost 69.11424255 : Time 379.87s : 16053.91 words/s
[2019-07-17 03:29:42] Ep. 2 : Up. 160000 : Sen. 11,341,502 : Cost 69.00998688 : Time 381.30s : 16054.74 words/s
[2019-07-17 03:29:42] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-17 03:29:48] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.iter160000.npz
[2019-07-17 03:29:51] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-17 03:29:57] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-17 03:30:16] [valid] Ep. 2 : Up. 160000 : cross-entropy : 54.7026 : new best
[2019-07-17 03:30:23] [valid] Ep. 2 : Up. 160000 : perplexity : 8.73683 : new best
[2019-07-17 03:31:16] [valid] Ep. 2 : Up. 160000 : translation : 24.54 : new best
[2019-07-17 03:37:39] Ep. 2 : Up. 162000 : Sen. 11,631,222 : Cost 68.85541534 : Time 477.07s : 12801.72 words/s
[2019-07-17 03:41:15] Seen 11795626 samples
[2019-07-17 03:41:15] Starting epoch 3
[2019-07-17 03:41:15] [data] Shuffling data
[2019-07-17 03:41:25] [data] Done reading 13926791 sentences
[2019-07-17 03:42:46] [data] Done shuffling 13926791 sentences to temp files
[2019-07-17 03:45:34] Ep. 3 : Up. 164000 : Sen. 124,816 : Cost 68.43778229 : Time 474.62s : 12855.13 words/s
[2019-07-17 03:51:55] Ep. 3 : Up. 166000 : Sen. 413,353 : Cost 68.26063538 : Time 380.78s : 16018.95 words/s
[2019-07-17 03:58:16] Ep. 3 : Up. 168000 : Sen. 702,503 : Cost 68.05224609 : Time 381.21s : 16007.57 words/s
[2019-07-17 04:04:37] Ep. 3 : Up. 170000 : Sen. 991,256 : Cost 68.47216034 : Time 380.79s : 16060.97 words/s
[2019-07-17 04:10:59] Ep. 3 : Up. 172000 : Sen. 1,281,029 : Cost 68.16242218 : Time 382.13s : 16013.36 words/s
[2019-07-17 04:17:21] Ep. 3 : Up. 174000 : Sen. 1,570,884 : Cost 68.28521729 : Time 382.39s : 16024.77 words/s
[2019-07-17 04:23:43] Ep. 3 : Up. 176000 : Sen. 1,860,521 : Cost 67.89791870 : Time 381.23s : 16002.83 words/s
[2019-07-17 04:30:04] Ep. 3 : Up. 178000 : Sen. 2,150,268 : Cost 67.94056702 : Time 381.34s : 16016.76 words/s
[2019-07-17 04:36:25] Ep. 3 : Up. 180000 : Sen. 2,439,399 : Cost 67.98975372 : Time 381.43s : 16016.79 words/s
[2019-07-17 04:36:25] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-17 04:36:32] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.iter180000.npz
[2019-07-17 04:36:34] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-17 04:36:40] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-17 04:37:00] [valid] Ep. 3 : Up. 180000 : cross-entropy : 54.0219 : new best
[2019-07-17 04:37:06] [valid] Ep. 3 : Up. 180000 : perplexity : 8.50432 : new best
[2019-07-17 04:37:59] [valid] Ep. 3 : Up. 180000 : translation : 24.69 : new best
[2019-07-17 04:44:22] Ep. 3 : Up. 182000 : Sen. 2,727,752 : Cost 67.81607056 : Time 476.68s : 12779.35 words/s
[2019-07-17 04:50:44] Ep. 3 : Up. 184000 : Sen. 3,016,604 : Cost 68.17465210 : Time 382.08s : 16015.32 words/s
[2019-07-17 04:57:04] Ep. 3 : Up. 186000 : Sen. 3,305,671 : Cost 67.85632324 : Time 380.10s : 16044.71 words/s
[2019-07-17 05:03:25] Ep. 3 : Up. 188000 : Sen. 3,595,604 : Cost 67.80996704 : Time 380.63s : 16085.12 words/s
[2019-07-17 05:09:48] Ep. 3 : Up. 190000 : Sen. 3,885,988 : Cost 67.90432739 : Time 383.04s : 16022.47 words/s
[2019-07-17 05:16:09] Ep. 3 : Up. 192000 : Sen. 4,176,012 : Cost 67.48237610 : Time 381.27s : 16009.57 words/s
[2019-07-17 05:22:30] Ep. 3 : Up. 194000 : Sen. 4,465,661 : Cost 67.84638977 : Time 381.38s : 16048.29 words/s
[2019-07-17 05:28:52] Ep. 3 : Up. 196000 : Sen. 4,754,606 : Cost 67.93884277 : Time 381.66s : 15999.47 words/s
[2019-07-17 05:35:12] Ep. 3 : Up. 198000 : Sen. 5,043,860 : Cost 67.60546875 : Time 380.00s : 16052.50 words/s
[2019-07-17 05:41:32] Ep. 3 : Up. 200000 : Sen. 5,333,140 : Cost 67.41719818 : Time 380.21s : 16043.55 words/s
[2019-07-17 05:41:32] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-17 05:41:39] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.iter200000.npz
[2019-07-17 05:41:41] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-17 05:41:47] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-17 05:42:07] [valid] Ep. 3 : Up. 200000 : cross-entropy : 53.4321 : new best
[2019-07-17 05:42:13] [valid] Ep. 3 : Up. 200000 : perplexity : 8.30789 : new best
[2019-07-17 05:43:08] [valid] Ep. 3 : Up. 200000 : translation : 24.85 : new best
[2019-07-17 05:49:32] Ep. 3 : Up. 202000 : Sen. 5,622,589 : Cost 67.65661621 : Time 479.22s : 12768.84 words/s
[2019-07-17 05:55:54] Ep. 3 : Up. 204000 : Sen. 5,912,037 : Cost 67.89584351 : Time 382.38s : 16032.28 words/s
[2019-07-17 06:02:15] Ep. 3 : Up. 206000 : Sen. 6,201,043 : Cost 67.54053497 : Time 380.70s : 16016.62 words/s
[2019-07-17 06:08:37] Ep. 3 : Up. 208000 : Sen. 6,491,167 : Cost 67.38945770 : Time 381.89s : 16024.93 words/s
[2019-07-17 06:14:58] Ep. 3 : Up. 210000 : Sen. 6,781,046 : Cost 67.49050140 : Time 381.35s : 16055.90 words/s
[2019-07-17 06:21:20] Ep. 3 : Up. 212000 : Sen. 7,070,838 : Cost 67.47325897 : Time 381.85s : 16041.35 words/s
[2019-07-17 06:27:40] Ep. 3 : Up. 214000 : Sen. 7,360,208 : Cost 67.28432465 : Time 380.28s : 16055.35 words/s
[2019-07-17 06:33:59] Ep. 3 : Up. 216000 : Sen. 7,648,668 : Cost 67.23845673 : Time 379.43s : 16037.92 words/s
[2019-07-17 06:40:20] Ep. 3 : Up. 218000 : Sen. 7,938,191 : Cost 67.34930420 : Time 380.99s : 16051.25 words/s
[2019-07-17 06:46:42] Ep. 3 : Up. 220000 : Sen. 8,228,303 : Cost 67.43057251 : Time 381.36s : 16067.22 words/s
[2019-07-17 06:46:42] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-17 06:46:47] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.iter220000.npz
[2019-07-17 06:46:50] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-17 06:46:56] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-17 06:47:17] [valid] Ep. 3 : Up. 220000 : cross-entropy : 52.985 : new best
[2019-07-17 06:47:24] [valid] Ep. 3 : Up. 220000 : perplexity : 8.162 : new best
[2019-07-17 06:48:22] [valid] Ep. 3 : Up. 220000 : translation : 24.97 : new best
[2019-07-17 06:54:43] Ep. 3 : Up. 222000 : Sen. 8,517,436 : Cost 67.10870361 : Time 480.74s : 12671.99 words/s
[2019-07-17 07:01:03] Ep. 3 : Up. 224000 : Sen. 8,806,664 : Cost 67.31895447 : Time 380.38s : 16073.23 words/s
[2019-07-17 07:07:23] Ep. 3 : Up. 226000 : Sen. 9,096,509 : Cost 66.95315552 : Time 380.39s : 16052.19 words/s
[2019-07-17 07:13:43] Ep. 3 : Up. 228000 : Sen. 9,384,464 : Cost 67.16435242 : Time 379.87s : 16016.65 words/s
[2019-07-17 07:20:05] Ep. 3 : Up. 230000 : Sen. 9,673,971 : Cost 67.22026062 : Time 381.48s : 16051.86 words/s
[2019-07-17 07:26:25] Ep. 3 : Up. 232000 : Sen. 9,964,008 : Cost 66.84556580 : Time 380.45s : 16060.72 words/s
[2019-07-17 07:32:46] Ep. 3 : Up. 234000 : Sen. 10,252,800 : Cost 67.15059662 : Time 380.38s : 16051.11 words/s
[2019-07-17 07:39:06] Ep. 3 : Up. 236000 : Sen. 10,542,489 : Cost 66.96777344 : Time 380.98s : 16044.74 words/s
[2019-07-17 07:45:28] Ep. 3 : Up. 238000 : Sen. 10,831,314 : Cost 66.84545135 : Time 381.18s : 16016.64 words/s
[2019-07-17 07:51:47] Ep. 3 : Up. 240000 : Sen. 11,119,796 : Cost 67.14356232 : Time 379.60s : 16077.14 words/s
[2019-07-17 07:51:47] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-17 07:51:53] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.iter240000.npz
[2019-07-17 07:51:55] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-17 07:52:01] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-17 07:52:19] [valid] Ep. 3 : Up. 240000 : cross-entropy : 52.5104 : new best
[2019-07-17 07:52:25] [valid] Ep. 3 : Up. 240000 : perplexity : 8.00994 : new best
[2019-07-17 07:53:18] [valid] Ep. 3 : Up. 240000 : translation : 25.11 : new best
[2019-07-17 07:59:40] Ep. 3 : Up. 242000 : Sen. 11,407,762 : Cost 66.84752655 : Time 472.57s : 12865.20 words/s
[2019-07-17 08:05:59] Ep. 3 : Up. 244000 : Sen. 11,695,894 : Cost 66.83001709 : Time 379.24s : 16030.51 words/s
[2019-07-17 08:08:11] Seen 11795626 samples
[2019-07-17 08:08:11] Starting epoch 4
[2019-07-17 08:08:11] [data] Shuffling data
[2019-07-17 08:08:28] [data] Done reading 13926791 sentences
[2019-07-17 08:09:47] [data] Done shuffling 13926791 sentences to temp files
[2019-07-17 08:13:58] Ep. 4 : Up. 246000 : Sen. 188,372 : Cost 66.14849091 : Time 479.30s : 12675.76 words/s
[2019-07-17 08:20:20] Ep. 4 : Up. 248000 : Sen. 478,054 : Cost 66.05720520 : Time 381.35s : 16062.76 words/s
[2019-07-17 08:26:40] Ep. 4 : Up. 250000 : Sen. 767,388 : Cost 66.00351715 : Time 380.31s : 16051.96 words/s
[2019-07-17 08:33:01] Ep. 4 : Up. 252000 : Sen. 1,056,396 : Cost 66.04366302 : Time 380.77s : 16024.29 words/s
[2019-07-17 08:39:22] Ep. 4 : Up. 254000 : Sen. 1,345,987 : Cost 66.05439758 : Time 381.12s : 16053.55 words/s
[2019-07-17 08:45:43] Ep. 4 : Up. 256000 : Sen. 1,635,579 : Cost 65.99347687 : Time 380.84s : 16033.91 words/s
[2019-07-17 08:52:05] Ep. 4 : Up. 258000 : Sen. 1,925,166 : Cost 66.02932739 : Time 382.17s : 16006.52 words/s
[2019-07-17 08:58:25] Ep. 4 : Up. 260000 : Sen. 2,214,532 : Cost 66.07777405 : Time 380.49s : 16040.58 words/s
[2019-07-17 08:58:25] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-17 08:58:31] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.iter260000.npz
[2019-07-17 08:58:33] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-17 08:58:39] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-17 08:58:58] [valid] Ep. 4 : Up. 260000 : cross-entropy : 52.1748 : new best
[2019-07-17 08:59:04] [valid] Ep. 4 : Up. 260000 : perplexity : 7.90414 : new best
[2019-07-17 08:59:58] [valid] Ep. 4 : Up. 260000 : translation : 24.84 : stalled 1 times (last best: 25.11)
[2019-07-17 09:06:20] Ep. 4 : Up. 262000 : Sen. 2,502,796 : Cost 66.13185120 : Time 474.84s : 12828.45 words/s
[2019-07-17 09:12:41] Ep. 4 : Up. 264000 : Sen. 2,791,906 : Cost 65.86986542 : Time 380.68s : 16016.29 words/s
[2019-07-17 09:19:01] Ep. 4 : Up. 266000 : Sen. 3,080,608 : Cost 66.23046875 : Time 380.32s : 16028.09 words/s
[2019-07-17 09:25:21] Ep. 4 : Up. 268000 : Sen. 3,369,517 : Cost 66.11456299 : Time 380.18s : 16018.82 words/s
[2019-07-17 09:31:42] Ep. 4 : Up. 270000 : Sen. 3,658,429 : Cost 65.88811493 : Time 380.90s : 16028.34 words/s
[2019-07-17 09:38:04] Ep. 4 : Up. 272000 : Sen. 3,948,404 : Cost 66.08237457 : Time 381.78s : 16070.44 words/s
[2019-07-17 09:44:25] Ep. 4 : Up. 274000 : Sen. 4,237,328 : Cost 65.84606171 : Time 380.93s : 16011.03 words/s
[2019-07-17 09:50:46] Ep. 4 : Up. 276000 : Sen. 4,526,527 : Cost 66.13553619 : Time 380.93s : 16039.99 words/s
[2019-07-17 09:57:06] Ep. 4 : Up. 278000 : Sen. 4,815,267 : Cost 65.79885864 : Time 380.05s : 16020.14 words/s
[2019-07-17 10:03:27] Ep. 4 : Up. 280000 : Sen. 5,104,092 : Cost 65.76133728 : Time 380.59s : 16020.96 words/s
[2019-07-17 10:03:27] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-17 10:03:32] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.iter280000.npz
[2019-07-17 10:03:34] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-17 10:03:40] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-17 10:03:58] [valid] Ep. 4 : Up. 280000 : cross-entropy : 51.8786 : new best
[2019-07-17 10:04:05] [valid] Ep. 4 : Up. 280000 : perplexity : 7.81192 : new best
[2019-07-17 10:04:58] [valid] Ep. 4 : Up. 280000 : translation : 24.98 : stalled 2 times (last best: 25.11)
[2019-07-17 10:11:22] Ep. 4 : Up. 282000 : Sen. 5,392,899 : Cost 66.00351715 : Time 474.98s : 12848.33 words/s
[2019-07-17 10:17:43] Ep. 4 : Up. 284000 : Sen. 5,682,498 : Cost 65.81829071 : Time 381.55s : 16025.99 words/s
[2019-07-17 10:24:06] Ep. 4 : Up. 286000 : Sen. 5,971,464 : Cost 66.08139038 : Time 382.45s : 15965.57 words/s
[2019-07-17 10:30:29] Ep. 4 : Up. 288000 : Sen. 6,261,207 : Cost 65.68476868 : Time 383.18s : 15953.29 words/s
[2019-07-17 10:36:51] Ep. 4 : Up. 290000 : Sen. 6,550,121 : Cost 65.86607361 : Time 382.03s : 15948.54 words/s
[2019-07-17 10:43:14] Ep. 4 : Up. 292000 : Sen. 6,839,935 : Cost 65.59168243 : Time 382.82s : 15965.33 words/s
[2019-07-17 10:49:37] Ep. 4 : Up. 294000 : Sen. 7,129,162 : Cost 66.06894684 : Time 383.35s : 15986.13 words/s
[2019-07-17 10:56:00] Ep. 4 : Up. 296000 : Sen. 7,419,120 : Cost 65.91143799 : Time 383.21s : 16005.43 words/s
[2019-07-17 11:02:22] Ep. 4 : Up. 298000 : Sen. 7,708,732 : Cost 65.60981750 : Time 382.13s : 15986.83 words/s
[2019-07-17 11:08:45] Ep. 4 : Up. 300000 : Sen. 7,998,477 : Cost 65.89165497 : Time 382.75s : 15997.52 words/s
[2019-07-17 11:08:45] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-17 11:08:51] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.iter300000.npz
[2019-07-17 11:08:53] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-17 11:08:59] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-17 11:09:18] [valid] Ep. 4 : Up. 300000 : cross-entropy : 51.5789 : new best
[2019-07-17 11:09:24] [valid] Ep. 4 : Up. 300000 : perplexity : 7.71968 : new best
[2019-07-17 11:10:17] [valid] Ep. 4 : Up. 300000 : translation : 25.2 : new best
[2019-07-17 11:16:40] Ep. 4 : Up. 302000 : Sen. 8,288,000 : Cost 65.69944000 : Time 475.22s : 12854.12 words/s
[2019-07-17 11:23:02] Ep. 4 : Up. 304000 : Sen. 8,576,480 : Cost 65.86406708 : Time 381.39s : 15997.42 words/s
[2019-07-17 11:29:24] Ep. 4 : Up. 306000 : Sen. 8,866,523 : Cost 65.98298645 : Time 382.37s : 16054.21 words/s
[2019-07-17 11:35:44] Ep. 4 : Up. 308000 : Sen. 9,155,952 : Cost 65.56349945 : Time 380.31s : 16066.93 words/s
[2019-07-17 11:42:05] Ep. 4 : Up. 310000 : Sen. 9,445,337 : Cost 65.40605164 : Time 380.11s : 16039.43 words/s
[2019-07-17 11:48:24] Ep. 4 : Up. 312000 : Sen. 9,734,136 : Cost 65.60833740 : Time 379.98s : 16033.66 words/s
[2019-07-17 11:54:46] Ep. 4 : Up. 314000 : Sen. 10,023,144 : Cost 65.77580261 : Time 381.44s : 16005.85 words/s
[2019-07-17 12:01:06] Ep. 4 : Up. 316000 : Sen. 10,313,640 : Cost 65.53961182 : Time 380.46s : 16096.82 words/s
[2019-07-17 12:07:28] Ep. 4 : Up. 318000 : Sen. 10,603,868 : Cost 65.59973907 : Time 381.97s : 16046.70 words/s
[2019-07-17 12:13:48] Ep. 4 : Up. 320000 : Sen. 10,891,854 : Cost 65.33856964 : Time 379.84s : 16007.10 words/s
[2019-07-17 12:13:48] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-17 12:13:53] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.iter320000.npz
[2019-07-17 12:13:56] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-17 12:14:01] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-17 12:14:20] [valid] Ep. 4 : Up. 320000 : cross-entropy : 51.2897 : new best
[2019-07-17 12:14:27] [valid] Ep. 4 : Up. 320000 : perplexity : 7.63173 : new best
[2019-07-17 12:15:20] [valid] Ep. 4 : Up. 320000 : translation : 25.04 : stalled 1 times (last best: 25.2)
[2019-07-17 12:21:43] Ep. 4 : Up. 322000 : Sen. 11,180,536 : Cost 65.79947662 : Time 475.09s : 12858.97 words/s
[2019-07-17 12:28:06] Ep. 4 : Up. 324000 : Sen. 11,470,633 : Cost 65.36307526 : Time 382.50s : 16032.37 words/s
[2019-07-17 12:34:27] Ep. 4 : Up. 326000 : Sen. 11,760,410 : Cost 65.36738586 : Time 381.51s : 16029.25 words/s
[2019-07-17 12:35:14] Seen 11795626 samples
[2019-07-17 12:35:14] Starting epoch 5
[2019-07-17 12:35:14] [data] Shuffling data
[2019-07-17 12:35:23] [data] Done reading 13926791 sentences
[2019-07-17 12:36:43] [data] Done shuffling 13926791 sentences to temp files
[2019-07-17 12:42:21] Ep. 5 : Up. 328000 : Sen. 253,650 : Cost 64.79811096 : Time 473.67s : 12883.50 words/s
[2019-07-17 12:48:42] Ep. 5 : Up. 330000 : Sen. 542,902 : Cost 64.59903717 : Time 380.73s : 16028.26 words/s
[2019-07-17 12:55:03] Ep. 5 : Up. 332000 : Sen. 831,868 : Cost 65.01560974 : Time 381.20s : 16026.89 words/s
[2019-07-17 13:01:24] Ep. 5 : Up. 334000 : Sen. 1,120,936 : Cost 65.07208252 : Time 381.41s : 16032.13 words/s
[2019-07-17 13:07:44] Ep. 5 : Up. 336000 : Sen. 1,410,154 : Cost 64.83170319 : Time 380.10s : 16045.31 words/s
[2019-07-17 13:14:06] Ep. 5 : Up. 338000 : Sen. 1,699,174 : Cost 64.80140686 : Time 381.40s : 16005.63 words/s
[2019-07-17 13:20:25] Ep. 5 : Up. 340000 : Sen. 1,988,013 : Cost 64.59342194 : Time 379.31s : 16036.12 words/s
[2019-07-17 13:20:25] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-17 13:20:31] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.iter340000.npz
[2019-07-17 13:20:33] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-17 13:20:39] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-17 13:20:57] [valid] Ep. 5 : Up. 340000 : cross-entropy : 51.1426 : new best
[2019-07-17 13:21:04] [valid] Ep. 5 : Up. 340000 : perplexity : 7.58738 : new best
[2019-07-17 13:21:57] [valid] Ep. 5 : Up. 340000 : translation : 24.9 : stalled 2 times (last best: 25.2)
[2019-07-17 13:28:21] Ep. 5 : Up. 342000 : Sen. 2,277,872 : Cost 64.68360901 : Time 475.67s : 12859.20 words/s
[2019-07-17 13:34:41] Ep. 5 : Up. 344000 : Sen. 2,566,268 : Cost 64.71116638 : Time 380.31s : 16017.14 words/s
[2019-07-17 13:41:02] Ep. 5 : Up. 346000 : Sen. 2,855,981 : Cost 64.80076599 : Time 381.05s : 16064.82 words/s
[2019-07-17 13:47:25] Ep. 5 : Up. 348000 : Sen. 3,146,171 : Cost 64.77126312 : Time 382.42s : 16020.67 words/s
[2019-07-17 13:53:46] Ep. 5 : Up. 350000 : Sen. 3,435,512 : Cost 65.01291656 : Time 381.30s : 16025.76 words/s
[2019-07-17 14:00:07] Ep. 5 : Up. 352000 : Sen. 3,724,494 : Cost 64.67199707 : Time 381.46s : 15993.39 words/s
[2019-07-17 14:06:29] Ep. 5 : Up. 354000 : Sen. 4,014,421 : Cost 64.91094971 : Time 381.51s : 16039.08 words/s
[2019-07-17 14:12:51] Ep. 5 : Up. 356000 : Sen. 4,303,781 : Cost 64.84284210 : Time 381.98s : 16024.37 words/s
[2019-07-17 14:19:12] Ep. 5 : Up. 358000 : Sen. 4,593,268 : Cost 64.72014618 : Time 381.48s : 15983.12 words/s
[2019-07-17 14:25:34] Ep. 5 : Up. 360000 : Sen. 4,883,020 : Cost 64.90501404 : Time 382.15s : 16048.61 words/s
[2019-07-17 14:25:34] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-17 14:25:40] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.iter360000.npz
[2019-07-17 14:25:42] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-17 14:25:49] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-17 14:26:07] [valid] Ep. 5 : Up. 360000 : cross-entropy : 50.914 : new best
[2019-07-17 14:26:14] [valid] Ep. 5 : Up. 360000 : perplexity : 7.51895 : new best
[2019-07-17 14:27:07] [valid] Ep. 5 : Up. 360000 : translation : 25.05 : stalled 3 times (last best: 25.2)
[2019-07-17 14:33:31] Ep. 5 : Up. 362000 : Sen. 5,172,783 : Cost 64.57213593 : Time 476.98s : 12806.68 words/s
[2019-07-17 14:39:52] Ep. 5 : Up. 364000 : Sen. 5,461,113 : Cost 64.91846466 : Time 380.81s : 16024.49 words/s
[2019-07-17 14:46:12] Ep. 5 : Up. 366000 : Sen. 5,749,961 : Cost 64.49610901 : Time 380.24s : 16005.18 words/s
[2019-07-17 14:52:34] Ep. 5 : Up. 368000 : Sen. 6,038,917 : Cost 64.74076843 : Time 381.50s : 16003.54 words/s
[2019-07-17 14:58:55] Ep. 5 : Up. 370000 : Sen. 6,328,410 : Cost 64.68392181 : Time 380.81s : 16028.69 words/s
[2019-07-17 15:05:17] Ep. 5 : Up. 372000 : Sen. 6,618,490 : Cost 64.61395264 : Time 382.25s : 16026.88 words/s
