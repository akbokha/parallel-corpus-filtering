[2019-07-16 18:49:31] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-16 18:49:31] [marian] Running on bil as process 107225 with command line:
[2019-07-16 18:49:31] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz -T . --devices 1 --train-sets ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/data/train.bpe.de ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/data/train.bpe.en --vocabs ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/data/train.bpe.de.json ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/data/train.bpe.en.json --mini-batch-fit -w 5000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/data/dev.bpe.de ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/dev.out --valid-script-path ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/train.log --valid-log ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/valid.log
[2019-07-16 18:49:31] [config] after-batches: 0
[2019-07-16 18:49:31] [config] after-epochs: 0
[2019-07-16 18:49:31] [config] allow-unk: false
[2019-07-16 18:49:31] [config] beam-size: 12
[2019-07-16 18:49:31] [config] bert-class-symbol: "[CLS]"
[2019-07-16 18:49:31] [config] bert-mask-symbol: "[MASK]"
[2019-07-16 18:49:31] [config] bert-masking-fraction: 0.15
[2019-07-16 18:49:31] [config] bert-sep-symbol: "[SEP]"
[2019-07-16 18:49:31] [config] bert-train-type-embeddings: true
[2019-07-16 18:49:31] [config] bert-type-vocab-size: 2
[2019-07-16 18:49:31] [config] best-deep: false
[2019-07-16 18:49:31] [config] clip-gemm: 0
[2019-07-16 18:49:31] [config] clip-norm: 1
[2019-07-16 18:49:31] [config] cost-type: ce-mean
[2019-07-16 18:49:31] [config] cpu-threads: 0
[2019-07-16 18:49:31] [config] data-weighting: ""
[2019-07-16 18:49:31] [config] data-weighting-type: sentence
[2019-07-16 18:49:31] [config] dec-cell: gru
[2019-07-16 18:49:31] [config] dec-cell-base-depth: 2
[2019-07-16 18:49:31] [config] dec-cell-high-depth: 1
[2019-07-16 18:49:31] [config] dec-depth: 1
[2019-07-16 18:49:31] [config] devices:
[2019-07-16 18:49:31] [config]   - 1
[2019-07-16 18:49:31] [config] dim-emb: 512
[2019-07-16 18:49:31] [config] dim-rnn: 1024
[2019-07-16 18:49:31] [config] dim-vocabs:
[2019-07-16 18:49:31] [config]   - 50000
[2019-07-16 18:49:31] [config]   - 50000
[2019-07-16 18:49:31] [config] disp-first: 0
[2019-07-16 18:49:31] [config] disp-freq: 2000
[2019-07-16 18:49:31] [config] disp-label-counts: false
[2019-07-16 18:49:31] [config] dropout-rnn: 0.2
[2019-07-16 18:49:31] [config] dropout-src: 0.1
[2019-07-16 18:49:31] [config] dropout-trg: 0.1
[2019-07-16 18:49:31] [config] dump-config: ""
[2019-07-16 18:49:31] [config] early-stopping: 5
[2019-07-16 18:49:31] [config] embedding-fix-src: false
[2019-07-16 18:49:31] [config] embedding-fix-trg: false
[2019-07-16 18:49:31] [config] embedding-normalization: false
[2019-07-16 18:49:31] [config] embedding-vectors:
[2019-07-16 18:49:31] [config]   []
[2019-07-16 18:49:31] [config] enc-cell: gru
[2019-07-16 18:49:31] [config] enc-cell-depth: 1
[2019-07-16 18:49:31] [config] enc-depth: 1
[2019-07-16 18:49:31] [config] enc-type: bidirectional
[2019-07-16 18:49:31] [config] exponential-smoothing: 0.0001
[2019-07-16 18:49:31] [config] grad-dropping-momentum: 0
[2019-07-16 18:49:31] [config] grad-dropping-rate: 0
[2019-07-16 18:49:31] [config] grad-dropping-warmup: 100
[2019-07-16 18:49:31] [config] guided-alignment: none
[2019-07-16 18:49:31] [config] guided-alignment-cost: mse
[2019-07-16 18:49:31] [config] guided-alignment-weight: 0.1
[2019-07-16 18:49:31] [config] ignore-model-config: false
[2019-07-16 18:49:31] [config] input-types:
[2019-07-16 18:49:31] [config]   []
[2019-07-16 18:49:31] [config] interpolate-env-vars: false
[2019-07-16 18:49:31] [config] keep-best: false
[2019-07-16 18:49:31] [config] label-smoothing: 0
[2019-07-16 18:49:31] [config] layer-normalization: true
[2019-07-16 18:49:31] [config] learn-rate: 0.0001
[2019-07-16 18:49:31] [config] log: ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/train.log
[2019-07-16 18:49:31] [config] log-level: info
[2019-07-16 18:49:31] [config] log-time-zone: ""
[2019-07-16 18:49:31] [config] lr-decay: 0
[2019-07-16 18:49:31] [config] lr-decay-freq: 50000
[2019-07-16 18:49:31] [config] lr-decay-inv-sqrt:
[2019-07-16 18:49:31] [config]   - 0
[2019-07-16 18:49:31] [config] lr-decay-repeat-warmup: false
[2019-07-16 18:49:31] [config] lr-decay-reset-optimizer: false
[2019-07-16 18:49:31] [config] lr-decay-start:
[2019-07-16 18:49:31] [config]   - 10
[2019-07-16 18:49:31] [config]   - 1
[2019-07-16 18:49:31] [config] lr-decay-strategy: epoch+stalled
[2019-07-16 18:49:31] [config] lr-report: false
[2019-07-16 18:49:31] [config] lr-warmup: 0
[2019-07-16 18:49:31] [config] lr-warmup-at-reload: false
[2019-07-16 18:49:31] [config] lr-warmup-cycle: false
[2019-07-16 18:49:31] [config] lr-warmup-start-rate: 0
[2019-07-16 18:49:31] [config] max-length: 50
[2019-07-16 18:49:31] [config] max-length-crop: false
[2019-07-16 18:49:31] [config] max-length-factor: 3
[2019-07-16 18:49:31] [config] maxi-batch: 100
[2019-07-16 18:49:31] [config] maxi-batch-sort: trg
[2019-07-16 18:49:31] [config] mini-batch: 64
[2019-07-16 18:49:31] [config] mini-batch-fit: true
[2019-07-16 18:49:31] [config] mini-batch-fit-step: 10
[2019-07-16 18:49:31] [config] mini-batch-overstuff: 1
[2019-07-16 18:49:31] [config] mini-batch-track-lr: false
[2019-07-16 18:49:31] [config] mini-batch-understuff: 1
[2019-07-16 18:49:31] [config] mini-batch-warmup: 0
[2019-07-16 18:49:31] [config] mini-batch-words: 0
[2019-07-16 18:49:31] [config] mini-batch-words-ref: 0
[2019-07-16 18:49:31] [config] model: ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-16 18:49:31] [config] multi-loss-type: sum
[2019-07-16 18:49:31] [config] multi-node: false
[2019-07-16 18:49:31] [config] multi-node-overlap: true
[2019-07-16 18:49:31] [config] n-best: false
[2019-07-16 18:49:31] [config] no-nccl: false
[2019-07-16 18:49:31] [config] no-reload: false
[2019-07-16 18:49:31] [config] no-restore-corpus: false
[2019-07-16 18:49:31] [config] no-shuffle: false
[2019-07-16 18:49:31] [config] normalize: 1
[2019-07-16 18:49:31] [config] num-devices: 0
[2019-07-16 18:49:31] [config] optimizer: adam
[2019-07-16 18:49:31] [config] optimizer-delay: 1
[2019-07-16 18:49:31] [config] optimizer-params:
[2019-07-16 18:49:31] [config]   []
[2019-07-16 18:49:31] [config] overwrite: false
[2019-07-16 18:49:31] [config] pretrained-model: ""
[2019-07-16 18:49:31] [config] quiet: false
[2019-07-16 18:49:31] [config] quiet-translation: true
[2019-07-16 18:49:31] [config] relative-paths: false
[2019-07-16 18:49:31] [config] right-left: false
[2019-07-16 18:49:31] [config] save-freq: 20000
[2019-07-16 18:49:31] [config] seed: 1111
[2019-07-16 18:49:31] [config] shuffle-in-ram: false
[2019-07-16 18:49:31] [config] skip: false
[2019-07-16 18:49:31] [config] sqlite: ""
[2019-07-16 18:49:31] [config] sqlite-drop: false
[2019-07-16 18:49:31] [config] sync-sgd: true
[2019-07-16 18:49:31] [config] tempdir: .
[2019-07-16 18:49:31] [config] tied-embeddings: false
[2019-07-16 18:49:31] [config] tied-embeddings-all: false
[2019-07-16 18:49:31] [config] tied-embeddings-src: false
[2019-07-16 18:49:31] [config] train-sets:
[2019-07-16 18:49:31] [config]   - ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/data/train.bpe.de
[2019-07-16 18:49:31] [config]   - ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/data/train.bpe.en
[2019-07-16 18:49:31] [config] transformer-aan-activation: swish
[2019-07-16 18:49:31] [config] transformer-aan-depth: 2
[2019-07-16 18:49:31] [config] transformer-aan-nogate: false
[2019-07-16 18:49:31] [config] transformer-decoder-autoreg: self-attention
[2019-07-16 18:49:31] [config] transformer-dim-aan: 2048
[2019-07-16 18:49:31] [config] transformer-dim-ffn: 2048
[2019-07-16 18:49:31] [config] transformer-dropout: 0
[2019-07-16 18:49:31] [config] transformer-dropout-attention: 0
[2019-07-16 18:49:31] [config] transformer-dropout-ffn: 0
[2019-07-16 18:49:31] [config] transformer-ffn-activation: swish
[2019-07-16 18:49:31] [config] transformer-ffn-depth: 2
[2019-07-16 18:49:31] [config] transformer-guided-alignment-layer: last
[2019-07-16 18:49:31] [config] transformer-heads: 8
[2019-07-16 18:49:31] [config] transformer-no-projection: false
[2019-07-16 18:49:31] [config] transformer-postprocess: dan
[2019-07-16 18:49:31] [config] transformer-postprocess-emb: d
[2019-07-16 18:49:31] [config] transformer-preprocess: ""
[2019-07-16 18:49:31] [config] transformer-tied-layers:
[2019-07-16 18:49:31] [config]   []
[2019-07-16 18:49:31] [config] transformer-train-position-embeddings: false
[2019-07-16 18:49:31] [config] type: amun
[2019-07-16 18:49:31] [config] ulr: false
[2019-07-16 18:49:31] [config] ulr-dim-emb: 0
[2019-07-16 18:49:31] [config] ulr-dropout: 0
[2019-07-16 18:49:31] [config] ulr-keys-vectors: ""
[2019-07-16 18:49:31] [config] ulr-query-vectors: ""
[2019-07-16 18:49:31] [config] ulr-softmax-temperature: 1
[2019-07-16 18:49:31] [config] ulr-trainable-transformation: false
[2019-07-16 18:49:31] [config] valid-freq: 20000
[2019-07-16 18:49:31] [config] valid-log: ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/valid.log
[2019-07-16 18:49:31] [config] valid-max-length: 1000
[2019-07-16 18:49:31] [config] valid-metrics:
[2019-07-16 18:49:31] [config]   - cross-entropy
[2019-07-16 18:49:31] [config]   - perplexity
[2019-07-16 18:49:31] [config]   - translation
[2019-07-16 18:49:31] [config] valid-mini-batch: 8
[2019-07-16 18:49:31] [config] valid-script-path: ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/score-dev.sh
[2019-07-16 18:49:31] [config] valid-sets:
[2019-07-16 18:49:31] [config]   - ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/data/dev.bpe.de
[2019-07-16 18:49:31] [config]   - ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/data/dev.bpe.en
[2019-07-16 18:49:31] [config] valid-translation-output: ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/dev.out
[2019-07-16 18:49:31] [config] vocabs:
[2019-07-16 18:49:31] [config]   - ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/data/train.bpe.de.json
[2019-07-16 18:49:31] [config]   - ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/data/train.bpe.en.json
[2019-07-16 18:49:31] [config] word-penalty: 0
[2019-07-16 18:49:31] [config] workspace: 5000
[2019-07-16 18:49:31] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-16 18:49:31] Using synchronous training
[2019-07-16 18:49:31] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/data/train.bpe.de.json
[2019-07-16 18:49:32] [data] Using unused word id eos for 0
[2019-07-16 18:49:32] [data] Using unused word id UNK for 1
[2019-07-16 18:49:32] [data] Setting vocabulary size for input 0 to 50000
[2019-07-16 18:49:32] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/data/train.bpe.en.json
[2019-07-16 18:49:32] [data] Using unused word id eos for 0
[2019-07-16 18:49:32] [data] Using unused word id UNK for 1
[2019-07-16 18:49:32] [data] Setting vocabulary size for input 1 to 50000
[2019-07-16 18:49:32] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-16 18:49:32] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-16 18:49:33] [memory] Extending reserved space to 5120 MB (device gpu1)
[2019-07-16 18:49:34] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-16 18:49:34] [comm] NCCLCommunicator constructed successfully.
[2019-07-16 18:49:34] [training] Using 1 GPUs
[2019-07-16 18:49:34] [memory] Reserving 422 MB, device gpu1
[2019-07-16 18:49:34] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-16 18:49:34] [memory] Reserving 422 MB, device gpu1
[2019-07-16 18:49:38] [batching] Done. Typical MB size is 6880 target words
[2019-07-16 18:49:38] [memory] Extending reserved space to 5120 MB (device gpu1)
[2019-07-16 18:49:38] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-16 18:49:39] [comm] NCCLCommunicator constructed successfully.
[2019-07-16 18:49:39] [training] Using 1 GPUs
[2019-07-16 18:49:39] Training started
[2019-07-16 18:49:39] [data] Shuffling data
[2019-07-16 18:49:50] [data] Done reading 13926791 sentences
[2019-07-16 18:51:05] [data] Done shuffling 13926791 sentences to temp files
[2019-07-16 18:51:09] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-07-16 18:51:09] [memory] Reserving 422 MB, device gpu1
[2019-07-16 18:51:09] [memory] Reserving 422 MB, device gpu1
[2019-07-16 18:51:09] [memory] Reserving 422 MB, device gpu1
[2019-07-16 18:51:10] [memory] Reserving 844 MB, device gpu1
[2019-07-16 18:57:36] Ep. 1 : Up. 2000 : Sen. 288,528 : Cost 136.88179016 : Time 483.85s : 12569.46 words/s
[2019-07-16 19:04:05] Ep. 1 : Up. 4000 : Sen. 578,111 : Cost 118.92135620 : Time 389.59s : 15719.39 words/s
[2019-07-16 19:10:35] Ep. 1 : Up. 6000 : Sen. 867,005 : Cost 110.56600189 : Time 389.24s : 15682.54 words/s
[2019-07-16 19:17:03] Ep. 1 : Up. 8000 : Sen. 1,156,241 : Cost 104.73595428 : Time 387.98s : 15720.76 words/s
[2019-07-16 19:23:32] Ep. 1 : Up. 10000 : Sen. 1,445,774 : Cost 100.70191956 : Time 389.45s : 15699.28 words/s
[2019-07-16 19:30:00] Ep. 1 : Up. 12000 : Sen. 1,734,799 : Cost 97.26471710 : Time 387.94s : 15711.26 words/s
[2019-07-16 19:36:29] Ep. 1 : Up. 14000 : Sen. 2,024,239 : Cost 94.86360168 : Time 389.11s : 15720.53 words/s
[2019-07-16 19:42:58] Ep. 1 : Up. 16000 : Sen. 2,313,415 : Cost 92.60398102 : Time 388.89s : 15705.19 words/s
[2019-07-16 19:49:27] Ep. 1 : Up. 18000 : Sen. 2,603,094 : Cost 90.64198303 : Time 389.12s : 15723.80 words/s
[2019-07-16 19:55:57] Ep. 1 : Up. 20000 : Sen. 2,892,668 : Cost 89.23893738 : Time 389.38s : 15718.76 words/s
[2019-07-16 19:55:57] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-16 19:56:01] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.iter20000.npz
[2019-07-16 19:56:03] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-16 19:56:08] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-16 19:56:26] [valid] Ep. 1 : Up. 20000 : cross-entropy : 90.3938 : new best
[2019-07-16 19:56:32] [valid] Ep. 1 : Up. 20000 : perplexity : 35.9393 : new best
[2019-07-16 19:57:33] [valid] Ep. 1 : Up. 20000 : translation : 12.35 : new best
[2019-07-16 20:04:04] Ep. 1 : Up. 22000 : Sen. 3,182,201 : Cost 87.56404114 : Time 487.87s : 12517.50 words/s
[2019-07-16 20:10:33] Ep. 1 : Up. 24000 : Sen. 3,469,739 : Cost 86.66011810 : Time 388.32s : 15665.64 words/s
[2019-07-16 20:17:02] Ep. 1 : Up. 26000 : Sen. 3,758,776 : Cost 85.19395447 : Time 389.18s : 15673.43 words/s
[2019-07-16 20:23:30] Ep. 1 : Up. 28000 : Sen. 4,047,258 : Cost 84.34592438 : Time 387.97s : 15664.57 words/s
[2019-07-16 20:30:01] Ep. 1 : Up. 30000 : Sen. 4,336,108 : Cost 84.05047607 : Time 391.23s : 15646.93 words/s
[2019-07-16 20:36:32] Ep. 1 : Up. 32000 : Sen. 4,626,307 : Cost 82.65547943 : Time 390.55s : 15672.62 words/s
[2019-07-16 20:43:02] Ep. 1 : Up. 34000 : Sen. 4,915,856 : Cost 82.24341583 : Time 390.12s : 15668.27 words/s
[2019-07-16 20:49:32] Ep. 1 : Up. 36000 : Sen. 5,205,021 : Cost 81.48593140 : Time 390.66s : 15641.66 words/s
[2019-07-16 20:56:00] Ep. 1 : Up. 38000 : Sen. 5,492,153 : Cost 80.93486786 : Time 387.75s : 15641.11 words/s
[2019-07-16 21:02:30] Ep. 1 : Up. 40000 : Sen. 5,781,767 : Cost 80.22971344 : Time 389.50s : 15689.34 words/s
[2019-07-16 21:02:30] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-16 21:02:35] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.iter40000.npz
[2019-07-16 21:02:38] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-16 21:02:43] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-16 21:03:03] [valid] Ep. 1 : Up. 40000 : cross-entropy : 72.8554 : new best
[2019-07-16 21:03:10] [valid] Ep. 1 : Up. 40000 : perplexity : 17.9372 : new best
[2019-07-16 21:04:02] [valid] Ep. 1 : Up. 40000 : translation : 19.85 : new best
[2019-07-16 21:10:31] Ep. 1 : Up. 42000 : Sen. 6,070,179 : Cost 79.59739685 : Time 481.01s : 12636.21 words/s
[2019-07-16 21:17:00] Ep. 1 : Up. 44000 : Sen. 6,358,333 : Cost 79.53002930 : Time 389.01s : 15664.11 words/s
[2019-07-16 21:23:27] Ep. 1 : Up. 46000 : Sen. 6,646,152 : Cost 78.69382477 : Time 387.64s : 15668.85 words/s
[2019-07-16 21:29:55] Ep. 1 : Up. 48000 : Sen. 6,934,986 : Cost 78.28050995 : Time 387.29s : 15730.96 words/s
[2019-07-16 21:36:24] Ep. 1 : Up. 50000 : Sen. 7,224,189 : Cost 77.85938263 : Time 389.43s : 15666.26 words/s
[2019-07-16 21:42:54] Ep. 1 : Up. 52000 : Sen. 7,513,336 : Cost 77.79228210 : Time 389.72s : 15701.64 words/s
[2019-07-16 21:49:23] Ep. 1 : Up. 54000 : Sen. 7,802,854 : Cost 77.25613403 : Time 389.35s : 15701.86 words/s
[2019-07-16 21:55:53] Ep. 1 : Up. 56000 : Sen. 8,091,993 : Cost 77.17910767 : Time 389.64s : 15684.80 words/s
[2019-07-16 22:02:21] Ep. 1 : Up. 58000 : Sen. 8,381,184 : Cost 76.47481537 : Time 388.11s : 15698.96 words/s
[2019-07-16 22:08:50] Ep. 1 : Up. 60000 : Sen. 8,669,663 : Cost 76.60727692 : Time 389.29s : 15698.57 words/s
[2019-07-16 22:08:50] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-16 22:08:56] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.iter60000.npz
[2019-07-16 22:08:58] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-16 22:09:04] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-16 22:09:23] [valid] Ep. 1 : Up. 60000 : cross-entropy : 65.955 : new best
[2019-07-16 22:09:30] [valid] Ep. 1 : Up. 60000 : perplexity : 13.646 : new best
[2019-07-16 22:10:22] [valid] Ep. 1 : Up. 60000 : translation : 21.75 : new best
[2019-07-16 22:16:53] Ep. 1 : Up. 62000 : Sen. 8,958,370 : Cost 76.00045013 : Time 482.98s : 12633.83 words/s
[2019-07-16 22:23:24] Ep. 1 : Up. 64000 : Sen. 9,247,562 : Cost 75.84820557 : Time 390.48s : 15649.67 words/s
[2019-07-16 22:29:54] Ep. 1 : Up. 66000 : Sen. 9,536,903 : Cost 75.59458923 : Time 389.85s : 15687.63 words/s
[2019-07-16 22:36:23] Ep. 1 : Up. 68000 : Sen. 9,826,669 : Cost 75.00468445 : Time 389.14s : 15671.28 words/s
[2019-07-16 22:42:54] Ep. 1 : Up. 70000 : Sen. 10,117,714 : Cost 75.17548370 : Time 391.10s : 15718.33 words/s
[2019-07-16 22:49:24] Ep. 1 : Up. 72000 : Sen. 10,408,154 : Cost 74.97193146 : Time 390.03s : 15702.59 words/s
[2019-07-16 22:55:53] Ep. 1 : Up. 74000 : Sen. 10,697,506 : Cost 74.55012512 : Time 389.38s : 15696.32 words/s
[2019-07-16 23:02:25] Ep. 1 : Up. 76000 : Sen. 10,987,660 : Cost 74.52098083 : Time 391.38s : 15677.76 words/s
[2019-07-16 23:08:55] Ep. 1 : Up. 78000 : Sen. 11,278,280 : Cost 73.84957886 : Time 390.49s : 15695.70 words/s
[2019-07-16 23:15:25] Ep. 1 : Up. 80000 : Sen. 11,567,748 : Cost 74.09455872 : Time 390.41s : 15695.65 words/s
[2019-07-16 23:15:25] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-16 23:15:31] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.iter80000.npz
[2019-07-16 23:15:33] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-16 23:15:40] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-16 23:15:59] [valid] Ep. 1 : Up. 80000 : cross-entropy : 62.0928 : new best
[2019-07-16 23:16:06] [valid] Ep. 1 : Up. 80000 : perplexity : 11.7096 : new best
[2019-07-16 23:16:58] [valid] Ep. 1 : Up. 80000 : translation : 22.9 : new best
[2019-07-16 23:22:07] Seen 11795623 samples
[2019-07-16 23:22:07] Starting epoch 2
[2019-07-16 23:22:07] [data] Shuffling data
[2019-07-16 23:22:15] [data] Done reading 13926791 sentences
[2019-07-16 23:23:34] [data] Done shuffling 13926791 sentences to temp files
[2019-07-16 23:24:59] Ep. 2 : Up. 82000 : Sen. 60,939 : Cost 73.57783508 : Time 573.90s : 10610.38 words/s
[2019-07-16 23:31:29] Ep. 2 : Up. 84000 : Sen. 350,195 : Cost 73.02826691 : Time 390.01s : 15655.87 words/s
[2019-07-16 23:37:59] Ep. 2 : Up. 86000 : Sen. 639,472 : Cost 72.64840698 : Time 389.30s : 15667.28 words/s
[2019-07-16 23:44:28] Ep. 2 : Up. 88000 : Sen. 927,868 : Cost 72.68930817 : Time 389.32s : 15676.89 words/s
[2019-07-16 23:50:56] Ep. 2 : Up. 90000 : Sen. 1,216,626 : Cost 72.69294739 : Time 388.32s : 15708.48 words/s
[2019-07-16 23:57:26] Ep. 2 : Up. 92000 : Sen. 1,505,872 : Cost 72.36633301 : Time 390.11s : 15666.39 words/s
[2019-07-17 00:03:56] Ep. 2 : Up. 94000 : Sen. 1,795,349 : Cost 72.24792480 : Time 389.93s : 15659.03 words/s
[2019-07-17 00:10:27] Ep. 2 : Up. 96000 : Sen. 2,084,384 : Cost 72.16948700 : Time 390.42s : 15656.56 words/s
[2019-07-17 00:16:57] Ep. 2 : Up. 98000 : Sen. 2,374,268 : Cost 71.80864716 : Time 390.00s : 15668.77 words/s
[2019-07-17 00:23:26] Ep. 2 : Up. 100000 : Sen. 2,663,445 : Cost 71.98236084 : Time 389.69s : 15669.15 words/s
[2019-07-17 00:23:26] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-17 00:23:33] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.iter100000.npz
[2019-07-17 00:23:35] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-17 00:23:41] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-17 00:24:01] [valid] Ep. 2 : Up. 100000 : cross-entropy : 59.7129 : new best
[2019-07-17 00:24:07] [valid] Ep. 2 : Up. 100000 : perplexity : 10.6558 : new best
[2019-07-17 00:24:59] [valid] Ep. 2 : Up. 100000 : translation : 23.59 : new best
[2019-07-17 00:31:32] Ep. 2 : Up. 102000 : Sen. 2,952,650 : Cost 71.95118713 : Time 485.48s : 12584.49 words/s
[2019-07-17 00:38:03] Ep. 2 : Up. 104000 : Sen. 3,242,754 : Cost 71.61843872 : Time 391.03s : 15675.49 words/s
[2019-07-17 00:44:33] Ep. 2 : Up. 106000 : Sen. 3,531,121 : Cost 71.82207489 : Time 389.65s : 15687.06 words/s
[2019-07-17 00:51:03] Ep. 2 : Up. 108000 : Sen. 3,820,485 : Cost 71.43343353 : Time 389.92s : 15645.62 words/s
[2019-07-17 00:57:33] Ep. 2 : Up. 110000 : Sen. 4,110,524 : Cost 71.20092773 : Time 390.90s : 15660.46 words/s
[2019-07-17 01:04:04] Ep. 2 : Up. 112000 : Sen. 4,399,683 : Cost 71.32155609 : Time 390.50s : 15669.30 words/s
[2019-07-17 01:10:33] Ep. 2 : Up. 114000 : Sen. 4,688,381 : Cost 70.98097992 : Time 389.26s : 15649.35 words/s
[2019-07-17 01:17:03] Ep. 2 : Up. 116000 : Sen. 4,978,199 : Cost 70.69235992 : Time 390.07s : 15657.39 words/s
[2019-07-17 01:23:33] Ep. 2 : Up. 118000 : Sen. 5,267,506 : Cost 71.10271454 : Time 389.56s : 15709.07 words/s
[2019-07-17 01:30:03] Ep. 2 : Up. 120000 : Sen. 5,557,370 : Cost 70.82608795 : Time 390.43s : 15670.00 words/s
[2019-07-17 01:30:03] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-17 01:30:09] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.iter120000.npz
[2019-07-17 01:30:11] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-17 01:30:16] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-17 01:30:35] [valid] Ep. 2 : Up. 120000 : cross-entropy : 57.8977 : new best
[2019-07-17 01:30:41] [valid] Ep. 2 : Up. 120000 : perplexity : 9.91632 : new best
[2019-07-17 01:31:34] [valid] Ep. 2 : Up. 120000 : translation : 24.03 : new best
[2019-07-17 01:38:07] Ep. 2 : Up. 122000 : Sen. 5,846,882 : Cost 70.61516571 : Time 483.38s : 12662.46 words/s
[2019-07-17 01:44:35] Ep. 2 : Up. 124000 : Sen. 6,135,830 : Cost 70.55711365 : Time 388.40s : 15703.10 words/s
[2019-07-17 01:51:04] Ep. 2 : Up. 126000 : Sen. 6,424,508 : Cost 70.36801910 : Time 388.65s : 15676.07 words/s
[2019-07-17 01:57:34] Ep. 2 : Up. 128000 : Sen. 6,713,600 : Cost 70.36399078 : Time 390.45s : 15654.50 words/s
[2019-07-17 02:04:04] Ep. 2 : Up. 130000 : Sen. 7,002,779 : Cost 70.40937042 : Time 389.99s : 15674.23 words/s
[2019-07-17 02:10:35] Ep. 2 : Up. 132000 : Sen. 7,293,267 : Cost 70.05545807 : Time 390.82s : 15677.74 words/s
[2019-07-17 02:17:04] Ep. 2 : Up. 134000 : Sen. 7,582,530 : Cost 70.09300232 : Time 389.38s : 15685.41 words/s
[2019-07-17 02:23:34] Ep. 2 : Up. 136000 : Sen. 7,871,575 : Cost 70.08137512 : Time 389.95s : 15647.73 words/s
[2019-07-17 02:30:03] Ep. 2 : Up. 138000 : Sen. 8,161,429 : Cost 69.90261841 : Time 388.96s : 15721.05 words/s
[2019-07-17 02:36:32] Ep. 2 : Up. 140000 : Sen. 8,449,782 : Cost 69.77475739 : Time 388.68s : 15652.64 words/s
[2019-07-17 02:36:32] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-17 02:36:38] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.iter140000.npz
[2019-07-17 02:36:41] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-17 02:36:46] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-17 02:37:05] [valid] Ep. 2 : Up. 140000 : cross-entropy : 56.5735 : new best
[2019-07-17 02:37:12] [valid] Ep. 2 : Up. 140000 : perplexity : 9.40941 : new best
[2019-07-17 02:38:03] [valid] Ep. 2 : Up. 140000 : translation : 24.07 : new best
[2019-07-17 02:44:36] Ep. 2 : Up. 142000 : Sen. 8,739,488 : Cost 70.06741333 : Time 484.36s : 12667.50 words/s
[2019-07-17 02:51:06] Ep. 2 : Up. 144000 : Sen. 9,029,162 : Cost 69.44530487 : Time 389.68s : 15658.98 words/s
[2019-07-17 02:57:35] Ep. 2 : Up. 146000 : Sen. 9,317,698 : Cost 69.64128113 : Time 388.84s : 15676.28 words/s
[2019-07-17 03:04:05] Ep. 2 : Up. 148000 : Sen. 9,606,706 : Cost 69.53553009 : Time 390.12s : 15643.05 words/s
[2019-07-17 03:10:35] Ep. 2 : Up. 150000 : Sen. 9,895,416 : Cost 69.76985931 : Time 389.67s : 15667.13 words/s
[2019-07-17 03:17:04] Ep. 2 : Up. 152000 : Sen. 10,184,790 : Cost 69.33039093 : Time 389.44s : 15679.07 words/s
[2019-07-17 03:23:34] Ep. 2 : Up. 154000 : Sen. 10,474,463 : Cost 69.39527130 : Time 390.33s : 15661.91 words/s
[2019-07-17 03:30:04] Ep. 2 : Up. 156000 : Sen. 10,763,795 : Cost 69.08740234 : Time 389.95s : 15645.98 words/s
[2019-07-17 03:36:34] Ep. 2 : Up. 158000 : Sen. 11,052,800 : Cost 69.10585785 : Time 389.32s : 15678.17 words/s
[2019-07-17 03:43:04] Ep. 2 : Up. 160000 : Sen. 11,342,766 : Cost 68.88452148 : Time 390.26s : 15687.10 words/s
[2019-07-17 03:43:04] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-17 03:43:09] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.iter160000.npz
[2019-07-17 03:43:12] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-17 03:43:17] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-17 03:43:37] [valid] Ep. 2 : Up. 160000 : cross-entropy : 55.6509 : new best
[2019-07-17 03:43:43] [valid] Ep. 2 : Up. 160000 : perplexity : 9.07164 : new best
[2019-07-17 03:44:35] [valid] Ep. 2 : Up. 160000 : translation : 24.18 : new best
[2019-07-17 03:51:06] Ep. 2 : Up. 162000 : Sen. 11,632,080 : Cost 68.78927612 : Time 482.49s : 12620.35 words/s
[2019-07-17 03:54:47] Seen 11795623 samples
[2019-07-17 03:54:47] Starting epoch 3
[2019-07-17 03:54:47] [data] Shuffling data
[2019-07-17 03:54:55] [data] Done reading 13926791 sentences
[2019-07-17 03:56:15] [data] Done shuffling 13926791 sentences to temp files
[2019-07-17 03:59:08] Ep. 3 : Up. 164000 : Sen. 125,900 : Cost 68.54756165 : Time 481.32s : 12672.48 words/s
[2019-07-17 04:05:38] Ep. 3 : Up. 166000 : Sen. 414,506 : Cost 68.38731384 : Time 390.73s : 15654.86 words/s
[2019-07-17 04:12:09] Ep. 3 : Up. 168000 : Sen. 703,736 : Cost 68.05290222 : Time 390.85s : 15626.70 words/s
[2019-07-17 04:18:39] Ep. 3 : Up. 170000 : Sen. 992,757 : Cost 68.17026520 : Time 389.46s : 15680.88 words/s
[2019-07-17 04:25:10] Ep. 3 : Up. 172000 : Sen. 1,282,792 : Cost 67.95193481 : Time 391.22s : 15659.85 words/s
[2019-07-17 04:31:41] Ep. 3 : Up. 174000 : Sen. 1,572,332 : Cost 68.20679474 : Time 390.83s : 15667.28 words/s
[2019-07-17 04:38:10] Ep. 3 : Up. 176000 : Sen. 1,862,258 : Cost 67.97861481 : Time 389.45s : 15697.07 words/s
[2019-07-17 04:44:40] Ep. 3 : Up. 178000 : Sen. 2,152,191 : Cost 67.96170807 : Time 390.15s : 15676.89 words/s
[2019-07-17 04:51:10] Ep. 3 : Up. 180000 : Sen. 2,441,418 : Cost 67.95257568 : Time 389.69s : 15669.65 words/s
[2019-07-17 04:51:10] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-17 04:51:16] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.iter180000.npz
[2019-07-17 04:51:18] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-17 04:51:24] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-17 04:51:43] [valid] Ep. 3 : Up. 180000 : cross-entropy : 54.933 : new best
[2019-07-17 04:51:50] [valid] Ep. 3 : Up. 180000 : perplexity : 8.81722 : new best
[2019-07-17 04:52:42] [valid] Ep. 3 : Up. 180000 : translation : 24.31 : new best
[2019-07-17 04:59:14] Ep. 3 : Up. 182000 : Sen. 2,729,784 : Cost 67.85166168 : Time 484.35s : 12589.10 words/s
[2019-07-17 05:05:45] Ep. 3 : Up. 184000 : Sen. 3,019,044 : Cost 67.96937561 : Time 390.15s : 15651.29 words/s
[2019-07-17 05:12:14] Ep. 3 : Up. 186000 : Sen. 3,307,458 : Cost 68.00070953 : Time 389.32s : 15659.13 words/s
[2019-07-17 05:18:44] Ep. 3 : Up. 188000 : Sen. 3,597,328 : Cost 67.73673248 : Time 390.27s : 15698.40 words/s
[2019-07-17 05:25:16] Ep. 3 : Up. 190000 : Sen. 3,887,736 : Cost 67.77292633 : Time 391.39s : 15666.33 words/s
[2019-07-17 05:31:46] Ep. 3 : Up. 192000 : Sen. 4,177,717 : Cost 67.68718719 : Time 390.86s : 15630.64 words/s
[2019-07-17 05:38:17] Ep. 3 : Up. 194000 : Sen. 4,467,332 : Cost 67.64020538 : Time 390.14s : 15668.81 words/s
[2019-07-17 05:44:48] Ep. 3 : Up. 196000 : Sen. 4,756,702 : Cost 67.98034668 : Time 391.08s : 15638.36 words/s
[2019-07-17 05:51:17] Ep. 3 : Up. 198000 : Sen. 5,045,569 : Cost 67.63326263 : Time 388.96s : 15672.92 words/s
[2019-07-17 05:57:46] Ep. 3 : Up. 200000 : Sen. 5,334,646 : Cost 67.38388062 : Time 389.08s : 15663.75 words/s
[2019-07-17 05:57:46] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-17 05:57:51] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.iter200000.npz
[2019-07-17 05:57:54] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-17 05:57:59] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-17 05:58:19] [valid] Ep. 3 : Up. 200000 : cross-entropy : 54.3685 : new best
[2019-07-17 05:58:25] [valid] Ep. 3 : Up. 200000 : perplexity : 8.6222 : new best
[2019-07-17 05:59:18] [valid] Ep. 3 : Up. 200000 : translation : 24.62 : new best
[2019-07-17 06:05:52] Ep. 3 : Up. 202000 : Sen. 5,624,436 : Cost 67.62503052 : Time 486.00s : 12603.47 words/s
[2019-07-17 06:12:23] Ep. 3 : Up. 204000 : Sen. 5,913,600 : Cost 67.71382141 : Time 391.00s : 15644.48 words/s
[2019-07-17 06:18:53] Ep. 3 : Up. 206000 : Sen. 6,202,764 : Cost 67.48477936 : Time 390.59s : 15629.06 words/s
[2019-07-17 06:25:25] Ep. 3 : Up. 208000 : Sen. 6,492,918 : Cost 67.23076630 : Time 391.56s : 15622.84 words/s
[2019-07-17 06:31:54] Ep. 3 : Up. 210000 : Sen. 6,782,366 : Cost 67.49851990 : Time 389.52s : 15690.08 words/s
[2019-07-17 06:38:26] Ep. 3 : Up. 212000 : Sen. 7,072,494 : Cost 67.62360382 : Time 391.19s : 15687.67 words/s
[2019-07-17 06:44:55] Ep. 3 : Up. 214000 : Sen. 7,361,813 : Cost 67.45211029 : Time 389.26s : 15677.97 words/s
[2019-07-17 06:51:25] Ep. 3 : Up. 216000 : Sen. 7,650,195 : Cost 67.41465759 : Time 390.04s : 15648.61 words/s
[2019-07-17 06:57:55] Ep. 3 : Up. 218000 : Sen. 7,939,865 : Cost 67.21829224 : Time 389.97s : 15658.52 words/s
[2019-07-17 07:04:25] Ep. 3 : Up. 220000 : Sen. 8,229,600 : Cost 67.19078827 : Time 390.58s : 15642.35 words/s
[2019-07-17 07:04:25] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-17 07:04:31] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.iter220000.npz
[2019-07-17 07:04:33] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-17 07:04:39] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-17 07:04:58] [valid] Ep. 3 : Up. 220000 : cross-entropy : 53.8865 : new best
[2019-07-17 07:05:05] [valid] Ep. 3 : Up. 220000 : perplexity : 8.45908 : new best
[2019-07-17 07:06:00] [valid] Ep. 3 : Up. 220000 : translation : 24.51 : stalled 1 times (last best: 24.62)
[2019-07-17 07:12:32] Ep. 3 : Up. 222000 : Sen. 8,518,664 : Cost 67.01747131 : Time 486.14s : 12552.99 words/s
[2019-07-17 07:19:02] Ep. 3 : Up. 224000 : Sen. 8,807,596 : Cost 67.06290436 : Time 389.98s : 15639.44 words/s
[2019-07-17 07:25:32] Ep. 3 : Up. 226000 : Sen. 9,096,952 : Cost 66.92073059 : Time 390.46s : 15624.83 words/s
[2019-07-17 07:32:02] Ep. 3 : Up. 228000 : Sen. 9,385,551 : Cost 67.00325012 : Time 389.77s : 15621.92 words/s
[2019-07-17 07:38:33] Ep. 3 : Up. 230000 : Sen. 9,675,382 : Cost 67.08332062 : Time 390.82s : 15676.44 words/s
[2019-07-17 07:45:03] Ep. 3 : Up. 232000 : Sen. 9,965,064 : Cost 67.16322327 : Time 390.10s : 15683.73 words/s
[2019-07-17 07:51:32] Ep. 3 : Up. 234000 : Sen. 10,254,114 : Cost 67.22993469 : Time 389.06s : 15695.16 words/s
[2019-07-17 07:58:02] Ep. 3 : Up. 236000 : Sen. 10,543,418 : Cost 67.07494354 : Time 389.82s : 15668.30 words/s
[2019-07-17 08:04:31] Ep. 3 : Up. 238000 : Sen. 10,831,865 : Cost 66.81690979 : Time 389.70s : 15637.87 words/s
[2019-07-17 08:11:01] Ep. 3 : Up. 240000 : Sen. 11,120,362 : Cost 66.89427948 : Time 389.72s : 15645.04 words/s
[2019-07-17 08:11:01] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-17 08:11:07] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.iter240000.npz
[2019-07-17 08:11:09] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-17 08:11:14] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-17 08:11:33] [valid] Ep. 3 : Up. 240000 : cross-entropy : 53.4479 : new best
[2019-07-17 08:11:39] [valid] Ep. 3 : Up. 240000 : perplexity : 8.31333 : new best
[2019-07-17 08:12:31] [valid] Ep. 3 : Up. 240000 : translation : 24.73 : new best
[2019-07-17 08:19:03] Ep. 3 : Up. 242000 : Sen. 11,408,773 : Cost 66.96690369 : Time 481.93s : 12666.79 words/s
[2019-07-17 08:25:31] Ep. 3 : Up. 244000 : Sen. 11,696,884 : Cost 66.72071075 : Time 387.82s : 15636.54 words/s
[2019-07-17 08:27:44] Seen 11795623 samples
[2019-07-17 08:27:44] Starting epoch 4
[2019-07-17 08:27:44] [data] Shuffling data
[2019-07-17 08:27:57] [data] Done reading 13926791 sentences
[2019-07-17 08:29:19] [data] Done shuffling 13926791 sentences to temp files
[2019-07-17 08:33:37] Ep. 4 : Up. 246000 : Sen. 189,451 : Cost 65.95436096 : Time 486.65s : 12495.07 words/s
[2019-07-17 08:40:08] Ep. 4 : Up. 248000 : Sen. 479,166 : Cost 66.11811829 : Time 390.75s : 15676.32 words/s
[2019-07-17 08:46:39] Ep. 4 : Up. 250000 : Sen. 768,758 : Cost 65.90254974 : Time 391.15s : 15625.83 words/s
[2019-07-17 08:53:10] Ep. 4 : Up. 252000 : Sen. 1,057,924 : Cost 65.85737610 : Time 390.45s : 15627.17 words/s
[2019-07-17 08:59:40] Ep. 4 : Up. 254000 : Sen. 1,347,649 : Cost 65.94576263 : Time 390.34s : 15672.68 words/s
[2019-07-17 09:06:11] Ep. 4 : Up. 256000 : Sen. 1,636,921 : Cost 66.07488251 : Time 390.92s : 15635.69 words/s
[2019-07-17 09:12:42] Ep. 4 : Up. 258000 : Sen. 1,926,844 : Cost 65.82958221 : Time 390.94s : 15621.62 words/s
[2019-07-17 09:19:12] Ep. 4 : Up. 260000 : Sen. 2,215,952 : Cost 66.07159424 : Time 390.26s : 15651.55 words/s
[2019-07-17 09:19:12] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-17 09:19:18] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.iter260000.npz
[2019-07-17 09:19:20] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-17 09:19:26] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-17 09:19:44] [valid] Ep. 4 : Up. 260000 : cross-entropy : 53.2163 : new best
[2019-07-17 09:19:51] [valid] Ep. 4 : Up. 260000 : perplexity : 8.23737 : new best
[2019-07-17 09:20:44] [valid] Ep. 4 : Up. 260000 : translation : 24.78 : new best
[2019-07-17 09:27:15] Ep. 4 : Up. 262000 : Sen. 2,504,024 : Cost 65.85990143 : Time 483.31s : 12589.15 words/s
[2019-07-17 09:33:45] Ep. 4 : Up. 264000 : Sen. 2,792,827 : Cost 65.82281494 : Time 389.84s : 15624.82 words/s
[2019-07-17 09:40:15] Ep. 4 : Up. 266000 : Sen. 3,081,671 : Cost 65.99613190 : Time 389.57s : 15652.09 words/s
[2019-07-17 09:46:45] Ep. 4 : Up. 268000 : Sen. 3,370,293 : Cost 66.04553986 : Time 390.40s : 15618.71 words/s
[2019-07-17 09:53:15] Ep. 4 : Up. 270000 : Sen. 3,659,468 : Cost 65.85719299 : Time 389.65s : 15660.15 words/s
[2019-07-17 09:59:47] Ep. 4 : Up. 272000 : Sen. 3,949,567 : Cost 65.90107727 : Time 391.60s : 15667.80 words/s
[2019-07-17 10:06:17] Ep. 4 : Up. 274000 : Sen. 4,238,459 : Cost 65.90380859 : Time 390.47s : 15638.82 words/s
[2019-07-17 10:12:46] Ep. 4 : Up. 276000 : Sen. 4,527,701 : Cost 65.87762451 : Time 389.37s : 15643.55 words/s
[2019-07-17 10:19:17] Ep. 4 : Up. 278000 : Sen. 4,816,130 : Cost 65.91500854 : Time 390.45s : 15604.96 words/s
[2019-07-17 10:25:48] Ep. 4 : Up. 280000 : Sen. 5,104,995 : Cost 65.80249023 : Time 390.94s : 15592.61 words/s
[2019-07-17 10:25:48] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-17 10:25:54] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.iter280000.npz
[2019-07-17 10:25:56] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-17 10:26:02] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-17 10:26:21] [valid] Ep. 4 : Up. 280000 : cross-entropy : 52.9536 : new best
[2019-07-17 10:26:27] [valid] Ep. 4 : Up. 280000 : perplexity : 8.15208 : new best
[2019-07-17 10:27:20] [valid] Ep. 4 : Up. 280000 : translation : 24.69 : stalled 1 times (last best: 24.78)
[2019-07-17 10:33:55] Ep. 4 : Up. 282000 : Sen. 5,393,760 : Cost 65.73097992 : Time 487.24s : 12512.06 words/s
[2019-07-17 10:40:28] Ep. 4 : Up. 284000 : Sen. 5,683,506 : Cost 65.87978363 : Time 392.63s : 15599.75 words/s
[2019-07-17 10:46:58] Ep. 4 : Up. 286000 : Sen. 5,972,282 : Cost 65.85406494 : Time 390.67s : 15615.22 words/s
[2019-07-17 10:53:31] Ep. 4 : Up. 288000 : Sen. 6,261,912 : Cost 65.95003510 : Time 392.36s : 15616.46 words/s
[2019-07-17 11:00:01] Ep. 4 : Up. 290000 : Sen. 6,551,232 : Cost 65.42318726 : Time 390.53s : 15593.37 words/s
[2019-07-17 11:06:33] Ep. 4 : Up. 292000 : Sen. 6,840,839 : Cost 65.68846893 : Time 391.93s : 15607.08 words/s
[2019-07-17 11:13:04] Ep. 4 : Up. 294000 : Sen. 7,129,864 : Cost 65.81777954 : Time 391.27s : 15618.23 words/s
[2019-07-17 11:19:37] Ep. 4 : Up. 296000 : Sen. 7,420,279 : Cost 65.87795258 : Time 392.61s : 15645.51 words/s
[2019-07-17 11:26:08] Ep. 4 : Up. 298000 : Sen. 7,709,827 : Cost 65.80265045 : Time 390.93s : 15652.36 words/s
[2019-07-17 11:32:39] Ep. 4 : Up. 300000 : Sen. 7,999,638 : Cost 65.68025208 : Time 391.00s : 15655.75 words/s
[2019-07-17 11:32:39] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-17 11:32:45] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.iter300000.npz
[2019-07-17 11:32:47] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-17 11:32:52] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-17 11:33:12] [valid] Ep. 4 : Up. 300000 : cross-entropy : 52.6025 : new best
[2019-07-17 11:33:18] [valid] Ep. 4 : Up. 300000 : perplexity : 8.03945 : new best
[2019-07-17 11:34:11] [valid] Ep. 4 : Up. 300000 : translation : 24.66 : stalled 2 times (last best: 24.78)
[2019-07-17 11:40:43] Ep. 4 : Up. 302000 : Sen. 8,289,240 : Cost 65.63779449 : Time 484.00s : 12601.56 words/s
[2019-07-17 11:47:14] Ep. 4 : Up. 304000 : Sen. 8,577,581 : Cost 66.07413483 : Time 390.57s : 15642.26 words/s
[2019-07-17 11:53:46] Ep. 4 : Up. 306000 : Sen. 8,867,723 : Cost 65.72610474 : Time 392.62s : 15616.74 words/s
[2019-07-17 12:00:16] Ep. 4 : Up. 308000 : Sen. 9,157,272 : Cost 65.78084564 : Time 390.19s : 15667.41 words/s
[2019-07-17 12:06:46] Ep. 4 : Up. 310000 : Sen. 9,446,825 : Cost 65.43129730 : Time 389.94s : 15647.08 words/s
[2019-07-17 12:13:17] Ep. 4 : Up. 312000 : Sen. 9,735,767 : Cost 65.67020416 : Time 390.70s : 15612.43 words/s
[2019-07-17 12:19:47] Ep. 4 : Up. 314000 : Sen. 10,024,933 : Cost 65.47827911 : Time 390.08s : 15649.08 words/s
[2019-07-17 12:26:17] Ep. 4 : Up. 316000 : Sen. 10,315,295 : Cost 65.61457825 : Time 390.46s : 15686.64 words/s
[2019-07-17 12:32:49] Ep. 4 : Up. 318000 : Sen. 10,605,636 : Cost 65.57263947 : Time 391.05s : 15658.59 words/s
[2019-07-17 12:39:18] Ep. 4 : Up. 320000 : Sen. 10,893,655 : Cost 65.45522308 : Time 389.82s : 15602.89 words/s
[2019-07-17 12:39:18] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-17 12:39:24] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.iter320000.npz
[2019-07-17 12:39:26] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-17 12:39:32] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-17 12:39:51] [valid] Ep. 4 : Up. 320000 : cross-entropy : 52.371 : new best
[2019-07-17 12:39:58] [valid] Ep. 4 : Up. 320000 : perplexity : 7.96604 : new best
[2019-07-17 12:40:51] [valid] Ep. 4 : Up. 320000 : translation : 24.4 : stalled 3 times (last best: 24.78)
[2019-07-17 12:47:24] Ep. 4 : Up. 322000 : Sen. 11,182,156 : Cost 65.87900543 : Time 485.69s : 12598.70 words/s
[2019-07-17 12:53:55] Ep. 4 : Up. 324000 : Sen. 11,472,489 : Cost 65.41954803 : Time 390.91s : 15661.02 words/s
[2019-07-17 13:00:27] Ep. 4 : Up. 326000 : Sen. 11,762,050 : Cost 65.42221069 : Time 391.64s : 15631.49 words/s
[2019-07-17 13:01:12] Seen 11795623 samples
[2019-07-17 13:01:12] Starting epoch 5
[2019-07-17 13:01:12] [data] Shuffling data
[2019-07-17 13:01:24] [data] Done reading 13926791 sentences
[2019-07-17 13:02:44] [data] Done shuffling 13926791 sentences to temp files
[2019-07-17 13:08:32] Ep. 5 : Up. 328000 : Sen. 255,408 : Cost 64.80860138 : Time 485.59s : 12579.00 words/s
[2019-07-17 13:15:03] Ep. 5 : Up. 330000 : Sen. 544,971 : Cost 64.59341431 : Time 390.68s : 15641.96 words/s
[2019-07-17 13:21:32] Ep. 5 : Up. 332000 : Sen. 833,800 : Cost 64.72366333 : Time 389.53s : 15647.76 words/s
[2019-07-17 13:28:04] Ep. 5 : Up. 334000 : Sen. 1,122,902 : Cost 64.84166718 : Time 391.25s : 15637.76 words/s
[2019-07-17 13:34:33] Ep. 5 : Up. 336000 : Sen. 1,412,077 : Cost 64.54599762 : Time 389.18s : 15640.29 words/s
[2019-07-17 13:41:03] Ep. 5 : Up. 338000 : Sen. 1,700,863 : Cost 64.73202515 : Time 390.47s : 15609.83 words/s
[2019-07-17 13:47:33] Ep. 5 : Up. 340000 : Sen. 1,989,474 : Cost 64.64717865 : Time 390.17s : 15618.86 words/s
[2019-07-17 13:47:33] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-17 13:47:39] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.iter340000.npz
[2019-07-17 13:47:42] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-17 13:47:47] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-17 13:48:06] [valid] Ep. 5 : Up. 340000 : cross-entropy : 52.2509 : new best
[2019-07-17 13:48:13] [valid] Ep. 5 : Up. 340000 : perplexity : 7.92823 : new best
[2019-07-17 13:49:05] [valid] Ep. 5 : Up. 340000 : translation : 24.7 : stalled 4 times (last best: 24.78)
[2019-07-17 13:55:39] Ep. 5 : Up. 342000 : Sen. 2,279,379 : Cost 64.70382690 : Time 485.36s : 12612.47 words/s
[2019-07-17 14:02:09] Ep. 5 : Up. 344000 : Sen. 2,567,729 : Cost 64.61400604 : Time 390.11s : 15601.98 words/s
[2019-07-17 14:08:39] Ep. 5 : Up. 346000 : Sen. 2,857,206 : Cost 64.74258423 : Time 390.15s : 15661.21 words/s
[2019-07-17 14:15:11] Ep. 5 : Up. 348000 : Sen. 3,147,486 : Cost 64.80478668 : Time 392.04s : 15639.55 words/s
[2019-07-17 14:21:41] Ep. 5 : Up. 350000 : Sen. 3,436,130 : Cost 64.81663513 : Time 390.32s : 15609.42 words/s
[2019-07-17 14:28:12] Ep. 5 : Up. 352000 : Sen. 3,725,433 : Cost 64.57341003 : Time 390.78s : 15628.03 words/s
[2019-07-17 14:34:43] Ep. 5 : Up. 354000 : Sen. 4,015,003 : Cost 64.76158142 : Time 391.11s : 15625.09 words/s
[2019-07-17 14:41:15] Ep. 5 : Up. 356000 : Sen. 4,304,691 : Cost 65.18514252 : Time 392.00s : 15639.22 words/s
[2019-07-17 14:47:46] Ep. 5 : Up. 358000 : Sen. 4,594,144 : Cost 64.99259186 : Time 390.77s : 15638.81 words/s
[2019-07-17 14:54:17] Ep. 5 : Up. 360000 : Sen. 4,884,033 : Cost 64.56321716 : Time 390.92s : 15643.46 words/s
[2019-07-17 14:54:17] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-17 14:54:23] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.iter360000.npz
[2019-07-17 14:54:25] Saving model to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-17 14:54:31] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-17 14:54:49] [valid] Ep. 5 : Up. 360000 : cross-entropy : 52.0842 : new best
[2019-07-17 14:54:55] [valid] Ep. 5 : Up. 360000 : perplexity : 7.87603 : new best
[2019-07-17 14:55:48] [valid] Ep. 5 : Up. 360000 : translation : 25.13 : new best
[2019-07-17 15:02:20] Ep. 5 : Up. 362000 : Sen. 5,173,609 : Cost 64.78977203 : Time 483.28s : 12634.55 words/s
[2019-07-17 15:08:52] Ep. 5 : Up. 364000 : Sen. 5,461,909 : Cost 65.05782318 : Time 391.45s : 15623.04 words/s
