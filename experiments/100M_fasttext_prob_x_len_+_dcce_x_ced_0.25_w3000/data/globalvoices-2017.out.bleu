MT evaluation scorer began on 2019 Jul 30 at 00:18:03
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/100M_fasttext_prob_x_len_+_dcce_x_ced_0.25_w3000/data/globalvoices-2017.de.sgm -r ../experiments/100M_fasttext_prob_x_len_+_dcce_x_ced_0.25_w3000/data/globalvoices-2017.en.sgm -t ../experiments/100M_fasttext_prob_x_len_+_dcce_x_ced_0.25_w3000/data/globalvoices-2017.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 3000 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 1.07118050023897 (67238/62770), penalty (log): 0
NIST score = 6.6458  BLEU score = 0.2452 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  5.0480   1.3453   0.2251   0.0232   0.0042   0.0009   0.0004   0.0001   0.0001  "Edinburgh"

 BLEU:  0.5460   0.3010   0.1858   0.1184   0.0769   0.0509   0.0338   0.0224   0.0147  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  5.0480   6.3933   6.6184   6.6416   6.6458   6.6467   6.6471   6.6472   6.6473  "Edinburgh"

 BLEU:  0.5460   0.4054   0.3126   0.2452   0.1945   0.1555   0.1251   0.1009   0.0814  "Edinburgh"
MT evaluation scorer ended on 2019 Jul 30 at 00:18:23
