[2019-08-07 00:54:54] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 00:54:54] [marian] Running on fulla as process 327861 with command line:
[2019-08-07 00:54:54] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz -T . --devices 7 --train-sets ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/train.bpe.de ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/train.bpe.en --vocabs ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/train.bpe.de.json ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/dev.bpe.de ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/dev.out --valid-script-path ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/train.log --valid-log ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/valid.log
[2019-08-07 00:54:54] [config] after-batches: 0
[2019-08-07 00:54:54] [config] after-epochs: 0
[2019-08-07 00:54:54] [config] allow-unk: false
[2019-08-07 00:54:54] [config] beam-size: 12
[2019-08-07 00:54:54] [config] bert-class-symbol: "[CLS]"
[2019-08-07 00:54:54] [config] bert-mask-symbol: "[MASK]"
[2019-08-07 00:54:54] [config] bert-masking-fraction: 0.15
[2019-08-07 00:54:54] [config] bert-sep-symbol: "[SEP]"
[2019-08-07 00:54:54] [config] bert-train-type-embeddings: true
[2019-08-07 00:54:54] [config] bert-type-vocab-size: 2
[2019-08-07 00:54:54] [config] best-deep: false
[2019-08-07 00:54:54] [config] clip-gemm: 0
[2019-08-07 00:54:54] [config] clip-norm: 1
[2019-08-07 00:54:54] [config] cost-type: ce-mean
[2019-08-07 00:54:54] [config] cpu-threads: 0
[2019-08-07 00:54:54] [config] data-weighting: ""
[2019-08-07 00:54:54] [config] data-weighting-type: sentence
[2019-08-07 00:54:54] [config] dec-cell: gru
[2019-08-07 00:54:54] [config] dec-cell-base-depth: 2
[2019-08-07 00:54:54] [config] dec-cell-high-depth: 1
[2019-08-07 00:54:54] [config] dec-depth: 1
[2019-08-07 00:54:54] [config] devices:
[2019-08-07 00:54:54] [config]   - 7
[2019-08-07 00:54:54] [config] dim-emb: 512
[2019-08-07 00:54:54] [config] dim-rnn: 1024
[2019-08-07 00:54:54] [config] dim-vocabs:
[2019-08-07 00:54:54] [config]   - 50000
[2019-08-07 00:54:54] [config]   - 50000
[2019-08-07 00:54:54] [config] disp-first: 0
[2019-08-07 00:54:54] [config] disp-freq: 2000
[2019-08-07 00:54:54] [config] disp-label-counts: false
[2019-08-07 00:54:54] [config] dropout-rnn: 0.2
[2019-08-07 00:54:54] [config] dropout-src: 0.1
[2019-08-07 00:54:54] [config] dropout-trg: 0.1
[2019-08-07 00:54:54] [config] dump-config: ""
[2019-08-07 00:54:54] [config] early-stopping: 5
[2019-08-07 00:54:54] [config] embedding-fix-src: false
[2019-08-07 00:54:54] [config] embedding-fix-trg: false
[2019-08-07 00:54:54] [config] embedding-normalization: false
[2019-08-07 00:54:54] [config] embedding-vectors:
[2019-08-07 00:54:54] [config]   []
[2019-08-07 00:54:54] [config] enc-cell: gru
[2019-08-07 00:54:54] [config] enc-cell-depth: 1
[2019-08-07 00:54:54] [config] enc-depth: 1
[2019-08-07 00:54:54] [config] enc-type: bidirectional
[2019-08-07 00:54:54] [config] exponential-smoothing: 0.0001
[2019-08-07 00:54:54] [config] grad-dropping-momentum: 0
[2019-08-07 00:54:54] [config] grad-dropping-rate: 0
[2019-08-07 00:54:54] [config] grad-dropping-warmup: 100
[2019-08-07 00:54:54] [config] guided-alignment: none
[2019-08-07 00:54:54] [config] guided-alignment-cost: mse
[2019-08-07 00:54:54] [config] guided-alignment-weight: 0.1
[2019-08-07 00:54:54] [config] ignore-model-config: false
[2019-08-07 00:54:54] [config] input-types:
[2019-08-07 00:54:54] [config]   []
[2019-08-07 00:54:54] [config] interpolate-env-vars: false
[2019-08-07 00:54:54] [config] keep-best: false
[2019-08-07 00:54:54] [config] label-smoothing: 0
[2019-08-07 00:54:54] [config] layer-normalization: true
[2019-08-07 00:54:54] [config] learn-rate: 0.0001
[2019-08-07 00:54:54] [config] log: ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/train.log
[2019-08-07 00:54:54] [config] log-level: info
[2019-08-07 00:54:54] [config] log-time-zone: ""
[2019-08-07 00:54:54] [config] lr-decay: 0
[2019-08-07 00:54:54] [config] lr-decay-freq: 50000
[2019-08-07 00:54:54] [config] lr-decay-inv-sqrt:
[2019-08-07 00:54:54] [config]   - 0
[2019-08-07 00:54:54] [config] lr-decay-repeat-warmup: false
[2019-08-07 00:54:54] [config] lr-decay-reset-optimizer: false
[2019-08-07 00:54:54] [config] lr-decay-start:
[2019-08-07 00:54:54] [config]   - 10
[2019-08-07 00:54:54] [config]   - 1
[2019-08-07 00:54:54] [config] lr-decay-strategy: epoch+stalled
[2019-08-07 00:54:54] [config] lr-report: false
[2019-08-07 00:54:54] [config] lr-warmup: 0
[2019-08-07 00:54:54] [config] lr-warmup-at-reload: false
[2019-08-07 00:54:54] [config] lr-warmup-cycle: false
[2019-08-07 00:54:54] [config] lr-warmup-start-rate: 0
[2019-08-07 00:54:54] [config] max-length: 50
[2019-08-07 00:54:54] [config] max-length-crop: false
[2019-08-07 00:54:54] [config] max-length-factor: 3
[2019-08-07 00:54:54] [config] maxi-batch: 100
[2019-08-07 00:54:54] [config] maxi-batch-sort: trg
[2019-08-07 00:54:54] [config] mini-batch: 64
[2019-08-07 00:54:54] [config] mini-batch-fit: true
[2019-08-07 00:54:54] [config] mini-batch-fit-step: 10
[2019-08-07 00:54:54] [config] mini-batch-overstuff: 1
[2019-08-07 00:54:54] [config] mini-batch-track-lr: false
[2019-08-07 00:54:54] [config] mini-batch-understuff: 1
[2019-08-07 00:54:54] [config] mini-batch-warmup: 0
[2019-08-07 00:54:54] [config] mini-batch-words: 0
[2019-08-07 00:54:54] [config] mini-batch-words-ref: 0
[2019-08-07 00:54:54] [config] model: ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz
[2019-08-07 00:54:54] [config] multi-loss-type: sum
[2019-08-07 00:54:54] [config] multi-node: false
[2019-08-07 00:54:54] [config] multi-node-overlap: true
[2019-08-07 00:54:54] [config] n-best: false
[2019-08-07 00:54:54] [config] no-nccl: false
[2019-08-07 00:54:54] [config] no-reload: false
[2019-08-07 00:54:54] [config] no-restore-corpus: false
[2019-08-07 00:54:54] [config] no-shuffle: false
[2019-08-07 00:54:54] [config] normalize: 1
[2019-08-07 00:54:54] [config] num-devices: 0
[2019-08-07 00:54:54] [config] optimizer: adam
[2019-08-07 00:54:54] [config] optimizer-delay: 1
[2019-08-07 00:54:54] [config] optimizer-params:
[2019-08-07 00:54:54] [config]   []
[2019-08-07 00:54:54] [config] overwrite: false
[2019-08-07 00:54:54] [config] pretrained-model: ""
[2019-08-07 00:54:54] [config] quiet: false
[2019-08-07 00:54:54] [config] quiet-translation: true
[2019-08-07 00:54:54] [config] relative-paths: false
[2019-08-07 00:54:54] [config] right-left: false
[2019-08-07 00:54:54] [config] save-freq: 20000
[2019-08-07 00:54:54] [config] seed: 1111
[2019-08-07 00:54:54] [config] shuffle-in-ram: false
[2019-08-07 00:54:54] [config] skip: false
[2019-08-07 00:54:54] [config] sqlite: ""
[2019-08-07 00:54:54] [config] sqlite-drop: false
[2019-08-07 00:54:54] [config] sync-sgd: true
[2019-08-07 00:54:54] [config] tempdir: .
[2019-08-07 00:54:54] [config] tied-embeddings: false
[2019-08-07 00:54:54] [config] tied-embeddings-all: false
[2019-08-07 00:54:54] [config] tied-embeddings-src: false
[2019-08-07 00:54:54] [config] train-sets:
[2019-08-07 00:54:54] [config]   - ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/train.bpe.de
[2019-08-07 00:54:54] [config]   - ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/train.bpe.en
[2019-08-07 00:54:54] [config] transformer-aan-activation: swish
[2019-08-07 00:54:54] [config] transformer-aan-depth: 2
[2019-08-07 00:54:54] [config] transformer-aan-nogate: false
[2019-08-07 00:54:54] [config] transformer-decoder-autoreg: self-attention
[2019-08-07 00:54:54] [config] transformer-dim-aan: 2048
[2019-08-07 00:54:54] [config] transformer-dim-ffn: 2048
[2019-08-07 00:54:54] [config] transformer-dropout: 0
[2019-08-07 00:54:54] [config] transformer-dropout-attention: 0
[2019-08-07 00:54:54] [config] transformer-dropout-ffn: 0
[2019-08-07 00:54:54] [config] transformer-ffn-activation: swish
[2019-08-07 00:54:54] [config] transformer-ffn-depth: 2
[2019-08-07 00:54:54] [config] transformer-guided-alignment-layer: last
[2019-08-07 00:54:54] [config] transformer-heads: 8
[2019-08-07 00:54:54] [config] transformer-no-projection: false
[2019-08-07 00:54:54] [config] transformer-postprocess: dan
[2019-08-07 00:54:54] [config] transformer-postprocess-emb: d
[2019-08-07 00:54:54] [config] transformer-preprocess: ""
[2019-08-07 00:54:54] [config] transformer-tied-layers:
[2019-08-07 00:54:54] [config]   []
[2019-08-07 00:54:54] [config] transformer-train-position-embeddings: false
[2019-08-07 00:54:54] [config] type: amun
[2019-08-07 00:54:54] [config] ulr: false
[2019-08-07 00:54:54] [config] ulr-dim-emb: 0
[2019-08-07 00:54:54] [config] ulr-dropout: 0
[2019-08-07 00:54:54] [config] ulr-keys-vectors: ""
[2019-08-07 00:54:54] [config] ulr-query-vectors: ""
[2019-08-07 00:54:54] [config] ulr-softmax-temperature: 1
[2019-08-07 00:54:54] [config] ulr-trainable-transformation: false
[2019-08-07 00:54:54] [config] valid-freq: 20000
[2019-08-07 00:54:54] [config] valid-log: ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/valid.log
[2019-08-07 00:54:54] [config] valid-max-length: 1000
[2019-08-07 00:54:54] [config] valid-metrics:
[2019-08-07 00:54:54] [config]   - cross-entropy
[2019-08-07 00:54:54] [config]   - perplexity
[2019-08-07 00:54:54] [config]   - translation
[2019-08-07 00:54:54] [config] valid-mini-batch: 8
[2019-08-07 00:54:54] [config] valid-script-path: ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/score-dev.sh
[2019-08-07 00:54:54] [config] valid-sets:
[2019-08-07 00:54:54] [config]   - ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/dev.bpe.de
[2019-08-07 00:54:54] [config]   - ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/dev.bpe.en
[2019-08-07 00:54:54] [config] valid-translation-output: ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/dev.out
[2019-08-07 00:54:54] [config] vocabs:
[2019-08-07 00:54:54] [config]   - ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/train.bpe.de.json
[2019-08-07 00:54:54] [config]   - ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/train.bpe.en.json
[2019-08-07 00:54:54] [config] word-penalty: 0
[2019-08-07 00:54:54] [config] workspace: 3000
[2019-08-07 00:54:54] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 00:54:54] Using synchronous training
[2019-08-07 00:54:54] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/train.bpe.de.json
[2019-08-07 00:54:55] [data] Using unused word id eos for 0
[2019-08-07 00:54:55] [data] Using unused word id UNK for 1
[2019-08-07 00:54:55] [data] Setting vocabulary size for input 0 to 50000
[2019-08-07 00:54:55] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/train.bpe.en.json
[2019-08-07 00:54:55] [data] Using unused word id eos for 0
[2019-08-07 00:54:55] [data] Using unused word id UNK for 1
[2019-08-07 00:54:55] [data] Setting vocabulary size for input 1 to 50000
[2019-08-07 00:54:55] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-07 00:54:55] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-07 00:54:56] [memory] Extending reserved space to 3072 MB (device gpu7)
[2019-08-07 00:54:56] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 00:54:56] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 00:54:56] [training] Using 1 GPUs
[2019-08-07 00:54:56] [memory] Reserving 422 MB, device gpu7
[2019-08-07 00:54:56] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-07 00:54:57] [memory] Reserving 422 MB, device gpu7
[2019-08-07 00:54:59] [batching] Done. Typical MB size is 4042 target words
[2019-08-07 00:54:59] [memory] Extending reserved space to 3072 MB (device gpu7)
[2019-08-07 00:54:59] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 00:54:59] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 00:54:59] [training] Using 1 GPUs
[2019-08-07 00:54:59] Training started
[2019-08-07 00:54:59] [data] Shuffling data
[2019-08-07 00:55:02] [data] Done reading 4250865 sentences
[2019-08-07 00:55:24] [data] Done shuffling 4250865 sentences to temp files
[2019-08-07 00:55:33] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-07 00:55:33] [memory] Reserving 422 MB, device gpu7
[2019-08-07 00:55:33] [memory] Reserving 422 MB, device gpu7
[2019-08-07 00:55:33] [memory] Reserving 422 MB, device gpu7
[2019-08-07 00:55:33] [memory] Reserving 844 MB, device gpu7
[2019-08-07 01:01:11] Ep. 1 : Up. 2000 : Sen. 203,142 : Cost 153.19602966 : Time 376.07s : 13182.86 words/s
[2019-08-07 01:06:53] Ep. 1 : Up. 4000 : Sen. 406,675 : Cost 127.10836029 : Time 341.66s : 14583.50 words/s
[2019-08-07 01:12:32] Ep. 1 : Up. 6000 : Sen. 609,342 : Cost 111.76332855 : Time 339.42s : 14581.76 words/s
[2019-08-07 01:18:12] Ep. 1 : Up. 8000 : Sen. 811,700 : Cost 101.67066193 : Time 340.41s : 14541.65 words/s
[2019-08-07 01:23:53] Ep. 1 : Up. 10000 : Sen. 1,013,905 : Cost 94.86280823 : Time 340.09s : 14577.33 words/s
[2019-08-07 01:29:33] Ep. 1 : Up. 12000 : Sen. 1,217,367 : Cost 89.26624298 : Time 340.35s : 14604.64 words/s
[2019-08-07 01:35:12] Ep. 1 : Up. 14000 : Sen. 1,420,251 : Cost 85.52413940 : Time 339.36s : 14590.38 words/s
[2019-08-07 01:40:51] Ep. 1 : Up. 16000 : Sen. 1,622,252 : Cost 82.25805664 : Time 339.16s : 14564.64 words/s
[2019-08-07 01:46:32] Ep. 1 : Up. 18000 : Sen. 1,824,775 : Cost 80.29222870 : Time 340.62s : 14556.86 words/s
[2019-08-07 01:52:13] Ep. 1 : Up. 20000 : Sen. 2,027,996 : Cost 77.97856140 : Time 341.24s : 14554.60 words/s
[2019-08-07 01:52:13] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz.orig.npz
[2019-08-07 01:52:23] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.iter20000.npz
[2019-08-07 01:52:32] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz
[2019-08-07 01:52:41] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz.optimizer.npz
[2019-08-07 01:53:08] [valid] Ep. 1 : Up. 20000 : cross-entropy : 65.4172 : new best
[2019-08-07 01:53:15] [valid] Ep. 1 : Up. 20000 : perplexity : 13.2453 : new best
[2019-08-07 01:54:31] [valid] Ep. 1 : Up. 20000 : translation : 16.11 : new best
[2019-08-07 02:00:14] Ep. 1 : Up. 22000 : Sen. 2,230,619 : Cost 76.23147583 : Time 480.47s : 10312.99 words/s
[2019-08-07 02:05:56] Ep. 1 : Up. 24000 : Sen. 2,434,205 : Cost 75.11894226 : Time 341.92s : 14586.41 words/s
[2019-08-07 02:11:37] Ep. 1 : Up. 26000 : Sen. 2,637,384 : Cost 73.81305695 : Time 341.08s : 14555.29 words/s
[2019-08-07 02:17:17] Ep. 1 : Up. 28000 : Sen. 2,840,487 : Cost 72.47507477 : Time 340.36s : 14563.69 words/s
[2019-08-07 02:22:56] Ep. 1 : Up. 30000 : Sen. 3,042,293 : Cost 71.78336334 : Time 338.85s : 14553.77 words/s
[2019-08-07 02:28:37] Ep. 1 : Up. 32000 : Sen. 3,245,398 : Cost 70.72043610 : Time 340.57s : 14583.04 words/s
[2019-08-07 02:34:18] Ep. 1 : Up. 34000 : Sen. 3,448,470 : Cost 70.12306976 : Time 341.33s : 14573.44 words/s
[2019-08-07 02:34:23] Seen 3451500 samples
[2019-08-07 02:34:23] Starting epoch 2
[2019-08-07 02:34:23] [data] Shuffling data
[2019-08-07 02:34:26] [data] Done reading 4250865 sentences
[2019-08-07 02:34:49] [data] Done shuffling 4250865 sentences to temp files
[2019-08-07 02:40:33] Ep. 2 : Up. 36000 : Sen. 199,856 : Cost 68.20507812 : Time 375.37s : 13205.43 words/s
[2019-08-07 02:46:14] Ep. 2 : Up. 38000 : Sen. 402,707 : Cost 67.43098450 : Time 340.86s : 14527.63 words/s
[2019-08-07 02:51:55] Ep. 2 : Up. 40000 : Sen. 605,187 : Cost 66.99605560 : Time 340.58s : 14538.53 words/s
[2019-08-07 02:51:55] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz.orig.npz
[2019-08-07 02:52:05] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.iter40000.npz
[2019-08-07 02:52:12] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz
[2019-08-07 02:52:23] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz.optimizer.npz
[2019-08-07 02:52:50] [valid] Ep. 2 : Up. 40000 : cross-entropy : 53.4264 : new best
[2019-08-07 02:52:57] [valid] Ep. 2 : Up. 40000 : perplexity : 8.24878 : new best
[2019-08-07 02:54:04] [valid] Ep. 2 : Up. 40000 : translation : 21.94 : new best
[2019-08-07 02:59:46] Ep. 2 : Up. 42000 : Sen. 808,199 : Cost 66.54272461 : Time 471.76s : 10515.82 words/s
[2019-08-07 03:05:26] Ep. 2 : Up. 44000 : Sen. 1,010,689 : Cost 66.08808136 : Time 339.66s : 14560.58 words/s
[2019-08-07 03:11:09] Ep. 2 : Up. 46000 : Sen. 1,214,534 : Cost 65.69067383 : Time 342.63s : 14583.09 words/s
[2019-08-07 03:16:49] Ep. 2 : Up. 48000 : Sen. 1,416,339 : Cost 65.23384857 : Time 340.08s : 14526.56 words/s
[2019-08-07 03:22:29] Ep. 2 : Up. 50000 : Sen. 1,618,542 : Cost 64.90132141 : Time 339.78s : 14557.80 words/s
[2019-08-07 03:28:09] Ep. 2 : Up. 52000 : Sen. 1,821,348 : Cost 64.36137390 : Time 340.53s : 14545.28 words/s
[2019-08-07 03:33:50] Ep. 2 : Up. 54000 : Sen. 2,023,408 : Cost 64.17870331 : Time 340.81s : 14515.89 words/s
[2019-08-07 03:39:31] Ep. 2 : Up. 56000 : Sen. 2,226,448 : Cost 63.76787949 : Time 341.13s : 14559.47 words/s
[2019-08-07 03:45:13] Ep. 2 : Up. 58000 : Sen. 2,430,135 : Cost 63.38939285 : Time 341.47s : 14590.98 words/s
[2019-08-07 03:50:53] Ep. 2 : Up. 60000 : Sen. 2,632,810 : Cost 62.82960892 : Time 340.29s : 14556.20 words/s
[2019-08-07 03:50:53] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz.orig.npz
[2019-08-07 03:51:03] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.iter60000.npz
[2019-08-07 03:51:10] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz
[2019-08-07 03:51:20] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz.optimizer.npz
[2019-08-07 03:51:49] [valid] Ep. 2 : Up. 60000 : cross-entropy : 48.643 : new best
[2019-08-07 03:51:56] [valid] Ep. 2 : Up. 60000 : perplexity : 6.82879 : new best
[2019-08-07 03:53:01] [valid] Ep. 2 : Up. 60000 : translation : 24 : new best
[2019-08-07 03:58:45] Ep. 2 : Up. 62000 : Sen. 2,836,444 : Cost 62.83977127 : Time 471.85s : 10550.71 words/s
[2019-08-07 04:04:25] Ep. 2 : Up. 64000 : Sen. 3,039,766 : Cost 62.49742889 : Time 339.82s : 14589.09 words/s
[2019-08-07 04:10:06] Ep. 2 : Up. 66000 : Sen. 3,242,809 : Cost 62.34679413 : Time 341.48s : 14539.91 words/s
[2019-08-07 04:15:47] Ep. 2 : Up. 68000 : Sen. 3,445,063 : Cost 61.98701477 : Time 340.83s : 14525.43 words/s
[2019-08-07 04:15:58] Seen 3451500 samples
[2019-08-07 04:15:58] Starting epoch 3
[2019-08-07 04:15:58] [data] Shuffling data
[2019-08-07 04:16:01] [data] Done reading 4250865 sentences
[2019-08-07 04:16:23] [data] Done shuffling 4250865 sentences to temp files
[2019-08-07 04:22:01] Ep. 3 : Up. 70000 : Sen. 196,236 : Cost 60.60193634 : Time 373.64s : 13265.75 words/s
[2019-08-07 04:27:42] Ep. 3 : Up. 72000 : Sen. 399,635 : Cost 60.26211548 : Time 341.73s : 14522.80 words/s
[2019-08-07 04:33:23] Ep. 3 : Up. 74000 : Sen. 602,060 : Cost 60.01580429 : Time 340.24s : 14513.49 words/s
[2019-08-07 04:39:04] Ep. 3 : Up. 76000 : Sen. 805,018 : Cost 60.27882004 : Time 341.18s : 14559.96 words/s
[2019-08-07 04:44:44] Ep. 3 : Up. 78000 : Sen. 1,007,531 : Cost 60.03525162 : Time 340.73s : 14560.06 words/s
[2019-08-07 04:50:25] Ep. 3 : Up. 80000 : Sen. 1,210,663 : Cost 59.96863937 : Time 340.60s : 14582.86 words/s
[2019-08-07 04:50:25] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz.orig.npz
[2019-08-07 04:50:35] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.iter80000.npz
[2019-08-07 04:50:42] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz
[2019-08-07 04:50:53] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz.optimizer.npz
[2019-08-07 04:51:20] [valid] Ep. 3 : Up. 80000 : cross-entropy : 46.0278 : new best
[2019-08-07 04:51:26] [valid] Ep. 3 : Up. 80000 : perplexity : 6.15867 : new best
[2019-08-07 04:52:31] [valid] Ep. 3 : Up. 80000 : translation : 25.06 : new best
[2019-08-07 04:58:14] Ep. 3 : Up. 82000 : Sen. 1,413,226 : Cost 59.65440750 : Time 468.86s : 10568.34 words/s
[2019-08-07 05:03:54] Ep. 3 : Up. 84000 : Sen. 1,616,161 : Cost 59.29956436 : Time 340.26s : 14556.64 words/s
[2019-08-07 05:09:35] Ep. 3 : Up. 86000 : Sen. 1,818,873 : Cost 59.41077805 : Time 340.73s : 14511.13 words/s
[2019-08-07 05:15:16] Ep. 3 : Up. 88000 : Sen. 2,022,180 : Cost 59.36939240 : Time 341.45s : 14584.11 words/s
[2019-08-07 05:20:57] Ep. 3 : Up. 90000 : Sen. 2,225,521 : Cost 59.08956909 : Time 341.15s : 14570.42 words/s
[2019-08-07 05:26:39] Ep. 3 : Up. 92000 : Sen. 2,428,503 : Cost 59.07371902 : Time 341.12s : 14557.06 words/s
[2019-08-07 05:32:21] Ep. 3 : Up. 94000 : Sen. 2,632,182 : Cost 58.87698746 : Time 341.93s : 14572.59 words/s
[2019-08-07 05:38:01] Ep. 3 : Up. 96000 : Sen. 2,835,200 : Cost 58.59829330 : Time 340.93s : 14555.35 words/s
[2019-08-07 05:43:40] Ep. 3 : Up. 98000 : Sen. 3,036,077 : Cost 58.94901276 : Time 339.02s : 14524.91 words/s
[2019-08-07 05:49:21] Ep. 3 : Up. 100000 : Sen. 3,238,930 : Cost 58.40647507 : Time 340.22s : 14556.26 words/s
[2019-08-07 05:49:21] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz.orig.npz
[2019-08-07 05:49:31] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.iter100000.npz
[2019-08-07 05:49:39] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz
[2019-08-07 05:49:49] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz.optimizer.npz
[2019-08-07 05:50:16] [valid] Ep. 3 : Up. 100000 : cross-entropy : 44.3024 : new best
[2019-08-07 05:50:22] [valid] Ep. 3 : Up. 100000 : perplexity : 5.75297 : new best
[2019-08-07 05:51:26] [valid] Ep. 3 : Up. 100000 : translation : 26.01 : new best
[2019-08-07 05:57:08] Ep. 3 : Up. 102000 : Sen. 3,441,478 : Cost 58.58507919 : Time 467.09s : 10614.16 words/s
[2019-08-07 05:57:25] Seen 3451500 samples
[2019-08-07 05:57:25] Starting epoch 4
[2019-08-07 05:57:25] [data] Shuffling data
[2019-08-07 05:57:29] [data] Done reading 4250865 sentences
[2019-08-07 05:57:44] [data] Done shuffling 4250865 sentences to temp files
[2019-08-07 06:03:23] Ep. 4 : Up. 104000 : Sen. 192,213 : Cost 57.06501770 : Time 375.15s : 13209.83 words/s
[2019-08-07 06:09:03] Ep. 4 : Up. 106000 : Sen. 395,521 : Cost 56.89968872 : Time 339.89s : 14617.25 words/s
[2019-08-07 06:14:42] Ep. 4 : Up. 108000 : Sen. 597,866 : Cost 56.76397324 : Time 339.41s : 14571.79 words/s
[2019-08-07 06:20:22] Ep. 4 : Up. 110000 : Sen. 800,213 : Cost 56.72840118 : Time 339.87s : 14557.82 words/s
[2019-08-07 06:26:04] Ep. 4 : Up. 112000 : Sen. 1,004,047 : Cost 56.70491791 : Time 341.45s : 14582.76 words/s
[2019-08-07 06:31:44] Ep. 4 : Up. 114000 : Sen. 1,206,078 : Cost 57.11233521 : Time 340.77s : 14517.69 words/s
[2019-08-07 06:37:25] Ep. 4 : Up. 116000 : Sen. 1,408,542 : Cost 56.88624954 : Time 340.74s : 14542.57 words/s
[2019-08-07 06:43:06] Ep. 4 : Up. 118000 : Sen. 1,611,333 : Cost 56.62990952 : Time 340.50s : 14549.74 words/s
[2019-08-07 06:48:47] Ep. 4 : Up. 120000 : Sen. 1,815,103 : Cost 56.57251740 : Time 341.27s : 14593.28 words/s
[2019-08-07 06:48:47] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz.orig.npz
[2019-08-07 06:48:57] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.iter120000.npz
[2019-08-07 06:49:08] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz
[2019-08-07 06:49:23] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz.optimizer.npz
[2019-08-07 06:49:53] [valid] Ep. 4 : Up. 120000 : cross-entropy : 43.1182 : new best
[2019-08-07 06:50:00] [valid] Ep. 4 : Up. 120000 : perplexity : 5.49009 : new best
[2019-08-07 06:51:03] [valid] Ep. 4 : Up. 120000 : translation : 26.83 : new best
[2019-08-07 06:56:46] Ep. 4 : Up. 122000 : Sen. 2,017,527 : Cost 56.85289383 : Time 478.64s : 10357.04 words/s
[2019-08-07 07:02:24] Ep. 4 : Up. 124000 : Sen. 2,220,165 : Cost 56.33866882 : Time 338.89s : 14584.64 words/s
[2019-08-07 07:08:05] Ep. 4 : Up. 126000 : Sen. 2,423,039 : Cost 56.61839294 : Time 340.82s : 14570.38 words/s
[2019-08-07 07:13:45] Ep. 4 : Up. 128000 : Sen. 2,625,512 : Cost 56.50350571 : Time 340.23s : 14545.49 words/s
[2019-08-07 07:19:26] Ep. 4 : Up. 130000 : Sen. 2,828,372 : Cost 56.32307434 : Time 340.47s : 14567.74 words/s
[2019-08-07 07:25:05] Ep. 4 : Up. 132000 : Sen. 3,030,702 : Cost 56.45686340 : Time 339.44s : 14588.52 words/s
[2019-08-07 07:30:44] Ep. 4 : Up. 134000 : Sen. 3,232,428 : Cost 56.22069168 : Time 339.05s : 14545.50 words/s
[2019-08-07 07:36:24] Ep. 4 : Up. 136000 : Sen. 3,435,861 : Cost 55.94314575 : Time 339.82s : 14599.04 words/s
[2019-08-07 07:36:51] Seen 3451500 samples
[2019-08-07 07:36:51] Starting epoch 5
[2019-08-07 07:36:51] [data] Shuffling data
[2019-08-07 07:36:58] [data] Done reading 4250865 sentences
[2019-08-07 07:37:15] [data] Done shuffling 4250865 sentences to temp files
[2019-08-07 07:42:37] Ep. 5 : Up. 138000 : Sen. 187,188 : Cost 54.68291092 : Time 373.27s : 13296.24 words/s
[2019-08-07 07:48:17] Ep. 5 : Up. 140000 : Sen. 389,284 : Cost 54.64715195 : Time 339.57s : 14542.98 words/s
[2019-08-07 07:48:17] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz.orig.npz
[2019-08-07 07:48:27] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.iter140000.npz
[2019-08-07 07:48:34] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz
[2019-08-07 07:48:44] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz.optimizer.npz
[2019-08-07 07:49:11] [valid] Ep. 5 : Up. 140000 : cross-entropy : 42.1173 : new best
[2019-08-07 07:49:18] [valid] Ep. 5 : Up. 140000 : perplexity : 5.27729 : new best
[2019-08-07 07:50:20] [valid] Ep. 5 : Up. 140000 : translation : 26.95 : new best
[2019-08-07 07:56:02] Ep. 5 : Up. 142000 : Sen. 591,879 : Cost 54.86898041 : Time 465.03s : 10637.57 words/s
[2019-08-07 08:01:43] Ep. 5 : Up. 144000 : Sen. 794,162 : Cost 55.08865738 : Time 340.45s : 14578.76 words/s
[2019-08-07 08:07:23] Ep. 5 : Up. 146000 : Sen. 996,645 : Cost 55.11610413 : Time 340.17s : 14571.53 words/s
[2019-08-07 08:13:03] Ep. 5 : Up. 148000 : Sen. 1,199,694 : Cost 54.86210251 : Time 339.90s : 14598.92 words/s
[2019-08-07 08:18:44] Ep. 5 : Up. 150000 : Sen. 1,402,958 : Cost 54.79405975 : Time 340.95s : 14583.59 words/s
[2019-08-07 08:24:24] Ep. 5 : Up. 152000 : Sen. 1,605,585 : Cost 54.91408539 : Time 340.46s : 14553.02 words/s
[2019-08-07 08:30:04] Ep. 5 : Up. 154000 : Sen. 1,808,880 : Cost 54.79516602 : Time 340.08s : 14583.18 words/s
[2019-08-07 08:35:44] Ep. 5 : Up. 156000 : Sen. 2,010,779 : Cost 54.82011795 : Time 340.26s : 14539.33 words/s
[2019-08-07 08:41:24] Ep. 5 : Up. 158000 : Sen. 2,213,396 : Cost 54.70399857 : Time 339.37s : 14573.48 words/s
[2019-08-07 08:47:04] Ep. 5 : Up. 160000 : Sen. 2,416,360 : Cost 54.82076645 : Time 340.34s : 14576.93 words/s
[2019-08-07 08:47:04] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz.orig.npz
[2019-08-07 08:47:17] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.iter160000.npz
[2019-08-07 08:47:25] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz
[2019-08-07 08:47:41] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz.optimizer.npz
[2019-08-07 08:48:07] [valid] Ep. 5 : Up. 160000 : cross-entropy : 41.5023 : new best
[2019-08-07 08:48:14] [valid] Ep. 5 : Up. 160000 : perplexity : 5.15066 : new best
[2019-08-07 08:49:16] [valid] Ep. 5 : Up. 160000 : translation : 27.42 : new best
[2019-08-07 08:54:57] Ep. 5 : Up. 162000 : Sen. 2,618,813 : Cost 54.90242004 : Time 472.72s : 10488.77 words/s
[2019-08-07 09:00:36] Ep. 5 : Up. 164000 : Sen. 2,820,852 : Cost 54.67799759 : Time 339.17s : 14569.18 words/s
[2019-08-07 09:06:16] Ep. 5 : Up. 166000 : Sen. 3,024,073 : Cost 54.80440140 : Time 340.22s : 14595.37 words/s
[2019-08-07 09:11:58] Ep. 5 : Up. 168000 : Sen. 3,226,764 : Cost 54.64264679 : Time 341.40s : 14517.78 words/s
[2019-08-07 09:17:39] Ep. 5 : Up. 170000 : Sen. 3,430,064 : Cost 54.55416489 : Time 340.94s : 14569.13 words/s
[2019-08-07 09:18:15] Seen 3451500 samples
[2019-08-07 09:18:15] Starting epoch 6
[2019-08-07 09:18:15] [data] Shuffling data
[2019-08-07 09:18:18] [data] Done reading 4250865 sentences
[2019-08-07 09:18:36] [data] Done shuffling 4250865 sentences to temp files
[2019-08-07 09:24:05] Ep. 6 : Up. 172000 : Sen. 181,824 : Cost 53.36638260 : Time 386.02s : 12849.22 words/s
[2019-08-07 09:29:45] Ep. 6 : Up. 174000 : Sen. 384,338 : Cost 53.20329285 : Time 340.68s : 14537.55 words/s
[2019-08-07 09:35:27] Ep. 6 : Up. 176000 : Sen. 587,406 : Cost 53.38162613 : Time 341.78s : 14540.94 words/s
[2019-08-07 09:41:07] Ep. 6 : Up. 178000 : Sen. 789,445 : Cost 53.36108398 : Time 339.91s : 14493.05 words/s
[2019-08-07 09:46:49] Ep. 6 : Up. 180000 : Sen. 992,000 : Cost 53.54918289 : Time 341.91s : 14494.37 words/s
[2019-08-07 09:46:49] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz.orig.npz
[2019-08-07 09:46:59] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.iter180000.npz
[2019-08-07 09:47:06] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz
[2019-08-07 09:47:17] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz.optimizer.npz
[2019-08-07 09:47:44] [valid] Ep. 6 : Up. 180000 : cross-entropy : 40.9665 : new best
[2019-08-07 09:47:50] [valid] Ep. 6 : Up. 180000 : perplexity : 5.04281 : new best
[2019-08-07 09:48:54] [valid] Ep. 6 : Up. 180000 : translation : 27.37 : stalled 1 times (last best: 27.42)
[2019-08-07 09:54:37] Ep. 6 : Up. 182000 : Sen. 1,194,656 : Cost 53.18445206 : Time 468.21s : 10577.10 words/s
[2019-08-07 10:00:19] Ep. 6 : Up. 184000 : Sen. 1,396,702 : Cost 53.48784256 : Time 341.52s : 14501.91 words/s
[2019-08-07 10:06:00] Ep. 6 : Up. 186000 : Sen. 1,599,179 : Cost 53.55826187 : Time 341.44s : 14517.38 words/s
[2019-08-07 10:11:42] Ep. 6 : Up. 188000 : Sen. 1,802,281 : Cost 53.26752090 : Time 341.60s : 14506.29 words/s
[2019-08-07 10:17:24] Ep. 6 : Up. 190000 : Sen. 2,005,364 : Cost 53.58912277 : Time 342.62s : 14536.36 words/s
[2019-08-07 10:23:08] Ep. 6 : Up. 192000 : Sen. 2,208,389 : Cost 53.41540527 : Time 343.55s : 14451.64 words/s
[2019-08-07 10:28:52] Ep. 6 : Up. 194000 : Sen. 2,410,795 : Cost 53.62118530 : Time 343.82s : 14429.46 words/s
[2019-08-07 10:34:35] Ep. 6 : Up. 196000 : Sen. 2,613,532 : Cost 53.32060623 : Time 343.12s : 14407.59 words/s
[2019-08-07 10:40:19] Ep. 6 : Up. 198000 : Sen. 2,816,135 : Cost 53.52997589 : Time 343.85s : 14407.28 words/s
[2019-08-07 10:46:03] Ep. 6 : Up. 200000 : Sen. 3,018,916 : Cost 53.37899017 : Time 343.97s : 14390.64 words/s
[2019-08-07 10:46:03] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz.orig.npz
[2019-08-07 10:46:13] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.iter200000.npz
[2019-08-07 10:46:21] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz
[2019-08-07 10:46:32] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz.optimizer.npz
[2019-08-07 10:46:58] [valid] Ep. 6 : Up. 200000 : cross-entropy : 40.5661 : new best
[2019-08-07 10:47:05] [valid] Ep. 6 : Up. 200000 : perplexity : 4.9637 : new best
[2019-08-07 10:48:08] [valid] Ep. 6 : Up. 200000 : translation : 27.37 : stalled 2 times (last best: 27.42)
[2019-08-07 10:53:56] Ep. 6 : Up. 202000 : Sen. 3,222,770 : Cost 53.40809250 : Time 473.11s : 10526.03 words/s
[2019-08-07 10:59:41] Ep. 6 : Up. 204000 : Sen. 3,425,904 : Cost 53.33307648 : Time 345.26s : 14398.75 words/s
[2019-08-07 11:00:25] Seen 3451500 samples
[2019-08-07 11:00:25] Starting epoch 7
[2019-08-07 11:00:25] [data] Shuffling data
[2019-08-07 11:00:28] [data] Done reading 4250865 sentences
[2019-08-07 11:00:49] [data] Done shuffling 4250865 sentences to temp files
[2019-08-07 11:05:58] Ep. 7 : Up. 206000 : Sen. 175,215 : Cost 52.37588501 : Time 376.73s : 13082.04 words/s
[2019-08-07 11:11:43] Ep. 7 : Up. 208000 : Sen. 377,800 : Cost 52.00087357 : Time 345.52s : 14346.96 words/s
[2019-08-07 11:17:27] Ep. 7 : Up. 210000 : Sen. 580,574 : Cost 52.10890961 : Time 343.78s : 14392.37 words/s
[2019-08-07 11:23:10] Ep. 7 : Up. 212000 : Sen. 782,490 : Cost 52.37532425 : Time 343.50s : 14392.59 words/s
[2019-08-07 11:28:53] Ep. 7 : Up. 214000 : Sen. 985,059 : Cost 52.39567184 : Time 343.02s : 14423.85 words/s
[2019-08-07 11:34:38] Ep. 7 : Up. 216000 : Sen. 1,187,886 : Cost 52.40101242 : Time 344.66s : 14409.39 words/s
[2019-08-07 11:40:23] Ep. 7 : Up. 218000 : Sen. 1,390,843 : Cost 52.33998489 : Time 345.09s : 14385.27 words/s
[2019-08-07 11:46:08] Ep. 7 : Up. 220000 : Sen. 1,594,308 : Cost 52.31823730 : Time 344.90s : 14406.62 words/s
[2019-08-07 11:46:08] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz.orig.npz
[2019-08-07 11:46:18] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.iter220000.npz
[2019-08-07 11:46:26] Saving model to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz
[2019-08-07 11:46:39] Saving Adam parameters to ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz.optimizer.npz
[2019-08-07 11:47:07] [valid] Ep. 7 : Up. 220000 : cross-entropy : 40.3091 : new best
[2019-08-07 11:47:14] [valid] Ep. 7 : Up. 220000 : perplexity : 4.91357 : new best
[2019-08-07 11:48:17] [valid] Ep. 7 : Up. 220000 : translation : 27.49 : new best
[2019-08-07 11:54:02] Ep. 7 : Up. 222000 : Sen. 1,796,991 : Cost 52.47414398 : Time 473.65s : 10459.25 words/s
[2019-08-07 11:59:45] Ep. 7 : Up. 224000 : Sen. 1,999,455 : Cost 52.75524902 : Time 343.43s : 14439.36 words/s
[2019-08-07 12:05:28] Ep. 7 : Up. 226000 : Sen. 2,202,222 : Cost 52.42006302 : Time 342.37s : 14462.57 words/s
[2019-08-07 15:40:52] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 15:40:52] [marian] Running on fulla as process 5263 with command line:
[2019-08-07 15:40:52] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz -T . --devices 7 --train-sets ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/train.bpe.de ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/train.bpe.en --vocabs ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/train.bpe.de.json ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/dev.bpe.de ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/dev.out --valid-script-path ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/train.log --valid-log ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/valid.log
[2019-08-07 15:40:53] [config] after-batches: 0
[2019-08-07 15:40:53] [config] after-epochs: 0
[2019-08-07 15:40:53] [config] allow-unk: false
[2019-08-07 15:40:53] [config] beam-size: 12
[2019-08-07 15:40:53] [config] bert-class-symbol: "[CLS]"
[2019-08-07 15:40:53] [config] bert-mask-symbol: "[MASK]"
[2019-08-07 15:40:53] [config] bert-masking-fraction: 0.15
[2019-08-07 15:40:53] [config] bert-sep-symbol: "[SEP]"
[2019-08-07 15:40:53] [config] bert-train-type-embeddings: true
[2019-08-07 15:40:53] [config] bert-type-vocab-size: 2
[2019-08-07 15:40:53] [config] best-deep: false
[2019-08-07 15:40:53] [config] clip-gemm: 0
[2019-08-07 15:40:53] [config] clip-norm: 1
[2019-08-07 15:40:53] [config] cost-type: ce-mean
[2019-08-07 15:40:53] [config] cpu-threads: 0
[2019-08-07 15:40:53] [config] data-weighting: ""
[2019-08-07 15:40:53] [config] data-weighting-type: sentence
[2019-08-07 15:40:53] [config] dec-cell: gru
[2019-08-07 15:40:53] [config] dec-cell-base-depth: 2
[2019-08-07 15:40:53] [config] dec-cell-high-depth: 1
[2019-08-07 15:40:53] [config] dec-depth: 1
[2019-08-07 15:40:53] [config] devices:
[2019-08-07 15:40:53] [config]   - 7
[2019-08-07 15:40:53] [config] dim-emb: 512
[2019-08-07 15:40:53] [config] dim-rnn: 1024
[2019-08-07 15:40:53] [config] dim-vocabs:
[2019-08-07 15:40:53] [config]   - 50000
[2019-08-07 15:40:53] [config]   - 50000
[2019-08-07 15:40:53] [config] disp-first: 0
[2019-08-07 15:40:53] [config] disp-freq: 2000
[2019-08-07 15:40:53] [config] disp-label-counts: false
[2019-08-07 15:40:53] [config] dropout-rnn: 0.2
[2019-08-07 15:40:53] [config] dropout-src: 0.1
[2019-08-07 15:40:53] [config] dropout-trg: 0.1
[2019-08-07 15:40:53] [config] dump-config: ""
[2019-08-07 15:40:53] [config] early-stopping: 5
[2019-08-07 15:40:53] [config] embedding-fix-src: false
[2019-08-07 15:40:53] [config] embedding-fix-trg: false
[2019-08-07 15:40:53] [config] embedding-normalization: false
[2019-08-07 15:40:53] [config] embedding-vectors:
[2019-08-07 15:40:53] [config]   []
[2019-08-07 15:40:53] [config] enc-cell: gru
[2019-08-07 15:40:53] [config] enc-cell-depth: 1
[2019-08-07 15:40:53] [config] enc-depth: 1
[2019-08-07 15:40:53] [config] enc-type: bidirectional
[2019-08-07 15:40:53] [config] exponential-smoothing: 0.0001
[2019-08-07 15:40:53] [config] grad-dropping-momentum: 0
[2019-08-07 15:40:53] [config] grad-dropping-rate: 0
[2019-08-07 15:40:53] [config] grad-dropping-warmup: 100
[2019-08-07 15:40:53] [config] guided-alignment: none
[2019-08-07 15:40:53] [config] guided-alignment-cost: mse
[2019-08-07 15:40:53] [config] guided-alignment-weight: 0.1
[2019-08-07 15:40:53] [config] ignore-model-config: false
[2019-08-07 15:40:53] [config] input-types:
[2019-08-07 15:40:53] [config]   []
[2019-08-07 15:40:53] [config] interpolate-env-vars: false
[2019-08-07 15:40:53] [config] keep-best: false
[2019-08-07 15:40:53] [config] label-smoothing: 0
[2019-08-07 15:40:53] [config] layer-normalization: true
[2019-08-07 15:40:53] [config] learn-rate: 0.0001
[2019-08-07 15:40:53] [config] log: ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/train.log
[2019-08-07 15:40:53] [config] log-level: info
[2019-08-07 15:40:53] [config] log-time-zone: ""
[2019-08-07 15:40:53] [config] lr-decay: 0
[2019-08-07 15:40:53] [config] lr-decay-freq: 50000
[2019-08-07 15:40:53] [config] lr-decay-inv-sqrt:
[2019-08-07 15:40:53] [config]   - 0
[2019-08-07 15:40:53] [config] lr-decay-repeat-warmup: false
[2019-08-07 15:40:53] [config] lr-decay-reset-optimizer: false
[2019-08-07 15:40:53] [config] lr-decay-start:
[2019-08-07 15:40:53] [config]   - 10
[2019-08-07 15:40:53] [config]   - 1
[2019-08-07 15:40:53] [config] lr-decay-strategy: epoch+stalled
[2019-08-07 15:40:53] [config] lr-report: false
[2019-08-07 15:40:53] [config] lr-warmup: 0
[2019-08-07 15:40:53] [config] lr-warmup-at-reload: false
[2019-08-07 15:40:53] [config] lr-warmup-cycle: false
[2019-08-07 15:40:53] [config] lr-warmup-start-rate: 0
[2019-08-07 15:40:53] [config] max-length: 50
[2019-08-07 15:40:53] [config] max-length-crop: false
[2019-08-07 15:40:53] [config] max-length-factor: 3
[2019-08-07 15:40:53] [config] maxi-batch: 100
[2019-08-07 15:40:53] [config] maxi-batch-sort: trg
[2019-08-07 15:40:53] [config] mini-batch: 64
[2019-08-07 15:40:53] [config] mini-batch-fit: true
[2019-08-07 15:40:53] [config] mini-batch-fit-step: 10
[2019-08-07 15:40:53] [config] mini-batch-overstuff: 1
[2019-08-07 15:40:53] [config] mini-batch-track-lr: false
[2019-08-07 15:40:53] [config] mini-batch-understuff: 1
[2019-08-07 15:40:53] [config] mini-batch-warmup: 0
[2019-08-07 15:40:53] [config] mini-batch-words: 0
[2019-08-07 15:40:53] [config] mini-batch-words-ref: 0
[2019-08-07 15:40:53] [config] model: ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz
[2019-08-07 15:40:53] [config] multi-loss-type: sum
[2019-08-07 15:40:53] [config] multi-node: false
[2019-08-07 15:40:53] [config] multi-node-overlap: true
[2019-08-07 15:40:53] [config] n-best: false
[2019-08-07 15:40:53] [config] no-nccl: false
[2019-08-07 15:40:53] [config] no-reload: false
[2019-08-07 15:40:53] [config] no-restore-corpus: false
[2019-08-07 15:40:53] [config] no-shuffle: false
[2019-08-07 15:40:53] [config] normalize: 1
[2019-08-07 15:40:53] [config] num-devices: 0
[2019-08-07 15:40:53] [config] optimizer: adam
[2019-08-07 15:40:53] [config] optimizer-delay: 1
[2019-08-07 15:40:53] [config] optimizer-params:
[2019-08-07 15:40:53] [config]   []
[2019-08-07 15:40:53] [config] overwrite: false
[2019-08-07 15:40:53] [config] pretrained-model: ""
[2019-08-07 15:40:53] [config] quiet: false
[2019-08-07 15:40:53] [config] quiet-translation: true
[2019-08-07 15:40:53] [config] relative-paths: false
[2019-08-07 15:40:53] [config] right-left: false
[2019-08-07 15:40:53] [config] save-freq: 20000
[2019-08-07 15:40:53] [config] seed: 1111
[2019-08-07 15:40:53] [config] shuffle-in-ram: false
[2019-08-07 15:40:53] [config] skip: false
[2019-08-07 15:40:53] [config] sqlite: ""
[2019-08-07 15:40:53] [config] sqlite-drop: false
[2019-08-07 15:40:53] [config] sync-sgd: true
[2019-08-07 15:40:53] [config] tempdir: .
[2019-08-07 15:40:53] [config] tied-embeddings: false
[2019-08-07 15:40:53] [config] tied-embeddings-all: false
[2019-08-07 15:40:53] [config] tied-embeddings-src: false
[2019-08-07 15:40:53] [config] train-sets:
[2019-08-07 15:40:53] [config]   - ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/train.bpe.de
[2019-08-07 15:40:53] [config]   - ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/train.bpe.en
[2019-08-07 15:40:53] [config] transformer-aan-activation: swish
[2019-08-07 15:40:53] [config] transformer-aan-depth: 2
[2019-08-07 15:40:53] [config] transformer-aan-nogate: false
[2019-08-07 15:40:53] [config] transformer-decoder-autoreg: self-attention
[2019-08-07 15:40:53] [config] transformer-dim-aan: 2048
[2019-08-07 15:40:53] [config] transformer-dim-ffn: 2048
[2019-08-07 15:40:53] [config] transformer-dropout: 0
[2019-08-07 15:40:53] [config] transformer-dropout-attention: 0
[2019-08-07 15:40:53] [config] transformer-dropout-ffn: 0
[2019-08-07 15:40:53] [config] transformer-ffn-activation: swish
[2019-08-07 15:40:53] [config] transformer-ffn-depth: 2
[2019-08-07 15:40:53] [config] transformer-guided-alignment-layer: last
[2019-08-07 15:40:53] [config] transformer-heads: 8
[2019-08-07 15:40:53] [config] transformer-no-projection: false
[2019-08-07 15:40:53] [config] transformer-postprocess: dan
[2019-08-07 15:40:53] [config] transformer-postprocess-emb: d
[2019-08-07 15:40:53] [config] transformer-preprocess: ""
[2019-08-07 15:40:53] [config] transformer-tied-layers:
[2019-08-07 15:40:53] [config]   []
[2019-08-07 15:40:53] [config] transformer-train-position-embeddings: false
[2019-08-07 15:40:53] [config] type: amun
[2019-08-07 15:40:53] [config] ulr: false
[2019-08-07 15:40:53] [config] ulr-dim-emb: 0
[2019-08-07 15:40:53] [config] ulr-dropout: 0
[2019-08-07 15:40:53] [config] ulr-keys-vectors: ""
[2019-08-07 15:40:53] [config] ulr-query-vectors: ""
[2019-08-07 15:40:53] [config] ulr-softmax-temperature: 1
[2019-08-07 15:40:53] [config] ulr-trainable-transformation: false
[2019-08-07 15:40:53] [config] valid-freq: 20000
[2019-08-07 15:40:53] [config] valid-log: ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/valid.log
[2019-08-07 15:40:53] [config] valid-max-length: 1000
[2019-08-07 15:40:53] [config] valid-metrics:
[2019-08-07 15:40:53] [config]   - cross-entropy
[2019-08-07 15:40:53] [config]   - perplexity
[2019-08-07 15:40:53] [config]   - translation
[2019-08-07 15:40:53] [config] valid-mini-batch: 8
[2019-08-07 15:40:53] [config] valid-script-path: ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/score-dev.sh
[2019-08-07 15:40:53] [config] valid-sets:
[2019-08-07 15:40:53] [config]   - ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/dev.bpe.de
[2019-08-07 15:40:53] [config]   - ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/dev.bpe.en
[2019-08-07 15:40:53] [config] valid-translation-output: ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/dev.out
[2019-08-07 15:40:53] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 15:40:53] [config] vocabs:
[2019-08-07 15:40:53] [config]   - ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/train.bpe.de.json
[2019-08-07 15:40:53] [config]   - ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/train.bpe.en.json
[2019-08-07 15:40:53] [config] word-penalty: 0
[2019-08-07 15:40:53] [config] workspace: 3000
[2019-08-07 15:40:53] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 15:40:53] Using synchronous training
[2019-08-07 15:40:53] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/train.bpe.de.json
[2019-08-07 15:40:53] [data] Using unused word id eos for 0
[2019-08-07 15:40:53] [data] Using unused word id UNK for 1
[2019-08-07 15:40:53] [data] Setting vocabulary size for input 0 to 50000
[2019-08-07 15:40:53] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/data/train.bpe.en.json
[2019-08-07 15:40:54] [data] Using unused word id eos for 0
[2019-08-07 15:40:54] [data] Using unused word id UNK for 1
[2019-08-07 15:40:54] [data] Setting vocabulary size for input 1 to 50000
[2019-08-07 15:40:54] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-07 15:40:54] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-07 15:40:55] [memory] Extending reserved space to 3072 MB (device gpu7)
[2019-08-07 15:40:55] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 15:40:55] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 15:40:55] [training] Using 1 GPUs
[2019-08-07 15:40:55] [memory] Reserving 422 MB, device gpu7
[2019-08-07 15:40:55] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-07 15:40:55] [memory] Reserving 422 MB, device gpu7
[2019-08-07 15:40:58] [batching] Done. Typical MB size is 4042 target words
[2019-08-07 15:40:58] [memory] Extending reserved space to 3072 MB (device gpu7)
[2019-08-07 15:40:58] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 15:40:58] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 15:40:58] [training] Using 1 GPUs
[2019-08-07 15:40:58] Loading model from ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz.orig.npz
[2019-08-07 15:41:08] Loading Adam parameters from ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz.optimizer.npz
[2019-08-07 15:41:24] [memory] Reserving 844 MB, device gpu7
[2019-08-07 15:41:25] [training] Model reloaded from ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz
[2019-08-07 15:41:25] [data] Restoring the corpus state to epoch 7, batch 220000
[2019-08-07 15:41:25] [data] Shuffling data
[2019-08-07 15:41:40] [data] Done reading 4250865 sentences
[2019-08-07 15:41:54] [data] Done shuffling 4250865 sentences to temp files
[2019-08-07 15:43:06] Training started
[2019-08-07 15:43:06] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-07 15:43:06] [memory] Reserving 422 MB, device gpu7
[2019-08-07 15:43:06] [memory] Reserving 422 MB, device gpu7
[2019-08-07 15:43:06] Loading model from ../experiments/100M_fasttext_prob_x_len_x_bic1.1_+_biced_0.5_x_bic1.1/model/model.npz
[2019-08-07 15:43:15] [memory] Reserving 422 MB, device cpu0
[2019-08-07 15:43:15] [memory] Reserving 422 MB, device gpu7
[2019-08-07 15:48:48] Ep. 7 : Up. 222000 : Sen. 1,796,991 : Cost 52.88017273 : Time 474.49s : 10440.83 words/s
[2019-08-07 15:54:20] Ep. 7 : Up. 224000 : Sen. 1,999,455 : Cost 52.93021011 : Time 331.65s : 14952.19 words/s
