MT evaluation scorer began on 2019 Aug 10 at 09:59:04
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/EMEA.de.sgm -r ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/EMEA.en.sgm -t ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/EMEA.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 3000 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 0.979021889797475 (105238/107493), penalty (log): -0.0214276212014672
NIST score = 7.9247  BLEU score = 0.3265 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  5.7658   1.6738   0.3669   0.0902   0.0279   0.0113   0.0054   0.0032   0.0030  "Edinburgh"

 BLEU:  0.6488   0.3963   0.2650   0.1818   0.1283   0.0924   0.0679   0.0514   0.0395  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  5.7658   7.4397   7.8066   7.8967   7.9247   7.9360   7.9414   7.9447   7.9476  "Edinburgh"

 BLEU:  0.6351   0.4963   0.3998   0.3265   0.2697   0.2248   0.1889   0.1601   0.1367  "Edinburgh"
MT evaluation scorer ended on 2019 Aug 10 at 09:59:38
