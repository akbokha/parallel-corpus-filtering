[2019-08-07 00:18:33] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 00:18:33] [marian] Running on fulla as process 325373 with command line:
[2019-08-07 00:18:33] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz -T . --devices 6 --train-sets ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/train.bpe.de ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/train.bpe.en --vocabs ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/train.bpe.de.json ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/dev.bpe.de ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/dev.out --valid-script-path ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/train.log --valid-log ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/valid.log
[2019-08-07 00:18:33] [config] after-batches: 0
[2019-08-07 00:18:33] [config] after-epochs: 0
[2019-08-07 00:18:33] [config] allow-unk: false
[2019-08-07 00:18:33] [config] beam-size: 12
[2019-08-07 00:18:33] [config] bert-class-symbol: "[CLS]"
[2019-08-07 00:18:33] [config] bert-mask-symbol: "[MASK]"
[2019-08-07 00:18:33] [config] bert-masking-fraction: 0.15
[2019-08-07 00:18:33] [config] bert-sep-symbol: "[SEP]"
[2019-08-07 00:18:33] [config] bert-train-type-embeddings: true
[2019-08-07 00:18:33] [config] bert-type-vocab-size: 2
[2019-08-07 00:18:33] [config] best-deep: false
[2019-08-07 00:18:33] [config] clip-gemm: 0
[2019-08-07 00:18:33] [config] clip-norm: 1
[2019-08-07 00:18:33] [config] cost-type: ce-mean
[2019-08-07 00:18:33] [config] cpu-threads: 0
[2019-08-07 00:18:33] [config] data-weighting: ""
[2019-08-07 00:18:33] [config] data-weighting-type: sentence
[2019-08-07 00:18:33] [config] dec-cell: gru
[2019-08-07 00:18:33] [config] dec-cell-base-depth: 2
[2019-08-07 00:18:33] [config] dec-cell-high-depth: 1
[2019-08-07 00:18:33] [config] dec-depth: 1
[2019-08-07 00:18:33] [config] devices:
[2019-08-07 00:18:33] [config]   - 6
[2019-08-07 00:18:33] [config] dim-emb: 512
[2019-08-07 00:18:33] [config] dim-rnn: 1024
[2019-08-07 00:18:33] [config] dim-vocabs:
[2019-08-07 00:18:33] [config]   - 50000
[2019-08-07 00:18:33] [config]   - 50000
[2019-08-07 00:18:33] [config] disp-first: 0
[2019-08-07 00:18:33] [config] disp-freq: 2000
[2019-08-07 00:18:33] [config] disp-label-counts: false
[2019-08-07 00:18:33] [config] dropout-rnn: 0.2
[2019-08-07 00:18:33] [config] dropout-src: 0.1
[2019-08-07 00:18:33] [config] dropout-trg: 0.1
[2019-08-07 00:18:33] [config] dump-config: ""
[2019-08-07 00:18:33] [config] early-stopping: 5
[2019-08-07 00:18:33] [config] embedding-fix-src: false
[2019-08-07 00:18:33] [config] embedding-fix-trg: false
[2019-08-07 00:18:33] [config] embedding-normalization: false
[2019-08-07 00:18:33] [config] embedding-vectors:
[2019-08-07 00:18:33] [config]   []
[2019-08-07 00:18:33] [config] enc-cell: gru
[2019-08-07 00:18:33] [config] enc-cell-depth: 1
[2019-08-07 00:18:33] [config] enc-depth: 1
[2019-08-07 00:18:33] [config] enc-type: bidirectional
[2019-08-07 00:18:33] [config] exponential-smoothing: 0.0001
[2019-08-07 00:18:33] [config] grad-dropping-momentum: 0
[2019-08-07 00:18:33] [config] grad-dropping-rate: 0
[2019-08-07 00:18:33] [config] grad-dropping-warmup: 100
[2019-08-07 00:18:33] [config] guided-alignment: none
[2019-08-07 00:18:33] [config] guided-alignment-cost: mse
[2019-08-07 00:18:33] [config] guided-alignment-weight: 0.1
[2019-08-07 00:18:33] [config] ignore-model-config: false
[2019-08-07 00:18:33] [config] input-types:
[2019-08-07 00:18:33] [config]   []
[2019-08-07 00:18:33] [config] interpolate-env-vars: false
[2019-08-07 00:18:33] [config] keep-best: false
[2019-08-07 00:18:33] [config] label-smoothing: 0
[2019-08-07 00:18:33] [config] layer-normalization: true
[2019-08-07 00:18:33] [config] learn-rate: 0.0001
[2019-08-07 00:18:33] [config] log: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/train.log
[2019-08-07 00:18:33] [config] log-level: info
[2019-08-07 00:18:33] [config] log-time-zone: ""
[2019-08-07 00:18:33] [config] lr-decay: 0
[2019-08-07 00:18:33] [config] lr-decay-freq: 50000
[2019-08-07 00:18:33] [config] lr-decay-inv-sqrt:
[2019-08-07 00:18:33] [config]   - 0
[2019-08-07 00:18:33] [config] lr-decay-repeat-warmup: false
[2019-08-07 00:18:33] [config] lr-decay-reset-optimizer: false
[2019-08-07 00:18:33] [config] lr-decay-start:
[2019-08-07 00:18:33] [config]   - 10
[2019-08-07 00:18:33] [config]   - 1
[2019-08-07 00:18:33] [config] lr-decay-strategy: epoch+stalled
[2019-08-07 00:18:33] [config] lr-report: false
[2019-08-07 00:18:33] [config] lr-warmup: 0
[2019-08-07 00:18:33] [config] lr-warmup-at-reload: false
[2019-08-07 00:18:33] [config] lr-warmup-cycle: false
[2019-08-07 00:18:33] [config] lr-warmup-start-rate: 0
[2019-08-07 00:18:33] [config] max-length: 50
[2019-08-07 00:18:33] [config] max-length-crop: false
[2019-08-07 00:18:33] [config] max-length-factor: 3
[2019-08-07 00:18:33] [config] maxi-batch: 100
[2019-08-07 00:18:33] [config] maxi-batch-sort: trg
[2019-08-07 00:18:33] [config] mini-batch: 64
[2019-08-07 00:18:33] [config] mini-batch-fit: true
[2019-08-07 00:18:33] [config] mini-batch-fit-step: 10
[2019-08-07 00:18:33] [config] mini-batch-overstuff: 1
[2019-08-07 00:18:33] [config] mini-batch-track-lr: false
[2019-08-07 00:18:33] [config] mini-batch-understuff: 1
[2019-08-07 00:18:33] [config] mini-batch-warmup: 0
[2019-08-07 00:18:33] [config] mini-batch-words: 0
[2019-08-07 00:18:33] [config] mini-batch-words-ref: 0
[2019-08-07 00:18:33] [config] model: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 00:18:33] [config] multi-loss-type: sum
[2019-08-07 00:18:33] [config] multi-node: false
[2019-08-07 00:18:33] [config] multi-node-overlap: true
[2019-08-07 00:18:33] [config] n-best: false
[2019-08-07 00:18:33] [config] no-nccl: false
[2019-08-07 00:18:33] [config] no-reload: false
[2019-08-07 00:18:33] [config] no-restore-corpus: false
[2019-08-07 00:18:33] [config] no-shuffle: false
[2019-08-07 00:18:33] [config] normalize: 1
[2019-08-07 00:18:33] [config] num-devices: 0
[2019-08-07 00:18:33] [config] optimizer: adam
[2019-08-07 00:18:33] [config] optimizer-delay: 1
[2019-08-07 00:18:33] [config] optimizer-params:
[2019-08-07 00:18:33] [config]   []
[2019-08-07 00:18:33] [config] overwrite: false
[2019-08-07 00:18:33] [config] pretrained-model: ""
[2019-08-07 00:18:33] [config] quiet: false
[2019-08-07 00:18:33] [config] quiet-translation: true
[2019-08-07 00:18:33] [config] relative-paths: false
[2019-08-07 00:18:33] [config] right-left: false
[2019-08-07 00:18:33] [config] save-freq: 20000
[2019-08-07 00:18:33] [config] seed: 1111
[2019-08-07 00:18:33] [config] shuffle-in-ram: false
[2019-08-07 00:18:33] [config] skip: false
[2019-08-07 00:18:33] [config] sqlite: ""
[2019-08-07 00:18:33] [config] sqlite-drop: false
[2019-08-07 00:18:33] [config] sync-sgd: true
[2019-08-07 00:18:33] [config] tempdir: .
[2019-08-07 00:18:33] [config] tied-embeddings: false
[2019-08-07 00:18:33] [config] tied-embeddings-all: false
[2019-08-07 00:18:33] [config] tied-embeddings-src: false
[2019-08-07 00:18:33] [config] train-sets:
[2019-08-07 00:18:33] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/train.bpe.de
[2019-08-07 00:18:33] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/train.bpe.en
[2019-08-07 00:18:33] [config] transformer-aan-activation: swish
[2019-08-07 00:18:33] [config] transformer-aan-depth: 2
[2019-08-07 00:18:33] [config] transformer-aan-nogate: false
[2019-08-07 00:18:33] [config] transformer-decoder-autoreg: self-attention
[2019-08-07 00:18:33] [config] transformer-dim-aan: 2048
[2019-08-07 00:18:33] [config] transformer-dim-ffn: 2048
[2019-08-07 00:18:33] [config] transformer-dropout: 0
[2019-08-07 00:18:33] [config] transformer-dropout-attention: 0
[2019-08-07 00:18:33] [config] transformer-dropout-ffn: 0
[2019-08-07 00:18:33] [config] transformer-ffn-activation: swish
[2019-08-07 00:18:33] [config] transformer-ffn-depth: 2
[2019-08-07 00:18:33] [config] transformer-guided-alignment-layer: last
[2019-08-07 00:18:33] [config] transformer-heads: 8
[2019-08-07 00:18:33] [config] transformer-no-projection: false
[2019-08-07 00:18:33] [config] transformer-postprocess: dan
[2019-08-07 00:18:33] [config] transformer-postprocess-emb: d
[2019-08-07 00:18:33] [config] transformer-preprocess: ""
[2019-08-07 00:18:33] [config] transformer-tied-layers:
[2019-08-07 00:18:33] [config]   []
[2019-08-07 00:18:33] [config] transformer-train-position-embeddings: false
[2019-08-07 00:18:33] [config] type: amun
[2019-08-07 00:18:33] [config] ulr: false
[2019-08-07 00:18:33] [config] ulr-dim-emb: 0
[2019-08-07 00:18:33] [config] ulr-dropout: 0
[2019-08-07 00:18:33] [config] ulr-keys-vectors: ""
[2019-08-07 00:18:33] [config] ulr-query-vectors: ""
[2019-08-07 00:18:33] [config] ulr-softmax-temperature: 1
[2019-08-07 00:18:33] [config] ulr-trainable-transformation: false
[2019-08-07 00:18:33] [config] valid-freq: 20000
[2019-08-07 00:18:33] [config] valid-log: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/valid.log
[2019-08-07 00:18:33] [config] valid-max-length: 1000
[2019-08-07 00:18:33] [config] valid-metrics:
[2019-08-07 00:18:33] [config]   - cross-entropy
[2019-08-07 00:18:33] [config]   - perplexity
[2019-08-07 00:18:33] [config]   - translation
[2019-08-07 00:18:33] [config] valid-mini-batch: 8
[2019-08-07 00:18:33] [config] valid-script-path: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/score-dev.sh
[2019-08-07 00:18:33] [config] valid-sets:
[2019-08-07 00:18:33] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/dev.bpe.de
[2019-08-07 00:18:33] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/dev.bpe.en
[2019-08-07 00:18:33] [config] valid-translation-output: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/dev.out
[2019-08-07 00:18:33] [config] vocabs:
[2019-08-07 00:18:33] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/train.bpe.de.json
[2019-08-07 00:18:33] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/train.bpe.en.json
[2019-08-07 00:18:33] [config] word-penalty: 0
[2019-08-07 00:18:33] [config] workspace: 3000
[2019-08-07 00:18:33] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 00:18:33] Using synchronous training
[2019-08-07 00:18:33] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/train.bpe.de.json
[2019-08-07 00:18:33] [data] Using unused word id eos for 0
[2019-08-07 00:18:33] [data] Using unused word id UNK for 1
[2019-08-07 00:18:33] [data] Setting vocabulary size for input 0 to 50000
[2019-08-07 00:18:33] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/train.bpe.en.json
[2019-08-07 00:18:34] [data] Using unused word id eos for 0
[2019-08-07 00:18:34] [data] Using unused word id UNK for 1
[2019-08-07 00:18:34] [data] Setting vocabulary size for input 1 to 50000
[2019-08-07 00:18:34] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-07 00:18:34] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-07 00:18:35] [memory] Extending reserved space to 3072 MB (device gpu6)
[2019-08-07 00:18:35] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 00:18:35] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 00:18:35] [training] Using 1 GPUs
[2019-08-07 00:18:35] [memory] Reserving 422 MB, device gpu6
[2019-08-07 00:18:35] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-07 00:18:35] [memory] Reserving 422 MB, device gpu6
[2019-08-07 00:18:38] [batching] Done. Typical MB size is 4042 target words
[2019-08-07 00:18:38] [memory] Extending reserved space to 3072 MB (device gpu6)
[2019-08-07 00:18:38] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 00:18:38] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 00:18:38] [training] Using 1 GPUs
[2019-08-07 00:18:38] Training started
[2019-08-07 00:18:38] [data] Shuffling data
[2019-08-07 00:18:42] [data] Done reading 5469066 sentences
[2019-08-07 00:19:10] [data] Done shuffling 5469066 sentences to temp files
[2019-08-07 00:19:20] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-07 00:19:20] [memory] Reserving 422 MB, device gpu6
[2019-08-07 00:19:20] [memory] Reserving 422 MB, device gpu6
[2019-08-07 00:19:20] [memory] Reserving 422 MB, device gpu6
[2019-08-07 00:19:20] [memory] Reserving 844 MB, device gpu6
[2019-08-07 00:24:45] Ep. 1 : Up. 2000 : Sen. 234,431 : Cost 131.95526123 : Time 371.07s : 13452.70 words/s
[2019-08-07 00:30:11] Ep. 1 : Up. 4000 : Sen. 467,961 : Cost 104.07748413 : Time 326.11s : 15288.99 words/s
[2019-08-07 00:35:37] Ep. 1 : Up. 6000 : Sen. 702,121 : Cost 88.85112000 : Time 326.02s : 15302.60 words/s
[2019-08-07 00:41:02] Ep. 1 : Up. 8000 : Sen. 936,367 : Cost 79.01366425 : Time 324.70s : 15352.02 words/s
[2019-08-07 00:46:25] Ep. 1 : Up. 10000 : Sen. 1,169,972 : Cost 72.91334534 : Time 323.77s : 15368.63 words/s
[2019-08-07 00:51:50] Ep. 1 : Up. 12000 : Sen. 1,403,730 : Cost 68.51135254 : Time 325.06s : 15364.93 words/s
[2019-08-07 00:57:14] Ep. 1 : Up. 14000 : Sen. 1,638,189 : Cost 64.86890411 : Time 323.55s : 15406.95 words/s
[2019-08-07 01:02:37] Ep. 1 : Up. 16000 : Sen. 1,871,394 : Cost 62.61927414 : Time 323.37s : 15396.94 words/s
[2019-08-07 01:08:03] Ep. 1 : Up. 18000 : Sen. 2,105,501 : Cost 60.57268143 : Time 325.40s : 15344.99 words/s
[2019-08-07 01:13:27] Ep. 1 : Up. 20000 : Sen. 2,338,686 : Cost 59.12263107 : Time 324.61s : 15367.52 words/s
[2019-08-07 01:13:27] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz.orig.npz
[2019-08-07 01:13:36] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.iter20000.npz
[2019-08-07 01:13:44] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 01:13:54] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz.optimizer.npz
[2019-08-07 01:14:21] [valid] Ep. 1 : Up. 20000 : cross-entropy : 68.5647 : new best
[2019-08-07 01:14:27] [valid] Ep. 1 : Up. 20000 : perplexity : 14.7093 : new best
[2019-08-07 01:15:33] [valid] Ep. 1 : Up. 20000 : translation : 16.91 : new best
[2019-08-07 01:21:00] Ep. 1 : Up. 22000 : Sen. 2,572,722 : Cost 57.24197006 : Time 452.32s : 11027.57 words/s
[2019-08-07 01:26:25] Ep. 1 : Up. 24000 : Sen. 2,806,810 : Cost 56.27552414 : Time 325.13s : 15360.37 words/s
[2019-08-07 01:31:50] Ep. 1 : Up. 26000 : Sen. 3,041,699 : Cost 54.99402618 : Time 325.34s : 15397.42 words/s
[2019-08-07 01:37:15] Ep. 1 : Up. 28000 : Sen. 3,275,919 : Cost 54.42447281 : Time 325.02s : 15380.25 words/s
[2019-08-07 01:42:39] Ep. 1 : Up. 30000 : Sen. 3,509,679 : Cost 53.40277481 : Time 323.76s : 15352.43 words/s
[2019-08-07 01:48:03] Ep. 1 : Up. 32000 : Sen. 3,742,621 : Cost 52.50654602 : Time 323.79s : 15344.06 words/s
[2019-08-07 01:53:28] Ep. 1 : Up. 34000 : Sen. 3,976,199 : Cost 52.14743805 : Time 325.25s : 15342.75 words/s
[2019-08-07 01:58:52] Ep. 1 : Up. 36000 : Sen. 4,210,810 : Cost 50.75469208 : Time 324.46s : 15358.49 words/s
[2019-08-07 02:04:17] Ep. 1 : Up. 38000 : Sen. 4,443,997 : Cost 50.82407761 : Time 324.52s : 15314.78 words/s
[2019-08-07 02:09:42] Ep. 1 : Up. 40000 : Sen. 4,677,199 : Cost 50.47954941 : Time 325.05s : 15319.70 words/s
[2019-08-07 02:09:42] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz.orig.npz
[2019-08-07 02:09:51] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.iter40000.npz
[2019-08-07 02:09:59] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 02:10:09] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz.optimizer.npz
[2019-08-07 02:10:35] [valid] Ep. 1 : Up. 40000 : cross-entropy : 56.3738 : new best
[2019-08-07 02:10:42] [valid] Ep. 1 : Up. 40000 : perplexity : 9.11995 : new best
[2019-08-07 02:11:45] [valid] Ep. 1 : Up. 40000 : translation : 20.39 : new best
[2019-08-07 02:15:37] Seen 4842315 samples
[2019-08-07 02:15:37] Starting epoch 2
[2019-08-07 02:15:37] [data] Shuffling data
[2019-08-07 02:15:44] [data] Done reading 5469066 sentences
[2019-08-07 02:16:20] [data] Done shuffling 5469066 sentences to temp files
[2019-08-07 02:18:00] Ep. 2 : Up. 42000 : Sen. 68,643 : Cost 49.62886810 : Time 498.51s : 10012.24 words/s
[2019-08-07 02:23:27] Ep. 2 : Up. 44000 : Sen. 303,614 : Cost 48.68802261 : Time 326.07s : 15375.81 words/s
[2019-08-07 02:28:53] Ep. 2 : Up. 46000 : Sen. 538,521 : Cost 48.33282852 : Time 326.85s : 15339.66 words/s
[2019-08-07 02:34:18] Ep. 2 : Up. 48000 : Sen. 772,351 : Cost 47.80229568 : Time 324.55s : 15343.00 words/s
[2019-08-07 02:39:44] Ep. 2 : Up. 50000 : Sen. 1,007,912 : Cost 47.46680450 : Time 326.07s : 15372.59 words/s
[2019-08-07 02:45:10] Ep. 2 : Up. 52000 : Sen. 1,242,485 : Cost 46.89142227 : Time 326.11s : 15342.70 words/s
[2019-08-07 02:50:34] Ep. 2 : Up. 54000 : Sen. 1,475,599 : Cost 46.95476151 : Time 324.19s : 15316.62 words/s
[2019-08-07 02:56:00] Ep. 2 : Up. 56000 : Sen. 1,709,917 : Cost 46.65792084 : Time 325.69s : 15349.92 words/s
[2019-08-07 03:01:26] Ep. 2 : Up. 58000 : Sen. 1,944,236 : Cost 46.44753265 : Time 326.17s : 15310.10 words/s
[2019-08-07 03:06:52] Ep. 2 : Up. 60000 : Sen. 2,178,860 : Cost 46.06932831 : Time 325.96s : 15349.65 words/s
[2019-08-07 03:06:52] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz.orig.npz
[2019-08-07 03:07:02] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.iter60000.npz
[2019-08-07 03:07:13] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 03:07:24] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz.optimizer.npz
[2019-08-07 03:07:59] [valid] Ep. 2 : Up. 60000 : cross-entropy : 51.3563 : new best
[2019-08-07 03:08:06] [valid] Ep. 2 : Up. 60000 : perplexity : 7.49115 : new best
[2019-08-07 03:09:09] [valid] Ep. 2 : Up. 60000 : translation : 22.95 : new best
[2019-08-07 03:14:38] Ep. 2 : Up. 62000 : Sen. 2,414,856 : Cost 45.89199066 : Time 465.63s : 10816.36 words/s
[2019-08-07 03:20:03] Ep. 2 : Up. 64000 : Sen. 2,649,260 : Cost 45.61560440 : Time 325.14s : 15379.63 words/s
[2019-08-07 03:25:29] Ep. 2 : Up. 66000 : Sen. 2,883,540 : Cost 45.66635895 : Time 325.72s : 15352.57 words/s
[2019-08-07 03:30:52] Ep. 2 : Up. 68000 : Sen. 3,117,684 : Cost 45.01928329 : Time 323.89s : 15352.95 words/s
[2019-08-07 03:36:19] Ep. 2 : Up. 70000 : Sen. 3,351,709 : Cost 45.21755981 : Time 326.62s : 15319.00 words/s
[2019-08-07 03:41:45] Ep. 2 : Up. 72000 : Sen. 3,585,965 : Cost 44.72329712 : Time 325.57s : 15345.83 words/s
[2019-08-07 03:47:09] Ep. 2 : Up. 74000 : Sen. 3,819,570 : Cost 44.54545975 : Time 324.02s : 15360.04 words/s
[2019-08-07 03:52:34] Ep. 2 : Up. 76000 : Sen. 4,053,878 : Cost 44.42488098 : Time 325.10s : 15368.79 words/s
[2019-08-07 03:57:59] Ep. 2 : Up. 78000 : Sen. 4,288,078 : Cost 44.12063980 : Time 325.20s : 15337.32 words/s
[2019-08-07 04:03:24] Ep. 2 : Up. 80000 : Sen. 4,521,493 : Cost 44.34383774 : Time 325.33s : 15316.27 words/s
[2019-08-07 04:03:24] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz.orig.npz
[2019-08-07 04:03:34] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.iter80000.npz
[2019-08-07 04:03:41] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 04:03:52] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz.optimizer.npz
[2019-08-07 04:04:19] [valid] Ep. 2 : Up. 80000 : cross-entropy : 48.4266 : new best
[2019-08-07 04:04:26] [valid] Ep. 2 : Up. 80000 : perplexity : 6.67819 : new best
[2019-08-07 04:05:26] [valid] Ep. 2 : Up. 80000 : translation : 25.17 : new best
[2019-08-07 04:10:53] Ep. 2 : Up. 82000 : Sen. 4,755,044 : Cost 44.11977005 : Time 449.06s : 11088.44 words/s
[2019-08-07 04:12:55] Seen 4842315 samples
[2019-08-07 04:12:55] Starting epoch 3
[2019-08-07 04:12:55] [data] Shuffling data
[2019-08-07 04:12:59] [data] Done reading 5469066 sentences
[2019-08-07 04:13:23] [data] Done shuffling 5469066 sentences to temp files
[2019-08-07 04:16:56] Ep. 3 : Up. 84000 : Sen. 147,528 : Cost 43.18353271 : Time 362.35s : 13819.60 words/s
[2019-08-07 04:22:22] Ep. 3 : Up. 86000 : Sen. 381,357 : Cost 42.84853363 : Time 326.15s : 15330.34 words/s
[2019-08-07 04:27:47] Ep. 3 : Up. 88000 : Sen. 614,977 : Cost 42.61787415 : Time 324.76s : 15312.46 words/s
[2019-08-07 04:33:11] Ep. 3 : Up. 90000 : Sen. 848,648 : Cost 42.58064651 : Time 324.56s : 15360.21 words/s
[2019-08-07 04:38:36] Ep. 3 : Up. 92000 : Sen. 1,082,407 : Cost 42.64135361 : Time 324.95s : 15354.32 words/s
[2019-08-07 04:44:03] Ep. 3 : Up. 94000 : Sen. 1,316,919 : Cost 42.58125305 : Time 326.53s : 15332.45 words/s
[2019-08-07 04:49:27] Ep. 3 : Up. 96000 : Sen. 1,550,559 : Cost 42.31622696 : Time 324.25s : 15340.27 words/s
[2019-08-07 04:54:53] Ep. 3 : Up. 98000 : Sen. 1,785,195 : Cost 42.30362320 : Time 326.30s : 15349.98 words/s
[2019-08-07 05:00:18] Ep. 3 : Up. 100000 : Sen. 2,019,742 : Cost 42.03211212 : Time 325.18s : 15354.49 words/s
[2019-08-07 05:00:18] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz.orig.npz
[2019-08-07 05:00:28] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.iter100000.npz
[2019-08-07 05:00:36] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 05:00:47] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz.optimizer.npz
[2019-08-07 05:01:15] [valid] Ep. 3 : Up. 100000 : cross-entropy : 46.5589 : new best
[2019-08-07 05:01:22] [valid] Ep. 3 : Up. 100000 : perplexity : 6.20659 : new best
[2019-08-07 05:02:22] [valid] Ep. 3 : Up. 100000 : translation : 26.47 : new best
[2019-08-07 05:07:48] Ep. 3 : Up. 102000 : Sen. 2,252,902 : Cost 42.11523056 : Time 449.38s : 11059.39 words/s
[2019-08-07 05:13:13] Ep. 3 : Up. 104000 : Sen. 2,486,849 : Cost 42.21707535 : Time 325.55s : 15358.86 words/s
[2019-08-07 05:18:38] Ep. 3 : Up. 106000 : Sen. 2,721,280 : Cost 41.80321121 : Time 325.04s : 15336.18 words/s
[2019-08-07 05:24:04] Ep. 3 : Up. 108000 : Sen. 2,955,944 : Cost 41.49466324 : Time 325.30s : 15365.09 words/s
[2019-08-07 05:29:29] Ep. 3 : Up. 110000 : Sen. 3,189,617 : Cost 41.81136703 : Time 324.88s : 15353.65 words/s
[2019-08-07 05:34:54] Ep. 3 : Up. 112000 : Sen. 3,423,580 : Cost 41.38542175 : Time 325.01s : 15321.06 words/s
[2019-08-07 05:40:19] Ep. 3 : Up. 114000 : Sen. 3,657,161 : Cost 41.70880890 : Time 325.18s : 15341.19 words/s
[2019-08-07 05:45:44] Ep. 3 : Up. 116000 : Sen. 3,891,849 : Cost 41.33759308 : Time 325.40s : 15365.78 words/s
[2019-08-07 05:51:09] Ep. 3 : Up. 118000 : Sen. 4,125,621 : Cost 41.43428040 : Time 324.33s : 15379.55 words/s
[2019-08-07 05:56:33] Ep. 3 : Up. 120000 : Sen. 4,358,998 : Cost 41.21789551 : Time 324.24s : 15329.45 words/s
[2019-08-07 05:56:33] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz.orig.npz
[2019-08-07 05:56:45] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.iter120000.npz
[2019-08-07 05:56:52] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 05:57:03] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz.optimizer.npz
[2019-08-07 05:57:30] [valid] Ep. 3 : Up. 120000 : cross-entropy : 45.0727 : new best
[2019-08-07 05:57:37] [valid] Ep. 3 : Up. 120000 : perplexity : 5.85524 : new best
[2019-08-07 05:58:36] [valid] Ep. 3 : Up. 120000 : translation : 27.34 : new best
[2019-08-07 06:04:02] Ep. 3 : Up. 122000 : Sen. 4,593,266 : Cost 41.36429214 : Time 449.71s : 11110.65 words/s
[2019-08-07 06:09:27] Ep. 3 : Up. 124000 : Sen. 4,827,803 : Cost 41.34049988 : Time 324.99s : 15422.47 words/s
[2019-08-07 06:09:47] Seen 4842315 samples
[2019-08-07 06:09:47] Starting epoch 4
[2019-08-07 06:09:47] [data] Shuffling data
[2019-08-07 06:09:50] [data] Done reading 5469066 sentences
[2019-08-07 06:10:14] [data] Done shuffling 5469066 sentences to temp files
[2019-08-07 06:15:27] Ep. 4 : Up. 126000 : Sen. 219,308 : Cost 39.85340118 : Time 359.27s : 13838.74 words/s
[2019-08-07 06:20:51] Ep. 4 : Up. 128000 : Sen. 453,737 : Cost 40.11231995 : Time 323.96s : 15398.79 words/s
[2019-08-07 06:26:14] Ep. 4 : Up. 130000 : Sen. 686,751 : Cost 40.06768799 : Time 323.32s : 15356.63 words/s
[2019-08-07 06:31:38] Ep. 4 : Up. 132000 : Sen. 921,215 : Cost 39.99967194 : Time 323.88s : 15418.48 words/s
[2019-08-07 06:37:02] Ep. 4 : Up. 134000 : Sen. 1,154,748 : Cost 40.29430008 : Time 324.34s : 15385.33 words/s
[2019-08-07 06:42:26] Ep. 4 : Up. 136000 : Sen. 1,388,902 : Cost 40.05780792 : Time 323.52s : 15427.88 words/s
[2019-08-07 06:47:51] Ep. 4 : Up. 138000 : Sen. 1,622,638 : Cost 40.12169266 : Time 324.88s : 15376.14 words/s
[2019-08-07 06:53:14] Ep. 4 : Up. 140000 : Sen. 1,856,237 : Cost 40.14104462 : Time 323.56s : 15414.21 words/s
[2019-08-07 06:53:14] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz.orig.npz
[2019-08-07 06:53:24] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.iter140000.npz
[2019-08-07 06:53:32] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 06:53:43] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz.optimizer.npz
[2019-08-07 06:54:10] [valid] Ep. 4 : Up. 140000 : cross-entropy : 44.1328 : new best
[2019-08-07 06:54:17] [valid] Ep. 4 : Up. 140000 : perplexity : 5.64337 : new best
[2019-08-07 06:55:17] [valid] Ep. 4 : Up. 140000 : translation : 27.8 : new best
[2019-08-07 07:00:44] Ep. 4 : Up. 142000 : Sen. 2,090,540 : Cost 39.90519714 : Time 449.68s : 11110.50 words/s
[2019-08-07 07:06:08] Ep. 4 : Up. 144000 : Sen. 2,324,731 : Cost 39.68640518 : Time 323.73s : 15386.71 words/s
[2019-08-07 07:11:32] Ep. 4 : Up. 146000 : Sen. 2,558,698 : Cost 40.09647369 : Time 324.45s : 15409.55 words/s
[2019-08-07 07:16:57] Ep. 4 : Up. 148000 : Sen. 2,793,375 : Cost 39.84535217 : Time 325.16s : 15384.29 words/s
[2019-08-07 07:22:22] Ep. 4 : Up. 150000 : Sen. 3,027,823 : Cost 39.82393265 : Time 324.90s : 15413.23 words/s
[2019-08-07 07:27:44] Ep. 4 : Up. 152000 : Sen. 3,261,394 : Cost 39.67478561 : Time 322.20s : 15416.66 words/s
[2019-08-07 07:33:08] Ep. 4 : Up. 154000 : Sen. 3,494,580 : Cost 39.84207916 : Time 323.91s : 15381.82 words/s
[2019-08-07 07:38:32] Ep. 4 : Up. 156000 : Sen. 3,728,573 : Cost 39.82994843 : Time 323.94s : 15417.85 words/s
[2019-08-07 07:43:57] Ep. 4 : Up. 158000 : Sen. 3,963,498 : Cost 39.52497101 : Time 324.57s : 15410.02 words/s
[2019-08-07 07:49:21] Ep. 4 : Up. 160000 : Sen. 4,198,136 : Cost 39.61740494 : Time 324.52s : 15409.22 words/s
[2019-08-07 07:49:21] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz.orig.npz
[2019-08-07 07:49:31] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.iter160000.npz
[2019-08-07 07:49:38] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 07:49:49] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz.optimizer.npz
[2019-08-07 07:50:17] [valid] Ep. 4 : Up. 160000 : cross-entropy : 43.3235 : new best
[2019-08-07 07:50:23] [valid] Ep. 4 : Up. 160000 : perplexity : 5.4671 : new best
[2019-08-07 07:51:22] [valid] Ep. 4 : Up. 160000 : translation : 28.23 : new best
[2019-08-07 07:56:48] Ep. 4 : Up. 162000 : Sen. 4,431,979 : Cost 39.38726425 : Time 446.40s : 11157.73 words/s
[2019-08-07 08:02:11] Ep. 4 : Up. 164000 : Sen. 4,665,113 : Cost 39.43258286 : Time 323.44s : 15375.43 words/s
[2019-08-07 08:06:17] Seen 4842315 samples
[2019-08-07 08:06:17] Starting epoch 5
[2019-08-07 08:06:17] [data] Shuffling data
[2019-08-07 08:06:25] [data] Done reading 5469066 sentences
[2019-08-07 08:06:51] [data] Done shuffling 5469066 sentences to temp files
[2019-08-07 08:08:18] Ep. 5 : Up. 166000 : Sen. 56,620 : Cost 39.17980194 : Time 366.68s : 13565.08 words/s
[2019-08-07 08:13:43] Ep. 5 : Up. 168000 : Sen. 290,269 : Cost 38.44099045 : Time 324.75s : 15347.21 words/s
[2019-08-07 08:19:08] Ep. 5 : Up. 170000 : Sen. 523,936 : Cost 38.44478989 : Time 325.09s : 15324.84 words/s
[2019-08-07 08:24:33] Ep. 5 : Up. 172000 : Sen. 758,534 : Cost 38.50459671 : Time 325.45s : 15397.78 words/s
[2019-08-07 08:29:58] Ep. 5 : Up. 174000 : Sen. 992,676 : Cost 38.47557068 : Time 325.24s : 15357.34 words/s
[2019-08-07 08:35:24] Ep. 5 : Up. 176000 : Sen. 1,226,663 : Cost 38.53580475 : Time 325.46s : 15350.54 words/s
[2019-08-07 08:40:46] Ep. 5 : Up. 178000 : Sen. 1,461,406 : Cost 38.45344925 : Time 322.50s : 15439.74 words/s
[2019-08-07 08:46:11] Ep. 5 : Up. 180000 : Sen. 1,695,795 : Cost 38.48300552 : Time 324.34s : 15418.91 words/s
[2019-08-07 08:46:11] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz.orig.npz
[2019-08-07 08:46:20] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.iter180000.npz
[2019-08-07 08:46:28] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 08:46:38] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz.optimizer.npz
[2019-08-07 08:47:07] [valid] Ep. 5 : Up. 180000 : cross-entropy : 42.7651 : new best
[2019-08-07 08:47:14] [valid] Ep. 5 : Up. 180000 : perplexity : 5.34871 : new best
[2019-08-07 08:48:12] [valid] Ep. 5 : Up. 180000 : translation : 28.68 : new best
[2019-08-07 08:53:39] Ep. 5 : Up. 182000 : Sen. 1,930,608 : Cost 38.24805832 : Time 447.84s : 11163.07 words/s
[2019-08-07 08:59:03] Ep. 5 : Up. 184000 : Sen. 2,164,024 : Cost 38.57136154 : Time 324.07s : 15385.00 words/s
[2019-08-07 09:04:27] Ep. 5 : Up. 186000 : Sen. 2,397,839 : Cost 38.37178802 : Time 324.26s : 15371.18 words/s
[2019-08-07 09:09:52] Ep. 5 : Up. 188000 : Sen. 2,631,897 : Cost 38.47843552 : Time 325.05s : 15362.89 words/s
[2019-08-07 09:15:17] Ep. 5 : Up. 190000 : Sen. 2,865,342 : Cost 38.41605377 : Time 325.21s : 15308.30 words/s
[2019-08-07 09:20:43] Ep. 5 : Up. 192000 : Sen. 3,098,872 : Cost 38.47210312 : Time 325.71s : 15310.44 words/s
[2019-08-07 09:26:09] Ep. 5 : Up. 194000 : Sen. 3,333,334 : Cost 38.44578171 : Time 326.00s : 15338.46 words/s
[2019-08-07 09:31:36] Ep. 5 : Up. 196000 : Sen. 3,567,295 : Cost 38.62851334 : Time 327.58s : 15292.03 words/s
[2019-08-07 09:37:02] Ep. 5 : Up. 198000 : Sen. 3,801,522 : Cost 38.65966415 : Time 326.07s : 15304.81 words/s
[2019-08-07 09:42:28] Ep. 5 : Up. 200000 : Sen. 4,035,183 : Cost 38.03464508 : Time 325.15s : 15285.32 words/s
[2019-08-07 09:42:28] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz.orig.npz
[2019-08-07 09:42:38] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.iter200000.npz
[2019-08-07 09:42:46] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 09:42:56] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz.optimizer.npz
[2019-08-07 09:43:22] [valid] Ep. 5 : Up. 200000 : cross-entropy : 42.2518 : new best
[2019-08-07 09:43:29] [valid] Ep. 5 : Up. 200000 : perplexity : 5.24212 : new best
[2019-08-07 09:44:27] [valid] Ep. 5 : Up. 200000 : translation : 28.81 : new best
[2019-08-07 09:49:56] Ep. 5 : Up. 202000 : Sen. 4,269,570 : Cost 38.48235703 : Time 448.74s : 11138.78 words/s
[2019-08-07 09:55:23] Ep. 5 : Up. 204000 : Sen. 4,504,145 : Cost 38.15447998 : Time 326.60s : 15274.81 words/s
[2019-08-07 10:00:50] Ep. 5 : Up. 206000 : Sen. 4,739,055 : Cost 38.39571762 : Time 327.20s : 15307.21 words/s
[2019-08-07 10:03:14] Seen 4842315 samples
[2019-08-07 10:03:14] Starting epoch 6
[2019-08-07 10:03:14] [data] Shuffling data
[2019-08-07 10:03:17] [data] Done reading 5469066 sentences
[2019-08-07 10:03:40] [data] Done shuffling 5469066 sentences to temp files
[2019-08-07 10:06:51] Ep. 6 : Up. 208000 : Sen. 130,060 : Cost 38.01907730 : Time 360.64s : 13817.28 words/s
[2019-08-07 10:12:17] Ep. 6 : Up. 210000 : Sen. 363,763 : Cost 37.21106720 : Time 325.90s : 15268.20 words/s
[2019-08-07 10:17:43] Ep. 6 : Up. 212000 : Sen. 597,805 : Cost 37.30118561 : Time 326.51s : 15299.91 words/s
[2019-08-07 10:23:10] Ep. 6 : Up. 214000 : Sen. 831,558 : Cost 37.66073990 : Time 326.56s : 15302.19 words/s
[2019-08-07 10:28:36] Ep. 6 : Up. 216000 : Sen. 1,066,166 : Cost 37.17554092 : Time 326.71s : 15278.58 words/s
[2019-08-07 10:34:04] Ep. 6 : Up. 218000 : Sen. 1,300,784 : Cost 37.34345627 : Time 327.62s : 15265.10 words/s
[2019-08-07 10:39:33] Ep. 6 : Up. 220000 : Sen. 1,535,439 : Cost 37.49182129 : Time 329.10s : 15239.07 words/s
[2019-08-07 10:39:33] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz.orig.npz
[2019-08-07 10:39:43] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.iter220000.npz
[2019-08-07 10:39:50] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 10:40:00] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz.optimizer.npz
[2019-08-07 10:40:27] [valid] Ep. 6 : Up. 220000 : cross-entropy : 41.9186 : new best
[2019-08-07 10:40:34] [valid] Ep. 6 : Up. 220000 : perplexity : 5.17409 : new best
[2019-08-07 10:41:33] [valid] Ep. 6 : Up. 220000 : translation : 29.01 : new best
[2019-08-07 10:47:04] Ep. 6 : Up. 222000 : Sen. 1,769,074 : Cost 37.41843414 : Time 450.39s : 11071.42 words/s
[2019-08-07 10:52:31] Ep. 6 : Up. 224000 : Sen. 2,002,596 : Cost 37.46131516 : Time 327.18s : 15195.19 words/s
[2019-08-07 10:57:59] Ep. 6 : Up. 226000 : Sen. 2,236,327 : Cost 37.64234924 : Time 328.49s : 15167.36 words/s
[2019-08-07 11:03:29] Ep. 6 : Up. 228000 : Sen. 2,470,875 : Cost 37.46474457 : Time 329.69s : 15170.65 words/s
[2019-08-07 11:08:59] Ep. 6 : Up. 230000 : Sen. 2,705,624 : Cost 37.43236923 : Time 330.51s : 15130.97 words/s
[2019-08-07 11:14:29] Ep. 6 : Up. 232000 : Sen. 2,939,838 : Cost 37.44293594 : Time 329.76s : 15158.54 words/s
[2019-08-07 11:19:57] Ep. 6 : Up. 234000 : Sen. 3,172,671 : Cost 37.48805618 : Time 327.31s : 15167.53 words/s
[2019-08-07 11:25:25] Ep. 6 : Up. 236000 : Sen. 3,407,453 : Cost 37.45424271 : Time 328.41s : 15213.20 words/s
[2019-08-07 11:30:55] Ep. 6 : Up. 238000 : Sen. 3,641,869 : Cost 37.49472809 : Time 329.62s : 15181.28 words/s
[2019-08-07 11:36:24] Ep. 6 : Up. 240000 : Sen. 3,875,739 : Cost 37.50591660 : Time 329.07s : 15171.50 words/s
[2019-08-07 11:36:24] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz.orig.npz
[2019-08-07 11:36:34] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.iter240000.npz
[2019-08-07 11:36:41] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 11:36:51] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz.optimizer.npz
[2019-08-07 11:37:21] [valid] Ep. 6 : Up. 240000 : cross-entropy : 41.5321 : new best
[2019-08-07 11:37:28] [valid] Ep. 6 : Up. 240000 : perplexity : 5.09627 : new best
[2019-08-07 11:38:26] [valid] Ep. 6 : Up. 240000 : translation : 29.32 : new best
[2019-08-07 11:43:56] Ep. 6 : Up. 242000 : Sen. 4,108,800 : Cost 37.54353333 : Time 452.47s : 10998.48 words/s
[2019-08-07 11:49:24] Ep. 6 : Up. 244000 : Sen. 4,343,006 : Cost 37.32703400 : Time 327.97s : 15201.12 words/s
[2019-08-07 11:54:52] Ep. 6 : Up. 246000 : Sen. 4,577,506 : Cost 37.38224030 : Time 327.44s : 15236.72 words/s
[2019-08-07 12:00:19] Ep. 6 : Up. 248000 : Sen. 4,811,704 : Cost 37.53677368 : Time 327.26s : 15252.80 words/s
[2019-08-07 12:01:02] Seen 4842315 samples
[2019-08-07 12:01:02] Starting epoch 7
[2019-08-07 12:01:02] [data] Shuffling data
[2019-08-07 12:01:05] [data] Done reading 5469066 sentences
[2019-08-07 12:01:31] [data] Done shuffling 5469066 sentences to temp files
[2019-08-07 15:40:03] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 15:40:03] [marian] Running on fulla as process 5210 with command line:
[2019-08-07 15:40:03] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz -T . --devices 6 --train-sets ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/train.bpe.de ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/train.bpe.en --vocabs ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/train.bpe.de.json ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/dev.bpe.de ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/dev.out --valid-script-path ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/train.log --valid-log ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/valid.log
[2019-08-07 15:40:04] [config] after-batches: 0
[2019-08-07 15:40:04] [config] after-epochs: 0
[2019-08-07 15:40:04] [config] allow-unk: false
[2019-08-07 15:40:04] [config] beam-size: 12
[2019-08-07 15:40:04] [config] bert-class-symbol: "[CLS]"
[2019-08-07 15:40:04] [config] bert-mask-symbol: "[MASK]"
[2019-08-07 15:40:04] [config] bert-masking-fraction: 0.15
[2019-08-07 15:40:04] [config] bert-sep-symbol: "[SEP]"
[2019-08-07 15:40:04] [config] bert-train-type-embeddings: true
[2019-08-07 15:40:04] [config] bert-type-vocab-size: 2
[2019-08-07 15:40:04] [config] best-deep: false
[2019-08-07 15:40:04] [config] clip-gemm: 0
[2019-08-07 15:40:04] [config] clip-norm: 1
[2019-08-07 15:40:04] [config] cost-type: ce-mean
[2019-08-07 15:40:04] [config] cpu-threads: 0
[2019-08-07 15:40:04] [config] data-weighting: ""
[2019-08-07 15:40:04] [config] data-weighting-type: sentence
[2019-08-07 15:40:04] [config] dec-cell: gru
[2019-08-07 15:40:04] [config] dec-cell-base-depth: 2
[2019-08-07 15:40:04] [config] dec-cell-high-depth: 1
[2019-08-07 15:40:04] [config] dec-depth: 1
[2019-08-07 15:40:04] [config] devices:
[2019-08-07 15:40:04] [config]   - 6
[2019-08-07 15:40:04] [config] dim-emb: 512
[2019-08-07 15:40:04] [config] dim-rnn: 1024
[2019-08-07 15:40:04] [config] dim-vocabs:
[2019-08-07 15:40:04] [config]   - 50000
[2019-08-07 15:40:04] [config]   - 50000
[2019-08-07 15:40:04] [config] disp-first: 0
[2019-08-07 15:40:04] [config] disp-freq: 2000
[2019-08-07 15:40:04] [config] disp-label-counts: false
[2019-08-07 15:40:04] [config] dropout-rnn: 0.2
[2019-08-07 15:40:04] [config] dropout-src: 0.1
[2019-08-07 15:40:04] [config] dropout-trg: 0.1
[2019-08-07 15:40:04] [config] dump-config: ""
[2019-08-07 15:40:04] [config] early-stopping: 5
[2019-08-07 15:40:04] [config] embedding-fix-src: false
[2019-08-07 15:40:04] [config] embedding-fix-trg: false
[2019-08-07 15:40:04] [config] embedding-normalization: false
[2019-08-07 15:40:04] [config] embedding-vectors:
[2019-08-07 15:40:04] [config]   []
[2019-08-07 15:40:04] [config] enc-cell: gru
[2019-08-07 15:40:04] [config] enc-cell-depth: 1
[2019-08-07 15:40:04] [config] enc-depth: 1
[2019-08-07 15:40:04] [config] enc-type: bidirectional
[2019-08-07 15:40:04] [config] exponential-smoothing: 0.0001
[2019-08-07 15:40:04] [config] grad-dropping-momentum: 0
[2019-08-07 15:40:04] [config] grad-dropping-rate: 0
[2019-08-07 15:40:04] [config] grad-dropping-warmup: 100
[2019-08-07 15:40:04] [config] guided-alignment: none
[2019-08-07 15:40:04] [config] guided-alignment-cost: mse
[2019-08-07 15:40:04] [config] guided-alignment-weight: 0.1
[2019-08-07 15:40:04] [config] ignore-model-config: false
[2019-08-07 15:40:04] [config] input-types:
[2019-08-07 15:40:04] [config]   []
[2019-08-07 15:40:04] [config] interpolate-env-vars: false
[2019-08-07 15:40:04] [config] keep-best: false
[2019-08-07 15:40:04] [config] label-smoothing: 0
[2019-08-07 15:40:04] [config] layer-normalization: true
[2019-08-07 15:40:04] [config] learn-rate: 0.0001
[2019-08-07 15:40:04] [config] log: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/train.log
[2019-08-07 15:40:04] [config] log-level: info
[2019-08-07 15:40:04] [config] log-time-zone: ""
[2019-08-07 15:40:04] [config] lr-decay: 0
[2019-08-07 15:40:04] [config] lr-decay-freq: 50000
[2019-08-07 15:40:04] [config] lr-decay-inv-sqrt:
[2019-08-07 15:40:04] [config]   - 0
[2019-08-07 15:40:04] [config] lr-decay-repeat-warmup: false
[2019-08-07 15:40:04] [config] lr-decay-reset-optimizer: false
[2019-08-07 15:40:04] [config] lr-decay-start:
[2019-08-07 15:40:04] [config]   - 10
[2019-08-07 15:40:04] [config]   - 1
[2019-08-07 15:40:04] [config] lr-decay-strategy: epoch+stalled
[2019-08-07 15:40:04] [config] lr-report: false
[2019-08-07 15:40:04] [config] lr-warmup: 0
[2019-08-07 15:40:04] [config] lr-warmup-at-reload: false
[2019-08-07 15:40:04] [config] lr-warmup-cycle: false
[2019-08-07 15:40:04] [config] lr-warmup-start-rate: 0
[2019-08-07 15:40:04] [config] max-length: 50
[2019-08-07 15:40:04] [config] max-length-crop: false
[2019-08-07 15:40:04] [config] max-length-factor: 3
[2019-08-07 15:40:04] [config] maxi-batch: 100
[2019-08-07 15:40:04] [config] maxi-batch-sort: trg
[2019-08-07 15:40:04] [config] mini-batch: 64
[2019-08-07 15:40:04] [config] mini-batch-fit: true
[2019-08-07 15:40:04] [config] mini-batch-fit-step: 10
[2019-08-07 15:40:04] [config] mini-batch-overstuff: 1
[2019-08-07 15:40:04] [config] mini-batch-track-lr: false
[2019-08-07 15:40:04] [config] mini-batch-understuff: 1
[2019-08-07 15:40:04] [config] mini-batch-warmup: 0
[2019-08-07 15:40:04] [config] mini-batch-words: 0
[2019-08-07 15:40:04] [config] mini-batch-words-ref: 0
[2019-08-07 15:40:04] [config] model: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 15:40:04] [config] multi-loss-type: sum
[2019-08-07 15:40:04] [config] multi-node: false
[2019-08-07 15:40:04] [config] multi-node-overlap: true
[2019-08-07 15:40:04] [config] n-best: false
[2019-08-07 15:40:04] [config] no-nccl: false
[2019-08-07 15:40:04] [config] no-reload: false
[2019-08-07 15:40:04] [config] no-restore-corpus: false
[2019-08-07 15:40:04] [config] no-shuffle: false
[2019-08-07 15:40:04] [config] normalize: 1
[2019-08-07 15:40:04] [config] num-devices: 0
[2019-08-07 15:40:04] [config] optimizer: adam
[2019-08-07 15:40:04] [config] optimizer-delay: 1
[2019-08-07 15:40:04] [config] optimizer-params:
[2019-08-07 15:40:04] [config]   []
[2019-08-07 15:40:04] [config] overwrite: false
[2019-08-07 15:40:04] [config] pretrained-model: ""
[2019-08-07 15:40:04] [config] quiet: false
[2019-08-07 15:40:04] [config] quiet-translation: true
[2019-08-07 15:40:04] [config] relative-paths: false
[2019-08-07 15:40:04] [config] right-left: false
[2019-08-07 15:40:04] [config] save-freq: 20000
[2019-08-07 15:40:04] [config] seed: 1111
[2019-08-07 15:40:04] [config] shuffle-in-ram: false
[2019-08-07 15:40:04] [config] skip: false
[2019-08-07 15:40:04] [config] sqlite: ""
[2019-08-07 15:40:04] [config] sqlite-drop: false
[2019-08-07 15:40:04] [config] sync-sgd: true
[2019-08-07 15:40:04] [config] tempdir: .
[2019-08-07 15:40:04] [config] tied-embeddings: false
[2019-08-07 15:40:04] [config] tied-embeddings-all: false
[2019-08-07 15:40:04] [config] tied-embeddings-src: false
[2019-08-07 15:40:04] [config] train-sets:
[2019-08-07 15:40:04] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/train.bpe.de
[2019-08-07 15:40:04] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/train.bpe.en
[2019-08-07 15:40:04] [config] transformer-aan-activation: swish
[2019-08-07 15:40:04] [config] transformer-aan-depth: 2
[2019-08-07 15:40:04] [config] transformer-aan-nogate: false
[2019-08-07 15:40:04] [config] transformer-decoder-autoreg: self-attention
[2019-08-07 15:40:04] [config] transformer-dim-aan: 2048
[2019-08-07 15:40:04] [config] transformer-dim-ffn: 2048
[2019-08-07 15:40:04] [config] transformer-dropout: 0
[2019-08-07 15:40:04] [config] transformer-dropout-attention: 0
[2019-08-07 15:40:04] [config] transformer-dropout-ffn: 0
[2019-08-07 15:40:04] [config] transformer-ffn-activation: swish
[2019-08-07 15:40:04] [config] transformer-ffn-depth: 2
[2019-08-07 15:40:04] [config] transformer-guided-alignment-layer: last
[2019-08-07 15:40:04] [config] transformer-heads: 8
[2019-08-07 15:40:04] [config] transformer-no-projection: false
[2019-08-07 15:40:04] [config] transformer-postprocess: dan
[2019-08-07 15:40:04] [config] transformer-postprocess-emb: d
[2019-08-07 15:40:04] [config] transformer-preprocess: ""
[2019-08-07 15:40:04] [config] transformer-tied-layers:
[2019-08-07 15:40:04] [config]   []
[2019-08-07 15:40:04] [config] transformer-train-position-embeddings: false
[2019-08-07 15:40:04] [config] type: amun
[2019-08-07 15:40:04] [config] ulr: false
[2019-08-07 15:40:04] [config] ulr-dim-emb: 0
[2019-08-07 15:40:04] [config] ulr-dropout: 0
[2019-08-07 15:40:04] [config] ulr-keys-vectors: ""
[2019-08-07 15:40:04] [config] ulr-query-vectors: ""
[2019-08-07 15:40:04] [config] ulr-softmax-temperature: 1
[2019-08-07 15:40:04] [config] ulr-trainable-transformation: false
[2019-08-07 15:40:04] [config] valid-freq: 20000
[2019-08-07 15:40:04] [config] valid-log: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/valid.log
[2019-08-07 15:40:04] [config] valid-max-length: 1000
[2019-08-07 15:40:04] [config] valid-metrics:
[2019-08-07 15:40:04] [config]   - cross-entropy
[2019-08-07 15:40:04] [config]   - perplexity
[2019-08-07 15:40:04] [config]   - translation
[2019-08-07 15:40:04] [config] valid-mini-batch: 8
[2019-08-07 15:40:04] [config] valid-script-path: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/score-dev.sh
[2019-08-07 15:40:04] [config] valid-sets:
[2019-08-07 15:40:04] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/dev.bpe.de
[2019-08-07 15:40:04] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/dev.bpe.en
[2019-08-07 15:40:04] [config] valid-translation-output: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/dev.out
[2019-08-07 15:40:04] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 15:40:04] [config] vocabs:
[2019-08-07 15:40:04] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/train.bpe.de.json
[2019-08-07 15:40:04] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/train.bpe.en.json
[2019-08-07 15:40:04] [config] word-penalty: 0
[2019-08-07 15:40:04] [config] workspace: 3000
[2019-08-07 15:40:04] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 15:40:04] Using synchronous training
[2019-08-07 15:40:04] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/train.bpe.de.json
[2019-08-07 15:40:04] [data] Using unused word id eos for 0
[2019-08-07 15:40:04] [data] Using unused word id UNK for 1
[2019-08-07 15:40:04] [data] Setting vocabulary size for input 0 to 50000
[2019-08-07 15:40:04] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/data/train.bpe.en.json
[2019-08-07 15:40:04] [data] Using unused word id eos for 0
[2019-08-07 15:40:04] [data] Using unused word id UNK for 1
[2019-08-07 15:40:04] [data] Setting vocabulary size for input 1 to 50000
[2019-08-07 15:40:05] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-07 15:40:05] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-07 15:40:06] [memory] Extending reserved space to 3072 MB (device gpu6)
[2019-08-07 15:40:06] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 15:40:06] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 15:40:06] [training] Using 1 GPUs
[2019-08-07 15:40:06] [memory] Reserving 422 MB, device gpu6
[2019-08-07 15:40:06] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-07 15:40:06] [memory] Reserving 422 MB, device gpu6
[2019-08-07 15:40:09] [batching] Done. Typical MB size is 4042 target words
[2019-08-07 15:40:09] [memory] Extending reserved space to 3072 MB (device gpu6)
[2019-08-07 15:40:09] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 15:40:09] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 15:40:09] [training] Using 1 GPUs
[2019-08-07 15:40:09] Loading model from ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz.orig.npz
[2019-08-07 15:40:19] Loading Adam parameters from ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz.optimizer.npz
[2019-08-07 15:40:31] [memory] Reserving 844 MB, device gpu6
[2019-08-07 15:40:32] [training] Model reloaded from ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 15:40:32] [data] Restoring the corpus state to epoch 6, batch 240000
[2019-08-07 15:40:32] [data] Shuffling data
[2019-08-07 15:40:46] [data] Done reading 5469066 sentences
[2019-08-07 15:41:13] [data] Done shuffling 5469066 sentences to temp files
[2019-08-07 15:43:15] Training started
[2019-08-07 15:43:15] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-07 15:43:15] [memory] Reserving 422 MB, device gpu6
[2019-08-07 15:43:15] [memory] Reserving 422 MB, device gpu6
[2019-08-07 15:43:15] Loading model from ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.25_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 15:43:22] [memory] Reserving 422 MB, device cpu0
[2019-08-07 15:43:23] [memory] Reserving 422 MB, device gpu6
[2019-08-07 15:48:40] Ep. 6 : Up. 242000 : Sen. 4,108,800 : Cost 37.81934357 : Time 515.14s : 9660.35 words/s
[2019-08-07 15:53:58] Ep. 6 : Up. 244000 : Sen. 4,343,006 : Cost 37.48714828 : Time 318.71s : 15642.81 words/s
