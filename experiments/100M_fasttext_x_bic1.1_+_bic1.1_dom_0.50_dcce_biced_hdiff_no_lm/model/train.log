[2019-08-07 00:00:34] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 00:00:34] [marian] Running on bil as process 190110 with command line:
[2019-08-07 00:00:34] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz -T . --devices 7 --train-sets ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/train.bpe.de ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/train.bpe.en --vocabs ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/train.bpe.de.json ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/dev.bpe.de ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/dev.out --valid-script-path ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/train.log --valid-log ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/valid.log
[2019-08-07 00:00:34] [config] after-batches: 0
[2019-08-07 00:00:34] [config] after-epochs: 0
[2019-08-07 00:00:34] [config] allow-unk: false
[2019-08-07 00:00:34] [config] beam-size: 12
[2019-08-07 00:00:34] [config] bert-class-symbol: "[CLS]"
[2019-08-07 00:00:34] [config] bert-mask-symbol: "[MASK]"
[2019-08-07 00:00:34] [config] bert-masking-fraction: 0.15
[2019-08-07 00:00:34] [config] bert-sep-symbol: "[SEP]"
[2019-08-07 00:00:34] [config] bert-train-type-embeddings: true
[2019-08-07 00:00:34] [config] bert-type-vocab-size: 2
[2019-08-07 00:00:34] [config] best-deep: false
[2019-08-07 00:00:34] [config] clip-gemm: 0
[2019-08-07 00:00:34] [config] clip-norm: 1
[2019-08-07 00:00:34] [config] cost-type: ce-mean
[2019-08-07 00:00:34] [config] cpu-threads: 0
[2019-08-07 00:00:34] [config] data-weighting: ""
[2019-08-07 00:00:34] [config] data-weighting-type: sentence
[2019-08-07 00:00:34] [config] dec-cell: gru
[2019-08-07 00:00:34] [config] dec-cell-base-depth: 2
[2019-08-07 00:00:34] [config] dec-cell-high-depth: 1
[2019-08-07 00:00:34] [config] dec-depth: 1
[2019-08-07 00:00:34] [config] devices:
[2019-08-07 00:00:34] [config]   - 7
[2019-08-07 00:00:34] [config] dim-emb: 512
[2019-08-07 00:00:34] [config] dim-rnn: 1024
[2019-08-07 00:00:34] [config] dim-vocabs:
[2019-08-07 00:00:34] [config]   - 50000
[2019-08-07 00:00:34] [config]   - 50000
[2019-08-07 00:00:34] [config] disp-first: 0
[2019-08-07 00:00:34] [config] disp-freq: 2000
[2019-08-07 00:00:34] [config] disp-label-counts: false
[2019-08-07 00:00:34] [config] dropout-rnn: 0.2
[2019-08-07 00:00:34] [config] dropout-src: 0.1
[2019-08-07 00:00:34] [config] dropout-trg: 0.1
[2019-08-07 00:00:34] [config] dump-config: ""
[2019-08-07 00:00:34] [config] early-stopping: 5
[2019-08-07 00:00:34] [config] embedding-fix-src: false
[2019-08-07 00:00:34] [config] embedding-fix-trg: false
[2019-08-07 00:00:34] [config] embedding-normalization: false
[2019-08-07 00:00:34] [config] embedding-vectors:
[2019-08-07 00:00:34] [config]   []
[2019-08-07 00:00:34] [config] enc-cell: gru
[2019-08-07 00:00:34] [config] enc-cell-depth: 1
[2019-08-07 00:00:34] [config] enc-depth: 1
[2019-08-07 00:00:34] [config] enc-type: bidirectional
[2019-08-07 00:00:34] [config] exponential-smoothing: 0.0001
[2019-08-07 00:00:34] [config] grad-dropping-momentum: 0
[2019-08-07 00:00:34] [config] grad-dropping-rate: 0
[2019-08-07 00:00:34] [config] grad-dropping-warmup: 100
[2019-08-07 00:00:34] [config] guided-alignment: none
[2019-08-07 00:00:34] [config] guided-alignment-cost: mse
[2019-08-07 00:00:34] [config] guided-alignment-weight: 0.1
[2019-08-07 00:00:34] [config] ignore-model-config: false
[2019-08-07 00:00:34] [config] input-types:
[2019-08-07 00:00:34] [config]   []
[2019-08-07 00:00:34] [config] interpolate-env-vars: false
[2019-08-07 00:00:34] [config] keep-best: false
[2019-08-07 00:00:34] [config] label-smoothing: 0
[2019-08-07 00:00:34] [config] layer-normalization: true
[2019-08-07 00:00:34] [config] learn-rate: 0.0001
[2019-08-07 00:00:34] [config] log: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/train.log
[2019-08-07 00:00:34] [config] log-level: info
[2019-08-07 00:00:34] [config] log-time-zone: ""
[2019-08-07 00:00:34] [config] lr-decay: 0
[2019-08-07 00:00:34] [config] lr-decay-freq: 50000
[2019-08-07 00:00:34] [config] lr-decay-inv-sqrt:
[2019-08-07 00:00:34] [config]   - 0
[2019-08-07 00:00:34] [config] lr-decay-repeat-warmup: false
[2019-08-07 00:00:34] [config] lr-decay-reset-optimizer: false
[2019-08-07 00:00:34] [config] lr-decay-start:
[2019-08-07 00:00:34] [config]   - 10
[2019-08-07 00:00:34] [config]   - 1
[2019-08-07 00:00:34] [config] lr-decay-strategy: epoch+stalled
[2019-08-07 00:00:34] [config] lr-report: false
[2019-08-07 00:00:34] [config] lr-warmup: 0
[2019-08-07 00:00:34] [config] lr-warmup-at-reload: false
[2019-08-07 00:00:34] [config] lr-warmup-cycle: false
[2019-08-07 00:00:34] [config] lr-warmup-start-rate: 0
[2019-08-07 00:00:34] [config] max-length: 50
[2019-08-07 00:00:34] [config] max-length-crop: false
[2019-08-07 00:00:34] [config] max-length-factor: 3
[2019-08-07 00:00:34] [config] maxi-batch: 100
[2019-08-07 00:00:34] [config] maxi-batch-sort: trg
[2019-08-07 00:00:34] [config] mini-batch: 64
[2019-08-07 00:00:34] [config] mini-batch-fit: true
[2019-08-07 00:00:34] [config] mini-batch-fit-step: 10
[2019-08-07 00:00:34] [config] mini-batch-overstuff: 1
[2019-08-07 00:00:34] [config] mini-batch-track-lr: false
[2019-08-07 00:00:34] [config] mini-batch-understuff: 1
[2019-08-07 00:00:34] [config] mini-batch-warmup: 0
[2019-08-07 00:00:34] [config] mini-batch-words: 0
[2019-08-07 00:00:34] [config] mini-batch-words-ref: 0
[2019-08-07 00:00:34] [config] model: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 00:00:34] [config] multi-loss-type: sum
[2019-08-07 00:00:34] [config] multi-node: false
[2019-08-07 00:00:34] [config] multi-node-overlap: true
[2019-08-07 00:00:34] [config] n-best: false
[2019-08-07 00:00:34] [config] no-nccl: false
[2019-08-07 00:00:34] [config] no-reload: false
[2019-08-07 00:00:34] [config] no-restore-corpus: false
[2019-08-07 00:00:34] [config] no-shuffle: false
[2019-08-07 00:00:34] [config] normalize: 1
[2019-08-07 00:00:34] [config] num-devices: 0
[2019-08-07 00:00:34] [config] optimizer: adam
[2019-08-07 00:00:34] [config] optimizer-delay: 1
[2019-08-07 00:00:34] [config] optimizer-params:
[2019-08-07 00:00:34] [config]   []
[2019-08-07 00:00:34] [config] overwrite: false
[2019-08-07 00:00:34] [config] pretrained-model: ""
[2019-08-07 00:00:34] [config] quiet: false
[2019-08-07 00:00:34] [config] quiet-translation: true
[2019-08-07 00:00:34] [config] relative-paths: false
[2019-08-07 00:00:34] [config] right-left: false
[2019-08-07 00:00:34] [config] save-freq: 20000
[2019-08-07 00:00:34] [config] seed: 1111
[2019-08-07 00:00:34] [config] shuffle-in-ram: false
[2019-08-07 00:00:34] [config] skip: false
[2019-08-07 00:00:34] [config] sqlite: ""
[2019-08-07 00:00:34] [config] sqlite-drop: false
[2019-08-07 00:00:34] [config] sync-sgd: true
[2019-08-07 00:00:34] [config] tempdir: .
[2019-08-07 00:00:34] [config] tied-embeddings: false
[2019-08-07 00:00:34] [config] tied-embeddings-all: false
[2019-08-07 00:00:34] [config] tied-embeddings-src: false
[2019-08-07 00:00:34] [config] train-sets:
[2019-08-07 00:00:34] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/train.bpe.de
[2019-08-07 00:00:34] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/train.bpe.en
[2019-08-07 00:00:34] [config] transformer-aan-activation: swish
[2019-08-07 00:00:34] [config] transformer-aan-depth: 2
[2019-08-07 00:00:34] [config] transformer-aan-nogate: false
[2019-08-07 00:00:34] [config] transformer-decoder-autoreg: self-attention
[2019-08-07 00:00:34] [config] transformer-dim-aan: 2048
[2019-08-07 00:00:34] [config] transformer-dim-ffn: 2048
[2019-08-07 00:00:34] [config] transformer-dropout: 0
[2019-08-07 00:00:34] [config] transformer-dropout-attention: 0
[2019-08-07 00:00:34] [config] transformer-dropout-ffn: 0
[2019-08-07 00:00:34] [config] transformer-ffn-activation: swish
[2019-08-07 00:00:34] [config] transformer-ffn-depth: 2
[2019-08-07 00:00:34] [config] transformer-guided-alignment-layer: last
[2019-08-07 00:00:34] [config] transformer-heads: 8
[2019-08-07 00:00:34] [config] transformer-no-projection: false
[2019-08-07 00:00:34] [config] transformer-postprocess: dan
[2019-08-07 00:00:34] [config] transformer-postprocess-emb: d
[2019-08-07 00:00:34] [config] transformer-preprocess: ""
[2019-08-07 00:00:34] [config] transformer-tied-layers:
[2019-08-07 00:00:34] [config]   []
[2019-08-07 00:00:34] [config] transformer-train-position-embeddings: false
[2019-08-07 00:00:34] [config] type: amun
[2019-08-07 00:00:34] [config] ulr: false
[2019-08-07 00:00:34] [config] ulr-dim-emb: 0
[2019-08-07 00:00:34] [config] ulr-dropout: 0
[2019-08-07 00:00:34] [config] ulr-keys-vectors: ""
[2019-08-07 00:00:34] [config] ulr-query-vectors: ""
[2019-08-07 00:00:34] [config] ulr-softmax-temperature: 1
[2019-08-07 00:00:34] [config] ulr-trainable-transformation: false
[2019-08-07 00:00:34] [config] valid-freq: 20000
[2019-08-07 00:00:34] [config] valid-log: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/valid.log
[2019-08-07 00:00:34] [config] valid-max-length: 1000
[2019-08-07 00:00:34] [config] valid-metrics:
[2019-08-07 00:00:34] [config]   - cross-entropy
[2019-08-07 00:00:34] [config]   - perplexity
[2019-08-07 00:00:34] [config]   - translation
[2019-08-07 00:00:34] [config] valid-mini-batch: 8
[2019-08-07 00:00:34] [config] valid-script-path: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/score-dev.sh
[2019-08-07 00:00:34] [config] valid-sets:
[2019-08-07 00:00:34] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/dev.bpe.de
[2019-08-07 00:00:34] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/dev.bpe.en
[2019-08-07 00:00:34] [config] valid-translation-output: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/dev.out
[2019-08-07 00:00:34] [config] vocabs:
[2019-08-07 00:00:34] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/train.bpe.de.json
[2019-08-07 00:00:34] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/train.bpe.en.json
[2019-08-07 00:00:34] [config] word-penalty: 0
[2019-08-07 00:00:34] [config] workspace: 3000
[2019-08-07 00:00:34] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 00:00:34] Using synchronous training
[2019-08-07 00:00:34] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/train.bpe.de.json
[2019-08-07 00:00:35] [data] Using unused word id eos for 0
[2019-08-07 00:00:35] [data] Using unused word id UNK for 1
[2019-08-07 00:00:35] [data] Setting vocabulary size for input 0 to 50000
[2019-08-07 00:00:35] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/train.bpe.en.json
[2019-08-07 00:00:35] [data] Using unused word id eos for 0
[2019-08-07 00:00:35] [data] Using unused word id UNK for 1
[2019-08-07 00:00:35] [data] Setting vocabulary size for input 1 to 50000
[2019-08-07 00:00:35] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-07 00:00:35] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-07 00:00:36] [memory] Extending reserved space to 3072 MB (device gpu7)
[2019-08-07 00:00:36] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 00:00:37] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 00:00:37] [training] Using 1 GPUs
[2019-08-07 00:00:37] [memory] Reserving 422 MB, device gpu7
[2019-08-07 00:00:37] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-07 00:00:37] [memory] Reserving 422 MB, device gpu7
[2019-08-07 00:00:39] [batching] Done. Typical MB size is 4042 target words
[2019-08-07 00:00:39] [memory] Extending reserved space to 3072 MB (device gpu7)
[2019-08-07 00:00:39] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 00:00:39] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 00:00:39] [training] Using 1 GPUs
[2019-08-07 00:00:39] Training started
[2019-08-07 00:00:39] [data] Shuffling data
[2019-08-07 00:00:43] [data] Done reading 5229931 sentences
[2019-08-07 00:01:08] [data] Done shuffling 5229931 sentences to temp files
[2019-08-07 00:01:09] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-07 00:01:09] [memory] Reserving 422 MB, device gpu7
[2019-08-07 00:01:09] [memory] Reserving 422 MB, device gpu7
[2019-08-07 00:01:09] [memory] Reserving 422 MB, device gpu7
[2019-08-07 00:01:09] [memory] Reserving 844 MB, device gpu7
[2019-08-07 00:06:37] Ep. 1 : Up. 2000 : Sen. 229,280 : Cost 135.79214478 : Time 361.75s : 13860.12 words/s
[2019-08-07 00:12:05] Ep. 1 : Up. 4000 : Sen. 457,402 : Cost 107.89965820 : Time 327.87s : 15221.66 words/s
[2019-08-07 00:17:33] Ep. 1 : Up. 6000 : Sen. 685,812 : Cost 92.66709137 : Time 328.79s : 15212.37 words/s
[2019-08-07 00:23:02] Ep. 1 : Up. 8000 : Sen. 914,376 : Cost 82.78683472 : Time 328.81s : 15211.08 words/s
[2019-08-07 00:28:31] Ep. 1 : Up. 10000 : Sen. 1,142,458 : Cost 76.24276733 : Time 328.72s : 15219.10 words/s
[2019-08-07 00:34:00] Ep. 1 : Up. 12000 : Sen. 1,371,733 : Cost 71.65660095 : Time 329.19s : 15228.46 words/s
[2019-08-07 00:39:28] Ep. 1 : Up. 14000 : Sen. 1,600,957 : Cost 68.00974274 : Time 328.25s : 15249.38 words/s
[2019-08-07 00:44:57] Ep. 1 : Up. 16000 : Sen. 1,829,637 : Cost 65.46048737 : Time 328.86s : 15209.49 words/s
[2019-08-07 00:50:27] Ep. 1 : Up. 18000 : Sen. 2,057,678 : Cost 63.66011047 : Time 330.24s : 15188.95 words/s
[2019-08-07 00:55:56] Ep. 1 : Up. 20000 : Sen. 2,287,181 : Cost 61.46319580 : Time 328.75s : 15247.26 words/s
[2019-08-07 00:55:56] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz.orig.npz
[2019-08-07 00:56:01] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.iter20000.npz
[2019-08-07 00:56:03] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 00:56:08] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz.optimizer.npz
[2019-08-07 00:56:24] [valid] Ep. 1 : Up. 20000 : cross-entropy : 68.2788 : new best
[2019-08-07 00:56:31] [valid] Ep. 1 : Up. 20000 : perplexity : 14.5918 : new best
[2019-08-07 00:57:33] [valid] Ep. 1 : Up. 20000 : translation : 16.67 : new best
[2019-08-07 01:03:04] Ep. 1 : Up. 22000 : Sen. 2,515,065 : Cost 60.44520187 : Time 427.59s : 11673.25 words/s
[2019-08-07 01:08:34] Ep. 1 : Up. 24000 : Sen. 2,743,443 : Cost 59.08551788 : Time 330.18s : 15161.19 words/s
[2019-08-07 01:14:00] Ep. 1 : Up. 26000 : Sen. 2,971,932 : Cost 57.74978638 : Time 326.08s : 15323.74 words/s
[2019-08-07 01:19:30] Ep. 1 : Up. 28000 : Sen. 3,200,789 : Cost 57.16077042 : Time 329.62s : 15237.38 words/s
[2019-08-07 01:24:57] Ep. 1 : Up. 30000 : Sen. 3,429,341 : Cost 56.16430283 : Time 327.12s : 15258.36 words/s
[2019-08-07 01:30:25] Ep. 1 : Up. 32000 : Sen. 3,657,517 : Cost 55.74130630 : Time 328.18s : 15246.03 words/s
[2019-08-07 01:35:53] Ep. 1 : Up. 34000 : Sen. 3,885,844 : Cost 54.97445679 : Time 328.29s : 15262.04 words/s
[2019-08-07 01:41:19] Ep. 1 : Up. 36000 : Sen. 4,113,950 : Cost 53.96516418 : Time 325.79s : 15321.82 words/s
[2019-08-07 01:46:45] Ep. 1 : Up. 38000 : Sen. 4,341,997 : Cost 53.29179382 : Time 325.55s : 15319.69 words/s
[2019-08-07 01:51:13] Seen 4528921 samples
[2019-08-07 01:51:13] Starting epoch 2
[2019-08-07 01:51:13] [data] Shuffling data
[2019-08-07 01:51:16] [data] Done reading 5229931 sentences
[2019-08-07 01:51:40] [data] Done shuffling 5229931 sentences to temp files
[2019-08-07 01:52:40] Ep. 2 : Up. 40000 : Sen. 41,404 : Cost 52.92639923 : Time 355.76s : 14050.03 words/s
[2019-08-07 01:52:40] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz.orig.npz
[2019-08-07 01:52:46] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.iter40000.npz
[2019-08-07 01:52:48] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 01:52:54] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz.optimizer.npz
[2019-08-07 01:53:14] [valid] Ep. 2 : Up. 40000 : cross-entropy : 55.9532 : new best
[2019-08-07 01:53:20] [valid] Ep. 2 : Up. 40000 : perplexity : 8.99424 : new best
[2019-08-07 01:54:19] [valid] Ep. 2 : Up. 40000 : translation : 21.54 : new best
[2019-08-07 01:59:47] Ep. 2 : Up. 42000 : Sen. 269,873 : Cost 51.82946014 : Time 426.50s : 11736.53 words/s
[2019-08-07 02:05:12] Ep. 2 : Up. 44000 : Sen. 498,389 : Cost 51.01514053 : Time 324.83s : 15391.57 words/s
[2019-08-07 02:10:38] Ep. 2 : Up. 46000 : Sen. 728,027 : Cost 50.65983582 : Time 325.97s : 15397.27 words/s
[2019-08-07 02:16:03] Ep. 2 : Up. 48000 : Sen. 957,654 : Cost 50.43260193 : Time 325.59s : 15414.22 words/s
[2019-08-07 02:21:28] Ep. 2 : Up. 50000 : Sen. 1,185,581 : Cost 50.05192566 : Time 325.20s : 15359.23 words/s
[2019-08-07 02:26:53] Ep. 2 : Up. 52000 : Sen. 1,414,740 : Cost 49.51336288 : Time 324.74s : 15414.35 words/s
[2019-08-07 02:32:18] Ep. 2 : Up. 54000 : Sen. 1,643,380 : Cost 49.44710159 : Time 325.13s : 15415.03 words/s
[2019-08-07 02:37:45] Ep. 2 : Up. 56000 : Sen. 1,873,212 : Cost 49.19338226 : Time 326.53s : 15396.04 words/s
[2019-08-07 02:43:09] Ep. 2 : Up. 58000 : Sen. 2,101,740 : Cost 48.86090851 : Time 324.23s : 15416.55 words/s
[2019-08-07 02:48:34] Ep. 2 : Up. 60000 : Sen. 2,330,481 : Cost 48.74391174 : Time 325.33s : 15423.10 words/s
[2019-08-07 02:48:34] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz.orig.npz
[2019-08-07 02:48:40] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.iter60000.npz
[2019-08-07 02:48:43] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 02:48:49] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz.optimizer.npz
[2019-08-07 02:49:08] [valid] Ep. 2 : Up. 60000 : cross-entropy : 51.0464 : new best
[2019-08-07 02:49:15] [valid] Ep. 2 : Up. 60000 : perplexity : 7.41833 : new best
[2019-08-07 02:50:13] [valid] Ep. 2 : Up. 60000 : translation : 23.97 : new best
[2019-08-07 02:55:39] Ep. 2 : Up. 62000 : Sen. 2,557,776 : Cost 48.60935974 : Time 424.95s : 11742.53 words/s
[2019-08-07 03:01:04] Ep. 2 : Up. 64000 : Sen. 2,786,549 : Cost 48.10951614 : Time 324.80s : 15404.83 words/s
[2019-08-07 03:06:29] Ep. 2 : Up. 66000 : Sen. 3,014,400 : Cost 47.80658340 : Time 324.82s : 15342.33 words/s
[2019-08-07 03:11:55] Ep. 2 : Up. 68000 : Sen. 3,242,661 : Cost 47.86918640 : Time 325.65s : 15367.17 words/s
[2019-08-07 03:17:21] Ep. 2 : Up. 70000 : Sen. 3,472,000 : Cost 47.59642029 : Time 326.24s : 15383.21 words/s
[2019-08-07 03:22:46] Ep. 2 : Up. 72000 : Sen. 3,701,017 : Cost 47.48936462 : Time 325.46s : 15423.95 words/s
[2019-08-07 03:28:11] Ep. 2 : Up. 74000 : Sen. 3,929,387 : Cost 47.07557297 : Time 324.86s : 15378.63 words/s
[2019-08-07 03:33:38] Ep. 2 : Up. 76000 : Sen. 4,156,708 : Cost 46.90433502 : Time 326.44s : 15260.67 words/s
[2019-08-07 03:39:05] Ep. 2 : Up. 78000 : Sen. 4,385,450 : Cost 46.73633194 : Time 326.89s : 15308.60 words/s
[2019-08-07 03:42:30] Seen 4528921 samples
[2019-08-07 03:42:30] Starting epoch 3
[2019-08-07 03:42:30] [data] Shuffling data
[2019-08-07 03:42:33] [data] Done reading 5229931 sentences
[2019-08-07 03:42:57] [data] Done shuffling 5229931 sentences to temp files
[2019-08-07 03:45:00] Ep. 3 : Up. 80000 : Sen. 84,880 : Cost 46.29723358 : Time 355.71s : 14091.95 words/s
[2019-08-07 03:45:00] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz.orig.npz
[2019-08-07 03:45:06] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.iter80000.npz
[2019-08-07 03:45:08] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 03:45:14] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz.optimizer.npz
[2019-08-07 03:45:33] [valid] Ep. 3 : Up. 80000 : cross-entropy : 48.1169 : new best
[2019-08-07 03:45:39] [valid] Ep. 3 : Up. 80000 : perplexity : 6.61242 : new best
[2019-08-07 03:46:35] [valid] Ep. 3 : Up. 80000 : translation : 25.33 : new best
[2019-08-07 03:52:03] Ep. 3 : Up. 82000 : Sen. 313,047 : Cost 45.69966125 : Time 422.90s : 11827.00 words/s
[2019-08-07 03:57:28] Ep. 3 : Up. 84000 : Sen. 541,318 : Cost 45.67197037 : Time 325.36s : 15367.63 words/s
[2019-08-07 04:02:53] Ep. 3 : Up. 86000 : Sen. 769,475 : Cost 45.21456528 : Time 324.66s : 15383.73 words/s
[2019-08-07 04:08:18] Ep. 3 : Up. 88000 : Sen. 997,756 : Cost 45.15167236 : Time 324.75s : 15411.45 words/s
[2019-08-07 04:13:44] Ep. 3 : Up. 90000 : Sen. 1,227,535 : Cost 45.13949585 : Time 326.50s : 15407.76 words/s
[2019-08-07 04:19:09] Ep. 3 : Up. 92000 : Sen. 1,456,017 : Cost 45.11696243 : Time 324.62s : 15401.00 words/s
[2019-08-07 04:24:34] Ep. 3 : Up. 94000 : Sen. 1,684,730 : Cost 44.65015793 : Time 324.95s : 15382.82 words/s
[2019-08-07 04:30:00] Ep. 3 : Up. 96000 : Sen. 1,912,884 : Cost 44.91451263 : Time 326.05s : 15357.26 words/s
[2019-08-07 04:35:24] Ep. 3 : Up. 98000 : Sen. 2,140,580 : Cost 44.62891769 : Time 323.97s : 15393.34 words/s
[2019-08-07 04:40:49] Ep. 3 : Up. 100000 : Sen. 2,369,120 : Cost 44.76736832 : Time 324.64s : 15422.40 words/s
[2019-08-07 04:40:49] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz.orig.npz
[2019-08-07 04:40:54] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.iter100000.npz
[2019-08-07 04:40:56] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 04:41:02] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz.optimizer.npz
[2019-08-07 04:41:21] [valid] Ep. 3 : Up. 100000 : cross-entropy : 46.3171 : new best
[2019-08-07 04:41:27] [valid] Ep. 3 : Up. 100000 : perplexity : 6.16134 : new best
[2019-08-07 04:42:23] [valid] Ep. 3 : Up. 100000 : translation : 25.99 : new best
[2019-08-07 04:47:50] Ep. 3 : Up. 102000 : Sen. 2,598,016 : Cost 44.66605759 : Time 421.87s : 11859.40 words/s
[2019-08-07 04:53:17] Ep. 3 : Up. 104000 : Sen. 2,827,093 : Cost 44.58205032 : Time 326.04s : 15404.27 words/s
[2019-08-07 04:58:41] Ep. 3 : Up. 106000 : Sen. 3,055,395 : Cost 44.37397766 : Time 324.63s : 15397.35 words/s
[2019-08-07 05:04:07] Ep. 3 : Up. 108000 : Sen. 3,283,413 : Cost 44.36695099 : Time 325.38s : 15336.01 words/s
[2019-08-07 05:09:31] Ep. 3 : Up. 110000 : Sen. 3,511,581 : Cost 44.06534958 : Time 324.62s : 15379.15 words/s
[2019-08-07 05:14:57] Ep. 3 : Up. 112000 : Sen. 3,740,774 : Cost 44.07104492 : Time 326.07s : 15364.70 words/s
[2019-08-07 05:20:21] Ep. 3 : Up. 114000 : Sen. 3,968,000 : Cost 44.14222717 : Time 324.13s : 15362.15 words/s
[2019-08-07 05:25:46] Ep. 3 : Up. 116000 : Sen. 4,196,700 : Cost 44.02793884 : Time 324.58s : 15423.76 words/s
[2019-08-07 05:31:10] Ep. 3 : Up. 118000 : Sen. 4,424,802 : Cost 43.62019348 : Time 323.87s : 15404.84 words/s
[2019-08-07 05:33:38] Seen 4528921 samples
[2019-08-07 05:33:38] Starting epoch 4
[2019-08-07 05:33:38] [data] Shuffling data
[2019-08-07 05:33:42] [data] Done reading 5229931 sentences
[2019-08-07 05:34:04] [data] Done shuffling 5229931 sentences to temp files
[2019-08-07 05:37:01] Ep. 4 : Up. 120000 : Sen. 123,166 : Cost 43.17081070 : Time 351.60s : 14133.25 words/s
[2019-08-07 05:37:01] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz.orig.npz
[2019-08-07 05:37:07] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.iter120000.npz
[2019-08-07 05:37:10] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 05:37:16] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz.optimizer.npz
[2019-08-07 05:37:35] [valid] Ep. 4 : Up. 120000 : cross-entropy : 44.8581 : new best
[2019-08-07 05:37:42] [valid] Ep. 4 : Up. 120000 : perplexity : 5.81836 : new best
[2019-08-07 05:38:37] [valid] Ep. 4 : Up. 120000 : translation : 26.79 : new best
[2019-08-07 05:44:03] Ep. 4 : Up. 122000 : Sen. 351,440 : Cost 42.74105072 : Time 421.43s : 11880.33 words/s
[2019-08-07 05:49:26] Ep. 4 : Up. 124000 : Sen. 580,452 : Cost 42.48566818 : Time 323.56s : 15462.47 words/s
[2019-08-07 05:54:51] Ep. 4 : Up. 126000 : Sen. 809,113 : Cost 42.72658920 : Time 324.77s : 15437.05 words/s
[2019-08-07 06:00:16] Ep. 4 : Up. 128000 : Sen. 1,037,620 : Cost 42.63462830 : Time 324.58s : 15432.45 words/s
[2019-08-07 06:05:39] Ep. 4 : Up. 130000 : Sen. 1,265,602 : Cost 42.44771576 : Time 323.62s : 15433.61 words/s
[2019-08-07 06:11:02] Ep. 4 : Up. 132000 : Sen. 1,494,574 : Cost 42.44655609 : Time 322.92s : 15474.63 words/s
[2019-08-07 06:16:27] Ep. 4 : Up. 134000 : Sen. 1,723,995 : Cost 42.68219376 : Time 324.88s : 15486.30 words/s
[2019-08-07 06:21:51] Ep. 4 : Up. 136000 : Sen. 1,952,180 : Cost 42.32781219 : Time 323.35s : 15429.04 words/s
[2019-08-07 06:27:14] Ep. 4 : Up. 138000 : Sen. 2,180,168 : Cost 42.37250900 : Time 323.74s : 15432.64 words/s
[2019-08-07 06:32:38] Ep. 4 : Up. 140000 : Sen. 2,408,571 : Cost 42.25388718 : Time 323.52s : 15449.11 words/s
[2019-08-07 06:32:38] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz.orig.npz
[2019-08-07 06:32:43] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.iter140000.npz
[2019-08-07 06:32:45] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 06:32:51] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz.optimizer.npz
[2019-08-07 06:33:09] [valid] Ep. 4 : Up. 140000 : cross-entropy : 43.9391 : new best
[2019-08-07 06:33:16] [valid] Ep. 4 : Up. 140000 : perplexity : 5.61218 : new best
[2019-08-07 06:34:13] [valid] Ep. 4 : Up. 140000 : translation : 27.26 : new best
[2019-08-07 06:39:40] Ep. 4 : Up. 142000 : Sen. 2,636,800 : Cost 42.34393692 : Time 422.13s : 11825.27 words/s
[2019-08-07 06:45:05] Ep. 4 : Up. 144000 : Sen. 2,865,535 : Cost 42.26700592 : Time 325.14s : 15397.93 words/s
[2019-08-07 06:50:30] Ep. 4 : Up. 146000 : Sen. 3,093,591 : Cost 42.32425690 : Time 325.20s : 15365.75 words/s
[2019-08-07 06:55:56] Ep. 4 : Up. 148000 : Sen. 3,322,602 : Cost 42.14131165 : Time 325.61s : 15352.03 words/s
[2019-08-07 07:01:23] Ep. 4 : Up. 150000 : Sen. 3,551,045 : Cost 42.19914246 : Time 326.74s : 15346.70 words/s
[2019-08-07 07:06:49] Ep. 4 : Up. 152000 : Sen. 3,779,676 : Cost 41.82427979 : Time 326.28s : 15330.34 words/s
[2019-08-07 07:12:17] Ep. 4 : Up. 154000 : Sen. 4,007,987 : Cost 42.13200378 : Time 327.92s : 15259.07 words/s
[2019-08-07 07:17:44] Ep. 4 : Up. 156000 : Sen. 4,236,878 : Cost 42.06237793 : Time 326.67s : 15363.90 words/s
[2019-08-07 07:23:10] Ep. 4 : Up. 158000 : Sen. 4,465,616 : Cost 42.02441788 : Time 326.20s : 15351.03 words/s
[2019-08-07 07:24:40] Seen 4528921 samples
[2019-08-07 07:24:40] Starting epoch 5
[2019-08-07 07:24:40] [data] Shuffling data
[2019-08-07 07:24:47] [data] Done reading 5229931 sentences
[2019-08-07 07:25:10] [data] Done shuffling 5229931 sentences to temp files
[2019-08-07 07:29:09] Ep. 5 : Up. 160000 : Sen. 166,061 : Cost 41.08535767 : Time 359.05s : 13942.69 words/s
[2019-08-07 07:29:09] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz.orig.npz
[2019-08-07 07:29:15] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.iter160000.npz
[2019-08-07 07:29:17] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 07:29:22] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz.optimizer.npz
[2019-08-07 07:29:43] [valid] Ep. 5 : Up. 160000 : cross-entropy : 43.1444 : new best
[2019-08-07 07:29:49] [valid] Ep. 5 : Up. 160000 : perplexity : 5.4398 : new best
[2019-08-07 07:30:46] [valid] Ep. 5 : Up. 160000 : translation : 27.66 : new best
[2019-08-07 07:36:13] Ep. 5 : Up. 162000 : Sen. 394,850 : Cost 40.80266953 : Time 423.96s : 11806.65 words/s
[2019-08-07 07:41:38] Ep. 5 : Up. 164000 : Sen. 623,884 : Cost 41.08819580 : Time 325.43s : 15419.80 words/s
[2019-08-07 07:47:01] Ep. 5 : Up. 166000 : Sen. 851,585 : Cost 40.81638718 : Time 322.94s : 15412.27 words/s
[2019-08-07 07:52:26] Ep. 5 : Up. 168000 : Sen. 1,080,081 : Cost 40.94416428 : Time 325.26s : 15397.06 words/s
[2019-08-07 07:57:52] Ep. 5 : Up. 170000 : Sen. 1,309,110 : Cost 40.75358200 : Time 325.27s : 15386.93 words/s
[2019-08-07 08:03:16] Ep. 5 : Up. 172000 : Sen. 1,538,163 : Cost 40.90569687 : Time 323.77s : 15483.22 words/s
[2019-08-07 08:08:39] Ep. 5 : Up. 174000 : Sen. 1,766,400 : Cost 41.21582413 : Time 323.56s : 15482.05 words/s
[2019-08-07 08:14:03] Ep. 5 : Up. 176000 : Sen. 1,994,098 : Cost 41.07239151 : Time 323.98s : 15435.40 words/s
[2019-08-07 08:19:27] Ep. 5 : Up. 178000 : Sen. 2,222,158 : Cost 41.20777512 : Time 323.67s : 15447.79 words/s
[2019-08-07 08:24:51] Ep. 5 : Up. 180000 : Sen. 2,450,550 : Cost 41.16633606 : Time 323.90s : 15440.31 words/s
[2019-08-07 08:24:51] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz.orig.npz
[2019-08-07 08:24:57] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.iter180000.npz
[2019-08-07 08:24:59] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 08:25:05] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz.optimizer.npz
[2019-08-07 08:25:26] [valid] Ep. 5 : Up. 180000 : cross-entropy : 42.6378 : new best
[2019-08-07 08:25:32] [valid] Ep. 5 : Up. 180000 : perplexity : 5.33269 : new best
[2019-08-07 08:26:26] [valid] Ep. 5 : Up. 180000 : translation : 27.89 : new best
[2019-08-07 08:31:51] Ep. 5 : Up. 182000 : Sen. 2,678,725 : Cost 40.87208557 : Time 420.76s : 11873.92 words/s
[2019-08-07 08:37:16] Ep. 5 : Up. 184000 : Sen. 2,907,581 : Cost 40.94869232 : Time 324.16s : 15436.97 words/s
[2019-08-07 08:42:39] Ep. 5 : Up. 186000 : Sen. 3,136,000 : Cost 40.89600754 : Time 323.51s : 15474.16 words/s
[2019-08-07 08:48:02] Ep. 5 : Up. 188000 : Sen. 3,364,396 : Cost 40.81972885 : Time 322.72s : 15470.89 words/s
[2019-08-07 08:53:24] Ep. 5 : Up. 190000 : Sen. 3,591,271 : Cost 41.04406738 : Time 322.07s : 15451.72 words/s
[2019-08-07 08:58:46] Ep. 5 : Up. 192000 : Sen. 3,820,902 : Cost 40.59083939 : Time 322.42s : 15557.34 words/s
[2019-08-07 09:04:12] Ep. 5 : Up. 194000 : Sen. 4,049,299 : Cost 40.72363663 : Time 325.93s : 15328.57 words/s
[2019-08-07 09:09:42] Ep. 5 : Up. 196000 : Sen. 4,277,998 : Cost 40.74893951 : Time 329.50s : 15219.83 words/s
[2019-08-07 09:15:11] Ep. 5 : Up. 198000 : Sen. 4,506,531 : Cost 40.69606400 : Time 328.99s : 15212.91 words/s
[2019-08-07 09:15:43] Seen 4528921 samples
[2019-08-07 09:15:43] Starting epoch 6
[2019-08-07 09:15:43] [data] Shuffling data
[2019-08-07 09:15:50] [data] Done reading 5229931 sentences
[2019-08-07 09:16:16] [data] Done shuffling 5229931 sentences to temp files
[2019-08-07 09:21:14] Ep. 6 : Up. 200000 : Sen. 206,124 : Cost 39.65822220 : Time 362.95s : 13778.38 words/s
[2019-08-07 09:21:14] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz.orig.npz
[2019-08-07 09:21:20] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.iter200000.npz
[2019-08-07 09:21:22] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 09:21:28] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz.optimizer.npz
[2019-08-07 09:21:48] [valid] Ep. 6 : Up. 200000 : cross-entropy : 42.0419 : new best
[2019-08-07 09:21:54] [valid] Ep. 6 : Up. 200000 : perplexity : 5.20937 : new best
[2019-08-07 09:22:53] [valid] Ep. 6 : Up. 200000 : translation : 28.01 : new best
[2019-08-07 09:28:25] Ep. 6 : Up. 202000 : Sen. 434,701 : Cost 39.66723251 : Time 431.20s : 11605.35 words/s
[2019-08-07 09:33:55] Ep. 6 : Up. 204000 : Sen. 662,853 : Cost 39.59952545 : Time 330.56s : 15105.86 words/s
[2019-08-07 09:39:26] Ep. 6 : Up. 206000 : Sen. 892,294 : Cost 39.60803604 : Time 330.32s : 15160.77 words/s
[2019-08-07 09:44:57] Ep. 6 : Up. 208000 : Sen. 1,121,305 : Cost 40.00260544 : Time 331.73s : 15160.34 words/s
[2019-08-07 09:50:28] Ep. 6 : Up. 210000 : Sen. 1,349,835 : Cost 39.71220398 : Time 330.43s : 15127.24 words/s
[2019-08-07 09:55:56] Ep. 6 : Up. 212000 : Sen. 1,578,118 : Cost 39.83063507 : Time 328.46s : 15193.39 words/s
[2019-08-07 10:01:27] Ep. 6 : Up. 214000 : Sen. 1,807,737 : Cost 39.73455048 : Time 330.21s : 15240.18 words/s
[2019-08-07 10:06:56] Ep. 6 : Up. 216000 : Sen. 2,036,146 : Cost 39.83948898 : Time 329.59s : 15171.49 words/s
[2019-08-07 10:12:26] Ep. 6 : Up. 218000 : Sen. 2,264,346 : Cost 40.04851532 : Time 329.60s : 15181.77 words/s
[2019-08-07 10:17:56] Ep. 6 : Up. 220000 : Sen. 2,493,525 : Cost 39.66120911 : Time 330.35s : 15142.64 words/s
[2019-08-07 10:17:56] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz.orig.npz
[2019-08-07 10:18:02] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.iter220000.npz
[2019-08-07 10:18:05] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 10:18:11] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz.optimizer.npz
[2019-08-07 10:18:31] [valid] Ep. 6 : Up. 220000 : cross-entropy : 41.6879 : new best
[2019-08-07 10:18:38] [valid] Ep. 6 : Up. 220000 : perplexity : 5.13748 : new best
[2019-08-07 10:19:37] [valid] Ep. 6 : Up. 220000 : translation : 28.06 : new best
[2019-08-07 10:25:11] Ep. 6 : Up. 222000 : Sen. 2,720,958 : Cost 39.89265442 : Time 435.19s : 11436.99 words/s
[2019-08-07 10:30:45] Ep. 6 : Up. 224000 : Sen. 2,949,299 : Cost 39.96139908 : Time 333.46s : 15001.70 words/s
[2019-08-07 10:36:18] Ep. 6 : Up. 226000 : Sen. 3,178,031 : Cost 39.81920242 : Time 333.59s : 14998.38 words/s
[2019-08-07 10:41:52] Ep. 6 : Up. 228000 : Sen. 3,406,739 : Cost 39.84974670 : Time 334.00s : 14988.80 words/s
[2019-08-07 10:47:28] Ep. 6 : Up. 230000 : Sen. 3,636,086 : Cost 39.97192764 : Time 335.37s : 14982.68 words/s
[2019-08-07 10:53:05] Ep. 6 : Up. 232000 : Sen. 3,864,842 : Cost 39.89316940 : Time 337.09s : 14865.61 words/s
[2019-08-07 10:58:38] Ep. 6 : Up. 234000 : Sen. 4,093,726 : Cost 39.94042969 : Time 333.40s : 15018.11 words/s
[2019-08-07 11:04:12] Ep. 6 : Up. 236000 : Sen. 4,321,691 : Cost 39.84158707 : Time 334.15s : 14972.00 words/s
[2019-08-07 11:09:15] Seen 4528921 samples
[2019-08-07 11:09:15] Starting epoch 7
[2019-08-07 11:09:15] [data] Shuffling data
[2019-08-07 11:09:23] [data] Done reading 5229931 sentences
[2019-08-07 11:09:48] [data] Done shuffling 5229931 sentences to temp files
[2019-08-07 11:10:20] Ep. 7 : Up. 238000 : Sen. 21,328 : Cost 39.52371979 : Time 368.08s : 13606.29 words/s
[2019-08-07 11:15:53] Ep. 7 : Up. 240000 : Sen. 249,600 : Cost 38.67995453 : Time 332.42s : 15026.09 words/s
[2019-08-07 11:15:53] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz.orig.npz
[2019-08-07 11:15:59] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.iter240000.npz
[2019-08-07 11:16:02] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 11:16:08] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz.optimizer.npz
[2019-08-07 11:16:29] [valid] Ep. 7 : Up. 240000 : cross-entropy : 41.2866 : new best
[2019-08-07 11:16:36] [valid] Ep. 7 : Up. 240000 : perplexity : 5.05718 : new best
[2019-08-07 11:17:34] [valid] Ep. 7 : Up. 240000 : translation : 28.23 : new best
[2019-08-07 11:23:09] Ep. 7 : Up. 242000 : Sen. 478,560 : Cost 38.77069855 : Time 435.89s : 11488.89 words/s
[2019-08-07 11:28:40] Ep. 7 : Up. 244000 : Sen. 707,563 : Cost 38.94337463 : Time 331.72s : 15107.79 words/s
[2019-08-07 11:34:12] Ep. 7 : Up. 246000 : Sen. 936,242 : Cost 38.74006271 : Time 331.63s : 15097.77 words/s
[2019-08-07 11:39:43] Ep. 7 : Up. 248000 : Sen. 1,164,986 : Cost 38.67236710 : Time 331.28s : 15077.09 words/s
[2019-08-07 11:45:16] Ep. 7 : Up. 250000 : Sen. 1,393,203 : Cost 39.08639908 : Time 332.18s : 15071.28 words/s
[2019-08-07 11:50:48] Ep. 7 : Up. 252000 : Sen. 1,621,232 : Cost 39.16028976 : Time 332.34s : 15075.52 words/s
[2019-08-07 11:56:18] Ep. 7 : Up. 254000 : Sen. 1,850,135 : Cost 38.94813919 : Time 330.22s : 15122.27 words/s
[2019-08-07 12:01:49] Ep. 7 : Up. 256000 : Sen. 2,078,922 : Cost 39.03393936 : Time 330.37s : 15160.22 words/s
[2019-08-07 15:31:09] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 15:31:09] [marian] Running on bil as process 2986 with command line:
[2019-08-07 15:31:09] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz -T . --devices 7 --train-sets ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/train.bpe.de ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/train.bpe.en --vocabs ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/train.bpe.de.json ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/dev.bpe.de ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/dev.out --valid-script-path ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/train.log --valid-log ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/valid.log
[2019-08-07 15:31:10] [config] after-batches: 0
[2019-08-07 15:31:10] [config] after-epochs: 0
[2019-08-07 15:31:10] [config] allow-unk: false
[2019-08-07 15:31:10] [config] beam-size: 12
[2019-08-07 15:31:10] [config] bert-class-symbol: "[CLS]"
[2019-08-07 15:31:10] [config] bert-mask-symbol: "[MASK]"
[2019-08-07 15:31:10] [config] bert-masking-fraction: 0.15
[2019-08-07 15:31:10] [config] bert-sep-symbol: "[SEP]"
[2019-08-07 15:31:10] [config] bert-train-type-embeddings: true
[2019-08-07 15:31:10] [config] bert-type-vocab-size: 2
[2019-08-07 15:31:10] [config] best-deep: false
[2019-08-07 15:31:10] [config] clip-gemm: 0
[2019-08-07 15:31:10] [config] clip-norm: 1
[2019-08-07 15:31:10] [config] cost-type: ce-mean
[2019-08-07 15:31:10] [config] cpu-threads: 0
[2019-08-07 15:31:10] [config] data-weighting: ""
[2019-08-07 15:31:10] [config] data-weighting-type: sentence
[2019-08-07 15:31:10] [config] dec-cell: gru
[2019-08-07 15:31:10] [config] dec-cell-base-depth: 2
[2019-08-07 15:31:10] [config] dec-cell-high-depth: 1
[2019-08-07 15:31:10] [config] dec-depth: 1
[2019-08-07 15:31:10] [config] devices:
[2019-08-07 15:31:10] [config]   - 7
[2019-08-07 15:31:10] [config] dim-emb: 512
[2019-08-07 15:31:10] [config] dim-rnn: 1024
[2019-08-07 15:31:10] [config] dim-vocabs:
[2019-08-07 15:31:10] [config]   - 50000
[2019-08-07 15:31:10] [config]   - 50000
[2019-08-07 15:31:10] [config] disp-first: 0
[2019-08-07 15:31:10] [config] disp-freq: 2000
[2019-08-07 15:31:10] [config] disp-label-counts: false
[2019-08-07 15:31:10] [config] dropout-rnn: 0.2
[2019-08-07 15:31:10] [config] dropout-src: 0.1
[2019-08-07 15:31:10] [config] dropout-trg: 0.1
[2019-08-07 15:31:10] [config] dump-config: ""
[2019-08-07 15:31:10] [config] early-stopping: 5
[2019-08-07 15:31:10] [config] embedding-fix-src: false
[2019-08-07 15:31:10] [config] embedding-fix-trg: false
[2019-08-07 15:31:10] [config] embedding-normalization: false
[2019-08-07 15:31:10] [config] embedding-vectors:
[2019-08-07 15:31:10] [config]   []
[2019-08-07 15:31:10] [config] enc-cell: gru
[2019-08-07 15:31:10] [config] enc-cell-depth: 1
[2019-08-07 15:31:10] [config] enc-depth: 1
[2019-08-07 15:31:10] [config] enc-type: bidirectional
[2019-08-07 15:31:10] [config] exponential-smoothing: 0.0001
[2019-08-07 15:31:10] [config] grad-dropping-momentum: 0
[2019-08-07 15:31:10] [config] grad-dropping-rate: 0
[2019-08-07 15:31:10] [config] grad-dropping-warmup: 100
[2019-08-07 15:31:10] [config] guided-alignment: none
[2019-08-07 15:31:10] [config] guided-alignment-cost: mse
[2019-08-07 15:31:10] [config] guided-alignment-weight: 0.1
[2019-08-07 15:31:10] [config] ignore-model-config: false
[2019-08-07 15:31:10] [config] input-types:
[2019-08-07 15:31:10] [config]   []
[2019-08-07 15:31:10] [config] interpolate-env-vars: false
[2019-08-07 15:31:10] [config] keep-best: false
[2019-08-07 15:31:10] [config] label-smoothing: 0
[2019-08-07 15:31:10] [config] layer-normalization: true
[2019-08-07 15:31:10] [config] learn-rate: 0.0001
[2019-08-07 15:31:10] [config] log: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/train.log
[2019-08-07 15:31:10] [config] log-level: info
[2019-08-07 15:31:10] [config] log-time-zone: ""
[2019-08-07 15:31:10] [config] lr-decay: 0
[2019-08-07 15:31:10] [config] lr-decay-freq: 50000
[2019-08-07 15:31:10] [config] lr-decay-inv-sqrt:
[2019-08-07 15:31:10] [config]   - 0
[2019-08-07 15:31:10] [config] lr-decay-repeat-warmup: false
[2019-08-07 15:31:10] [config] lr-decay-reset-optimizer: false
[2019-08-07 15:31:10] [config] lr-decay-start:
[2019-08-07 15:31:10] [config]   - 10
[2019-08-07 15:31:10] [config]   - 1
[2019-08-07 15:31:10] [config] lr-decay-strategy: epoch+stalled
[2019-08-07 15:31:10] [config] lr-report: false
[2019-08-07 15:31:10] [config] lr-warmup: 0
[2019-08-07 15:31:10] [config] lr-warmup-at-reload: false
[2019-08-07 15:31:10] [config] lr-warmup-cycle: false
[2019-08-07 15:31:10] [config] lr-warmup-start-rate: 0
[2019-08-07 15:31:10] [config] max-length: 50
[2019-08-07 15:31:10] [config] max-length-crop: false
[2019-08-07 15:31:10] [config] max-length-factor: 3
[2019-08-07 15:31:10] [config] maxi-batch: 100
[2019-08-07 15:31:10] [config] maxi-batch-sort: trg
[2019-08-07 15:31:10] [config] mini-batch: 64
[2019-08-07 15:31:10] [config] mini-batch-fit: true
[2019-08-07 15:31:10] [config] mini-batch-fit-step: 10
[2019-08-07 15:31:10] [config] mini-batch-overstuff: 1
[2019-08-07 15:31:10] [config] mini-batch-track-lr: false
[2019-08-07 15:31:10] [config] mini-batch-understuff: 1
[2019-08-07 15:31:10] [config] mini-batch-warmup: 0
[2019-08-07 15:31:10] [config] mini-batch-words: 0
[2019-08-07 15:31:10] [config] mini-batch-words-ref: 0
[2019-08-07 15:31:10] [config] model: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 15:31:10] [config] multi-loss-type: sum
[2019-08-07 15:31:10] [config] multi-node: false
[2019-08-07 15:31:10] [config] multi-node-overlap: true
[2019-08-07 15:31:10] [config] n-best: false
[2019-08-07 15:31:10] [config] no-nccl: false
[2019-08-07 15:31:10] [config] no-reload: false
[2019-08-07 15:31:10] [config] no-restore-corpus: false
[2019-08-07 15:31:10] [config] no-shuffle: false
[2019-08-07 15:31:10] [config] normalize: 1
[2019-08-07 15:31:10] [config] num-devices: 0
[2019-08-07 15:31:10] [config] optimizer: adam
[2019-08-07 15:31:10] [config] optimizer-delay: 1
[2019-08-07 15:31:10] [config] optimizer-params:
[2019-08-07 15:31:10] [config]   []
[2019-08-07 15:31:10] [config] overwrite: false
[2019-08-07 15:31:10] [config] pretrained-model: ""
[2019-08-07 15:31:10] [config] quiet: false
[2019-08-07 15:31:10] [config] quiet-translation: true
[2019-08-07 15:31:10] [config] relative-paths: false
[2019-08-07 15:31:10] [config] right-left: false
[2019-08-07 15:31:10] [config] save-freq: 20000
[2019-08-07 15:31:10] [config] seed: 1111
[2019-08-07 15:31:10] [config] shuffle-in-ram: false
[2019-08-07 15:31:10] [config] skip: false
[2019-08-07 15:31:10] [config] sqlite: ""
[2019-08-07 15:31:10] [config] sqlite-drop: false
[2019-08-07 15:31:10] [config] sync-sgd: true
[2019-08-07 15:31:10] [config] tempdir: .
[2019-08-07 15:31:10] [config] tied-embeddings: false
[2019-08-07 15:31:10] [config] tied-embeddings-all: false
[2019-08-07 15:31:10] [config] tied-embeddings-src: false
[2019-08-07 15:31:10] [config] train-sets:
[2019-08-07 15:31:10] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/train.bpe.de
[2019-08-07 15:31:10] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/train.bpe.en
[2019-08-07 15:31:10] [config] transformer-aan-activation: swish
[2019-08-07 15:31:10] [config] transformer-aan-depth: 2
[2019-08-07 15:31:10] [config] transformer-aan-nogate: false
[2019-08-07 15:31:10] [config] transformer-decoder-autoreg: self-attention
[2019-08-07 15:31:10] [config] transformer-dim-aan: 2048
[2019-08-07 15:31:10] [config] transformer-dim-ffn: 2048
[2019-08-07 15:31:10] [config] transformer-dropout: 0
[2019-08-07 15:31:10] [config] transformer-dropout-attention: 0
[2019-08-07 15:31:10] [config] transformer-dropout-ffn: 0
[2019-08-07 15:31:10] [config] transformer-ffn-activation: swish
[2019-08-07 15:31:10] [config] transformer-ffn-depth: 2
[2019-08-07 15:31:10] [config] transformer-guided-alignment-layer: last
[2019-08-07 15:31:10] [config] transformer-heads: 8
[2019-08-07 15:31:10] [config] transformer-no-projection: false
[2019-08-07 15:31:10] [config] transformer-postprocess: dan
[2019-08-07 15:31:10] [config] transformer-postprocess-emb: d
[2019-08-07 15:31:10] [config] transformer-preprocess: ""
[2019-08-07 15:31:10] [config] transformer-tied-layers:
[2019-08-07 15:31:10] [config]   []
[2019-08-07 15:31:10] [config] transformer-train-position-embeddings: false
[2019-08-07 15:31:10] [config] type: amun
[2019-08-07 15:31:10] [config] ulr: false
[2019-08-07 15:31:10] [config] ulr-dim-emb: 0
[2019-08-07 15:31:10] [config] ulr-dropout: 0
[2019-08-07 15:31:10] [config] ulr-keys-vectors: ""
[2019-08-07 15:31:10] [config] ulr-query-vectors: ""
[2019-08-07 15:31:10] [config] ulr-softmax-temperature: 1
[2019-08-07 15:31:10] [config] ulr-trainable-transformation: false
[2019-08-07 15:31:10] [config] valid-freq: 20000
[2019-08-07 15:31:10] [config] valid-log: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/valid.log
[2019-08-07 15:31:10] [config] valid-max-length: 1000
[2019-08-07 15:31:10] [config] valid-metrics:
[2019-08-07 15:31:10] [config]   - cross-entropy
[2019-08-07 15:31:10] [config]   - perplexity
[2019-08-07 15:31:10] [config]   - translation
[2019-08-07 15:31:10] [config] valid-mini-batch: 8
[2019-08-07 15:31:10] [config] valid-script-path: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/score-dev.sh
[2019-08-07 15:31:10] [config] valid-sets:
[2019-08-07 15:31:10] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/dev.bpe.de
[2019-08-07 15:31:10] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/dev.bpe.en
[2019-08-07 15:31:10] [config] valid-translation-output: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/dev.out
[2019-08-07 15:31:10] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 15:31:10] [config] vocabs:
[2019-08-07 15:31:10] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/train.bpe.de.json
[2019-08-07 15:31:10] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/train.bpe.en.json
[2019-08-07 15:31:10] [config] word-penalty: 0
[2019-08-07 15:31:10] [config] workspace: 3000
[2019-08-07 15:31:10] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 15:31:10] Using synchronous training
[2019-08-07 15:31:10] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/train.bpe.de.json
[2019-08-07 15:31:10] [data] Using unused word id eos for 0
[2019-08-07 15:31:10] [data] Using unused word id UNK for 1
[2019-08-07 15:31:10] [data] Setting vocabulary size for input 0 to 50000
[2019-08-07 15:31:10] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/data/train.bpe.en.json
[2019-08-07 15:31:11] [data] Using unused word id eos for 0
[2019-08-07 15:31:11] [data] Using unused word id UNK for 1
[2019-08-07 15:31:11] [data] Setting vocabulary size for input 1 to 50000
[2019-08-07 15:31:11] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-07 15:31:11] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-07 15:31:12] [memory] Extending reserved space to 3072 MB (device gpu7)
[2019-08-07 15:31:12] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 15:31:12] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 15:31:12] [training] Using 1 GPUs
[2019-08-07 15:31:12] [memory] Reserving 422 MB, device gpu7
[2019-08-07 15:31:12] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-07 15:31:12] [memory] Reserving 422 MB, device gpu7
[2019-08-07 15:31:15] [batching] Done. Typical MB size is 4042 target words
[2019-08-07 15:31:15] [memory] Extending reserved space to 3072 MB (device gpu7)
[2019-08-07 15:31:15] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 15:31:15] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 15:31:15] [training] Using 1 GPUs
[2019-08-07 15:31:15] Loading model from ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz.orig.npz
[2019-08-07 15:31:18] Loading Adam parameters from ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz.optimizer.npz
[2019-08-07 15:31:22] [memory] Reserving 844 MB, device gpu7
[2019-08-07 15:31:23] [training] Model reloaded from ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 15:31:23] [data] Restoring the corpus state to epoch 7, batch 240000
[2019-08-07 15:31:23] [data] Shuffling data
[2019-08-07 15:31:28] [data] Done reading 5229931 sentences
[2019-08-07 15:31:50] [data] Done shuffling 5229931 sentences to temp files
[2019-08-07 15:31:58] Training started
[2019-08-07 15:31:58] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-07 15:31:58] [memory] Reserving 422 MB, device gpu7
[2019-08-07 15:31:59] [memory] Reserving 422 MB, device gpu7
[2019-08-07 15:31:59] Loading model from ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_dom_0.50_dcce_biced_hdiff_no_lm/model/model.npz
[2019-08-07 15:32:02] [memory] Reserving 422 MB, device cpu0
[2019-08-07 15:32:03] [memory] Reserving 422 MB, device gpu7
[2019-08-07 15:37:25] Ep. 7 : Up. 242000 : Sen. 478,560 : Cost 39.17048645 : Time 374.67s : 13366.35 words/s
[2019-08-07 15:42:49] Ep. 7 : Up. 244000 : Sen. 707,563 : Cost 38.86565399 : Time 324.03s : 15466.25 words/s
[2019-08-07 15:48:14] Ep. 7 : Up. 246000 : Sen. 936,242 : Cost 39.00487518 : Time 324.28s : 15439.98 words/s
[2019-08-07 15:53:37] Ep. 7 : Up. 248000 : Sen. 1,164,986 : Cost 38.87028885 : Time 323.31s : 15448.58 words/s
[2019-08-07 15:59:02] Ep. 7 : Up. 250000 : Sen. 1,393,203 : Cost 39.11099625 : Time 324.85s : 15411.57 words/s
