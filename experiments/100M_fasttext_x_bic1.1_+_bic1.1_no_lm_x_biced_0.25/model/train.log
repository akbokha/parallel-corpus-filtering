[2019-08-06 17:44:55] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-06 17:44:55] [marian] Running on elli as process 97582 with command line:
[2019-08-06 17:44:55] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz -T . --devices 0 --train-sets ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en --vocabs ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de.json ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/dev.bpe.de ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/dev.out --valid-script-path ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/train.log --valid-log ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/valid.log
[2019-08-06 17:44:55] [config] after-batches: 0
[2019-08-06 17:44:55] [config] after-epochs: 0
[2019-08-06 17:44:55] [config] allow-unk: false
[2019-08-06 17:44:55] [config] beam-size: 12
[2019-08-06 17:44:55] [config] bert-class-symbol: "[CLS]"
[2019-08-06 17:44:55] [config] bert-mask-symbol: "[MASK]"
[2019-08-06 17:44:55] [config] bert-masking-fraction: 0.15
[2019-08-06 17:44:55] [config] bert-sep-symbol: "[SEP]"
[2019-08-06 17:44:55] [config] bert-train-type-embeddings: true
[2019-08-06 17:44:55] [config] bert-type-vocab-size: 2
[2019-08-06 17:44:55] [config] best-deep: false
[2019-08-06 17:44:55] [config] clip-gemm: 0
[2019-08-06 17:44:55] [config] clip-norm: 1
[2019-08-06 17:44:55] [config] cost-type: ce-mean
[2019-08-06 17:44:55] [config] cpu-threads: 0
[2019-08-06 17:44:55] [config] data-weighting: ""
[2019-08-06 17:44:55] [config] data-weighting-type: sentence
[2019-08-06 17:44:55] [config] dec-cell: gru
[2019-08-06 17:44:55] [config] dec-cell-base-depth: 2
[2019-08-06 17:44:55] [config] dec-cell-high-depth: 1
[2019-08-06 17:44:55] [config] dec-depth: 1
[2019-08-06 17:44:55] [config] devices:
[2019-08-06 17:44:55] [config]   - 0
[2019-08-06 17:44:55] [config] dim-emb: 512
[2019-08-06 17:44:55] [config] dim-rnn: 1024
[2019-08-06 17:44:55] [config] dim-vocabs:
[2019-08-06 17:44:55] [config]   - 50000
[2019-08-06 17:44:55] [config]   - 50000
[2019-08-06 17:44:55] [config] disp-first: 0
[2019-08-06 17:44:55] [config] disp-freq: 2000
[2019-08-06 17:44:55] [config] disp-label-counts: false
[2019-08-06 17:44:55] [config] dropout-rnn: 0.2
[2019-08-06 17:44:55] [config] dropout-src: 0.1
[2019-08-06 17:44:55] [config] dropout-trg: 0.1
[2019-08-06 17:44:55] [config] dump-config: ""
[2019-08-06 17:44:55] [config] early-stopping: 5
[2019-08-06 17:44:55] [config] embedding-fix-src: false
[2019-08-06 17:44:55] [config] embedding-fix-trg: false
[2019-08-06 17:44:55] [config] embedding-normalization: false
[2019-08-06 17:44:55] [config] embedding-vectors:
[2019-08-06 17:44:55] [config]   []
[2019-08-06 17:44:55] [config] enc-cell: gru
[2019-08-06 17:44:55] [config] enc-cell-depth: 1
[2019-08-06 17:44:55] [config] enc-depth: 1
[2019-08-06 17:44:55] [config] enc-type: bidirectional
[2019-08-06 17:44:55] [config] exponential-smoothing: 0.0001
[2019-08-06 17:44:55] [config] grad-dropping-momentum: 0
[2019-08-06 17:44:55] [config] grad-dropping-rate: 0
[2019-08-06 17:44:55] [config] grad-dropping-warmup: 100
[2019-08-06 17:44:55] [config] guided-alignment: none
[2019-08-06 17:44:55] [config] guided-alignment-cost: mse
[2019-08-06 17:44:55] [config] guided-alignment-weight: 0.1
[2019-08-06 17:44:55] [config] ignore-model-config: false
[2019-08-06 17:44:55] [config] input-types:
[2019-08-06 17:44:55] [config]   []
[2019-08-06 17:44:55] [config] interpolate-env-vars: false
[2019-08-06 17:44:55] [config] keep-best: false
[2019-08-06 17:44:55] [config] label-smoothing: 0
[2019-08-06 17:44:55] [config] layer-normalization: true
[2019-08-06 17:44:55] [config] learn-rate: 0.0001
[2019-08-06 17:44:55] [config] log: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/train.log
[2019-08-06 17:44:55] [config] log-level: info
[2019-08-06 17:44:55] [config] log-time-zone: ""
[2019-08-06 17:44:55] [config] lr-decay: 0
[2019-08-06 17:44:55] [config] lr-decay-freq: 50000
[2019-08-06 17:44:55] [config] lr-decay-inv-sqrt:
[2019-08-06 17:44:55] [config]   - 0
[2019-08-06 17:44:55] [config] lr-decay-repeat-warmup: false
[2019-08-06 17:44:55] [config] lr-decay-reset-optimizer: false
[2019-08-06 17:44:55] [config] lr-decay-start:
[2019-08-06 17:44:55] [config]   - 10
[2019-08-06 17:44:55] [config]   - 1
[2019-08-06 17:44:55] [config] lr-decay-strategy: epoch+stalled
[2019-08-06 17:44:55] [config] lr-report: false
[2019-08-06 17:44:55] [config] lr-warmup: 0
[2019-08-06 17:44:55] [config] lr-warmup-at-reload: false
[2019-08-06 17:44:55] [config] lr-warmup-cycle: false
[2019-08-06 17:44:55] [config] lr-warmup-start-rate: 0
[2019-08-06 17:44:55] [config] max-length: 50
[2019-08-06 17:44:55] [config] max-length-crop: false
[2019-08-06 17:44:55] [config] max-length-factor: 3
[2019-08-06 17:44:55] [config] maxi-batch: 100
[2019-08-06 17:44:55] [config] maxi-batch-sort: trg
[2019-08-06 17:44:55] [config] mini-batch: 64
[2019-08-06 17:44:55] [config] mini-batch-fit: true
[2019-08-06 17:44:55] [config] mini-batch-fit-step: 10
[2019-08-06 17:44:55] [config] mini-batch-overstuff: 1
[2019-08-06 17:44:55] [config] mini-batch-track-lr: false
[2019-08-06 17:44:55] [config] mini-batch-understuff: 1
[2019-08-06 17:44:55] [config] mini-batch-warmup: 0
[2019-08-06 17:44:55] [config] mini-batch-words: 0
[2019-08-06 17:44:55] [config] mini-batch-words-ref: 0
[2019-08-06 17:44:55] [config] model: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-06 17:44:55] [config] multi-loss-type: sum
[2019-08-06 17:44:55] [config] multi-node: false
[2019-08-06 17:44:55] [config] multi-node-overlap: true
[2019-08-06 17:44:55] [config] n-best: false
[2019-08-06 17:44:55] [config] no-nccl: false
[2019-08-06 17:44:55] [config] no-reload: false
[2019-08-06 17:44:55] [config] no-restore-corpus: false
[2019-08-06 17:44:55] [config] no-shuffle: false
[2019-08-06 17:44:55] [config] normalize: 1
[2019-08-06 17:44:55] [config] num-devices: 0
[2019-08-06 17:44:55] [config] optimizer: adam
[2019-08-06 17:44:55] [config] optimizer-delay: 1
[2019-08-06 17:44:55] [config] optimizer-params:
[2019-08-06 17:44:55] [config]   []
[2019-08-06 17:44:55] [config] overwrite: false
[2019-08-06 17:44:55] [config] pretrained-model: ""
[2019-08-06 17:44:55] [config] quiet: false
[2019-08-06 17:44:55] [config] quiet-translation: true
[2019-08-06 17:44:55] [config] relative-paths: false
[2019-08-06 17:44:55] [config] right-left: false
[2019-08-06 17:44:55] [config] save-freq: 20000
[2019-08-06 17:44:55] [config] seed: 1111
[2019-08-06 17:44:55] [config] shuffle-in-ram: false
[2019-08-06 17:44:55] [config] skip: false
[2019-08-06 17:44:55] [config] sqlite: ""
[2019-08-06 17:44:55] [config] sqlite-drop: false
[2019-08-06 17:44:55] [config] sync-sgd: true
[2019-08-06 17:44:55] [config] tempdir: .
[2019-08-06 17:44:55] [config] tied-embeddings: false
[2019-08-06 17:44:55] [config] tied-embeddings-all: false
[2019-08-06 17:44:55] [config] tied-embeddings-src: false
[2019-08-06 17:44:55] [config] train-sets:
[2019-08-06 17:44:55] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de
[2019-08-06 17:44:55] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en
[2019-08-06 17:44:55] [config] transformer-aan-activation: swish
[2019-08-06 17:44:55] [config] transformer-aan-depth: 2
[2019-08-06 17:44:55] [config] transformer-aan-nogate: false
[2019-08-06 17:44:55] [config] transformer-decoder-autoreg: self-attention
[2019-08-06 17:44:55] [config] transformer-dim-aan: 2048
[2019-08-06 17:44:55] [config] transformer-dim-ffn: 2048
[2019-08-06 17:44:55] [config] transformer-dropout: 0
[2019-08-06 17:44:55] [config] transformer-dropout-attention: 0
[2019-08-06 17:44:55] [config] transformer-dropout-ffn: 0
[2019-08-06 17:44:55] [config] transformer-ffn-activation: swish
[2019-08-06 17:44:55] [config] transformer-ffn-depth: 2
[2019-08-06 17:44:55] [config] transformer-guided-alignment-layer: last
[2019-08-06 17:44:55] [config] transformer-heads: 8
[2019-08-06 17:44:55] [config] transformer-no-projection: false
[2019-08-06 17:44:55] [config] transformer-postprocess: dan
[2019-08-06 17:44:55] [config] transformer-postprocess-emb: d
[2019-08-06 17:44:55] [config] transformer-preprocess: ""
[2019-08-06 17:44:55] [config] transformer-tied-layers:
[2019-08-06 17:44:55] [config]   []
[2019-08-06 17:44:55] [config] transformer-train-position-embeddings: false
[2019-08-06 17:44:55] [config] type: amun
[2019-08-06 17:44:55] [config] ulr: false
[2019-08-06 17:44:55] [config] ulr-dim-emb: 0
[2019-08-06 17:44:55] [config] ulr-dropout: 0
[2019-08-06 17:44:55] [config] ulr-keys-vectors: ""
[2019-08-06 17:44:55] [config] ulr-query-vectors: ""
[2019-08-06 17:44:55] [config] ulr-softmax-temperature: 1
[2019-08-06 17:44:55] [config] ulr-trainable-transformation: false
[2019-08-06 17:44:55] [config] valid-freq: 20000
[2019-08-06 17:44:55] [config] valid-log: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/valid.log
[2019-08-06 17:44:55] [config] valid-max-length: 1000
[2019-08-06 17:44:55] [config] valid-metrics:
[2019-08-06 17:44:55] [config]   - cross-entropy
[2019-08-06 17:44:55] [config]   - perplexity
[2019-08-06 17:44:55] [config]   - translation
[2019-08-06 17:44:55] [config] valid-mini-batch: 8
[2019-08-06 17:44:55] [config] valid-script-path: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/score-dev.sh
[2019-08-06 17:44:55] [config] valid-sets:
[2019-08-06 17:44:55] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/dev.bpe.de
[2019-08-06 17:44:55] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/dev.bpe.en
[2019-08-06 17:44:55] [config] valid-translation-output: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/dev.out
[2019-08-06 17:44:55] [config] vocabs:
[2019-08-06 17:44:55] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de.json
[2019-08-06 17:44:55] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en.json
[2019-08-06 17:44:55] [config] word-penalty: 0
[2019-08-06 17:44:55] [config] workspace: 3000
[2019-08-06 17:44:55] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-06 17:44:55] Using synchronous training
[2019-08-06 17:44:55] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de.json
[2019-08-06 17:44:56] [data] Using unused word id eos for 0
[2019-08-06 17:44:56] [data] Using unused word id UNK for 1
[2019-08-06 17:44:56] [data] Setting vocabulary size for input 0 to 50000
[2019-08-06 17:44:56] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en.json
[2019-08-06 17:44:56] [data] Using unused word id eos for 0
[2019-08-06 17:44:56] [data] Using unused word id UNK for 1
[2019-08-06 17:44:56] [data] Setting vocabulary size for input 1 to 50000
[2019-08-06 17:44:56] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-06 17:44:56] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-06 17:45:02] [memory] Extending reserved space to 3072 MB (device gpu0)
[2019-08-06 17:45:03] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-06 17:45:03] [comm] NCCLCommunicator constructed successfully.
[2019-08-06 17:45:03] [training] Using 1 GPUs
[2019-08-06 17:45:03] [memory] Reserving 422 MB, device gpu0
[2019-08-06 17:45:03] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-06 17:45:03] [memory] Reserving 422 MB, device gpu0
[2019-08-06 17:45:07] [batching] Done. Typical MB size is 4042 target words
[2019-08-06 17:45:08] [memory] Extending reserved space to 3072 MB (device gpu0)
[2019-08-06 17:45:08] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-06 17:45:08] [comm] NCCLCommunicator constructed successfully.
[2019-08-06 17:45:08] [training] Using 1 GPUs
[2019-08-06 17:45:08] Training started
[2019-08-06 17:45:08] [data] Shuffling data
[2019-08-06 17:45:12] [data] Done reading 5171769 sentences
[2019-08-06 17:45:47] [data] Done shuffling 5171769 sentences to temp files
[2019-08-06 17:45:54] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-06 17:45:54] [memory] Reserving 422 MB, device gpu0
[2019-08-06 17:45:55] [memory] Reserving 422 MB, device gpu0
[2019-08-06 17:45:55] [memory] Reserving 422 MB, device gpu0
[2019-08-06 17:45:55] [memory] Reserving 844 MB, device gpu0
[2019-08-06 17:55:09] Ep. 1 : Up. 2000 : Sen. 220,271 : Cost 137.76446533 : Time 612.55s : 7922.58 words/s
[2019-08-06 18:04:49] Ep. 1 : Up. 4000 : Sen. 441,026 : Cost 109.52619934 : Time 580.38s : 8367.79 words/s
[2019-08-06 18:14:42] Ep. 1 : Up. 6000 : Sen. 661,572 : Cost 94.99361420 : Time 593.31s : 8176.73 words/s
[2019-08-06 18:24:38] Ep. 1 : Up. 8000 : Sen. 883,108 : Cost 84.89438629 : Time 595.39s : 8178.30 words/s
[2019-08-06 18:34:25] Ep. 1 : Up. 10000 : Sen. 1,103,624 : Cost 78.06376648 : Time 587.16s : 8246.68 words/s
[2019-08-06 18:44:15] Ep. 1 : Up. 12000 : Sen. 1,323,625 : Cost 73.46514130 : Time 589.80s : 8221.43 words/s
[2019-08-06 18:54:09] Ep. 1 : Up. 14000 : Sen. 1,544,018 : Cost 70.14063263 : Time 594.33s : 8171.84 words/s
[2019-08-06 19:04:04] Ep. 1 : Up. 16000 : Sen. 1,764,615 : Cost 67.31591797 : Time 595.37s : 8159.61 words/s
[2019-08-06 19:14:04] Ep. 1 : Up. 18000 : Sen. 1,985,223 : Cost 65.26039124 : Time 599.11s : 8116.76 words/s
[2019-08-06 19:23:52] Ep. 1 : Up. 20000 : Sen. 2,205,091 : Cost 63.52455902 : Time 588.25s : 8238.60 words/s
[2019-08-06 19:23:52] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-06 19:24:05] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter20000.npz
[2019-08-06 19:24:15] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-06 19:24:28] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-06 19:25:01] [valid] Ep. 1 : Up. 20000 : cross-entropy : 69.0884 : new best
[2019-08-06 19:25:09] [valid] Ep. 1 : Up. 20000 : perplexity : 15.1107 : new best
[2019-08-06 19:26:30] [valid] Ep. 1 : Up. 20000 : translation : 16.32 : new best
[2019-08-06 19:36:22] Ep. 1 : Up. 22000 : Sen. 2,426,527 : Cost 61.81749725 : Time 749.84s : 6496.18 words/s
[2019-08-06 19:46:12] Ep. 1 : Up. 24000 : Sen. 2,646,428 : Cost 60.61356735 : Time 590.69s : 8200.07 words/s
[2019-08-06 19:56:03] Ep. 1 : Up. 26000 : Sen. 2,867,065 : Cost 59.40487289 : Time 591.11s : 8205.18 words/s
[2019-08-06 20:05:53] Ep. 1 : Up. 28000 : Sen. 3,087,070 : Cost 58.46337509 : Time 589.80s : 8204.14 words/s
[2019-08-06 20:15:47] Ep. 1 : Up. 30000 : Sen. 3,307,170 : Cost 57.44023132 : Time 593.76s : 8140.49 words/s
[2019-08-06 20:25:45] Ep. 1 : Up. 32000 : Sen. 3,528,608 : Cost 56.69012451 : Time 598.42s : 8133.18 words/s
[2019-08-06 20:35:40] Ep. 1 : Up. 34000 : Sen. 3,748,421 : Cost 56.03413773 : Time 594.88s : 8120.33 words/s
[2019-08-06 20:45:39] Ep. 1 : Up. 36000 : Sen. 3,969,905 : Cost 55.46601486 : Time 599.16s : 8125.90 words/s
[2019-08-06 20:55:37] Ep. 1 : Up. 38000 : Sen. 4,189,553 : Cost 54.97241211 : Time 597.78s : 8094.97 words/s
[2019-08-06 21:05:27] Ep. 1 : Up. 40000 : Sen. 4,410,793 : Cost 54.33181763 : Time 589.92s : 8240.80 words/s
[2019-08-06 21:05:27] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-06 21:05:41] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter40000.npz
[2019-08-06 21:05:50] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-06 21:06:01] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-06 21:06:33] [valid] Ep. 1 : Up. 40000 : cross-entropy : 56.5684 : new best
[2019-08-06 21:06:41] [valid] Ep. 1 : Up. 40000 : perplexity : 9.23799 : new best
[2019-08-06 21:08:03] [valid] Ep. 1 : Up. 40000 : translation : 21.21 : new best
[2019-08-06 21:08:38] Seen 4423484 samples
[2019-08-06 21:08:38] Starting epoch 2
[2019-08-06 21:08:38] [data] Shuffling data
[2019-08-06 21:08:53] [data] Done reading 5171769 sentences
[2019-08-06 21:09:26] [data] Done shuffling 5171769 sentences to temp files
[2019-08-06 21:18:27] Ep. 2 : Up. 42000 : Sen. 207,813 : Cost 52.92236328 : Time 779.94s : 6213.79 words/s
[2019-08-06 21:28:06] Ep. 2 : Up. 44000 : Sen. 427,560 : Cost 52.36396790 : Time 578.80s : 8356.28 words/s
[2019-08-06 21:37:46] Ep. 2 : Up. 46000 : Sen. 647,699 : Cost 52.19247818 : Time 579.62s : 8377.58 words/s
[2019-08-06 21:47:25] Ep. 2 : Up. 48000 : Sen. 868,704 : Cost 51.76683044 : Time 579.79s : 8372.10 words/s
[2019-08-06 21:57:06] Ep. 2 : Up. 50000 : Sen. 1,089,199 : Cost 51.21697617 : Time 580.61s : 8335.45 words/s
[2019-08-06 22:06:50] Ep. 2 : Up. 52000 : Sen. 1,309,430 : Cost 51.24593735 : Time 583.78s : 8321.43 words/s
[2019-08-06 22:16:34] Ep. 2 : Up. 54000 : Sen. 1,529,678 : Cost 51.01040268 : Time 584.60s : 8289.76 words/s
[2019-08-06 22:26:18] Ep. 2 : Up. 56000 : Sen. 1,750,222 : Cost 50.67446518 : Time 584.09s : 8320.76 words/s
[2019-08-06 22:36:04] Ep. 2 : Up. 58000 : Sen. 1,970,178 : Cost 50.50365829 : Time 585.55s : 8285.39 words/s
[2019-08-06 22:45:53] Ep. 2 : Up. 60000 : Sen. 2,192,474 : Cost 49.80665970 : Time 589.19s : 8276.96 words/s
[2019-08-06 22:45:53] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-06 22:46:07] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter60000.npz
[2019-08-06 22:46:17] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-06 22:46:30] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-06 22:47:02] [valid] Ep. 2 : Up. 60000 : cross-entropy : 51.3917 : new best
[2019-08-06 22:47:10] [valid] Ep. 2 : Up. 60000 : perplexity : 7.53731 : new best
[2019-08-06 22:48:28] [valid] Ep. 2 : Up. 60000 : translation : 24 : new best
[2019-08-06 22:58:13] Ep. 2 : Up. 62000 : Sen. 2,413,375 : Cost 50.05529785 : Time 739.90s : 6590.79 words/s
[2019-08-06 23:07:58] Ep. 2 : Up. 64000 : Sen. 2,633,831 : Cost 49.37023544 : Time 585.41s : 8272.70 words/s
[2019-08-06 23:17:44] Ep. 2 : Up. 66000 : Sen. 2,853,708 : Cost 49.49062347 : Time 585.95s : 8288.27 words/s
[2019-08-06 23:27:30] Ep. 2 : Up. 68000 : Sen. 3,074,744 : Cost 48.83174515 : Time 585.51s : 8306.30 words/s
[2019-08-06 23:37:12] Ep. 2 : Up. 70000 : Sen. 3,295,585 : Cost 48.64730453 : Time 581.94s : 8329.10 words/s
[2019-08-06 23:46:58] Ep. 2 : Up. 72000 : Sen. 3,515,506 : Cost 48.77630615 : Time 585.87s : 8250.40 words/s
[2019-08-06 23:56:46] Ep. 2 : Up. 74000 : Sen. 3,736,347 : Cost 48.64004898 : Time 588.07s : 8289.09 words/s
[2019-08-07 00:06:33] Ep. 2 : Up. 76000 : Sen. 3,957,488 : Cost 48.02976990 : Time 587.04s : 8276.08 words/s
[2019-08-07 00:16:20] Ep. 2 : Up. 78000 : Sen. 4,178,310 : Cost 48.18053818 : Time 586.88s : 8267.66 words/s
[2019-08-07 00:26:07] Ep. 2 : Up. 80000 : Sen. 4,399,203 : Cost 47.79886627 : Time 587.39s : 8263.60 words/s
[2019-08-07 00:26:07] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-07 00:26:20] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter80000.npz
[2019-08-07 00:26:30] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 00:26:44] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-07 00:27:18] [valid] Ep. 2 : Up. 80000 : cross-entropy : 48.3306 : new best
[2019-08-07 00:27:26] [valid] Ep. 2 : Up. 80000 : perplexity : 6.6829 : new best
[2019-08-07 00:28:49] [valid] Ep. 2 : Up. 80000 : translation : 25.21 : new best
[2019-08-07 00:29:53] Seen 4423484 samples
[2019-08-07 00:29:53] Starting epoch 3
[2019-08-07 00:29:53] [data] Shuffling data
[2019-08-07 00:30:08] [data] Done reading 5171769 sentences
[2019-08-07 00:30:45] [data] Done shuffling 5171769 sentences to temp files
[2019-08-07 00:39:21] Ep. 3 : Up. 82000 : Sen. 196,076 : Cost 46.66702652 : Time 793.83s : 6108.74 words/s
[2019-08-07 00:49:05] Ep. 3 : Up. 84000 : Sen. 415,726 : Cost 46.62441254 : Time 583.61s : 8283.45 words/s
[2019-08-07 00:58:46] Ep. 3 : Up. 86000 : Sen. 636,097 : Cost 46.46555710 : Time 581.53s : 8326.47 words/s
[2019-08-07 01:08:31] Ep. 3 : Up. 88000 : Sen. 855,782 : Cost 46.57354736 : Time 584.84s : 8272.69 words/s
[2019-08-07 01:18:17] Ep. 3 : Up. 90000 : Sen. 1,075,753 : Cost 46.44598007 : Time 585.68s : 8284.27 words/s
[2019-08-07 01:28:06] Ep. 3 : Up. 92000 : Sen. 1,297,249 : Cost 46.24480438 : Time 589.25s : 8286.35 words/s
[2019-08-07 01:37:52] Ep. 3 : Up. 94000 : Sen. 1,518,254 : Cost 45.84471893 : Time 585.86s : 8279.83 words/s
[2019-08-07 01:47:39] Ep. 3 : Up. 96000 : Sen. 1,738,023 : Cost 46.01253128 : Time 586.98s : 8239.44 words/s
[2019-08-07 01:57:30] Ep. 3 : Up. 98000 : Sen. 1,959,210 : Cost 45.96427155 : Time 590.89s : 8246.16 words/s
[2019-08-07 02:07:16] Ep. 3 : Up. 100000 : Sen. 2,180,302 : Cost 45.66551971 : Time 586.71s : 8275.56 words/s
[2019-08-07 02:07:16] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-07 02:07:30] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter100000.npz
[2019-08-07 02:07:40] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 02:07:54] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-07 02:08:27] [valid] Ep. 3 : Up. 100000 : cross-entropy : 46.5238 : new best
[2019-08-07 02:08:35] [valid] Ep. 3 : Up. 100000 : perplexity : 6.2248 : new best
[2019-08-07 02:09:57] [valid] Ep. 3 : Up. 100000 : translation : 25.93 : new best
[2019-08-07 02:19:39] Ep. 3 : Up. 102000 : Sen. 2,400,816 : Cost 45.98583221 : Time 742.89s : 6538.47 words/s
[2019-08-07 02:29:23] Ep. 3 : Up. 104000 : Sen. 2,622,135 : Cost 45.32702637 : Time 584.28s : 8324.06 words/s
[2019-08-07 02:39:07] Ep. 3 : Up. 106000 : Sen. 2,842,415 : Cost 45.64377975 : Time 583.25s : 8327.11 words/s
[2019-08-07 02:48:49] Ep. 3 : Up. 108000 : Sen. 3,063,688 : Cost 45.37416077 : Time 582.70s : 8350.90 words/s
[2019-08-07 02:58:30] Ep. 3 : Up. 110000 : Sen. 3,283,884 : Cost 45.13617325 : Time 581.02s : 8344.84 words/s
[2019-08-07 03:08:10] Ep. 3 : Up. 112000 : Sen. 3,504,098 : Cost 44.97329712 : Time 579.43s : 8337.41 words/s
[2019-08-07 03:17:52] Ep. 3 : Up. 114000 : Sen. 3,724,048 : Cost 45.17445374 : Time 582.44s : 8322.85 words/s
[2019-08-07 03:27:32] Ep. 3 : Up. 116000 : Sen. 3,944,563 : Cost 44.96041107 : Time 579.94s : 8363.54 words/s
[2019-08-07 03:37:11] Ep. 3 : Up. 118000 : Sen. 4,165,740 : Cost 44.63404846 : Time 578.54s : 8383.65 words/s
[2019-08-07 03:46:53] Ep. 3 : Up. 120000 : Sen. 4,386,150 : Cost 45.00309372 : Time 582.59s : 8352.88 words/s
[2019-08-07 03:46:53] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-07 03:47:06] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter120000.npz
[2019-08-07 03:47:16] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 03:47:29] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-07 03:48:03] [valid] Ep. 3 : Up. 120000 : cross-entropy : 45.0288 : new best
[2019-08-07 03:48:11] [valid] Ep. 3 : Up. 120000 : perplexity : 5.86957 : new best
[2019-08-07 03:49:27] [valid] Ep. 3 : Up. 120000 : translation : 26.61 : new best
[2019-08-07 03:51:04] Seen 4423484 samples
[2019-08-07 03:51:04] Starting epoch 4
[2019-08-07 03:51:04] [data] Shuffling data
[2019-08-07 03:51:18] [data] Done reading 5171769 sentences
[2019-08-07 03:51:54] [data] Done shuffling 5171769 sentences to temp files
[2019-08-07 03:59:49] Ep. 4 : Up. 122000 : Sen. 183,936 : Cost 43.78788757 : Time 776.03s : 6275.86 words/s
[2019-08-07 04:09:29] Ep. 4 : Up. 124000 : Sen. 406,002 : Cost 43.38663101 : Time 579.86s : 8418.94 words/s
[2019-08-07 04:19:08] Ep. 4 : Up. 126000 : Sen. 626,349 : Cost 43.83247757 : Time 578.90s : 8390.82 words/s
[2019-08-07 04:28:45] Ep. 4 : Up. 128000 : Sen. 846,973 : Cost 43.70221329 : Time 576.51s : 8425.10 words/s
[2019-08-07 04:38:20] Ep. 4 : Up. 130000 : Sen. 1,067,136 : Cost 43.67787933 : Time 574.95s : 8433.94 words/s
[2019-08-07 04:47:55] Ep. 4 : Up. 132000 : Sen. 1,287,691 : Cost 43.38280106 : Time 575.06s : 8433.49 words/s
[2019-08-07 04:57:27] Ep. 4 : Up. 134000 : Sen. 1,507,988 : Cost 43.47028732 : Time 572.62s : 8468.78 words/s
[2019-08-07 05:06:59] Ep. 4 : Up. 136000 : Sen. 1,727,208 : Cost 43.85335922 : Time 571.64s : 8458.05 words/s
[2019-08-07 05:16:32] Ep. 4 : Up. 138000 : Sen. 1,947,676 : Cost 43.47458267 : Time 573.40s : 8478.48 words/s
[2019-08-07 05:26:08] Ep. 4 : Up. 140000 : Sen. 2,169,366 : Cost 43.32634735 : Time 575.55s : 8459.39 words/s
[2019-08-07 05:26:08] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-07 05:26:21] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter140000.npz
[2019-08-07 05:26:32] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 05:26:46] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-07 05:27:18] [valid] Ep. 4 : Up. 140000 : cross-entropy : 44.0856 : new best
[2019-08-07 05:27:26] [valid] Ep. 4 : Up. 140000 : perplexity : 5.65596 : new best
[2019-08-07 05:28:41] [valid] Ep. 4 : Up. 140000 : translation : 27.13 : new best
[2019-08-07 05:38:11] Ep. 4 : Up. 142000 : Sen. 2,390,260 : Cost 43.49135971 : Time 723.59s : 6719.74 words/s
[2019-08-07 05:47:44] Ep. 4 : Up. 144000 : Sen. 2,611,011 : Cost 43.40800858 : Time 572.09s : 8479.76 words/s
[2019-08-07 05:57:14] Ep. 4 : Up. 146000 : Sen. 2,831,842 : Cost 43.14625168 : Time 570.34s : 8494.64 words/s
[2019-08-07 06:06:46] Ep. 4 : Up. 148000 : Sen. 3,052,722 : Cost 43.20722580 : Time 572.58s : 8496.27 words/s
[2019-08-07 06:16:21] Ep. 4 : Up. 150000 : Sen. 3,274,539 : Cost 43.16016006 : Time 574.36s : 8495.63 words/s
[2019-08-07 06:25:51] Ep. 4 : Up. 152000 : Sen. 3,494,400 : Cost 43.21568680 : Time 570.34s : 8487.02 words/s
[2019-08-07 06:35:21] Ep. 4 : Up. 154000 : Sen. 3,714,451 : Cost 43.28927994 : Time 570.15s : 8490.22 words/s
[2019-08-07 06:44:55] Ep. 4 : Up. 156000 : Sen. 3,935,718 : Cost 43.01747513 : Time 573.74s : 8485.93 words/s
[2019-08-07 06:54:25] Ep. 4 : Up. 158000 : Sen. 4,156,378 : Cost 43.07338333 : Time 570.02s : 8492.62 words/s
[2019-08-07 07:04:01] Ep. 4 : Up. 160000 : Sen. 4,378,080 : Cost 42.86511993 : Time 575.46s : 8482.47 words/s
[2019-08-07 07:04:01] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-07 07:04:10] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter160000.npz
[2019-08-07 07:04:17] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 07:04:27] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-07 07:04:53] [valid] Ep. 4 : Up. 160000 : cross-entropy : 43.2717 : new best
[2019-08-07 07:05:00] [valid] Ep. 4 : Up. 160000 : perplexity : 5.47789 : new best
[2019-08-07 07:06:18] [valid] Ep. 4 : Up. 160000 : translation : 27.41 : new best
[2019-08-07 07:08:15] Seen 4423484 samples
[2019-08-07 07:08:15] Starting epoch 5
[2019-08-07 07:08:15] [data] Shuffling data
[2019-08-07 07:08:46] [data] Done reading 5171769 sentences
[2019-08-07 07:09:12] [data] Done shuffling 5171769 sentences to temp files
[2019-08-07 07:16:44] Ep. 5 : Up. 162000 : Sen. 174,947 : Cost 42.17552948 : Time 763.75s : 6353.81 words/s
[2019-08-07 07:26:15] Ep. 5 : Up. 164000 : Sen. 395,223 : Cost 41.75116348 : Time 570.95s : 8494.70 words/s
[2019-08-07 07:35:45] Ep. 5 : Up. 166000 : Sen. 615,338 : Cost 41.66501999 : Time 569.77s : 8488.83 words/s
[2019-08-07 07:45:14] Ep. 5 : Up. 168000 : Sen. 836,387 : Cost 41.85647583 : Time 568.53s : 8553.69 words/s
[2019-08-07 07:54:41] Ep. 5 : Up. 170000 : Sen. 1,056,543 : Cost 42.01766586 : Time 567.50s : 8540.52 words/s
[2019-08-07 08:04:08] Ep. 5 : Up. 172000 : Sen. 1,276,855 : Cost 41.75703812 : Time 566.97s : 8532.04 words/s
[2019-08-07 08:13:37] Ep. 5 : Up. 174000 : Sen. 1,497,028 : Cost 42.00217438 : Time 569.37s : 8517.97 words/s
[2019-08-07 08:23:08] Ep. 5 : Up. 176000 : Sen. 1,717,194 : Cost 41.82738495 : Time 570.75s : 8475.68 words/s
[2019-08-07 08:32:38] Ep. 5 : Up. 178000 : Sen. 1,936,675 : Cost 42.10128784 : Time 569.69s : 8483.27 words/s
[2019-08-07 08:42:09] Ep. 5 : Up. 180000 : Sen. 2,157,889 : Cost 41.88175201 : Time 570.90s : 8510.71 words/s
[2019-08-07 08:42:09] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-07 08:42:22] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter180000.npz
[2019-08-07 08:42:32] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 08:42:45] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-07 08:43:16] [valid] Ep. 5 : Up. 180000 : cross-entropy : 42.7477 : new best
[2019-08-07 08:43:24] [valid] Ep. 5 : Up. 180000 : perplexity : 5.36623 : new best
[2019-08-07 08:44:39] [valid] Ep. 5 : Up. 180000 : translation : 27.49 : new best
[2019-08-07 08:54:03] Ep. 5 : Up. 182000 : Sen. 2,379,087 : Cost 41.78371811 : Time 714.54s : 6795.13 words/s
[2019-08-07 09:03:33] Ep. 5 : Up. 184000 : Sen. 2,599,132 : Cost 41.97344971 : Time 570.08s : 8520.08 words/s
[2019-08-07 09:13:09] Ep. 5 : Up. 186000 : Sen. 2,820,122 : Cost 41.86732483 : Time 576.00s : 8438.73 words/s
[2019-08-07 09:22:53] Ep. 5 : Up. 188000 : Sen. 3,041,670 : Cost 41.77406311 : Time 584.02s : 8349.22 words/s
[2019-08-07 09:32:39] Ep. 5 : Up. 190000 : Sen. 3,262,530 : Cost 41.80754471 : Time 585.76s : 8288.07 words/s
[2019-08-07 09:42:24] Ep. 5 : Up. 192000 : Sen. 3,481,993 : Cost 42.07696915 : Time 584.50s : 8274.53 words/s
[2019-08-07 09:52:15] Ep. 5 : Up. 194000 : Sen. 3,703,177 : Cost 41.86753845 : Time 591.00s : 8244.62 words/s
[2019-08-07 10:02:06] Ep. 5 : Up. 196000 : Sen. 3,922,931 : Cost 41.80311966 : Time 591.43s : 8182.15 words/s
[2019-08-07 10:12:07] Ep. 5 : Up. 198000 : Sen. 4,144,244 : Cost 41.83488083 : Time 600.95s : 8117.26 words/s
[2019-08-07 10:22:15] Ep. 5 : Up. 200000 : Sen. 4,365,005 : Cost 41.49062729 : Time 607.71s : 7977.56 words/s
[2019-08-07 10:22:15] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-07 10:22:27] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter200000.npz
[2019-08-07 10:22:39] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 10:22:53] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-07 10:23:24] [valid] Ep. 5 : Up. 200000 : cross-entropy : 42.1568 : new best
[2019-08-07 10:23:32] [valid] Ep. 5 : Up. 200000 : perplexity : 5.24304 : new best
[2019-08-07 10:24:49] [valid] Ep. 5 : Up. 200000 : translation : 27.7 : new best
[2019-08-07 10:27:28] Seen 4423484 samples
[2019-08-07 10:27:28] Starting epoch 6
[2019-08-07 10:27:28] [data] Shuffling data
[2019-08-07 10:27:43] [data] Done reading 5171769 sentences
[2019-08-07 10:28:12] [data] Done shuffling 5171769 sentences to temp files
[2019-08-07 10:35:47] Ep. 6 : Up. 202000 : Sen. 161,614 : Cost 40.86782837 : Time 812.67s : 5960.93 words/s
[2019-08-07 10:46:18] Ep. 6 : Up. 204000 : Sen. 383,153 : Cost 40.84260178 : Time 630.98s : 7725.59 words/s
[2019-08-07 10:56:38] Ep. 6 : Up. 206000 : Sen. 603,191 : Cost 40.89533234 : Time 619.75s : 7826.67 words/s
[2019-08-07 11:07:01] Ep. 6 : Up. 208000 : Sen. 823,292 : Cost 40.74270630 : Time 623.29s : 7775.00 words/s
[2019-08-07 11:17:26] Ep. 6 : Up. 210000 : Sen. 1,043,563 : Cost 40.71134567 : Time 624.61s : 7755.33 words/s
[2019-08-07 11:27:55] Ep. 6 : Up. 212000 : Sen. 1,264,395 : Cost 40.75851822 : Time 629.24s : 7728.06 words/s
[2019-08-07 11:38:36] Ep. 6 : Up. 214000 : Sen. 1,485,185 : Cost 40.95918274 : Time 640.34s : 7594.89 words/s
[2019-08-07 11:49:07] Ep. 6 : Up. 216000 : Sen. 1,706,256 : Cost 40.75728989 : Time 631.76s : 7703.89 words/s
[2019-08-07 11:59:21] Ep. 6 : Up. 218000 : Sen. 1,926,478 : Cost 40.97517776 : Time 613.59s : 7907.77 words/s
[2019-08-07 15:19:30] Ep. 6 : Up. 220000 : Sen. 2,146,916 : Cost 40.83630371 : Time 12008.66s : 403.63 words/s
[2019-08-07 15:19:30] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-07 15:19:40] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter220000.npz
[2019-08-07 15:19:47] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 15:19:56] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-07 15:20:22] [valid] Ep. 6 : Up. 220000 : cross-entropy : 41.8868 : new best
[2019-08-07 15:20:30] [valid] Ep. 6 : Up. 220000 : perplexity : 5.18769 : new best
[2019-08-07 15:21:39] [valid] Ep. 6 : Up. 220000 : translation : 27.7 : stalled 1 times (last best: 27.7)
[2019-08-07 15:30:33] Ep. 6 : Up. 222000 : Sen. 2,366,975 : Cost 40.84515381 : Time 663.46s : 7306.29 words/s
[2019-08-07 15:39:34] Ep. 6 : Up. 224000 : Sen. 2,587,925 : Cost 40.73976517 : Time 540.33s : 8987.91 words/s
[2019-08-07 15:45:16] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 15:45:16] [marian] Running on fulla as process 5580 with command line:
[2019-08-07 15:45:16] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz -T . --devices 1 --train-sets ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en --vocabs ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de.json ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/dev.bpe.de ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/dev.out --valid-script-path ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/train.log --valid-log ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/valid.log
[2019-08-07 15:45:16] [config] after-batches: 0
[2019-08-07 15:45:16] [config] after-epochs: 0
[2019-08-07 15:45:16] [config] allow-unk: false
[2019-08-07 15:45:16] [config] beam-size: 12
[2019-08-07 15:45:16] [config] bert-class-symbol: "[CLS]"
[2019-08-07 15:45:16] [config] bert-mask-symbol: "[MASK]"
[2019-08-07 15:45:16] [config] bert-masking-fraction: 0.15
[2019-08-07 15:45:16] [config] bert-sep-symbol: "[SEP]"
[2019-08-07 15:45:16] [config] bert-train-type-embeddings: true
[2019-08-07 15:45:16] [config] bert-type-vocab-size: 2
[2019-08-07 15:45:16] [config] best-deep: false
[2019-08-07 15:45:16] [config] clip-gemm: 0
[2019-08-07 15:45:16] [config] clip-norm: 1
[2019-08-07 15:45:16] [config] cost-type: ce-mean
[2019-08-07 15:45:16] [config] cpu-threads: 0
[2019-08-07 15:45:16] [config] data-weighting: ""
[2019-08-07 15:45:16] [config] data-weighting-type: sentence
[2019-08-07 15:45:16] [config] dec-cell: gru
[2019-08-07 15:45:16] [config] dec-cell-base-depth: 2
[2019-08-07 15:45:16] [config] dec-cell-high-depth: 1
[2019-08-07 15:45:16] [config] dec-depth: 1
[2019-08-07 15:45:16] [config] devices:
[2019-08-07 15:45:16] [config]   - 1
[2019-08-07 15:45:16] [config] dim-emb: 512
[2019-08-07 15:45:16] [config] dim-rnn: 1024
[2019-08-07 15:45:16] [config] dim-vocabs:
[2019-08-07 15:45:16] [config]   - 50000
[2019-08-07 15:45:16] [config]   - 50000
[2019-08-07 15:45:16] [config] disp-first: 0
[2019-08-07 15:45:16] [config] disp-freq: 2000
[2019-08-07 15:45:16] [config] disp-label-counts: false
[2019-08-07 15:45:16] [config] dropout-rnn: 0.2
[2019-08-07 15:45:16] [config] dropout-src: 0.1
[2019-08-07 15:45:16] [config] dropout-trg: 0.1
[2019-08-07 15:45:16] [config] dump-config: ""
[2019-08-07 15:45:16] [config] early-stopping: 5
[2019-08-07 15:45:16] [config] embedding-fix-src: false
[2019-08-07 15:45:16] [config] embedding-fix-trg: false
[2019-08-07 15:45:16] [config] embedding-normalization: false
[2019-08-07 15:45:16] [config] embedding-vectors:
[2019-08-07 15:45:16] [config]   []
[2019-08-07 15:45:16] [config] enc-cell: gru
[2019-08-07 15:45:16] [config] enc-cell-depth: 1
[2019-08-07 15:45:16] [config] enc-depth: 1
[2019-08-07 15:45:16] [config] enc-type: bidirectional
[2019-08-07 15:45:16] [config] exponential-smoothing: 0.0001
[2019-08-07 15:45:16] [config] grad-dropping-momentum: 0
[2019-08-07 15:45:16] [config] grad-dropping-rate: 0
[2019-08-07 15:45:16] [config] grad-dropping-warmup: 100
[2019-08-07 15:45:16] [config] guided-alignment: none
[2019-08-07 15:45:16] [config] guided-alignment-cost: mse
[2019-08-07 15:45:16] [config] guided-alignment-weight: 0.1
[2019-08-07 15:45:16] [config] ignore-model-config: false
[2019-08-07 15:45:16] [config] input-types:
[2019-08-07 15:45:16] [config]   []
[2019-08-07 15:45:16] [config] interpolate-env-vars: false
[2019-08-07 15:45:16] [config] keep-best: false
[2019-08-07 15:45:16] [config] label-smoothing: 0
[2019-08-07 15:45:16] [config] layer-normalization: true
[2019-08-07 15:45:16] [config] learn-rate: 0.0001
[2019-08-07 15:45:16] [config] log: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/train.log
[2019-08-07 15:45:16] [config] log-level: info
[2019-08-07 15:45:16] [config] log-time-zone: ""
[2019-08-07 15:45:16] [config] lr-decay: 0
[2019-08-07 15:45:16] [config] lr-decay-freq: 50000
[2019-08-07 15:45:16] [config] lr-decay-inv-sqrt:
[2019-08-07 15:45:16] [config]   - 0
[2019-08-07 15:45:16] [config] lr-decay-repeat-warmup: false
[2019-08-07 15:45:16] [config] lr-decay-reset-optimizer: false
[2019-08-07 15:45:16] [config] lr-decay-start:
[2019-08-07 15:45:16] [config]   - 10
[2019-08-07 15:45:16] [config]   - 1
[2019-08-07 15:45:16] [config] lr-decay-strategy: epoch+stalled
[2019-08-07 15:45:16] [config] lr-report: false
[2019-08-07 15:45:16] [config] lr-warmup: 0
[2019-08-07 15:45:16] [config] lr-warmup-at-reload: false
[2019-08-07 15:45:16] [config] lr-warmup-cycle: false
[2019-08-07 15:45:16] [config] lr-warmup-start-rate: 0
[2019-08-07 15:45:16] [config] max-length: 50
[2019-08-07 15:45:16] [config] max-length-crop: false
[2019-08-07 15:45:16] [config] max-length-factor: 3
[2019-08-07 15:45:16] [config] maxi-batch: 100
[2019-08-07 15:45:16] [config] maxi-batch-sort: trg
[2019-08-07 15:45:16] [config] mini-batch: 64
[2019-08-07 15:45:16] [config] mini-batch-fit: true
[2019-08-07 15:45:16] [config] mini-batch-fit-step: 10
[2019-08-07 15:45:16] [config] mini-batch-overstuff: 1
[2019-08-07 15:45:16] [config] mini-batch-track-lr: false
[2019-08-07 15:45:16] [config] mini-batch-understuff: 1
[2019-08-07 15:45:16] [config] mini-batch-warmup: 0
[2019-08-07 15:45:16] [config] mini-batch-words: 0
[2019-08-07 15:45:16] [config] mini-batch-words-ref: 0
[2019-08-07 15:45:16] [config] model: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 15:45:16] [config] multi-loss-type: sum
[2019-08-07 15:45:16] [config] multi-node: false
[2019-08-07 15:45:16] [config] multi-node-overlap: true
[2019-08-07 15:45:16] [config] n-best: false
[2019-08-07 15:45:16] [config] no-nccl: false
[2019-08-07 15:45:16] [config] no-reload: false
[2019-08-07 15:45:16] [config] no-restore-corpus: false
[2019-08-07 15:45:16] [config] no-shuffle: false
[2019-08-07 15:45:16] [config] normalize: 1
[2019-08-07 15:45:16] [config] num-devices: 0
[2019-08-07 15:45:16] [config] optimizer: adam
[2019-08-07 15:45:16] [config] optimizer-delay: 1
[2019-08-07 15:45:16] [config] optimizer-params:
[2019-08-07 15:45:16] [config]   []
[2019-08-07 15:45:16] [config] overwrite: false
[2019-08-07 15:45:16] [config] pretrained-model: ""
[2019-08-07 15:45:16] [config] quiet: false
[2019-08-07 15:45:16] [config] quiet-translation: true
[2019-08-07 15:45:16] [config] relative-paths: false
[2019-08-07 15:45:16] [config] right-left: false
[2019-08-07 15:45:16] [config] save-freq: 20000
[2019-08-07 15:45:16] [config] seed: 1111
[2019-08-07 15:45:16] [config] shuffle-in-ram: false
[2019-08-07 15:45:16] [config] skip: false
[2019-08-07 15:45:16] [config] sqlite: ""
[2019-08-07 15:45:16] [config] sqlite-drop: false
[2019-08-07 15:45:16] [config] sync-sgd: true
[2019-08-07 15:45:16] [config] tempdir: .
[2019-08-07 15:45:16] [config] tied-embeddings: false
[2019-08-07 15:45:16] [config] tied-embeddings-all: false
[2019-08-07 15:45:16] [config] tied-embeddings-src: false
[2019-08-07 15:45:16] [config] train-sets:
[2019-08-07 15:45:16] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de
[2019-08-07 15:45:16] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en
[2019-08-07 15:45:16] [config] transformer-aan-activation: swish
[2019-08-07 15:45:16] [config] transformer-aan-depth: 2
[2019-08-07 15:45:16] [config] transformer-aan-nogate: false
[2019-08-07 15:45:16] [config] transformer-decoder-autoreg: self-attention
[2019-08-07 15:45:16] [config] transformer-dim-aan: 2048
[2019-08-07 15:45:16] [config] transformer-dim-ffn: 2048
[2019-08-07 15:45:16] [config] transformer-dropout: 0
[2019-08-07 15:45:16] [config] transformer-dropout-attention: 0
[2019-08-07 15:45:16] [config] transformer-dropout-ffn: 0
[2019-08-07 15:45:16] [config] transformer-ffn-activation: swish
[2019-08-07 15:45:16] [config] transformer-ffn-depth: 2
[2019-08-07 15:45:16] [config] transformer-guided-alignment-layer: last
[2019-08-07 15:45:16] [config] transformer-heads: 8
[2019-08-07 15:45:16] [config] transformer-no-projection: false
[2019-08-07 15:45:16] [config] transformer-postprocess: dan
[2019-08-07 15:45:16] [config] transformer-postprocess-emb: d
[2019-08-07 15:45:16] [config] transformer-preprocess: ""
[2019-08-07 15:45:16] [config] transformer-tied-layers:
[2019-08-07 15:45:16] [config]   []
[2019-08-07 15:45:16] [config] transformer-train-position-embeddings: false
[2019-08-07 15:45:16] [config] type: amun
[2019-08-07 15:45:16] [config] ulr: false
[2019-08-07 15:45:16] [config] ulr-dim-emb: 0
[2019-08-07 15:45:16] [config] ulr-dropout: 0
[2019-08-07 15:45:16] [config] ulr-keys-vectors: ""
[2019-08-07 15:45:16] [config] ulr-query-vectors: ""
[2019-08-07 15:45:16] [config] ulr-softmax-temperature: 1
[2019-08-07 15:45:16] [config] ulr-trainable-transformation: false
[2019-08-07 15:45:16] [config] valid-freq: 20000
[2019-08-07 15:45:16] [config] valid-log: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/valid.log
[2019-08-07 15:45:16] [config] valid-max-length: 1000
[2019-08-07 15:45:16] [config] valid-metrics:
[2019-08-07 15:45:16] [config]   - cross-entropy
[2019-08-07 15:45:16] [config]   - perplexity
[2019-08-07 15:45:16] [config]   - translation
[2019-08-07 15:45:16] [config] valid-mini-batch: 8
[2019-08-07 15:45:16] [config] valid-script-path: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/score-dev.sh
[2019-08-07 15:45:16] [config] valid-sets:
[2019-08-07 15:45:16] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/dev.bpe.de
[2019-08-07 15:45:16] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/dev.bpe.en
[2019-08-07 15:45:16] [config] valid-translation-output: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/dev.out
[2019-08-07 15:45:16] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 15:45:16] [config] vocabs:
[2019-08-07 15:45:16] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de.json
[2019-08-07 15:45:16] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en.json
[2019-08-07 15:45:16] [config] word-penalty: 0
[2019-08-07 15:45:16] [config] workspace: 3000
[2019-08-07 15:45:16] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 15:45:16] Using synchronous training
[2019-08-07 15:45:16] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de.json
[2019-08-07 15:45:16] [data] Using unused word id eos for 0
[2019-08-07 15:45:16] [data] Using unused word id UNK for 1
[2019-08-07 15:45:16] [data] Setting vocabulary size for input 0 to 50000
[2019-08-07 15:45:16] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en.json
[2019-08-07 15:45:17] [data] Using unused word id eos for 0
[2019-08-07 15:45:17] [data] Using unused word id UNK for 1
[2019-08-07 15:45:17] [data] Setting vocabulary size for input 1 to 50000
[2019-08-07 15:45:17] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-07 15:45:17] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-07 15:45:18] [memory] Extending reserved space to 3072 MB (device gpu1)
[2019-08-07 15:45:18] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 15:45:18] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 15:45:18] [training] Using 1 GPUs
[2019-08-07 15:45:18] [memory] Reserving 422 MB, device gpu1
[2019-08-07 15:45:18] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-07 15:45:18] [memory] Reserving 422 MB, device gpu1
[2019-08-07 15:45:21] [batching] Done. Typical MB size is 4042 target words
[2019-08-07 15:45:21] [memory] Extending reserved space to 3072 MB (device gpu1)
[2019-08-07 15:45:21] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 15:45:21] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 15:45:21] [training] Using 1 GPUs
[2019-08-07 15:45:21] Loading model from ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-07 15:45:27] Loading Adam parameters from ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-07 15:45:38] [memory] Reserving 844 MB, device gpu1
[2019-08-07 15:45:39] [training] Model reloaded from ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 15:45:39] [data] Restoring the corpus state to epoch 6, batch 220000
[2019-08-07 15:45:39] [data] Shuffling data
[2019-08-07 15:45:53] [data] Done reading 5171769 sentences
[2019-08-07 15:46:11] [data] Done shuffling 5171769 sentences to temp files
[2019-08-07 15:47:31] Training started
[2019-08-07 15:47:31] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-07 15:47:31] [memory] Reserving 422 MB, device gpu1
[2019-08-07 15:47:31] [memory] Reserving 422 MB, device gpu1
[2019-08-07 15:47:31] Loading model from ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 15:47:38] [memory] Reserving 422 MB, device cpu0
[2019-08-07 15:47:38] [memory] Reserving 422 MB, device gpu1
[2019-08-07 15:52:59] Ep. 6 : Up. 222000 : Sen. 2,366,975 : Cost 41.08972168 : Time 462.62s : 10478.32 words/s
[2019-08-07 15:58:20] Ep. 6 : Up. 224000 : Sen. 2,587,925 : Cost 40.76732254 : Time 320.36s : 15159.28 words/s
[2019-08-07 16:03:39] Ep. 6 : Up. 226000 : Sen. 2,807,906 : Cost 40.70326996 : Time 319.72s : 15112.88 words/s
[2019-08-07 16:09:02] Ep. 6 : Up. 228000 : Sen. 3,027,380 : Cost 41.13952637 : Time 322.53s : 14993.27 words/s
[2019-08-07 16:14:26] Ep. 6 : Up. 230000 : Sen. 3,248,145 : Cost 40.97523499 : Time 324.50s : 14977.80 words/s
[2019-08-07 16:19:47] Ep. 6 : Up. 232000 : Sen. 3,467,836 : Cost 40.79482269 : Time 321.10s : 15041.51 words/s
[2019-08-07 16:25:12] Ep. 6 : Up. 234000 : Sen. 3,689,065 : Cost 40.75379944 : Time 324.66s : 15035.04 words/s
[2019-08-07 16:50:42] Error: Error reading from file '.'
[2019-08-07 17:00:54] Error: Aborted from marian::io::InputFileStream& marian::io::getline(marian::io::InputFileStream&, std::__cxx11::string&) in /fs/bil0/abdel/marian-dev/src/common/file_stream.h:216

[CALL STACK]
[0x727f12]                                                            
[0x728985]          marian::data::Corpus::  next  ()                   + 0x6f5
[0x716e4f]          marian::data::CorpusIterator::  increment  ()      + 0x2f
[0x681a7d]          marian::data::BatchGenerator<marian::data::CorpusBase>::  fetchBatches  () + 0x10dd
[0x682adb]          std::future<std::result_of<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1} ()>::type> marian::ThreadPool::enqueue<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}>(std::result_of&&,(marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}&&)...)::{lambda()#1}::  operator()  () const + 0x2b
[0x6834be]          std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base,std::__future_base::_Result_base::_Deleter> (),std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<std::deque<std::shared_ptr<marian::data::CorpusBatch>,std::allocator<std::shared_ptr<marian::data::CorpusBatch>>>>,std::__future_base::_Result_base::_Deleter>,std::_Bind_simple<std::reference_wrapper<std::future<std::result_of<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1} ()>::type> marian::ThreadPool::enqueue<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}>(std::result_of&&,(marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}&&)...)::{lambda()#1}> ()>,std::deque<std::shared_ptr<marian::data::CorpusBatch>,std::allocator<std::shared_ptr<marian::data::CorpusBatch>>>>>::  _M_invoke  (std::_Any_data const&) + 0x3e
[0x5a5f19]          std::__future_base::_State_baseV2::  _M_do_set  (std::function<std::unique_ptr<std::__future_base::_Result_base,std::__future_base::_Result_base::_Deleter> ()>*,  bool*) + 0x29
[0x7f0ea3749a99]                                                       + 0xea99
[0x59fac2]                                                            
[0x5a7341]          std::__future_base::_Task_state<std::future<std::result_of<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1} ()>::type> marian::ThreadPool::enqueue<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}>(std::result_of&&,(marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}&&)...)::{lambda()#1},std::allocator<int>,std::deque<std::shared_ptr<marian::data::CorpusBatch>,std::allocator<std::shared_ptr>> ()>::  _M_run  () + 0x51
[0x5d00b4]          std::thread::_Impl<std::_Bind_simple<marian::ThreadPool::reserve(unsigned long)::{lambda()#1} ()>>::  _M_run  () + 0x174
[0x7f0ea3269c80]                                                       + 0xb8c80
[0x7f0ea37426ba]                                                       + 0x76ba
[0x7f0ea29cf41d]    clone                                              + 0x6d

[2019-08-07 17:36:04] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 17:36:04] [marian] Running on fulla as process 14927 with command line:
[2019-08-07 17:36:04] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz -T . --devices 1 --train-sets ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en --vocabs ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de.json ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/dev.bpe.de ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/dev.out --valid-script-path ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/train.log --valid-log ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/valid.log
[2019-08-07 17:36:04] [config] after-batches: 0
[2019-08-07 17:36:04] [config] after-epochs: 0
[2019-08-07 17:36:04] [config] allow-unk: false
[2019-08-07 17:36:04] [config] beam-size: 12
[2019-08-07 17:36:04] [config] bert-class-symbol: "[CLS]"
[2019-08-07 17:36:04] [config] bert-mask-symbol: "[MASK]"
[2019-08-07 17:36:04] [config] bert-masking-fraction: 0.15
[2019-08-07 17:36:04] [config] bert-sep-symbol: "[SEP]"
[2019-08-07 17:36:04] [config] bert-train-type-embeddings: true
[2019-08-07 17:36:04] [config] bert-type-vocab-size: 2
[2019-08-07 17:36:04] [config] best-deep: false
[2019-08-07 17:36:04] [config] clip-gemm: 0
[2019-08-07 17:36:04] [config] clip-norm: 1
[2019-08-07 17:36:04] [config] cost-type: ce-mean
[2019-08-07 17:36:04] [config] cpu-threads: 0
[2019-08-07 17:36:04] [config] data-weighting: ""
[2019-08-07 17:36:04] [config] data-weighting-type: sentence
[2019-08-07 17:36:04] [config] dec-cell: gru
[2019-08-07 17:36:04] [config] dec-cell-base-depth: 2
[2019-08-07 17:36:04] [config] dec-cell-high-depth: 1
[2019-08-07 17:36:04] [config] dec-depth: 1
[2019-08-07 17:36:04] [config] devices:
[2019-08-07 17:36:04] [config]   - 1
[2019-08-07 17:36:04] [config] dim-emb: 512
[2019-08-07 17:36:04] [config] dim-rnn: 1024
[2019-08-07 17:36:04] [config] dim-vocabs:
[2019-08-07 17:36:04] [config]   - 50000
[2019-08-07 17:36:04] [config]   - 50000
[2019-08-07 17:36:04] [config] disp-first: 0
[2019-08-07 17:36:04] [config] disp-freq: 2000
[2019-08-07 17:36:04] [config] disp-label-counts: false
[2019-08-07 17:36:04] [config] dropout-rnn: 0.2
[2019-08-07 17:36:04] [config] dropout-src: 0.1
[2019-08-07 17:36:04] [config] dropout-trg: 0.1
[2019-08-07 17:36:04] [config] dump-config: ""
[2019-08-07 17:36:04] [config] early-stopping: 5
[2019-08-07 17:36:04] [config] embedding-fix-src: false
[2019-08-07 17:36:04] [config] embedding-fix-trg: false
[2019-08-07 17:36:04] [config] embedding-normalization: false
[2019-08-07 17:36:04] [config] embedding-vectors:
[2019-08-07 17:36:04] [config]   []
[2019-08-07 17:36:04] [config] enc-cell: gru
[2019-08-07 17:36:04] [config] enc-cell-depth: 1
[2019-08-07 17:36:04] [config] enc-depth: 1
[2019-08-07 17:36:04] [config] enc-type: bidirectional
[2019-08-07 17:36:04] [config] exponential-smoothing: 0.0001
[2019-08-07 17:36:04] [config] grad-dropping-momentum: 0
[2019-08-07 17:36:04] [config] grad-dropping-rate: 0
[2019-08-07 17:36:04] [config] grad-dropping-warmup: 100
[2019-08-07 17:36:04] [config] guided-alignment: none
[2019-08-07 17:36:04] [config] guided-alignment-cost: mse
[2019-08-07 17:36:04] [config] guided-alignment-weight: 0.1
[2019-08-07 17:36:04] [config] ignore-model-config: false
[2019-08-07 17:36:04] [config] input-types:
[2019-08-07 17:36:04] [config]   []
[2019-08-07 17:36:04] [config] interpolate-env-vars: false
[2019-08-07 17:36:04] [config] keep-best: false
[2019-08-07 17:36:04] [config] label-smoothing: 0
[2019-08-07 17:36:04] [config] layer-normalization: true
[2019-08-07 17:36:04] [config] learn-rate: 0.0001
[2019-08-07 17:36:04] [config] log: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/train.log
[2019-08-07 17:36:04] [config] log-level: info
[2019-08-07 17:36:04] [config] log-time-zone: ""
[2019-08-07 17:36:04] [config] lr-decay: 0
[2019-08-07 17:36:04] [config] lr-decay-freq: 50000
[2019-08-07 17:36:04] [config] lr-decay-inv-sqrt:
[2019-08-07 17:36:04] [config]   - 0
[2019-08-07 17:36:04] [config] lr-decay-repeat-warmup: false
[2019-08-07 17:36:04] [config] lr-decay-reset-optimizer: false
[2019-08-07 17:36:04] [config] lr-decay-start:
[2019-08-07 17:36:04] [config]   - 10
[2019-08-07 17:36:04] [config]   - 1
[2019-08-07 17:36:04] [config] lr-decay-strategy: epoch+stalled
[2019-08-07 17:36:04] [config] lr-report: false
[2019-08-07 17:36:04] [config] lr-warmup: 0
[2019-08-07 17:36:04] [config] lr-warmup-at-reload: false
[2019-08-07 17:36:04] [config] lr-warmup-cycle: false
[2019-08-07 17:36:04] [config] lr-warmup-start-rate: 0
[2019-08-07 17:36:04] [config] max-length: 50
[2019-08-07 17:36:04] [config] max-length-crop: false
[2019-08-07 17:36:04] [config] max-length-factor: 3
[2019-08-07 17:36:04] [config] maxi-batch: 100
[2019-08-07 17:36:04] [config] maxi-batch-sort: trg
[2019-08-07 17:36:04] [config] mini-batch: 64
[2019-08-07 17:36:04] [config] mini-batch-fit: true
[2019-08-07 17:36:04] [config] mini-batch-fit-step: 10
[2019-08-07 17:36:04] [config] mini-batch-overstuff: 1
[2019-08-07 17:36:04] [config] mini-batch-track-lr: false
[2019-08-07 17:36:04] [config] mini-batch-understuff: 1
[2019-08-07 17:36:04] [config] mini-batch-warmup: 0
[2019-08-07 17:36:04] [config] mini-batch-words: 0
[2019-08-07 17:36:04] [config] mini-batch-words-ref: 0
[2019-08-07 17:36:04] [config] model: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 17:36:04] [config] multi-loss-type: sum
[2019-08-07 17:36:04] [config] multi-node: false
[2019-08-07 17:36:04] [config] multi-node-overlap: true
[2019-08-07 17:36:04] [config] n-best: false
[2019-08-07 17:36:04] [config] no-nccl: false
[2019-08-07 17:36:04] [config] no-reload: false
[2019-08-07 17:36:04] [config] no-restore-corpus: false
[2019-08-07 17:36:04] [config] no-shuffle: false
[2019-08-07 17:36:04] [config] normalize: 1
[2019-08-07 17:36:04] [config] num-devices: 0
[2019-08-07 17:36:04] [config] optimizer: adam
[2019-08-07 17:36:04] [config] optimizer-delay: 1
[2019-08-07 17:36:04] [config] optimizer-params:
[2019-08-07 17:36:04] [config]   []
[2019-08-07 17:36:04] [config] overwrite: false
[2019-08-07 17:36:04] [config] pretrained-model: ""
[2019-08-07 17:36:04] [config] quiet: false
[2019-08-07 17:36:04] [config] quiet-translation: true
[2019-08-07 17:36:04] [config] relative-paths: false
[2019-08-07 17:36:04] [config] right-left: false
[2019-08-07 17:36:04] [config] save-freq: 20000
[2019-08-07 17:36:04] [config] seed: 1111
[2019-08-07 17:36:04] [config] shuffle-in-ram: false
[2019-08-07 17:36:04] [config] skip: false
[2019-08-07 17:36:04] [config] sqlite: ""
[2019-08-07 17:36:04] [config] sqlite-drop: false
[2019-08-07 17:36:04] [config] sync-sgd: true
[2019-08-07 17:36:04] [config] tempdir: .
[2019-08-07 17:36:04] [config] tied-embeddings: false
[2019-08-07 17:36:04] [config] tied-embeddings-all: false
[2019-08-07 17:36:04] [config] tied-embeddings-src: false
[2019-08-07 17:36:04] [config] train-sets:
[2019-08-07 17:36:04] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de
[2019-08-07 17:36:04] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en
[2019-08-07 17:36:04] [config] transformer-aan-activation: swish
[2019-08-07 17:36:04] [config] transformer-aan-depth: 2
[2019-08-07 17:36:04] [config] transformer-aan-nogate: false
[2019-08-07 17:36:04] [config] transformer-decoder-autoreg: self-attention
[2019-08-07 17:36:04] [config] transformer-dim-aan: 2048
[2019-08-07 17:36:04] [config] transformer-dim-ffn: 2048
[2019-08-07 17:36:04] [config] transformer-dropout: 0
[2019-08-07 17:36:04] [config] transformer-dropout-attention: 0
[2019-08-07 17:36:04] [config] transformer-dropout-ffn: 0
[2019-08-07 17:36:04] [config] transformer-ffn-activation: swish
[2019-08-07 17:36:04] [config] transformer-ffn-depth: 2
[2019-08-07 17:36:04] [config] transformer-guided-alignment-layer: last
[2019-08-07 17:36:04] [config] transformer-heads: 8
[2019-08-07 17:36:04] [config] transformer-no-projection: false
[2019-08-07 17:36:04] [config] transformer-postprocess: dan
[2019-08-07 17:36:04] [config] transformer-postprocess-emb: d
[2019-08-07 17:36:04] [config] transformer-preprocess: ""
[2019-08-07 17:36:04] [config] transformer-tied-layers:
[2019-08-07 17:36:04] [config]   []
[2019-08-07 17:36:04] [config] transformer-train-position-embeddings: false
[2019-08-07 17:36:04] [config] type: amun
[2019-08-07 17:36:04] [config] ulr: false
[2019-08-07 17:36:04] [config] ulr-dim-emb: 0
[2019-08-07 17:36:04] [config] ulr-dropout: 0
[2019-08-07 17:36:04] [config] ulr-keys-vectors: ""
[2019-08-07 17:36:04] [config] ulr-query-vectors: ""
[2019-08-07 17:36:04] [config] ulr-softmax-temperature: 1
[2019-08-07 17:36:04] [config] ulr-trainable-transformation: false
[2019-08-07 17:36:04] [config] valid-freq: 20000
[2019-08-07 17:36:04] [config] valid-log: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/valid.log
[2019-08-07 17:36:04] [config] valid-max-length: 1000
[2019-08-07 17:36:04] [config] valid-metrics:
[2019-08-07 17:36:04] [config]   - cross-entropy
[2019-08-07 17:36:04] [config]   - perplexity
[2019-08-07 17:36:04] [config]   - translation
[2019-08-07 17:36:04] [config] valid-mini-batch: 8
[2019-08-07 17:36:04] [config] valid-script-path: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/score-dev.sh
[2019-08-07 17:36:04] [config] valid-sets:
[2019-08-07 17:36:04] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/dev.bpe.de
[2019-08-07 17:36:04] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/dev.bpe.en
[2019-08-07 17:36:04] [config] valid-translation-output: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/dev.out
[2019-08-07 17:36:04] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 17:36:04] [config] vocabs:
[2019-08-07 17:36:04] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de.json
[2019-08-07 17:36:04] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en.json
[2019-08-07 17:36:04] [config] word-penalty: 0
[2019-08-07 17:36:04] [config] workspace: 3000
[2019-08-07 17:36:04] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 17:36:04] Using synchronous training
[2019-08-07 17:36:04] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de.json
[2019-08-07 17:36:04] [data] Using unused word id eos for 0
[2019-08-07 17:36:04] [data] Using unused word id UNK for 1
[2019-08-07 17:36:04] [data] Setting vocabulary size for input 0 to 50000
[2019-08-07 17:36:04] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en.json
[2019-08-07 17:36:05] [data] Using unused word id eos for 0
[2019-08-07 17:36:08] [data] Using unused word id UNK for 1
[2019-08-07 17:36:08] [data] Setting vocabulary size for input 1 to 50000
[2019-08-07 17:36:08] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-07 17:36:08] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-07 17:36:09] [memory] Extending reserved space to 3072 MB (device gpu1)
[2019-08-07 17:36:10] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 17:36:10] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 17:36:10] [training] Using 1 GPUs
[2019-08-07 17:36:10] [memory] Reserving 422 MB, device gpu1
[2019-08-07 17:36:10] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-07 17:36:10] [memory] Reserving 422 MB, device gpu1
[2019-08-07 17:36:12] [batching] Done. Typical MB size is 4042 target words
[2019-08-07 17:36:13] [memory] Extending reserved space to 3072 MB (device gpu1)
[2019-08-07 17:36:13] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 17:36:13] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 17:36:13] [training] Using 1 GPUs
[2019-08-07 17:36:13] Loading model from ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-07 17:36:16] Loading Adam parameters from ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-07 17:36:18] [memory] Reserving 844 MB, device gpu1
[2019-08-07 17:36:20] [training] Model reloaded from ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 17:36:31] [data] Restoring the corpus state to epoch 6, batch 220000
[2019-08-07 17:36:31] [data] Shuffling data
[2019-08-07 17:36:34] [data] Done reading 5171769 sentences
[2019-08-07 17:37:16] [data] Done shuffling 5171769 sentences to temp files
[2019-08-07 17:38:44] Training started
[2019-08-07 17:38:44] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-07 17:38:44] [memory] Reserving 422 MB, device gpu1
[2019-08-07 17:38:45] [memory] Reserving 422 MB, device gpu1
[2019-08-07 17:38:45] Loading model from ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 17:38:47] [memory] Reserving 422 MB, device cpu0
[2019-08-07 17:38:48] [memory] Reserving 422 MB, device gpu1
[2019-08-07 17:44:08] Ep. 6 : Up. 222000 : Sen. 2,366,975 : Cost 41.08973312 : Time 479.38s : 10112.00 words/s
[2019-08-07 17:49:29] Ep. 6 : Up. 224000 : Sen. 2,587,925 : Cost 40.76732254 : Time 321.25s : 15117.45 words/s
[2019-08-07 17:54:49] Ep. 6 : Up. 226000 : Sen. 2,807,906 : Cost 40.70325470 : Time 319.78s : 15109.87 words/s
[2019-08-07 18:00:10] Ep. 6 : Up. 228000 : Sen. 3,027,380 : Cost 41.13972092 : Time 321.24s : 15053.28 words/s
[2019-08-07 18:05:33] Ep. 6 : Up. 230000 : Sen. 3,248,145 : Cost 40.97521973 : Time 322.84s : 15054.88 words/s
[2019-08-07 18:10:54] Ep. 6 : Up. 232000 : Sen. 3,467,836 : Cost 40.79470444 : Time 321.15s : 15039.28 words/s
[2019-08-07 18:16:19] Ep. 6 : Up. 234000 : Sen. 3,689,065 : Cost 40.75407791 : Time 325.01s : 15018.87 words/s
[2019-08-07 18:21:41] Ep. 6 : Up. 236000 : Sen. 3,910,637 : Cost 40.47288132 : Time 322.29s : 15055.89 words/s
[2019-08-07 18:27:05] Ep. 6 : Up. 238000 : Sen. 4,131,107 : Cost 40.80332565 : Time 323.18s : 15009.74 words/s
[2019-08-07 18:32:27] Ep. 6 : Up. 240000 : Sen. 4,351,348 : Cost 40.75941086 : Time 322.41s : 15020.47 words/s
[2019-08-07 18:32:27] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-07 18:32:36] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter240000.npz
[2019-08-07 18:32:46] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 18:33:02] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-07 18:33:36] [valid] Ep. 6 : Up. 240000 : cross-entropy : 41.4723 : new best
[2019-08-07 18:33:42] [valid] Ep. 6 : Up. 240000 : perplexity : 5.10387 : new best
[2019-08-07 18:34:41] [valid] Ep. 6 : Up. 240000 : translation : 28.04 : new best
[2019-08-07 18:36:28] Seen 4423484 samples
[2019-08-07 18:36:28] Starting epoch 7
[2019-08-07 18:36:28] [data] Shuffling data
[2019-08-07 18:36:31] [data] Done reading 5171769 sentences
[2019-08-07 18:36:47] [data] Done shuffling 5171769 sentences to temp files
[2019-08-07 18:40:35] Ep. 7 : Up. 242000 : Sen. 147,820 : Cost 39.80758286 : Time 488.25s : 9898.29 words/s
[2019-08-07 18:45:58] Ep. 7 : Up. 244000 : Sen. 367,764 : Cost 39.60440826 : Time 323.14s : 14965.56 words/s
[2019-08-07 18:51:22] Ep. 7 : Up. 246000 : Sen. 587,789 : Cost 39.90510941 : Time 323.89s : 14969.94 words/s
[2019-08-07 18:56:46] Ep. 7 : Up. 248000 : Sen. 807,986 : Cost 39.62732315 : Time 324.14s : 14953.34 words/s
[2019-08-07 19:02:11] Ep. 7 : Up. 250000 : Sen. 1,028,702 : Cost 40.04280472 : Time 324.13s : 14992.89 words/s
[2019-08-07 19:07:34] Ep. 7 : Up. 252000 : Sen. 1,249,938 : Cost 39.73607254 : Time 323.55s : 15024.39 words/s
[2019-08-07 19:12:58] Ep. 7 : Up. 254000 : Sen. 1,470,418 : Cost 39.75108719 : Time 323.46s : 14983.74 words/s
[2019-08-07 19:18:22] Ep. 7 : Up. 256000 : Sen. 1,690,648 : Cost 39.96615219 : Time 324.23s : 14979.50 words/s
[2019-08-07 19:23:46] Ep. 7 : Up. 258000 : Sen. 1,911,259 : Cost 39.99641037 : Time 324.30s : 14977.36 words/s
[2019-08-07 19:29:10] Ep. 7 : Up. 260000 : Sen. 2,131,610 : Cost 40.01004791 : Time 323.86s : 14973.89 words/s
[2019-08-07 19:29:10] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-07 19:29:27] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter260000.npz
[2019-08-07 19:29:38] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 19:29:47] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-07 19:30:14] [valid] Ep. 7 : Up. 260000 : cross-entropy : 41.2553 : new best
[2019-08-07 19:30:20] [valid] Ep. 7 : Up. 260000 : perplexity : 5.06052 : new best
[2019-08-07 19:31:18] [valid] Ep. 7 : Up. 260000 : translation : 28.06 : new best
[2019-08-07 19:36:44] Ep. 7 : Up. 262000 : Sen. 2,352,405 : Cost 40.02395248 : Time 454.24s : 10700.59 words/s
[2019-08-07 19:42:09] Ep. 7 : Up. 264000 : Sen. 2,573,304 : Cost 39.95781708 : Time 324.41s : 14965.28 words/s
[2019-08-07 19:47:32] Ep. 7 : Up. 266000 : Sen. 2,792,903 : Cost 39.84505463 : Time 323.48s : 14935.65 words/s
[2019-08-07 19:52:56] Ep. 7 : Up. 268000 : Sen. 3,013,781 : Cost 39.86178207 : Time 323.58s : 14999.60 words/s
[2019-08-07 19:58:19] Ep. 7 : Up. 270000 : Sen. 3,234,032 : Cost 40.29916382 : Time 323.57s : 15007.55 words/s
[2019-08-07 20:03:43] Ep. 7 : Up. 272000 : Sen. 3,454,424 : Cost 40.26185989 : Time 324.23s : 14975.43 words/s
[2019-08-07 20:09:05] Ep. 7 : Up. 274000 : Sen. 3,673,319 : Cost 40.01063538 : Time 321.71s : 14947.33 words/s
[2019-08-07 20:14:27] Ep. 7 : Up. 276000 : Sen. 3,892,619 : Cost 39.94985962 : Time 321.78s : 14985.63 words/s
[2019-08-07 20:19:51] Ep. 7 : Up. 278000 : Sen. 4,114,114 : Cost 40.03935242 : Time 324.44s : 15041.77 words/s
[2019-08-07 20:25:15] Ep. 7 : Up. 280000 : Sen. 4,334,715 : Cost 39.94270706 : Time 323.31s : 14983.19 words/s
[2019-08-07 20:25:15] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-07 20:25:27] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter280000.npz
[2019-08-07 20:25:34] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 20:25:44] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-07 20:26:09] [valid] Ep. 7 : Up. 280000 : cross-entropy : 40.9315 : new best
[2019-08-07 20:26:15] [valid] Ep. 7 : Up. 280000 : perplexity : 4.99652 : new best
[2019-08-07 20:27:11] [valid] Ep. 7 : Up. 280000 : translation : 28.05 : stalled 1 times (last best: 28.06)
[2019-08-07 20:29:24] Seen 4423484 samples
[2019-08-07 20:29:24] Starting epoch 8
[2019-08-07 20:29:24] [data] Shuffling data
[2019-08-07 20:29:27] [data] Done reading 5171769 sentences
[2019-08-07 20:29:47] [data] Done shuffling 5171769 sentences to temp files
[2019-08-07 20:33:12] Ep. 8 : Up. 282000 : Sen. 131,292 : Cost 39.26855469 : Time 477.60s : 10125.66 words/s
[2019-08-07 20:38:37] Ep. 8 : Up. 284000 : Sen. 352,315 : Cost 38.78779984 : Time 324.41s : 15013.70 words/s
[2019-08-07 20:43:59] Ep. 8 : Up. 286000 : Sen. 572,519 : Cost 38.88439941 : Time 322.02s : 15016.77 words/s
[2019-08-07 20:49:22] Ep. 8 : Up. 288000 : Sen. 792,911 : Cost 39.10008240 : Time 323.22s : 15023.99 words/s
[2019-08-07 20:54:45] Ep. 8 : Up. 290000 : Sen. 1,012,580 : Cost 39.16919708 : Time 322.47s : 14990.18 words/s
[2019-08-07 21:00:08] Ep. 8 : Up. 292000 : Sen. 1,233,052 : Cost 39.01219177 : Time 323.39s : 14995.17 words/s
[2019-08-07 21:05:32] Ep. 8 : Up. 294000 : Sen. 1,454,967 : Cost 38.95883942 : Time 324.31s : 15042.57 words/s
[2019-08-07 21:10:56] Ep. 8 : Up. 296000 : Sen. 1,674,944 : Cost 39.33801651 : Time 323.31s : 15007.96 words/s
[2019-08-07 21:16:19] Ep. 8 : Up. 298000 : Sen. 1,896,598 : Cost 38.99159622 : Time 323.56s : 15045.60 words/s
[2019-08-07 21:21:42] Ep. 8 : Up. 300000 : Sen. 2,117,306 : Cost 39.29505539 : Time 322.84s : 15042.78 words/s
[2019-08-07 21:21:42] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-07 21:21:51] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter300000.npz
[2019-08-07 21:21:58] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 21:22:07] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-07 21:22:33] [valid] Ep. 8 : Up. 300000 : cross-entropy : 40.7744 : new best
[2019-08-07 21:22:39] [valid] Ep. 8 : Up. 300000 : perplexity : 4.96577 : new best
[2019-08-07 21:23:35] [valid] Ep. 8 : Up. 300000 : translation : 28.28 : new best
[2019-08-07 21:29:01] Ep. 8 : Up. 302000 : Sen. 2,338,854 : Cost 39.28759003 : Time 439.15s : 11097.01 words/s
[2019-08-07 21:34:25] Ep. 8 : Up. 304000 : Sen. 2,559,795 : Cost 39.21596527 : Time 323.92s : 15026.40 words/s
[2019-08-07 21:39:48] Ep. 8 : Up. 306000 : Sen. 2,780,776 : Cost 39.31369400 : Time 322.72s : 15042.02 words/s
[2019-08-07 21:45:11] Ep. 8 : Up. 308000 : Sen. 3,001,317 : Cost 39.32555008 : Time 323.63s : 14992.38 words/s
[2019-08-07 21:50:35] Ep. 8 : Up. 310000 : Sen. 3,221,114 : Cost 39.36814880 : Time 323.45s : 14969.96 words/s
[2019-08-07 21:55:57] Ep. 8 : Up. 312000 : Sen. 3,440,832 : Cost 39.26482010 : Time 322.24s : 15014.91 words/s
[2019-08-07 22:01:20] Ep. 8 : Up. 314000 : Sen. 3,662,037 : Cost 39.11718369 : Time 322.96s : 15042.87 words/s
[2019-08-07 22:06:44] Ep. 8 : Up. 316000 : Sen. 3,882,711 : Cost 39.43554306 : Time 323.56s : 15027.49 words/s
[2019-08-07 22:12:07] Ep. 8 : Up. 318000 : Sen. 4,102,826 : Cost 39.30697632 : Time 322.92s : 15004.26 words/s
[2019-08-07 22:17:29] Ep. 8 : Up. 320000 : Sen. 4,323,442 : Cost 39.33254623 : Time 322.90s : 15017.35 words/s
[2019-08-07 22:17:29] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-07 22:17:38] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter320000.npz
[2019-08-07 22:17:45] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 22:17:55] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-07 22:18:20] [valid] Ep. 8 : Up. 320000 : cross-entropy : 40.5257 : new best
[2019-08-07 22:18:26] [valid] Ep. 8 : Up. 320000 : perplexity : 4.91748 : new best
[2019-08-07 22:19:24] [valid] Ep. 8 : Up. 320000 : translation : 28.5 : new best
[2019-08-07 22:21:53] Seen 4423484 samples
[2019-08-07 22:21:53] Starting epoch 9
[2019-08-07 22:21:53] [data] Shuffling data
[2019-08-07 22:21:56] [data] Done reading 5171769 sentences
[2019-08-07 22:22:15] [data] Done shuffling 5171769 sentences to temp files
[2019-08-07 22:25:26] Ep. 9 : Up. 322000 : Sen. 120,736 : Cost 38.76229095 : Time 476.58s : 10208.76 words/s
[2019-08-07 22:30:49] Ep. 9 : Up. 324000 : Sen. 341,938 : Cost 38.12656021 : Time 323.31s : 15024.02 words/s
[2019-08-07 22:36:14] Ep. 9 : Up. 326000 : Sen. 562,392 : Cost 38.42247009 : Time 324.43s : 14956.42 words/s
[2019-08-07 22:41:39] Ep. 9 : Up. 328000 : Sen. 783,026 : Cost 38.42306137 : Time 325.09s : 14951.74 words/s
[2019-08-07 22:47:03] Ep. 9 : Up. 330000 : Sen. 1,003,531 : Cost 38.46799469 : Time 324.13s : 14944.03 words/s
[2019-08-07 22:52:27] Ep. 9 : Up. 332000 : Sen. 1,223,651 : Cost 38.42829895 : Time 323.88s : 14962.59 words/s
[2019-08-07 22:57:51] Ep. 9 : Up. 334000 : Sen. 1,444,577 : Cost 38.53961563 : Time 323.88s : 15019.32 words/s
[2019-08-07 23:03:14] Ep. 9 : Up. 336000 : Sen. 1,666,169 : Cost 38.62919235 : Time 323.73s : 15039.61 words/s
[2019-08-07 23:08:38] Ep. 9 : Up. 338000 : Sen. 1,887,428 : Cost 38.62553024 : Time 323.81s : 15021.67 words/s
[2019-08-07 23:14:01] Ep. 9 : Up. 340000 : Sen. 2,107,706 : Cost 38.61941910 : Time 323.13s : 15010.53 words/s
[2019-08-07 23:14:01] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-07 23:14:12] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter340000.npz
[2019-08-07 23:14:19] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 23:14:28] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-07 23:14:54] [valid] Ep. 9 : Up. 340000 : cross-entropy : 40.4285 : new best
[2019-08-07 23:15:00] [valid] Ep. 9 : Up. 340000 : perplexity : 4.89873 : new best
[2019-08-07 23:15:57] [valid] Ep. 9 : Up. 340000 : translation : 28.22 : stalled 1 times (last best: 28.5)
[2019-08-07 23:21:22] Ep. 9 : Up. 342000 : Sen. 2,328,973 : Cost 38.29936981 : Time 440.73s : 11010.41 words/s
[2019-08-07 23:26:46] Ep. 9 : Up. 344000 : Sen. 2,549,195 : Cost 38.85800552 : Time 323.62s : 14975.94 words/s
[2019-08-07 23:32:10] Ep. 9 : Up. 346000 : Sen. 2,769,160 : Cost 38.88819504 : Time 324.22s : 14985.16 words/s
[2019-08-07 23:37:33] Ep. 9 : Up. 348000 : Sen. 2,989,699 : Cost 38.64761734 : Time 322.78s : 15014.97 words/s
[2019-08-07 23:42:54] Ep. 9 : Up. 350000 : Sen. 3,210,231 : Cost 38.83834457 : Time 321.20s : 15080.70 words/s
[2019-08-07 23:48:15] Ep. 9 : Up. 352000 : Sen. 3,430,651 : Cost 38.78516006 : Time 321.39s : 15117.37 words/s
[2019-08-07 23:53:37] Ep. 9 : Up. 354000 : Sen. 3,652,177 : Cost 38.83741760 : Time 321.86s : 15159.70 words/s
[2019-08-07 23:58:59] Ep. 9 : Up. 356000 : Sen. 3,873,056 : Cost 38.83546829 : Time 321.96s : 15105.00 words/s
[2019-08-08 00:04:21] Ep. 9 : Up. 358000 : Sen. 4,094,258 : Cost 38.79389954 : Time 321.47s : 15132.63 words/s
[2019-08-08 00:09:43] Ep. 9 : Up. 360000 : Sen. 4,315,075 : Cost 38.96099854 : Time 321.91s : 15126.26 words/s
[2019-08-08 00:09:43] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-08 00:09:53] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter360000.npz
[2019-08-08 00:10:04] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-08 00:10:13] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-08 00:10:39] [valid] Ep. 9 : Up. 360000 : cross-entropy : 40.253 : new best
[2019-08-08 00:10:45] [valid] Ep. 9 : Up. 360000 : perplexity : 4.86504 : new best
[2019-08-08 00:11:46] [valid] Ep. 9 : Up. 360000 : translation : 28.26 : stalled 2 times (last best: 28.5)
[2019-08-08 00:14:26] Seen 4423484 samples
[2019-08-08 00:14:26] Starting epoch 10
[2019-08-08 00:14:26] [data] Shuffling data
[2019-08-08 00:14:29] [data] Done reading 5171769 sentences
[2019-08-08 00:14:51] [data] Done shuffling 5171769 sentences to temp files
[2019-08-08 00:17:41] Ep. 10 : Up. 362000 : Sen. 111,907 : Cost 38.34936905 : Time 478.62s : 10141.83 words/s
[2019-08-08 00:23:01] Ep. 10 : Up. 364000 : Sen. 332,878 : Cost 37.64904022 : Time 320.23s : 15153.10 words/s
[2019-08-08 00:28:22] Ep. 10 : Up. 366000 : Sen. 552,332 : Cost 38.12252808 : Time 320.40s : 15093.81 words/s
[2019-08-08 00:33:43] Ep. 10 : Up. 368000 : Sen. 772,954 : Cost 37.82938385 : Time 321.33s : 15101.60 words/s
[2019-08-08 00:39:04] Ep. 10 : Up. 370000 : Sen. 993,652 : Cost 38.02827454 : Time 321.00s : 15134.42 words/s
[2019-08-08 00:44:26] Ep. 10 : Up. 372000 : Sen. 1,214,209 : Cost 38.08669281 : Time 321.49s : 15116.61 words/s
[2019-08-08 00:49:47] Ep. 10 : Up. 374000 : Sen. 1,434,761 : Cost 37.85890579 : Time 320.92s : 15098.85 words/s
[2019-08-08 00:55:08] Ep. 10 : Up. 376000 : Sen. 1,655,352 : Cost 38.30460358 : Time 321.32s : 15117.90 words/s
[2019-08-08 01:00:29] Ep. 10 : Up. 378000 : Sen. 1,876,244 : Cost 38.17219162 : Time 321.01s : 15152.82 words/s
[2019-08-08 01:05:50] Ep. 10 : Up. 380000 : Sen. 2,096,361 : Cost 38.16708755 : Time 320.77s : 15066.47 words/s
[2019-08-08 01:05:50] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-08 01:05:59] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter380000.npz
[2019-08-08 01:06:06] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-08 01:06:15] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-08 01:06:47] [valid] Ep. 10 : Up. 380000 : cross-entropy : 40.1682 : new best
[2019-08-08 01:06:53] [valid] Ep. 10 : Up. 380000 : perplexity : 4.84886 : new best
[2019-08-08 01:07:48] [valid] Ep. 10 : Up. 380000 : translation : 28.39 : stalled 3 times (last best: 28.5)
[2019-08-08 01:13:10] Ep. 10 : Up. 382000 : Sen. 2,316,485 : Cost 38.40989685 : Time 440.56s : 11007.69 words/s
[2019-08-08 01:18:30] Ep. 10 : Up. 384000 : Sen. 2,537,389 : Cost 38.24923325 : Time 319.94s : 15159.60 words/s
[2019-08-08 01:23:51] Ep. 10 : Up. 386000 : Sen. 2,757,238 : Cost 38.22978973 : Time 321.15s : 15085.10 words/s
[2019-08-08 01:29:13] Ep. 10 : Up. 388000 : Sen. 2,977,596 : Cost 38.45858383 : Time 321.53s : 15138.47 words/s
[2019-08-08 01:34:35] Ep. 10 : Up. 390000 : Sen. 3,198,005 : Cost 38.25091934 : Time 322.19s : 15045.81 words/s
[2019-08-08 01:39:56] Ep. 10 : Up. 392000 : Sen. 3,417,989 : Cost 38.22764206 : Time 320.99s : 15079.08 words/s
[2019-08-08 01:45:16] Ep. 10 : Up. 394000 : Sen. 3,638,234 : Cost 38.19966507 : Time 320.23s : 15138.99 words/s
[2019-08-08 01:50:37] Ep. 10 : Up. 396000 : Sen. 3,859,200 : Cost 38.16965866 : Time 320.65s : 15155.68 words/s
[2019-08-08 01:55:57] Ep. 10 : Up. 398000 : Sen. 4,079,803 : Cost 38.13915634 : Time 320.10s : 15145.94 words/s
[2019-08-08 02:01:17] Ep. 10 : Up. 400000 : Sen. 4,299,824 : Cost 38.23757553 : Time 320.28s : 15093.60 words/s
[2019-08-08 02:01:17] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-08 02:01:26] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter400000.npz
[2019-08-08 02:01:33] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-08 02:01:43] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-08 02:02:15] [valid] Ep. 10 : Up. 400000 : cross-entropy : 40.0049 : new best
[2019-08-08 02:02:22] [valid] Ep. 10 : Up. 400000 : perplexity : 4.81784 : new best
[2019-08-08 02:03:16] [valid] Ep. 10 : Up. 400000 : translation : 28.46 : stalled 4 times (last best: 28.5)
[2019-08-08 02:06:18] Seen 4423484 samples
[2019-08-08 02:06:18] Starting epoch 11
[2019-08-08 02:06:18] [data] Shuffling data
[2019-08-08 02:06:20] [data] Done reading 5171769 sentences
[2019-08-08 02:06:42] [data] Done shuffling 5171769 sentences to temp files
[2019-08-08 02:09:10] Ep. 11 : Up. 402000 : Sen. 96,595 : Cost 38.14015198 : Time 472.28s : 10275.17 words/s
[2019-08-08 02:14:30] Ep. 11 : Up. 404000 : Sen. 316,648 : Cost 37.25236511 : Time 320.81s : 15107.36 words/s
[2019-08-08 02:19:52] Ep. 11 : Up. 406000 : Sen. 537,522 : Cost 37.39751053 : Time 321.27s : 15122.80 words/s
[2019-08-08 02:25:12] Ep. 11 : Up. 408000 : Sen. 758,090 : Cost 37.56749725 : Time 320.34s : 15167.17 words/s
[2019-08-08 02:30:33] Ep. 11 : Up. 410000 : Sen. 979,019 : Cost 37.34541702 : Time 320.50s : 15152.87 words/s
[2019-08-08 02:35:53] Ep. 11 : Up. 412000 : Sen. 1,198,506 : Cost 37.85366440 : Time 320.53s : 15124.90 words/s
[2019-08-08 02:41:13] Ep. 11 : Up. 414000 : Sen. 1,418,952 : Cost 37.48857498 : Time 320.24s : 15129.80 words/s
[2019-08-08 02:46:33] Ep. 11 : Up. 416000 : Sen. 1,639,321 : Cost 37.74030685 : Time 319.61s : 15155.48 words/s
[2019-08-08 02:51:53] Ep. 11 : Up. 418000 : Sen. 1,859,539 : Cost 37.74010849 : Time 319.95s : 15131.62 words/s
[2019-08-08 02:57:13] Ep. 11 : Up. 420000 : Sen. 2,080,078 : Cost 37.77745438 : Time 320.57s : 15135.87 words/s
[2019-08-08 02:57:13] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-08 02:57:23] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter420000.npz
[2019-08-08 02:57:30] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-08 02:57:39] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-08 02:58:04] [valid] Ep. 11 : Up. 420000 : cross-entropy : 39.9917 : new best
[2019-08-08 02:58:10] [valid] Ep. 11 : Up. 420000 : perplexity : 4.81533 : new best
[2019-08-08 02:59:04] [valid] Ep. 11 : Up. 420000 : translation : 28.58 : new best
[2019-08-08 03:04:26] Ep. 11 : Up. 422000 : Sen. 2,300,661 : Cost 37.81863403 : Time 433.00s : 11214.89 words/s
[2019-08-08 03:09:47] Ep. 11 : Up. 424000 : Sen. 2,521,600 : Cost 37.60832977 : Time 320.07s : 15183.28 words/s
[2019-08-08 03:15:07] Ep. 11 : Up. 426000 : Sen. 2,742,908 : Cost 37.90666962 : Time 320.51s : 15175.87 words/s
[2019-08-08 03:20:27] Ep. 11 : Up. 428000 : Sen. 2,962,995 : Cost 37.88784027 : Time 320.09s : 15124.46 words/s
[2019-08-08 03:25:46] Ep. 11 : Up. 430000 : Sen. 3,182,420 : Cost 37.94152451 : Time 319.06s : 15136.62 words/s
[2019-08-08 03:31:08] Ep. 11 : Up. 432000 : Sen. 3,403,629 : Cost 38.05283356 : Time 321.64s : 15134.21 words/s
[2019-08-08 03:36:27] Ep. 11 : Up. 434000 : Sen. 3,623,162 : Cost 37.81478119 : Time 319.28s : 15133.89 words/s
[2019-08-08 03:41:46] Ep. 11 : Up. 436000 : Sen. 3,843,098 : Cost 37.97263336 : Time 318.95s : 15171.43 words/s
[2019-08-08 03:47:06] Ep. 11 : Up. 438000 : Sen. 4,063,844 : Cost 37.67152405 : Time 319.53s : 15163.38 words/s
[2019-08-08 03:52:26] Ep. 11 : Up. 440000 : Sen. 4,284,135 : Cost 37.99661255 : Time 320.71s : 15106.80 words/s
[2019-08-08 03:52:26] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-08 03:52:36] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter440000.npz
[2019-08-08 03:52:43] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-08 03:52:53] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-08 03:53:25] [valid] Ep. 11 : Up. 440000 : cross-entropy : 39.8196 : new best
[2019-08-08 03:53:31] [valid] Ep. 11 : Up. 440000 : perplexity : 4.78287 : new best
[2019-08-08 03:54:25] [valid] Ep. 11 : Up. 440000 : translation : 28.83 : new best
[2019-08-08 03:57:49] Seen 4423484 samples
[2019-08-08 03:57:49] Starting epoch 12
[2019-08-08 03:57:49] [data] Shuffling data
[2019-08-08 03:57:52] [data] Done reading 5171769 sentences
[2019-08-08 03:58:13] [data] Done shuffling 5171769 sentences to temp files
[2019-08-08 04:00:18] Ep. 12 : Up. 442000 : Sen. 81,190 : Cost 37.33960724 : Time 472.20s : 10261.64 words/s
[2019-08-08 04:05:39] Ep. 12 : Up. 444000 : Sen. 300,800 : Cost 36.97235107 : Time 320.07s : 15138.53 words/s
[2019-08-08 04:10:58] Ep. 12 : Up. 446000 : Sen. 520,154 : Cost 37.15283585 : Time 319.27s : 15131.60 words/s
[2019-08-08 04:16:18] Ep. 12 : Up. 448000 : Sen. 740,217 : Cost 37.12758255 : Time 320.35s : 15116.94 words/s
[2019-08-08 04:21:39] Ep. 12 : Up. 450000 : Sen. 960,416 : Cost 37.11642075 : Time 320.43s : 15112.63 words/s
[2019-08-08 04:27:00] Ep. 12 : Up. 452000 : Sen. 1,181,065 : Cost 37.23016739 : Time 320.92s : 15149.13 words/s
[2019-08-08 04:32:19] Ep. 12 : Up. 454000 : Sen. 1,402,120 : Cost 37.06766510 : Time 319.84s : 15174.87 words/s
[2019-08-08 04:37:40] Ep. 12 : Up. 456000 : Sen. 1,622,872 : Cost 37.33732986 : Time 320.92s : 15156.22 words/s
[2019-08-08 04:43:01] Ep. 12 : Up. 458000 : Sen. 1,843,798 : Cost 37.63227844 : Time 320.40s : 15210.67 words/s
[2019-08-08 04:48:21] Ep. 12 : Up. 460000 : Sen. 2,063,903 : Cost 37.53703690 : Time 320.02s : 15149.33 words/s
[2019-08-08 04:48:21] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-08 04:48:30] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter460000.npz
[2019-08-08 04:48:38] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-08 04:48:48] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-08 04:49:14] [valid] Ep. 12 : Up. 460000 : cross-entropy : 39.7985 : new best
[2019-08-08 04:49:21] [valid] Ep. 12 : Up. 460000 : perplexity : 4.77891 : new best
[2019-08-08 04:50:15] [valid] Ep. 12 : Up. 460000 : translation : 28.5 : stalled 1 times (last best: 28.83)
[2019-08-08 04:55:37] Ep. 12 : Up. 462000 : Sen. 2,285,094 : Cost 37.64051056 : Time 436.69s : 11150.73 words/s
[2019-08-08 05:00:58] Ep. 12 : Up. 464000 : Sen. 2,505,865 : Cost 37.35423279 : Time 320.87s : 15116.49 words/s
[2019-08-08 05:06:18] Ep. 12 : Up. 466000 : Sen. 2,726,322 : Cost 37.35142136 : Time 319.74s : 15143.29 words/s
[2019-08-08 05:11:39] Ep. 12 : Up. 468000 : Sen. 2,947,339 : Cost 37.44544601 : Time 320.57s : 15134.67 words/s
[2019-08-08 05:17:00] Ep. 12 : Up. 470000 : Sen. 3,168,264 : Cost 37.64271545 : Time 321.42s : 15168.83 words/s
[2019-08-08 05:22:22] Ep. 12 : Up. 472000 : Sen. 3,389,442 : Cost 37.59252167 : Time 321.86s : 15141.70 words/s
[2019-08-08 05:27:43] Ep. 12 : Up. 474000 : Sen. 3,610,234 : Cost 37.70275116 : Time 320.87s : 15150.46 words/s
[2019-08-08 05:33:01] Ep. 12 : Up. 476000 : Sen. 3,829,539 : Cost 37.55701828 : Time 318.60s : 15151.38 words/s
[2019-08-08 05:38:20] Ep. 12 : Up. 478000 : Sen. 4,049,904 : Cost 37.26902390 : Time 318.26s : 15189.15 words/s
[2019-08-08 05:43:39] Ep. 12 : Up. 480000 : Sen. 4,270,475 : Cost 37.67965317 : Time 319.49s : 15194.41 words/s
[2019-08-08 05:43:39] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-08 05:43:48] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter480000.npz
[2019-08-08 05:43:55] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-08 05:44:05] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-08 05:44:34] [valid] Ep. 12 : Up. 480000 : cross-entropy : 39.6883 : new best
[2019-08-08 05:44:41] [valid] Ep. 12 : Up. 480000 : perplexity : 4.75825 : new best
[2019-08-08 05:45:35] [valid] Ep. 12 : Up. 480000 : translation : 28.68 : stalled 2 times (last best: 28.83)
[2019-08-08 05:49:18] Seen 4423484 samples
[2019-08-08 05:49:18] Starting epoch 13
[2019-08-08 05:49:18] [data] Shuffling data
[2019-08-08 05:49:21] [data] Done reading 5171769 sentences
[2019-08-08 05:49:42] [data] Done shuffling 5171769 sentences to temp files
[2019-08-08 05:51:27] Ep. 13 : Up. 482000 : Sen. 67,266 : Cost 37.26530457 : Time 467.82s : 10328.52 words/s
[2019-08-08 05:56:47] Ep. 13 : Up. 484000 : Sen. 287,637 : Cost 36.56108093 : Time 320.50s : 15159.86 words/s
[2019-08-08 06:02:06] Ep. 13 : Up. 486000 : Sen. 507,968 : Cost 36.76774216 : Time 318.99s : 15205.96 words/s
[2019-08-08 06:07:25] Ep. 13 : Up. 488000 : Sen. 728,089 : Cost 36.90976334 : Time 319.08s : 15177.75 words/s
[2019-08-08 06:12:46] Ep. 13 : Up. 490000 : Sen. 948,854 : Cost 36.87734604 : Time 320.51s : 15161.46 words/s
[2019-08-08 06:18:06] Ep. 13 : Up. 492000 : Sen. 1,169,961 : Cost 36.99839783 : Time 320.05s : 15181.11 words/s
[2019-08-08 06:23:27] Ep. 13 : Up. 494000 : Sen. 1,390,974 : Cost 37.15819931 : Time 321.08s : 15197.61 words/s
[2019-08-08 06:28:48] Ep. 13 : Up. 496000 : Sen. 1,611,914 : Cost 36.90619659 : Time 320.79s : 15156.98 words/s
[2019-08-08 06:34:10] Ep. 13 : Up. 498000 : Sen. 1,832,592 : Cost 37.09085083 : Time 321.58s : 15091.06 words/s
[2019-08-08 06:39:30] Ep. 13 : Up. 500000 : Sen. 2,052,865 : Cost 36.81774521 : Time 320.66s : 15102.64 words/s
[2019-08-08 06:39:30] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-08 06:39:40] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter500000.npz
[2019-08-08 06:39:47] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-08 06:39:56] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-08 06:40:21] [valid] Ep. 13 : Up. 500000 : cross-entropy : 39.695 : stalled 1 times (last best: 39.6883)
[2019-08-08 06:40:27] [valid] Ep. 13 : Up. 500000 : perplexity : 4.75952 : stalled 1 times (last best: 4.75825)
[2019-08-08 06:41:22] [valid] Ep. 13 : Up. 500000 : translation : 28.57 : stalled 3 times (last best: 28.83)
[2019-08-08 06:46:44] Ep. 13 : Up. 502000 : Sen. 2,273,168 : Cost 37.12669754 : Time 433.62s : 11167.62 words/s
[2019-08-08 06:52:03] Ep. 13 : Up. 504000 : Sen. 2,494,129 : Cost 37.08723831 : Time 319.57s : 15192.63 words/s
[2019-08-08 06:57:25] Ep. 13 : Up. 506000 : Sen. 2,713,985 : Cost 37.15101624 : Time 321.22s : 15056.81 words/s
[2019-08-08 07:02:47] Ep. 13 : Up. 508000 : Sen. 2,935,047 : Cost 36.98375320 : Time 322.49s : 15103.11 words/s
[2019-08-08 07:08:10] Ep. 13 : Up. 510000 : Sen. 3,156,606 : Cost 37.24399185 : Time 322.70s : 15119.76 words/s
[2019-08-08 07:13:29] Ep. 13 : Up. 512000 : Sen. 3,377,250 : Cost 37.23744965 : Time 319.67s : 15166.66 words/s
[2019-08-08 07:18:51] Ep. 13 : Up. 514000 : Sen. 3,598,520 : Cost 37.23894119 : Time 321.19s : 15154.66 words/s
[2019-08-08 07:24:11] Ep. 13 : Up. 516000 : Sen. 3,819,582 : Cost 37.42714691 : Time 320.05s : 15213.26 words/s
[2019-08-08 07:29:31] Ep. 13 : Up. 518000 : Sen. 4,040,568 : Cost 37.24655914 : Time 319.98s : 15179.26 words/s
[2019-08-08 07:34:51] Ep. 13 : Up. 520000 : Sen. 4,260,843 : Cost 37.16613007 : Time 320.13s : 15175.63 words/s
[2019-08-08 07:34:51] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-08 07:35:00] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter520000.npz
[2019-08-08 07:35:08] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-08 07:35:17] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-08 07:35:42] [valid] Ep. 13 : Up. 520000 : cross-entropy : 39.5785 : new best
[2019-08-08 07:35:48] [valid] Ep. 13 : Up. 520000 : perplexity : 4.73776 : new best
[2019-08-08 07:36:42] [valid] Ep. 13 : Up. 520000 : translation : 28.74 : stalled 4 times (last best: 28.83)
[2019-08-08 07:40:39] Seen 4423484 samples
[2019-08-08 07:40:39] Starting epoch 14
[2019-08-08 07:40:39] [data] Shuffling data
[2019-08-08 07:40:41] [data] Done reading 5171769 sentences
[2019-08-08 07:40:57] [data] Done shuffling 5171769 sentences to temp files
[2019-08-08 07:42:29] Ep. 14 : Up. 522000 : Sen. 58,276 : Cost 36.79424286 : Time 458.65s : 10573.40 words/s
[2019-08-08 07:47:47] Ep. 14 : Up. 524000 : Sen. 279,072 : Cost 36.15831757 : Time 318.05s : 15255.03 words/s
[2019-08-08 07:53:06] Ep. 14 : Up. 526000 : Sen. 498,987 : Cost 36.39332962 : Time 318.04s : 15224.29 words/s
[2019-08-08 07:58:23] Ep. 14 : Up. 528000 : Sen. 718,962 : Cost 36.30900192 : Time 317.18s : 15250.97 words/s
[2019-08-08 08:03:42] Ep. 14 : Up. 530000 : Sen. 939,937 : Cost 36.52637100 : Time 318.82s : 15250.69 words/s
[2019-08-08 08:09:01] Ep. 14 : Up. 532000 : Sen. 1,160,646 : Cost 36.63891220 : Time 319.53s : 15232.81 words/s
[2019-08-08 08:14:20] Ep. 14 : Up. 534000 : Sen. 1,380,773 : Cost 36.69868088 : Time 319.05s : 15203.62 words/s
[2019-08-08 08:19:39] Ep. 14 : Up. 536000 : Sen. 1,601,250 : Cost 36.72485733 : Time 318.96s : 15206.26 words/s
[2019-08-08 08:24:57] Ep. 14 : Up. 538000 : Sen. 1,820,649 : Cost 36.61602783 : Time 317.67s : 15218.17 words/s
[2019-08-08 08:30:17] Ep. 14 : Up. 540000 : Sen. 2,040,359 : Cost 36.51759720 : Time 319.99s : 15089.53 words/s
[2019-08-08 08:30:17] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-08 08:30:29] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter540000.npz
[2019-08-08 08:30:37] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-08 08:30:47] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-08 08:31:15] [valid] Ep. 14 : Up. 540000 : cross-entropy : 39.6127 : stalled 1 times (last best: 39.5785)
[2019-08-08 08:31:22] [valid] Ep. 14 : Up. 540000 : perplexity : 4.74414 : stalled 1 times (last best: 4.73776)
[2019-08-08 08:32:26] [valid] Ep. 14 : Up. 540000 : translation : 28.86 : new best
[2019-08-08 08:37:52] Ep. 14 : Up. 542000 : Sen. 2,260,414 : Cost 36.85886383 : Time 455.38s : 10636.46 words/s
[2019-08-08 08:43:17] Ep. 14 : Up. 544000 : Sen. 2,481,410 : Cost 36.74587631 : Time 324.99s : 14950.81 words/s
[2019-08-08 08:48:43] Ep. 14 : Up. 546000 : Sen. 2,701,239 : Cost 36.84068298 : Time 325.70s : 14849.68 words/s
[2019-08-08 08:54:07] Ep. 14 : Up. 548000 : Sen. 2,921,065 : Cost 36.89348602 : Time 324.09s : 14910.73 words/s
[2019-08-08 08:59:32] Ep. 14 : Up. 550000 : Sen. 3,140,809 : Cost 36.84839249 : Time 325.18s : 14875.26 words/s
[2019-08-08 09:04:58] Ep. 14 : Up. 552000 : Sen. 3,361,546 : Cost 36.69287491 : Time 326.20s : 14864.77 words/s
[2019-08-08 09:10:24] Ep. 14 : Up. 554000 : Sen. 3,581,580 : Cost 37.12229156 : Time 325.86s : 14890.59 words/s
[2019-08-08 09:15:49] Ep. 14 : Up. 556000 : Sen. 3,801,581 : Cost 37.05240631 : Time 324.32s : 14934.87 words/s
[2019-08-08 09:21:14] Ep. 14 : Up. 558000 : Sen. 4,022,018 : Cost 36.92449570 : Time 325.21s : 14909.72 words/s
[2019-08-08 09:26:39] Ep. 14 : Up. 560000 : Sen. 4,243,200 : Cost 37.05069351 : Time 325.11s : 14958.83 words/s
[2019-08-08 09:26:39] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-08 09:26:50] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter560000.npz
[2019-08-08 09:26:59] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-08 09:27:09] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-08 09:27:38] [valid] Ep. 14 : Up. 560000 : cross-entropy : 39.4306 : new best
[2019-08-08 09:27:44] [valid] Ep. 14 : Up. 560000 : perplexity : 4.71031 : new best
[2019-08-08 09:28:55] [valid] Ep. 14 : Up. 560000 : translation : 28.9 : new best
[2019-08-08 09:33:22] Seen 4423484 samples
[2019-08-08 09:33:22] Starting epoch 15
[2019-08-08 09:33:22] [data] Shuffling data
[2019-08-08 09:33:41] [data] Done reading 5171769 sentences
[2019-08-08 09:34:12] [data] Done shuffling 5171769 sentences to temp files
[2019-08-08 09:35:14] Ep. 15 : Up. 562000 : Sen. 41,645 : Cost 36.80649567 : Time 515.59s : 9480.29 words/s
[2019-08-08 09:40:41] Ep. 15 : Up. 564000 : Sen. 262,715 : Cost 35.87897873 : Time 326.69s : 14878.64 words/s
[2019-08-08 09:46:06] Ep. 15 : Up. 566000 : Sen. 482,128 : Cost 36.15354156 : Time 325.06s : 14880.87 words/s
[2019-08-08 09:51:32] Ep. 15 : Up. 568000 : Sen. 702,459 : Cost 36.17083740 : Time 325.85s : 14880.86 words/s
[2019-08-08 09:56:57] Ep. 15 : Up. 570000 : Sen. 922,976 : Cost 35.99095154 : Time 325.31s : 14908.15 words/s
[2019-08-08 10:02:22] Ep. 15 : Up. 572000 : Sen. 1,142,726 : Cost 36.35248566 : Time 325.02s : 14902.73 words/s
[2019-08-08 10:07:48] Ep. 15 : Up. 574000 : Sen. 1,363,200 : Cost 36.28780365 : Time 325.89s : 14880.24 words/s
[2019-08-08 10:13:14] Ep. 15 : Up. 576000 : Sen. 1,584,980 : Cost 36.19031906 : Time 326.07s : 14910.75 words/s
[2019-08-08 10:18:41] Ep. 15 : Up. 578000 : Sen. 1,804,722 : Cost 36.57486725 : Time 326.13s : 14883.06 words/s
[2019-08-08 10:24:06] Ep. 15 : Up. 580000 : Sen. 2,025,610 : Cost 36.38184738 : Time 324.99s : 14907.22 words/s
[2019-08-08 10:24:06] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-08 10:24:17] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter580000.npz
[2019-08-08 10:24:26] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-08 10:24:36] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-08 10:25:06] [valid] Ep. 15 : Up. 580000 : cross-entropy : 39.4495 : stalled 1 times (last best: 39.4306)
[2019-08-08 10:25:12] [valid] Ep. 15 : Up. 580000 : perplexity : 4.71381 : stalled 1 times (last best: 4.71031)
[2019-08-08 10:26:12] [valid] Ep. 15 : Up. 580000 : translation : 28.91 : new best
[2019-08-08 10:31:40] Ep. 15 : Up. 582000 : Sen. 2,246,298 : Cost 36.59080505 : Time 454.89s : 10683.86 words/s
[2019-08-08 10:37:06] Ep. 15 : Up. 584000 : Sen. 2,467,002 : Cost 36.54050827 : Time 326.06s : 14913.72 words/s
[2019-08-08 10:42:32] Ep. 15 : Up. 586000 : Sen. 2,687,504 : Cost 36.57794571 : Time 325.78s : 14876.83 words/s
[2019-08-08 10:47:57] Ep. 15 : Up. 588000 : Sen. 2,906,177 : Cost 36.63016510 : Time 324.30s : 14853.40 words/s
[2019-08-08 10:53:23] Ep. 15 : Up. 590000 : Sen. 3,126,849 : Cost 36.72790146 : Time 326.68s : 14873.71 words/s
[2019-08-08 10:58:50] Ep. 15 : Up. 592000 : Sen. 3,347,581 : Cost 36.64020920 : Time 326.73s : 14846.07 words/s
[2019-08-08 11:04:18] Ep. 15 : Up. 594000 : Sen. 3,568,894 : Cost 36.79348373 : Time 327.85s : 14858.83 words/s
[2019-08-08 11:09:44] Ep. 15 : Up. 596000 : Sen. 3,789,382 : Cost 36.62664795 : Time 326.57s : 14866.17 words/s
[2019-08-08 11:15:12] Ep. 15 : Up. 598000 : Sen. 4,010,606 : Cost 36.85456085 : Time 327.50s : 14844.00 words/s
[2019-08-08 11:20:39] Ep. 15 : Up. 600000 : Sen. 4,231,913 : Cost 36.71401978 : Time 326.90s : 14876.41 words/s
[2019-08-08 11:20:39] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-08 11:20:50] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter600000.npz
[2019-08-08 11:20:58] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-08 11:21:10] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-08 11:21:38] [valid] Ep. 15 : Up. 600000 : cross-entropy : 39.3642 : new best
[2019-08-08 11:21:44] [valid] Ep. 15 : Up. 600000 : perplexity : 4.69803 : new best
[2019-08-08 11:22:47] [valid] Ep. 15 : Up. 600000 : translation : 28.83 : stalled 1 times (last best: 28.91)
[2019-08-08 11:27:34] Seen 4423484 samples
[2019-08-08 11:27:34] Starting epoch 16
[2019-08-08 11:27:34] [data] Shuffling data
[2019-08-08 11:27:52] [data] Done reading 5171769 sentences
[2019-08-08 11:28:13] [data] Done shuffling 5171769 sentences to temp files
[2019-08-08 11:29:00] Ep. 16 : Up. 602000 : Sen. 28,466 : Cost 36.58836365 : Time 501.60s : 9662.10 words/s
[2019-08-08 11:34:27] Ep. 16 : Up. 604000 : Sen. 248,979 : Cost 35.69688797 : Time 326.64s : 14844.78 words/s
[2019-08-08 11:39:56] Ep. 16 : Up. 606000 : Sen. 469,733 : Cost 35.91317368 : Time 328.75s : 14764.14 words/s
[2019-08-08 11:45:24] Ep. 16 : Up. 608000 : Sen. 690,743 : Cost 35.84212494 : Time 327.99s : 14839.84 words/s
[2019-08-08 11:50:51] Ep. 16 : Up. 610000 : Sen. 911,693 : Cost 35.97167587 : Time 326.87s : 14884.75 words/s
[2019-08-08 11:56:17] Ep. 16 : Up. 612000 : Sen. 1,131,425 : Cost 36.00948715 : Time 326.71s : 14811.90 words/s
[2019-08-08 12:01:44] Ep. 16 : Up. 614000 : Sen. 1,351,613 : Cost 36.10473251 : Time 326.53s : 14831.43 words/s
[2019-08-08 12:07:11] Ep. 16 : Up. 616000 : Sen. 1,571,220 : Cost 36.49954987 : Time 327.03s : 14817.40 words/s
[2019-08-08 12:12:39] Ep. 16 : Up. 618000 : Sen. 1,791,922 : Cost 35.94697189 : Time 327.96s : 14785.22 words/s
[2019-08-08 12:18:06] Ep. 16 : Up. 620000 : Sen. 2,011,465 : Cost 36.31052399 : Time 326.88s : 14793.76 words/s
[2019-08-08 12:18:06] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-08 12:18:18] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter620000.npz
[2019-08-08 12:18:26] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-08 12:18:37] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-08 12:19:13] [valid] Ep. 16 : Up. 620000 : cross-entropy : 39.3996 : stalled 1 times (last best: 39.3642)
[2019-08-08 12:19:20] [valid] Ep. 16 : Up. 620000 : perplexity : 4.70458 : stalled 1 times (last best: 4.69803)
[2019-08-08 12:20:19] [valid] Ep. 16 : Up. 620000 : translation : 28.99 : new best
[2019-08-08 12:25:49] Ep. 16 : Up. 622000 : Sen. 2,231,913 : Cost 36.18671799 : Time 463.10s : 10472.67 words/s
[2019-08-08 12:31:17] Ep. 16 : Up. 624000 : Sen. 2,451,914 : Cost 36.39310455 : Time 328.12s : 14770.76 words/s
[2019-08-08 12:36:46] Ep. 16 : Up. 626000 : Sen. 2,672,068 : Cost 36.41386795 : Time 329.11s : 14732.54 words/s
[2019-08-08 12:42:15] Ep. 16 : Up. 628000 : Sen. 2,892,424 : Cost 36.41851425 : Time 329.12s : 14713.88 words/s
[2019-08-08 12:47:44] Ep. 16 : Up. 630000 : Sen. 3,112,151 : Cost 36.42134476 : Time 328.57s : 14709.03 words/s
[2019-08-08 12:53:14] Ep. 16 : Up. 632000 : Sen. 3,334,322 : Cost 36.26422501 : Time 329.94s : 14774.34 words/s
[2019-08-08 12:58:42] Ep. 16 : Up. 634000 : Sen. 3,554,276 : Cost 36.55156326 : Time 328.51s : 14731.99 words/s
[2019-08-08 13:04:10] Ep. 16 : Up. 636000 : Sen. 3,774,591 : Cost 36.45994186 : Time 328.13s : 14765.04 words/s
[2019-08-08 13:09:39] Ep. 16 : Up. 638000 : Sen. 3,995,273 : Cost 36.61673737 : Time 328.29s : 14822.49 words/s
[2019-08-08 13:15:07] Ep. 16 : Up. 640000 : Sen. 4,216,553 : Cost 36.59560776 : Time 328.03s : 14813.00 words/s
[2019-08-08 13:15:07] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-08 13:15:19] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter640000.npz
[2019-08-08 13:15:27] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-08 13:15:39] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-08 13:16:11] [valid] Ep. 16 : Up. 640000 : cross-entropy : 39.3178 : new best
[2019-08-08 13:16:18] [valid] Ep. 16 : Up. 640000 : perplexity : 4.68947 : new best
[2019-08-08 13:17:19] [valid] Ep. 16 : Up. 640000 : translation : 28.91 : stalled 1 times (last best: 28.99)
[2019-08-08 13:22:29] Seen 4423484 samples
[2019-08-08 13:22:29] Starting epoch 17
[2019-08-08 13:22:29] [data] Shuffling data
[2019-08-08 13:22:45] [data] Done reading 5171769 sentences
[2019-08-08 13:23:08] [data] Done shuffling 5171769 sentences to temp files
[2019-08-08 13:23:35] Ep. 17 : Up. 642000 : Sen. 13,159 : Cost 36.38846970 : Time 508.49s : 9524.28 words/s
[2019-08-08 13:29:05] Ep. 17 : Up. 644000 : Sen. 233,492 : Cost 35.62593842 : Time 329.87s : 14706.00 words/s
[2019-08-08 13:34:35] Ep. 17 : Up. 646000 : Sen. 454,505 : Cost 35.59733200 : Time 329.80s : 14714.27 words/s
[2019-08-08 13:40:05] Ep. 17 : Up. 648000 : Sen. 675,136 : Cost 35.71017456 : Time 330.45s : 14707.28 words/s
[2019-08-08 22:38:14] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-08 22:38:14] [marian] Running on fulla as process 159681 with command line:
[2019-08-08 22:38:14] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz -T . --devices 1 --train-sets ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en --vocabs ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de.json ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/dev.bpe.de ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/dev.out --valid-script-path ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/train.log --valid-log ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/valid.log
[2019-08-08 22:38:14] [config] after-batches: 0
[2019-08-08 22:38:14] [config] after-epochs: 0
[2019-08-08 22:38:14] [config] allow-unk: false
[2019-08-08 22:38:14] [config] beam-size: 12
[2019-08-08 22:38:14] [config] bert-class-symbol: "[CLS]"
[2019-08-08 22:38:14] [config] bert-mask-symbol: "[MASK]"
[2019-08-08 22:38:14] [config] bert-masking-fraction: 0.15
[2019-08-08 22:38:14] [config] bert-sep-symbol: "[SEP]"
[2019-08-08 22:38:14] [config] bert-train-type-embeddings: true
[2019-08-08 22:38:14] [config] bert-type-vocab-size: 2
[2019-08-08 22:38:14] [config] best-deep: false
[2019-08-08 22:38:14] [config] clip-gemm: 0
[2019-08-08 22:38:14] [config] clip-norm: 1
[2019-08-08 22:38:14] [config] cost-type: ce-mean
[2019-08-08 22:38:14] [config] cpu-threads: 0
[2019-08-08 22:38:14] [config] data-weighting: ""
[2019-08-08 22:38:14] [config] data-weighting-type: sentence
[2019-08-08 22:38:14] [config] dec-cell: gru
[2019-08-08 22:38:14] [config] dec-cell-base-depth: 2
[2019-08-08 22:38:14] [config] dec-cell-high-depth: 1
[2019-08-08 22:38:14] [config] dec-depth: 1
[2019-08-08 22:38:14] [config] devices:
[2019-08-08 22:38:14] [config]   - 1
[2019-08-08 22:38:14] [config] dim-emb: 512
[2019-08-08 22:38:14] [config] dim-rnn: 1024
[2019-08-08 22:38:14] [config] dim-vocabs:
[2019-08-08 22:38:14] [config]   - 50000
[2019-08-08 22:38:14] [config]   - 50000
[2019-08-08 22:38:14] [config] disp-first: 0
[2019-08-08 22:38:14] [config] disp-freq: 2000
[2019-08-08 22:38:14] [config] disp-label-counts: false
[2019-08-08 22:38:14] [config] dropout-rnn: 0.2
[2019-08-08 22:38:14] [config] dropout-src: 0.1
[2019-08-08 22:38:14] [config] dropout-trg: 0.1
[2019-08-08 22:38:14] [config] dump-config: ""
[2019-08-08 22:38:14] [config] early-stopping: 5
[2019-08-08 22:38:14] [config] embedding-fix-src: false
[2019-08-08 22:38:14] [config] embedding-fix-trg: false
[2019-08-08 22:38:14] [config] embedding-normalization: false
[2019-08-08 22:38:14] [config] embedding-vectors:
[2019-08-08 22:38:14] [config]   []
[2019-08-08 22:38:14] [config] enc-cell: gru
[2019-08-08 22:38:14] [config] enc-cell-depth: 1
[2019-08-08 22:38:14] [config] enc-depth: 1
[2019-08-08 22:38:14] [config] enc-type: bidirectional
[2019-08-08 22:38:14] [config] exponential-smoothing: 0.0001
[2019-08-08 22:38:14] [config] grad-dropping-momentum: 0
[2019-08-08 22:38:14] [config] grad-dropping-rate: 0
[2019-08-08 22:38:14] [config] grad-dropping-warmup: 100
[2019-08-08 22:38:14] [config] guided-alignment: none
[2019-08-08 22:38:14] [config] guided-alignment-cost: mse
[2019-08-08 22:38:14] [config] guided-alignment-weight: 0.1
[2019-08-08 22:38:14] [config] ignore-model-config: false
[2019-08-08 22:38:14] [config] input-types:
[2019-08-08 22:38:14] [config]   []
[2019-08-08 22:38:14] [config] interpolate-env-vars: false
[2019-08-08 22:38:14] [config] keep-best: false
[2019-08-08 22:38:14] [config] label-smoothing: 0
[2019-08-08 22:38:14] [config] layer-normalization: true
[2019-08-08 22:38:14] [config] learn-rate: 0.0001
[2019-08-08 22:38:14] [config] log: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/train.log
[2019-08-08 22:38:14] [config] log-level: info
[2019-08-08 22:38:14] [config] log-time-zone: ""
[2019-08-08 22:38:14] [config] lr-decay: 0
[2019-08-08 22:38:14] [config] lr-decay-freq: 50000
[2019-08-08 22:38:14] [config] lr-decay-inv-sqrt:
[2019-08-08 22:38:14] [config]   - 0
[2019-08-08 22:38:14] [config] lr-decay-repeat-warmup: false
[2019-08-08 22:38:14] [config] lr-decay-reset-optimizer: false
[2019-08-08 22:38:14] [config] lr-decay-start:
[2019-08-08 22:38:14] [config]   - 10
[2019-08-08 22:38:14] [config]   - 1
[2019-08-08 22:38:14] [config] lr-decay-strategy: epoch+stalled
[2019-08-08 22:38:14] [config] lr-report: false
[2019-08-08 22:38:14] [config] lr-warmup: 0
[2019-08-08 22:38:14] [config] lr-warmup-at-reload: false
[2019-08-08 22:38:14] [config] lr-warmup-cycle: false
[2019-08-08 22:38:14] [config] lr-warmup-start-rate: 0
[2019-08-08 22:38:14] [config] max-length: 50
[2019-08-08 22:38:14] [config] max-length-crop: false
[2019-08-08 22:38:14] [config] max-length-factor: 3
[2019-08-08 22:38:14] [config] maxi-batch: 100
[2019-08-08 22:38:14] [config] maxi-batch-sort: trg
[2019-08-08 22:38:14] [config] mini-batch: 64
[2019-08-08 22:38:14] [config] mini-batch-fit: true
[2019-08-08 22:38:14] [config] mini-batch-fit-step: 10
[2019-08-08 22:38:14] [config] mini-batch-overstuff: 1
[2019-08-08 22:38:14] [config] mini-batch-track-lr: false
[2019-08-08 22:38:14] [config] mini-batch-understuff: 1
[2019-08-08 22:38:14] [config] mini-batch-warmup: 0
[2019-08-08 22:38:14] [config] mini-batch-words: 0
[2019-08-08 22:38:14] [config] mini-batch-words-ref: 0
[2019-08-08 22:38:14] [config] model: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-08 22:38:14] [config] multi-loss-type: sum
[2019-08-08 22:38:14] [config] multi-node: false
[2019-08-08 22:38:14] [config] multi-node-overlap: true
[2019-08-08 22:38:14] [config] n-best: false
[2019-08-08 22:38:14] [config] no-nccl: false
[2019-08-08 22:38:14] [config] no-reload: false
[2019-08-08 22:38:14] [config] no-restore-corpus: false
[2019-08-08 22:38:14] [config] no-shuffle: false
[2019-08-08 22:38:14] [config] normalize: 1
[2019-08-08 22:38:14] [config] num-devices: 0
[2019-08-08 22:38:14] [config] optimizer: adam
[2019-08-08 22:38:14] [config] optimizer-delay: 1
[2019-08-08 22:38:14] [config] optimizer-params:
[2019-08-08 22:38:14] [config]   []
[2019-08-08 22:38:14] [config] overwrite: false
[2019-08-08 22:38:14] [config] pretrained-model: ""
[2019-08-08 22:38:14] [config] quiet: false
[2019-08-08 22:38:14] [config] quiet-translation: true
[2019-08-08 22:38:14] [config] relative-paths: false
[2019-08-08 22:38:14] [config] right-left: false
[2019-08-08 22:38:14] [config] save-freq: 20000
[2019-08-08 22:38:14] [config] seed: 1111
[2019-08-08 22:38:14] [config] shuffle-in-ram: false
[2019-08-08 22:38:14] [config] skip: false
[2019-08-08 22:38:14] [config] sqlite: ""
[2019-08-08 22:38:14] [config] sqlite-drop: false
[2019-08-08 22:38:14] [config] sync-sgd: true
[2019-08-08 22:38:14] [config] tempdir: .
[2019-08-08 22:38:14] [config] tied-embeddings: false
[2019-08-08 22:38:14] [config] tied-embeddings-all: false
[2019-08-08 22:38:14] [config] tied-embeddings-src: false
[2019-08-08 22:38:14] [config] train-sets:
[2019-08-08 22:38:14] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de
[2019-08-08 22:38:14] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en
[2019-08-08 22:38:14] [config] transformer-aan-activation: swish
[2019-08-08 22:38:14] [config] transformer-aan-depth: 2
[2019-08-08 22:38:14] [config] transformer-aan-nogate: false
[2019-08-08 22:38:14] [config] transformer-decoder-autoreg: self-attention
[2019-08-08 22:38:14] [config] transformer-dim-aan: 2048
[2019-08-08 22:38:14] [config] transformer-dim-ffn: 2048
[2019-08-08 22:38:14] [config] transformer-dropout: 0
[2019-08-08 22:38:14] [config] transformer-dropout-attention: 0
[2019-08-08 22:38:14] [config] transformer-dropout-ffn: 0
[2019-08-08 22:38:14] [config] transformer-ffn-activation: swish
[2019-08-08 22:38:14] [config] transformer-ffn-depth: 2
[2019-08-08 22:38:14] [config] transformer-guided-alignment-layer: last
[2019-08-08 22:38:14] [config] transformer-heads: 8
[2019-08-08 22:38:14] [config] transformer-no-projection: false
[2019-08-08 22:38:14] [config] transformer-postprocess: dan
[2019-08-08 22:38:14] [config] transformer-postprocess-emb: d
[2019-08-08 22:38:14] [config] transformer-preprocess: ""
[2019-08-08 22:38:14] [config] transformer-tied-layers:
[2019-08-08 22:38:14] [config]   []
[2019-08-08 22:38:14] [config] transformer-train-position-embeddings: false
[2019-08-08 22:38:14] [config] type: amun
[2019-08-08 22:38:14] [config] ulr: false
[2019-08-08 22:38:14] [config] ulr-dim-emb: 0
[2019-08-08 22:38:14] [config] ulr-dropout: 0
[2019-08-08 22:38:14] [config] ulr-keys-vectors: ""
[2019-08-08 22:38:14] [config] ulr-query-vectors: ""
[2019-08-08 22:38:14] [config] ulr-softmax-temperature: 1
[2019-08-08 22:38:14] [config] ulr-trainable-transformation: false
[2019-08-08 22:38:14] [config] valid-freq: 20000
[2019-08-08 22:38:14] [config] valid-log: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/valid.log
[2019-08-08 22:38:14] [config] valid-max-length: 1000
[2019-08-08 22:38:14] [config] valid-metrics:
[2019-08-08 22:38:14] [config]   - cross-entropy
[2019-08-08 22:38:14] [config]   - perplexity
[2019-08-08 22:38:14] [config]   - translation
[2019-08-08 22:38:14] [config] valid-mini-batch: 8
[2019-08-08 22:38:14] [config] valid-script-path: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/score-dev.sh
[2019-08-08 22:38:14] [config] valid-sets:
[2019-08-08 22:38:14] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/dev.bpe.de
[2019-08-08 22:38:14] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/dev.bpe.en
[2019-08-08 22:38:14] [config] valid-translation-output: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/dev.out
[2019-08-08 22:38:14] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-08 22:38:14] [config] vocabs:
[2019-08-08 22:38:14] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de.json
[2019-08-08 22:38:14] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en.json
[2019-08-08 22:38:14] [config] word-penalty: 0
[2019-08-08 22:38:14] [config] workspace: 3000
[2019-08-08 22:38:14] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-08 22:38:14] Using synchronous training
[2019-08-08 22:38:14] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de.json
[2019-08-08 22:38:15] [data] Using unused word id eos for 0
[2019-08-08 22:38:15] [data] Using unused word id UNK for 1
[2019-08-08 22:38:15] [data] Setting vocabulary size for input 0 to 50000
[2019-08-08 22:38:15] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en.json
[2019-08-08 22:38:15] [data] Using unused word id eos for 0
[2019-08-08 22:38:15] [data] Using unused word id UNK for 1
[2019-08-08 22:38:15] [data] Setting vocabulary size for input 1 to 50000
[2019-08-08 22:38:15] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-08 22:38:15] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-08 22:38:17] [memory] Extending reserved space to 3072 MB (device gpu1)
[2019-08-08 22:38:18] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-08 22:38:18] [comm] NCCLCommunicator constructed successfully.
[2019-08-08 22:38:18] [training] Using 1 GPUs
[2019-08-08 22:38:18] [memory] Reserving 422 MB, device gpu1
[2019-08-08 22:38:18] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-08 22:38:18] [memory] Reserving 422 MB, device gpu1
[2019-08-08 22:38:21] [batching] Done. Typical MB size is 4042 target words
[2019-08-08 22:38:21] [memory] Extending reserved space to 3072 MB (device gpu1)
[2019-08-08 22:38:21] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-08 22:38:21] [comm] NCCLCommunicator constructed successfully.
[2019-08-08 22:38:21] [training] Using 1 GPUs
[2019-08-08 22:38:21] Loading model from ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-08 22:38:28] Loading Adam parameters from ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-08 22:38:47] [memory] Reserving 844 MB, device gpu1
[2019-08-08 22:38:48] [training] Model reloaded from ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-08 22:38:48] [data] Restoring the corpus state to epoch 16, batch 640000
[2019-08-08 22:38:48] [data] Shuffling data
[2019-08-08 22:39:31] [data] Done reading 5171769 sentences
[2019-08-08 22:39:51] [data] Done shuffling 5171769 sentences to temp files
[2019-08-08 22:42:40] Training started
[2019-08-08 22:42:40] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-08 22:42:40] [memory] Reserving 422 MB, device gpu1
[2019-08-08 22:42:40] [memory] Reserving 422 MB, device gpu1
[2019-08-08 22:42:40] Loading model from ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-08 22:42:52] [memory] Reserving 422 MB, device cpu0
[2019-08-08 22:42:53] [memory] Reserving 422 MB, device gpu1
[2019-08-08 22:47:54] Seen 4423484 samples
[2019-08-08 22:47:54] Starting epoch 17
[2019-08-08 22:47:54] [data] Shuffling data
[2019-08-08 22:47:57] [data] Done reading 5171769 sentences
[2019-08-08 22:48:16] [data] Done shuffling 5171769 sentences to temp files
[2019-08-08 22:48:58] Ep. 17 : Up. 642000 : Sen. 13,159 : Cost 36.34959412 : Time 643.13s : 7530.39 words/s
[2019-08-08 22:54:21] Ep. 17 : Up. 644000 : Sen. 233,492 : Cost 35.65727234 : Time 322.53s : 15040.87 words/s
[2019-08-08 22:59:43] Ep. 17 : Up. 646000 : Sen. 454,505 : Cost 35.70844269 : Time 321.96s : 15072.65 words/s
[2019-08-08 23:05:05] Ep. 17 : Up. 648000 : Sen. 675,136 : Cost 35.55034256 : Time 322.70s : 15060.46 words/s
[2019-08-08 23:10:28] Ep. 17 : Up. 650000 : Sen. 896,156 : Cost 35.78613281 : Time 323.12s : 15053.28 words/s
[2019-08-08 23:15:51] Ep. 17 : Up. 652000 : Sen. 1,117,164 : Cost 35.76498413 : Time 322.94s : 15070.58 words/s
[2019-08-08 23:21:15] Ep. 17 : Up. 654000 : Sen. 1,338,649 : Cost 35.69210815 : Time 323.96s : 15042.48 words/s
[2019-08-08 23:26:39] Ep. 17 : Up. 656000 : Sen. 1,559,853 : Cost 35.94781113 : Time 323.47s : 15025.12 words/s
[2019-08-08 23:32:02] Ep. 17 : Up. 658000 : Sen. 1,780,954 : Cost 35.92135620 : Time 323.73s : 15022.65 words/s
[2019-08-08 23:37:25] Ep. 17 : Up. 660000 : Sen. 2,000,970 : Cost 36.16233826 : Time 322.73s : 15024.69 words/s
[2019-08-08 23:37:25] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-08 23:37:38] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter660000.npz
[2019-08-08 23:37:50] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-08 23:38:12] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-08 23:38:59] [valid] Ep. 17 : Up. 660000 : cross-entropy : 39.3588 : new best
[2019-08-08 23:39:06] [valid] Ep. 17 : Up. 660000 : perplexity : 4.69704 : new best
[2019-08-08 23:40:02] [valid] Ep. 17 : Up. 660000 : translation : 28.72 : stalled 1 times (last best: 28.99)
[2019-08-08 23:45:27] Ep. 17 : Up. 662000 : Sen. 2,221,685 : Cost 35.77461243 : Time 481.69s : 10062.64 words/s
[2019-08-08 23:50:51] Ep. 17 : Up. 664000 : Sen. 2,442,592 : Cost 35.99241638 : Time 323.71s : 14985.77 words/s
[2019-08-08 23:56:15] Ep. 17 : Up. 666000 : Sen. 2,662,874 : Cost 36.34501266 : Time 324.47s : 14996.84 words/s
[2019-08-09 00:01:38] Ep. 17 : Up. 668000 : Sen. 2,883,728 : Cost 36.06174469 : Time 323.01s : 15024.46 words/s
[2019-08-09 00:07:01] Ep. 17 : Up. 670000 : Sen. 3,103,292 : Cost 36.24998474 : Time 322.70s : 14983.76 words/s
[2019-08-09 00:12:24] Ep. 17 : Up. 672000 : Sen. 3,323,729 : Cost 36.18946457 : Time 323.29s : 14997.14 words/s
[2019-08-09 00:17:47] Ep. 17 : Up. 674000 : Sen. 3,542,873 : Cost 36.30077744 : Time 322.74s : 14939.73 words/s
[2019-08-09 00:23:09] Ep. 17 : Up. 676000 : Sen. 3,761,938 : Cost 36.15312576 : Time 322.47s : 14949.06 words/s
[2019-08-09 00:28:31] Ep. 17 : Up. 678000 : Sen. 3,982,165 : Cost 36.10184860 : Time 322.12s : 15021.98 words/s
[2019-08-09 00:33:56] Ep. 17 : Up. 680000 : Sen. 4,202,724 : Cost 36.32321548 : Time 324.17s : 15004.65 words/s
[2019-08-09 00:33:56] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-09 00:34:11] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter680000.npz
[2019-08-09 00:34:23] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-09 00:34:41] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-09 00:35:07] [valid] Ep. 17 : Up. 680000 : cross-entropy : 39.2505 : new best
[2019-08-09 00:35:14] [valid] Ep. 17 : Up. 680000 : perplexity : 4.67708 : new best
[2019-08-09 00:36:09] [valid] Ep. 17 : Up. 680000 : translation : 28.93 : stalled 2 times (last best: 28.99)
[2019-08-09 00:41:35] Ep. 17 : Up. 682000 : Sen. 4,423,051 : Cost 36.19027710 : Time 459.14s : 10558.07 words/s
[2019-08-09 00:41:35] Seen 4423484 samples
[2019-08-09 00:41:35] Starting epoch 18
[2019-08-09 00:41:35] [data] Shuffling data
[2019-08-09 00:41:38] [data] Done reading 5171769 sentences
[2019-08-09 00:42:00] [data] Done shuffling 5171769 sentences to temp files
[2019-08-09 00:47:31] Ep. 18 : Up. 684000 : Sen. 220,060 : Cost 35.26688385 : Time 356.11s : 13613.54 words/s
[2019-08-09 00:52:55] Ep. 18 : Up. 686000 : Sen. 440,755 : Cost 35.51483536 : Time 323.89s : 15008.29 words/s
[2019-08-09 00:58:19] Ep. 18 : Up. 688000 : Sen. 662,394 : Cost 35.19581223 : Time 324.58s : 14980.75 words/s
[2019-08-09 01:03:43] Ep. 18 : Up. 690000 : Sen. 882,222 : Cost 35.58011246 : Time 324.03s : 14956.78 words/s
[2019-08-09 01:09:07] Ep. 18 : Up. 692000 : Sen. 1,101,878 : Cost 35.62969971 : Time 323.37s : 14956.10 words/s
[2019-08-09 01:14:29] Ep. 18 : Up. 694000 : Sen. 1,321,650 : Cost 35.58156204 : Time 322.30s : 14986.10 words/s
[2019-08-09 01:19:55] Ep. 18 : Up. 696000 : Sen. 1,542,761 : Cost 35.67513657 : Time 325.48s : 14960.83 words/s
[2019-08-09 01:25:19] Ep. 18 : Up. 698000 : Sen. 1,764,421 : Cost 35.72845840 : Time 324.00s : 15015.53 words/s
[2019-08-09 01:30:44] Ep. 18 : Up. 700000 : Sen. 1,986,069 : Cost 35.76307297 : Time 325.62s : 14964.66 words/s
[2019-08-09 01:30:44] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-09 01:30:57] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter700000.npz
[2019-08-09 01:31:05] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-09 01:31:15] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-09 01:31:40] [valid] Ep. 18 : Up. 700000 : cross-entropy : 39.329 : stalled 1 times (last best: 39.2505)
[2019-08-09 01:31:47] [valid] Ep. 18 : Up. 700000 : perplexity : 4.69154 : stalled 1 times (last best: 4.67708)
[2019-08-09 01:32:43] [valid] Ep. 18 : Up. 700000 : translation : 29.04 : new best
[2019-08-09 01:38:08] Ep. 18 : Up. 702000 : Sen. 2,206,372 : Cost 35.83009338 : Time 443.77s : 10924.00 words/s
[2019-08-09 01:43:32] Ep. 18 : Up. 704000 : Sen. 2,426,412 : Cost 35.96934128 : Time 323.61s : 14976.69 words/s
[2019-08-09 01:48:56] Ep. 18 : Up. 706000 : Sen. 2,647,649 : Cost 36.00607300 : Time 324.98s : 14996.68 words/s
[2019-08-09 01:54:20] Ep. 18 : Up. 708000 : Sen. 2,868,212 : Cost 35.67446899 : Time 323.76s : 14952.70 words/s
[2019-08-09 01:59:45] Ep. 18 : Up. 710000 : Sen. 3,089,061 : Cost 36.09006119 : Time 324.51s : 14987.47 words/s
[2019-08-09 02:05:08] Ep. 18 : Up. 712000 : Sen. 3,309,275 : Cost 35.95282745 : Time 323.42s : 14978.11 words/s
[2019-08-09 02:10:31] Ep. 18 : Up. 714000 : Sen. 3,529,023 : Cost 35.87755203 : Time 322.40s : 14991.56 words/s
[2019-08-09 02:15:55] Ep. 18 : Up. 716000 : Sen. 3,749,422 : Cost 36.03168488 : Time 324.03s : 14971.59 words/s
[2019-08-09 02:21:18] Ep. 18 : Up. 718000 : Sen. 3,969,340 : Cost 36.23113632 : Time 323.41s : 14978.89 words/s
[2019-08-09 02:26:42] Ep. 18 : Up. 720000 : Sen. 4,190,393 : Cost 36.15392303 : Time 324.36s : 14978.03 words/s
[2019-08-09 02:26:42] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-09 02:26:54] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter720000.npz
[2019-08-09 02:27:01] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-09 02:27:11] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-09 02:27:37] [valid] Ep. 18 : Up. 720000 : cross-entropy : 39.1786 : new best
[2019-08-09 02:27:43] [valid] Ep. 18 : Up. 720000 : perplexity : 4.66389 : new best
[2019-08-09 02:28:39] [valid] Ep. 18 : Up. 720000 : translation : 28.98 : stalled 1 times (last best: 29.04)
[2019-08-09 02:34:04] Ep. 18 : Up. 722000 : Sen. 4,409,600 : Cost 36.14788437 : Time 441.99s : 10949.84 words/s
[2019-08-09 02:34:25] Seen 4423484 samples
[2019-08-09 02:34:25] Starting epoch 19
[2019-08-09 02:34:25] [data] Shuffling data
[2019-08-09 02:34:28] [data] Done reading 5171769 sentences
[2019-08-09 02:34:46] [data] Done shuffling 5171769 sentences to temp files
[2019-08-09 02:40:02] Ep. 19 : Up. 724000 : Sen. 205,732 : Cost 35.27154160 : Time 357.46s : 13501.41 words/s
[2019-08-09 02:45:27] Ep. 19 : Up. 726000 : Sen. 426,804 : Cost 35.28725815 : Time 325.34s : 14977.61 words/s
[2019-08-09 02:50:51] Ep. 19 : Up. 728000 : Sen. 648,302 : Cost 35.18122864 : Time 323.83s : 14983.97 words/s
[2019-08-09 02:56:15] Ep. 19 : Up. 730000 : Sen. 868,267 : Cost 35.55624008 : Time 324.10s : 14981.18 words/s
[2019-08-09 03:01:38] Ep. 19 : Up. 732000 : Sen. 1,088,921 : Cost 35.51160049 : Time 323.05s : 15026.85 words/s
[2019-08-09 03:07:01] Ep. 19 : Up. 734000 : Sen. 1,308,110 : Cost 35.56451797 : Time 323.00s : 14950.75 words/s
[2019-08-09 03:12:25] Ep. 19 : Up. 736000 : Sen. 1,528,602 : Cost 35.66899872 : Time 324.23s : 14994.81 words/s
[2019-08-09 03:17:49] Ep. 19 : Up. 738000 : Sen. 1,748,701 : Cost 35.66959000 : Time 324.03s : 14979.40 words/s
[2019-08-09 03:23:13] Ep. 19 : Up. 740000 : Sen. 1,969,903 : Cost 35.41918182 : Time 323.23s : 15016.33 words/s
[2019-08-09 03:23:13] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-09 03:23:22] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter740000.npz
[2019-08-09 03:23:30] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-09 03:23:39] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-09 03:24:08] [valid] Ep. 19 : Up. 740000 : cross-entropy : 39.2657 : stalled 1 times (last best: 39.1786)
[2019-08-09 03:24:14] [valid] Ep. 19 : Up. 740000 : perplexity : 4.67988 : stalled 1 times (last best: 4.66389)
[2019-08-09 03:25:10] [valid] Ep. 19 : Up. 740000 : translation : 29.04 : stalled 2 times (last best: 29.04)
[2019-08-09 03:30:36] Ep. 19 : Up. 742000 : Sen. 2,190,783 : Cost 35.46253586 : Time 443.65s : 10957.36 words/s
[2019-08-09 03:36:01] Ep. 19 : Up. 744000 : Sen. 2,412,252 : Cost 35.60563660 : Time 324.45s : 15002.99 words/s
[2019-08-09 03:41:25] Ep. 19 : Up. 746000 : Sen. 2,632,704 : Cost 35.74081421 : Time 323.77s : 14962.01 words/s
[2019-08-09 03:46:47] Ep. 19 : Up. 748000 : Sen. 2,853,045 : Cost 35.59370041 : Time 322.35s : 15048.67 words/s
[2019-08-09 03:52:11] Ep. 19 : Up. 750000 : Sen. 3,072,798 : Cost 35.86909485 : Time 323.70s : 14959.72 words/s
[2019-08-09 03:57:35] Ep. 19 : Up. 752000 : Sen. 3,293,648 : Cost 35.97433853 : Time 324.03s : 15005.63 words/s
[2019-08-09 04:02:59] Ep. 19 : Up. 754000 : Sen. 3,514,919 : Cost 35.88209152 : Time 324.47s : 14989.07 words/s
[2019-08-09 04:08:23] Ep. 19 : Up. 756000 : Sen. 3,734,653 : Cost 35.99378967 : Time 323.65s : 14984.76 words/s
[2019-08-09 04:13:44] Ep. 19 : Up. 758000 : Sen. 3,954,377 : Cost 35.73416519 : Time 321.65s : 15004.66 words/s
[2019-08-09 04:19:07] Ep. 19 : Up. 760000 : Sen. 4,174,195 : Cost 35.95321655 : Time 322.92s : 14977.40 words/s
[2019-08-09 04:19:07] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-09 04:19:17] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter760000.npz
[2019-08-09 04:19:25] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-09 04:19:35] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-09 04:20:01] [valid] Ep. 19 : Up. 760000 : cross-entropy : 39.1685 : new best
[2019-08-09 04:20:07] [valid] Ep. 19 : Up. 760000 : perplexity : 4.66203 : new best
[2019-08-09 04:21:03] [valid] Ep. 19 : Up. 760000 : translation : 28.96 : stalled 3 times (last best: 29.04)
[2019-08-09 04:26:29] Ep. 19 : Up. 762000 : Sen. 4,394,039 : Cost 35.84527206 : Time 441.59s : 10935.04 words/s
[2019-08-09 04:27:12] Seen 4423484 samples
[2019-08-09 04:27:12] Starting epoch 20
[2019-08-09 04:27:12] [data] Shuffling data
[2019-08-09 04:27:15] [data] Done reading 5171769 sentences
[2019-08-09 04:27:37] [data] Done shuffling 5171769 sentences to temp files
[2019-08-09 04:32:26] Ep. 20 : Up. 764000 : Sen. 191,472 : Cost 35.06537247 : Time 357.38s : 13574.39 words/s
[2019-08-09 04:37:49] Ep. 20 : Up. 766000 : Sen. 411,700 : Cost 34.94208527 : Time 323.03s : 14988.39 words/s
[2019-08-09 04:43:13] Ep. 20 : Up. 768000 : Sen. 632,210 : Cost 35.03973007 : Time 324.08s : 14964.48 words/s
[2019-08-09 04:48:38] Ep. 20 : Up. 770000 : Sen. 851,561 : Cost 35.28200912 : Time 324.13s : 14940.66 words/s
[2019-08-09 04:54:03] Ep. 20 : Up. 772000 : Sen. 1,073,241 : Cost 35.29929733 : Time 325.06s : 15011.64 words/s
[2019-08-09 04:59:25] Ep. 20 : Up. 774000 : Sen. 1,292,595 : Cost 35.19427872 : Time 322.52s : 14953.74 words/s
[2019-08-09 05:04:50] Ep. 20 : Up. 776000 : Sen. 1,513,942 : Cost 35.40079880 : Time 324.64s : 14994.48 words/s
[2019-08-09 05:10:14] Ep. 20 : Up. 778000 : Sen. 1,734,400 : Cost 35.39797974 : Time 324.38s : 14962.91 words/s
[2019-08-09 05:15:38] Ep. 20 : Up. 780000 : Sen. 1,955,388 : Cost 35.32038498 : Time 323.90s : 14972.98 words/s
[2019-08-09 05:15:38] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-09 05:15:47] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter780000.npz
[2019-08-09 05:15:54] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-09 05:16:04] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-09 05:16:31] [valid] Ep. 20 : Up. 780000 : cross-entropy : 39.2541 : stalled 1 times (last best: 39.1685)
[2019-08-09 05:16:38] [valid] Ep. 20 : Up. 780000 : perplexity : 4.67774 : stalled 1 times (last best: 4.66203)
[2019-08-09 05:17:36] [valid] Ep. 20 : Up. 780000 : translation : 29.1 : new best
[2019-08-09 05:23:01] Ep. 20 : Up. 782000 : Sen. 2,175,082 : Cost 35.50412750 : Time 442.99s : 10911.39 words/s
[2019-08-09 05:28:25] Ep. 20 : Up. 784000 : Sen. 2,394,358 : Cost 35.60816956 : Time 323.44s : 14941.27 words/s
[2019-08-09 05:33:48] Ep. 20 : Up. 786000 : Sen. 2,614,649 : Cost 35.52794647 : Time 323.38s : 14992.63 words/s
[2019-08-09 05:39:12] Ep. 20 : Up. 788000 : Sen. 2,834,939 : Cost 35.60216141 : Time 323.69s : 14979.27 words/s
[2019-08-09 05:44:36] Ep. 20 : Up. 790000 : Sen. 3,055,922 : Cost 35.64500809 : Time 324.31s : 14989.38 words/s
[2019-08-09 05:49:59] Ep. 20 : Up. 792000 : Sen. 3,275,670 : Cost 35.89170074 : Time 323.16s : 14967.13 words/s
[2019-08-09 05:55:22] Ep. 20 : Up. 794000 : Sen. 3,496,157 : Cost 35.64969254 : Time 323.37s : 14997.94 words/s
[2019-08-09 06:00:48] Ep. 20 : Up. 796000 : Sen. 3,717,011 : Cost 35.74073029 : Time 325.94s : 14937.55 words/s
[2019-08-09 06:06:12] Ep. 20 : Up. 798000 : Sen. 3,936,747 : Cost 35.77866745 : Time 323.28s : 14993.07 words/s
[2019-08-09 06:11:36] Ep. 20 : Up. 800000 : Sen. 4,157,610 : Cost 35.59917450 : Time 324.09s : 14968.94 words/s
[2019-08-09 06:11:36] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-09 06:11:45] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter800000.npz
[2019-08-09 06:11:53] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-09 06:12:02] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-09 06:12:28] [valid] Ep. 20 : Up. 800000 : cross-entropy : 39.1282 : new best
[2019-08-09 06:12:34] [valid] Ep. 20 : Up. 800000 : perplexity : 4.65465 : new best
[2019-08-09 06:13:29] [valid] Ep. 20 : Up. 800000 : translation : 29.11 : new best
[2019-08-09 06:18:55] Ep. 20 : Up. 802000 : Sen. 4,378,626 : Cost 35.72695160 : Time 439.40s : 11066.75 words/s
[2019-08-09 06:20:01] Seen 4423484 samples
[2019-08-09 06:20:01] Starting epoch 21
[2019-08-09 06:20:01] [data] Shuffling data
[2019-08-09 06:20:04] [data] Done reading 5171769 sentences
[2019-08-09 06:20:26] [data] Done shuffling 5171769 sentences to temp files
[2019-08-09 06:24:52] Ep. 21 : Up. 804000 : Sen. 175,930 : Cost 34.83630371 : Time 356.88s : 13595.10 words/s
[2019-08-09 06:30:16] Ep. 21 : Up. 806000 : Sen. 395,816 : Cost 34.90190125 : Time 324.21s : 14939.86 words/s
[2019-08-09 06:35:42] Ep. 21 : Up. 808000 : Sen. 616,338 : Cost 34.94019318 : Time 325.46s : 14916.93 words/s
[2019-08-09 06:41:05] Ep. 21 : Up. 810000 : Sen. 836,152 : Cost 34.96728516 : Time 323.35s : 14943.26 words/s
[2019-08-09 06:46:30] Ep. 21 : Up. 812000 : Sen. 1,056,156 : Cost 35.13400269 : Time 324.54s : 14942.62 words/s
[2019-08-09 06:51:54] Ep. 21 : Up. 814000 : Sen. 1,277,032 : Cost 35.01050186 : Time 324.82s : 14964.25 words/s
[2019-08-09 06:57:18] Ep. 21 : Up. 816000 : Sen. 1,496,608 : Cost 35.05407333 : Time 323.26s : 14953.45 words/s
[2019-08-09 07:02:42] Ep. 21 : Up. 818000 : Sen. 1,717,755 : Cost 35.15285873 : Time 324.77s : 14971.59 words/s
[2019-08-09 07:08:07] Ep. 21 : Up. 820000 : Sen. 1,939,515 : Cost 35.19771576 : Time 324.98s : 14993.27 words/s
[2019-08-09 07:08:07] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-09 07:08:20] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter820000.npz
[2019-08-09 07:08:30] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-09 07:08:43] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-09 07:09:10] [valid] Ep. 21 : Up. 820000 : cross-entropy : 39.1736 : stalled 1 times (last best: 39.1282)
[2019-08-09 07:09:17] [valid] Ep. 21 : Up. 820000 : perplexity : 4.66298 : stalled 1 times (last best: 4.65465)
[2019-08-09 07:10:12] [valid] Ep. 21 : Up. 820000 : translation : 29.11 : stalled 1 times (last best: 29.11)
[2019-08-09 07:15:39] Ep. 21 : Up. 822000 : Sen. 2,159,933 : Cost 35.41489410 : Time 451.61s : 10748.96 words/s
[2019-08-09 07:21:03] Ep. 21 : Up. 824000 : Sen. 2,380,184 : Cost 35.16452408 : Time 323.98s : 14928.10 words/s
[2019-08-09 07:26:27] Ep. 21 : Up. 826000 : Sen. 2,600,646 : Cost 35.58245087 : Time 323.72s : 14975.58 words/s
[2019-08-09 07:31:51] Ep. 21 : Up. 828000 : Sen. 2,820,713 : Cost 35.65985107 : Time 323.93s : 14982.09 words/s
[2019-08-09 07:37:16] Ep. 21 : Up. 830000 : Sen. 3,041,614 : Cost 35.48058319 : Time 325.08s : 14944.89 words/s
[2019-08-09 07:42:40] Ep. 21 : Up. 832000 : Sen. 3,261,427 : Cost 35.49558258 : Time 323.79s : 14940.22 words/s
[2019-08-09 07:48:04] Ep. 21 : Up. 834000 : Sen. 3,481,522 : Cost 35.37432861 : Time 323.94s : 14947.98 words/s
[2019-08-09 07:53:27] Ep. 21 : Up. 836000 : Sen. 3,701,305 : Cost 35.42062759 : Time 323.02s : 14937.67 words/s
[2019-08-09 07:58:51] Ep. 21 : Up. 838000 : Sen. 3,922,220 : Cost 35.74190903 : Time 324.89s : 14969.33 words/s
[2019-08-09 08:04:16] Ep. 21 : Up. 840000 : Sen. 4,143,633 : Cost 35.77080154 : Time 325.01s : 14997.14 words/s
[2019-08-09 08:04:16] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-09 08:04:25] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter840000.npz
[2019-08-09 08:04:33] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-09 08:04:42] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-09 08:05:08] [valid] Ep. 21 : Up. 840000 : cross-entropy : 39.1032 : new best
[2019-08-09 08:05:15] [valid] Ep. 21 : Up. 840000 : perplexity : 4.65008 : new best
[2019-08-09 08:06:11] [valid] Ep. 21 : Up. 840000 : translation : 29.01 : stalled 2 times (last best: 29.11)
[2019-08-09 08:11:38] Ep. 21 : Up. 842000 : Sen. 4,364,067 : Cost 35.61707306 : Time 441.64s : 10986.89 words/s
[2019-08-09 08:13:06] Seen 4423484 samples
[2019-08-09 08:13:06] Starting epoch 22
[2019-08-09 08:13:06] [data] Shuffling data
[2019-08-09 08:13:10] [data] Done reading 5171769 sentences
[2019-08-09 08:13:32] [data] Done shuffling 5171769 sentences to temp files
[2019-08-09 08:17:37] Ep. 22 : Up. 844000 : Sen. 160,524 : Cost 34.71839905 : Time 358.89s : 13496.20 words/s
[2019-08-09 08:23:00] Ep. 22 : Up. 846000 : Sen. 380,028 : Cost 34.65040588 : Time 323.13s : 14947.51 words/s
[2019-08-09 08:28:24] Ep. 22 : Up. 848000 : Sen. 600,382 : Cost 34.57043839 : Time 323.39s : 14979.83 words/s
[2019-08-09 08:33:47] Ep. 22 : Up. 850000 : Sen. 820,105 : Cost 34.87607956 : Time 323.66s : 14940.89 words/s
[2019-08-09 08:39:13] Ep. 22 : Up. 852000 : Sen. 1,041,311 : Cost 35.01877213 : Time 325.58s : 14955.59 words/s
[2019-08-09 08:44:37] Ep. 22 : Up. 854000 : Sen. 1,261,608 : Cost 35.07316208 : Time 324.72s : 14944.40 words/s
[2019-08-09 08:50:01] Ep. 22 : Up. 856000 : Sen. 1,481,895 : Cost 35.19467163 : Time 323.70s : 14988.53 words/s
[2019-08-09 08:55:27] Ep. 22 : Up. 858000 : Sen. 1,703,013 : Cost 35.09415436 : Time 325.44s : 14950.32 words/s
[2019-08-09 09:00:51] Ep. 22 : Up. 860000 : Sen. 1,924,086 : Cost 35.00840378 : Time 324.24s : 14994.15 words/s
[2019-08-09 09:00:51] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-09 09:01:01] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter860000.npz
[2019-08-09 09:01:08] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-09 09:01:18] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-09 09:01:45] [valid] Ep. 22 : Up. 860000 : cross-entropy : 39.1632 : stalled 1 times (last best: 39.1032)
[2019-08-09 09:01:51] [valid] Ep. 22 : Up. 860000 : perplexity : 4.66107 : stalled 1 times (last best: 4.65008)
[2019-08-09 09:02:46] [valid] Ep. 22 : Up. 860000 : translation : 29.11 : stalled 3 times (last best: 29.11)
[2019-08-09 09:08:14] Ep. 22 : Up. 862000 : Sen. 2,144,765 : Cost 35.33915710 : Time 442.87s : 10969.73 words/s
[2019-08-09 09:13:39] Ep. 22 : Up. 864000 : Sen. 2,365,511 : Cost 35.27664185 : Time 324.79s : 14940.45 words/s
[2019-08-09 09:19:02] Ep. 22 : Up. 866000 : Sen. 2,585,330 : Cost 35.32713318 : Time 323.02s : 14970.91 words/s
[2019-08-09 09:24:27] Ep. 22 : Up. 868000 : Sen. 2,806,136 : Cost 35.27222824 : Time 325.11s : 14937.43 words/s
[2019-08-09 09:29:52] Ep. 22 : Up. 870000 : Sen. 3,025,983 : Cost 35.38078690 : Time 325.07s : 14922.47 words/s
[2019-08-09 09:35:16] Ep. 22 : Up. 872000 : Sen. 3,246,882 : Cost 35.63945389 : Time 324.58s : 14949.66 words/s
[2019-08-09 09:40:41] Ep. 22 : Up. 874000 : Sen. 3,467,927 : Cost 35.21360397 : Time 324.71s : 14943.18 words/s
[2019-08-09 09:46:07] Ep. 22 : Up. 876000 : Sen. 3,688,831 : Cost 35.20084381 : Time 325.44s : 14926.60 words/s
[2019-08-09 09:51:32] Ep. 22 : Up. 878000 : Sen. 3,909,851 : Cost 35.39913940 : Time 325.43s : 14954.53 words/s
[2019-08-09 09:56:58] Ep. 22 : Up. 880000 : Sen. 4,130,722 : Cost 35.59125519 : Time 325.84s : 14921.15 words/s
[2019-08-09 09:56:58] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-09 09:57:07] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter880000.npz
[2019-08-09 09:57:14] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-09 09:57:24] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-09 09:57:50] [valid] Ep. 22 : Up. 880000 : cross-entropy : 39.0723 : new best
[2019-08-09 09:57:57] [valid] Ep. 22 : Up. 880000 : perplexity : 4.64444 : new best
[2019-08-09 09:58:52] [valid] Ep. 22 : Up. 880000 : translation : 29.09 : stalled 4 times (last best: 29.11)
[2019-08-09 10:04:19] Ep. 22 : Up. 882000 : Sen. 4,350,920 : Cost 35.43041611 : Time 441.26s : 10985.01 words/s
[2019-08-09 10:06:07] Seen 4423484 samples
[2019-08-09 10:06:07] Starting epoch 23
[2019-08-09 10:06:07] [data] Shuffling data
[2019-08-09 10:06:10] [data] Done reading 5171769 sentences
[2019-08-09 10:06:31] [data] Done shuffling 5171769 sentences to temp files
[2019-08-09 10:10:17] Ep. 23 : Up. 884000 : Sen. 148,595 : Cost 34.53094101 : Time 357.93s : 13557.95 words/s
[2019-08-09 10:15:43] Ep. 23 : Up. 886000 : Sen. 368,579 : Cost 34.59703064 : Time 325.82s : 14871.00 words/s
[2019-08-09 10:21:09] Ep. 23 : Up. 888000 : Sen. 589,649 : Cost 34.62291718 : Time 326.10s : 14902.41 words/s
[2019-08-09 10:26:36] Ep. 23 : Up. 890000 : Sen. 810,440 : Cost 34.87467575 : Time 326.93s : 14902.17 words/s
[2019-08-09 10:32:02] Ep. 23 : Up. 892000 : Sen. 1,031,377 : Cost 34.82912445 : Time 326.36s : 14908.46 words/s
[2019-08-09 10:37:29] Ep. 23 : Up. 894000 : Sen. 1,252,064 : Cost 34.98470688 : Time 326.71s : 14869.64 words/s
[2019-08-09 10:42:56] Ep. 23 : Up. 896000 : Sen. 1,473,907 : Cost 34.85669708 : Time 327.49s : 14907.96 words/s
[2019-08-09 10:48:22] Ep. 23 : Up. 898000 : Sen. 1,694,447 : Cost 34.85824966 : Time 325.64s : 14885.95 words/s
[2019-08-09 10:53:48] Ep. 23 : Up. 900000 : Sen. 1,914,417 : Cost 35.09207916 : Time 325.87s : 14884.38 words/s
[2019-08-09 10:53:48] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-09 10:53:57] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter900000.npz
[2019-08-09 10:54:04] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-09 10:54:14] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-09 10:54:40] [valid] Ep. 23 : Up. 900000 : cross-entropy : 39.1827 : stalled 1 times (last best: 39.0723)
[2019-08-09 10:54:47] [valid] Ep. 23 : Up. 900000 : perplexity : 4.66464 : stalled 1 times (last best: 4.64444)
[2019-08-09 10:55:43] [valid] Ep. 23 : Up. 900000 : translation : 29.07 : stalled 5 times (last best: 29.11)
[2019-08-09 11:01:11] Ep. 23 : Up. 902000 : Sen. 2,135,242 : Cost 34.82951355 : Time 442.91s : 10969.26 words/s
[2019-08-09 11:06:37] Ep. 23 : Up. 904000 : Sen. 2,356,035 : Cost 35.14403152 : Time 326.12s : 14899.49 words/s
[2019-08-09 11:12:02] Ep. 23 : Up. 906000 : Sen. 2,575,511 : Cost 35.09662247 : Time 324.49s : 14860.61 words/s
[2019-08-09 11:17:27] Ep. 23 : Up. 908000 : Sen. 2,796,722 : Cost 35.19749832 : Time 325.40s : 14939.34 words/s
[2019-08-09 11:22:51] Ep. 23 : Up. 910000 : Sen. 3,016,927 : Cost 35.18304825 : Time 324.40s : 14960.75 words/s
[2019-08-09 11:28:15] Ep. 23 : Up. 912000 : Sen. 3,237,206 : Cost 35.35555267 : Time 323.62s : 14984.38 words/s
[2019-08-09 11:33:40] Ep. 23 : Up. 914000 : Sen. 3,458,021 : Cost 35.05622864 : Time 324.59s : 14955.04 words/s
[2019-08-09 11:39:03] Ep. 23 : Up. 916000 : Sen. 3,677,510 : Cost 35.32802963 : Time 323.28s : 14948.12 words/s
[2019-08-09 11:44:27] Ep. 23 : Up. 918000 : Sen. 3,897,824 : Cost 35.32606506 : Time 323.86s : 14939.77 words/s
[2019-08-09 11:49:51] Ep. 23 : Up. 920000 : Sen. 4,117,976 : Cost 35.36355209 : Time 324.24s : 14929.44 words/s
[2019-08-09 11:49:51] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-09 11:50:00] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter920000.npz
[2019-08-09 11:50:07] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-09 11:50:17] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-09 11:50:43] [valid] Ep. 23 : Up. 920000 : cross-entropy : 39.0809 : stalled 2 times (last best: 39.0723)
[2019-08-09 11:50:50] [valid] Ep. 23 : Up. 920000 : perplexity : 4.64601 : stalled 2 times (last best: 4.64444)
[2019-08-09 11:51:45] [valid] Ep. 23 : Up. 920000 : translation : 29.17 : new best
[2019-08-09 11:57:12] Ep. 23 : Up. 922000 : Sen. 4,338,007 : Cost 35.42912292 : Time 440.61s : 10999.48 words/s
[2019-08-09 11:59:17] Seen 4423484 samples
[2019-08-09 11:59:17] Starting epoch 24
[2019-08-09 11:59:17] [data] Shuffling data
[2019-08-09 11:59:20] [data] Done reading 5171769 sentences
[2019-08-09 11:59:43] [data] Done shuffling 5171769 sentences to temp files
[2019-08-09 12:03:10] Ep. 24 : Up. 924000 : Sen. 134,863 : Cost 34.75702286 : Time 358.76s : 13513.20 words/s
[2019-08-09 12:08:35] Ep. 24 : Up. 926000 : Sen. 355,628 : Cost 34.24246216 : Time 324.75s : 14946.53 words/s
[2019-08-09 12:13:59] Ep. 24 : Up. 928000 : Sen. 575,787 : Cost 34.46186066 : Time 324.30s : 14928.92 words/s
[2019-08-09 12:19:24] Ep. 24 : Up. 930000 : Sen. 796,316 : Cost 34.62443924 : Time 325.01s : 14949.94 words/s
[2019-08-09 12:24:49] Ep. 24 : Up. 932000 : Sen. 1,016,956 : Cost 34.64552689 : Time 324.22s : 14972.52 words/s
[2019-08-09 12:30:13] Ep. 24 : Up. 934000 : Sen. 1,238,150 : Cost 34.71327972 : Time 324.49s : 14983.94 words/s
[2019-08-09 12:35:38] Ep. 24 : Up. 936000 : Sen. 1,459,200 : Cost 34.78977966 : Time 324.50s : 14997.23 words/s
[2019-08-09 12:41:03] Ep. 24 : Up. 938000 : Sen. 1,679,784 : Cost 34.73222733 : Time 324.99s : 14937.65 words/s
[2019-08-09 12:46:27] Ep. 24 : Up. 940000 : Sen. 1,899,403 : Cost 35.00115967 : Time 324.94s : 14917.48 words/s
[2019-08-09 12:46:27] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-09 12:46:37] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter940000.npz
[2019-08-09 12:46:44] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-09 12:46:54] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-09 12:47:20] [valid] Ep. 24 : Up. 940000 : cross-entropy : 39.1244 : stalled 3 times (last best: 39.0723)
[2019-08-09 12:47:26] [valid] Ep. 24 : Up. 940000 : perplexity : 4.65396 : stalled 3 times (last best: 4.64444)
[2019-08-09 12:48:21] [valid] Ep. 24 : Up. 940000 : translation : 29.01 : stalled 1 times (last best: 29.17)
[2019-08-09 12:53:47] Ep. 24 : Up. 942000 : Sen. 2,120,234 : Cost 34.94296646 : Time 439.87s : 11062.89 words/s
[2019-08-09 12:59:11] Ep. 24 : Up. 944000 : Sen. 2,341,374 : Cost 34.75461197 : Time 323.96s : 14971.98 words/s
[2019-08-09 13:04:36] Ep. 24 : Up. 946000 : Sen. 2,561,920 : Cost 35.17925262 : Time 324.31s : 14981.80 words/s
[2019-08-09 13:09:59] Ep. 24 : Up. 948000 : Sen. 2,782,160 : Cost 35.03518295 : Time 323.62s : 14938.95 words/s
[2019-08-09 13:15:24] Ep. 24 : Up. 950000 : Sen. 3,002,325 : Cost 35.00665665 : Time 324.37s : 14919.79 words/s
[2019-08-09 13:20:49] Ep. 24 : Up. 952000 : Sen. 3,223,231 : Cost 34.98782349 : Time 325.56s : 14939.58 words/s
[2019-08-09 13:26:14] Ep. 24 : Up. 954000 : Sen. 3,444,224 : Cost 35.11294937 : Time 325.19s : 14945.13 words/s
[2019-08-09 13:31:39] Ep. 24 : Up. 956000 : Sen. 3,664,912 : Cost 35.15053940 : Time 324.91s : 14954.02 words/s
[2019-08-09 13:37:05] Ep. 24 : Up. 958000 : Sen. 3,885,523 : Cost 35.35525131 : Time 325.41s : 14923.09 words/s
[2019-08-09 13:42:30] Ep. 24 : Up. 960000 : Sen. 4,105,624 : Cost 35.09268188 : Time 325.75s : 14869.30 words/s
[2019-08-09 13:42:30] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-09 13:42:40] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter960000.npz
[2019-08-09 13:42:47] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-09 13:42:56] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-09 13:43:22] [valid] Ep. 24 : Up. 960000 : cross-entropy : 39.0426 : new best
[2019-08-09 13:43:29] [valid] Ep. 24 : Up. 960000 : perplexity : 4.63902 : new best
[2019-08-09 13:44:23] [valid] Ep. 24 : Up. 960000 : translation : 29.39 : new best
[2019-08-09 13:49:49] Ep. 24 : Up. 962000 : Sen. 4,325,252 : Cost 35.41834259 : Time 438.59s : 11041.68 words/s
[2019-08-09 13:52:14] Seen 4423484 samples
[2019-08-09 13:52:14] Starting epoch 25
[2019-08-09 13:52:14] [data] Shuffling data
[2019-08-09 13:52:17] [data] Done reading 5171769 sentences
[2019-08-09 13:52:34] [data] Done shuffling 5171769 sentences to temp files
[2019-08-09 13:55:43] Ep. 25 : Up. 964000 : Sen. 122,867 : Cost 34.56728363 : Time 354.08s : 13716.74 words/s
[2019-08-09 14:01:08] Ep. 25 : Up. 966000 : Sen. 343,122 : Cost 34.38986969 : Time 324.62s : 14931.23 words/s
[2019-08-09 14:06:34] Ep. 25 : Up. 968000 : Sen. 565,043 : Cost 34.35455704 : Time 326.64s : 14932.10 words/s
[2019-08-09 14:12:01] Ep. 25 : Up. 970000 : Sen. 785,994 : Cost 34.43766785 : Time 327.09s : 14849.57 words/s
[2019-08-09 14:17:30] Ep. 25 : Up. 972000 : Sen. 1,006,925 : Cost 34.78205872 : Time 328.21s : 14838.72 words/s
[2019-08-09 14:22:55] Ep. 25 : Up. 974000 : Sen. 1,227,255 : Cost 34.50519562 : Time 325.52s : 14916.18 words/s
[2019-08-09 14:28:22] Ep. 25 : Up. 976000 : Sen. 1,448,363 : Cost 34.54590988 : Time 326.52s : 14888.70 words/s
[2019-08-09 14:33:47] Ep. 25 : Up. 978000 : Sen. 1,668,168 : Cost 34.79040909 : Time 324.82s : 14891.58 words/s
[2019-08-09 14:39:11] Ep. 25 : Up. 980000 : Sen. 1,887,701 : Cost 34.73165894 : Time 324.58s : 14888.08 words/s
[2019-08-09 14:39:11] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-09 14:39:21] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter980000.npz
[2019-08-09 14:39:28] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-09 14:39:38] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-09 14:40:03] [valid] Ep. 25 : Up. 980000 : cross-entropy : 39.1093 : stalled 1 times (last best: 39.0426)
[2019-08-09 14:40:10] [valid] Ep. 25 : Up. 980000 : perplexity : 4.6512 : stalled 1 times (last best: 4.63902)
[2019-08-09 14:41:06] [valid] Ep. 25 : Up. 980000 : translation : 29.24 : stalled 1 times (last best: 29.39)
[2019-08-09 14:46:33] Ep. 25 : Up. 982000 : Sen. 2,108,418 : Cost 34.73342896 : Time 442.28s : 10979.43 words/s
[2019-08-09 14:51:59] Ep. 25 : Up. 984000 : Sen. 2,328,633 : Cost 34.74527359 : Time 325.43s : 14870.48 words/s
[2019-08-09 14:57:26] Ep. 25 : Up. 986000 : Sen. 2,549,211 : Cost 34.87359238 : Time 326.98s : 14834.85 words/s
[2019-08-09 15:02:52] Ep. 25 : Up. 988000 : Sen. 2,768,347 : Cost 34.99551392 : Time 326.29s : 14798.17 words/s
[2019-08-09 15:08:19] Ep. 25 : Up. 990000 : Sen. 2,987,637 : Cost 34.90851212 : Time 326.81s : 14777.93 words/s
[2019-08-09 15:13:46] Ep. 25 : Up. 992000 : Sen. 3,207,003 : Cost 34.96668243 : Time 326.81s : 14774.79 words/s
[2019-08-09 15:19:13] Ep. 25 : Up. 994000 : Sen. 3,427,918 : Cost 34.76744843 : Time 327.23s : 14812.99 words/s
[2019-08-09 15:24:41] Ep. 25 : Up. 996000 : Sen. 3,648,628 : Cost 35.30428314 : Time 327.54s : 14846.00 words/s
[2019-08-09 15:30:06] Ep. 25 : Up. 998000 : Sen. 3,867,988 : Cost 35.15719223 : Time 325.49s : 14814.80 words/s
[2019-08-09 15:35:33] Ep. 25 : Up. 1000000 : Sen. 4,089,182 : Cost 35.07165527 : Time 326.71s : 14894.00 words/s
[2019-08-09 15:35:33] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-09 15:35:43] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter1000000.npz
[2019-08-09 15:35:50] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-09 15:35:59] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-09 15:36:25] [valid] Ep. 25 : Up. 1000000 : cross-entropy : 39.0476 : stalled 2 times (last best: 39.0426)
[2019-08-09 15:36:32] [valid] Ep. 25 : Up. 1000000 : perplexity : 4.63993 : stalled 2 times (last best: 4.63902)
[2019-08-09 15:37:28] [valid] Ep. 25 : Up. 1000000 : translation : 29.01 : stalled 2 times (last best: 29.39)
[2019-08-09 15:42:56] Ep. 25 : Up. 1002000 : Sen. 4,308,502 : Cost 35.22940063 : Time 443.50s : 10884.65 words/s
[2019-08-09 15:45:47] Seen 4423484 samples
[2019-08-09 15:45:47] Starting epoch 26
[2019-08-09 15:45:47] [data] Shuffling data
[2019-08-09 15:45:50] [data] Done reading 5171769 sentences
[2019-08-09 15:46:10] [data] Done shuffling 5171769 sentences to temp files
[2019-08-09 15:48:58] Ep. 26 : Up. 1004000 : Sen. 104,444 : Cost 34.97781754 : Time 361.52s : 13397.37 words/s
[2019-08-09 15:54:24] Ep. 26 : Up. 1006000 : Sen. 325,953 : Cost 34.09952927 : Time 326.19s : 14921.60 words/s
[2019-08-09 15:59:49] Ep. 26 : Up. 1008000 : Sen. 545,837 : Cost 34.28476715 : Time 325.18s : 14904.11 words/s
[2019-08-09 16:05:13] Ep. 26 : Up. 1010000 : Sen. 765,367 : Cost 34.36164474 : Time 324.05s : 14897.42 words/s
[2019-08-09 16:10:38] Ep. 26 : Up. 1012000 : Sen. 986,231 : Cost 34.39574051 : Time 325.21s : 14934.91 words/s
[2019-08-09 16:16:04] Ep. 26 : Up. 1014000 : Sen. 1,207,411 : Cost 34.37095261 : Time 325.92s : 14925.64 words/s
[2019-08-09 16:21:28] Ep. 26 : Up. 1016000 : Sen. 1,427,122 : Cost 34.47457504 : Time 323.70s : 14905.08 words/s
[2019-08-09 16:26:52] Ep. 26 : Up. 1018000 : Sen. 1,647,424 : Cost 34.70455170 : Time 324.43s : 14927.77 words/s
[2019-08-09 16:32:18] Ep. 26 : Up. 1020000 : Sen. 1,868,665 : Cost 34.71188736 : Time 325.85s : 14961.74 words/s
[2019-08-09 16:32:18] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-09 16:32:28] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter1020000.npz
[2019-08-09 16:32:35] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-09 16:32:45] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-09 16:33:12] [valid] Ep. 26 : Up. 1020000 : cross-entropy : 39.0829 : stalled 3 times (last best: 39.0426)
[2019-08-09 16:33:18] [valid] Ep. 26 : Up. 1020000 : perplexity : 4.64638 : stalled 3 times (last best: 4.63902)
[2019-08-09 16:34:15] [valid] Ep. 26 : Up. 1020000 : translation : 28.94 : stalled 3 times (last best: 29.39)
[2019-08-09 16:39:41] Ep. 26 : Up. 1022000 : Sen. 2,089,386 : Cost 34.55603790 : Time 443.07s : 10949.61 words/s
[2019-08-09 16:45:06] Ep. 26 : Up. 1024000 : Sen. 2,309,613 : Cost 34.76829529 : Time 324.81s : 14911.80 words/s
[2019-08-09 16:50:31] Ep. 26 : Up. 1026000 : Sen. 2,530,046 : Cost 34.74571228 : Time 325.21s : 14923.87 words/s
[2019-08-09 16:55:56] Ep. 26 : Up. 1028000 : Sen. 2,750,756 : Cost 34.68234253 : Time 324.30s : 14951.53 words/s
[2019-08-09 17:01:22] Ep. 26 : Up. 1030000 : Sen. 2,972,655 : Cost 34.91004562 : Time 326.49s : 14942.74 words/s
[2019-08-09 17:06:47] Ep. 26 : Up. 1032000 : Sen. 3,193,018 : Cost 35.02561951 : Time 324.63s : 14936.56 words/s
[2019-08-09 17:12:11] Ep. 26 : Up. 1034000 : Sen. 3,413,066 : Cost 34.89522552 : Time 324.57s : 14959.97 words/s
[2019-08-09 17:17:35] Ep. 26 : Up. 1036000 : Sen. 3,633,440 : Cost 35.02204514 : Time 323.82s : 14940.10 words/s
[2019-08-09 17:23:01] Ep. 26 : Up. 1038000 : Sen. 3,854,206 : Cost 34.99726105 : Time 325.46s : 14956.49 words/s
[2019-08-09 17:28:26] Ep. 26 : Up. 1040000 : Sen. 4,074,912 : Cost 35.08322906 : Time 325.08s : 14960.12 words/s
[2019-08-09 17:28:26] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-09 17:28:35] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter1040000.npz
[2019-08-09 17:28:43] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-09 17:28:53] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-09 17:29:19] [valid] Ep. 26 : Up. 1040000 : cross-entropy : 38.9791 : new best
[2019-08-09 17:29:26] [valid] Ep. 26 : Up. 1040000 : perplexity : 4.62745 : new best
[2019-08-09 17:30:22] [valid] Ep. 26 : Up. 1040000 : translation : 29.08 : stalled 4 times (last best: 29.39)
[2019-08-09 17:35:49] Ep. 26 : Up. 1042000 : Sen. 4,296,498 : Cost 34.89088058 : Time 443.48s : 10987.38 words/s
[2019-08-09 17:38:57] Seen 4423484 samples
[2019-08-09 17:38:57] Starting epoch 27
[2019-08-09 17:38:57] [data] Shuffling data
[2019-08-09 17:39:00] [data] Done reading 5171769 sentences
[2019-08-09 17:39:18] [data] Done shuffling 5171769 sentences to temp files
[2019-08-09 17:41:44] Ep. 27 : Up. 1044000 : Sen. 94,001 : Cost 34.34757614 : Time 354.55s : 13702.38 words/s
[2019-08-09 17:47:08] Ep. 27 : Up. 1046000 : Sen. 314,525 : Cost 34.23327255 : Time 323.86s : 14997.40 words/s
[2019-08-09 17:52:32] Ep. 27 : Up. 1048000 : Sen. 535,264 : Cost 34.37408447 : Time 324.76s : 14987.25 words/s
[2019-08-09 17:57:56] Ep. 27 : Up. 1050000 : Sen. 756,345 : Cost 34.06216431 : Time 323.55s : 15002.60 words/s
[2019-08-09 18:03:20] Ep. 27 : Up. 1052000 : Sen. 977,195 : Cost 34.20806503 : Time 323.71s : 14992.74 words/s
[2019-08-09 18:08:44] Ep. 27 : Up. 1054000 : Sen. 1,197,601 : Cost 34.36676025 : Time 324.79s : 14941.41 words/s
[2019-08-09 18:14:09] Ep. 27 : Up. 1056000 : Sen. 1,417,619 : Cost 34.58588409 : Time 324.27s : 14954.60 words/s
[2019-08-09 18:19:32] Ep. 27 : Up. 1058000 : Sen. 1,637,658 : Cost 34.28018188 : Time 323.39s : 14963.20 words/s
[2019-08-09 18:24:56] Ep. 27 : Up. 1060000 : Sen. 1,857,935 : Cost 34.70999146 : Time 324.24s : 14965.73 words/s
[2019-08-09 18:24:56] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-09 18:25:06] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter1060000.npz
[2019-08-09 18:25:14] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-09 18:25:24] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-09 18:25:50] [valid] Ep. 27 : Up. 1060000 : cross-entropy : 39.012 : stalled 1 times (last best: 38.9791)
[2019-08-09 18:25:56] [valid] Ep. 27 : Up. 1060000 : perplexity : 4.63344 : stalled 1 times (last best: 4.62745)
[2019-08-09 18:26:52] [valid] Ep. 27 : Up. 1060000 : translation : 29.18 : stalled 5 times (last best: 29.39)
[2019-08-09 18:32:18] Ep. 27 : Up. 1062000 : Sen. 2,078,194 : Cost 34.37327957 : Time 441.36s : 10981.81 words/s
[2019-08-09 18:37:42] Ep. 27 : Up. 1064000 : Sen. 2,298,810 : Cost 34.75072479 : Time 324.72s : 14940.52 words/s
[2019-08-09 18:43:07] Ep. 27 : Up. 1066000 : Sen. 2,518,374 : Cost 34.69739532 : Time 324.13s : 14925.78 words/s
[2019-08-09 18:48:30] Ep. 27 : Up. 1068000 : Sen. 2,738,688 : Cost 34.69381332 : Time 323.71s : 14986.40 words/s
[2019-08-09 18:53:55] Ep. 27 : Up. 1070000 : Sen. 2,960,376 : Cost 34.75395966 : Time 324.63s : 15017.02 words/s
[2019-08-09 18:59:17] Ep. 27 : Up. 1072000 : Sen. 3,180,092 : Cost 34.58748627 : Time 322.19s : 14946.26 words/s
[2019-08-09 19:04:42] Ep. 27 : Up. 1074000 : Sen. 3,400,464 : Cost 34.63923645 : Time 324.61s : 14950.09 words/s
[2019-08-09 19:10:06] Ep. 27 : Up. 1076000 : Sen. 3,620,526 : Cost 34.76391220 : Time 324.56s : 14943.92 words/s
[2019-08-09 19:15:30] Ep. 27 : Up. 1078000 : Sen. 3,840,770 : Cost 34.98637009 : Time 323.80s : 14962.35 words/s
[2019-08-09 19:20:54] Ep. 27 : Up. 1080000 : Sen. 4,061,464 : Cost 34.88682175 : Time 323.57s : 15009.99 words/s
[2019-08-09 19:20:54] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-09 19:21:03] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter1080000.npz
[2019-08-09 19:21:12] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-09 19:21:23] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-09 19:21:49] [valid] Ep. 27 : Up. 1080000 : cross-entropy : 38.9588 : new best
[2019-08-09 19:21:56] [valid] Ep. 27 : Up. 1080000 : perplexity : 4.62376 : new best
[2019-08-09 19:22:53] [valid] Ep. 27 : Up. 1080000 : translation : 28.97 : stalled 6 times (last best: 29.39)
[2019-08-09 19:28:18] Ep. 27 : Up. 1082000 : Sen. 4,281,395 : Cost 35.06300735 : Time 444.46s : 10894.29 words/s
[2019-08-09 19:31:47] Seen 4423484 samples
[2019-08-09 19:31:47] Starting epoch 28
[2019-08-09 19:31:47] [data] Shuffling data
[2019-08-09 19:31:50] [data] Done reading 5171769 sentences
[2019-08-09 19:32:14] [data] Done shuffling 5171769 sentences to temp files
[2019-08-09 19:34:17] Ep. 28 : Up. 1084000 : Sen. 78,217 : Cost 34.59679794 : Time 358.52s : 13515.34 words/s
[2019-08-09 19:39:41] Ep. 28 : Up. 1086000 : Sen. 298,750 : Cost 34.08396912 : Time 323.93s : 14975.07 words/s
[2019-08-09 19:45:05] Ep. 28 : Up. 1088000 : Sen. 518,634 : Cost 34.12462616 : Time 324.11s : 14955.11 words/s
[2019-08-09 19:50:28] Ep. 28 : Up. 1090000 : Sen. 739,593 : Cost 34.25753784 : Time 323.48s : 15021.40 words/s
[2019-08-09 19:55:51] Ep. 28 : Up. 1092000 : Sen. 959,801 : Cost 34.15346146 : Time 322.71s : 14999.60 words/s
[2019-08-09 20:01:15] Ep. 28 : Up. 1094000 : Sen. 1,181,132 : Cost 34.40584183 : Time 324.47s : 15020.40 words/s
[2019-08-09 20:06:40] Ep. 28 : Up. 1096000 : Sen. 1,401,678 : Cost 34.24065781 : Time 324.34s : 14976.91 words/s
[2019-08-09 20:12:04] Ep. 28 : Up. 1098000 : Sen. 1,622,702 : Cost 34.27006912 : Time 324.09s : 15010.99 words/s
[2019-08-09 20:17:27] Ep. 28 : Up. 1100000 : Sen. 1,843,550 : Cost 34.43078995 : Time 323.31s : 15008.71 words/s
[2019-08-09 20:17:27] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-09 20:17:37] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter1100000.npz
[2019-08-09 20:17:44] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-09 20:17:54] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-09 20:18:20] [valid] Ep. 28 : Up. 1100000 : cross-entropy : 39.0441 : stalled 1 times (last best: 38.9588)
[2019-08-09 20:18:27] [valid] Ep. 28 : Up. 1100000 : perplexity : 4.63929 : stalled 1 times (last best: 4.62376)
[2019-08-09 20:19:23] [valid] Ep. 28 : Up. 1100000 : translation : 28.97 : stalled 7 times (last best: 29.39)
[2019-08-09 20:24:49] Ep. 28 : Up. 1102000 : Sen. 2,064,684 : Cost 34.41129684 : Time 441.83s : 10995.69 words/s
[2019-08-09 20:30:14] Ep. 28 : Up. 1104000 : Sen. 2,284,374 : Cost 34.75497818 : Time 324.91s : 14935.36 words/s
[2019-08-09 20:35:38] Ep. 28 : Up. 1106000 : Sen. 2,505,434 : Cost 34.48017883 : Time 324.27s : 15003.48 words/s
[2019-08-09 20:41:03] Ep. 28 : Up. 1108000 : Sen. 2,725,687 : Cost 34.40663528 : Time 324.89s : 14940.64 words/s
[2019-08-09 20:46:26] Ep. 28 : Up. 1110000 : Sen. 2,945,981 : Cost 34.48835373 : Time 323.10s : 14992.29 words/s
[2019-08-09 20:51:49] Ep. 28 : Up. 1112000 : Sen. 3,166,099 : Cost 34.50928497 : Time 322.47s : 14994.18 words/s
[2019-08-09 20:57:12] Ep. 28 : Up. 1114000 : Sen. 3,386,368 : Cost 34.81737900 : Time 323.58s : 14976.31 words/s
[2019-08-09 21:02:36] Ep. 28 : Up. 1116000 : Sen. 3,606,035 : Cost 34.82563019 : Time 323.83s : 14960.16 words/s
[2019-08-09 21:07:57] Ep. 28 : Up. 1118000 : Sen. 3,826,495 : Cost 34.78749084 : Time 321.31s : 15039.26 words/s
[2019-08-09 21:13:21] Ep. 28 : Up. 1120000 : Sen. 4,046,373 : Cost 34.74764252 : Time 323.31s : 14974.60 words/s
[2019-08-09 21:13:21] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-09 21:13:31] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter1120000.npz
[2019-08-09 21:13:38] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-09 21:13:49] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-09 21:14:16] [valid] Ep. 28 : Up. 1120000 : cross-entropy : 38.9729 : stalled 2 times (last best: 38.9588)
[2019-08-09 21:14:22] [valid] Ep. 28 : Up. 1120000 : perplexity : 4.62633 : stalled 2 times (last best: 4.62376)
[2019-08-09 21:15:19] [valid] Ep. 28 : Up. 1120000 : translation : 29.02 : stalled 8 times (last best: 29.39)
[2019-08-09 21:20:45] Ep. 28 : Up. 1122000 : Sen. 4,267,281 : Cost 34.67276382 : Time 444.56s : 10929.71 words/s
[2019-08-09 21:24:35] Seen 4423484 samples
[2019-08-09 21:24:35] Starting epoch 29
[2019-08-09 21:24:35] [data] Shuffling data
[2019-08-09 21:24:38] [data] Done reading 5171769 sentences
[2019-08-09 21:25:00] [data] Done shuffling 5171769 sentences to temp files
[2019-08-09 21:26:41] Ep. 29 : Up. 1124000 : Sen. 63,446 : Cost 34.59906769 : Time 355.56s : 13598.64 words/s
[2019-08-09 21:32:05] Ep. 29 : Up. 1126000 : Sen. 284,523 : Cost 33.89432144 : Time 324.30s : 14995.34 words/s
[2019-08-09 21:37:27] Ep. 29 : Up. 1128000 : Sen. 504,389 : Cost 33.97126389 : Time 322.36s : 15008.45 words/s
[2019-08-09 21:42:51] Ep. 29 : Up. 1130000 : Sen. 724,913 : Cost 33.94715500 : Time 323.41s : 14987.41 words/s
[2019-08-09 21:48:16] Ep. 29 : Up. 1132000 : Sen. 946,214 : Cost 34.14591599 : Time 325.47s : 14978.82 words/s
[2019-08-09 21:53:41] Ep. 29 : Up. 1134000 : Sen. 1,167,889 : Cost 33.86038971 : Time 324.58s : 14989.67 words/s
[2019-08-09 21:59:04] Ep. 29 : Up. 1136000 : Sen. 1,387,169 : Cost 34.32290649 : Time 323.19s : 14952.61 words/s
[2019-08-09 22:04:27] Ep. 29 : Up. 1138000 : Sen. 1,606,896 : Cost 34.34085464 : Time 323.39s : 14972.23 words/s
[2019-08-09 22:09:52] Ep. 29 : Up. 1140000 : Sen. 1,828,283 : Cost 34.23690796 : Time 324.22s : 15024.73 words/s
[2019-08-09 22:09:52] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-09 22:10:02] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter1140000.npz
[2019-08-09 22:10:09] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-09 22:10:19] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-09 22:10:46] [valid] Ep. 29 : Up. 1140000 : cross-entropy : 39.0308 : stalled 3 times (last best: 38.9588)
[2019-08-09 22:10:52] [valid] Ep. 29 : Up. 1140000 : perplexity : 4.63688 : stalled 3 times (last best: 4.62376)
[2019-08-09 22:11:49] [valid] Ep. 29 : Up. 1140000 : translation : 29.12 : stalled 9 times (last best: 29.39)
[2019-08-09 22:17:15] Ep. 29 : Up. 1142000 : Sen. 2,049,333 : Cost 34.54492950 : Time 443.15s : 10981.94 words/s
[2019-08-09 22:22:36] Ep. 29 : Up. 1144000 : Sen. 2,269,825 : Cost 34.34828568 : Time 321.62s : 15058.82 words/s
[2019-08-09 22:28:00] Ep. 29 : Up. 1146000 : Sen. 2,490,704 : Cost 34.37202835 : Time 323.29s : 15028.81 words/s
[2019-08-09 22:33:21] Ep. 29 : Up. 1148000 : Sen. 2,709,850 : Cost 34.48789978 : Time 321.58s : 15022.10 words/s
[2019-08-09 22:38:43] Ep. 29 : Up. 1150000 : Sen. 2,930,102 : Cost 34.21738434 : Time 321.88s : 15036.30 words/s
[2019-08-09 22:44:05] Ep. 29 : Up. 1152000 : Sen. 3,150,089 : Cost 34.48669052 : Time 322.05s : 15031.21 words/s
[2019-08-09 22:49:27] Ep. 29 : Up. 1154000 : Sen. 3,370,319 : Cost 34.52445221 : Time 321.94s : 15070.67 words/s
[2019-08-09 22:54:49] Ep. 29 : Up. 1156000 : Sen. 3,590,712 : Cost 34.46597672 : Time 321.45s : 15079.73 words/s
[2019-08-09 23:00:10] Ep. 29 : Up. 1158000 : Sen. 3,811,286 : Cost 34.76618195 : Time 321.59s : 15111.25 words/s
[2019-08-09 23:05:32] Ep. 29 : Up. 1160000 : Sen. 4,031,216 : Cost 34.60948181 : Time 321.47s : 15044.68 words/s
[2019-08-09 23:05:32] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-09 23:05:41] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter1160000.npz
[2019-08-09 23:05:48] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-09 23:05:57] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-09 23:06:23] [valid] Ep. 29 : Up. 1160000 : cross-entropy : 38.9758 : stalled 4 times (last best: 38.9588)
[2019-08-09 23:06:30] [valid] Ep. 29 : Up. 1160000 : perplexity : 4.62687 : stalled 4 times (last best: 4.62376)
[2019-08-09 23:07:24] [valid] Ep. 29 : Up. 1160000 : translation : 28.89 : stalled 10 times (last best: 29.39)
[2019-08-09 23:12:48] Ep. 29 : Up. 1162000 : Sen. 4,252,209 : Cost 34.60128021 : Time 436.08s : 11143.61 words/s
[2019-08-09 23:16:59] Seen 4423484 samples
[2019-08-09 23:16:59] Starting epoch 30
[2019-08-09 23:16:59] [data] Shuffling data
[2019-08-09 23:17:01] [data] Done reading 5171769 sentences
[2019-08-09 23:17:23] [data] Done shuffling 5171769 sentences to temp files
[2019-08-09 23:18:44] Ep. 30 : Up. 1164000 : Sen. 48,966 : Cost 34.38562012 : Time 356.44s : 13604.00 words/s
[2019-08-09 23:24:06] Ep. 30 : Up. 1166000 : Sen. 268,956 : Cost 33.80191422 : Time 321.68s : 15032.87 words/s
[2019-08-09 23:29:28] Ep. 30 : Up. 1168000 : Sen. 489,301 : Cost 33.77372742 : Time 322.02s : 15056.10 words/s
[2019-08-09 23:34:50] Ep. 30 : Up. 1170000 : Sen. 710,007 : Cost 33.77751160 : Time 321.83s : 15063.39 words/s
[2019-08-09 23:40:13] Ep. 30 : Up. 1172000 : Sen. 929,985 : Cost 34.20737076 : Time 322.69s : 15004.66 words/s
[2019-08-09 23:45:34] Ep. 30 : Up. 1174000 : Sen. 1,150,642 : Cost 33.96596909 : Time 321.76s : 15078.63 words/s
[2019-08-09 23:50:57] Ep. 30 : Up. 1176000 : Sen. 1,371,206 : Cost 34.00414276 : Time 322.88s : 15018.14 words/s
[2019-08-09 23:56:20] Ep. 30 : Up. 1178000 : Sen. 1,591,169 : Cost 34.14818954 : Time 322.34s : 15027.75 words/s
[2019-08-10 00:01:42] Ep. 30 : Up. 1180000 : Sen. 1,812,597 : Cost 33.97927475 : Time 322.71s : 15071.09 words/s
[2019-08-10 00:01:42] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-10 00:01:52] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter1180000.npz
[2019-08-10 00:01:59] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-10 00:02:08] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-10 00:02:35] [valid] Ep. 30 : Up. 1180000 : cross-entropy : 38.9939 : stalled 5 times (last best: 38.9588)
[2019-08-10 00:02:41] [valid] Ep. 30 : Up. 1180000 : perplexity : 4.63015 : stalled 5 times (last best: 4.62376)
[2019-08-10 00:03:35] [valid] Ep. 30 : Up. 1180000 : translation : 28.95 : stalled 11 times (last best: 29.39)
[2019-08-10 00:03:37] Training finished
[2019-08-10 00:03:42] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-10 00:03:51] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-10 00:04:01] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
