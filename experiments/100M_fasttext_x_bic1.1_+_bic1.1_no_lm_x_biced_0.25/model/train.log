[2019-08-06 17:44:55] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-06 17:44:55] [marian] Running on elli as process 97582 with command line:
[2019-08-06 17:44:55] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz -T . --devices 0 --train-sets ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en --vocabs ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de.json ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/dev.bpe.de ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/dev.out --valid-script-path ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/train.log --valid-log ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/valid.log
[2019-08-06 17:44:55] [config] after-batches: 0
[2019-08-06 17:44:55] [config] after-epochs: 0
[2019-08-06 17:44:55] [config] allow-unk: false
[2019-08-06 17:44:55] [config] beam-size: 12
[2019-08-06 17:44:55] [config] bert-class-symbol: "[CLS]"
[2019-08-06 17:44:55] [config] bert-mask-symbol: "[MASK]"
[2019-08-06 17:44:55] [config] bert-masking-fraction: 0.15
[2019-08-06 17:44:55] [config] bert-sep-symbol: "[SEP]"
[2019-08-06 17:44:55] [config] bert-train-type-embeddings: true
[2019-08-06 17:44:55] [config] bert-type-vocab-size: 2
[2019-08-06 17:44:55] [config] best-deep: false
[2019-08-06 17:44:55] [config] clip-gemm: 0
[2019-08-06 17:44:55] [config] clip-norm: 1
[2019-08-06 17:44:55] [config] cost-type: ce-mean
[2019-08-06 17:44:55] [config] cpu-threads: 0
[2019-08-06 17:44:55] [config] data-weighting: ""
[2019-08-06 17:44:55] [config] data-weighting-type: sentence
[2019-08-06 17:44:55] [config] dec-cell: gru
[2019-08-06 17:44:55] [config] dec-cell-base-depth: 2
[2019-08-06 17:44:55] [config] dec-cell-high-depth: 1
[2019-08-06 17:44:55] [config] dec-depth: 1
[2019-08-06 17:44:55] [config] devices:
[2019-08-06 17:44:55] [config]   - 0
[2019-08-06 17:44:55] [config] dim-emb: 512
[2019-08-06 17:44:55] [config] dim-rnn: 1024
[2019-08-06 17:44:55] [config] dim-vocabs:
[2019-08-06 17:44:55] [config]   - 50000
[2019-08-06 17:44:55] [config]   - 50000
[2019-08-06 17:44:55] [config] disp-first: 0
[2019-08-06 17:44:55] [config] disp-freq: 2000
[2019-08-06 17:44:55] [config] disp-label-counts: false
[2019-08-06 17:44:55] [config] dropout-rnn: 0.2
[2019-08-06 17:44:55] [config] dropout-src: 0.1
[2019-08-06 17:44:55] [config] dropout-trg: 0.1
[2019-08-06 17:44:55] [config] dump-config: ""
[2019-08-06 17:44:55] [config] early-stopping: 5
[2019-08-06 17:44:55] [config] embedding-fix-src: false
[2019-08-06 17:44:55] [config] embedding-fix-trg: false
[2019-08-06 17:44:55] [config] embedding-normalization: false
[2019-08-06 17:44:55] [config] embedding-vectors:
[2019-08-06 17:44:55] [config]   []
[2019-08-06 17:44:55] [config] enc-cell: gru
[2019-08-06 17:44:55] [config] enc-cell-depth: 1
[2019-08-06 17:44:55] [config] enc-depth: 1
[2019-08-06 17:44:55] [config] enc-type: bidirectional
[2019-08-06 17:44:55] [config] exponential-smoothing: 0.0001
[2019-08-06 17:44:55] [config] grad-dropping-momentum: 0
[2019-08-06 17:44:55] [config] grad-dropping-rate: 0
[2019-08-06 17:44:55] [config] grad-dropping-warmup: 100
[2019-08-06 17:44:55] [config] guided-alignment: none
[2019-08-06 17:44:55] [config] guided-alignment-cost: mse
[2019-08-06 17:44:55] [config] guided-alignment-weight: 0.1
[2019-08-06 17:44:55] [config] ignore-model-config: false
[2019-08-06 17:44:55] [config] input-types:
[2019-08-06 17:44:55] [config]   []
[2019-08-06 17:44:55] [config] interpolate-env-vars: false
[2019-08-06 17:44:55] [config] keep-best: false
[2019-08-06 17:44:55] [config] label-smoothing: 0
[2019-08-06 17:44:55] [config] layer-normalization: true
[2019-08-06 17:44:55] [config] learn-rate: 0.0001
[2019-08-06 17:44:55] [config] log: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/train.log
[2019-08-06 17:44:55] [config] log-level: info
[2019-08-06 17:44:55] [config] log-time-zone: ""
[2019-08-06 17:44:55] [config] lr-decay: 0
[2019-08-06 17:44:55] [config] lr-decay-freq: 50000
[2019-08-06 17:44:55] [config] lr-decay-inv-sqrt:
[2019-08-06 17:44:55] [config]   - 0
[2019-08-06 17:44:55] [config] lr-decay-repeat-warmup: false
[2019-08-06 17:44:55] [config] lr-decay-reset-optimizer: false
[2019-08-06 17:44:55] [config] lr-decay-start:
[2019-08-06 17:44:55] [config]   - 10
[2019-08-06 17:44:55] [config]   - 1
[2019-08-06 17:44:55] [config] lr-decay-strategy: epoch+stalled
[2019-08-06 17:44:55] [config] lr-report: false
[2019-08-06 17:44:55] [config] lr-warmup: 0
[2019-08-06 17:44:55] [config] lr-warmup-at-reload: false
[2019-08-06 17:44:55] [config] lr-warmup-cycle: false
[2019-08-06 17:44:55] [config] lr-warmup-start-rate: 0
[2019-08-06 17:44:55] [config] max-length: 50
[2019-08-06 17:44:55] [config] max-length-crop: false
[2019-08-06 17:44:55] [config] max-length-factor: 3
[2019-08-06 17:44:55] [config] maxi-batch: 100
[2019-08-06 17:44:55] [config] maxi-batch-sort: trg
[2019-08-06 17:44:55] [config] mini-batch: 64
[2019-08-06 17:44:55] [config] mini-batch-fit: true
[2019-08-06 17:44:55] [config] mini-batch-fit-step: 10
[2019-08-06 17:44:55] [config] mini-batch-overstuff: 1
[2019-08-06 17:44:55] [config] mini-batch-track-lr: false
[2019-08-06 17:44:55] [config] mini-batch-understuff: 1
[2019-08-06 17:44:55] [config] mini-batch-warmup: 0
[2019-08-06 17:44:55] [config] mini-batch-words: 0
[2019-08-06 17:44:55] [config] mini-batch-words-ref: 0
[2019-08-06 17:44:55] [config] model: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-06 17:44:55] [config] multi-loss-type: sum
[2019-08-06 17:44:55] [config] multi-node: false
[2019-08-06 17:44:55] [config] multi-node-overlap: true
[2019-08-06 17:44:55] [config] n-best: false
[2019-08-06 17:44:55] [config] no-nccl: false
[2019-08-06 17:44:55] [config] no-reload: false
[2019-08-06 17:44:55] [config] no-restore-corpus: false
[2019-08-06 17:44:55] [config] no-shuffle: false
[2019-08-06 17:44:55] [config] normalize: 1
[2019-08-06 17:44:55] [config] num-devices: 0
[2019-08-06 17:44:55] [config] optimizer: adam
[2019-08-06 17:44:55] [config] optimizer-delay: 1
[2019-08-06 17:44:55] [config] optimizer-params:
[2019-08-06 17:44:55] [config]   []
[2019-08-06 17:44:55] [config] overwrite: false
[2019-08-06 17:44:55] [config] pretrained-model: ""
[2019-08-06 17:44:55] [config] quiet: false
[2019-08-06 17:44:55] [config] quiet-translation: true
[2019-08-06 17:44:55] [config] relative-paths: false
[2019-08-06 17:44:55] [config] right-left: false
[2019-08-06 17:44:55] [config] save-freq: 20000
[2019-08-06 17:44:55] [config] seed: 1111
[2019-08-06 17:44:55] [config] shuffle-in-ram: false
[2019-08-06 17:44:55] [config] skip: false
[2019-08-06 17:44:55] [config] sqlite: ""
[2019-08-06 17:44:55] [config] sqlite-drop: false
[2019-08-06 17:44:55] [config] sync-sgd: true
[2019-08-06 17:44:55] [config] tempdir: .
[2019-08-06 17:44:55] [config] tied-embeddings: false
[2019-08-06 17:44:55] [config] tied-embeddings-all: false
[2019-08-06 17:44:55] [config] tied-embeddings-src: false
[2019-08-06 17:44:55] [config] train-sets:
[2019-08-06 17:44:55] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de
[2019-08-06 17:44:55] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en
[2019-08-06 17:44:55] [config] transformer-aan-activation: swish
[2019-08-06 17:44:55] [config] transformer-aan-depth: 2
[2019-08-06 17:44:55] [config] transformer-aan-nogate: false
[2019-08-06 17:44:55] [config] transformer-decoder-autoreg: self-attention
[2019-08-06 17:44:55] [config] transformer-dim-aan: 2048
[2019-08-06 17:44:55] [config] transformer-dim-ffn: 2048
[2019-08-06 17:44:55] [config] transformer-dropout: 0
[2019-08-06 17:44:55] [config] transformer-dropout-attention: 0
[2019-08-06 17:44:55] [config] transformer-dropout-ffn: 0
[2019-08-06 17:44:55] [config] transformer-ffn-activation: swish
[2019-08-06 17:44:55] [config] transformer-ffn-depth: 2
[2019-08-06 17:44:55] [config] transformer-guided-alignment-layer: last
[2019-08-06 17:44:55] [config] transformer-heads: 8
[2019-08-06 17:44:55] [config] transformer-no-projection: false
[2019-08-06 17:44:55] [config] transformer-postprocess: dan
[2019-08-06 17:44:55] [config] transformer-postprocess-emb: d
[2019-08-06 17:44:55] [config] transformer-preprocess: ""
[2019-08-06 17:44:55] [config] transformer-tied-layers:
[2019-08-06 17:44:55] [config]   []
[2019-08-06 17:44:55] [config] transformer-train-position-embeddings: false
[2019-08-06 17:44:55] [config] type: amun
[2019-08-06 17:44:55] [config] ulr: false
[2019-08-06 17:44:55] [config] ulr-dim-emb: 0
[2019-08-06 17:44:55] [config] ulr-dropout: 0
[2019-08-06 17:44:55] [config] ulr-keys-vectors: ""
[2019-08-06 17:44:55] [config] ulr-query-vectors: ""
[2019-08-06 17:44:55] [config] ulr-softmax-temperature: 1
[2019-08-06 17:44:55] [config] ulr-trainable-transformation: false
[2019-08-06 17:44:55] [config] valid-freq: 20000
[2019-08-06 17:44:55] [config] valid-log: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/valid.log
[2019-08-06 17:44:55] [config] valid-max-length: 1000
[2019-08-06 17:44:55] [config] valid-metrics:
[2019-08-06 17:44:55] [config]   - cross-entropy
[2019-08-06 17:44:55] [config]   - perplexity
[2019-08-06 17:44:55] [config]   - translation
[2019-08-06 17:44:55] [config] valid-mini-batch: 8
[2019-08-06 17:44:55] [config] valid-script-path: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/score-dev.sh
[2019-08-06 17:44:55] [config] valid-sets:
[2019-08-06 17:44:55] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/dev.bpe.de
[2019-08-06 17:44:55] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/dev.bpe.en
[2019-08-06 17:44:55] [config] valid-translation-output: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/dev.out
[2019-08-06 17:44:55] [config] vocabs:
[2019-08-06 17:44:55] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de.json
[2019-08-06 17:44:55] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en.json
[2019-08-06 17:44:55] [config] word-penalty: 0
[2019-08-06 17:44:55] [config] workspace: 3000
[2019-08-06 17:44:55] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-06 17:44:55] Using synchronous training
[2019-08-06 17:44:55] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de.json
[2019-08-06 17:44:56] [data] Using unused word id eos for 0
[2019-08-06 17:44:56] [data] Using unused word id UNK for 1
[2019-08-06 17:44:56] [data] Setting vocabulary size for input 0 to 50000
[2019-08-06 17:44:56] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en.json
[2019-08-06 17:44:56] [data] Using unused word id eos for 0
[2019-08-06 17:44:56] [data] Using unused word id UNK for 1
[2019-08-06 17:44:56] [data] Setting vocabulary size for input 1 to 50000
[2019-08-06 17:44:56] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-06 17:44:56] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-06 17:45:02] [memory] Extending reserved space to 3072 MB (device gpu0)
[2019-08-06 17:45:03] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-06 17:45:03] [comm] NCCLCommunicator constructed successfully.
[2019-08-06 17:45:03] [training] Using 1 GPUs
[2019-08-06 17:45:03] [memory] Reserving 422 MB, device gpu0
[2019-08-06 17:45:03] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-06 17:45:03] [memory] Reserving 422 MB, device gpu0
[2019-08-06 17:45:07] [batching] Done. Typical MB size is 4042 target words
[2019-08-06 17:45:08] [memory] Extending reserved space to 3072 MB (device gpu0)
[2019-08-06 17:45:08] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-06 17:45:08] [comm] NCCLCommunicator constructed successfully.
[2019-08-06 17:45:08] [training] Using 1 GPUs
[2019-08-06 17:45:08] Training started
[2019-08-06 17:45:08] [data] Shuffling data
[2019-08-06 17:45:12] [data] Done reading 5171769 sentences
[2019-08-06 17:45:47] [data] Done shuffling 5171769 sentences to temp files
[2019-08-06 17:45:54] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-06 17:45:54] [memory] Reserving 422 MB, device gpu0
[2019-08-06 17:45:55] [memory] Reserving 422 MB, device gpu0
[2019-08-06 17:45:55] [memory] Reserving 422 MB, device gpu0
[2019-08-06 17:45:55] [memory] Reserving 844 MB, device gpu0
[2019-08-06 17:55:09] Ep. 1 : Up. 2000 : Sen. 220,271 : Cost 137.76446533 : Time 612.55s : 7922.58 words/s
[2019-08-06 18:04:49] Ep. 1 : Up. 4000 : Sen. 441,026 : Cost 109.52619934 : Time 580.38s : 8367.79 words/s
[2019-08-06 18:14:42] Ep. 1 : Up. 6000 : Sen. 661,572 : Cost 94.99361420 : Time 593.31s : 8176.73 words/s
[2019-08-06 18:24:38] Ep. 1 : Up. 8000 : Sen. 883,108 : Cost 84.89438629 : Time 595.39s : 8178.30 words/s
[2019-08-06 18:34:25] Ep. 1 : Up. 10000 : Sen. 1,103,624 : Cost 78.06376648 : Time 587.16s : 8246.68 words/s
[2019-08-06 18:44:15] Ep. 1 : Up. 12000 : Sen. 1,323,625 : Cost 73.46514130 : Time 589.80s : 8221.43 words/s
[2019-08-06 18:54:09] Ep. 1 : Up. 14000 : Sen. 1,544,018 : Cost 70.14063263 : Time 594.33s : 8171.84 words/s
[2019-08-06 19:04:04] Ep. 1 : Up. 16000 : Sen. 1,764,615 : Cost 67.31591797 : Time 595.37s : 8159.61 words/s
[2019-08-06 19:14:04] Ep. 1 : Up. 18000 : Sen. 1,985,223 : Cost 65.26039124 : Time 599.11s : 8116.76 words/s
[2019-08-06 19:23:52] Ep. 1 : Up. 20000 : Sen. 2,205,091 : Cost 63.52455902 : Time 588.25s : 8238.60 words/s
[2019-08-06 19:23:52] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-06 19:24:05] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter20000.npz
[2019-08-06 19:24:15] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-06 19:24:28] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-06 19:25:01] [valid] Ep. 1 : Up. 20000 : cross-entropy : 69.0884 : new best
[2019-08-06 19:25:09] [valid] Ep. 1 : Up. 20000 : perplexity : 15.1107 : new best
[2019-08-06 19:26:30] [valid] Ep. 1 : Up. 20000 : translation : 16.32 : new best
[2019-08-06 19:36:22] Ep. 1 : Up. 22000 : Sen. 2,426,527 : Cost 61.81749725 : Time 749.84s : 6496.18 words/s
[2019-08-06 19:46:12] Ep. 1 : Up. 24000 : Sen. 2,646,428 : Cost 60.61356735 : Time 590.69s : 8200.07 words/s
[2019-08-06 19:56:03] Ep. 1 : Up. 26000 : Sen. 2,867,065 : Cost 59.40487289 : Time 591.11s : 8205.18 words/s
[2019-08-06 20:05:53] Ep. 1 : Up. 28000 : Sen. 3,087,070 : Cost 58.46337509 : Time 589.80s : 8204.14 words/s
[2019-08-06 20:15:47] Ep. 1 : Up. 30000 : Sen. 3,307,170 : Cost 57.44023132 : Time 593.76s : 8140.49 words/s
[2019-08-06 20:25:45] Ep. 1 : Up. 32000 : Sen. 3,528,608 : Cost 56.69012451 : Time 598.42s : 8133.18 words/s
[2019-08-06 20:35:40] Ep. 1 : Up. 34000 : Sen. 3,748,421 : Cost 56.03413773 : Time 594.88s : 8120.33 words/s
[2019-08-06 20:45:39] Ep. 1 : Up. 36000 : Sen. 3,969,905 : Cost 55.46601486 : Time 599.16s : 8125.90 words/s
[2019-08-06 20:55:37] Ep. 1 : Up. 38000 : Sen. 4,189,553 : Cost 54.97241211 : Time 597.78s : 8094.97 words/s
[2019-08-06 21:05:27] Ep. 1 : Up. 40000 : Sen. 4,410,793 : Cost 54.33181763 : Time 589.92s : 8240.80 words/s
[2019-08-06 21:05:27] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-06 21:05:41] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter40000.npz
[2019-08-06 21:05:50] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-06 21:06:01] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-06 21:06:33] [valid] Ep. 1 : Up. 40000 : cross-entropy : 56.5684 : new best
[2019-08-06 21:06:41] [valid] Ep. 1 : Up. 40000 : perplexity : 9.23799 : new best
[2019-08-06 21:08:03] [valid] Ep. 1 : Up. 40000 : translation : 21.21 : new best
[2019-08-06 21:08:38] Seen 4423484 samples
[2019-08-06 21:08:38] Starting epoch 2
[2019-08-06 21:08:38] [data] Shuffling data
[2019-08-06 21:08:53] [data] Done reading 5171769 sentences
[2019-08-06 21:09:26] [data] Done shuffling 5171769 sentences to temp files
[2019-08-06 21:18:27] Ep. 2 : Up. 42000 : Sen. 207,813 : Cost 52.92236328 : Time 779.94s : 6213.79 words/s
[2019-08-06 21:28:06] Ep. 2 : Up. 44000 : Sen. 427,560 : Cost 52.36396790 : Time 578.80s : 8356.28 words/s
[2019-08-06 21:37:46] Ep. 2 : Up. 46000 : Sen. 647,699 : Cost 52.19247818 : Time 579.62s : 8377.58 words/s
[2019-08-06 21:47:25] Ep. 2 : Up. 48000 : Sen. 868,704 : Cost 51.76683044 : Time 579.79s : 8372.10 words/s
[2019-08-06 21:57:06] Ep. 2 : Up. 50000 : Sen. 1,089,199 : Cost 51.21697617 : Time 580.61s : 8335.45 words/s
[2019-08-06 22:06:50] Ep. 2 : Up. 52000 : Sen. 1,309,430 : Cost 51.24593735 : Time 583.78s : 8321.43 words/s
[2019-08-06 22:16:34] Ep. 2 : Up. 54000 : Sen. 1,529,678 : Cost 51.01040268 : Time 584.60s : 8289.76 words/s
[2019-08-06 22:26:18] Ep. 2 : Up. 56000 : Sen. 1,750,222 : Cost 50.67446518 : Time 584.09s : 8320.76 words/s
[2019-08-06 22:36:04] Ep. 2 : Up. 58000 : Sen. 1,970,178 : Cost 50.50365829 : Time 585.55s : 8285.39 words/s
[2019-08-06 22:45:53] Ep. 2 : Up. 60000 : Sen. 2,192,474 : Cost 49.80665970 : Time 589.19s : 8276.96 words/s
[2019-08-06 22:45:53] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-06 22:46:07] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter60000.npz
[2019-08-06 22:46:17] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-06 22:46:30] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-06 22:47:02] [valid] Ep. 2 : Up. 60000 : cross-entropy : 51.3917 : new best
[2019-08-06 22:47:10] [valid] Ep. 2 : Up. 60000 : perplexity : 7.53731 : new best
[2019-08-06 22:48:28] [valid] Ep. 2 : Up. 60000 : translation : 24 : new best
[2019-08-06 22:58:13] Ep. 2 : Up. 62000 : Sen. 2,413,375 : Cost 50.05529785 : Time 739.90s : 6590.79 words/s
[2019-08-06 23:07:58] Ep. 2 : Up. 64000 : Sen. 2,633,831 : Cost 49.37023544 : Time 585.41s : 8272.70 words/s
[2019-08-06 23:17:44] Ep. 2 : Up. 66000 : Sen. 2,853,708 : Cost 49.49062347 : Time 585.95s : 8288.27 words/s
[2019-08-06 23:27:30] Ep. 2 : Up. 68000 : Sen. 3,074,744 : Cost 48.83174515 : Time 585.51s : 8306.30 words/s
[2019-08-06 23:37:12] Ep. 2 : Up. 70000 : Sen. 3,295,585 : Cost 48.64730453 : Time 581.94s : 8329.10 words/s
[2019-08-06 23:46:58] Ep. 2 : Up. 72000 : Sen. 3,515,506 : Cost 48.77630615 : Time 585.87s : 8250.40 words/s
[2019-08-06 23:56:46] Ep. 2 : Up. 74000 : Sen. 3,736,347 : Cost 48.64004898 : Time 588.07s : 8289.09 words/s
[2019-08-07 00:06:33] Ep. 2 : Up. 76000 : Sen. 3,957,488 : Cost 48.02976990 : Time 587.04s : 8276.08 words/s
[2019-08-07 00:16:20] Ep. 2 : Up. 78000 : Sen. 4,178,310 : Cost 48.18053818 : Time 586.88s : 8267.66 words/s
[2019-08-07 00:26:07] Ep. 2 : Up. 80000 : Sen. 4,399,203 : Cost 47.79886627 : Time 587.39s : 8263.60 words/s
[2019-08-07 00:26:07] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-07 00:26:20] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter80000.npz
[2019-08-07 00:26:30] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 00:26:44] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-07 00:27:18] [valid] Ep. 2 : Up. 80000 : cross-entropy : 48.3306 : new best
[2019-08-07 00:27:26] [valid] Ep. 2 : Up. 80000 : perplexity : 6.6829 : new best
[2019-08-07 00:28:49] [valid] Ep. 2 : Up. 80000 : translation : 25.21 : new best
[2019-08-07 00:29:53] Seen 4423484 samples
[2019-08-07 00:29:53] Starting epoch 3
[2019-08-07 00:29:53] [data] Shuffling data
[2019-08-07 00:30:08] [data] Done reading 5171769 sentences
[2019-08-07 00:30:45] [data] Done shuffling 5171769 sentences to temp files
[2019-08-07 00:39:21] Ep. 3 : Up. 82000 : Sen. 196,076 : Cost 46.66702652 : Time 793.83s : 6108.74 words/s
[2019-08-07 00:49:05] Ep. 3 : Up. 84000 : Sen. 415,726 : Cost 46.62441254 : Time 583.61s : 8283.45 words/s
[2019-08-07 00:58:46] Ep. 3 : Up. 86000 : Sen. 636,097 : Cost 46.46555710 : Time 581.53s : 8326.47 words/s
[2019-08-07 01:08:31] Ep. 3 : Up. 88000 : Sen. 855,782 : Cost 46.57354736 : Time 584.84s : 8272.69 words/s
[2019-08-07 01:18:17] Ep. 3 : Up. 90000 : Sen. 1,075,753 : Cost 46.44598007 : Time 585.68s : 8284.27 words/s
[2019-08-07 01:28:06] Ep. 3 : Up. 92000 : Sen. 1,297,249 : Cost 46.24480438 : Time 589.25s : 8286.35 words/s
[2019-08-07 01:37:52] Ep. 3 : Up. 94000 : Sen. 1,518,254 : Cost 45.84471893 : Time 585.86s : 8279.83 words/s
[2019-08-07 01:47:39] Ep. 3 : Up. 96000 : Sen. 1,738,023 : Cost 46.01253128 : Time 586.98s : 8239.44 words/s
[2019-08-07 01:57:30] Ep. 3 : Up. 98000 : Sen. 1,959,210 : Cost 45.96427155 : Time 590.89s : 8246.16 words/s
[2019-08-07 02:07:16] Ep. 3 : Up. 100000 : Sen. 2,180,302 : Cost 45.66551971 : Time 586.71s : 8275.56 words/s
[2019-08-07 02:07:16] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-07 02:07:30] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter100000.npz
[2019-08-07 02:07:40] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 02:07:54] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-07 02:08:27] [valid] Ep. 3 : Up. 100000 : cross-entropy : 46.5238 : new best
[2019-08-07 02:08:35] [valid] Ep. 3 : Up. 100000 : perplexity : 6.2248 : new best
[2019-08-07 02:09:57] [valid] Ep. 3 : Up. 100000 : translation : 25.93 : new best
[2019-08-07 02:19:39] Ep. 3 : Up. 102000 : Sen. 2,400,816 : Cost 45.98583221 : Time 742.89s : 6538.47 words/s
[2019-08-07 02:29:23] Ep. 3 : Up. 104000 : Sen. 2,622,135 : Cost 45.32702637 : Time 584.28s : 8324.06 words/s
[2019-08-07 02:39:07] Ep. 3 : Up. 106000 : Sen. 2,842,415 : Cost 45.64377975 : Time 583.25s : 8327.11 words/s
[2019-08-07 02:48:49] Ep. 3 : Up. 108000 : Sen. 3,063,688 : Cost 45.37416077 : Time 582.70s : 8350.90 words/s
[2019-08-07 02:58:30] Ep. 3 : Up. 110000 : Sen. 3,283,884 : Cost 45.13617325 : Time 581.02s : 8344.84 words/s
[2019-08-07 03:08:10] Ep. 3 : Up. 112000 : Sen. 3,504,098 : Cost 44.97329712 : Time 579.43s : 8337.41 words/s
[2019-08-07 03:17:52] Ep. 3 : Up. 114000 : Sen. 3,724,048 : Cost 45.17445374 : Time 582.44s : 8322.85 words/s
[2019-08-07 03:27:32] Ep. 3 : Up. 116000 : Sen. 3,944,563 : Cost 44.96041107 : Time 579.94s : 8363.54 words/s
[2019-08-07 03:37:11] Ep. 3 : Up. 118000 : Sen. 4,165,740 : Cost 44.63404846 : Time 578.54s : 8383.65 words/s
[2019-08-07 03:46:53] Ep. 3 : Up. 120000 : Sen. 4,386,150 : Cost 45.00309372 : Time 582.59s : 8352.88 words/s
[2019-08-07 03:46:53] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-07 03:47:06] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter120000.npz
[2019-08-07 03:47:16] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 03:47:29] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-07 03:48:03] [valid] Ep. 3 : Up. 120000 : cross-entropy : 45.0288 : new best
[2019-08-07 03:48:11] [valid] Ep. 3 : Up. 120000 : perplexity : 5.86957 : new best
[2019-08-07 03:49:27] [valid] Ep. 3 : Up. 120000 : translation : 26.61 : new best
[2019-08-07 03:51:04] Seen 4423484 samples
[2019-08-07 03:51:04] Starting epoch 4
[2019-08-07 03:51:04] [data] Shuffling data
[2019-08-07 03:51:18] [data] Done reading 5171769 sentences
[2019-08-07 03:51:54] [data] Done shuffling 5171769 sentences to temp files
[2019-08-07 03:59:49] Ep. 4 : Up. 122000 : Sen. 183,936 : Cost 43.78788757 : Time 776.03s : 6275.86 words/s
[2019-08-07 04:09:29] Ep. 4 : Up. 124000 : Sen. 406,002 : Cost 43.38663101 : Time 579.86s : 8418.94 words/s
[2019-08-07 04:19:08] Ep. 4 : Up. 126000 : Sen. 626,349 : Cost 43.83247757 : Time 578.90s : 8390.82 words/s
[2019-08-07 04:28:45] Ep. 4 : Up. 128000 : Sen. 846,973 : Cost 43.70221329 : Time 576.51s : 8425.10 words/s
[2019-08-07 04:38:20] Ep. 4 : Up. 130000 : Sen. 1,067,136 : Cost 43.67787933 : Time 574.95s : 8433.94 words/s
[2019-08-07 04:47:55] Ep. 4 : Up. 132000 : Sen. 1,287,691 : Cost 43.38280106 : Time 575.06s : 8433.49 words/s
[2019-08-07 04:57:27] Ep. 4 : Up. 134000 : Sen. 1,507,988 : Cost 43.47028732 : Time 572.62s : 8468.78 words/s
[2019-08-07 05:06:59] Ep. 4 : Up. 136000 : Sen. 1,727,208 : Cost 43.85335922 : Time 571.64s : 8458.05 words/s
[2019-08-07 05:16:32] Ep. 4 : Up. 138000 : Sen. 1,947,676 : Cost 43.47458267 : Time 573.40s : 8478.48 words/s
[2019-08-07 05:26:08] Ep. 4 : Up. 140000 : Sen. 2,169,366 : Cost 43.32634735 : Time 575.55s : 8459.39 words/s
[2019-08-07 05:26:08] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-07 05:26:21] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter140000.npz
[2019-08-07 05:26:32] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 05:26:46] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-07 05:27:18] [valid] Ep. 4 : Up. 140000 : cross-entropy : 44.0856 : new best
[2019-08-07 05:27:26] [valid] Ep. 4 : Up. 140000 : perplexity : 5.65596 : new best
[2019-08-07 05:28:41] [valid] Ep. 4 : Up. 140000 : translation : 27.13 : new best
[2019-08-07 05:38:11] Ep. 4 : Up. 142000 : Sen. 2,390,260 : Cost 43.49135971 : Time 723.59s : 6719.74 words/s
[2019-08-07 05:47:44] Ep. 4 : Up. 144000 : Sen. 2,611,011 : Cost 43.40800858 : Time 572.09s : 8479.76 words/s
[2019-08-07 05:57:14] Ep. 4 : Up. 146000 : Sen. 2,831,842 : Cost 43.14625168 : Time 570.34s : 8494.64 words/s
[2019-08-07 06:06:46] Ep. 4 : Up. 148000 : Sen. 3,052,722 : Cost 43.20722580 : Time 572.58s : 8496.27 words/s
[2019-08-07 06:16:21] Ep. 4 : Up. 150000 : Sen. 3,274,539 : Cost 43.16016006 : Time 574.36s : 8495.63 words/s
[2019-08-07 06:25:51] Ep. 4 : Up. 152000 : Sen. 3,494,400 : Cost 43.21568680 : Time 570.34s : 8487.02 words/s
[2019-08-07 06:35:21] Ep. 4 : Up. 154000 : Sen. 3,714,451 : Cost 43.28927994 : Time 570.15s : 8490.22 words/s
[2019-08-07 06:44:55] Ep. 4 : Up. 156000 : Sen. 3,935,718 : Cost 43.01747513 : Time 573.74s : 8485.93 words/s
[2019-08-07 06:54:25] Ep. 4 : Up. 158000 : Sen. 4,156,378 : Cost 43.07338333 : Time 570.02s : 8492.62 words/s
[2019-08-07 07:04:01] Ep. 4 : Up. 160000 : Sen. 4,378,080 : Cost 42.86511993 : Time 575.46s : 8482.47 words/s
[2019-08-07 07:04:01] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-07 07:04:10] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter160000.npz
[2019-08-07 07:04:17] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 07:04:27] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-07 07:04:53] [valid] Ep. 4 : Up. 160000 : cross-entropy : 43.2717 : new best
[2019-08-07 07:05:00] [valid] Ep. 4 : Up. 160000 : perplexity : 5.47789 : new best
[2019-08-07 07:06:18] [valid] Ep. 4 : Up. 160000 : translation : 27.41 : new best
[2019-08-07 07:08:15] Seen 4423484 samples
[2019-08-07 07:08:15] Starting epoch 5
[2019-08-07 07:08:15] [data] Shuffling data
[2019-08-07 07:08:46] [data] Done reading 5171769 sentences
[2019-08-07 07:09:12] [data] Done shuffling 5171769 sentences to temp files
[2019-08-07 07:16:44] Ep. 5 : Up. 162000 : Sen. 174,947 : Cost 42.17552948 : Time 763.75s : 6353.81 words/s
[2019-08-07 07:26:15] Ep. 5 : Up. 164000 : Sen. 395,223 : Cost 41.75116348 : Time 570.95s : 8494.70 words/s
[2019-08-07 07:35:45] Ep. 5 : Up. 166000 : Sen. 615,338 : Cost 41.66501999 : Time 569.77s : 8488.83 words/s
[2019-08-07 07:45:14] Ep. 5 : Up. 168000 : Sen. 836,387 : Cost 41.85647583 : Time 568.53s : 8553.69 words/s
[2019-08-07 07:54:41] Ep. 5 : Up. 170000 : Sen. 1,056,543 : Cost 42.01766586 : Time 567.50s : 8540.52 words/s
[2019-08-07 08:04:08] Ep. 5 : Up. 172000 : Sen. 1,276,855 : Cost 41.75703812 : Time 566.97s : 8532.04 words/s
[2019-08-07 08:13:37] Ep. 5 : Up. 174000 : Sen. 1,497,028 : Cost 42.00217438 : Time 569.37s : 8517.97 words/s
[2019-08-07 08:23:08] Ep. 5 : Up. 176000 : Sen. 1,717,194 : Cost 41.82738495 : Time 570.75s : 8475.68 words/s
[2019-08-07 08:32:38] Ep. 5 : Up. 178000 : Sen. 1,936,675 : Cost 42.10128784 : Time 569.69s : 8483.27 words/s
[2019-08-07 08:42:09] Ep. 5 : Up. 180000 : Sen. 2,157,889 : Cost 41.88175201 : Time 570.90s : 8510.71 words/s
[2019-08-07 08:42:09] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-07 08:42:22] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter180000.npz
[2019-08-07 08:42:32] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 08:42:45] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-07 08:43:16] [valid] Ep. 5 : Up. 180000 : cross-entropy : 42.7477 : new best
[2019-08-07 08:43:24] [valid] Ep. 5 : Up. 180000 : perplexity : 5.36623 : new best
[2019-08-07 08:44:39] [valid] Ep. 5 : Up. 180000 : translation : 27.49 : new best
[2019-08-07 08:54:03] Ep. 5 : Up. 182000 : Sen. 2,379,087 : Cost 41.78371811 : Time 714.54s : 6795.13 words/s
[2019-08-07 09:03:33] Ep. 5 : Up. 184000 : Sen. 2,599,132 : Cost 41.97344971 : Time 570.08s : 8520.08 words/s
[2019-08-07 09:13:09] Ep. 5 : Up. 186000 : Sen. 2,820,122 : Cost 41.86732483 : Time 576.00s : 8438.73 words/s
[2019-08-07 09:22:53] Ep. 5 : Up. 188000 : Sen. 3,041,670 : Cost 41.77406311 : Time 584.02s : 8349.22 words/s
[2019-08-07 09:32:39] Ep. 5 : Up. 190000 : Sen. 3,262,530 : Cost 41.80754471 : Time 585.76s : 8288.07 words/s
[2019-08-07 09:42:24] Ep. 5 : Up. 192000 : Sen. 3,481,993 : Cost 42.07696915 : Time 584.50s : 8274.53 words/s
[2019-08-07 09:52:15] Ep. 5 : Up. 194000 : Sen. 3,703,177 : Cost 41.86753845 : Time 591.00s : 8244.62 words/s
[2019-08-07 10:02:06] Ep. 5 : Up. 196000 : Sen. 3,922,931 : Cost 41.80311966 : Time 591.43s : 8182.15 words/s
[2019-08-07 10:12:07] Ep. 5 : Up. 198000 : Sen. 4,144,244 : Cost 41.83488083 : Time 600.95s : 8117.26 words/s
[2019-08-07 10:22:15] Ep. 5 : Up. 200000 : Sen. 4,365,005 : Cost 41.49062729 : Time 607.71s : 7977.56 words/s
[2019-08-07 10:22:15] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-07 10:22:27] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter200000.npz
[2019-08-07 10:22:39] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 10:22:53] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-07 10:23:24] [valid] Ep. 5 : Up. 200000 : cross-entropy : 42.1568 : new best
[2019-08-07 10:23:32] [valid] Ep. 5 : Up. 200000 : perplexity : 5.24304 : new best
[2019-08-07 10:24:49] [valid] Ep. 5 : Up. 200000 : translation : 27.7 : new best
[2019-08-07 10:27:28] Seen 4423484 samples
[2019-08-07 10:27:28] Starting epoch 6
[2019-08-07 10:27:28] [data] Shuffling data
[2019-08-07 10:27:43] [data] Done reading 5171769 sentences
[2019-08-07 10:28:12] [data] Done shuffling 5171769 sentences to temp files
[2019-08-07 10:35:47] Ep. 6 : Up. 202000 : Sen. 161,614 : Cost 40.86782837 : Time 812.67s : 5960.93 words/s
[2019-08-07 10:46:18] Ep. 6 : Up. 204000 : Sen. 383,153 : Cost 40.84260178 : Time 630.98s : 7725.59 words/s
[2019-08-07 10:56:38] Ep. 6 : Up. 206000 : Sen. 603,191 : Cost 40.89533234 : Time 619.75s : 7826.67 words/s
[2019-08-07 11:07:01] Ep. 6 : Up. 208000 : Sen. 823,292 : Cost 40.74270630 : Time 623.29s : 7775.00 words/s
[2019-08-07 11:17:26] Ep. 6 : Up. 210000 : Sen. 1,043,563 : Cost 40.71134567 : Time 624.61s : 7755.33 words/s
[2019-08-07 11:27:55] Ep. 6 : Up. 212000 : Sen. 1,264,395 : Cost 40.75851822 : Time 629.24s : 7728.06 words/s
[2019-08-07 11:38:36] Ep. 6 : Up. 214000 : Sen. 1,485,185 : Cost 40.95918274 : Time 640.34s : 7594.89 words/s
[2019-08-07 11:49:07] Ep. 6 : Up. 216000 : Sen. 1,706,256 : Cost 40.75728989 : Time 631.76s : 7703.89 words/s
[2019-08-07 11:59:21] Ep. 6 : Up. 218000 : Sen. 1,926,478 : Cost 40.97517776 : Time 613.59s : 7907.77 words/s
[2019-08-07 15:19:30] Ep. 6 : Up. 220000 : Sen. 2,146,916 : Cost 40.83630371 : Time 12008.66s : 403.63 words/s
[2019-08-07 15:19:30] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-07 15:19:40] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.iter220000.npz
[2019-08-07 15:19:47] Saving model to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 15:19:56] Saving Adam parameters to ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-07 15:20:22] [valid] Ep. 6 : Up. 220000 : cross-entropy : 41.8868 : new best
[2019-08-07 15:20:30] [valid] Ep. 6 : Up. 220000 : perplexity : 5.18769 : new best
[2019-08-07 15:21:39] [valid] Ep. 6 : Up. 220000 : translation : 27.7 : stalled 1 times (last best: 27.7)
[2019-08-07 15:30:33] Ep. 6 : Up. 222000 : Sen. 2,366,975 : Cost 40.84515381 : Time 663.46s : 7306.29 words/s
[2019-08-07 15:39:34] Ep. 6 : Up. 224000 : Sen. 2,587,925 : Cost 40.73976517 : Time 540.33s : 8987.91 words/s
[2019-08-07 15:45:16] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 15:45:16] [marian] Running on fulla as process 5580 with command line:
[2019-08-07 15:45:16] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz -T . --devices 1 --train-sets ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en --vocabs ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de.json ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/dev.bpe.de ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/dev.out --valid-script-path ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/train.log --valid-log ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/valid.log
[2019-08-07 15:45:16] [config] after-batches: 0
[2019-08-07 15:45:16] [config] after-epochs: 0
[2019-08-07 15:45:16] [config] allow-unk: false
[2019-08-07 15:45:16] [config] beam-size: 12
[2019-08-07 15:45:16] [config] bert-class-symbol: "[CLS]"
[2019-08-07 15:45:16] [config] bert-mask-symbol: "[MASK]"
[2019-08-07 15:45:16] [config] bert-masking-fraction: 0.15
[2019-08-07 15:45:16] [config] bert-sep-symbol: "[SEP]"
[2019-08-07 15:45:16] [config] bert-train-type-embeddings: true
[2019-08-07 15:45:16] [config] bert-type-vocab-size: 2
[2019-08-07 15:45:16] [config] best-deep: false
[2019-08-07 15:45:16] [config] clip-gemm: 0
[2019-08-07 15:45:16] [config] clip-norm: 1
[2019-08-07 15:45:16] [config] cost-type: ce-mean
[2019-08-07 15:45:16] [config] cpu-threads: 0
[2019-08-07 15:45:16] [config] data-weighting: ""
[2019-08-07 15:45:16] [config] data-weighting-type: sentence
[2019-08-07 15:45:16] [config] dec-cell: gru
[2019-08-07 15:45:16] [config] dec-cell-base-depth: 2
[2019-08-07 15:45:16] [config] dec-cell-high-depth: 1
[2019-08-07 15:45:16] [config] dec-depth: 1
[2019-08-07 15:45:16] [config] devices:
[2019-08-07 15:45:16] [config]   - 1
[2019-08-07 15:45:16] [config] dim-emb: 512
[2019-08-07 15:45:16] [config] dim-rnn: 1024
[2019-08-07 15:45:16] [config] dim-vocabs:
[2019-08-07 15:45:16] [config]   - 50000
[2019-08-07 15:45:16] [config]   - 50000
[2019-08-07 15:45:16] [config] disp-first: 0
[2019-08-07 15:45:16] [config] disp-freq: 2000
[2019-08-07 15:45:16] [config] disp-label-counts: false
[2019-08-07 15:45:16] [config] dropout-rnn: 0.2
[2019-08-07 15:45:16] [config] dropout-src: 0.1
[2019-08-07 15:45:16] [config] dropout-trg: 0.1
[2019-08-07 15:45:16] [config] dump-config: ""
[2019-08-07 15:45:16] [config] early-stopping: 5
[2019-08-07 15:45:16] [config] embedding-fix-src: false
[2019-08-07 15:45:16] [config] embedding-fix-trg: false
[2019-08-07 15:45:16] [config] embedding-normalization: false
[2019-08-07 15:45:16] [config] embedding-vectors:
[2019-08-07 15:45:16] [config]   []
[2019-08-07 15:45:16] [config] enc-cell: gru
[2019-08-07 15:45:16] [config] enc-cell-depth: 1
[2019-08-07 15:45:16] [config] enc-depth: 1
[2019-08-07 15:45:16] [config] enc-type: bidirectional
[2019-08-07 15:45:16] [config] exponential-smoothing: 0.0001
[2019-08-07 15:45:16] [config] grad-dropping-momentum: 0
[2019-08-07 15:45:16] [config] grad-dropping-rate: 0
[2019-08-07 15:45:16] [config] grad-dropping-warmup: 100
[2019-08-07 15:45:16] [config] guided-alignment: none
[2019-08-07 15:45:16] [config] guided-alignment-cost: mse
[2019-08-07 15:45:16] [config] guided-alignment-weight: 0.1
[2019-08-07 15:45:16] [config] ignore-model-config: false
[2019-08-07 15:45:16] [config] input-types:
[2019-08-07 15:45:16] [config]   []
[2019-08-07 15:45:16] [config] interpolate-env-vars: false
[2019-08-07 15:45:16] [config] keep-best: false
[2019-08-07 15:45:16] [config] label-smoothing: 0
[2019-08-07 15:45:16] [config] layer-normalization: true
[2019-08-07 15:45:16] [config] learn-rate: 0.0001
[2019-08-07 15:45:16] [config] log: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/train.log
[2019-08-07 15:45:16] [config] log-level: info
[2019-08-07 15:45:16] [config] log-time-zone: ""
[2019-08-07 15:45:16] [config] lr-decay: 0
[2019-08-07 15:45:16] [config] lr-decay-freq: 50000
[2019-08-07 15:45:16] [config] lr-decay-inv-sqrt:
[2019-08-07 15:45:16] [config]   - 0
[2019-08-07 15:45:16] [config] lr-decay-repeat-warmup: false
[2019-08-07 15:45:16] [config] lr-decay-reset-optimizer: false
[2019-08-07 15:45:16] [config] lr-decay-start:
[2019-08-07 15:45:16] [config]   - 10
[2019-08-07 15:45:16] [config]   - 1
[2019-08-07 15:45:16] [config] lr-decay-strategy: epoch+stalled
[2019-08-07 15:45:16] [config] lr-report: false
[2019-08-07 15:45:16] [config] lr-warmup: 0
[2019-08-07 15:45:16] [config] lr-warmup-at-reload: false
[2019-08-07 15:45:16] [config] lr-warmup-cycle: false
[2019-08-07 15:45:16] [config] lr-warmup-start-rate: 0
[2019-08-07 15:45:16] [config] max-length: 50
[2019-08-07 15:45:16] [config] max-length-crop: false
[2019-08-07 15:45:16] [config] max-length-factor: 3
[2019-08-07 15:45:16] [config] maxi-batch: 100
[2019-08-07 15:45:16] [config] maxi-batch-sort: trg
[2019-08-07 15:45:16] [config] mini-batch: 64
[2019-08-07 15:45:16] [config] mini-batch-fit: true
[2019-08-07 15:45:16] [config] mini-batch-fit-step: 10
[2019-08-07 15:45:16] [config] mini-batch-overstuff: 1
[2019-08-07 15:45:16] [config] mini-batch-track-lr: false
[2019-08-07 15:45:16] [config] mini-batch-understuff: 1
[2019-08-07 15:45:16] [config] mini-batch-warmup: 0
[2019-08-07 15:45:16] [config] mini-batch-words: 0
[2019-08-07 15:45:16] [config] mini-batch-words-ref: 0
[2019-08-07 15:45:16] [config] model: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 15:45:16] [config] multi-loss-type: sum
[2019-08-07 15:45:16] [config] multi-node: false
[2019-08-07 15:45:16] [config] multi-node-overlap: true
[2019-08-07 15:45:16] [config] n-best: false
[2019-08-07 15:45:16] [config] no-nccl: false
[2019-08-07 15:45:16] [config] no-reload: false
[2019-08-07 15:45:16] [config] no-restore-corpus: false
[2019-08-07 15:45:16] [config] no-shuffle: false
[2019-08-07 15:45:16] [config] normalize: 1
[2019-08-07 15:45:16] [config] num-devices: 0
[2019-08-07 15:45:16] [config] optimizer: adam
[2019-08-07 15:45:16] [config] optimizer-delay: 1
[2019-08-07 15:45:16] [config] optimizer-params:
[2019-08-07 15:45:16] [config]   []
[2019-08-07 15:45:16] [config] overwrite: false
[2019-08-07 15:45:16] [config] pretrained-model: ""
[2019-08-07 15:45:16] [config] quiet: false
[2019-08-07 15:45:16] [config] quiet-translation: true
[2019-08-07 15:45:16] [config] relative-paths: false
[2019-08-07 15:45:16] [config] right-left: false
[2019-08-07 15:45:16] [config] save-freq: 20000
[2019-08-07 15:45:16] [config] seed: 1111
[2019-08-07 15:45:16] [config] shuffle-in-ram: false
[2019-08-07 15:45:16] [config] skip: false
[2019-08-07 15:45:16] [config] sqlite: ""
[2019-08-07 15:45:16] [config] sqlite-drop: false
[2019-08-07 15:45:16] [config] sync-sgd: true
[2019-08-07 15:45:16] [config] tempdir: .
[2019-08-07 15:45:16] [config] tied-embeddings: false
[2019-08-07 15:45:16] [config] tied-embeddings-all: false
[2019-08-07 15:45:16] [config] tied-embeddings-src: false
[2019-08-07 15:45:16] [config] train-sets:
[2019-08-07 15:45:16] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de
[2019-08-07 15:45:16] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en
[2019-08-07 15:45:16] [config] transformer-aan-activation: swish
[2019-08-07 15:45:16] [config] transformer-aan-depth: 2
[2019-08-07 15:45:16] [config] transformer-aan-nogate: false
[2019-08-07 15:45:16] [config] transformer-decoder-autoreg: self-attention
[2019-08-07 15:45:16] [config] transformer-dim-aan: 2048
[2019-08-07 15:45:16] [config] transformer-dim-ffn: 2048
[2019-08-07 15:45:16] [config] transformer-dropout: 0
[2019-08-07 15:45:16] [config] transformer-dropout-attention: 0
[2019-08-07 15:45:16] [config] transformer-dropout-ffn: 0
[2019-08-07 15:45:16] [config] transformer-ffn-activation: swish
[2019-08-07 15:45:16] [config] transformer-ffn-depth: 2
[2019-08-07 15:45:16] [config] transformer-guided-alignment-layer: last
[2019-08-07 15:45:16] [config] transformer-heads: 8
[2019-08-07 15:45:16] [config] transformer-no-projection: false
[2019-08-07 15:45:16] [config] transformer-postprocess: dan
[2019-08-07 15:45:16] [config] transformer-postprocess-emb: d
[2019-08-07 15:45:16] [config] transformer-preprocess: ""
[2019-08-07 15:45:16] [config] transformer-tied-layers:
[2019-08-07 15:45:16] [config]   []
[2019-08-07 15:45:16] [config] transformer-train-position-embeddings: false
[2019-08-07 15:45:16] [config] type: amun
[2019-08-07 15:45:16] [config] ulr: false
[2019-08-07 15:45:16] [config] ulr-dim-emb: 0
[2019-08-07 15:45:16] [config] ulr-dropout: 0
[2019-08-07 15:45:16] [config] ulr-keys-vectors: ""
[2019-08-07 15:45:16] [config] ulr-query-vectors: ""
[2019-08-07 15:45:16] [config] ulr-softmax-temperature: 1
[2019-08-07 15:45:16] [config] ulr-trainable-transformation: false
[2019-08-07 15:45:16] [config] valid-freq: 20000
[2019-08-07 15:45:16] [config] valid-log: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/valid.log
[2019-08-07 15:45:16] [config] valid-max-length: 1000
[2019-08-07 15:45:16] [config] valid-metrics:
[2019-08-07 15:45:16] [config]   - cross-entropy
[2019-08-07 15:45:16] [config]   - perplexity
[2019-08-07 15:45:16] [config]   - translation
[2019-08-07 15:45:16] [config] valid-mini-batch: 8
[2019-08-07 15:45:16] [config] valid-script-path: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/score-dev.sh
[2019-08-07 15:45:16] [config] valid-sets:
[2019-08-07 15:45:16] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/dev.bpe.de
[2019-08-07 15:45:16] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/dev.bpe.en
[2019-08-07 15:45:16] [config] valid-translation-output: ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/dev.out
[2019-08-07 15:45:16] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 15:45:16] [config] vocabs:
[2019-08-07 15:45:16] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de.json
[2019-08-07 15:45:16] [config]   - ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en.json
[2019-08-07 15:45:16] [config] word-penalty: 0
[2019-08-07 15:45:16] [config] workspace: 3000
[2019-08-07 15:45:16] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 15:45:16] Using synchronous training
[2019-08-07 15:45:16] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.de.json
[2019-08-07 15:45:16] [data] Using unused word id eos for 0
[2019-08-07 15:45:16] [data] Using unused word id UNK for 1
[2019-08-07 15:45:16] [data] Setting vocabulary size for input 0 to 50000
[2019-08-07 15:45:16] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/train.bpe.en.json
[2019-08-07 15:45:17] [data] Using unused word id eos for 0
[2019-08-07 15:45:17] [data] Using unused word id UNK for 1
[2019-08-07 15:45:17] [data] Setting vocabulary size for input 1 to 50000
[2019-08-07 15:45:17] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-07 15:45:17] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-07 15:45:18] [memory] Extending reserved space to 3072 MB (device gpu1)
[2019-08-07 15:45:18] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 15:45:18] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 15:45:18] [training] Using 1 GPUs
[2019-08-07 15:45:18] [memory] Reserving 422 MB, device gpu1
[2019-08-07 15:45:18] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-07 15:45:18] [memory] Reserving 422 MB, device gpu1
[2019-08-07 15:45:21] [batching] Done. Typical MB size is 4042 target words
[2019-08-07 15:45:21] [memory] Extending reserved space to 3072 MB (device gpu1)
[2019-08-07 15:45:21] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 15:45:21] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 15:45:21] [training] Using 1 GPUs
[2019-08-07 15:45:21] Loading model from ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.orig.npz
[2019-08-07 15:45:27] Loading Adam parameters from ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz.optimizer.npz
[2019-08-07 15:45:38] [memory] Reserving 844 MB, device gpu1
[2019-08-07 15:45:39] [training] Model reloaded from ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 15:45:39] [data] Restoring the corpus state to epoch 6, batch 220000
[2019-08-07 15:45:39] [data] Shuffling data
[2019-08-07 15:45:53] [data] Done reading 5171769 sentences
[2019-08-07 15:46:11] [data] Done shuffling 5171769 sentences to temp files
[2019-08-07 15:47:31] Training started
[2019-08-07 15:47:31] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-07 15:47:31] [memory] Reserving 422 MB, device gpu1
[2019-08-07 15:47:31] [memory] Reserving 422 MB, device gpu1
[2019-08-07 15:47:31] Loading model from ../experiments/100M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/model/model.npz
[2019-08-07 15:47:38] [memory] Reserving 422 MB, device cpu0
[2019-08-07 15:47:38] [memory] Reserving 422 MB, device gpu1
[2019-08-07 15:52:59] Ep. 6 : Up. 222000 : Sen. 2,366,975 : Cost 41.08972168 : Time 462.62s : 10478.32 words/s
[2019-08-07 15:58:20] Ep. 6 : Up. 224000 : Sen. 2,587,925 : Cost 40.76732254 : Time 320.36s : 15159.28 words/s
