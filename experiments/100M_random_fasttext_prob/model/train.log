[2019-08-07 11:18:20] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 11:18:20] [marian] Running on bil as process 252575 with command line:
[2019-08-07 11:18:20] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_random_fasttext_prob/model/model.npz -T . --devices 6 --train-sets ../experiments/100M_random_fasttext_prob/data/train.bpe.de ../experiments/100M_random_fasttext_prob/data/train.bpe.en --vocabs ../experiments/100M_random_fasttext_prob/data/train.bpe.de.json ../experiments/100M_random_fasttext_prob/data/train.bpe.en.json --mini-batch-fit -w 5000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_random_fasttext_prob/data/dev.bpe.de ../experiments/100M_random_fasttext_prob/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_random_fasttext_prob/model/dev.out --valid-script-path ../experiments/100M_random_fasttext_prob/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_random_fasttext_prob/model/train.log --valid-log ../experiments/100M_random_fasttext_prob/model/valid.log
[2019-08-07 11:18:20] [config] after-batches: 0
[2019-08-07 11:18:20] [config] after-epochs: 0
[2019-08-07 11:18:20] [config] allow-unk: false
[2019-08-07 11:18:20] [config] beam-size: 12
[2019-08-07 11:18:20] [config] bert-class-symbol: "[CLS]"
[2019-08-07 11:18:20] [config] bert-mask-symbol: "[MASK]"
[2019-08-07 11:18:20] [config] bert-masking-fraction: 0.15
[2019-08-07 11:18:20] [config] bert-sep-symbol: "[SEP]"
[2019-08-07 11:18:20] [config] bert-train-type-embeddings: true
[2019-08-07 11:18:20] [config] bert-type-vocab-size: 2
[2019-08-07 11:18:20] [config] best-deep: false
[2019-08-07 11:18:20] [config] clip-gemm: 0
[2019-08-07 11:18:20] [config] clip-norm: 1
[2019-08-07 11:18:20] [config] cost-type: ce-mean
[2019-08-07 11:18:20] [config] cpu-threads: 0
[2019-08-07 11:18:20] [config] data-weighting: ""
[2019-08-07 11:18:20] [config] data-weighting-type: sentence
[2019-08-07 11:18:20] [config] dec-cell: gru
[2019-08-07 11:18:20] [config] dec-cell-base-depth: 2
[2019-08-07 11:18:20] [config] dec-cell-high-depth: 1
[2019-08-07 11:18:20] [config] dec-depth: 1
[2019-08-07 11:18:20] [config] devices:
[2019-08-07 11:18:20] [config]   - 6
[2019-08-07 11:18:20] [config] dim-emb: 512
[2019-08-07 11:18:20] [config] dim-rnn: 1024
[2019-08-07 11:18:20] [config] dim-vocabs:
[2019-08-07 11:18:20] [config]   - 50000
[2019-08-07 11:18:20] [config]   - 50000
[2019-08-07 11:18:20] [config] disp-first: 0
[2019-08-07 11:18:20] [config] disp-freq: 2000
[2019-08-07 11:18:20] [config] disp-label-counts: false
[2019-08-07 11:18:20] [config] dropout-rnn: 0.2
[2019-08-07 11:18:20] [config] dropout-src: 0.1
[2019-08-07 11:18:20] [config] dropout-trg: 0.1
[2019-08-07 11:18:20] [config] dump-config: ""
[2019-08-07 11:18:20] [config] early-stopping: 5
[2019-08-07 11:18:20] [config] embedding-fix-src: false
[2019-08-07 11:18:20] [config] embedding-fix-trg: false
[2019-08-07 11:18:20] [config] embedding-normalization: false
[2019-08-07 11:18:20] [config] embedding-vectors:
[2019-08-07 11:18:20] [config]   []
[2019-08-07 11:18:20] [config] enc-cell: gru
[2019-08-07 11:18:20] [config] enc-cell-depth: 1
[2019-08-07 11:18:20] [config] enc-depth: 1
[2019-08-07 11:18:20] [config] enc-type: bidirectional
[2019-08-07 11:18:20] [config] exponential-smoothing: 0.0001
[2019-08-07 11:18:20] [config] grad-dropping-momentum: 0
[2019-08-07 11:18:20] [config] grad-dropping-rate: 0
[2019-08-07 11:18:20] [config] grad-dropping-warmup: 100
[2019-08-07 11:18:20] [config] guided-alignment: none
[2019-08-07 11:18:20] [config] guided-alignment-cost: mse
[2019-08-07 11:18:20] [config] guided-alignment-weight: 0.1
[2019-08-07 11:18:20] [config] ignore-model-config: false
[2019-08-07 11:18:20] [config] input-types:
[2019-08-07 11:18:20] [config]   []
[2019-08-07 11:18:20] [config] interpolate-env-vars: false
[2019-08-07 11:18:20] [config] keep-best: false
[2019-08-07 11:18:20] [config] label-smoothing: 0
[2019-08-07 11:18:20] [config] layer-normalization: true
[2019-08-07 11:18:20] [config] learn-rate: 0.0001
[2019-08-07 11:18:20] [config] log: ../experiments/100M_random_fasttext_prob/model/train.log
[2019-08-07 11:18:20] [config] log-level: info
[2019-08-07 11:18:20] [config] log-time-zone: ""
[2019-08-07 11:18:20] [config] lr-decay: 0
[2019-08-07 11:18:20] [config] lr-decay-freq: 50000
[2019-08-07 11:18:20] [config] lr-decay-inv-sqrt:
[2019-08-07 11:18:20] [config]   - 0
[2019-08-07 11:18:20] [config] lr-decay-repeat-warmup: false
[2019-08-07 11:18:20] [config] lr-decay-reset-optimizer: false
[2019-08-07 11:18:20] [config] lr-decay-start:
[2019-08-07 11:18:20] [config]   - 10
[2019-08-07 11:18:20] [config]   - 1
[2019-08-07 11:18:20] [config] lr-decay-strategy: epoch+stalled
[2019-08-07 11:18:20] [config] lr-report: false
[2019-08-07 11:18:20] [config] lr-warmup: 0
[2019-08-07 11:18:20] [config] lr-warmup-at-reload: false
[2019-08-07 11:18:20] [config] lr-warmup-cycle: false
[2019-08-07 11:18:20] [config] lr-warmup-start-rate: 0
[2019-08-07 11:18:20] [config] max-length: 50
[2019-08-07 11:18:20] [config] max-length-crop: false
[2019-08-07 11:18:20] [config] max-length-factor: 3
[2019-08-07 11:18:20] [config] maxi-batch: 100
[2019-08-07 11:18:20] [config] maxi-batch-sort: trg
[2019-08-07 11:18:20] [config] mini-batch: 64
[2019-08-07 11:18:20] [config] mini-batch-fit: true
[2019-08-07 11:18:20] [config] mini-batch-fit-step: 10
[2019-08-07 11:18:20] [config] mini-batch-overstuff: 1
[2019-08-07 11:18:20] [config] mini-batch-track-lr: false
[2019-08-07 11:18:20] [config] mini-batch-understuff: 1
[2019-08-07 11:18:20] [config] mini-batch-warmup: 0
[2019-08-07 11:18:20] [config] mini-batch-words: 0
[2019-08-07 11:18:20] [config] mini-batch-words-ref: 0
[2019-08-07 11:18:20] [config] model: ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-07 11:18:20] [config] multi-loss-type: sum
[2019-08-07 11:18:20] [config] multi-node: false
[2019-08-07 11:18:20] [config] multi-node-overlap: true
[2019-08-07 11:18:20] [config] n-best: false
[2019-08-07 11:18:20] [config] no-nccl: false
[2019-08-07 11:18:20] [config] no-reload: false
[2019-08-07 11:18:20] [config] no-restore-corpus: false
[2019-08-07 11:18:20] [config] no-shuffle: false
[2019-08-07 11:18:20] [config] normalize: 1
[2019-08-07 11:18:20] [config] num-devices: 0
[2019-08-07 11:18:20] [config] optimizer: adam
[2019-08-07 11:18:20] [config] optimizer-delay: 1
[2019-08-07 11:18:20] [config] optimizer-params:
[2019-08-07 11:18:20] [config]   []
[2019-08-07 11:18:20] [config] overwrite: false
[2019-08-07 11:18:20] [config] pretrained-model: ""
[2019-08-07 11:18:20] [config] quiet: false
[2019-08-07 11:18:20] [config] quiet-translation: true
[2019-08-07 11:18:20] [config] relative-paths: false
[2019-08-07 11:18:20] [config] right-left: false
[2019-08-07 11:18:20] [config] save-freq: 20000
[2019-08-07 11:18:20] [config] seed: 1111
[2019-08-07 11:18:20] [config] shuffle-in-ram: false
[2019-08-07 11:18:20] [config] skip: false
[2019-08-07 11:18:20] [config] sqlite: ""
[2019-08-07 11:18:20] [config] sqlite-drop: false
[2019-08-07 11:18:20] [config] sync-sgd: true
[2019-08-07 11:18:20] [config] tempdir: .
[2019-08-07 11:18:20] [config] tied-embeddings: false
[2019-08-07 11:18:20] [config] tied-embeddings-all: false
[2019-08-07 11:18:20] [config] tied-embeddings-src: false
[2019-08-07 11:18:20] [config] train-sets:
[2019-08-07 11:18:20] [config]   - ../experiments/100M_random_fasttext_prob/data/train.bpe.de
[2019-08-07 11:18:20] [config]   - ../experiments/100M_random_fasttext_prob/data/train.bpe.en
[2019-08-07 11:18:20] [config] transformer-aan-activation: swish
[2019-08-07 11:18:20] [config] transformer-aan-depth: 2
[2019-08-07 11:18:20] [config] transformer-aan-nogate: false
[2019-08-07 11:18:20] [config] transformer-decoder-autoreg: self-attention
[2019-08-07 11:18:20] [config] transformer-dim-aan: 2048
[2019-08-07 11:18:20] [config] transformer-dim-ffn: 2048
[2019-08-07 11:18:20] [config] transformer-dropout: 0
[2019-08-07 11:18:20] [config] transformer-dropout-attention: 0
[2019-08-07 11:18:20] [config] transformer-dropout-ffn: 0
[2019-08-07 11:18:20] [config] transformer-ffn-activation: swish
[2019-08-07 11:18:20] [config] transformer-ffn-depth: 2
[2019-08-07 11:18:20] [config] transformer-guided-alignment-layer: last
[2019-08-07 11:18:20] [config] transformer-heads: 8
[2019-08-07 11:18:20] [config] transformer-no-projection: false
[2019-08-07 11:18:20] [config] transformer-postprocess: dan
[2019-08-07 11:18:20] [config] transformer-postprocess-emb: d
[2019-08-07 11:18:20] [config] transformer-preprocess: ""
[2019-08-07 11:18:20] [config] transformer-tied-layers:
[2019-08-07 11:18:20] [config]   []
[2019-08-07 11:18:20] [config] transformer-train-position-embeddings: false
[2019-08-07 11:18:20] [config] type: amun
[2019-08-07 11:18:20] [config] ulr: false
[2019-08-07 11:18:20] [config] ulr-dim-emb: 0
[2019-08-07 11:18:20] [config] ulr-dropout: 0
[2019-08-07 11:18:20] [config] ulr-keys-vectors: ""
[2019-08-07 11:18:20] [config] ulr-query-vectors: ""
[2019-08-07 11:18:20] [config] ulr-softmax-temperature: 1
[2019-08-07 11:18:20] [config] ulr-trainable-transformation: false
[2019-08-07 11:18:20] [config] valid-freq: 20000
[2019-08-07 11:18:20] [config] valid-log: ../experiments/100M_random_fasttext_prob/model/valid.log
[2019-08-07 11:18:20] [config] valid-max-length: 1000
[2019-08-07 11:18:20] [config] valid-metrics:
[2019-08-07 11:18:20] [config]   - cross-entropy
[2019-08-07 11:18:20] [config]   - perplexity
[2019-08-07 11:18:20] [config]   - translation
[2019-08-07 11:18:20] [config] valid-mini-batch: 8
[2019-08-07 11:18:20] [config] valid-script-path: ../experiments/100M_random_fasttext_prob/score-dev.sh
[2019-08-07 11:18:20] [config] valid-sets:
[2019-08-07 11:18:20] [config]   - ../experiments/100M_random_fasttext_prob/data/dev.bpe.de
[2019-08-07 11:18:20] [config]   - ../experiments/100M_random_fasttext_prob/data/dev.bpe.en
[2019-08-07 11:18:20] [config] valid-translation-output: ../experiments/100M_random_fasttext_prob/model/dev.out
[2019-08-07 11:18:20] [config] vocabs:
[2019-08-07 11:18:20] [config]   - ../experiments/100M_random_fasttext_prob/data/train.bpe.de.json
[2019-08-07 11:18:20] [config]   - ../experiments/100M_random_fasttext_prob/data/train.bpe.en.json
[2019-08-07 11:18:20] [config] word-penalty: 0
[2019-08-07 11:18:20] [config] workspace: 5000
[2019-08-07 11:18:20] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 11:18:20] Using synchronous training
[2019-08-07 11:18:20] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_random_fasttext_prob/data/train.bpe.de.json
[2019-08-07 11:18:20] [data] Using unused word id eos for 0
[2019-08-07 11:18:20] [data] Using unused word id UNK for 1
[2019-08-07 11:18:20] [data] Setting vocabulary size for input 0 to 50000
[2019-08-07 11:18:20] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_random_fasttext_prob/data/train.bpe.en.json
[2019-08-07 11:18:21] [data] Using unused word id eos for 0
[2019-08-07 11:18:21] [data] Using unused word id UNK for 1
[2019-08-07 11:18:21] [data] Setting vocabulary size for input 1 to 50000
[2019-08-07 11:18:21] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-07 11:18:21] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-07 11:18:22] [memory] Extending reserved space to 5120 MB (device gpu6)
[2019-08-07 11:18:22] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 11:18:23] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 11:18:23] [training] Using 1 GPUs
[2019-08-07 11:18:23] [memory] Reserving 422 MB, device gpu6
[2019-08-07 11:18:23] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-07 11:18:23] [memory] Reserving 422 MB, device gpu6
[2019-08-07 11:18:31] [batching] Done. Typical MB size is 6880 target words
[2019-08-07 11:18:31] [memory] Extending reserved space to 5120 MB (device gpu6)
[2019-08-07 11:18:31] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 11:18:31] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 11:18:31] [training] Using 1 GPUs
[2019-08-07 11:18:31] Training started
[2019-08-07 11:18:31] [data] Shuffling data
[2019-08-07 11:18:35] [data] Done reading 6422600 sentences
[2019-08-07 11:19:05] [data] Done shuffling 6422600 sentences to temp files
[2019-08-07 11:19:06] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-07 11:19:06] [memory] Reserving 422 MB, device gpu6
[2019-08-07 11:19:07] [memory] Reserving 422 MB, device gpu6
[2019-08-07 11:19:07] [memory] Reserving 422 MB, device gpu6
[2019-08-07 11:19:07] [memory] Reserving 844 MB, device gpu6
[2019-08-07 11:32:21] Ep. 1 : Up. 2000 : Sen. 304,645 : Cost 119.06517029 : Time 840.60s : 6555.36 words/s
[2019-08-07 11:42:31] Ep. 1 : Up. 4000 : Sen. 610,110 : Cost 103.61695862 : Time 609.73s : 9103.42 words/s
[2019-08-07 11:48:41] Ep. 1 : Up. 6000 : Sen. 914,227 : Cost 95.85655212 : Time 369.65s : 14897.49 words/s
[2019-08-07 11:54:51] Ep. 1 : Up. 8000 : Sen. 1,219,378 : Cost 90.56117249 : Time 370.03s : 14896.55 words/s
[2019-08-07 12:01:02] Ep. 1 : Up. 10000 : Sen. 1,525,319 : Cost 87.26454163 : Time 371.19s : 14962.65 words/s
[2019-08-07 15:29:43] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 15:29:43] [marian] Running on bil as process 2868 with command line:
[2019-08-07 15:29:43] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_random_fasttext_prob/model/model.npz -T . --devices 6 --train-sets ../experiments/100M_random_fasttext_prob/data/train.bpe.de ../experiments/100M_random_fasttext_prob/data/train.bpe.en --vocabs ../experiments/100M_random_fasttext_prob/data/train.bpe.de.json ../experiments/100M_random_fasttext_prob/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_random_fasttext_prob/data/dev.bpe.de ../experiments/100M_random_fasttext_prob/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_random_fasttext_prob/model/dev.out --valid-script-path ../experiments/100M_random_fasttext_prob/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_random_fasttext_prob/model/train.log --valid-log ../experiments/100M_random_fasttext_prob/model/valid.log
[2019-08-07 15:29:43] [config] after-batches: 0
[2019-08-07 15:29:43] [config] after-epochs: 0
[2019-08-07 15:29:43] [config] allow-unk: false
[2019-08-07 15:29:43] [config] beam-size: 12
[2019-08-07 15:29:43] [config] bert-class-symbol: "[CLS]"
[2019-08-07 15:29:43] [config] bert-mask-symbol: "[MASK]"
[2019-08-07 15:29:43] [config] bert-masking-fraction: 0.15
[2019-08-07 15:29:43] [config] bert-sep-symbol: "[SEP]"
[2019-08-07 15:29:43] [config] bert-train-type-embeddings: true
[2019-08-07 15:29:43] [config] bert-type-vocab-size: 2
[2019-08-07 15:29:43] [config] best-deep: false
[2019-08-07 15:29:43] [config] clip-gemm: 0
[2019-08-07 15:29:43] [config] clip-norm: 1
[2019-08-07 15:29:43] [config] cost-type: ce-mean
[2019-08-07 15:29:43] [config] cpu-threads: 0
[2019-08-07 15:29:43] [config] data-weighting: ""
[2019-08-07 15:29:43] [config] data-weighting-type: sentence
[2019-08-07 15:29:43] [config] dec-cell: gru
[2019-08-07 15:29:43] [config] dec-cell-base-depth: 2
[2019-08-07 15:29:43] [config] dec-cell-high-depth: 1
[2019-08-07 15:29:43] [config] dec-depth: 1
[2019-08-07 15:29:43] [config] devices:
[2019-08-07 15:29:43] [config]   - 6
[2019-08-07 15:29:43] [config] dim-emb: 512
[2019-08-07 15:29:43] [config] dim-rnn: 1024
[2019-08-07 15:29:43] [config] dim-vocabs:
[2019-08-07 15:29:43] [config]   - 50000
[2019-08-07 15:29:43] [config]   - 50000
[2019-08-07 15:29:43] [config] disp-first: 0
[2019-08-07 15:29:43] [config] disp-freq: 2000
[2019-08-07 15:29:43] [config] disp-label-counts: false
[2019-08-07 15:29:43] [config] dropout-rnn: 0.2
[2019-08-07 15:29:43] [config] dropout-src: 0.1
[2019-08-07 15:29:43] [config] dropout-trg: 0.1
[2019-08-07 15:29:43] [config] dump-config: ""
[2019-08-07 15:29:43] [config] early-stopping: 5
[2019-08-07 15:29:43] [config] embedding-fix-src: false
[2019-08-07 15:29:43] [config] embedding-fix-trg: false
[2019-08-07 15:29:43] [config] embedding-normalization: false
[2019-08-07 15:29:43] [config] embedding-vectors:
[2019-08-07 15:29:43] [config]   []
[2019-08-07 15:29:43] [config] enc-cell: gru
[2019-08-07 15:29:43] [config] enc-cell-depth: 1
[2019-08-07 15:29:43] [config] enc-depth: 1
[2019-08-07 15:29:43] [config] enc-type: bidirectional
[2019-08-07 15:29:43] [config] exponential-smoothing: 0.0001
[2019-08-07 15:29:43] [config] grad-dropping-momentum: 0
[2019-08-07 15:29:43] [config] grad-dropping-rate: 0
[2019-08-07 15:29:43] [config] grad-dropping-warmup: 100
[2019-08-07 15:29:43] [config] guided-alignment: none
[2019-08-07 15:29:43] [config] guided-alignment-cost: mse
[2019-08-07 15:29:43] [config] guided-alignment-weight: 0.1
[2019-08-07 15:29:43] [config] ignore-model-config: false
[2019-08-07 15:29:43] [config] input-types:
[2019-08-07 15:29:43] [config]   []
[2019-08-07 15:29:43] [config] interpolate-env-vars: false
[2019-08-07 15:29:43] [config] keep-best: false
[2019-08-07 15:29:43] [config] label-smoothing: 0
[2019-08-07 15:29:43] [config] layer-normalization: true
[2019-08-07 15:29:43] [config] learn-rate: 0.0001
[2019-08-07 15:29:43] [config] log: ../experiments/100M_random_fasttext_prob/model/train.log
[2019-08-07 15:29:43] [config] log-level: info
[2019-08-07 15:29:43] [config] log-time-zone: ""
[2019-08-07 15:29:43] [config] lr-decay: 0
[2019-08-07 15:29:43] [config] lr-decay-freq: 50000
[2019-08-07 15:29:43] [config] lr-decay-inv-sqrt:
[2019-08-07 15:29:43] [config]   - 0
[2019-08-07 15:29:43] [config] lr-decay-repeat-warmup: false
[2019-08-07 15:29:43] [config] lr-decay-reset-optimizer: false
[2019-08-07 15:29:43] [config] lr-decay-start:
[2019-08-07 15:29:43] [config]   - 10
[2019-08-07 15:29:43] [config]   - 1
[2019-08-07 15:29:43] [config] lr-decay-strategy: epoch+stalled
[2019-08-07 15:29:43] [config] lr-report: false
[2019-08-07 15:29:43] [config] lr-warmup: 0
[2019-08-07 15:29:43] [config] lr-warmup-at-reload: false
[2019-08-07 15:29:43] [config] lr-warmup-cycle: false
[2019-08-07 15:29:43] [config] lr-warmup-start-rate: 0
[2019-08-07 15:29:43] [config] max-length: 50
[2019-08-07 15:29:43] [config] max-length-crop: false
[2019-08-07 15:29:43] [config] max-length-factor: 3
[2019-08-07 15:29:43] [config] maxi-batch: 100
[2019-08-07 15:29:43] [config] maxi-batch-sort: trg
[2019-08-07 15:29:43] [config] mini-batch: 64
[2019-08-07 15:29:43] [config] mini-batch-fit: true
[2019-08-07 15:29:43] [config] mini-batch-fit-step: 10
[2019-08-07 15:29:43] [config] mini-batch-overstuff: 1
[2019-08-07 15:29:43] [config] mini-batch-track-lr: false
[2019-08-07 15:29:43] [config] mini-batch-understuff: 1
[2019-08-07 15:29:43] [config] mini-batch-warmup: 0
[2019-08-07 15:29:43] [config] mini-batch-words: 0
[2019-08-07 15:29:43] [config] mini-batch-words-ref: 0
[2019-08-07 15:29:43] [config] model: ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-07 15:29:43] [config] multi-loss-type: sum
[2019-08-07 15:29:43] [config] multi-node: false
[2019-08-07 15:29:43] [config] multi-node-overlap: true
[2019-08-07 15:29:43] [config] n-best: false
[2019-08-07 15:29:43] [config] no-nccl: false
[2019-08-07 15:29:43] [config] no-reload: false
[2019-08-07 15:29:43] [config] no-restore-corpus: false
[2019-08-07 15:29:43] [config] no-shuffle: false
[2019-08-07 15:29:43] [config] normalize: 1
[2019-08-07 15:29:43] [config] num-devices: 0
[2019-08-07 15:29:43] [config] optimizer: adam
[2019-08-07 15:29:43] [config] optimizer-delay: 1
[2019-08-07 15:29:43] [config] optimizer-params:
[2019-08-07 15:29:43] [config]   []
[2019-08-07 15:29:43] [config] overwrite: false
[2019-08-07 15:29:43] [config] pretrained-model: ""
[2019-08-07 15:29:43] [config] quiet: false
[2019-08-07 15:29:43] [config] quiet-translation: true
[2019-08-07 15:29:43] [config] relative-paths: false
[2019-08-07 15:29:43] [config] right-left: false
[2019-08-07 15:29:43] [config] save-freq: 20000
[2019-08-07 15:29:43] [config] seed: 1111
[2019-08-07 15:29:43] [config] shuffle-in-ram: false
[2019-08-07 15:29:43] [config] skip: false
[2019-08-07 15:29:43] [config] sqlite: ""
[2019-08-07 15:29:43] [config] sqlite-drop: false
[2019-08-07 15:29:43] [config] sync-sgd: true
[2019-08-07 15:29:43] [config] tempdir: .
[2019-08-07 15:29:43] [config] tied-embeddings: false
[2019-08-07 15:29:43] [config] tied-embeddings-all: false
[2019-08-07 15:29:43] [config] tied-embeddings-src: false
[2019-08-07 15:29:43] [config] train-sets:
[2019-08-07 15:29:43] [config]   - ../experiments/100M_random_fasttext_prob/data/train.bpe.de
[2019-08-07 15:29:43] [config]   - ../experiments/100M_random_fasttext_prob/data/train.bpe.en
[2019-08-07 15:29:43] [config] transformer-aan-activation: swish
[2019-08-07 15:29:43] [config] transformer-aan-depth: 2
[2019-08-07 15:29:43] [config] transformer-aan-nogate: false
[2019-08-07 15:29:43] [config] transformer-decoder-autoreg: self-attention
[2019-08-07 15:29:43] [config] transformer-dim-aan: 2048
[2019-08-07 15:29:43] [config] transformer-dim-ffn: 2048
[2019-08-07 15:29:43] [config] transformer-dropout: 0
[2019-08-07 15:29:43] [config] transformer-dropout-attention: 0
[2019-08-07 15:29:43] [config] transformer-dropout-ffn: 0
[2019-08-07 15:29:43] [config] transformer-ffn-activation: swish
[2019-08-07 15:29:43] [config] transformer-ffn-depth: 2
[2019-08-07 15:29:43] [config] transformer-guided-alignment-layer: last
[2019-08-07 15:29:43] [config] transformer-heads: 8
[2019-08-07 15:29:43] [config] transformer-no-projection: false
[2019-08-07 15:29:43] [config] transformer-postprocess: dan
[2019-08-07 15:29:43] [config] transformer-postprocess-emb: d
[2019-08-07 15:29:43] [config] transformer-preprocess: ""
[2019-08-07 15:29:43] [config] transformer-tied-layers:
[2019-08-07 15:29:43] [config]   []
[2019-08-07 15:29:43] [config] transformer-train-position-embeddings: false
[2019-08-07 15:29:43] [config] type: amun
[2019-08-07 15:29:43] [config] ulr: false
[2019-08-07 15:29:43] [config] ulr-dim-emb: 0
[2019-08-07 15:29:43] [config] ulr-dropout: 0
[2019-08-07 15:29:43] [config] ulr-keys-vectors: ""
[2019-08-07 15:29:43] [config] ulr-query-vectors: ""
[2019-08-07 15:29:43] [config] ulr-softmax-temperature: 1
[2019-08-07 15:29:43] [config] ulr-trainable-transformation: false
[2019-08-07 15:29:43] [config] valid-freq: 20000
[2019-08-07 15:29:43] [config] valid-log: ../experiments/100M_random_fasttext_prob/model/valid.log
[2019-08-07 15:29:43] [config] valid-max-length: 1000
[2019-08-07 15:29:43] [config] valid-metrics:
[2019-08-07 15:29:43] [config]   - cross-entropy
[2019-08-07 15:29:43] [config]   - perplexity
[2019-08-07 15:29:43] [config]   - translation
[2019-08-07 15:29:43] [config] valid-mini-batch: 8
[2019-08-07 15:29:43] [config] valid-script-path: ../experiments/100M_random_fasttext_prob/score-dev.sh
[2019-08-07 15:29:43] [config] valid-sets:
[2019-08-07 15:29:43] [config]   - ../experiments/100M_random_fasttext_prob/data/dev.bpe.de
[2019-08-07 15:29:43] [config]   - ../experiments/100M_random_fasttext_prob/data/dev.bpe.en
[2019-08-07 15:29:43] [config] valid-translation-output: ../experiments/100M_random_fasttext_prob/model/dev.out
[2019-08-07 15:29:43] [config] vocabs:
[2019-08-07 15:29:43] [config]   - ../experiments/100M_random_fasttext_prob/data/train.bpe.de.json
[2019-08-07 15:29:43] [config]   - ../experiments/100M_random_fasttext_prob/data/train.bpe.en.json
[2019-08-07 15:29:43] [config] word-penalty: 0
[2019-08-07 15:29:43] [config] workspace: 3000
[2019-08-07 15:29:43] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 15:29:43] Using synchronous training
[2019-08-07 15:29:43] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_random_fasttext_prob/data/train.bpe.de.json
[2019-08-07 15:29:43] [data] Using unused word id eos for 0
[2019-08-07 15:29:43] [data] Using unused word id UNK for 1
[2019-08-07 15:29:43] [data] Setting vocabulary size for input 0 to 50000
[2019-08-07 15:29:43] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_random_fasttext_prob/data/train.bpe.en.json
[2019-08-07 15:29:44] [data] Using unused word id eos for 0
[2019-08-07 15:29:44] [data] Using unused word id UNK for 1
[2019-08-07 15:29:44] [data] Setting vocabulary size for input 1 to 50000
[2019-08-07 15:29:44] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-07 15:29:44] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-07 15:29:45] [memory] Extending reserved space to 3072 MB (device gpu6)
[2019-08-07 15:29:45] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 15:29:45] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 15:29:45] [training] Using 1 GPUs
[2019-08-07 15:29:45] [memory] Reserving 422 MB, device gpu6
[2019-08-07 15:29:45] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-07 15:29:45] [memory] Reserving 422 MB, device gpu6
[2019-08-07 15:29:48] [batching] Done. Typical MB size is 4042 target words
[2019-08-07 15:29:48] [memory] Extending reserved space to 3072 MB (device gpu6)
[2019-08-07 15:29:48] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 15:29:48] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 15:29:48] [training] Using 1 GPUs
[2019-08-07 15:29:48] Training started
[2019-08-07 15:29:48] [data] Shuffling data
[2019-08-07 15:29:54] [data] Done reading 6422600 sentences
[2019-08-07 15:30:20] [data] Done shuffling 6422600 sentences to temp files
[2019-08-07 15:30:22] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-07 15:30:22] [memory] Reserving 422 MB, device gpu6
[2019-08-07 15:30:22] [memory] Reserving 422 MB, device gpu6
[2019-08-07 15:30:22] [memory] Reserving 422 MB, device gpu6
[2019-08-07 15:30:22] [memory] Reserving 844 MB, device gpu6
[2019-08-07 15:34:55] Ep. 1 : Up. 2000 : Sen. 204,095 : Cost 121.18424988 : Time 311.50s : 11875.94 words/s
[2019-08-07 15:39:32] Ep. 1 : Up. 4000 : Sen. 408,466 : Cost 106.04425049 : Time 276.30s : 13400.04 words/s
[2019-08-07 15:44:08] Ep. 1 : Up. 6000 : Sen. 612,593 : Cost 99.05352783 : Time 276.52s : 13385.72 words/s
[2019-08-07 15:48:45] Ep. 1 : Up. 8000 : Sen. 817,567 : Cost 93.85297394 : Time 277.46s : 13335.90 words/s
[2019-08-07 15:53:23] Ep. 1 : Up. 10000 : Sen. 1,021,990 : Cost 90.13886261 : Time 277.04s : 13358.57 words/s
[2019-08-07 15:57:59] Ep. 1 : Up. 12000 : Sen. 1,226,101 : Cost 87.27455139 : Time 276.64s : 13376.18 words/s
[2019-08-07 16:02:38] Ep. 1 : Up. 14000 : Sen. 1,431,022 : Cost 84.79110718 : Time 278.37s : 13339.81 words/s
[2019-08-07 16:07:15] Ep. 1 : Up. 16000 : Sen. 1,635,078 : Cost 82.80017090 : Time 277.30s : 13357.01 words/s
[2019-08-07 16:11:52] Ep. 1 : Up. 18000 : Sen. 1,839,507 : Cost 81.21063232 : Time 277.18s : 13393.35 words/s
[2019-08-07 16:16:27] Ep. 1 : Up. 20000 : Sen. 2,043,724 : Cost 79.03755951 : Time 275.19s : 13391.09 words/s
[2019-08-07 16:16:27] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-07 16:16:31] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter20000.npz
[2019-08-07 16:16:33] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-07 16:16:37] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-07 16:16:52] [valid] Ep. 1 : Up. 20000 : cross-entropy : 98.5963 : new best
[2019-08-07 16:16:59] [valid] Ep. 1 : Up. 20000 : perplexity : 48.6689 : new best
[2019-08-07 16:17:58] [valid] Ep. 1 : Up. 20000 : translation : 9.66 : new best
[2019-08-07 16:22:38] Ep. 1 : Up. 22000 : Sen. 2,247,628 : Cost 78.19246674 : Time 370.42s : 9971.49 words/s
[2019-08-07 16:27:14] Ep. 1 : Up. 24000 : Sen. 2,451,954 : Cost 76.98451233 : Time 276.78s : 13376.08 words/s
[2019-08-07 17:34:15] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 17:34:16] [marian] Running on bil as process 6102 with command line:
[2019-08-07 17:34:16] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_random_fasttext_prob/model/model.npz -T . --devices 6 --train-sets ../experiments/100M_random_fasttext_prob/data/train.bpe.de ../experiments/100M_random_fasttext_prob/data/train.bpe.en --vocabs ../experiments/100M_random_fasttext_prob/data/train.bpe.de.json ../experiments/100M_random_fasttext_prob/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_random_fasttext_prob/data/dev.bpe.de ../experiments/100M_random_fasttext_prob/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_random_fasttext_prob/model/dev.out --valid-script-path ../experiments/100M_random_fasttext_prob/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_random_fasttext_prob/model/train.log --valid-log ../experiments/100M_random_fasttext_prob/model/valid.log
[2019-08-07 17:34:16] [config] after-batches: 0
[2019-08-07 17:34:16] [config] after-epochs: 0
[2019-08-07 17:34:16] [config] allow-unk: false
[2019-08-07 17:34:16] [config] beam-size: 12
[2019-08-07 17:34:16] [config] bert-class-symbol: "[CLS]"
[2019-08-07 17:34:16] [config] bert-mask-symbol: "[MASK]"
[2019-08-07 17:34:16] [config] bert-masking-fraction: 0.15
[2019-08-07 17:34:16] [config] bert-sep-symbol: "[SEP]"
[2019-08-07 17:34:16] [config] bert-train-type-embeddings: true
[2019-08-07 17:34:16] [config] bert-type-vocab-size: 2
[2019-08-07 17:34:16] [config] best-deep: false
[2019-08-07 17:34:16] [config] clip-gemm: 0
[2019-08-07 17:34:16] [config] clip-norm: 1
[2019-08-07 17:34:16] [config] cost-type: ce-mean
[2019-08-07 17:34:16] [config] cpu-threads: 0
[2019-08-07 17:34:16] [config] data-weighting: ""
[2019-08-07 17:34:16] [config] data-weighting-type: sentence
[2019-08-07 17:34:16] [config] dec-cell: gru
[2019-08-07 17:34:16] [config] dec-cell-base-depth: 2
[2019-08-07 17:34:16] [config] dec-cell-high-depth: 1
[2019-08-07 17:34:16] [config] dec-depth: 1
[2019-08-07 17:34:16] [config] devices:
[2019-08-07 17:34:16] [config]   - 6
[2019-08-07 17:34:16] [config] dim-emb: 512
[2019-08-07 17:34:16] [config] dim-rnn: 1024
[2019-08-07 17:34:16] [config] dim-vocabs:
[2019-08-07 17:34:16] [config]   - 50000
[2019-08-07 17:34:16] [config]   - 50000
[2019-08-07 17:34:16] [config] disp-first: 0
[2019-08-07 17:34:16] [config] disp-freq: 2000
[2019-08-07 17:34:16] [config] disp-label-counts: false
[2019-08-07 17:34:16] [config] dropout-rnn: 0.2
[2019-08-07 17:34:16] [config] dropout-src: 0.1
[2019-08-07 17:34:16] [config] dropout-trg: 0.1
[2019-08-07 17:34:16] [config] dump-config: ""
[2019-08-07 17:34:16] [config] early-stopping: 5
[2019-08-07 17:34:16] [config] embedding-fix-src: false
[2019-08-07 17:34:16] [config] embedding-fix-trg: false
[2019-08-07 17:34:16] [config] embedding-normalization: false
[2019-08-07 17:34:16] [config] embedding-vectors:
[2019-08-07 17:34:16] [config]   []
[2019-08-07 17:34:16] [config] enc-cell: gru
[2019-08-07 17:34:16] [config] enc-cell-depth: 1
[2019-08-07 17:34:16] [config] enc-depth: 1
[2019-08-07 17:34:16] [config] enc-type: bidirectional
[2019-08-07 17:34:16] [config] exponential-smoothing: 0.0001
[2019-08-07 17:34:16] [config] grad-dropping-momentum: 0
[2019-08-07 17:34:16] [config] grad-dropping-rate: 0
[2019-08-07 17:34:16] [config] grad-dropping-warmup: 100
[2019-08-07 17:34:16] [config] guided-alignment: none
[2019-08-07 17:34:16] [config] guided-alignment-cost: mse
[2019-08-07 17:34:16] [config] guided-alignment-weight: 0.1
[2019-08-07 17:34:16] [config] ignore-model-config: false
[2019-08-07 17:34:16] [config] input-types:
[2019-08-07 17:34:16] [config]   []
[2019-08-07 17:34:16] [config] interpolate-env-vars: false
[2019-08-07 17:34:16] [config] keep-best: false
[2019-08-07 17:34:16] [config] label-smoothing: 0
[2019-08-07 17:34:16] [config] layer-normalization: true
[2019-08-07 17:34:16] [config] learn-rate: 0.0001
[2019-08-07 17:34:16] [config] log: ../experiments/100M_random_fasttext_prob/model/train.log
[2019-08-07 17:34:16] [config] log-level: info
[2019-08-07 17:34:16] [config] log-time-zone: ""
[2019-08-07 17:34:16] [config] lr-decay: 0
[2019-08-07 17:34:16] [config] lr-decay-freq: 50000
[2019-08-07 17:34:16] [config] lr-decay-inv-sqrt:
[2019-08-07 17:34:16] [config]   - 0
[2019-08-07 17:34:16] [config] lr-decay-repeat-warmup: false
[2019-08-07 17:34:16] [config] lr-decay-reset-optimizer: false
[2019-08-07 17:34:16] [config] lr-decay-start:
[2019-08-07 17:34:16] [config]   - 10
[2019-08-07 17:34:16] [config]   - 1
[2019-08-07 17:34:16] [config] lr-decay-strategy: epoch+stalled
[2019-08-07 17:34:16] [config] lr-report: false
[2019-08-07 17:34:16] [config] lr-warmup: 0
[2019-08-07 17:34:16] [config] lr-warmup-at-reload: false
[2019-08-07 17:34:16] [config] lr-warmup-cycle: false
[2019-08-07 17:34:16] [config] lr-warmup-start-rate: 0
[2019-08-07 17:34:16] [config] max-length: 50
[2019-08-07 17:34:16] [config] max-length-crop: false
[2019-08-07 17:34:16] [config] max-length-factor: 3
[2019-08-07 17:34:16] [config] maxi-batch: 100
[2019-08-07 17:34:16] [config] maxi-batch-sort: trg
[2019-08-07 17:34:16] [config] mini-batch: 64
[2019-08-07 17:34:16] [config] mini-batch-fit: true
[2019-08-07 17:34:16] [config] mini-batch-fit-step: 10
[2019-08-07 17:34:16] [config] mini-batch-overstuff: 1
[2019-08-07 17:34:16] [config] mini-batch-track-lr: false
[2019-08-07 17:34:16] [config] mini-batch-understuff: 1
[2019-08-07 17:34:16] [config] mini-batch-warmup: 0
[2019-08-07 17:34:16] [config] mini-batch-words: 0
[2019-08-07 17:34:16] [config] mini-batch-words-ref: 0
[2019-08-07 17:34:16] [config] model: ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-07 17:34:16] [config] multi-loss-type: sum
[2019-08-07 17:34:16] [config] multi-node: false
[2019-08-07 17:34:16] [config] multi-node-overlap: true
[2019-08-07 17:34:16] [config] n-best: false
[2019-08-07 17:34:16] [config] no-nccl: false
[2019-08-07 17:34:16] [config] no-reload: false
[2019-08-07 17:34:16] [config] no-restore-corpus: false
[2019-08-07 17:34:16] [config] no-shuffle: false
[2019-08-07 17:34:16] [config] normalize: 1
[2019-08-07 17:34:16] [config] num-devices: 0
[2019-08-07 17:34:16] [config] optimizer: adam
[2019-08-07 17:34:16] [config] optimizer-delay: 1
[2019-08-07 17:34:16] [config] optimizer-params:
[2019-08-07 17:34:16] [config]   []
[2019-08-07 17:34:16] [config] overwrite: false
[2019-08-07 17:34:16] [config] pretrained-model: ""
[2019-08-07 17:34:16] [config] quiet: false
[2019-08-07 17:34:16] [config] quiet-translation: true
[2019-08-07 17:34:16] [config] relative-paths: false
[2019-08-07 17:34:16] [config] right-left: false
[2019-08-07 17:34:16] [config] save-freq: 20000
[2019-08-07 17:34:16] [config] seed: 1111
[2019-08-07 17:34:16] [config] shuffle-in-ram: false
[2019-08-07 17:34:16] [config] skip: false
[2019-08-07 17:34:16] [config] sqlite: ""
[2019-08-07 17:34:16] [config] sqlite-drop: false
[2019-08-07 17:34:16] [config] sync-sgd: true
[2019-08-07 17:34:16] [config] tempdir: .
[2019-08-07 17:34:16] [config] tied-embeddings: false
[2019-08-07 17:34:16] [config] tied-embeddings-all: false
[2019-08-07 17:34:16] [config] tied-embeddings-src: false
[2019-08-07 17:34:16] [config] train-sets:
[2019-08-07 17:34:16] [config]   - ../experiments/100M_random_fasttext_prob/data/train.bpe.de
[2019-08-07 17:34:16] [config]   - ../experiments/100M_random_fasttext_prob/data/train.bpe.en
[2019-08-07 17:34:16] [config] transformer-aan-activation: swish
[2019-08-07 17:34:16] [config] transformer-aan-depth: 2
[2019-08-07 17:34:16] [config] transformer-aan-nogate: false
[2019-08-07 17:34:16] [config] transformer-decoder-autoreg: self-attention
[2019-08-07 17:34:16] [config] transformer-dim-aan: 2048
[2019-08-07 17:34:16] [config] transformer-dim-ffn: 2048
[2019-08-07 17:34:16] [config] transformer-dropout: 0
[2019-08-07 17:34:16] [config] transformer-dropout-attention: 0
[2019-08-07 17:34:16] [config] transformer-dropout-ffn: 0
[2019-08-07 17:34:16] [config] transformer-ffn-activation: swish
[2019-08-07 17:34:16] [config] transformer-ffn-depth: 2
[2019-08-07 17:34:16] [config] transformer-guided-alignment-layer: last
[2019-08-07 17:34:16] [config] transformer-heads: 8
[2019-08-07 17:34:16] [config] transformer-no-projection: false
[2019-08-07 17:34:16] [config] transformer-postprocess: dan
[2019-08-07 17:34:16] [config] transformer-postprocess-emb: d
[2019-08-07 17:34:16] [config] transformer-preprocess: ""
[2019-08-07 17:34:16] [config] transformer-tied-layers:
[2019-08-07 17:34:16] [config]   []
[2019-08-07 17:34:16] [config] transformer-train-position-embeddings: false
[2019-08-07 17:34:16] [config] type: amun
[2019-08-07 17:34:16] [config] ulr: false
[2019-08-07 17:34:16] [config] ulr-dim-emb: 0
[2019-08-07 17:34:16] [config] ulr-dropout: 0
[2019-08-07 17:34:16] [config] ulr-keys-vectors: ""
[2019-08-07 17:34:16] [config] ulr-query-vectors: ""
[2019-08-07 17:34:16] [config] ulr-softmax-temperature: 1
[2019-08-07 17:34:16] [config] ulr-trainable-transformation: false
[2019-08-07 17:34:16] [config] valid-freq: 20000
[2019-08-07 17:34:16] [config] valid-log: ../experiments/100M_random_fasttext_prob/model/valid.log
[2019-08-07 17:34:16] [config] valid-max-length: 1000
[2019-08-07 17:34:16] [config] valid-metrics:
[2019-08-07 17:34:16] [config]   - cross-entropy
[2019-08-07 17:34:16] [config]   - perplexity
[2019-08-07 17:34:16] [config]   - translation
[2019-08-07 17:34:16] [config] valid-mini-batch: 8
[2019-08-07 17:34:16] [config] valid-script-path: ../experiments/100M_random_fasttext_prob/score-dev.sh
[2019-08-07 17:34:16] [config] valid-sets:
[2019-08-07 17:34:16] [config]   - ../experiments/100M_random_fasttext_prob/data/dev.bpe.de
[2019-08-07 17:34:16] [config]   - ../experiments/100M_random_fasttext_prob/data/dev.bpe.en
[2019-08-07 17:34:16] [config] valid-translation-output: ../experiments/100M_random_fasttext_prob/model/dev.out
[2019-08-07 17:34:16] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 17:34:16] [config] vocabs:
[2019-08-07 17:34:16] [config]   - ../experiments/100M_random_fasttext_prob/data/train.bpe.de.json
[2019-08-07 17:34:16] [config]   - ../experiments/100M_random_fasttext_prob/data/train.bpe.en.json
[2019-08-07 17:34:16] [config] word-penalty: 0
[2019-08-07 17:34:16] [config] workspace: 3000
[2019-08-07 17:34:16] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 17:34:16] Using synchronous training
[2019-08-07 17:34:16] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_random_fasttext_prob/data/train.bpe.de.json
[2019-08-07 17:34:17] [data] Using unused word id eos for 0
[2019-08-07 17:34:17] [data] Using unused word id UNK for 1
[2019-08-07 17:34:17] [data] Setting vocabulary size for input 0 to 50000
[2019-08-07 17:34:17] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_random_fasttext_prob/data/train.bpe.en.json
[2019-08-07 17:34:17] [data] Using unused word id eos for 0
[2019-08-07 17:34:17] [data] Using unused word id UNK for 1
[2019-08-07 17:34:17] [data] Setting vocabulary size for input 1 to 50000
[2019-08-07 17:34:17] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-07 17:34:17] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-07 17:34:18] [memory] Extending reserved space to 3072 MB (device gpu6)
[2019-08-07 17:34:18] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 17:34:18] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 17:34:18] [training] Using 1 GPUs
[2019-08-07 17:34:19] [memory] Reserving 422 MB, device gpu6
[2019-08-07 17:34:19] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-07 17:34:19] [memory] Reserving 422 MB, device gpu6
[2019-08-07 17:34:21] [batching] Done. Typical MB size is 4042 target words
[2019-08-07 17:34:21] [memory] Extending reserved space to 3072 MB (device gpu6)
[2019-08-07 17:34:21] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 17:34:21] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 17:34:21] [training] Using 1 GPUs
[2019-08-07 17:34:21] Loading model from ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-07 17:34:25] Loading Adam parameters from ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-07 17:34:28] [memory] Reserving 844 MB, device gpu6
[2019-08-07 17:34:29] [training] Model reloaded from ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-07 17:34:29] [data] Restoring the corpus state to epoch 1, batch 20000
[2019-08-07 17:34:29] [data] Shuffling data
[2019-08-07 17:34:32] [data] Done reading 6422600 sentences
[2019-08-07 17:35:06] [data] Done shuffling 6422600 sentences to temp files
[2019-08-07 17:36:02] Training started
[2019-08-07 17:36:02] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-07 17:36:02] [memory] Reserving 422 MB, device gpu6
[2019-08-07 17:36:02] [memory] Reserving 422 MB, device gpu6
[2019-08-07 17:36:02] Loading model from ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-07 17:36:05] [memory] Reserving 422 MB, device cpu0
[2019-08-07 17:36:05] [memory] Reserving 422 MB, device gpu6
[2019-08-07 17:40:41] Ep. 1 : Up. 22000 : Sen. 2,247,628 : Cost 78.63486481 : Time 383.78s : 9624.34 words/s
[2019-08-07 17:45:16] Ep. 1 : Up. 24000 : Sen. 2,451,954 : Cost 77.15065765 : Time 275.09s : 13458.03 words/s
[2019-08-07 17:49:50] Ep. 1 : Up. 26000 : Sen. 2,656,000 : Cost 75.72006226 : Time 274.26s : 13437.89 words/s
[2019-08-07 17:54:26] Ep. 1 : Up. 28000 : Sen. 2,860,144 : Cost 75.25574493 : Time 276.15s : 13417.47 words/s
[2019-08-07 17:59:03] Ep. 1 : Up. 30000 : Sen. 3,064,392 : Cost 74.37042236 : Time 276.85s : 13344.59 words/s
[2019-08-07 18:03:42] Ep. 1 : Up. 32000 : Sen. 3,268,574 : Cost 73.53610992 : Time 278.26s : 13302.95 words/s
[2019-08-07 18:08:18] Ep. 1 : Up. 34000 : Sen. 3,473,065 : Cost 72.70685577 : Time 276.40s : 13387.94 words/s
[2019-08-07 18:12:55] Ep. 1 : Up. 36000 : Sen. 3,677,293 : Cost 72.22030640 : Time 276.70s : 13358.48 words/s
[2019-08-07 18:17:32] Ep. 1 : Up. 38000 : Sen. 3,881,207 : Cost 71.73580170 : Time 277.27s : 13351.60 words/s
[2019-08-07 18:22:08] Ep. 1 : Up. 40000 : Sen. 4,084,909 : Cost 70.98711395 : Time 276.02s : 13342.70 words/s
[2019-08-07 18:22:08] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-07 18:22:13] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter40000.npz
[2019-08-07 18:22:15] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-07 18:22:20] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-07 18:22:36] [valid] Ep. 1 : Up. 40000 : cross-entropy : 79.3483 : new best
[2019-08-07 18:22:43] [valid] Ep. 1 : Up. 40000 : perplexity : 22.7964 : new best
[2019-08-07 18:23:36] [valid] Ep. 1 : Up. 40000 : translation : 17.58 : new best
[2019-08-07 18:28:15] Ep. 1 : Up. 42000 : Sen. 4,289,161 : Cost 70.44193268 : Time 366.80s : 10072.79 words/s
[2019-08-07 18:32:52] Ep. 1 : Up. 44000 : Sen. 4,493,518 : Cost 69.89652252 : Time 276.96s : 13310.25 words/s
[2019-08-07 18:37:30] Ep. 1 : Up. 46000 : Sen. 4,697,678 : Cost 69.86222839 : Time 278.27s : 13302.53 words/s
[2019-08-07 18:42:07] Ep. 1 : Up. 48000 : Sen. 4,901,786 : Cost 69.09610748 : Time 277.31s : 13296.97 words/s
[2019-08-07 18:46:44] Ep. 1 : Up. 50000 : Sen. 5,105,292 : Cost 69.30057526 : Time 276.82s : 13363.94 words/s
[2019-08-07 18:51:22] Ep. 1 : Up. 52000 : Sen. 5,309,242 : Cost 68.71495819 : Time 277.55s : 13319.23 words/s
[2019-08-07 18:55:59] Ep. 1 : Up. 54000 : Sen. 5,512,995 : Cost 68.60562134 : Time 277.89s : 13324.50 words/s
[2019-08-07 18:59:20] Seen 5659635 samples
[2019-08-07 18:59:20] Starting epoch 2
[2019-08-07 18:59:20] [data] Shuffling data
[2019-08-07 18:59:23] [data] Done reading 6422600 sentences
[2019-08-07 18:59:51] [data] Done shuffling 6422600 sentences to temp files
[2019-08-07 19:01:09] Ep. 2 : Up. 56000 : Sen. 57,170 : Cost 67.59060669 : Time 309.78s : 11889.64 words/s
[2019-08-07 19:05:49] Ep. 2 : Up. 58000 : Sen. 260,923 : Cost 66.88159943 : Time 280.00s : 13220.03 words/s
[2019-08-07 19:10:28] Ep. 2 : Up. 60000 : Sen. 465,180 : Cost 66.38735962 : Time 279.10s : 13241.94 words/s
[2019-08-07 19:10:28] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-07 19:10:33] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter60000.npz
[2019-08-07 19:10:35] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-07 19:10:40] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-07 19:10:57] [valid] Ep. 2 : Up. 60000 : cross-entropy : 71.1597 : new best
[2019-08-07 19:11:03] [valid] Ep. 2 : Up. 60000 : perplexity : 16.5096 : new best
[2019-08-07 19:11:54] [valid] Ep. 2 : Up. 60000 : translation : 20.39 : new best
[2019-08-07 19:16:35] Ep. 2 : Up. 62000 : Sen. 670,156 : Cost 66.26167297 : Time 366.68s : 10119.35 words/s
[2019-08-07 19:21:15] Ep. 2 : Up. 64000 : Sen. 874,807 : Cost 66.04229736 : Time 280.30s : 13182.64 words/s
[2019-08-07 19:25:56] Ep. 2 : Up. 66000 : Sen. 1,078,911 : Cost 65.84194183 : Time 280.81s : 13147.32 words/s
[2019-08-07 19:30:34] Ep. 2 : Up. 68000 : Sen. 1,282,442 : Cost 65.85050201 : Time 278.05s : 13269.26 words/s
[2019-08-07 19:35:11] Ep. 2 : Up. 70000 : Sen. 1,487,161 : Cost 65.10974884 : Time 276.78s : 13347.84 words/s
[2019-08-07 19:39:49] Ep. 2 : Up. 72000 : Sen. 1,691,247 : Cost 65.49651337 : Time 278.06s : 13324.30 words/s
[2019-08-07 19:44:26] Ep. 2 : Up. 74000 : Sen. 1,895,677 : Cost 65.03797150 : Time 277.16s : 13327.24 words/s
[2019-08-07 19:49:04] Ep. 2 : Up. 76000 : Sen. 2,100,604 : Cost 64.78180695 : Time 277.55s : 13375.53 words/s
[2019-08-07 19:53:42] Ep. 2 : Up. 78000 : Sen. 2,305,003 : Cost 64.95313263 : Time 277.95s : 13345.22 words/s
[2019-08-07 19:58:20] Ep. 2 : Up. 80000 : Sen. 2,509,051 : Cost 64.92472839 : Time 278.12s : 13327.74 words/s
[2019-08-07 19:58:20] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-07 19:58:25] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter80000.npz
[2019-08-07 19:58:27] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-07 19:58:31] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-07 19:58:48] [valid] Ep. 2 : Up. 80000 : cross-entropy : 66.8104 : new best
[2019-08-07 19:58:54] [valid] Ep. 2 : Up. 80000 : perplexity : 13.9094 : new best
[2019-08-07 19:59:44] [valid] Ep. 2 : Up. 80000 : translation : 21.55 : new best
[2019-08-07 20:04:26] Ep. 2 : Up. 82000 : Sen. 2,713,444 : Cost 64.49444580 : Time 366.48s : 10106.37 words/s
[2019-08-07 20:09:07] Ep. 2 : Up. 84000 : Sen. 2,917,454 : Cost 64.39985657 : Time 281.10s : 13153.72 words/s
[2019-08-07 20:13:48] Ep. 2 : Up. 86000 : Sen. 3,122,602 : Cost 64.28857422 : Time 280.67s : 13238.24 words/s
[2019-08-07 20:18:28] Ep. 2 : Up. 88000 : Sen. 3,326,865 : Cost 64.10884857 : Time 279.94s : 13223.95 words/s
[2019-08-07 20:23:09] Ep. 2 : Up. 90000 : Sen. 3,530,671 : Cost 63.90105438 : Time 280.81s : 13135.90 words/s
[2019-08-07 20:27:47] Ep. 2 : Up. 92000 : Sen. 3,734,229 : Cost 63.66046524 : Time 278.53s : 13256.01 words/s
[2019-08-07 20:32:27] Ep. 2 : Up. 94000 : Sen. 3,937,856 : Cost 63.60860443 : Time 280.01s : 13151.17 words/s
[2019-08-07 20:37:07] Ep. 2 : Up. 96000 : Sen. 4,142,912 : Cost 63.64959335 : Time 279.57s : 13299.10 words/s
[2019-08-07 20:41:44] Ep. 2 : Up. 98000 : Sen. 4,346,838 : Cost 63.45573425 : Time 277.53s : 13315.79 words/s
[2019-08-07 20:46:21] Ep. 2 : Up. 100000 : Sen. 4,551,904 : Cost 63.24118423 : Time 277.01s : 13381.65 words/s
[2019-08-07 20:46:21] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-07 20:46:26] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter100000.npz
[2019-08-07 20:46:28] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-07 20:46:33] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-07 20:46:50] [valid] Ep. 2 : Up. 100000 : cross-entropy : 63.9412 : new best
[2019-08-07 20:46:57] [valid] Ep. 2 : Up. 100000 : perplexity : 12.4225 : new best
[2019-08-07 20:47:46] [valid] Ep. 2 : Up. 100000 : translation : 22.39 : new best
[2019-08-07 20:52:27] Ep. 2 : Up. 102000 : Sen. 4,755,294 : Cost 63.32041550 : Time 365.72s : 10080.88 words/s
[2019-08-07 20:57:08] Ep. 2 : Up. 104000 : Sen. 4,960,283 : Cost 63.03386688 : Time 280.93s : 13206.12 words/s
[2019-08-07 21:01:47] Ep. 2 : Up. 106000 : Sen. 5,163,513 : Cost 62.70606232 : Time 278.71s : 13190.22 words/s
[2019-08-07 21:06:27] Ep. 2 : Up. 108000 : Sen. 5,367,226 : Cost 62.87795639 : Time 279.82s : 13194.61 words/s
[2019-08-07 21:11:04] Ep. 2 : Up. 110000 : Sen. 5,571,497 : Cost 62.56291962 : Time 277.14s : 13354.03 words/s
[2019-08-07 21:13:04] Seen 5659635 samples
[2019-08-07 21:13:04] Starting epoch 3
[2019-08-07 21:13:04] [data] Shuffling data
[2019-08-07 21:13:07] [data] Done reading 6422600 sentences
[2019-08-07 21:13:33] [data] Done shuffling 6422600 sentences to temp files
[2019-08-07 21:16:11] Ep. 3 : Up. 112000 : Sen. 115,698 : Cost 62.22626114 : Time 306.81s : 12049.92 words/s
[2019-08-07 21:20:49] Ep. 3 : Up. 114000 : Sen. 320,000 : Cost 61.50722122 : Time 278.42s : 13310.52 words/s
[2019-08-07 21:25:26] Ep. 3 : Up. 116000 : Sen. 523,481 : Cost 61.66302872 : Time 276.58s : 13355.27 words/s
[2019-08-07 21:30:02] Ep. 3 : Up. 118000 : Sen. 727,225 : Cost 61.21812820 : Time 276.78s : 13322.57 words/s
[2019-08-07 21:34:39] Ep. 3 : Up. 120000 : Sen. 931,541 : Cost 61.25511932 : Time 276.78s : 13344.17 words/s
[2019-08-07 21:34:39] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-07 21:34:44] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter120000.npz
[2019-08-07 21:34:46] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-07 21:34:51] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-07 21:35:08] [valid] Ep. 3 : Up. 120000 : cross-entropy : 61.8582 : new best
[2019-08-07 21:35:14] [valid] Ep. 3 : Up. 120000 : perplexity : 11.4436 : new best
[2019-08-07 21:36:03] [valid] Ep. 3 : Up. 120000 : translation : 22.76 : new best
[2019-08-07 21:40:43] Ep. 3 : Up. 122000 : Sen. 1,135,446 : Cost 61.55607605 : Time 363.54s : 10186.18 words/s
[2019-08-07 21:45:20] Ep. 3 : Up. 124000 : Sen. 1,340,002 : Cost 60.90707779 : Time 277.06s : 13319.66 words/s
[2019-08-07 21:49:58] Ep. 3 : Up. 126000 : Sen. 1,544,282 : Cost 61.43835068 : Time 278.28s : 13335.55 words/s
[2019-08-07 21:54:35] Ep. 3 : Up. 128000 : Sen. 1,748,396 : Cost 60.96976852 : Time 277.10s : 13300.89 words/s
[2019-08-07 21:59:11] Ep. 3 : Up. 130000 : Sen. 1,952,275 : Cost 60.97233963 : Time 276.12s : 13356.78 words/s
[2019-08-07 22:03:49] Ep. 3 : Up. 132000 : Sen. 2,156,046 : Cost 61.17733765 : Time 277.71s : 13344.28 words/s
[2019-08-07 22:08:24] Ep. 3 : Up. 134000 : Sen. 2,359,363 : Cost 60.87052155 : Time 275.41s : 13349.11 words/s
[2019-08-07 22:13:01] Ep. 3 : Up. 136000 : Sen. 2,563,625 : Cost 60.96815491 : Time 276.81s : 13367.24 words/s
[2019-08-07 22:17:42] Ep. 3 : Up. 138000 : Sen. 2,767,429 : Cost 60.85897064 : Time 280.75s : 13146.27 words/s
[2019-08-07 22:22:22] Ep. 3 : Up. 140000 : Sen. 2,972,043 : Cost 60.85296631 : Time 279.89s : 13240.67 words/s
[2019-08-07 22:22:22] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-07 22:22:27] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter140000.npz
[2019-08-07 22:22:29] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-07 22:22:34] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-07 22:22:51] [valid] Ep. 3 : Up. 140000 : cross-entropy : 60.4667 : new best
[2019-08-07 22:22:57] [valid] Ep. 3 : Up. 140000 : perplexity : 10.833 : new best
[2019-08-07 22:23:46] [valid] Ep. 3 : Up. 140000 : translation : 22.95 : new best
[2019-08-07 22:28:26] Ep. 3 : Up. 142000 : Sen. 3,176,591 : Cost 60.45271683 : Time 364.23s : 10130.70 words/s
[2019-08-07 22:33:07] Ep. 3 : Up. 144000 : Sen. 3,381,036 : Cost 60.67017365 : Time 280.58s : 13200.97 words/s
[2019-08-07 22:37:47] Ep. 3 : Up. 146000 : Sen. 3,584,000 : Cost 60.72087479 : Time 280.18s : 13144.66 words/s
[2019-08-07 22:42:26] Ep. 3 : Up. 148000 : Sen. 3,788,280 : Cost 60.72231674 : Time 279.61s : 13231.37 words/s
[2019-08-07 22:47:07] Ep. 3 : Up. 150000 : Sen. 3,992,071 : Cost 60.78530121 : Time 280.90s : 13178.99 words/s
[2019-08-07 22:51:48] Ep. 3 : Up. 152000 : Sen. 4,197,141 : Cost 60.27970505 : Time 280.29s : 13220.16 words/s
[2019-08-07 22:56:28] Ep. 3 : Up. 154000 : Sen. 4,401,286 : Cost 60.54340363 : Time 280.15s : 13186.94 words/s
[2019-08-07 23:01:08] Ep. 3 : Up. 156000 : Sen. 4,605,554 : Cost 60.16277313 : Time 279.80s : 13180.41 words/s
[2019-08-07 23:05:46] Ep. 3 : Up. 158000 : Sen. 4,809,555 : Cost 60.39013672 : Time 278.58s : 13298.54 words/s
[2019-08-07 23:10:24] Ep. 3 : Up. 160000 : Sen. 5,014,245 : Cost 59.95265961 : Time 277.77s : 13319.50 words/s
[2019-08-07 23:10:24] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-07 23:10:29] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter160000.npz
[2019-08-07 23:10:31] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-07 23:10:36] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-07 23:10:54] [valid] Ep. 3 : Up. 160000 : cross-entropy : 59.313 : new best
[2019-08-07 23:11:00] [valid] Ep. 3 : Up. 160000 : perplexity : 10.3516 : new best
[2019-08-07 23:11:49] [valid] Ep. 3 : Up. 160000 : translation : 23.4 : new best
[2019-08-07 23:16:31] Ep. 3 : Up. 162000 : Sen. 5,218,630 : Cost 59.98289108 : Time 367.33s : 10074.39 words/s
[2019-08-07 23:21:11] Ep. 3 : Up. 164000 : Sen. 5,422,662 : Cost 60.18561172 : Time 279.76s : 13186.80 words/s
[2019-08-07 23:25:52] Ep. 3 : Up. 166000 : Sen. 5,626,583 : Cost 60.26913452 : Time 280.92s : 13201.50 words/s
[2019-08-07 23:26:38] Seen 5659635 samples
[2019-08-07 23:26:38] Starting epoch 4
[2019-08-07 23:26:38] [data] Shuffling data
[2019-08-07 23:26:41] [data] Done reading 6422600 sentences
[2019-08-07 23:27:07] [data] Done shuffling 6422600 sentences to temp files
[2019-08-07 23:31:02] Ep. 4 : Up. 168000 : Sen. 170,928 : Cost 58.94187546 : Time 310.49s : 11907.83 words/s
[2019-08-07 23:35:40] Ep. 4 : Up. 170000 : Sen. 374,106 : Cost 58.68397522 : Time 277.87s : 13247.23 words/s
[2019-08-07 23:40:18] Ep. 4 : Up. 172000 : Sen. 579,556 : Cost 58.74603653 : Time 277.92s : 13347.02 words/s
[2019-08-07 23:44:55] Ep. 4 : Up. 174000 : Sen. 783,348 : Cost 59.13706970 : Time 277.03s : 13332.70 words/s
[2019-08-07 23:49:33] Ep. 4 : Up. 176000 : Sen. 987,261 : Cost 59.00426102 : Time 278.01s : 13276.86 words/s
[2019-08-07 23:54:12] Ep. 4 : Up. 178000 : Sen. 1,191,453 : Cost 59.15493393 : Time 278.26s : 13292.51 words/s
[2019-08-07 23:58:51] Ep. 4 : Up. 180000 : Sen. 1,395,200 : Cost 59.35109329 : Time 279.32s : 13274.02 words/s
[2019-08-07 23:58:51] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-07 23:58:56] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter180000.npz
[2019-08-07 23:58:58] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-07 23:59:03] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-07 23:59:21] [valid] Ep. 4 : Up. 180000 : cross-entropy : 58.5267 : new best
[2019-08-07 23:59:27] [valid] Ep. 4 : Up. 180000 : perplexity : 10.0358 : new best
[2019-08-08 00:00:17] [valid] Ep. 4 : Up. 180000 : translation : 23.34 : stalled 1 times (last best: 23.4)
[2019-08-08 00:04:55] Ep. 4 : Up. 182000 : Sen. 1,598,485 : Cost 58.86418152 : Time 364.34s : 10106.64 words/s
[2019-08-08 00:09:32] Ep. 4 : Up. 184000 : Sen. 1,802,296 : Cost 58.89081955 : Time 276.85s : 13327.53 words/s
[2019-08-08 00:14:09] Ep. 4 : Up. 186000 : Sen. 2,006,398 : Cost 58.94985199 : Time 276.77s : 13364.32 words/s
[2019-08-08 00:18:46] Ep. 4 : Up. 188000 : Sen. 2,210,787 : Cost 58.81658173 : Time 276.82s : 13331.36 words/s
[2019-08-08 00:23:23] Ep. 4 : Up. 190000 : Sen. 2,415,042 : Cost 59.01067352 : Time 277.50s : 13331.06 words/s
[2019-08-08 00:28:00] Ep. 4 : Up. 192000 : Sen. 2,619,156 : Cost 58.71303940 : Time 276.99s : 13322.68 words/s
[2019-08-08 00:32:38] Ep. 4 : Up. 194000 : Sen. 2,822,925 : Cost 59.02649689 : Time 277.94s : 13309.03 words/s
[2019-08-08 00:37:16] Ep. 4 : Up. 196000 : Sen. 3,027,278 : Cost 58.74988937 : Time 278.06s : 13309.97 words/s
[2019-08-08 00:41:54] Ep. 4 : Up. 198000 : Sen. 3,232,256 : Cost 58.73718262 : Time 278.30s : 13330.49 words/s
[2019-08-08 00:46:32] Ep. 4 : Up. 200000 : Sen. 3,436,399 : Cost 58.63001251 : Time 277.65s : 13317.84 words/s
[2019-08-08 00:46:32] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-08 00:46:37] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter200000.npz
[2019-08-08 00:46:39] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-08 00:46:44] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-08 00:47:01] [valid] Ep. 4 : Up. 200000 : cross-entropy : 57.8774 : new best
[2019-08-08 00:47:07] [valid] Ep. 4 : Up. 200000 : perplexity : 9.78226 : new best
[2019-08-08 00:47:57] [valid] Ep. 4 : Up. 200000 : translation : 23.78 : new best
[2019-08-08 00:52:35] Ep. 4 : Up. 202000 : Sen. 3,640,556 : Cost 58.75719833 : Time 362.99s : 10187.05 words/s
[2019-08-08 00:57:12] Ep. 4 : Up. 204000 : Sen. 3,845,596 : Cost 58.43033218 : Time 277.19s : 13348.12 words/s
[2019-08-08 01:01:51] Ep. 4 : Up. 206000 : Sen. 4,049,795 : Cost 58.92232513 : Time 278.28s : 13340.51 words/s
[2019-08-08 01:06:28] Ep. 4 : Up. 208000 : Sen. 4,254,022 : Cost 58.35447311 : Time 277.33s : 13302.10 words/s
[2019-08-08 01:11:06] Ep. 4 : Up. 210000 : Sen. 4,458,480 : Cost 58.56824875 : Time 277.89s : 13326.42 words/s
[2019-08-08 01:15:43] Ep. 4 : Up. 212000 : Sen. 4,662,967 : Cost 58.61995697 : Time 277.63s : 13369.09 words/s
[2019-08-08 01:20:21] Ep. 4 : Up. 214000 : Sen. 4,867,252 : Cost 58.68523407 : Time 277.18s : 13358.09 words/s
[2019-08-08 01:24:57] Ep. 4 : Up. 216000 : Sen. 5,071,450 : Cost 58.29913712 : Time 276.65s : 13328.10 words/s
[2019-08-08 01:29:34] Ep. 4 : Up. 218000 : Sen. 5,274,787 : Cost 58.76934433 : Time 277.28s : 13343.07 words/s
[2019-08-08 01:34:12] Ep. 4 : Up. 220000 : Sen. 5,479,448 : Cost 58.32061768 : Time 277.87s : 13310.26 words/s
[2019-08-08 01:34:12] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-08 01:34:17] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter220000.npz
[2019-08-08 01:34:19] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-08 01:34:24] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-08 01:34:43] [valid] Ep. 4 : Up. 220000 : cross-entropy : 57.2126 : new best
[2019-08-08 01:34:49] [valid] Ep. 4 : Up. 220000 : perplexity : 9.52933 : new best
[2019-08-08 01:35:38] [valid] Ep. 4 : Up. 220000 : translation : 23.84 : new best
[2019-08-08 01:39:46] Seen 5659635 samples
[2019-08-08 01:39:46] Starting epoch 5
[2019-08-08 01:39:46] [data] Shuffling data
[2019-08-08 01:39:49] [data] Done reading 6422600 sentences
[2019-08-08 01:40:16] [data] Done shuffling 6422600 sentences to temp files
[2019-08-08 01:40:49] Ep. 5 : Up. 222000 : Sen. 23,871 : Cost 58.17105103 : Time 396.42s : 9309.41 words/s
[2019-08-08 01:45:29] Ep. 5 : Up. 224000 : Sen. 227,381 : Cost 57.56866837 : Time 279.94s : 13194.25 words/s
[2019-08-08 01:50:09] Ep. 5 : Up. 226000 : Sen. 430,274 : Cost 57.40487671 : Time 280.28s : 13145.31 words/s
[2019-08-08 01:54:49] Ep. 5 : Up. 228000 : Sen. 634,149 : Cost 57.36798477 : Time 280.37s : 13160.82 words/s
[2019-08-08 01:59:30] Ep. 5 : Up. 230000 : Sen. 838,712 : Cost 57.44535446 : Time 280.33s : 13192.61 words/s
[2019-08-08 02:04:10] Ep. 5 : Up. 232000 : Sen. 1,043,012 : Cost 57.09452438 : Time 279.93s : 13212.68 words/s
[2019-08-08 02:08:50] Ep. 5 : Up. 234000 : Sen. 1,248,000 : Cost 57.11612320 : Time 280.45s : 13221.59 words/s
[2019-08-08 02:13:27] Ep. 5 : Up. 236000 : Sen. 1,451,402 : Cost 57.62118530 : Time 276.56s : 13324.43 words/s
[2019-08-08 02:18:04] Ep. 5 : Up. 238000 : Sen. 1,655,448 : Cost 57.45799637 : Time 277.39s : 13321.78 words/s
[2019-08-08 02:22:42] Ep. 5 : Up. 240000 : Sen. 1,859,993 : Cost 57.30937958 : Time 278.39s : 13283.83 words/s
[2019-08-08 02:22:42] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-08 02:22:48] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter240000.npz
[2019-08-08 02:22:50] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-08 02:22:55] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-08 02:23:14] [valid] Ep. 5 : Up. 240000 : cross-entropy : 56.9007 : new best
[2019-08-08 02:23:20] [valid] Ep. 5 : Up. 240000 : perplexity : 9.41297 : new best
[2019-08-08 02:24:11] [valid] Ep. 5 : Up. 240000 : translation : 23.8 : stalled 1 times (last best: 23.84)
[2019-08-08 02:28:51] Ep. 5 : Up. 242000 : Sen. 2,064,244 : Cost 57.52427292 : Time 368.32s : 10058.64 words/s
[2019-08-08 02:33:27] Ep. 5 : Up. 244000 : Sen. 2,268,752 : Cost 57.58734512 : Time 276.45s : 13408.99 words/s
[2019-08-08 02:38:06] Ep. 5 : Up. 246000 : Sen. 2,472,995 : Cost 57.59376907 : Time 278.89s : 13264.58 words/s
[2019-08-08 02:42:46] Ep. 5 : Up. 248000 : Sen. 2,677,218 : Cost 57.65316010 : Time 280.09s : 13195.93 words/s
[2019-08-08 02:47:26] Ep. 5 : Up. 250000 : Sen. 2,881,229 : Cost 57.54298401 : Time 279.53s : 13206.07 words/s
[2019-08-08 02:52:05] Ep. 5 : Up. 252000 : Sen. 3,084,469 : Cost 57.64505386 : Time 279.76s : 13188.36 words/s
[2019-08-08 02:56:45] Ep. 5 : Up. 254000 : Sen. 3,288,942 : Cost 57.50348282 : Time 279.78s : 13272.55 words/s
[2019-08-08 03:01:24] Ep. 5 : Up. 256000 : Sen. 3,493,372 : Cost 57.43278503 : Time 278.76s : 13254.85 words/s
[2019-08-08 03:06:01] Ep. 5 : Up. 258000 : Sen. 3,697,091 : Cost 57.55590439 : Time 277.08s : 13324.01 words/s
[2019-08-08 03:10:39] Ep. 5 : Up. 260000 : Sen. 3,902,563 : Cost 57.24344254 : Time 278.29s : 13371.88 words/s
[2019-08-08 03:10:39] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-08 03:10:45] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter260000.npz
[2019-08-08 03:10:48] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-08 03:10:54] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-08 03:11:14] [valid] Ep. 5 : Up. 260000 : cross-entropy : 56.4979 : new best
[2019-08-08 03:11:20] [valid] Ep. 5 : Up. 260000 : perplexity : 9.26473 : new best
[2019-08-08 03:12:10] [valid] Ep. 5 : Up. 260000 : translation : 23.75 : stalled 2 times (last best: 23.84)
[2019-08-08 03:16:48] Ep. 5 : Up. 262000 : Sen. 4,105,472 : Cost 57.37021637 : Time 368.55s : 9969.23 words/s
[2019-08-08 03:21:25] Ep. 5 : Up. 264000 : Sen. 4,309,834 : Cost 57.29531479 : Time 276.92s : 13360.19 words/s
[2019-08-08 03:26:01] Ep. 5 : Up. 266000 : Sen. 4,513,927 : Cost 57.38137054 : Time 276.12s : 13388.23 words/s
[2019-08-08 03:30:37] Ep. 5 : Up. 268000 : Sen. 4,718,905 : Cost 56.92465591 : Time 276.53s : 13380.03 words/s
[2019-08-08 03:35:13] Ep. 5 : Up. 270000 : Sen. 4,921,967 : Cost 57.61118317 : Time 275.96s : 13355.86 words/s
[2019-08-08 03:39:50] Ep. 5 : Up. 272000 : Sen. 5,126,400 : Cost 57.46583939 : Time 276.52s : 13392.30 words/s
[2019-08-08 03:44:27] Ep. 5 : Up. 274000 : Sen. 5,330,575 : Cost 57.30328751 : Time 276.99s : 13372.09 words/s
[2019-08-08 03:49:03] Ep. 5 : Up. 276000 : Sen. 5,534,471 : Cost 57.17090225 : Time 276.16s : 13353.28 words/s
[2019-08-08 03:51:53] Seen 5659635 samples
[2019-08-08 03:51:53] Starting epoch 6
[2019-08-08 03:51:53] [data] Shuffling data
[2019-08-08 03:51:56] [data] Done reading 6422600 sentences
[2019-08-08 03:52:24] [data] Done shuffling 6422600 sentences to temp files
[2019-08-08 03:54:12] Ep. 6 : Up. 278000 : Sen. 79,041 : Cost 56.88346100 : Time 309.28s : 11949.35 words/s
[2019-08-08 03:58:49] Ep. 6 : Up. 280000 : Sen. 284,064 : Cost 55.79027176 : Time 276.14s : 13395.13 words/s
[2019-08-08 03:58:49] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-08 03:58:54] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter280000.npz
[2019-08-08 03:58:56] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-08 03:59:00] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-08 03:59:18] [valid] Ep. 6 : Up. 280000 : cross-entropy : 56.1685 : new best
[2019-08-08 03:59:24] [valid] Ep. 6 : Up. 280000 : perplexity : 9.14524 : new best
[2019-08-08 04:00:14] [valid] Ep. 6 : Up. 280000 : translation : 23.7 : stalled 3 times (last best: 23.84)
[2019-08-08 04:04:52] Ep. 6 : Up. 282000 : Sen. 487,868 : Cost 56.60576248 : Time 363.89s : 10182.52 words/s
[2019-08-08 04:09:29] Ep. 6 : Up. 284000 : Sen. 692,042 : Cost 56.25071716 : Time 276.63s : 13356.96 words/s
[2019-08-08 04:14:05] Ep. 6 : Up. 286000 : Sen. 896,000 : Cost 56.17712784 : Time 276.16s : 13377.14 words/s
[2019-08-08 04:18:42] Ep. 6 : Up. 288000 : Sen. 1,100,878 : Cost 56.21896362 : Time 277.17s : 13387.02 words/s
[2019-08-08 04:23:19] Ep. 6 : Up. 290000 : Sen. 1,304,513 : Cost 56.20523071 : Time 276.35s : 13348.15 words/s
[2019-08-08 04:27:56] Ep. 6 : Up. 292000 : Sen. 1,508,706 : Cost 56.64040756 : Time 276.96s : 13379.82 words/s
[2019-08-08 04:32:32] Ep. 6 : Up. 294000 : Sen. 1,713,412 : Cost 56.18762589 : Time 276.73s : 13373.98 words/s
[2019-08-08 04:37:09] Ep. 6 : Up. 296000 : Sen. 1,918,230 : Cost 56.08220291 : Time 277.04s : 13373.80 words/s
[2019-08-08 04:41:46] Ep. 6 : Up. 298000 : Sen. 2,122,000 : Cost 56.59684372 : Time 276.72s : 13379.98 words/s
[2019-08-08 04:46:22] Ep. 6 : Up. 300000 : Sen. 2,326,336 : Cost 56.49674225 : Time 275.55s : 13397.32 words/s
[2019-08-08 04:46:22] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-08 04:46:27] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter300000.npz
[2019-08-08 04:46:29] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-08 04:46:34] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-08 04:46:52] [valid] Ep. 6 : Up. 300000 : cross-entropy : 56.0023 : new best
[2019-08-08 04:46:58] [valid] Ep. 6 : Up. 300000 : perplexity : 9.08557 : new best
[2019-08-08 04:47:47] [valid] Ep. 6 : Up. 300000 : translation : 24.1 : new best
[2019-08-08 04:52:26] Ep. 6 : Up. 302000 : Sen. 2,530,136 : Cost 56.93342590 : Time 364.56s : 10168.15 words/s
[2019-08-08 04:57:02] Ep. 6 : Up. 304000 : Sen. 2,734,203 : Cost 56.65591812 : Time 276.06s : 13420.98 words/s
[2019-08-08 05:01:38] Ep. 6 : Up. 306000 : Sen. 2,938,095 : Cost 56.26814651 : Time 275.63s : 13375.02 words/s
[2019-08-08 05:06:14] Ep. 6 : Up. 308000 : Sen. 3,142,400 : Cost 56.49306488 : Time 276.32s : 13372.69 words/s
[2019-08-08 05:10:51] Ep. 6 : Up. 310000 : Sen. 3,346,744 : Cost 56.65831757 : Time 276.44s : 13383.00 words/s
[2019-08-08 05:15:28] Ep. 6 : Up. 312000 : Sen. 3,551,322 : Cost 56.58197784 : Time 276.86s : 13371.15 words/s
[2019-08-08 05:20:03] Ep. 6 : Up. 314000 : Sen. 3,754,983 : Cost 56.48676300 : Time 275.80s : 13396.22 words/s
[2019-08-08 05:24:39] Ep. 6 : Up. 316000 : Sen. 3,958,604 : Cost 56.42246628 : Time 275.94s : 13354.43 words/s
[2019-08-08 05:29:16] Ep. 6 : Up. 318000 : Sen. 4,163,562 : Cost 56.42163849 : Time 276.69s : 13394.66 words/s
[2019-08-08 05:33:52] Ep. 6 : Up. 320000 : Sen. 4,368,936 : Cost 56.27741241 : Time 276.03s : 13446.55 words/s
[2019-08-08 05:33:52] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-08 05:33:58] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter320000.npz
[2019-08-08 05:34:00] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-08 05:34:05] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-08 05:34:23] [valid] Ep. 6 : Up. 320000 : cross-entropy : 55.6914 : new best
[2019-08-08 05:34:30] [valid] Ep. 6 : Up. 320000 : perplexity : 8.97494 : new best
[2019-08-08 05:35:19] [valid] Ep. 6 : Up. 320000 : translation : 23.87 : stalled 1 times (last best: 24.1)
[2019-08-08 05:39:59] Ep. 6 : Up. 322000 : Sen. 4,571,823 : Cost 56.62470627 : Time 366.88s : 10052.47 words/s
[2019-08-08 05:44:37] Ep. 6 : Up. 324000 : Sen. 4,775,646 : Cost 56.44025040 : Time 278.36s : 13262.68 words/s
[2019-08-08 05:49:16] Ep. 6 : Up. 326000 : Sen. 4,979,968 : Cost 56.29436493 : Time 278.65s : 13264.04 words/s
[2019-08-08 05:53:54] Ep. 6 : Up. 328000 : Sen. 5,184,390 : Cost 56.62565231 : Time 277.85s : 13335.42 words/s
[2019-08-08 05:58:29] Ep. 6 : Up. 330000 : Sen. 5,388,059 : Cost 56.63521194 : Time 274.85s : 13413.40 words/s
[2019-08-08 06:03:05] Ep. 6 : Up. 332000 : Sen. 5,591,838 : Cost 56.46800613 : Time 276.41s : 13389.16 words/s
[2019-08-08 06:04:36] Seen 5659635 samples
[2019-08-08 06:04:36] Starting epoch 7
[2019-08-08 06:04:36] [data] Shuffling data
[2019-08-08 06:04:39] [data] Done reading 6422600 sentences
[2019-08-08 06:05:08] [data] Done shuffling 6422600 sentences to temp files
[2019-08-08 06:08:13] Ep. 7 : Up. 334000 : Sen. 137,304 : Cost 55.22605133 : Time 307.88s : 11981.98 words/s
[2019-08-08 06:12:50] Ep. 7 : Up. 336000 : Sen. 342,253 : Cost 55.27497101 : Time 276.81s : 13389.35 words/s
[2019-08-08 06:17:26] Ep. 7 : Up. 338000 : Sen. 546,265 : Cost 55.55164719 : Time 276.09s : 13424.87 words/s
[2019-08-08 06:22:02] Ep. 7 : Up. 340000 : Sen. 750,361 : Cost 55.56718826 : Time 276.06s : 13404.48 words/s
[2019-08-08 06:22:02] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-08 06:22:08] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter340000.npz
[2019-08-08 06:22:10] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-08 06:22:16] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-08 06:22:35] [valid] Ep. 7 : Up. 340000 : cross-entropy : 55.5463 : new best
[2019-08-08 06:22:41] [valid] Ep. 7 : Up. 340000 : perplexity : 8.92377 : new best
[2019-08-08 06:23:31] [valid] Ep. 7 : Up. 340000 : translation : 23.78 : stalled 2 times (last best: 24.1)
[2019-08-08 06:28:11] Ep. 7 : Up. 342000 : Sen. 955,530 : Cost 55.32789230 : Time 368.85s : 10042.37 words/s
[2019-08-08 06:32:48] Ep. 7 : Up. 344000 : Sen. 1,159,620 : Cost 55.69664383 : Time 276.93s : 13377.47 words/s
[2019-08-08 06:37:26] Ep. 7 : Up. 346000 : Sen. 1,364,520 : Cost 55.38637924 : Time 278.11s : 13321.78 words/s
[2019-08-08 06:42:04] Ep. 7 : Up. 348000 : Sen. 1,568,456 : Cost 55.65425873 : Time 278.60s : 13303.37 words/s
[2019-08-08 06:46:41] Ep. 7 : Up. 350000 : Sen. 1,772,639 : Cost 55.59386444 : Time 277.00s : 13348.47 words/s
[2019-08-08 06:51:18] Ep. 7 : Up. 352000 : Sen. 1,977,288 : Cost 55.57501221 : Time 276.88s : 13382.46 words/s
[2019-08-08 06:55:56] Ep. 7 : Up. 354000 : Sen. 2,181,219 : Cost 55.88722610 : Time 277.52s : 13330.94 words/s
[2019-08-08 07:00:33] Ep. 7 : Up. 356000 : Sen. 2,385,644 : Cost 55.68843460 : Time 277.41s : 13356.25 words/s
[2019-08-08 07:05:10] Ep. 7 : Up. 358000 : Sen. 2,589,732 : Cost 55.38400269 : Time 276.66s : 13347.68 words/s
[2019-08-08 07:09:47] Ep. 7 : Up. 360000 : Sen. 2,793,769 : Cost 55.85069275 : Time 276.76s : 13354.93 words/s
[2019-08-08 07:09:47] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-08 07:09:52] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter360000.npz
[2019-08-08 07:09:55] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-08 07:10:00] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-08 07:10:18] [valid] Ep. 7 : Up. 360000 : cross-entropy : 55.4362 : new best
[2019-08-08 07:10:24] [valid] Ep. 7 : Up. 360000 : perplexity : 8.88514 : new best
[2019-08-08 07:11:16] [valid] Ep. 7 : Up. 360000 : translation : 24.19 : new best
[2019-08-08 07:15:56] Ep. 7 : Up. 362000 : Sen. 2,998,037 : Cost 55.76465607 : Time 369.21s : 10010.49 words/s
[2019-08-08 07:20:32] Ep. 7 : Up. 364000 : Sen. 3,201,461 : Cost 55.89865494 : Time 276.59s : 13338.92 words/s
[2019-08-08 07:25:09] Ep. 7 : Up. 366000 : Sen. 3,406,261 : Cost 55.67580414 : Time 277.02s : 13356.75 words/s
[2019-08-08 07:29:46] Ep. 7 : Up. 368000 : Sen. 3,609,930 : Cost 55.82897186 : Time 276.24s : 13376.68 words/s
[2019-08-08 07:34:21] Ep. 7 : Up. 370000 : Sen. 3,814,244 : Cost 55.68720245 : Time 275.77s : 13413.63 words/s
[2019-08-08 07:38:58] Ep. 7 : Up. 372000 : Sen. 4,017,658 : Cost 55.76504898 : Time 276.57s : 13319.17 words/s
[2019-08-08 07:43:35] Ep. 7 : Up. 374000 : Sen. 4,222,558 : Cost 55.61101532 : Time 277.10s : 13368.55 words/s
[2019-08-08 07:48:11] Ep. 7 : Up. 376000 : Sen. 4,427,107 : Cost 55.88747787 : Time 275.68s : 13468.62 words/s
[2019-08-08 07:52:44] Ep. 7 : Up. 378000 : Sen. 4,630,383 : Cost 55.73529434 : Time 273.30s : 13451.65 words/s
[2019-08-08 07:57:19] Ep. 7 : Up. 380000 : Sen. 4,834,590 : Cost 55.85594177 : Time 275.15s : 13452.96 words/s
[2019-08-08 07:57:19] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-08 07:57:25] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter380000.npz
[2019-08-08 07:57:28] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-08 07:57:34] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-08 07:57:54] [valid] Ep. 7 : Up. 380000 : cross-entropy : 55.1444 : new best
[2019-08-08 07:58:00] [valid] Ep. 7 : Up. 380000 : perplexity : 8.78355 : new best
[2019-08-08 07:58:49] [valid] Ep. 7 : Up. 380000 : translation : 23.94 : stalled 1 times (last best: 24.19)
[2019-08-08 08:03:26] Ep. 7 : Up. 382000 : Sen. 5,039,189 : Cost 55.50357437 : Time 366.82s : 10053.18 words/s
[2019-08-08 08:08:00] Ep. 7 : Up. 384000 : Sen. 5,242,429 : Cost 55.82814026 : Time 274.17s : 13426.19 words/s
[2019-08-08 08:12:36] Ep. 7 : Up. 386000 : Sen. 5,446,691 : Cost 55.81555176 : Time 275.53s : 13463.98 words/s
[2019-08-08 08:17:10] Ep. 7 : Up. 388000 : Sen. 5,650,100 : Cost 55.85403824 : Time 274.60s : 13436.07 words/s
[2019-08-08 08:17:24] Seen 5659635 samples
[2019-08-08 08:17:24] Starting epoch 8
[2019-08-08 08:17:24] [data] Shuffling data
[2019-08-08 08:17:28] [data] Done reading 6422600 sentences
[2019-08-08 08:17:58] [data] Done shuffling 6422600 sentences to temp files
[2019-08-08 08:22:22] Ep. 8 : Up. 390000 : Sen. 193,728 : Cost 54.83848953 : Time 311.97s : 11824.17 words/s
[2019-08-08 08:26:59] Ep. 8 : Up. 392000 : Sen. 398,681 : Cost 54.71952438 : Time 276.39s : 13406.18 words/s
[2019-08-08 08:31:38] Ep. 8 : Up. 394000 : Sen. 602,987 : Cost 54.77914429 : Time 279.63s : 13226.11 words/s
[2019-08-08 08:36:18] Ep. 8 : Up. 396000 : Sen. 806,823 : Cost 54.68931961 : Time 279.19s : 13236.92 words/s
[2019-08-08 08:40:56] Ep. 8 : Up. 398000 : Sen. 1,010,697 : Cost 54.89399719 : Time 278.68s : 13241.59 words/s
[2019-08-08 08:45:36] Ep. 8 : Up. 400000 : Sen. 1,214,395 : Cost 54.91223907 : Time 279.37s : 13214.76 words/s
[2019-08-08 08:45:36] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-08 08:45:42] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter400000.npz
[2019-08-08 08:45:44] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-08 08:45:50] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-08 08:46:09] [valid] Ep. 8 : Up. 400000 : cross-entropy : 55.1143 : new best
[2019-08-08 08:46:15] [valid] Ep. 8 : Up. 400000 : perplexity : 8.77316 : new best
[2019-08-08 08:47:09] [valid] Ep. 8 : Up. 400000 : translation : 23.77 : stalled 2 times (last best: 24.19)
[2019-08-08 08:51:50] Ep. 8 : Up. 402000 : Sen. 1,418,523 : Cost 54.79901505 : Time 374.72s : 9846.11 words/s
[2019-08-08 08:56:30] Ep. 8 : Up. 404000 : Sen. 1,623,311 : Cost 54.82645798 : Time 279.37s : 13255.72 words/s
[2019-08-08 09:01:10] Ep. 8 : Up. 406000 : Sen. 1,827,828 : Cost 55.00696945 : Time 280.57s : 13191.93 words/s
[2019-08-08 09:05:50] Ep. 8 : Up. 408000 : Sen. 2,031,468 : Cost 55.16481018 : Time 280.20s : 13191.91 words/s
[2019-08-08 09:10:30] Ep. 8 : Up. 410000 : Sen. 2,235,362 : Cost 54.99880981 : Time 279.85s : 13203.37 words/s
[2019-08-08 09:15:09] Ep. 8 : Up. 412000 : Sen. 2,439,841 : Cost 55.09475327 : Time 278.98s : 13269.89 words/s
[2019-08-08 09:19:50] Ep. 8 : Up. 414000 : Sen. 2,643,200 : Cost 55.09316635 : Time 280.65s : 13128.65 words/s
[2019-08-08 09:24:29] Ep. 8 : Up. 416000 : Sen. 2,847,179 : Cost 55.23685837 : Time 279.14s : 13241.81 words/s
[2019-08-08 09:29:09] Ep. 8 : Up. 418000 : Sen. 3,050,985 : Cost 55.42373276 : Time 280.26s : 13224.25 words/s
[2019-08-08 09:33:49] Ep. 8 : Up. 420000 : Sen. 3,255,868 : Cost 55.02112961 : Time 279.18s : 13264.30 words/s
[2019-08-08 09:33:49] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-08 09:33:54] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter420000.npz
[2019-08-08 09:33:57] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-08 09:34:03] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-08 09:34:22] [valid] Ep. 8 : Up. 420000 : cross-entropy : 55.0437 : new best
[2019-08-08 09:34:29] [valid] Ep. 8 : Up. 420000 : perplexity : 8.74879 : new best
[2019-08-08 09:35:21] [valid] Ep. 8 : Up. 420000 : translation : 24.26 : new best
[2019-08-08 09:40:02] Ep. 8 : Up. 422000 : Sen. 3,459,914 : Cost 55.00401688 : Time 373.65s : 9871.50 words/s
[2019-08-08 09:44:42] Ep. 8 : Up. 424000 : Sen. 3,663,911 : Cost 55.33218765 : Time 279.93s : 13225.10 words/s
[2019-08-08 09:49:21] Ep. 8 : Up. 426000 : Sen. 3,867,351 : Cost 55.00770187 : Time 278.90s : 13205.74 words/s
[2019-08-08 09:54:02] Ep. 8 : Up. 428000 : Sen. 4,072,778 : Cost 55.32782745 : Time 281.28s : 13227.34 words/s
[2019-08-08 09:58:42] Ep. 8 : Up. 430000 : Sen. 4,277,646 : Cost 55.24229431 : Time 279.60s : 13223.24 words/s
[2019-08-08 10:03:22] Ep. 8 : Up. 432000 : Sen. 4,481,069 : Cost 55.33122635 : Time 279.69s : 13189.52 words/s
[2019-08-08 10:08:03] Ep. 8 : Up. 434000 : Sen. 4,686,379 : Cost 55.15493011 : Time 281.81s : 13193.10 words/s
[2019-08-08 10:12:44] Ep. 8 : Up. 436000 : Sen. 4,890,708 : Cost 55.06782150 : Time 280.31s : 13182.41 words/s
[2019-08-08 10:17:24] Ep. 8 : Up. 438000 : Sen. 5,094,814 : Cost 55.25841141 : Time 280.15s : 13239.08 words/s
[2019-08-08 10:22:03] Ep. 8 : Up. 440000 : Sen. 5,298,459 : Cost 55.19257355 : Time 279.14s : 13188.90 words/s
[2019-08-08 10:22:03] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-08 10:22:09] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter440000.npz
[2019-08-08 10:22:11] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-08 10:22:17] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-08 10:22:36] [valid] Ep. 8 : Up. 440000 : cross-entropy : 54.7877 : new best
[2019-08-08 10:22:43] [valid] Ep. 8 : Up. 440000 : perplexity : 8.66099 : new best
[2019-08-08 10:23:35] [valid] Ep. 8 : Up. 440000 : translation : 24.07 : stalled 1 times (last best: 24.26)
[2019-08-08 10:28:18] Ep. 8 : Up. 442000 : Sen. 5,502,790 : Cost 55.43883514 : Time 375.24s : 9888.04 words/s
[2019-08-08 10:31:54] Seen 5659635 samples
[2019-08-08 10:31:54] Starting epoch 9
[2019-08-08 10:31:54] [data] Shuffling data
[2019-08-08 10:32:00] [data] Done reading 6422600 sentences
[2019-08-08 10:32:31] [data] Done shuffling 6422600 sentences to temp files
[2019-08-08 10:33:37] Ep. 9 : Up. 444000 : Sen. 47,489 : Cost 54.75725555 : Time 318.40s : 11596.85 words/s
[2019-08-08 10:38:17] Ep. 9 : Up. 446000 : Sen. 250,748 : Cost 54.42640305 : Time 280.35s : 13161.93 words/s
[2019-08-08 10:42:58] Ep. 9 : Up. 448000 : Sen. 455,644 : Cost 54.07225800 : Time 281.35s : 13184.91 words/s
[2019-08-08 10:47:39] Ep. 9 : Up. 450000 : Sen. 659,884 : Cost 54.18840027 : Time 280.39s : 13177.04 words/s
[2019-08-08 10:52:20] Ep. 9 : Up. 452000 : Sen. 864,795 : Cost 54.29462433 : Time 281.54s : 13171.15 words/s
[2019-08-08 10:57:02] Ep. 9 : Up. 454000 : Sen. 1,068,644 : Cost 54.64724731 : Time 281.29s : 13134.11 words/s
[2019-08-08 11:01:42] Ep. 9 : Up. 456000 : Sen. 1,272,821 : Cost 54.33553696 : Time 280.35s : 13189.69 words/s
[2019-08-08 11:06:22] Ep. 9 : Up. 458000 : Sen. 1,477,088 : Cost 54.37385941 : Time 280.22s : 13188.72 words/s
[2019-08-08 11:11:02] Ep. 9 : Up. 460000 : Sen. 1,680,750 : Cost 54.53975677 : Time 280.24s : 13195.39 words/s
[2019-08-08 11:11:02] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-08 11:11:08] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter460000.npz
[2019-08-08 11:11:11] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-08 11:11:16] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-08 11:11:35] [valid] Ep. 9 : Up. 460000 : cross-entropy : 54.8067 : stalled 1 times (last best: 54.7877)
[2019-08-08 11:11:41] [valid] Ep. 9 : Up. 460000 : perplexity : 8.66745 : stalled 1 times (last best: 8.66099)
[2019-08-08 11:12:35] [valid] Ep. 9 : Up. 460000 : translation : 23.63 : stalled 2 times (last best: 24.26)
[2019-08-08 11:17:16] Ep. 9 : Up. 462000 : Sen. 1,884,448 : Cost 54.28347015 : Time 374.14s : 9848.06 words/s
[2019-08-08 11:21:57] Ep. 9 : Up. 464000 : Sen. 2,088,321 : Cost 54.83999252 : Time 281.01s : 13184.15 words/s
[2019-08-08 11:26:40] Ep. 9 : Up. 466000 : Sen. 2,292,823 : Cost 54.50951767 : Time 282.31s : 13119.73 words/s
[2019-08-08 11:31:20] Ep. 9 : Up. 468000 : Sen. 2,496,436 : Cost 54.30391312 : Time 280.41s : 13152.55 words/s
[2019-08-08 11:36:02] Ep. 9 : Up. 470000 : Sen. 2,700,800 : Cost 54.83959198 : Time 281.74s : 13172.04 words/s
[2019-08-08 11:40:44] Ep. 9 : Up. 472000 : Sen. 2,905,600 : Cost 54.34300232 : Time 281.58s : 13152.18 words/s
[2019-08-08 11:45:24] Ep. 9 : Up. 474000 : Sen. 3,109,844 : Cost 54.53431702 : Time 280.25s : 13174.71 words/s
[2019-08-08 11:50:04] Ep. 9 : Up. 476000 : Sen. 3,313,884 : Cost 54.68303680 : Time 280.37s : 13182.93 words/s
[2019-08-08 11:54:45] Ep. 9 : Up. 478000 : Sen. 3,517,946 : Cost 54.61900711 : Time 280.74s : 13165.36 words/s
[2019-08-08 11:59:25] Ep. 9 : Up. 480000 : Sen. 3,721,972 : Cost 54.57348633 : Time 280.37s : 13178.63 words/s
[2019-08-08 11:59:25] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-08 11:59:31] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter480000.npz
[2019-08-08 11:59:33] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-08 11:59:40] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-08 11:59:59] [valid] Ep. 9 : Up. 480000 : cross-entropy : 54.7139 : new best
[2019-08-08 12:00:05] [valid] Ep. 9 : Up. 480000 : perplexity : 8.63581 : new best
[2019-08-08 12:00:58] [valid] Ep. 9 : Up. 480000 : translation : 24.05 : stalled 3 times (last best: 24.26)
[2019-08-08 12:05:43] Ep. 9 : Up. 482000 : Sen. 3,926,908 : Cost 54.82680893 : Time 378.09s : 9828.18 words/s
[2019-08-08 12:10:24] Ep. 9 : Up. 484000 : Sen. 4,130,449 : Cost 54.66981125 : Time 280.98s : 13122.11 words/s
[2019-08-08 12:15:05] Ep. 9 : Up. 486000 : Sen. 4,335,165 : Cost 54.61699295 : Time 281.04s : 13172.26 words/s
[2019-08-08 12:19:45] Ep. 9 : Up. 488000 : Sen. 4,538,731 : Cost 54.74699020 : Time 279.79s : 13185.53 words/s
[2019-08-08 12:24:27] Ep. 9 : Up. 490000 : Sen. 4,742,684 : Cost 54.78086090 : Time 281.38s : 13145.66 words/s
[2019-08-08 12:29:08] Ep. 9 : Up. 492000 : Sen. 4,946,969 : Cost 54.46891022 : Time 281.45s : 13122.82 words/s
[2019-08-08 12:33:51] Ep. 9 : Up. 494000 : Sen. 5,151,742 : Cost 54.64948654 : Time 282.68s : 13125.86 words/s
[2019-08-08 12:38:33] Ep. 9 : Up. 496000 : Sen. 5,355,901 : Cost 54.70377350 : Time 281.96s : 13113.89 words/s
[2019-08-08 12:43:14] Ep. 9 : Up. 498000 : Sen. 5,560,391 : Cost 54.43838882 : Time 281.61s : 13107.58 words/s
[2019-08-08 12:45:32] Seen 5659635 samples
[2019-08-08 12:45:32] Starting epoch 10
[2019-08-08 12:45:32] [data] Shuffling data
[2019-08-08 12:45:40] [data] Done reading 6422600 sentences
[2019-08-08 12:46:10] [data] Done shuffling 6422600 sentences to temp files
[2019-08-08 12:48:36] Ep. 10 : Up. 500000 : Sen. 104,892 : Cost 54.22842026 : Time 321.77s : 11510.59 words/s
[2019-08-08 12:48:36] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-08 12:48:42] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter500000.npz
[2019-08-08 12:48:44] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-08 12:48:50] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-08 12:49:09] [valid] Ep. 10 : Up. 500000 : cross-entropy : 54.4855 : new best
[2019-08-08 12:49:15] [valid] Ep. 10 : Up. 500000 : perplexity : 8.55845 : new best
[2019-08-08 12:50:08] [valid] Ep. 10 : Up. 500000 : translation : 24.24 : stalled 4 times (last best: 24.26)
[2019-08-08 12:54:54] Ep. 10 : Up. 502000 : Sen. 309,288 : Cost 53.57863235 : Time 378.19s : 9768.63 words/s
[2019-08-08 12:59:37] Ep. 10 : Up. 504000 : Sen. 513,016 : Cost 53.97942734 : Time 282.60s : 13099.22 words/s
[2019-08-08 13:04:20] Ep. 10 : Up. 506000 : Sen. 717,990 : Cost 53.93852997 : Time 283.31s : 13110.87 words/s
[2019-08-08 13:09:02] Ep. 10 : Up. 508000 : Sen. 922,454 : Cost 53.84636307 : Time 281.96s : 13145.56 words/s
[2019-08-08 13:13:44] Ep. 10 : Up. 510000 : Sen. 1,126,502 : Cost 53.88537979 : Time 281.95s : 13090.50 words/s
[2019-08-08 13:18:27] Ep. 10 : Up. 512000 : Sen. 1,330,750 : Cost 53.81088638 : Time 282.73s : 13083.50 words/s
[2019-08-08 13:23:09] Ep. 10 : Up. 514000 : Sen. 1,535,196 : Cost 53.79579544 : Time 282.11s : 13084.01 words/s
[2019-08-08 13:27:55] Ep. 10 : Up. 516000 : Sen. 1,738,240 : Cost 54.04814148 : Time 285.97s : 12897.53 words/s
[2019-08-08 13:32:38] Ep. 10 : Up. 518000 : Sen. 1,942,660 : Cost 53.82631683 : Time 283.07s : 13096.21 words/s
[2019-08-08 13:37:20] Ep. 10 : Up. 520000 : Sen. 2,145,903 : Cost 54.06534958 : Time 281.74s : 13092.22 words/s
[2019-08-08 13:37:20] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-08 13:37:25] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter520000.npz
[2019-08-08 13:37:27] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-08 13:37:33] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-08 13:37:52] [valid] Ep. 10 : Up. 520000 : cross-entropy : 54.6837 : stalled 1 times (last best: 54.4855)
[2019-08-08 13:37:59] [valid] Ep. 10 : Up. 520000 : perplexity : 8.62555 : stalled 1 times (last best: 8.55845)
[2019-08-08 13:38:52] [valid] Ep. 10 : Up. 520000 : translation : 23.81 : stalled 5 times (last best: 24.26)
[2019-08-08 22:33:53] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-08 22:33:53] [marian] Running on bil as process 190308 with command line:
[2019-08-08 22:33:53] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_random_fasttext_prob/model/model.npz -T . --devices 6 --train-sets ../experiments/100M_random_fasttext_prob/data/train.bpe.de ../experiments/100M_random_fasttext_prob/data/train.bpe.en --vocabs ../experiments/100M_random_fasttext_prob/data/train.bpe.de.json ../experiments/100M_random_fasttext_prob/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_random_fasttext_prob/data/dev.bpe.de ../experiments/100M_random_fasttext_prob/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_random_fasttext_prob/model/dev.out --valid-script-path ../experiments/100M_random_fasttext_prob/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_random_fasttext_prob/model/train.log --valid-log ../experiments/100M_random_fasttext_prob/model/valid.log
[2019-08-08 22:33:53] [config] after-batches: 0
[2019-08-08 22:33:53] [config] after-epochs: 0
[2019-08-08 22:33:53] [config] allow-unk: false
[2019-08-08 22:33:53] [config] beam-size: 12
[2019-08-08 22:33:53] [config] bert-class-symbol: "[CLS]"
[2019-08-08 22:33:53] [config] bert-mask-symbol: "[MASK]"
[2019-08-08 22:33:53] [config] bert-masking-fraction: 0.15
[2019-08-08 22:33:53] [config] bert-sep-symbol: "[SEP]"
[2019-08-08 22:33:53] [config] bert-train-type-embeddings: true
[2019-08-08 22:33:53] [config] bert-type-vocab-size: 2
[2019-08-08 22:33:53] [config] best-deep: false
[2019-08-08 22:33:53] [config] clip-gemm: 0
[2019-08-08 22:33:53] [config] clip-norm: 1
[2019-08-08 22:33:53] [config] cost-type: ce-mean
[2019-08-08 22:33:53] [config] cpu-threads: 0
[2019-08-08 22:33:53] [config] data-weighting: ""
[2019-08-08 22:33:53] [config] data-weighting-type: sentence
[2019-08-08 22:33:53] [config] dec-cell: gru
[2019-08-08 22:33:53] [config] dec-cell-base-depth: 2
[2019-08-08 22:33:53] [config] dec-cell-high-depth: 1
[2019-08-08 22:33:53] [config] dec-depth: 1
[2019-08-08 22:33:53] [config] devices:
[2019-08-08 22:33:53] [config]   - 6
[2019-08-08 22:33:53] [config] dim-emb: 512
[2019-08-08 22:33:53] [config] dim-rnn: 1024
[2019-08-08 22:33:53] [config] dim-vocabs:
[2019-08-08 22:33:53] [config]   - 50000
[2019-08-08 22:33:53] [config]   - 50000
[2019-08-08 22:33:53] [config] disp-first: 0
[2019-08-08 22:33:53] [config] disp-freq: 2000
[2019-08-08 22:33:53] [config] disp-label-counts: false
[2019-08-08 22:33:53] [config] dropout-rnn: 0.2
[2019-08-08 22:33:53] [config] dropout-src: 0.1
[2019-08-08 22:33:53] [config] dropout-trg: 0.1
[2019-08-08 22:33:53] [config] dump-config: ""
[2019-08-08 22:33:53] [config] early-stopping: 5
[2019-08-08 22:33:53] [config] embedding-fix-src: false
[2019-08-08 22:33:53] [config] embedding-fix-trg: false
[2019-08-08 22:33:53] [config] embedding-normalization: false
[2019-08-08 22:33:53] [config] embedding-vectors:
[2019-08-08 22:33:53] [config]   []
[2019-08-08 22:33:53] [config] enc-cell: gru
[2019-08-08 22:33:53] [config] enc-cell-depth: 1
[2019-08-08 22:33:53] [config] enc-depth: 1
[2019-08-08 22:33:53] [config] enc-type: bidirectional
[2019-08-08 22:33:53] [config] exponential-smoothing: 0.0001
[2019-08-08 22:33:53] [config] grad-dropping-momentum: 0
[2019-08-08 22:33:53] [config] grad-dropping-rate: 0
[2019-08-08 22:33:53] [config] grad-dropping-warmup: 100
[2019-08-08 22:33:53] [config] guided-alignment: none
[2019-08-08 22:33:53] [config] guided-alignment-cost: mse
[2019-08-08 22:33:53] [config] guided-alignment-weight: 0.1
[2019-08-08 22:33:53] [config] ignore-model-config: false
[2019-08-08 22:33:53] [config] input-types:
[2019-08-08 22:33:53] [config]   []
[2019-08-08 22:33:53] [config] interpolate-env-vars: false
[2019-08-08 22:33:53] [config] keep-best: false
[2019-08-08 22:33:53] [config] label-smoothing: 0
[2019-08-08 22:33:53] [config] layer-normalization: true
[2019-08-08 22:33:53] [config] learn-rate: 0.0001
[2019-08-08 22:33:53] [config] log: ../experiments/100M_random_fasttext_prob/model/train.log
[2019-08-08 22:33:53] [config] log-level: info
[2019-08-08 22:33:53] [config] log-time-zone: ""
[2019-08-08 22:33:53] [config] lr-decay: 0
[2019-08-08 22:33:53] [config] lr-decay-freq: 50000
[2019-08-08 22:33:53] [config] lr-decay-inv-sqrt:
[2019-08-08 22:33:53] [config]   - 0
[2019-08-08 22:33:53] [config] lr-decay-repeat-warmup: false
[2019-08-08 22:33:53] [config] lr-decay-reset-optimizer: false
[2019-08-08 22:33:53] [config] lr-decay-start:
[2019-08-08 22:33:53] [config]   - 10
[2019-08-08 22:33:53] [config]   - 1
[2019-08-08 22:33:53] [config] lr-decay-strategy: epoch+stalled
[2019-08-08 22:33:53] [config] lr-report: false
[2019-08-08 22:33:53] [config] lr-warmup: 0
[2019-08-08 22:33:53] [config] lr-warmup-at-reload: false
[2019-08-08 22:33:53] [config] lr-warmup-cycle: false
[2019-08-08 22:33:53] [config] lr-warmup-start-rate: 0
[2019-08-08 22:33:53] [config] max-length: 50
[2019-08-08 22:33:53] [config] max-length-crop: false
[2019-08-08 22:33:53] [config] max-length-factor: 3
[2019-08-08 22:33:53] [config] maxi-batch: 100
[2019-08-08 22:33:53] [config] maxi-batch-sort: trg
[2019-08-08 22:33:53] [config] mini-batch: 64
[2019-08-08 22:33:53] [config] mini-batch-fit: true
[2019-08-08 22:33:53] [config] mini-batch-fit-step: 10
[2019-08-08 22:33:53] [config] mini-batch-overstuff: 1
[2019-08-08 22:33:53] [config] mini-batch-track-lr: false
[2019-08-08 22:33:53] [config] mini-batch-understuff: 1
[2019-08-08 22:33:53] [config] mini-batch-warmup: 0
[2019-08-08 22:33:53] [config] mini-batch-words: 0
[2019-08-08 22:33:53] [config] mini-batch-words-ref: 0
[2019-08-08 22:33:53] [config] model: ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-08 22:33:53] [config] multi-loss-type: sum
[2019-08-08 22:33:53] [config] multi-node: false
[2019-08-08 22:33:53] [config] multi-node-overlap: true
[2019-08-08 22:33:53] [config] n-best: false
[2019-08-08 22:33:53] [config] no-nccl: false
[2019-08-08 22:33:53] [config] no-reload: false
[2019-08-08 22:33:53] [config] no-restore-corpus: false
[2019-08-08 22:33:53] [config] no-shuffle: false
[2019-08-08 22:33:53] [config] normalize: 1
[2019-08-08 22:33:53] [config] num-devices: 0
[2019-08-08 22:33:53] [config] optimizer: adam
[2019-08-08 22:33:53] [config] optimizer-delay: 1
[2019-08-08 22:33:53] [config] optimizer-params:
[2019-08-08 22:33:53] [config]   []
[2019-08-08 22:33:53] [config] overwrite: false
[2019-08-08 22:33:53] [config] pretrained-model: ""
[2019-08-08 22:33:53] [config] quiet: false
[2019-08-08 22:33:53] [config] quiet-translation: true
[2019-08-08 22:33:53] [config] relative-paths: false
[2019-08-08 22:33:53] [config] right-left: false
[2019-08-08 22:33:53] [config] save-freq: 20000
[2019-08-08 22:33:53] [config] seed: 1111
[2019-08-08 22:33:53] [config] shuffle-in-ram: false
[2019-08-08 22:33:53] [config] skip: false
[2019-08-08 22:33:53] [config] sqlite: ""
[2019-08-08 22:33:53] [config] sqlite-drop: false
[2019-08-08 22:33:53] [config] sync-sgd: true
[2019-08-08 22:33:53] [config] tempdir: .
[2019-08-08 22:33:53] [config] tied-embeddings: false
[2019-08-08 22:33:53] [config] tied-embeddings-all: false
[2019-08-08 22:33:53] [config] tied-embeddings-src: false
[2019-08-08 22:33:53] [config] train-sets:
[2019-08-08 22:33:53] [config]   - ../experiments/100M_random_fasttext_prob/data/train.bpe.de
[2019-08-08 22:33:53] [config]   - ../experiments/100M_random_fasttext_prob/data/train.bpe.en
[2019-08-08 22:33:53] [config] transformer-aan-activation: swish
[2019-08-08 22:33:53] [config] transformer-aan-depth: 2
[2019-08-08 22:33:53] [config] transformer-aan-nogate: false
[2019-08-08 22:33:53] [config] transformer-decoder-autoreg: self-attention
[2019-08-08 22:33:53] [config] transformer-dim-aan: 2048
[2019-08-08 22:33:53] [config] transformer-dim-ffn: 2048
[2019-08-08 22:33:53] [config] transformer-dropout: 0
[2019-08-08 22:33:53] [config] transformer-dropout-attention: 0
[2019-08-08 22:33:53] [config] transformer-dropout-ffn: 0
[2019-08-08 22:33:53] [config] transformer-ffn-activation: swish
[2019-08-08 22:33:53] [config] transformer-ffn-depth: 2
[2019-08-08 22:33:53] [config] transformer-guided-alignment-layer: last
[2019-08-08 22:33:53] [config] transformer-heads: 8
[2019-08-08 22:33:53] [config] transformer-no-projection: false
[2019-08-08 22:33:53] [config] transformer-postprocess: dan
[2019-08-08 22:33:53] [config] transformer-postprocess-emb: d
[2019-08-08 22:33:53] [config] transformer-preprocess: ""
[2019-08-08 22:33:53] [config] transformer-tied-layers:
[2019-08-08 22:33:53] [config]   []
[2019-08-08 22:33:53] [config] transformer-train-position-embeddings: false
[2019-08-08 22:33:53] [config] type: amun
[2019-08-08 22:33:53] [config] ulr: false
[2019-08-08 22:33:53] [config] ulr-dim-emb: 0
[2019-08-08 22:33:53] [config] ulr-dropout: 0
[2019-08-08 22:33:53] [config] ulr-keys-vectors: ""
[2019-08-08 22:33:53] [config] ulr-query-vectors: ""
[2019-08-08 22:33:53] [config] ulr-softmax-temperature: 1
[2019-08-08 22:33:53] [config] ulr-trainable-transformation: false
[2019-08-08 22:33:53] [config] valid-freq: 20000
[2019-08-08 22:33:53] [config] valid-log: ../experiments/100M_random_fasttext_prob/model/valid.log
[2019-08-08 22:33:53] [config] valid-max-length: 1000
[2019-08-08 22:33:53] [config] valid-metrics:
[2019-08-08 22:33:53] [config]   - cross-entropy
[2019-08-08 22:33:53] [config]   - perplexity
[2019-08-08 22:33:53] [config]   - translation
[2019-08-08 22:33:53] [config] valid-mini-batch: 8
[2019-08-08 22:33:53] [config] valid-script-path: ../experiments/100M_random_fasttext_prob/score-dev.sh
[2019-08-08 22:33:53] [config] valid-sets:
[2019-08-08 22:33:53] [config]   - ../experiments/100M_random_fasttext_prob/data/dev.bpe.de
[2019-08-08 22:33:53] [config]   - ../experiments/100M_random_fasttext_prob/data/dev.bpe.en
[2019-08-08 22:33:53] [config] valid-translation-output: ../experiments/100M_random_fasttext_prob/model/dev.out
[2019-08-08 22:33:53] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-08 22:33:53] [config] vocabs:
[2019-08-08 22:33:53] [config]   - ../experiments/100M_random_fasttext_prob/data/train.bpe.de.json
[2019-08-08 22:33:53] [config]   - ../experiments/100M_random_fasttext_prob/data/train.bpe.en.json
[2019-08-08 22:33:53] [config] word-penalty: 0
[2019-08-08 22:33:53] [config] workspace: 3000
[2019-08-08 22:33:53] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-08 22:33:53] Using synchronous training
[2019-08-08 22:33:53] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_random_fasttext_prob/data/train.bpe.de.json
[2019-08-08 22:33:54] [data] Using unused word id eos for 0
[2019-08-08 22:33:54] [data] Using unused word id UNK for 1
[2019-08-08 22:33:54] [data] Setting vocabulary size for input 0 to 50000
[2019-08-08 22:33:54] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_random_fasttext_prob/data/train.bpe.en.json
[2019-08-08 22:33:54] [data] Using unused word id eos for 0
[2019-08-08 22:33:54] [data] Using unused word id UNK for 1
[2019-08-08 22:33:54] [data] Setting vocabulary size for input 1 to 50000
[2019-08-08 22:33:54] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-08 22:33:54] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-08 22:33:55] [memory] Extending reserved space to 3072 MB (device gpu6)
[2019-08-08 22:33:55] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-08 22:33:55] [comm] NCCLCommunicator constructed successfully.
[2019-08-08 22:33:55] [training] Using 1 GPUs
[2019-08-08 22:33:55] [memory] Reserving 422 MB, device gpu6
[2019-08-08 22:33:55] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-08 22:33:56] [memory] Reserving 422 MB, device gpu6
[2019-08-08 22:33:58] [batching] Done. Typical MB size is 4042 target words
[2019-08-08 22:33:58] [memory] Extending reserved space to 3072 MB (device gpu6)
[2019-08-08 22:33:58] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-08 22:33:58] [comm] NCCLCommunicator constructed successfully.
[2019-08-08 22:33:58] [training] Using 1 GPUs
[2019-08-08 22:33:58] Loading model from ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-08 22:34:02] Loading Adam parameters from ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-08 22:34:06] [memory] Reserving 844 MB, device gpu6
[2019-08-08 22:34:07] [training] Model reloaded from ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-08 22:34:07] [data] Restoring the corpus state to epoch 10, batch 520000
[2019-08-08 22:34:07] [data] Shuffling data
[2019-08-08 22:34:13] [data] Done reading 6422600 sentences
[2019-08-08 22:34:50] [data] Done shuffling 6422600 sentences to temp files
[2019-08-08 22:35:50] Training started
[2019-08-08 22:35:50] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-08 22:35:50] [memory] Reserving 422 MB, device gpu6
[2019-08-08 22:35:50] [memory] Reserving 422 MB, device gpu6
[2019-08-08 22:35:50] Loading model from ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-08 22:35:53] [memory] Reserving 422 MB, device cpu0
[2019-08-08 22:35:54] [memory] Reserving 422 MB, device gpu6
[2019-08-08 22:40:30] Ep. 10 : Up. 522000 : Sen. 2,349,857 : Cost 54.03524780 : Time 395.68s : 9337.47 words/s
[2019-08-08 22:45:07] Ep. 10 : Up. 524000 : Sen. 2,554,331 : Cost 54.15094376 : Time 277.19s : 13319.95 words/s
[2019-08-08 22:49:45] Ep. 10 : Up. 526000 : Sen. 2,757,950 : Cost 54.14434814 : Time 277.74s : 13277.95 words/s
[2019-08-08 22:54:22] Ep. 10 : Up. 528000 : Sen. 2,961,765 : Cost 54.08878326 : Time 277.18s : 13316.15 words/s
[2019-08-08 22:59:00] Ep. 10 : Up. 530000 : Sen. 3,166,521 : Cost 54.14459610 : Time 278.30s : 13329.26 words/s
[2019-08-08 23:03:38] Ep. 10 : Up. 532000 : Sen. 3,370,438 : Cost 54.20622635 : Time 277.96s : 13325.97 words/s
[2019-08-08 23:08:15] Ep. 10 : Up. 534000 : Sen. 3,575,559 : Cost 53.95211029 : Time 276.66s : 13355.50 words/s
[2019-08-08 23:12:53] Ep. 10 : Up. 536000 : Sen. 3,779,616 : Cost 54.39109802 : Time 277.87s : 13330.81 words/s
[2019-08-08 23:17:30] Ep. 10 : Up. 538000 : Sen. 3,984,094 : Cost 54.27348328 : Time 277.68s : 13331.32 words/s
[2019-08-08 23:22:08] Ep. 10 : Up. 540000 : Sen. 4,187,964 : Cost 54.14743805 : Time 277.43s : 13320.01 words/s
[2019-08-08 23:22:08] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-08 23:22:14] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter540000.npz
[2019-08-08 23:22:16] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-08 23:22:22] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-08 23:22:43] [valid] Ep. 10 : Up. 540000 : cross-entropy : 54.4967 : stalled 1 times (last best: 54.4855)
[2019-08-08 23:22:49] [valid] Ep. 10 : Up. 540000 : perplexity : 8.56223 : stalled 1 times (last best: 8.55845)
[2019-08-08 23:23:41] [valid] Ep. 10 : Up. 540000 : translation : 23.79 : stalled 5 times (last best: 24.26)
[2019-08-08 23:28:21] Ep. 10 : Up. 542000 : Sen. 4,392,820 : Cost 53.74221802 : Time 373.19s : 9873.51 words/s
[2019-08-08 23:33:00] Ep. 10 : Up. 544000 : Sen. 4,597,160 : Cost 54.23065567 : Time 279.30s : 13250.39 words/s
[2019-08-08 23:37:40] Ep. 10 : Up. 546000 : Sen. 4,801,636 : Cost 54.44442749 : Time 279.34s : 13254.01 words/s
[2019-08-08 23:42:19] Ep. 10 : Up. 548000 : Sen. 5,005,710 : Cost 54.45355606 : Time 279.08s : 13290.22 words/s
[2019-08-08 23:46:57] Ep. 10 : Up. 550000 : Sen. 5,209,695 : Cost 54.35893631 : Time 278.47s : 13265.28 words/s
[2019-08-08 23:51:35] Ep. 10 : Up. 552000 : Sen. 5,413,624 : Cost 54.18806076 : Time 278.31s : 13276.20 words/s
[2019-08-08 23:56:16] Ep. 10 : Up. 554000 : Sen. 5,618,093 : Cost 54.72019577 : Time 280.18s : 13246.91 words/s
[2019-08-08 23:57:13] Seen 5659635 samples
[2019-08-08 23:57:13] Starting epoch 11
[2019-08-08 23:57:13] [data] Shuffling data
[2019-08-08 23:57:16] [data] Done reading 6422600 sentences
[2019-08-08 23:57:43] [data] Done shuffling 6422600 sentences to temp files
[2019-08-09 00:01:25] Ep. 11 : Up. 556000 : Sen. 162,679 : Cost 53.54110336 : Time 309.79s : 11908.62 words/s
[2019-08-09 00:06:05] Ep. 11 : Up. 558000 : Sen. 367,108 : Cost 53.41587067 : Time 279.60s : 13288.36 words/s
[2019-08-09 00:10:44] Ep. 11 : Up. 560000 : Sen. 572,326 : Cost 53.30485153 : Time 279.30s : 13275.32 words/s
[2019-08-09 00:10:44] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-09 00:10:49] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter560000.npz
[2019-08-09 00:10:52] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-09 00:10:57] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-09 00:11:16] [valid] Ep. 11 : Up. 560000 : cross-entropy : 54.4036 : new best
[2019-08-09 00:11:23] [valid] Ep. 11 : Up. 560000 : perplexity : 8.53086 : new best
[2019-08-09 00:12:13] [valid] Ep. 11 : Up. 560000 : translation : 24.06 : stalled 6 times (last best: 24.26)
[2019-08-09 00:16:55] Ep. 11 : Up. 562000 : Sen. 777,037 : Cost 53.66061020 : Time 370.45s : 10018.46 words/s
[2019-08-09 00:21:33] Ep. 11 : Up. 564000 : Sen. 980,750 : Cost 53.47847366 : Time 278.51s : 13246.59 words/s
[2019-08-09 00:26:11] Ep. 11 : Up. 566000 : Sen. 1,184,828 : Cost 53.31803513 : Time 277.94s : 13277.81 words/s
[2019-08-09 00:30:51] Ep. 11 : Up. 568000 : Sen. 1,388,495 : Cost 53.73352432 : Time 279.33s : 13234.63 words/s
[2019-08-09 00:35:29] Ep. 11 : Up. 570000 : Sen. 1,592,702 : Cost 53.50434113 : Time 278.49s : 13248.67 words/s
[2019-08-09 00:40:09] Ep. 11 : Up. 572000 : Sen. 1,797,035 : Cost 53.52426147 : Time 279.52s : 13232.46 words/s
[2019-08-09 00:44:47] Ep. 11 : Up. 574000 : Sen. 2,001,078 : Cost 53.94712830 : Time 278.41s : 13320.04 words/s
[2019-08-09 00:49:26] Ep. 11 : Up. 576000 : Sen. 2,205,310 : Cost 53.64353943 : Time 278.71s : 13277.60 words/s
[2019-08-09 00:54:04] Ep. 11 : Up. 578000 : Sen. 2,409,702 : Cost 53.93858337 : Time 278.62s : 13291.57 words/s
[2019-08-09 00:58:43] Ep. 11 : Up. 580000 : Sen. 2,612,833 : Cost 53.68824387 : Time 278.50s : 13222.76 words/s
[2019-08-09 00:58:43] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-09 00:58:49] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter580000.npz
[2019-08-09 00:58:52] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-09 00:58:57] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-09 00:59:17] [valid] Ep. 11 : Up. 580000 : cross-entropy : 54.5261 : stalled 1 times (last best: 54.4036)
[2019-08-09 00:59:23] [valid] Ep. 11 : Up. 580000 : perplexity : 8.57215 : stalled 1 times (last best: 8.53086)
[2019-08-09 01:00:14] [valid] Ep. 11 : Up. 580000 : translation : 23.53 : stalled 7 times (last best: 24.26)
[2019-08-09 01:04:54] Ep. 11 : Up. 582000 : Sen. 2,817,783 : Cost 53.52461624 : Time 371.64s : 9962.93 words/s
[2019-08-09 01:09:34] Ep. 11 : Up. 584000 : Sen. 3,023,168 : Cost 53.65009689 : Time 279.38s : 13320.50 words/s
[2019-08-09 01:14:13] Ep. 11 : Up. 586000 : Sen. 3,227,008 : Cost 53.74684906 : Time 278.71s : 13248.44 words/s
[2019-08-09 01:18:51] Ep. 11 : Up. 588000 : Sen. 3,430,924 : Cost 53.84696198 : Time 278.13s : 13266.72 words/s
[2019-08-09 01:23:30] Ep. 11 : Up. 590000 : Sen. 3,635,200 : Cost 54.11955261 : Time 279.53s : 13262.36 words/s
[2019-08-09 01:28:09] Ep. 11 : Up. 592000 : Sen. 3,839,443 : Cost 53.89285278 : Time 278.80s : 13271.97 words/s
[2019-08-09 01:32:48] Ep. 11 : Up. 594000 : Sen. 4,043,261 : Cost 53.96214294 : Time 279.12s : 13220.99 words/s
[2019-08-09 01:37:28] Ep. 11 : Up. 596000 : Sen. 4,247,530 : Cost 54.13216782 : Time 280.03s : 13226.67 words/s
[2019-08-09 01:42:07] Ep. 11 : Up. 598000 : Sen. 4,452,703 : Cost 53.76953506 : Time 279.12s : 13294.19 words/s
[2019-08-09 01:46:45] Ep. 11 : Up. 600000 : Sen. 4,656,544 : Cost 54.05400848 : Time 277.34s : 13311.58 words/s
[2019-08-09 01:46:45] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-09 01:46:51] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter600000.npz
[2019-08-09 01:46:53] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-09 01:47:00] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-09 01:47:19] [valid] Ep. 11 : Up. 600000 : cross-entropy : 54.4526 : stalled 2 times (last best: 54.4036)
[2019-08-09 01:47:26] [valid] Ep. 11 : Up. 600000 : perplexity : 8.54735 : stalled 2 times (last best: 8.53086)
[2019-08-09 01:48:16] [valid] Ep. 11 : Up. 600000 : translation : 24.06 : stalled 8 times (last best: 24.26)
[2019-08-09 01:52:55] Ep. 11 : Up. 602000 : Sen. 4,859,939 : Cost 54.09318924 : Time 370.74s : 9950.29 words/s
[2019-08-09 01:57:33] Ep. 11 : Up. 604000 : Sen. 5,064,506 : Cost 53.64042282 : Time 278.13s : 13278.32 words/s
[2019-08-09 02:02:12] Ep. 11 : Up. 606000 : Sen. 5,268,829 : Cost 54.07897186 : Time 278.17s : 13301.20 words/s
[2019-08-09 02:06:50] Ep. 11 : Up. 608000 : Sen. 5,471,832 : Cost 54.25133133 : Time 278.83s : 13223.60 words/s
[2019-08-09 02:11:06] Seen 5659635 samples
[2019-08-09 02:11:06] Starting epoch 12
[2019-08-09 02:11:06] [data] Shuffling data
[2019-08-09 02:11:10] [data] Done reading 6422600 sentences
[2019-08-09 02:11:41] [data] Done shuffling 6422600 sentences to temp files
[2019-08-09 02:12:05] Ep. 12 : Up. 610000 : Sen. 16,911 : Cost 53.45160675 : Time 314.05s : 11755.59 words/s
[2019-08-09 02:16:44] Ep. 12 : Up. 612000 : Sen. 220,815 : Cost 53.05607605 : Time 279.32s : 13241.76 words/s
[2019-08-09 02:21:23] Ep. 12 : Up. 614000 : Sen. 425,177 : Cost 52.77161026 : Time 279.16s : 13247.54 words/s
[2019-08-09 02:26:03] Ep. 12 : Up. 616000 : Sen. 629,327 : Cost 53.11226654 : Time 279.70s : 13214.38 words/s
[2019-08-09 02:30:42] Ep. 12 : Up. 618000 : Sen. 833,952 : Cost 52.99218750 : Time 278.92s : 13275.44 words/s
[2019-08-09 02:35:22] Ep. 12 : Up. 620000 : Sen. 1,038,162 : Cost 53.16909409 : Time 280.34s : 13220.63 words/s
[2019-08-09 02:35:22] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-09 02:35:27] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter620000.npz
[2019-08-09 02:35:30] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-09 02:35:35] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-09 02:35:54] [valid] Ep. 12 : Up. 620000 : cross-entropy : 54.4565 : stalled 3 times (last best: 54.4036)
[2019-08-09 02:36:01] [valid] Ep. 12 : Up. 620000 : perplexity : 8.54868 : stalled 3 times (last best: 8.53086)
[2019-08-09 02:36:51] [valid] Ep. 12 : Up. 620000 : translation : 24.27 : new best
[2019-08-09 02:41:33] Ep. 12 : Up. 622000 : Sen. 1,243,072 : Cost 53.14292145 : Time 370.89s : 9990.12 words/s
[2019-08-09 02:46:13] Ep. 12 : Up. 624000 : Sen. 1,447,571 : Cost 53.44219208 : Time 279.82s : 13271.19 words/s
[2019-08-09 02:50:52] Ep. 12 : Up. 626000 : Sen. 1,651,814 : Cost 53.52693939 : Time 279.00s : 13284.63 words/s
[2019-08-09 02:55:30] Ep. 12 : Up. 628000 : Sen. 1,855,404 : Cost 53.22463226 : Time 278.23s : 13264.51 words/s
[2019-08-09 03:00:10] Ep. 12 : Up. 630000 : Sen. 2,059,889 : Cost 53.63501358 : Time 279.73s : 13260.91 words/s
[2019-08-09 03:04:49] Ep. 12 : Up. 632000 : Sen. 2,264,649 : Cost 53.34373474 : Time 279.52s : 13283.52 words/s
[2019-08-09 03:09:28] Ep. 12 : Up. 634000 : Sen. 2,469,518 : Cost 53.46534729 : Time 278.70s : 13270.38 words/s
[2019-08-09 03:14:07] Ep. 12 : Up. 636000 : Sen. 2,674,210 : Cost 53.50189209 : Time 279.56s : 13285.29 words/s
[2019-08-09 03:18:46] Ep. 12 : Up. 638000 : Sen. 2,878,418 : Cost 53.39941025 : Time 278.47s : 13240.74 words/s
[2019-08-09 03:23:24] Ep. 12 : Up. 640000 : Sen. 3,082,533 : Cost 53.35990143 : Time 277.89s : 13276.73 words/s
[2019-08-09 03:23:24] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-09 03:23:29] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter640000.npz
[2019-08-09 03:23:31] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-09 03:23:37] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-09 03:23:56] [valid] Ep. 12 : Up. 640000 : cross-entropy : 54.5021 : stalled 4 times (last best: 54.4036)
[2019-08-09 03:24:02] [valid] Ep. 12 : Up. 640000 : perplexity : 8.56406 : stalled 4 times (last best: 8.53086)
[2019-08-09 03:24:52] [valid] Ep. 12 : Up. 640000 : translation : 23.96 : stalled 1 times (last best: 24.27)
[2019-08-09 03:29:34] Ep. 12 : Up. 642000 : Sen. 3,286,507 : Cost 53.82322311 : Time 370.19s : 10015.99 words/s
[2019-08-09 03:34:11] Ep. 12 : Up. 644000 : Sen. 3,490,566 : Cost 53.35763550 : Time 277.50s : 13298.20 words/s
[2019-08-09 03:38:51] Ep. 12 : Up. 646000 : Sen. 3,694,554 : Cost 53.41280746 : Time 279.06s : 13256.06 words/s
[2019-08-09 03:43:28] Ep. 12 : Up. 648000 : Sen. 3,898,371 : Cost 53.45574570 : Time 277.66s : 13267.37 words/s
[2019-08-09 03:48:06] Ep. 12 : Up. 650000 : Sen. 4,102,142 : Cost 53.51589203 : Time 277.85s : 13272.05 words/s
[2019-08-09 03:52:44] Ep. 12 : Up. 652000 : Sen. 4,306,132 : Cost 53.44538498 : Time 278.42s : 13246.77 words/s
[2019-08-09 03:57:23] Ep. 12 : Up. 654000 : Sen. 4,510,021 : Cost 53.81963730 : Time 278.78s : 13272.71 words/s
[2019-08-09 04:02:02] Ep. 12 : Up. 656000 : Sen. 4,714,549 : Cost 53.27039719 : Time 278.49s : 13254.83 words/s
[2019-08-09 04:06:40] Ep. 12 : Up. 658000 : Sen. 4,918,932 : Cost 53.74292374 : Time 278.64s : 13295.10 words/s
[2019-08-09 04:11:19] Ep. 12 : Up. 660000 : Sen. 5,122,917 : Cost 53.71541595 : Time 278.83s : 13279.72 words/s
[2019-08-09 04:11:19] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-09 04:11:24] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter660000.npz
[2019-08-09 04:11:26] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-09 04:11:31] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-09 04:11:49] [valid] Ep. 12 : Up. 660000 : cross-entropy : 54.2739 : new best
[2019-08-09 04:11:56] [valid] Ep. 12 : Up. 660000 : perplexity : 8.48738 : new best
[2019-08-09 04:12:46] [valid] Ep. 12 : Up. 660000 : translation : 23.69 : stalled 2 times (last best: 24.27)
[2019-08-09 04:17:26] Ep. 12 : Up. 662000 : Sen. 5,327,417 : Cost 53.52425003 : Time 366.71s : 10070.45 words/s
[2019-08-09 04:22:04] Ep. 12 : Up. 664000 : Sen. 5,530,978 : Cost 53.51926804 : Time 277.90s : 13248.56 words/s
[2019-08-09 04:25:01] Seen 5659635 samples
[2019-08-09 04:25:01] Starting epoch 13
[2019-08-09 04:25:01] [data] Shuffling data
[2019-08-09 04:25:04] [data] Done reading 6422600 sentences
[2019-08-09 04:25:36] [data] Done shuffling 6422600 sentences to temp files
[2019-08-09 04:27:18] Ep. 13 : Up. 666000 : Sen. 73,889 : Cost 53.72617722 : Time 314.28s : 11723.90 words/s
[2019-08-09 04:31:56] Ep. 13 : Up. 668000 : Sen. 277,983 : Cost 52.49215698 : Time 278.15s : 13277.21 words/s
[2019-08-09 04:36:34] Ep. 13 : Up. 670000 : Sen. 482,457 : Cost 52.79096222 : Time 278.02s : 13323.61 words/s
[2019-08-09 04:41:12] Ep. 13 : Up. 672000 : Sen. 686,410 : Cost 52.72345734 : Time 278.03s : 13289.75 words/s
[2019-08-09 04:45:51] Ep. 13 : Up. 674000 : Sen. 890,592 : Cost 52.59434128 : Time 278.24s : 13241.15 words/s
[2019-08-09 04:50:30] Ep. 13 : Up. 676000 : Sen. 1,094,400 : Cost 53.05328369 : Time 278.97s : 13264.34 words/s
[2019-08-09 04:55:09] Ep. 13 : Up. 678000 : Sen. 1,299,700 : Cost 52.78810501 : Time 279.82s : 13255.16 words/s
[2019-08-09 04:59:48] Ep. 13 : Up. 680000 : Sen. 1,503,002 : Cost 53.19673538 : Time 278.74s : 13254.06 words/s
[2019-08-09 04:59:48] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-09 04:59:54] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter680000.npz
[2019-08-09 04:59:56] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-09 05:00:01] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-09 05:00:19] [valid] Ep. 13 : Up. 680000 : cross-entropy : 54.3211 : stalled 1 times (last best: 54.2739)
[2019-08-09 05:00:26] [valid] Ep. 13 : Up. 680000 : perplexity : 8.50319 : stalled 1 times (last best: 8.48738)
[2019-08-09 05:01:16] [valid] Ep. 13 : Up. 680000 : translation : 23.58 : stalled 3 times (last best: 24.27)
[2019-08-09 05:05:57] Ep. 13 : Up. 682000 : Sen. 1,707,511 : Cost 52.71842957 : Time 368.73s : 10025.91 words/s
[2019-08-09 05:10:37] Ep. 13 : Up. 684000 : Sen. 1,912,025 : Cost 53.10633469 : Time 280.20s : 13279.63 words/s
[2019-08-09 05:15:16] Ep. 13 : Up. 686000 : Sen. 2,116,019 : Cost 53.05798340 : Time 278.90s : 13224.70 words/s
[2019-08-09 05:19:56] Ep. 13 : Up. 688000 : Sen. 2,319,657 : Cost 53.25870895 : Time 279.61s : 13252.59 words/s
[2019-08-09 05:24:33] Ep. 13 : Up. 690000 : Sen. 2,523,980 : Cost 53.03199387 : Time 277.75s : 13276.02 words/s
[2019-08-09 05:29:12] Ep. 13 : Up. 692000 : Sen. 2,727,916 : Cost 53.29719543 : Time 278.51s : 13266.69 words/s
[2019-08-09 05:33:51] Ep. 13 : Up. 694000 : Sen. 2,932,415 : Cost 53.05081177 : Time 279.34s : 13275.40 words/s
[2019-08-09 05:38:31] Ep. 13 : Up. 696000 : Sen. 3,137,022 : Cost 53.19729614 : Time 279.69s : 13237.90 words/s
[2019-08-09 05:43:10] Ep. 13 : Up. 698000 : Sen. 3,340,611 : Cost 53.54302597 : Time 278.94s : 13255.07 words/s
[2019-08-09 05:47:48] Ep. 13 : Up. 700000 : Sen. 3,544,270 : Cost 53.23537445 : Time 277.98s : 13255.86 words/s
[2019-08-09 05:47:48] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-09 05:47:53] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter700000.npz
[2019-08-09 05:47:55] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-09 05:48:00] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-09 05:48:18] [valid] Ep. 13 : Up. 700000 : cross-entropy : 54.3165 : stalled 2 times (last best: 54.2739)
[2019-08-09 05:48:25] [valid] Ep. 13 : Up. 700000 : perplexity : 8.50166 : stalled 2 times (last best: 8.48738)
[2019-08-09 05:49:15] [valid] Ep. 13 : Up. 700000 : translation : 23.73 : stalled 4 times (last best: 24.27)
[2019-08-09 05:53:56] Ep. 13 : Up. 702000 : Sen. 3,747,672 : Cost 53.28232574 : Time 368.41s : 10028.79 words/s
[2019-08-09 05:58:35] Ep. 13 : Up. 704000 : Sen. 3,951,913 : Cost 53.16679001 : Time 278.78s : 13254.87 words/s
[2019-08-09 06:03:13] Ep. 13 : Up. 706000 : Sen. 4,154,851 : Cost 53.57601929 : Time 278.37s : 13245.25 words/s
[2019-08-09 06:07:51] Ep. 13 : Up. 708000 : Sen. 4,359,244 : Cost 52.97775269 : Time 278.08s : 13257.72 words/s
[2019-08-09 06:12:31] Ep. 13 : Up. 710000 : Sen. 4,563,512 : Cost 53.29946136 : Time 279.43s : 13226.57 words/s
[2019-08-09 06:17:10] Ep. 13 : Up. 712000 : Sen. 4,767,602 : Cost 53.24716187 : Time 278.77s : 13246.27 words/s
[2019-08-09 06:21:48] Ep. 13 : Up. 714000 : Sen. 4,971,651 : Cost 53.20495987 : Time 278.46s : 13230.91 words/s
[2019-08-09 06:26:28] Ep. 13 : Up. 716000 : Sen. 5,175,392 : Cost 53.39826965 : Time 279.68s : 13237.60 words/s
[2019-08-09 06:31:07] Ep. 13 : Up. 718000 : Sen. 5,380,277 : Cost 53.17856216 : Time 279.72s : 13219.79 words/s
[2019-08-09 06:35:49] Ep. 13 : Up. 720000 : Sen. 5,585,016 : Cost 53.53652573 : Time 281.57s : 13167.07 words/s
[2019-08-09 06:35:49] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-09 06:35:54] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter720000.npz
[2019-08-09 06:35:56] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-09 06:36:02] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-09 06:36:21] [valid] Ep. 13 : Up. 720000 : cross-entropy : 54.2408 : new best
[2019-08-09 06:36:27] [valid] Ep. 13 : Up. 720000 : perplexity : 8.47633 : new best
[2019-08-09 06:37:20] [valid] Ep. 13 : Up. 720000 : translation : 23.98 : stalled 5 times (last best: 24.27)
[2019-08-09 06:39:05] Seen 5659635 samples
[2019-08-09 06:39:05] Starting epoch 14
[2019-08-09 06:39:05] [data] Shuffling data
[2019-08-09 06:39:09] [data] Done reading 6422600 sentences
[2019-08-09 06:39:38] [data] Done shuffling 6422600 sentences to temp files
[2019-08-09 06:42:36] Ep. 14 : Up. 722000 : Sen. 129,628 : Cost 52.69224548 : Time 406.87s : 9080.72 words/s
[2019-08-09 06:47:14] Ep. 14 : Up. 724000 : Sen. 333,128 : Cost 52.40427399 : Time 278.40s : 13253.22 words/s
[2019-08-09 06:51:54] Ep. 14 : Up. 726000 : Sen. 537,808 : Cost 52.32632828 : Time 279.37s : 13248.42 words/s
[2019-08-09 06:56:34] Ep. 14 : Up. 728000 : Sen. 742,751 : Cost 52.21504593 : Time 280.40s : 13228.49 words/s
[2019-08-09 07:01:14] Ep. 14 : Up. 730000 : Sen. 946,851 : Cost 52.54201889 : Time 279.74s : 13199.26 words/s
[2019-08-09 07:05:53] Ep. 14 : Up. 732000 : Sen. 1,150,580 : Cost 52.43666840 : Time 279.04s : 13243.49 words/s
[2019-08-09 07:10:33] Ep. 14 : Up. 734000 : Sen. 1,354,824 : Cost 52.64723206 : Time 279.82s : 13224.84 words/s
[2019-08-09 07:15:12] Ep. 14 : Up. 736000 : Sen. 1,559,779 : Cost 52.68466568 : Time 279.54s : 13259.32 words/s
[2019-08-09 07:19:51] Ep. 14 : Up. 738000 : Sen. 1,763,779 : Cost 52.83408356 : Time 278.93s : 13230.58 words/s
[2019-08-09 07:24:31] Ep. 14 : Up. 740000 : Sen. 1,968,261 : Cost 52.76839828 : Time 280.42s : 13208.82 words/s
[2019-08-09 07:24:31] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-09 07:24:37] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter740000.npz
[2019-08-09 07:24:39] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-09 07:24:44] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-09 07:25:02] [valid] Ep. 14 : Up. 740000 : cross-entropy : 54.3123 : stalled 1 times (last best: 54.2408)
[2019-08-09 07:25:08] [valid] Ep. 14 : Up. 740000 : perplexity : 8.50023 : stalled 1 times (last best: 8.47633)
[2019-08-09 07:26:03] [valid] Ep. 14 : Up. 740000 : translation : 23.89 : stalled 6 times (last best: 24.27)
[2019-08-09 07:30:43] Ep. 14 : Up. 742000 : Sen. 2,171,358 : Cost 52.77629471 : Time 371.74s : 9900.34 words/s
[2019-08-09 07:35:24] Ep. 14 : Up. 744000 : Sen. 2,375,619 : Cost 53.12126160 : Time 280.64s : 13201.03 words/s
[2019-08-09 07:40:03] Ep. 14 : Up. 746000 : Sen. 2,579,817 : Cost 52.75325394 : Time 278.65s : 13242.35 words/s
[2019-08-09 07:44:43] Ep. 14 : Up. 748000 : Sen. 2,783,844 : Cost 52.94282150 : Time 280.82s : 13197.39 words/s
[2019-08-09 07:49:23] Ep. 14 : Up. 750000 : Sen. 2,988,722 : Cost 52.76419067 : Time 280.12s : 13224.68 words/s
[2019-08-09 07:54:04] Ep. 14 : Up. 752000 : Sen. 3,192,446 : Cost 53.23188782 : Time 280.65s : 13208.39 words/s
[2019-08-09 07:58:43] Ep. 14 : Up. 754000 : Sen. 3,396,675 : Cost 53.12908173 : Time 278.61s : 13258.91 words/s
[2019-08-09 08:03:23] Ep. 14 : Up. 756000 : Sen. 3,600,651 : Cost 53.26692200 : Time 280.21s : 13197.65 words/s
[2019-08-09 08:08:01] Ep. 14 : Up. 758000 : Sen. 3,804,618 : Cost 52.57284927 : Time 278.55s : 13236.64 words/s
[2019-08-09 08:12:41] Ep. 14 : Up. 760000 : Sen. 4,009,074 : Cost 52.76736832 : Time 279.60s : 13207.32 words/s
[2019-08-09 08:12:41] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-09 08:12:47] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter760000.npz
[2019-08-09 08:12:49] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-09 08:12:54] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-09 08:13:13] [valid] Ep. 14 : Up. 760000 : cross-entropy : 54.2047 : new best
[2019-08-09 08:13:19] [valid] Ep. 14 : Up. 760000 : perplexity : 8.46426 : new best
[2019-08-09 08:14:11] [valid] Ep. 14 : Up. 760000 : translation : 23.69 : stalled 7 times (last best: 24.27)
[2019-08-09 08:18:51] Ep. 14 : Up. 762000 : Sen. 4,213,396 : Cost 53.11769485 : Time 370.31s : 10004.13 words/s
[2019-08-09 08:23:31] Ep. 14 : Up. 764000 : Sen. 4,418,329 : Cost 53.13573074 : Time 279.90s : 13242.14 words/s
[2019-08-09 08:28:11] Ep. 14 : Up. 766000 : Sen. 4,622,325 : Cost 53.16925430 : Time 279.22s : 13258.86 words/s
[2019-08-09 08:32:50] Ep. 14 : Up. 768000 : Sen. 4,826,515 : Cost 53.01736069 : Time 279.89s : 13233.25 words/s
[2019-08-09 08:37:29] Ep. 14 : Up. 770000 : Sen. 5,030,322 : Cost 53.00704193 : Time 278.44s : 13255.80 words/s
[2019-08-09 08:42:07] Ep. 14 : Up. 772000 : Sen. 5,233,892 : Cost 53.17265701 : Time 278.02s : 13261.02 words/s
[2019-08-09 08:46:46] Ep. 14 : Up. 774000 : Sen. 5,438,630 : Cost 53.11092377 : Time 278.81s : 13263.37 words/s
[2019-08-09 08:51:25] Ep. 14 : Up. 776000 : Sen. 5,642,418 : Cost 53.37950134 : Time 279.17s : 13236.46 words/s
[2019-08-09 08:51:49] Seen 5659635 samples
[2019-08-09 08:51:49] Starting epoch 15
[2019-08-09 08:51:49] [data] Shuffling data
[2019-08-09 08:51:55] [data] Done reading 6422600 sentences
[2019-08-09 08:52:23] [data] Done shuffling 6422600 sentences to temp files
[2019-08-09 08:56:39] Ep. 15 : Up. 778000 : Sen. 186,876 : Cost 52.20752716 : Time 314.22s : 11797.80 words/s
[2019-08-09 09:01:18] Ep. 15 : Up. 780000 : Sen. 391,772 : Cost 51.86463928 : Time 279.18s : 13255.16 words/s
[2019-08-09 09:01:18] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-09 09:01:24] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter780000.npz
[2019-08-09 09:01:26] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-09 09:01:31] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-09 09:01:50] [valid] Ep. 15 : Up. 780000 : cross-entropy : 54.1883 : new best
[2019-08-09 09:01:56] [valid] Ep. 15 : Up. 780000 : perplexity : 8.45881 : new best
[2019-08-09 09:02:47] [valid] Ep. 15 : Up. 780000 : translation : 23.79 : stalled 8 times (last best: 24.27)
[2019-08-09 09:07:27] Ep. 15 : Up. 782000 : Sen. 595,553 : Cost 52.22433090 : Time 368.74s : 10010.62 words/s
[2019-08-09 09:12:06] Ep. 15 : Up. 784000 : Sen. 799,431 : Cost 52.35046005 : Time 279.18s : 13232.05 words/s
[2019-08-09 09:16:44] Ep. 15 : Up. 786000 : Sen. 1,002,765 : Cost 52.41536713 : Time 278.23s : 13248.67 words/s
[2019-08-09 09:21:22] Ep. 15 : Up. 788000 : Sen. 1,206,853 : Cost 52.18233871 : Time 277.97s : 13277.92 words/s
[2019-08-09 09:26:01] Ep. 15 : Up. 790000 : Sen. 1,411,156 : Cost 52.69784164 : Time 279.12s : 13261.50 words/s
[2019-08-09 09:30:40] Ep. 15 : Up. 792000 : Sen. 1,616,218 : Cost 52.38953400 : Time 278.87s : 13303.28 words/s
[2019-08-09 09:35:20] Ep. 15 : Up. 794000 : Sen. 1,820,303 : Cost 52.71135712 : Time 279.37s : 13248.90 words/s
[2019-08-09 09:39:59] Ep. 15 : Up. 796000 : Sen. 2,024,633 : Cost 52.52815628 : Time 279.56s : 13242.48 words/s
[2019-08-09 09:44:38] Ep. 15 : Up. 798000 : Sen. 2,229,408 : Cost 52.35111237 : Time 279.13s : 13248.15 words/s
[2019-08-09 09:49:17] Ep. 15 : Up. 800000 : Sen. 2,434,055 : Cost 52.50503159 : Time 278.79s : 13235.42 words/s
[2019-08-09 09:49:17] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-09 09:49:22] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter800000.npz
[2019-08-09 09:49:24] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-09 09:49:30] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-09 09:49:48] [valid] Ep. 15 : Up. 800000 : cross-entropy : 54.2758 : stalled 1 times (last best: 54.1883)
[2019-08-09 09:49:54] [valid] Ep. 15 : Up. 800000 : perplexity : 8.48801 : stalled 1 times (last best: 8.45881)
[2019-08-09 09:50:45] [valid] Ep. 15 : Up. 800000 : translation : 23.7 : stalled 9 times (last best: 24.27)
[2019-08-09 09:55:26] Ep. 15 : Up. 802000 : Sen. 2,637,615 : Cost 52.82608414 : Time 368.65s : 10026.90 words/s
[2019-08-09 10:00:06] Ep. 15 : Up. 804000 : Sen. 2,841,981 : Cost 52.73837280 : Time 279.88s : 13238.37 words/s
[2019-08-09 10:04:46] Ep. 15 : Up. 806000 : Sen. 3,046,634 : Cost 52.56826401 : Time 280.31s : 13214.39 words/s
[2019-08-09 10:09:26] Ep. 15 : Up. 808000 : Sen. 3,250,080 : Cost 52.95748138 : Time 279.72s : 13182.40 words/s
[2019-08-09 10:14:06] Ep. 15 : Up. 810000 : Sen. 3,453,966 : Cost 52.74843216 : Time 280.51s : 13146.08 words/s
[2019-08-09 10:18:46] Ep. 15 : Up. 812000 : Sen. 3,658,594 : Cost 52.76004791 : Time 280.10s : 13227.88 words/s
[2019-08-09 10:23:26] Ep. 15 : Up. 814000 : Sen. 3,862,882 : Cost 52.55873489 : Time 279.85s : 13205.49 words/s
[2019-08-09 10:28:06] Ep. 15 : Up. 816000 : Sen. 4,066,795 : Cost 52.93650818 : Time 279.92s : 13218.79 words/s
[2019-08-09 10:32:45] Ep. 15 : Up. 818000 : Sen. 4,270,776 : Cost 52.87720490 : Time 279.26s : 13241.02 words/s
[2019-08-09 10:37:25] Ep. 15 : Up. 820000 : Sen. 4,474,655 : Cost 52.80604172 : Time 279.90s : 13204.70 words/s
[2019-08-09 10:37:25] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-09 10:37:30] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter820000.npz
[2019-08-09 10:37:32] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-09 10:37:38] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-09 10:37:56] [valid] Ep. 15 : Up. 820000 : cross-entropy : 54.1141 : new best
[2019-08-09 10:38:03] [valid] Ep. 15 : Up. 820000 : perplexity : 8.43412 : new best
[2019-08-09 10:38:53] [valid] Ep. 15 : Up. 820000 : translation : 24 : stalled 10 times (last best: 24.27)
[2019-08-09 10:43:34] Ep. 15 : Up. 822000 : Sen. 4,678,769 : Cost 52.99792862 : Time 369.17s : 10033.23 words/s
[2019-08-09 10:48:15] Ep. 15 : Up. 824000 : Sen. 4,883,434 : Cost 52.64905930 : Time 280.45s : 13202.22 words/s
[2019-08-09 10:52:55] Ep. 15 : Up. 826000 : Sen. 5,088,000 : Cost 52.90771103 : Time 280.00s : 13210.29 words/s
[2019-08-09 10:57:35] Ep. 15 : Up. 828000 : Sen. 5,291,769 : Cost 52.98157883 : Time 279.83s : 13225.47 words/s
[2019-08-09 11:02:15] Ep. 15 : Up. 830000 : Sen. 5,495,894 : Cost 53.08435059 : Time 280.32s : 13192.32 words/s
[2019-08-09 11:06:00] Seen 5659635 samples
[2019-08-09 11:06:00] Starting epoch 16
[2019-08-09 11:06:00] [data] Shuffling data
[2019-08-09 11:06:04] [data] Done reading 6422600 sentences
[2019-08-09 11:06:33] [data] Done shuffling 6422600 sentences to temp files
[2019-08-09 11:07:28] Ep. 16 : Up. 832000 : Sen. 39,806 : Cost 52.85631180 : Time 312.99s : 11780.48 words/s
[2019-08-09 11:12:08] Ep. 16 : Up. 834000 : Sen. 243,836 : Cost 52.03498840 : Time 279.82s : 13224.97 words/s
[2019-08-09 11:16:47] Ep. 16 : Up. 836000 : Sen. 447,584 : Cost 51.97702408 : Time 278.63s : 13250.36 words/s
[2019-08-09 11:21:26] Ep. 16 : Up. 838000 : Sen. 651,815 : Cost 52.08500671 : Time 279.30s : 13237.25 words/s
[2019-08-09 11:26:05] Ep. 16 : Up. 840000 : Sen. 855,255 : Cost 52.03249741 : Time 278.79s : 13204.27 words/s
[2019-08-09 11:26:05] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-09 11:26:10] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter840000.npz
[2019-08-09 11:26:12] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-09 11:26:17] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-09 11:26:36] [valid] Ep. 16 : Up. 840000 : cross-entropy : 54.1746 : stalled 1 times (last best: 54.1141)
[2019-08-09 11:26:42] [valid] Ep. 16 : Up. 840000 : perplexity : 8.45424 : stalled 1 times (last best: 8.43412)
[2019-08-09 11:27:33] [valid] Ep. 16 : Up. 840000 : translation : 23.66 : stalled 11 times (last best: 24.27)
[2019-08-09 11:32:15] Ep. 16 : Up. 842000 : Sen. 1,059,779 : Cost 52.42090225 : Time 370.70s : 10023.18 words/s
[2019-08-09 11:36:55] Ep. 16 : Up. 844000 : Sen. 1,264,673 : Cost 52.13760757 : Time 279.55s : 13252.89 words/s
[2019-08-09 11:41:34] Ep. 16 : Up. 846000 : Sen. 1,468,378 : Cost 52.26588058 : Time 279.42s : 13206.58 words/s
[2019-08-09 11:46:14] Ep. 16 : Up. 848000 : Sen. 1,672,810 : Cost 52.00186539 : Time 279.21s : 13243.94 words/s
[2019-08-09 11:50:54] Ep. 16 : Up. 850000 : Sen. 1,877,121 : Cost 52.18646240 : Time 280.70s : 13173.50 words/s
[2019-08-09 11:55:34] Ep. 16 : Up. 852000 : Sen. 2,080,998 : Cost 52.31448746 : Time 279.54s : 13211.67 words/s
[2019-08-09 12:00:14] Ep. 16 : Up. 854000 : Sen. 2,285,199 : Cost 52.47268677 : Time 279.92s : 13230.43 words/s
[2019-08-09 12:04:52] Ep. 16 : Up. 856000 : Sen. 2,489,234 : Cost 52.54673004 : Time 278.72s : 13236.36 words/s
[2019-08-09 12:09:32] Ep. 16 : Up. 858000 : Sen. 2,693,663 : Cost 52.54053116 : Time 279.40s : 13243.19 words/s
[2019-08-09 12:14:11] Ep. 16 : Up. 860000 : Sen. 2,897,485 : Cost 52.23078537 : Time 278.85s : 13228.61 words/s
[2019-08-09 12:14:11] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-09 12:14:16] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter860000.npz
[2019-08-09 12:14:18] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-09 12:14:23] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-09 12:14:41] [valid] Ep. 16 : Up. 860000 : cross-entropy : 54.2883 : stalled 2 times (last best: 54.1141)
[2019-08-09 12:14:48] [valid] Ep. 16 : Up. 860000 : perplexity : 8.4922 : stalled 2 times (last best: 8.43412)
[2019-08-09 12:15:38] [valid] Ep. 16 : Up. 860000 : translation : 23.66 : stalled 12 times (last best: 24.27)
[2019-08-09 12:20:20] Ep. 16 : Up. 862000 : Sen. 3,102,023 : Cost 52.31777954 : Time 369.03s : 10022.59 words/s
[2019-08-09 12:25:00] Ep. 16 : Up. 864000 : Sen. 3,305,979 : Cost 52.91898727 : Time 280.04s : 13221.49 words/s
[2019-08-09 12:29:40] Ep. 16 : Up. 866000 : Sen. 3,510,835 : Cost 52.57953262 : Time 279.79s : 13226.03 words/s
[2019-08-09 12:34:19] Ep. 16 : Up. 868000 : Sen. 3,714,797 : Cost 52.61209106 : Time 279.97s : 13206.44 words/s
[2019-08-09 12:38:59] Ep. 16 : Up. 870000 : Sen. 3,919,353 : Cost 52.53290558 : Time 279.49s : 13243.16 words/s
[2019-08-09 12:43:39] Ep. 16 : Up. 872000 : Sen. 4,123,652 : Cost 52.74707794 : Time 279.60s : 13239.07 words/s
[2019-08-09 12:48:18] Ep. 16 : Up. 874000 : Sen. 4,327,853 : Cost 52.76505661 : Time 279.90s : 13208.65 words/s
[2019-08-09 12:52:58] Ep. 16 : Up. 876000 : Sen. 4,531,525 : Cost 52.83027649 : Time 279.26s : 13214.89 words/s
[2019-08-09 12:57:37] Ep. 16 : Up. 878000 : Sen. 4,735,766 : Cost 52.82085800 : Time 279.66s : 13235.07 words/s
[2019-08-09 13:02:17] Ep. 16 : Up. 880000 : Sen. 4,939,915 : Cost 52.89333344 : Time 280.11s : 13213.81 words/s
[2019-08-09 13:02:17] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-09 13:02:23] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter880000.npz
[2019-08-09 13:02:25] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-09 13:02:30] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-09 13:02:49] [valid] Ep. 16 : Up. 880000 : cross-entropy : 54.2262 : stalled 3 times (last best: 54.1141)
[2019-08-09 13:02:55] [valid] Ep. 16 : Up. 880000 : perplexity : 8.47147 : stalled 3 times (last best: 8.43412)
[2019-08-09 13:03:45] [valid] Ep. 16 : Up. 880000 : translation : 23.77 : stalled 13 times (last best: 24.27)
[2019-08-09 13:08:26] Ep. 16 : Up. 882000 : Sen. 5,144,276 : Cost 52.58394241 : Time 368.87s : 10023.75 words/s
[2019-08-09 13:13:06] Ep. 16 : Up. 884000 : Sen. 5,348,522 : Cost 52.59978485 : Time 279.49s : 13249.78 words/s
[2019-08-09 13:17:47] Ep. 16 : Up. 886000 : Sen. 5,553,142 : Cost 52.83325577 : Time 280.74s : 13226.01 words/s
[2019-08-09 13:20:13] Seen 5659635 samples
[2019-08-09 13:20:13] Starting epoch 17
[2019-08-09 13:20:13] [data] Shuffling data
[2019-08-09 13:20:16] [data] Done reading 6422600 sentences
[2019-08-09 13:20:48] [data] Done shuffling 6422600 sentences to temp files
[2019-08-09 13:23:03] Ep. 17 : Up. 888000 : Sen. 97,590 : Cost 52.39070892 : Time 316.84s : 11696.79 words/s
[2019-08-09 13:27:43] Ep. 17 : Up. 890000 : Sen. 301,888 : Cost 51.44258499 : Time 279.83s : 13222.00 words/s
[2019-08-09 13:32:24] Ep. 17 : Up. 892000 : Sen. 507,089 : Cost 52.02031326 : Time 281.13s : 13237.17 words/s
[2019-08-09 13:37:04] Ep. 17 : Up. 894000 : Sen. 711,160 : Cost 51.92585754 : Time 279.99s : 13198.26 words/s
[2019-08-09 13:41:45] Ep. 17 : Up. 896000 : Sen. 915,373 : Cost 51.82561874 : Time 280.45s : 13184.29 words/s
[2019-08-09 13:46:26] Ep. 17 : Up. 898000 : Sen. 1,119,498 : Cost 51.90308380 : Time 281.43s : 13107.55 words/s
[2019-08-09 13:51:07] Ep. 17 : Up. 900000 : Sen. 1,323,191 : Cost 52.27376556 : Time 280.56s : 13179.56 words/s
[2019-08-09 13:51:07] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-09 13:51:12] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter900000.npz
[2019-08-09 13:51:14] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-09 13:51:19] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-09 13:51:37] [valid] Ep. 17 : Up. 900000 : cross-entropy : 54.274 : stalled 4 times (last best: 54.1141)
[2019-08-09 13:51:44] [valid] Ep. 17 : Up. 900000 : perplexity : 8.48742 : stalled 4 times (last best: 8.43412)
[2019-08-09 13:52:35] [valid] Ep. 17 : Up. 900000 : translation : 23.96 : stalled 14 times (last best: 24.27)
[2019-08-09 13:57:18] Ep. 17 : Up. 902000 : Sen. 1,527,906 : Cost 51.80023575 : Time 370.95s : 9982.39 words/s
[2019-08-09 14:01:57] Ep. 17 : Up. 904000 : Sen. 1,732,266 : Cost 52.03633118 : Time 279.58s : 13225.46 words/s
[2019-08-09 14:06:37] Ep. 17 : Up. 906000 : Sen. 1,936,631 : Cost 52.12372589 : Time 279.41s : 13223.13 words/s
[2019-08-09 14:11:18] Ep. 17 : Up. 908000 : Sen. 2,141,042 : Cost 52.08572388 : Time 281.06s : 13173.61 words/s
[2019-08-09 14:15:59] Ep. 17 : Up. 910000 : Sen. 2,344,768 : Cost 52.27070999 : Time 281.33s : 13106.52 words/s
[2019-08-09 14:20:40] Ep. 17 : Up. 912000 : Sen. 2,549,300 : Cost 52.33645630 : Time 280.55s : 13190.91 words/s
[2019-08-09 14:25:20] Ep. 17 : Up. 914000 : Sen. 2,753,817 : Cost 52.23363876 : Time 280.23s : 13201.22 words/s
[2019-08-09 14:30:01] Ep. 17 : Up. 916000 : Sen. 2,958,010 : Cost 52.45937729 : Time 281.26s : 13172.64 words/s
[2019-08-09 14:34:41] Ep. 17 : Up. 918000 : Sen. 3,161,756 : Cost 52.35750580 : Time 280.06s : 13188.97 words/s
[2019-08-09 14:39:21] Ep. 17 : Up. 920000 : Sen. 3,365,596 : Cost 52.41312408 : Time 279.81s : 13198.94 words/s
[2019-08-09 14:39:21] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-09 14:39:26] Saving model to ../experiments/100M_random_fasttext_prob/model/model.iter920000.npz
[2019-08-09 14:39:29] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-09 14:39:34] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
[2019-08-09 14:39:52] [valid] Ep. 17 : Up. 920000 : cross-entropy : 54.2261 : stalled 5 times (last best: 54.1141)
[2019-08-09 14:39:58] [valid] Ep. 17 : Up. 920000 : perplexity : 8.47143 : stalled 5 times (last best: 8.43412)
[2019-08-09 14:40:49] [valid] Ep. 17 : Up. 920000 : translation : 24.01 : stalled 15 times (last best: 24.27)
[2019-08-09 14:40:51] Training finished
[2019-08-09 14:40:56] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz.orig.npz
[2019-08-09 14:41:01] Saving model to ../experiments/100M_random_fasttext_prob/model/model.npz
[2019-08-09 14:41:06] Saving Adam parameters to ../experiments/100M_random_fasttext_prob/model/model.npz.optimizer.npz
