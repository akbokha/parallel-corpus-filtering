[2019-08-07 11:15:35] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 11:15:35] [marian] Running on fulla as process 380613 with command line:
[2019-08-07 11:15:35] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_random_hardrules_v1.0/model/model.npz -T . --devices 5 --train-sets ../experiments/100M_random_hardrules_v1.0/data/train.bpe.de ../experiments/100M_random_hardrules_v1.0/data/train.bpe.en --vocabs ../experiments/100M_random_hardrules_v1.0/data/train.bpe.de.json ../experiments/100M_random_hardrules_v1.0/data/train.bpe.en.json --mini-batch-fit -w 5000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_random_hardrules_v1.0/data/dev.bpe.de ../experiments/100M_random_hardrules_v1.0/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_random_hardrules_v1.0/model/dev.out --valid-script-path ../experiments/100M_random_hardrules_v1.0/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_random_hardrules_v1.0/model/train.log --valid-log ../experiments/100M_random_hardrules_v1.0/model/valid.log
[2019-08-07 11:15:35] [config] after-batches: 0
[2019-08-07 11:15:35] [config] after-epochs: 0
[2019-08-07 11:15:35] [config] allow-unk: false
[2019-08-07 11:15:35] [config] beam-size: 12
[2019-08-07 11:15:35] [config] bert-class-symbol: "[CLS]"
[2019-08-07 11:15:35] [config] bert-mask-symbol: "[MASK]"
[2019-08-07 11:15:35] [config] bert-masking-fraction: 0.15
[2019-08-07 11:15:35] [config] bert-sep-symbol: "[SEP]"
[2019-08-07 11:15:35] [config] bert-train-type-embeddings: true
[2019-08-07 11:15:35] [config] bert-type-vocab-size: 2
[2019-08-07 11:15:35] [config] best-deep: false
[2019-08-07 11:15:35] [config] clip-gemm: 0
[2019-08-07 11:15:35] [config] clip-norm: 1
[2019-08-07 11:15:35] [config] cost-type: ce-mean
[2019-08-07 11:15:35] [config] cpu-threads: 0
[2019-08-07 11:15:35] [config] data-weighting: ""
[2019-08-07 11:15:35] [config] data-weighting-type: sentence
[2019-08-07 11:15:35] [config] dec-cell: gru
[2019-08-07 11:15:35] [config] dec-cell-base-depth: 2
[2019-08-07 11:15:35] [config] dec-cell-high-depth: 1
[2019-08-07 11:15:35] [config] dec-depth: 1
[2019-08-07 11:15:35] [config] devices:
[2019-08-07 11:15:35] [config]   - 5
[2019-08-07 11:15:35] [config] dim-emb: 512
[2019-08-07 11:15:35] [config] dim-rnn: 1024
[2019-08-07 11:15:35] [config] dim-vocabs:
[2019-08-07 11:15:35] [config]   - 50000
[2019-08-07 11:15:35] [config]   - 50000
[2019-08-07 11:15:35] [config] disp-first: 0
[2019-08-07 11:15:35] [config] disp-freq: 2000
[2019-08-07 11:15:35] [config] disp-label-counts: false
[2019-08-07 11:15:35] [config] dropout-rnn: 0.2
[2019-08-07 11:15:35] [config] dropout-src: 0.1
[2019-08-07 11:15:35] [config] dropout-trg: 0.1
[2019-08-07 11:15:35] [config] dump-config: ""
[2019-08-07 11:15:35] [config] early-stopping: 5
[2019-08-07 11:15:35] [config] embedding-fix-src: false
[2019-08-07 11:15:35] [config] embedding-fix-trg: false
[2019-08-07 11:15:35] [config] embedding-normalization: false
[2019-08-07 11:15:35] [config] embedding-vectors:
[2019-08-07 11:15:35] [config]   []
[2019-08-07 11:15:35] [config] enc-cell: gru
[2019-08-07 11:15:35] [config] enc-cell-depth: 1
[2019-08-07 11:15:35] [config] enc-depth: 1
[2019-08-07 11:15:35] [config] enc-type: bidirectional
[2019-08-07 11:15:35] [config] exponential-smoothing: 0.0001
[2019-08-07 11:15:35] [config] grad-dropping-momentum: 0
[2019-08-07 11:15:35] [config] grad-dropping-rate: 0
[2019-08-07 11:15:35] [config] grad-dropping-warmup: 100
[2019-08-07 11:15:35] [config] guided-alignment: none
[2019-08-07 11:15:35] [config] guided-alignment-cost: mse
[2019-08-07 11:15:35] [config] guided-alignment-weight: 0.1
[2019-08-07 11:15:35] [config] ignore-model-config: false
[2019-08-07 11:15:35] [config] input-types:
[2019-08-07 11:15:35] [config]   []
[2019-08-07 11:15:35] [config] interpolate-env-vars: false
[2019-08-07 11:15:35] [config] keep-best: false
[2019-08-07 11:15:35] [config] label-smoothing: 0
[2019-08-07 11:15:35] [config] layer-normalization: true
[2019-08-07 11:15:35] [config] learn-rate: 0.0001
[2019-08-07 11:15:35] [config] log: ../experiments/100M_random_hardrules_v1.0/model/train.log
[2019-08-07 11:15:35] [config] log-level: info
[2019-08-07 11:15:35] [config] log-time-zone: ""
[2019-08-07 11:15:35] [config] lr-decay: 0
[2019-08-07 11:15:35] [config] lr-decay-freq: 50000
[2019-08-07 11:15:35] [config] lr-decay-inv-sqrt:
[2019-08-07 11:15:35] [config]   - 0
[2019-08-07 11:15:35] [config] lr-decay-repeat-warmup: false
[2019-08-07 11:15:35] [config] lr-decay-reset-optimizer: false
[2019-08-07 11:15:35] [config] lr-decay-start:
[2019-08-07 11:15:35] [config]   - 10
[2019-08-07 11:15:35] [config]   - 1
[2019-08-07 11:15:35] [config] lr-decay-strategy: epoch+stalled
[2019-08-07 11:15:35] [config] lr-report: false
[2019-08-07 11:15:35] [config] lr-warmup: 0
[2019-08-07 11:15:35] [config] lr-warmup-at-reload: false
[2019-08-07 11:15:35] [config] lr-warmup-cycle: false
[2019-08-07 11:15:35] [config] lr-warmup-start-rate: 0
[2019-08-07 11:15:35] [config] max-length: 50
[2019-08-07 11:15:35] [config] max-length-crop: false
[2019-08-07 11:15:35] [config] max-length-factor: 3
[2019-08-07 11:15:35] [config] maxi-batch: 100
[2019-08-07 11:15:35] [config] maxi-batch-sort: trg
[2019-08-07 11:15:35] [config] mini-batch: 64
[2019-08-07 11:15:35] [config] mini-batch-fit: true
[2019-08-07 11:15:35] [config] mini-batch-fit-step: 10
[2019-08-07 11:15:35] [config] mini-batch-overstuff: 1
[2019-08-07 11:15:35] [config] mini-batch-track-lr: false
[2019-08-07 11:15:35] [config] mini-batch-understuff: 1
[2019-08-07 11:15:35] [config] mini-batch-warmup: 0
[2019-08-07 11:15:35] [config] mini-batch-words: 0
[2019-08-07 11:15:35] [config] mini-batch-words-ref: 0
[2019-08-07 11:15:35] [config] model: ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-07 11:15:35] [config] multi-loss-type: sum
[2019-08-07 11:15:35] [config] multi-node: false
[2019-08-07 11:15:35] [config] multi-node-overlap: true
[2019-08-07 11:15:35] [config] n-best: false
[2019-08-07 11:15:35] [config] no-nccl: false
[2019-08-07 11:15:35] [config] no-reload: false
[2019-08-07 11:15:35] [config] no-restore-corpus: false
[2019-08-07 11:15:35] [config] no-shuffle: false
[2019-08-07 11:15:35] [config] normalize: 1
[2019-08-07 11:15:35] [config] num-devices: 0
[2019-08-07 11:15:35] [config] optimizer: adam
[2019-08-07 11:15:35] [config] optimizer-delay: 1
[2019-08-07 11:15:35] [config] optimizer-params:
[2019-08-07 11:15:35] [config]   []
[2019-08-07 11:15:35] [config] overwrite: false
[2019-08-07 11:15:35] [config] pretrained-model: ""
[2019-08-07 11:15:35] [config] quiet: false
[2019-08-07 11:15:35] [config] quiet-translation: true
[2019-08-07 11:15:35] [config] relative-paths: false
[2019-08-07 11:15:35] [config] right-left: false
[2019-08-07 11:15:35] [config] save-freq: 20000
[2019-08-07 11:15:35] [config] seed: 1111
[2019-08-07 11:15:35] [config] shuffle-in-ram: false
[2019-08-07 11:15:35] [config] skip: false
[2019-08-07 11:15:35] [config] sqlite: ""
[2019-08-07 11:15:35] [config] sqlite-drop: false
[2019-08-07 11:15:35] [config] sync-sgd: true
[2019-08-07 11:15:35] [config] tempdir: .
[2019-08-07 11:15:35] [config] tied-embeddings: false
[2019-08-07 11:15:35] [config] tied-embeddings-all: false
[2019-08-07 11:15:35] [config] tied-embeddings-src: false
[2019-08-07 11:15:35] [config] train-sets:
[2019-08-07 11:15:35] [config]   - ../experiments/100M_random_hardrules_v1.0/data/train.bpe.de
[2019-08-07 11:15:35] [config]   - ../experiments/100M_random_hardrules_v1.0/data/train.bpe.en
[2019-08-07 11:15:35] [config] transformer-aan-activation: swish
[2019-08-07 11:15:35] [config] transformer-aan-depth: 2
[2019-08-07 11:15:35] [config] transformer-aan-nogate: false
[2019-08-07 11:15:35] [config] transformer-decoder-autoreg: self-attention
[2019-08-07 11:15:35] [config] transformer-dim-aan: 2048
[2019-08-07 11:15:35] [config] transformer-dim-ffn: 2048
[2019-08-07 11:15:35] [config] transformer-dropout: 0
[2019-08-07 11:15:35] [config] transformer-dropout-attention: 0
[2019-08-07 11:15:35] [config] transformer-dropout-ffn: 0
[2019-08-07 11:15:35] [config] transformer-ffn-activation: swish
[2019-08-07 11:15:35] [config] transformer-ffn-depth: 2
[2019-08-07 11:15:35] [config] transformer-guided-alignment-layer: last
[2019-08-07 11:15:35] [config] transformer-heads: 8
[2019-08-07 11:15:35] [config] transformer-no-projection: false
[2019-08-07 11:15:35] [config] transformer-postprocess: dan
[2019-08-07 11:15:35] [config] transformer-postprocess-emb: d
[2019-08-07 11:15:35] [config] transformer-preprocess: ""
[2019-08-07 11:15:35] [config] transformer-tied-layers:
[2019-08-07 11:15:35] [config]   []
[2019-08-07 11:15:35] [config] transformer-train-position-embeddings: false
[2019-08-07 11:15:35] [config] type: amun
[2019-08-07 11:15:35] [config] ulr: false
[2019-08-07 11:15:35] [config] ulr-dim-emb: 0
[2019-08-07 11:15:35] [config] ulr-dropout: 0
[2019-08-07 11:15:35] [config] ulr-keys-vectors: ""
[2019-08-07 11:15:35] [config] ulr-query-vectors: ""
[2019-08-07 11:15:35] [config] ulr-softmax-temperature: 1
[2019-08-07 11:15:35] [config] ulr-trainable-transformation: false
[2019-08-07 11:15:35] [config] valid-freq: 20000
[2019-08-07 11:15:35] [config] valid-log: ../experiments/100M_random_hardrules_v1.0/model/valid.log
[2019-08-07 11:15:35] [config] valid-max-length: 1000
[2019-08-07 11:15:35] [config] valid-metrics:
[2019-08-07 11:15:35] [config]   - cross-entropy
[2019-08-07 11:15:35] [config]   - perplexity
[2019-08-07 11:15:35] [config]   - translation
[2019-08-07 11:15:35] [config] valid-mini-batch: 8
[2019-08-07 11:15:35] [config] valid-script-path: ../experiments/100M_random_hardrules_v1.0/score-dev.sh
[2019-08-07 11:15:35] [config] valid-sets:
[2019-08-07 11:15:35] [config]   - ../experiments/100M_random_hardrules_v1.0/data/dev.bpe.de
[2019-08-07 11:15:35] [config]   - ../experiments/100M_random_hardrules_v1.0/data/dev.bpe.en
[2019-08-07 11:15:35] [config] valid-translation-output: ../experiments/100M_random_hardrules_v1.0/model/dev.out
[2019-08-07 11:15:35] [config] vocabs:
[2019-08-07 11:15:35] [config]   - ../experiments/100M_random_hardrules_v1.0/data/train.bpe.de.json
[2019-08-07 11:15:35] [config]   - ../experiments/100M_random_hardrules_v1.0/data/train.bpe.en.json
[2019-08-07 11:15:35] [config] word-penalty: 0
[2019-08-07 11:15:35] [config] workspace: 5000
[2019-08-07 11:15:35] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 11:15:35] Using synchronous training
[2019-08-07 11:15:35] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_random_hardrules_v1.0/data/train.bpe.de.json
[2019-08-07 11:15:35] [data] Using unused word id eos for 0
[2019-08-07 11:15:35] [data] Using unused word id UNK for 1
[2019-08-07 11:15:35] [data] Setting vocabulary size for input 0 to 50000
[2019-08-07 11:15:35] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_random_hardrules_v1.0/data/train.bpe.en.json
[2019-08-07 11:15:36] [data] Using unused word id eos for 0
[2019-08-07 11:15:36] [data] Using unused word id UNK for 1
[2019-08-07 11:15:36] [data] Setting vocabulary size for input 1 to 50000
[2019-08-07 11:15:36] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-07 11:15:36] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-07 11:15:37] [memory] Extending reserved space to 5120 MB (device gpu5)
[2019-08-07 11:15:38] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 11:15:38] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 11:15:38] [training] Using 1 GPUs
[2019-08-07 11:15:38] [memory] Reserving 422 MB, device gpu5
[2019-08-07 11:15:38] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-07 11:15:38] [memory] Reserving 422 MB, device gpu5
[2019-08-07 11:15:46] [batching] Done. Typical MB size is 6880 target words
[2019-08-07 11:15:46] [memory] Extending reserved space to 5120 MB (device gpu5)
[2019-08-07 11:15:46] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 11:15:46] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 11:15:46] [training] Using 1 GPUs
[2019-08-07 11:15:46] Training started
[2019-08-07 11:15:46] [data] Shuffling data
[2019-08-07 11:15:50] [data] Done reading 6886952 sentences
[2019-08-07 11:16:19] [data] Done shuffling 6886952 sentences to temp files
[2019-08-07 11:16:27] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-07 11:16:27] [memory] Reserving 422 MB, device gpu5
[2019-08-07 11:16:27] [memory] Reserving 422 MB, device gpu5
[2019-08-07 11:16:27] [memory] Reserving 422 MB, device gpu5
[2019-08-07 11:16:27] [memory] Reserving 844 MB, device gpu5
[2019-08-07 11:29:36] Ep. 1 : Up. 2000 : Sen. 327,144 : Cost 123.92922974 : Time 840.76s : 7089.15 words/s
[2019-08-07 11:42:33] Ep. 1 : Up. 4000 : Sen. 654,156 : Cost 106.00535583 : Time 777.03s : 7669.16 words/s
[2019-08-07 11:48:47] Ep. 1 : Up. 6000 : Sen. 979,375 : Cost 98.01845551 : Time 373.56s : 15867.55 words/s
[2019-08-07 11:55:00] Ep. 1 : Up. 8000 : Sen. 1,303,530 : Cost 92.38931274 : Time 373.20s : 15814.86 words/s
[2019-08-07 12:01:13] Ep. 1 : Up. 10000 : Sen. 1,629,364 : Cost 88.48403931 : Time 373.38s : 15898.25 words/s
[2019-08-07 15:39:20] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 15:39:20] [marian] Running on fulla as process 5131 with command line:
[2019-08-07 15:39:20] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_random_hardrules_v1.0/model/model.npz -T . --devices 5 --train-sets ../experiments/100M_random_hardrules_v1.0/data/train.bpe.de ../experiments/100M_random_hardrules_v1.0/data/train.bpe.en --vocabs ../experiments/100M_random_hardrules_v1.0/data/train.bpe.de.json ../experiments/100M_random_hardrules_v1.0/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_random_hardrules_v1.0/data/dev.bpe.de ../experiments/100M_random_hardrules_v1.0/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_random_hardrules_v1.0/model/dev.out --valid-script-path ../experiments/100M_random_hardrules_v1.0/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_random_hardrules_v1.0/model/train.log --valid-log ../experiments/100M_random_hardrules_v1.0/model/valid.log
[2019-08-07 15:39:20] [config] after-batches: 0
[2019-08-07 15:39:20] [config] after-epochs: 0
[2019-08-07 15:39:20] [config] allow-unk: false
[2019-08-07 15:39:20] [config] beam-size: 12
[2019-08-07 15:39:20] [config] bert-class-symbol: "[CLS]"
[2019-08-07 15:39:20] [config] bert-mask-symbol: "[MASK]"
[2019-08-07 15:39:20] [config] bert-masking-fraction: 0.15
[2019-08-07 15:39:20] [config] bert-sep-symbol: "[SEP]"
[2019-08-07 15:39:20] [config] bert-train-type-embeddings: true
[2019-08-07 15:39:20] [config] bert-type-vocab-size: 2
[2019-08-07 15:39:20] [config] best-deep: false
[2019-08-07 15:39:20] [config] clip-gemm: 0
[2019-08-07 15:39:20] [config] clip-norm: 1
[2019-08-07 15:39:20] [config] cost-type: ce-mean
[2019-08-07 15:39:20] [config] cpu-threads: 0
[2019-08-07 15:39:20] [config] data-weighting: ""
[2019-08-07 15:39:20] [config] data-weighting-type: sentence
[2019-08-07 15:39:20] [config] dec-cell: gru
[2019-08-07 15:39:20] [config] dec-cell-base-depth: 2
[2019-08-07 15:39:20] [config] dec-cell-high-depth: 1
[2019-08-07 15:39:20] [config] dec-depth: 1
[2019-08-07 15:39:20] [config] devices:
[2019-08-07 15:39:20] [config]   - 5
[2019-08-07 15:39:20] [config] dim-emb: 512
[2019-08-07 15:39:20] [config] dim-rnn: 1024
[2019-08-07 15:39:20] [config] dim-vocabs:
[2019-08-07 15:39:20] [config]   - 50000
[2019-08-07 15:39:20] [config]   - 50000
[2019-08-07 15:39:20] [config] disp-first: 0
[2019-08-07 15:39:20] [config] disp-freq: 2000
[2019-08-07 15:39:20] [config] disp-label-counts: false
[2019-08-07 15:39:20] [config] dropout-rnn: 0.2
[2019-08-07 15:39:20] [config] dropout-src: 0.1
[2019-08-07 15:39:20] [config] dropout-trg: 0.1
[2019-08-07 15:39:20] [config] dump-config: ""
[2019-08-07 15:39:20] [config] early-stopping: 5
[2019-08-07 15:39:20] [config] embedding-fix-src: false
[2019-08-07 15:39:20] [config] embedding-fix-trg: false
[2019-08-07 15:39:20] [config] embedding-normalization: false
[2019-08-07 15:39:20] [config] embedding-vectors:
[2019-08-07 15:39:20] [config]   []
[2019-08-07 15:39:20] [config] enc-cell: gru
[2019-08-07 15:39:20] [config] enc-cell-depth: 1
[2019-08-07 15:39:20] [config] enc-depth: 1
[2019-08-07 15:39:20] [config] enc-type: bidirectional
[2019-08-07 15:39:20] [config] exponential-smoothing: 0.0001
[2019-08-07 15:39:20] [config] grad-dropping-momentum: 0
[2019-08-07 15:39:20] [config] grad-dropping-rate: 0
[2019-08-07 15:39:20] [config] grad-dropping-warmup: 100
[2019-08-07 15:39:20] [config] guided-alignment: none
[2019-08-07 15:39:20] [config] guided-alignment-cost: mse
[2019-08-07 15:39:20] [config] guided-alignment-weight: 0.1
[2019-08-07 15:39:20] [config] ignore-model-config: false
[2019-08-07 15:39:20] [config] input-types:
[2019-08-07 15:39:20] [config]   []
[2019-08-07 15:39:20] [config] interpolate-env-vars: false
[2019-08-07 15:39:20] [config] keep-best: false
[2019-08-07 15:39:20] [config] label-smoothing: 0
[2019-08-07 15:39:20] [config] layer-normalization: true
[2019-08-07 15:39:20] [config] learn-rate: 0.0001
[2019-08-07 15:39:20] [config] log: ../experiments/100M_random_hardrules_v1.0/model/train.log
[2019-08-07 15:39:20] [config] log-level: info
[2019-08-07 15:39:20] [config] log-time-zone: ""
[2019-08-07 15:39:20] [config] lr-decay: 0
[2019-08-07 15:39:20] [config] lr-decay-freq: 50000
[2019-08-07 15:39:20] [config] lr-decay-inv-sqrt:
[2019-08-07 15:39:20] [config]   - 0
[2019-08-07 15:39:20] [config] lr-decay-repeat-warmup: false
[2019-08-07 15:39:20] [config] lr-decay-reset-optimizer: false
[2019-08-07 15:39:20] [config] lr-decay-start:
[2019-08-07 15:39:20] [config]   - 10
[2019-08-07 15:39:20] [config]   - 1
[2019-08-07 15:39:20] [config] lr-decay-strategy: epoch+stalled
[2019-08-07 15:39:20] [config] lr-report: false
[2019-08-07 15:39:20] [config] lr-warmup: 0
[2019-08-07 15:39:20] [config] lr-warmup-at-reload: false
[2019-08-07 15:39:20] [config] lr-warmup-cycle: false
[2019-08-07 15:39:20] [config] lr-warmup-start-rate: 0
[2019-08-07 15:39:20] [config] max-length: 50
[2019-08-07 15:39:20] [config] max-length-crop: false
[2019-08-07 15:39:20] [config] max-length-factor: 3
[2019-08-07 15:39:20] [config] maxi-batch: 100
[2019-08-07 15:39:20] [config] maxi-batch-sort: trg
[2019-08-07 15:39:20] [config] mini-batch: 64
[2019-08-07 15:39:20] [config] mini-batch-fit: true
[2019-08-07 15:39:20] [config] mini-batch-fit-step: 10
[2019-08-07 15:39:20] [config] mini-batch-overstuff: 1
[2019-08-07 15:39:20] [config] mini-batch-track-lr: false
[2019-08-07 15:39:20] [config] mini-batch-understuff: 1
[2019-08-07 15:39:20] [config] mini-batch-warmup: 0
[2019-08-07 15:39:20] [config] mini-batch-words: 0
[2019-08-07 15:39:20] [config] mini-batch-words-ref: 0
[2019-08-07 15:39:20] [config] model: ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-07 15:39:20] [config] multi-loss-type: sum
[2019-08-07 15:39:20] [config] multi-node: false
[2019-08-07 15:39:20] [config] multi-node-overlap: true
[2019-08-07 15:39:20] [config] n-best: false
[2019-08-07 15:39:20] [config] no-nccl: false
[2019-08-07 15:39:20] [config] no-reload: false
[2019-08-07 15:39:20] [config] no-restore-corpus: false
[2019-08-07 15:39:20] [config] no-shuffle: false
[2019-08-07 15:39:20] [config] normalize: 1
[2019-08-07 15:39:20] [config] num-devices: 0
[2019-08-07 15:39:20] [config] optimizer: adam
[2019-08-07 15:39:20] [config] optimizer-delay: 1
[2019-08-07 15:39:20] [config] optimizer-params:
[2019-08-07 15:39:20] [config]   []
[2019-08-07 15:39:20] [config] overwrite: false
[2019-08-07 15:39:20] [config] pretrained-model: ""
[2019-08-07 15:39:20] [config] quiet: false
[2019-08-07 15:39:20] [config] quiet-translation: true
[2019-08-07 15:39:20] [config] relative-paths: false
[2019-08-07 15:39:20] [config] right-left: false
[2019-08-07 15:39:20] [config] save-freq: 20000
[2019-08-07 15:39:20] [config] seed: 1111
[2019-08-07 15:39:20] [config] shuffle-in-ram: false
[2019-08-07 15:39:20] [config] skip: false
[2019-08-07 15:39:20] [config] sqlite: ""
[2019-08-07 15:39:20] [config] sqlite-drop: false
[2019-08-07 15:39:20] [config] sync-sgd: true
[2019-08-07 15:39:20] [config] tempdir: .
[2019-08-07 15:39:20] [config] tied-embeddings: false
[2019-08-07 15:39:20] [config] tied-embeddings-all: false
[2019-08-07 15:39:20] [config] tied-embeddings-src: false
[2019-08-07 15:39:20] [config] train-sets:
[2019-08-07 15:39:20] [config]   - ../experiments/100M_random_hardrules_v1.0/data/train.bpe.de
[2019-08-07 15:39:20] [config]   - ../experiments/100M_random_hardrules_v1.0/data/train.bpe.en
[2019-08-07 15:39:20] [config] transformer-aan-activation: swish
[2019-08-07 15:39:20] [config] transformer-aan-depth: 2
[2019-08-07 15:39:20] [config] transformer-aan-nogate: false
[2019-08-07 15:39:20] [config] transformer-decoder-autoreg: self-attention
[2019-08-07 15:39:20] [config] transformer-dim-aan: 2048
[2019-08-07 15:39:20] [config] transformer-dim-ffn: 2048
[2019-08-07 15:39:20] [config] transformer-dropout: 0
[2019-08-07 15:39:20] [config] transformer-dropout-attention: 0
[2019-08-07 15:39:20] [config] transformer-dropout-ffn: 0
[2019-08-07 15:39:20] [config] transformer-ffn-activation: swish
[2019-08-07 15:39:20] [config] transformer-ffn-depth: 2
[2019-08-07 15:39:20] [config] transformer-guided-alignment-layer: last
[2019-08-07 15:39:20] [config] transformer-heads: 8
[2019-08-07 15:39:20] [config] transformer-no-projection: false
[2019-08-07 15:39:20] [config] transformer-postprocess: dan
[2019-08-07 15:39:20] [config] transformer-postprocess-emb: d
[2019-08-07 15:39:20] [config] transformer-preprocess: ""
[2019-08-07 15:39:20] [config] transformer-tied-layers:
[2019-08-07 15:39:20] [config]   []
[2019-08-07 15:39:20] [config] transformer-train-position-embeddings: false
[2019-08-07 15:39:20] [config] type: amun
[2019-08-07 15:39:20] [config] ulr: false
[2019-08-07 15:39:20] [config] ulr-dim-emb: 0
[2019-08-07 15:39:20] [config] ulr-dropout: 0
[2019-08-07 15:39:20] [config] ulr-keys-vectors: ""
[2019-08-07 15:39:20] [config] ulr-query-vectors: ""
[2019-08-07 15:39:20] [config] ulr-softmax-temperature: 1
[2019-08-07 15:39:20] [config] ulr-trainable-transformation: false
[2019-08-07 15:39:20] [config] valid-freq: 20000
[2019-08-07 15:39:20] [config] valid-log: ../experiments/100M_random_hardrules_v1.0/model/valid.log
[2019-08-07 15:39:20] [config] valid-max-length: 1000
[2019-08-07 15:39:20] [config] valid-metrics:
[2019-08-07 15:39:20] [config]   - cross-entropy
[2019-08-07 15:39:20] [config]   - perplexity
[2019-08-07 15:39:20] [config]   - translation
[2019-08-07 15:39:20] [config] valid-mini-batch: 8
[2019-08-07 15:39:20] [config] valid-script-path: ../experiments/100M_random_hardrules_v1.0/score-dev.sh
[2019-08-07 15:39:20] [config] valid-sets:
[2019-08-07 15:39:20] [config]   - ../experiments/100M_random_hardrules_v1.0/data/dev.bpe.de
[2019-08-07 15:39:20] [config]   - ../experiments/100M_random_hardrules_v1.0/data/dev.bpe.en
[2019-08-07 15:39:20] [config] valid-translation-output: ../experiments/100M_random_hardrules_v1.0/model/dev.out
[2019-08-07 15:39:20] [config] vocabs:
[2019-08-07 15:39:20] [config]   - ../experiments/100M_random_hardrules_v1.0/data/train.bpe.de.json
[2019-08-07 15:39:20] [config]   - ../experiments/100M_random_hardrules_v1.0/data/train.bpe.en.json
[2019-08-07 15:39:20] [config] word-penalty: 0
[2019-08-07 15:39:20] [config] workspace: 3000
[2019-08-07 15:39:20] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 15:39:20] Using synchronous training
[2019-08-07 15:39:20] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_random_hardrules_v1.0/data/train.bpe.de.json
[2019-08-07 15:39:20] [data] Using unused word id eos for 0
[2019-08-07 15:39:20] [data] Using unused word id UNK for 1
[2019-08-07 15:39:20] [data] Setting vocabulary size for input 0 to 50000
[2019-08-07 15:39:20] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_random_hardrules_v1.0/data/train.bpe.en.json
[2019-08-07 15:39:21] [data] Using unused word id eos for 0
[2019-08-07 15:39:21] [data] Using unused word id UNK for 1
[2019-08-07 15:39:21] [data] Setting vocabulary size for input 1 to 50000
[2019-08-07 15:39:21] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-07 15:39:21] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-07 15:39:22] [memory] Extending reserved space to 3072 MB (device gpu5)
[2019-08-07 15:39:22] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 15:39:22] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 15:39:22] [training] Using 1 GPUs
[2019-08-07 15:39:22] [memory] Reserving 422 MB, device gpu5
[2019-08-07 15:39:22] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-07 15:39:22] [memory] Reserving 422 MB, device gpu5
[2019-08-07 15:39:25] [batching] Done. Typical MB size is 4042 target words
[2019-08-07 15:39:25] [memory] Extending reserved space to 3072 MB (device gpu5)
[2019-08-07 15:39:25] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 15:39:25] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 15:39:25] [training] Using 1 GPUs
[2019-08-07 15:39:25] Training started
[2019-08-07 15:39:25] [data] Shuffling data
[2019-08-07 15:39:40] [data] Done reading 6886952 sentences
[2019-08-07 15:40:05] [data] Done shuffling 6886952 sentences to temp files
[2019-08-07 15:40:15] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-07 15:40:15] [memory] Reserving 422 MB, device gpu5
[2019-08-07 15:40:15] [memory] Reserving 422 MB, device gpu5
[2019-08-07 15:40:15] [memory] Reserving 422 MB, device gpu5
[2019-08-07 15:40:15] [memory] Reserving 844 MB, device gpu5
[2019-08-07 15:44:57] Ep. 1 : Up. 2000 : Sen. 220,542 : Cost 126.00410461 : Time 336.44s : 11951.39 words/s
[2019-08-07 15:49:41] Ep. 1 : Up. 4000 : Sen. 441,285 : Cost 109.08965302 : Time 283.37s : 14194.71 words/s
[2019-08-07 15:54:25] Ep. 1 : Up. 6000 : Sen. 663,069 : Cost 101.14069366 : Time 284.38s : 14212.43 words/s
[2019-08-07 15:59:08] Ep. 1 : Up. 8000 : Sen. 883,830 : Cost 95.69681549 : Time 283.29s : 14187.63 words/s
[2019-08-07 16:03:53] Ep. 1 : Up. 10000 : Sen. 1,104,401 : Cost 92.06130981 : Time 284.85s : 14133.49 words/s
[2019-08-07 16:08:38] Ep. 1 : Up. 12000 : Sen. 1,325,809 : Cost 88.31901550 : Time 284.45s : 14143.32 words/s
[2019-08-07 16:13:23] Ep. 1 : Up. 14000 : Sen. 1,547,265 : Cost 86.13413239 : Time 285.17s : 14161.60 words/s
[2019-08-07 16:18:07] Ep. 1 : Up. 16000 : Sen. 1,768,897 : Cost 83.91419220 : Time 284.77s : 14170.28 words/s
[2019-08-07 16:22:52] Ep. 1 : Up. 18000 : Sen. 1,990,400 : Cost 81.93228912 : Time 284.89s : 14134.64 words/s
[2019-08-07 16:27:37] Ep. 1 : Up. 20000 : Sen. 2,210,697 : Cost 80.56837463 : Time 284.65s : 14126.29 words/s
[2019-08-07 16:27:37] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-07 16:27:46] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter20000.npz
[2019-08-07 16:27:53] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-07 16:28:02] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-07 16:28:27] [valid] Ep. 1 : Up. 20000 : cross-entropy : 98.8021 : new best
[2019-08-07 16:28:34] [valid] Ep. 1 : Up. 20000 : perplexity : 47.8777 : new best
[2019-08-07 16:29:48] [valid] Ep. 1 : Up. 20000 : translation : 4.99 : new best
[2019-08-07 16:55:48] Error: Error reading from file '.'
[2019-08-07 17:00:54] Error: Aborted from marian::io::InputFileStream& marian::io::getline(marian::io::InputFileStream&, std::__cxx11::string&) in /fs/bil0/abdel/marian-dev/src/common/file_stream.h:216

[CALL STACK]
[0x727f12]                                                            
[0x728ff8]          marian::data::Corpus::  next  ()                   + 0xd68
[0x716e4f]          marian::data::CorpusIterator::  increment  ()      + 0x2f
[0x681a7d]          marian::data::BatchGenerator<marian::data::CorpusBase>::  fetchBatches  () + 0x10dd
[0x682adb]          std::future<std::result_of<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1} ()>::type> marian::ThreadPool::enqueue<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}>(std::result_of&&,(marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}&&)...)::{lambda()#1}::  operator()  () const + 0x2b
[0x6834be]          std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base,std::__future_base::_Result_base::_Deleter> (),std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<std::deque<std::shared_ptr<marian::data::CorpusBatch>,std::allocator<std::shared_ptr<marian::data::CorpusBatch>>>>,std::__future_base::_Result_base::_Deleter>,std::_Bind_simple<std::reference_wrapper<std::future<std::result_of<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1} ()>::type> marian::ThreadPool::enqueue<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}>(std::result_of&&,(marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}&&)...)::{lambda()#1}> ()>,std::deque<std::shared_ptr<marian::data::CorpusBatch>,std::allocator<std::shared_ptr<marian::data::CorpusBatch>>>>>::  _M_invoke  (std::_Any_data const&) + 0x3e
[0x5a5f19]          std::__future_base::_State_baseV2::  _M_do_set  (std::function<std::unique_ptr<std::__future_base::_Result_base,std::__future_base::_Result_base::_Deleter> ()>*,  bool*) + 0x29
[0x7f438b3cda99]                                                       + 0xea99
[0x59fac2]                                                            
[0x5a7341]          std::__future_base::_Task_state<std::future<std::result_of<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1} ()>::type> marian::ThreadPool::enqueue<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}>(std::result_of&&,(marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}&&)...)::{lambda()#1},std::allocator<int>,std::deque<std::shared_ptr<marian::data::CorpusBatch>,std::allocator<std::shared_ptr>> ()>::  _M_run  () + 0x51
[0x5d00b4]          std::thread::_Impl<std::_Bind_simple<marian::ThreadPool::reserve(unsigned long)::{lambda()#1} ()>>::  _M_run  () + 0x174
[0x7f438aeedc80]                                                       + 0xb8c80
[0x7f438b3c66ba]                                                       + 0x76ba
[0x7f438a65341d]    clone                                              + 0x6d

[2019-08-07 17:35:29] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 17:35:29] [marian] Running on fulla as process 14811 with command line:
[2019-08-07 17:35:29] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_random_hardrules_v1.0/model/model.npz -T . --devices 5 --train-sets ../experiments/100M_random_hardrules_v1.0/data/train.bpe.de ../experiments/100M_random_hardrules_v1.0/data/train.bpe.en --vocabs ../experiments/100M_random_hardrules_v1.0/data/train.bpe.de.json ../experiments/100M_random_hardrules_v1.0/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_random_hardrules_v1.0/data/dev.bpe.de ../experiments/100M_random_hardrules_v1.0/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_random_hardrules_v1.0/model/dev.out --valid-script-path ../experiments/100M_random_hardrules_v1.0/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_random_hardrules_v1.0/model/train.log --valid-log ../experiments/100M_random_hardrules_v1.0/model/valid.log
[2019-08-07 17:35:29] [config] after-batches: 0
[2019-08-07 17:35:29] [config] after-epochs: 0
[2019-08-07 17:35:29] [config] allow-unk: false
[2019-08-07 17:35:29] [config] beam-size: 12
[2019-08-07 17:35:29] [config] bert-class-symbol: "[CLS]"
[2019-08-07 17:35:29] [config] bert-mask-symbol: "[MASK]"
[2019-08-07 17:35:29] [config] bert-masking-fraction: 0.15
[2019-08-07 17:35:29] [config] bert-sep-symbol: "[SEP]"
[2019-08-07 17:35:29] [config] bert-train-type-embeddings: true
[2019-08-07 17:35:29] [config] bert-type-vocab-size: 2
[2019-08-07 17:35:29] [config] best-deep: false
[2019-08-07 17:35:29] [config] clip-gemm: 0
[2019-08-07 17:35:29] [config] clip-norm: 1
[2019-08-07 17:35:29] [config] cost-type: ce-mean
[2019-08-07 17:35:29] [config] cpu-threads: 0
[2019-08-07 17:35:29] [config] data-weighting: ""
[2019-08-07 17:35:29] [config] data-weighting-type: sentence
[2019-08-07 17:35:29] [config] dec-cell: gru
[2019-08-07 17:35:29] [config] dec-cell-base-depth: 2
[2019-08-07 17:35:29] [config] dec-cell-high-depth: 1
[2019-08-07 17:35:29] [config] dec-depth: 1
[2019-08-07 17:35:29] [config] devices:
[2019-08-07 17:35:29] [config]   - 5
[2019-08-07 17:35:29] [config] dim-emb: 512
[2019-08-07 17:35:29] [config] dim-rnn: 1024
[2019-08-07 17:35:29] [config] dim-vocabs:
[2019-08-07 17:35:29] [config]   - 50000
[2019-08-07 17:35:29] [config]   - 50000
[2019-08-07 17:35:29] [config] disp-first: 0
[2019-08-07 17:35:29] [config] disp-freq: 2000
[2019-08-07 17:35:29] [config] disp-label-counts: false
[2019-08-07 17:35:29] [config] dropout-rnn: 0.2
[2019-08-07 17:35:29] [config] dropout-src: 0.1
[2019-08-07 17:35:29] [config] dropout-trg: 0.1
[2019-08-07 17:35:29] [config] dump-config: ""
[2019-08-07 17:35:29] [config] early-stopping: 5
[2019-08-07 17:35:29] [config] embedding-fix-src: false
[2019-08-07 17:35:29] [config] embedding-fix-trg: false
[2019-08-07 17:35:29] [config] embedding-normalization: false
[2019-08-07 17:35:29] [config] embedding-vectors:
[2019-08-07 17:35:29] [config]   []
[2019-08-07 17:35:29] [config] enc-cell: gru
[2019-08-07 17:35:29] [config] enc-cell-depth: 1
[2019-08-07 17:35:29] [config] enc-depth: 1
[2019-08-07 17:35:29] [config] enc-type: bidirectional
[2019-08-07 17:35:29] [config] exponential-smoothing: 0.0001
[2019-08-07 17:35:29] [config] grad-dropping-momentum: 0
[2019-08-07 17:35:29] [config] grad-dropping-rate: 0
[2019-08-07 17:35:29] [config] grad-dropping-warmup: 100
[2019-08-07 17:35:29] [config] guided-alignment: none
[2019-08-07 17:35:29] [config] guided-alignment-cost: mse
[2019-08-07 17:35:29] [config] guided-alignment-weight: 0.1
[2019-08-07 17:35:29] [config] ignore-model-config: false
[2019-08-07 17:35:29] [config] input-types:
[2019-08-07 17:35:29] [config]   []
[2019-08-07 17:35:29] [config] interpolate-env-vars: false
[2019-08-07 17:35:29] [config] keep-best: false
[2019-08-07 17:35:29] [config] label-smoothing: 0
[2019-08-07 17:35:29] [config] layer-normalization: true
[2019-08-07 17:35:29] [config] learn-rate: 0.0001
[2019-08-07 17:35:29] [config] log: ../experiments/100M_random_hardrules_v1.0/model/train.log
[2019-08-07 17:35:29] [config] log-level: info
[2019-08-07 17:35:29] [config] log-time-zone: ""
[2019-08-07 17:35:29] [config] lr-decay: 0
[2019-08-07 17:35:29] [config] lr-decay-freq: 50000
[2019-08-07 17:35:29] [config] lr-decay-inv-sqrt:
[2019-08-07 17:35:29] [config]   - 0
[2019-08-07 17:35:29] [config] lr-decay-repeat-warmup: false
[2019-08-07 17:35:29] [config] lr-decay-reset-optimizer: false
[2019-08-07 17:35:29] [config] lr-decay-start:
[2019-08-07 17:35:29] [config]   - 10
[2019-08-07 17:35:29] [config]   - 1
[2019-08-07 17:35:29] [config] lr-decay-strategy: epoch+stalled
[2019-08-07 17:35:29] [config] lr-report: false
[2019-08-07 17:35:29] [config] lr-warmup: 0
[2019-08-07 17:35:29] [config] lr-warmup-at-reload: false
[2019-08-07 17:35:29] [config] lr-warmup-cycle: false
[2019-08-07 17:35:29] [config] lr-warmup-start-rate: 0
[2019-08-07 17:35:29] [config] max-length: 50
[2019-08-07 17:35:29] [config] max-length-crop: false
[2019-08-07 17:35:29] [config] max-length-factor: 3
[2019-08-07 17:35:29] [config] maxi-batch: 100
[2019-08-07 17:35:29] [config] maxi-batch-sort: trg
[2019-08-07 17:35:29] [config] mini-batch: 64
[2019-08-07 17:35:29] [config] mini-batch-fit: true
[2019-08-07 17:35:29] [config] mini-batch-fit-step: 10
[2019-08-07 17:35:29] [config] mini-batch-overstuff: 1
[2019-08-07 17:35:29] [config] mini-batch-track-lr: false
[2019-08-07 17:35:29] [config] mini-batch-understuff: 1
[2019-08-07 17:35:29] [config] mini-batch-warmup: 0
[2019-08-07 17:35:29] [config] mini-batch-words: 0
[2019-08-07 17:35:29] [config] mini-batch-words-ref: 0
[2019-08-07 17:35:29] [config] model: ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-07 17:35:29] [config] multi-loss-type: sum
[2019-08-07 17:35:29] [config] multi-node: false
[2019-08-07 17:35:29] [config] multi-node-overlap: true
[2019-08-07 17:35:29] [config] n-best: false
[2019-08-07 17:35:29] [config] no-nccl: false
[2019-08-07 17:35:29] [config] no-reload: false
[2019-08-07 17:35:29] [config] no-restore-corpus: false
[2019-08-07 17:35:29] [config] no-shuffle: false
[2019-08-07 17:35:29] [config] normalize: 1
[2019-08-07 17:35:29] [config] num-devices: 0
[2019-08-07 17:35:29] [config] optimizer: adam
[2019-08-07 17:35:29] [config] optimizer-delay: 1
[2019-08-07 17:35:29] [config] optimizer-params:
[2019-08-07 17:35:29] [config]   []
[2019-08-07 17:35:29] [config] overwrite: false
[2019-08-07 17:35:29] [config] pretrained-model: ""
[2019-08-07 17:35:29] [config] quiet: false
[2019-08-07 17:35:29] [config] quiet-translation: true
[2019-08-07 17:35:29] [config] relative-paths: false
[2019-08-07 17:35:29] [config] right-left: false
[2019-08-07 17:35:29] [config] save-freq: 20000
[2019-08-07 17:35:29] [config] seed: 1111
[2019-08-07 17:35:29] [config] shuffle-in-ram: false
[2019-08-07 17:35:29] [config] skip: false
[2019-08-07 17:35:29] [config] sqlite: ""
[2019-08-07 17:35:29] [config] sqlite-drop: false
[2019-08-07 17:35:29] [config] sync-sgd: true
[2019-08-07 17:35:29] [config] tempdir: .
[2019-08-07 17:35:29] [config] tied-embeddings: false
[2019-08-07 17:35:29] [config] tied-embeddings-all: false
[2019-08-07 17:35:29] [config] tied-embeddings-src: false
[2019-08-07 17:35:29] [config] train-sets:
[2019-08-07 17:35:29] [config]   - ../experiments/100M_random_hardrules_v1.0/data/train.bpe.de
[2019-08-07 17:35:29] [config]   - ../experiments/100M_random_hardrules_v1.0/data/train.bpe.en
[2019-08-07 17:35:29] [config] transformer-aan-activation: swish
[2019-08-07 17:35:29] [config] transformer-aan-depth: 2
[2019-08-07 17:35:29] [config] transformer-aan-nogate: false
[2019-08-07 17:35:29] [config] transformer-decoder-autoreg: self-attention
[2019-08-07 17:35:29] [config] transformer-dim-aan: 2048
[2019-08-07 17:35:29] [config] transformer-dim-ffn: 2048
[2019-08-07 17:35:29] [config] transformer-dropout: 0
[2019-08-07 17:35:29] [config] transformer-dropout-attention: 0
[2019-08-07 17:35:29] [config] transformer-dropout-ffn: 0
[2019-08-07 17:35:29] [config] transformer-ffn-activation: swish
[2019-08-07 17:35:29] [config] transformer-ffn-depth: 2
[2019-08-07 17:35:29] [config] transformer-guided-alignment-layer: last
[2019-08-07 17:35:29] [config] transformer-heads: 8
[2019-08-07 17:35:29] [config] transformer-no-projection: false
[2019-08-07 17:35:29] [config] transformer-postprocess: dan
[2019-08-07 17:35:29] [config] transformer-postprocess-emb: d
[2019-08-07 17:35:29] [config] transformer-preprocess: ""
[2019-08-07 17:35:29] [config] transformer-tied-layers:
[2019-08-07 17:35:29] [config]   []
[2019-08-07 17:35:29] [config] transformer-train-position-embeddings: false
[2019-08-07 17:35:29] [config] type: amun
[2019-08-07 17:35:29] [config] ulr: false
[2019-08-07 17:35:29] [config] ulr-dim-emb: 0
[2019-08-07 17:35:29] [config] ulr-dropout: 0
[2019-08-07 17:35:29] [config] ulr-keys-vectors: ""
[2019-08-07 17:35:29] [config] ulr-query-vectors: ""
[2019-08-07 17:35:29] [config] ulr-softmax-temperature: 1
[2019-08-07 17:35:29] [config] ulr-trainable-transformation: false
[2019-08-07 17:35:29] [config] valid-freq: 20000
[2019-08-07 17:35:29] [config] valid-log: ../experiments/100M_random_hardrules_v1.0/model/valid.log
[2019-08-07 17:35:29] [config] valid-max-length: 1000
[2019-08-07 17:35:29] [config] valid-metrics:
[2019-08-07 17:35:29] [config]   - cross-entropy
[2019-08-07 17:35:29] [config]   - perplexity
[2019-08-07 17:35:29] [config]   - translation
[2019-08-07 17:35:29] [config] valid-mini-batch: 8
[2019-08-07 17:35:29] [config] valid-script-path: ../experiments/100M_random_hardrules_v1.0/score-dev.sh
[2019-08-07 17:35:29] [config] valid-sets:
[2019-08-07 17:35:29] [config]   - ../experiments/100M_random_hardrules_v1.0/data/dev.bpe.de
[2019-08-07 17:35:29] [config]   - ../experiments/100M_random_hardrules_v1.0/data/dev.bpe.en
[2019-08-07 17:35:29] [config] valid-translation-output: ../experiments/100M_random_hardrules_v1.0/model/dev.out
[2019-08-07 17:35:29] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 17:35:29] [config] vocabs:
[2019-08-07 17:35:29] [config]   - ../experiments/100M_random_hardrules_v1.0/data/train.bpe.de.json
[2019-08-07 17:35:29] [config]   - ../experiments/100M_random_hardrules_v1.0/data/train.bpe.en.json
[2019-08-07 17:35:29] [config] word-penalty: 0
[2019-08-07 17:35:29] [config] workspace: 3000
[2019-08-07 17:35:29] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-07 17:35:29] Using synchronous training
[2019-08-07 17:35:29] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_random_hardrules_v1.0/data/train.bpe.de.json
[2019-08-07 17:35:30] [data] Using unused word id eos for 0
[2019-08-07 17:35:30] [data] Using unused word id UNK for 1
[2019-08-07 17:35:30] [data] Setting vocabulary size for input 0 to 50000
[2019-08-07 17:35:30] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_random_hardrules_v1.0/data/train.bpe.en.json
[2019-08-07 17:35:30] [data] Using unused word id eos for 0
[2019-08-07 17:35:30] [data] Using unused word id UNK for 1
[2019-08-07 17:35:30] [data] Setting vocabulary size for input 1 to 50000
[2019-08-07 17:35:30] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-07 17:35:30] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-07 17:35:31] [memory] Extending reserved space to 3072 MB (device gpu5)
[2019-08-07 17:35:32] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 17:35:32] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 17:35:32] [training] Using 1 GPUs
[2019-08-07 17:35:32] [memory] Reserving 422 MB, device gpu5
[2019-08-07 17:35:32] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-07 17:35:32] [memory] Reserving 422 MB, device gpu5
[2019-08-07 17:35:34] [batching] Done. Typical MB size is 4042 target words
[2019-08-07 17:35:35] [memory] Extending reserved space to 3072 MB (device gpu5)
[2019-08-07 17:35:35] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-07 17:35:35] [comm] NCCLCommunicator constructed successfully.
[2019-08-07 17:35:35] [training] Using 1 GPUs
[2019-08-07 17:35:35] Loading model from ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-07 17:35:42] Loading Adam parameters from ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-07 17:35:56] [memory] Reserving 844 MB, device gpu5
[2019-08-07 17:35:57] [training] Model reloaded from ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-07 17:35:57] [data] Restoring the corpus state to epoch 1, batch 20000
[2019-08-07 17:35:57] [data] Shuffling data
[2019-08-07 17:36:01] [data] Done reading 6886952 sentences
[2019-08-07 17:37:13] [data] Done shuffling 6886952 sentences to temp files
[2019-08-07 17:38:10] Training started
[2019-08-07 17:38:10] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-07 17:38:10] [memory] Reserving 422 MB, device gpu5
[2019-08-07 17:38:10] [memory] Reserving 422 MB, device gpu5
[2019-08-07 17:38:10] Loading model from ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-07 17:38:18] [memory] Reserving 422 MB, device cpu0
[2019-08-07 17:38:19] [memory] Reserving 422 MB, device gpu5
[2019-08-07 17:42:59] Ep. 1 : Up. 22000 : Sen. 2,431,696 : Cost 79.46711731 : Time 448.28s : 8971.78 words/s
[2019-08-07 17:47:40] Ep. 1 : Up. 24000 : Sen. 2,652,573 : Cost 77.84938049 : Time 281.23s : 14300.99 words/s
[2019-08-07 17:52:22] Ep. 1 : Up. 26000 : Sen. 2,873,444 : Cost 76.67632294 : Time 282.19s : 14279.63 words/s
[2019-08-07 17:57:05] Ep. 1 : Up. 28000 : Sen. 3,095,432 : Cost 75.78791046 : Time 282.98s : 14309.16 words/s
[2019-08-07 18:01:50] Ep. 1 : Up. 30000 : Sen. 3,316,951 : Cost 74.78464508 : Time 285.31s : 14131.85 words/s
[2019-08-07 18:06:33] Ep. 1 : Up. 32000 : Sen. 3,537,886 : Cost 74.28036499 : Time 282.54s : 14271.65 words/s
[2019-08-07 18:11:15] Ep. 1 : Up. 34000 : Sen. 3,758,569 : Cost 73.30829620 : Time 282.09s : 14248.53 words/s
[2019-08-07 18:15:58] Ep. 1 : Up. 36000 : Sen. 3,979,734 : Cost 72.75160217 : Time 282.83s : 14245.04 words/s
[2019-08-07 18:20:42] Ep. 1 : Up. 38000 : Sen. 4,202,030 : Cost 72.17480469 : Time 283.74s : 14267.86 words/s
[2019-08-07 18:25:27] Ep. 1 : Up. 40000 : Sen. 4,423,536 : Cost 71.84108734 : Time 285.90s : 14141.43 words/s
[2019-08-07 18:25:27] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-07 18:25:40] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter40000.npz
[2019-08-07 18:25:47] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-07 18:25:57] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-07 18:26:22] [valid] Ep. 1 : Up. 40000 : cross-entropy : 78.3055 : new best
[2019-08-07 18:26:28] [valid] Ep. 1 : Up. 40000 : perplexity : 21.4579 : new best
[2019-08-07 18:27:38] [valid] Ep. 1 : Up. 40000 : translation : 10.57 : new best
[2019-08-07 18:32:23] Ep. 1 : Up. 42000 : Sen. 4,646,088 : Cost 70.82997131 : Time 416.05s : 9739.87 words/s
[2019-08-07 18:37:08] Ep. 1 : Up. 44000 : Sen. 4,867,428 : Cost 70.44397736 : Time 284.59s : 14174.42 words/s
[2019-08-07 18:41:52] Ep. 1 : Up. 46000 : Sen. 5,088,565 : Cost 70.32058716 : Time 283.95s : 14204.29 words/s
[2019-08-07 18:46:36] Ep. 1 : Up. 48000 : Sen. 5,309,674 : Cost 69.66416168 : Time 283.84s : 14190.45 words/s
[2019-08-07 18:51:18] Ep. 1 : Up. 50000 : Sen. 5,530,542 : Cost 69.36634827 : Time 282.35s : 14244.55 words/s
[2019-08-07 18:56:03] Ep. 1 : Up. 52000 : Sen. 5,752,049 : Cost 69.30397034 : Time 284.67s : 14217.19 words/s
[2019-08-07 19:00:46] Ep. 1 : Up. 54000 : Sen. 5,972,935 : Cost 68.50797272 : Time 283.55s : 14160.11 words/s
[2019-08-07 19:05:33] Ep. 1 : Up. 56000 : Sen. 6,194,659 : Cost 68.06898499 : Time 287.00s : 14087.41 words/s
[2019-08-07 19:06:55] Seen 6258441 samples
[2019-08-07 19:06:55] Starting epoch 2
[2019-08-07 19:06:55] [data] Shuffling data
[2019-08-07 19:06:59] [data] Done reading 6886952 sentences
[2019-08-07 19:07:24] [data] Done shuffling 6886952 sentences to temp files
[2019-08-07 19:10:54] Ep. 2 : Up. 58000 : Sen. 157,366 : Cost 67.04596710 : Time 320.48s : 12550.09 words/s
[2019-08-07 19:15:38] Ep. 2 : Up. 60000 : Sen. 378,321 : Cost 66.84718323 : Time 283.91s : 14209.50 words/s
[2019-08-07 19:15:38] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-07 19:15:47] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter60000.npz
[2019-08-07 19:15:54] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-07 19:16:03] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-07 19:16:29] [valid] Ep. 2 : Up. 60000 : cross-entropy : 69.6189 : new best
[2019-08-07 19:16:36] [valid] Ep. 2 : Up. 60000 : perplexity : 15.2712 : new best
[2019-08-07 19:17:35] [valid] Ep. 2 : Up. 60000 : translation : 13.54 : new best
[2019-08-07 19:22:21] Ep. 2 : Up. 62000 : Sen. 599,156 : Cost 66.44535065 : Time 403.59s : 9972.91 words/s
[2019-08-07 19:27:08] Ep. 2 : Up. 64000 : Sen. 819,963 : Cost 66.48124695 : Time 286.32s : 14081.52 words/s
[2019-08-07 19:31:52] Ep. 2 : Up. 66000 : Sen. 1,042,209 : Cost 65.93652344 : Time 284.21s : 14215.61 words/s
[2019-08-07 19:36:35] Ep. 2 : Up. 68000 : Sen. 1,264,067 : Cost 65.62164307 : Time 282.76s : 14273.09 words/s
[2019-08-07 19:41:17] Ep. 2 : Up. 70000 : Sen. 1,485,045 : Cost 65.70298767 : Time 282.40s : 14271.59 words/s
[2019-08-07 19:46:00] Ep. 2 : Up. 72000 : Sen. 1,706,482 : Cost 65.21172333 : Time 282.81s : 14235.05 words/s
[2019-08-07 19:50:44] Ep. 2 : Up. 74000 : Sen. 1,927,780 : Cost 65.48901367 : Time 284.29s : 14222.12 words/s
[2019-08-07 19:55:27] Ep. 2 : Up. 76000 : Sen. 2,149,211 : Cost 64.98441315 : Time 283.08s : 14268.35 words/s
[2019-08-07 20:00:10] Ep. 2 : Up. 78000 : Sen. 2,370,785 : Cost 64.75421143 : Time 282.96s : 14212.93 words/s
[2019-08-07 20:04:53] Ep. 2 : Up. 80000 : Sen. 2,592,000 : Cost 64.99758911 : Time 283.05s : 14258.67 words/s
[2019-08-07 20:04:53] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-07 20:05:07] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter80000.npz
[2019-08-07 20:05:18] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-07 20:05:27] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-07 20:05:52] [valid] Ep. 2 : Up. 80000 : cross-entropy : 64.7902 : new best
[2019-08-07 20:05:58] [valid] Ep. 2 : Up. 80000 : perplexity : 12.6403 : new best
[2019-08-07 20:06:54] [valid] Ep. 2 : Up. 80000 : translation : 16.37 : new best
[2019-08-07 20:11:39] Ep. 2 : Up. 82000 : Sen. 2,814,040 : Cost 64.36521912 : Time 405.94s : 9952.33 words/s
[2019-08-07 20:16:22] Ep. 2 : Up. 84000 : Sen. 3,035,222 : Cost 64.33122253 : Time 282.61s : 14249.13 words/s
[2019-08-07 20:21:09] Ep. 2 : Up. 86000 : Sen. 3,256,934 : Cost 64.17093658 : Time 286.76s : 14081.11 words/s
[2019-08-07 20:25:52] Ep. 2 : Up. 88000 : Sen. 3,478,425 : Cost 64.20980072 : Time 283.67s : 14198.56 words/s
[2019-08-07 20:30:36] Ep. 2 : Up. 90000 : Sen. 3,699,932 : Cost 63.82105637 : Time 283.85s : 14217.98 words/s
[2019-08-07 20:35:20] Ep. 2 : Up. 92000 : Sen. 3,921,442 : Cost 64.11183167 : Time 283.73s : 14268.19 words/s
[2019-08-07 20:40:03] Ep. 2 : Up. 94000 : Sen. 4,142,690 : Cost 63.85548401 : Time 282.91s : 14273.18 words/s
[2019-08-07 20:44:46] Ep. 2 : Up. 96000 : Sen. 4,364,316 : Cost 63.42830276 : Time 283.52s : 14227.32 words/s
[2019-08-07 20:49:29] Ep. 2 : Up. 98000 : Sen. 4,585,834 : Cost 63.41632843 : Time 282.77s : 14271.84 words/s
[2019-08-07 20:54:12] Ep. 2 : Up. 100000 : Sen. 4,807,035 : Cost 63.23426819 : Time 282.87s : 14241.78 words/s
[2019-08-07 20:54:12] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-07 20:54:21] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter100000.npz
[2019-08-07 20:54:27] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-07 20:54:37] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-07 20:55:03] [valid] Ep. 2 : Up. 100000 : cross-entropy : 61.5337 : new best
[2019-08-07 20:55:09] [valid] Ep. 2 : Up. 100000 : perplexity : 11.1271 : new best
[2019-08-07 20:56:05] [valid] Ep. 2 : Up. 100000 : translation : 17.12 : new best
[2019-08-07 21:00:49] Ep. 2 : Up. 102000 : Sen. 5,028,274 : Cost 63.17022324 : Time 396.79s : 10151.39 words/s
[2019-08-07 21:05:33] Ep. 2 : Up. 104000 : Sen. 5,250,107 : Cost 62.93604279 : Time 283.96s : 14230.91 words/s
[2019-08-07 21:10:16] Ep. 2 : Up. 106000 : Sen. 5,471,337 : Cost 63.04231262 : Time 283.61s : 14258.24 words/s
[2019-08-07 21:14:59] Ep. 2 : Up. 108000 : Sen. 5,692,529 : Cost 62.86268616 : Time 282.97s : 14257.39 words/s
[2019-08-07 21:19:43] Ep. 2 : Up. 110000 : Sen. 5,912,773 : Cost 62.81104279 : Time 283.96s : 14145.91 words/s
[2019-08-07 21:24:26] Ep. 2 : Up. 112000 : Sen. 6,134,375 : Cost 62.37635803 : Time 283.11s : 14243.68 words/s
[2019-08-07 21:27:06] Seen 6258441 samples
[2019-08-07 21:27:06] Starting epoch 3
[2019-08-07 21:27:06] [data] Shuffling data
[2019-08-07 21:27:09] [data] Done reading 6886952 sentences
[2019-08-07 21:27:33] [data] Done shuffling 6886952 sentences to temp files
[2019-08-07 21:29:45] Ep. 3 : Up. 114000 : Sen. 96,344 : Cost 61.96520233 : Time 318.11s : 12633.11 words/s
[2019-08-07 21:34:28] Ep. 3 : Up. 116000 : Sen. 317,388 : Cost 61.51545715 : Time 283.80s : 14246.83 words/s
[2019-08-07 21:39:14] Ep. 3 : Up. 118000 : Sen. 539,295 : Cost 60.82141113 : Time 285.28s : 14130.33 words/s
[2019-08-07 21:43:57] Ep. 3 : Up. 120000 : Sen. 760,133 : Cost 61.09396362 : Time 283.33s : 14195.02 words/s
[2019-08-07 21:43:57] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-07 21:44:06] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter120000.npz
[2019-08-07 21:44:13] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-07 21:44:22] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-07 21:44:47] [valid] Ep. 3 : Up. 120000 : cross-entropy : 59.1704 : new best
[2019-08-07 21:44:53] [valid] Ep. 3 : Up. 120000 : perplexity : 10.1437 : new best
[2019-08-07 21:45:48] [valid] Ep. 3 : Up. 120000 : translation : 17.88 : new best
[2019-08-07 21:50:32] Ep. 3 : Up. 122000 : Sen. 980,156 : Cost 61.08267593 : Time 395.32s : 10135.71 words/s
[2019-08-07 21:55:16] Ep. 3 : Up. 124000 : Sen. 1,201,799 : Cost 61.08967972 : Time 283.34s : 14247.72 words/s
[2019-08-07 21:59:58] Ep. 3 : Up. 126000 : Sen. 1,422,997 : Cost 60.87696075 : Time 282.86s : 14248.49 words/s
[2019-08-07 22:04:44] Ep. 3 : Up. 128000 : Sen. 1,646,097 : Cost 60.75671768 : Time 285.50s : 14197.76 words/s
[2019-08-07 22:09:28] Ep. 3 : Up. 130000 : Sen. 1,867,308 : Cost 61.10494232 : Time 283.90s : 14219.41 words/s
[2019-08-07 22:14:15] Ep. 3 : Up. 132000 : Sen. 2,089,304 : Cost 60.98525238 : Time 287.56s : 14078.97 words/s
[2019-08-07 22:18:58] Ep. 3 : Up. 134000 : Sen. 2,309,589 : Cost 60.74159241 : Time 282.18s : 14229.33 words/s
[2019-08-07 22:23:40] Ep. 3 : Up. 136000 : Sen. 2,531,044 : Cost 60.48804474 : Time 282.58s : 14258.14 words/s
[2019-08-07 22:28:23] Ep. 3 : Up. 138000 : Sen. 2,752,254 : Cost 60.59337997 : Time 282.64s : 14255.85 words/s
[2019-08-07 22:33:05] Ep. 3 : Up. 140000 : Sen. 2,972,342 : Cost 60.62214279 : Time 282.10s : 14226.12 words/s
[2019-08-07 22:33:05] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-07 22:33:14] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter140000.npz
[2019-08-07 22:33:21] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-07 22:33:30] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-07 22:33:55] [valid] Ep. 3 : Up. 140000 : cross-entropy : 57.5882 : new best
[2019-08-07 22:34:01] [valid] Ep. 3 : Up. 140000 : perplexity : 9.53429 : new best
[2019-08-07 22:34:55] [valid] Ep. 3 : Up. 140000 : translation : 18.73 : new best
[2019-08-07 22:39:43] Ep. 3 : Up. 142000 : Sen. 3,193,883 : Cost 60.56265259 : Time 398.19s : 10132.29 words/s
[2019-08-07 22:44:26] Ep. 3 : Up. 144000 : Sen. 3,414,905 : Cost 60.46425629 : Time 283.38s : 14210.96 words/s
[2019-08-07 22:49:12] Ep. 3 : Up. 146000 : Sen. 3,635,881 : Cost 60.39553452 : Time 285.12s : 14121.61 words/s
[2019-08-07 22:53:55] Ep. 3 : Up. 148000 : Sen. 3,857,261 : Cost 60.57086945 : Time 283.65s : 14263.96 words/s
[2019-08-07 22:58:37] Ep. 3 : Up. 150000 : Sen. 4,077,590 : Cost 60.31303787 : Time 282.06s : 14219.83 words/s
[2019-08-07 23:03:20] Ep. 3 : Up. 152000 : Sen. 4,298,941 : Cost 60.14297485 : Time 283.12s : 14231.97 words/s
[2019-08-07 23:08:03] Ep. 3 : Up. 154000 : Sen. 4,519,995 : Cost 60.18635559 : Time 283.01s : 14243.99 words/s
[2019-08-07 23:12:47] Ep. 3 : Up. 156000 : Sen. 4,741,820 : Cost 60.00218582 : Time 283.46s : 14251.93 words/s
[2019-08-07 23:17:32] Ep. 3 : Up. 158000 : Sen. 4,963,033 : Cost 60.11133575 : Time 284.61s : 14164.36 words/s
[2019-08-07 23:22:14] Ep. 3 : Up. 160000 : Sen. 5,184,000 : Cost 60.05337906 : Time 282.95s : 14232.29 words/s
[2019-08-07 23:22:14] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-07 23:22:23] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter160000.npz
[2019-08-07 23:22:30] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-07 23:22:40] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-07 23:23:04] [valid] Ep. 3 : Up. 160000 : cross-entropy : 56.2996 : new best
[2019-08-07 23:23:10] [valid] Ep. 3 : Up. 160000 : perplexity : 9.06519 : new best
[2019-08-07 23:24:05] [valid] Ep. 3 : Up. 160000 : translation : 19.07 : new best
[2019-08-07 23:28:50] Ep. 3 : Up. 162000 : Sen. 5,405,671 : Cost 59.97654343 : Time 396.02s : 10205.02 words/s
[2019-08-07 23:33:34] Ep. 3 : Up. 164000 : Sen. 5,626,604 : Cost 60.16831970 : Time 283.18s : 14243.57 words/s
[2019-08-07 23:38:16] Ep. 3 : Up. 166000 : Sen. 5,846,974 : Cost 60.01813126 : Time 282.77s : 14225.14 words/s
[2019-08-07 23:42:59] Ep. 3 : Up. 168000 : Sen. 6,069,145 : Cost 59.50605774 : Time 282.54s : 14303.17 words/s
[2019-08-07 23:47:00] Seen 6258441 samples
[2019-08-07 23:47:00] Starting epoch 4
[2019-08-07 23:47:00] [data] Shuffling data
[2019-08-07 23:47:03] [data] Done reading 6886952 sentences
[2019-08-07 23:47:28] [data] Done shuffling 6886952 sentences to temp files
[2019-08-07 23:48:18] Ep. 4 : Up. 170000 : Sen. 32,361 : Cost 59.45714951 : Time 318.75s : 12667.47 words/s
[2019-08-07 23:53:00] Ep. 4 : Up. 172000 : Sen. 253,500 : Cost 58.49232483 : Time 281.96s : 14289.37 words/s
[2019-08-07 23:57:42] Ep. 4 : Up. 174000 : Sen. 474,605 : Cost 58.57787323 : Time 282.39s : 14264.02 words/s
[2019-08-08 00:02:26] Ep. 4 : Up. 176000 : Sen. 696,915 : Cost 58.44979477 : Time 283.64s : 14257.70 words/s
[2019-08-08 00:07:11] Ep. 4 : Up. 178000 : Sen. 917,310 : Cost 59.02803040 : Time 285.47s : 14128.45 words/s
[2019-08-08 00:11:53] Ep. 4 : Up. 180000 : Sen. 1,137,567 : Cost 58.35492325 : Time 281.55s : 14241.02 words/s
[2019-08-08 00:11:53] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-08 00:12:02] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter180000.npz
[2019-08-08 00:12:08] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-08 00:12:18] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-08 00:12:42] [valid] Ep. 4 : Up. 180000 : cross-entropy : 55.2885 : new best
[2019-08-08 00:12:49] [valid] Ep. 4 : Up. 180000 : perplexity : 8.71329 : new best
[2019-08-08 00:13:42] [valid] Ep. 4 : Up. 180000 : translation : 19.44 : new best
[2019-08-08 00:18:27] Ep. 4 : Up. 182000 : Sen. 1,360,246 : Cost 58.42226791 : Time 394.32s : 10279.75 words/s
[2019-08-08 00:23:11] Ep. 4 : Up. 184000 : Sen. 1,581,003 : Cost 58.83287048 : Time 283.56s : 14234.94 words/s
[2019-08-08 00:27:54] Ep. 4 : Up. 186000 : Sen. 1,802,030 : Cost 58.38015366 : Time 283.59s : 14207.58 words/s
[2019-08-08 00:32:36] Ep. 4 : Up. 188000 : Sen. 2,023,234 : Cost 58.66478729 : Time 281.92s : 14296.75 words/s
[2019-08-08 00:37:18] Ep. 4 : Up. 190000 : Sen. 2,244,094 : Cost 58.44768906 : Time 281.89s : 14288.19 words/s
[2019-08-08 00:42:01] Ep. 4 : Up. 192000 : Sen. 2,465,709 : Cost 58.68101120 : Time 282.52s : 14304.58 words/s
[2019-08-08 00:46:42] Ep. 4 : Up. 194000 : Sen. 2,686,855 : Cost 58.53224945 : Time 281.63s : 14289.72 words/s
[2019-08-08 00:51:25] Ep. 4 : Up. 196000 : Sen. 2,908,858 : Cost 58.39778900 : Time 282.30s : 14309.55 words/s
[2019-08-08 00:56:06] Ep. 4 : Up. 198000 : Sen. 3,128,937 : Cost 58.43335724 : Time 281.70s : 14249.93 words/s
[2019-08-08 01:00:52] Ep. 4 : Up. 200000 : Sen. 3,349,448 : Cost 58.56295013 : Time 285.61s : 14091.23 words/s
[2019-08-08 01:00:52] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-08 01:01:00] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter200000.npz
[2019-08-08 01:01:07] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-08 01:01:17] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-08 01:01:42] [valid] Ep. 4 : Up. 200000 : cross-entropy : 54.5676 : new best
[2019-08-08 01:01:48] [valid] Ep. 4 : Up. 200000 : perplexity : 8.47079 : new best
[2019-08-08 01:02:41] [valid] Ep. 4 : Up. 200000 : translation : 19.6 : new best
[2019-08-08 01:07:26] Ep. 4 : Up. 202000 : Sen. 3,571,200 : Cost 58.02200699 : Time 394.16s : 10213.12 words/s
[2019-08-08 01:12:12] Ep. 4 : Up. 204000 : Sen. 3,792,853 : Cost 58.43659210 : Time 285.75s : 14136.52 words/s
[2019-08-08 01:16:56] Ep. 4 : Up. 206000 : Sen. 4,016,058 : Cost 58.09214783 : Time 283.99s : 14283.07 words/s
[2019-08-08 01:21:38] Ep. 4 : Up. 208000 : Sen. 4,236,902 : Cost 58.50167084 : Time 282.59s : 14257.01 words/s
[2019-08-08 01:26:21] Ep. 4 : Up. 210000 : Sen. 4,457,903 : Cost 58.29980850 : Time 282.28s : 14261.90 words/s
[2019-08-08 01:31:03] Ep. 4 : Up. 212000 : Sen. 4,678,109 : Cost 58.20812225 : Time 282.48s : 14183.47 words/s
[2019-08-08 01:35:47] Ep. 4 : Up. 214000 : Sen. 4,899,174 : Cost 58.33111954 : Time 283.56s : 14221.58 words/s
[2019-08-08 01:40:30] Ep. 4 : Up. 216000 : Sen. 5,120,442 : Cost 58.00792694 : Time 283.36s : 14239.02 words/s
[2019-08-08 01:45:12] Ep. 4 : Up. 218000 : Sen. 5,340,882 : Cost 58.01078033 : Time 282.39s : 14202.21 words/s
[2019-08-08 01:49:57] Ep. 4 : Up. 220000 : Sen. 5,561,678 : Cost 58.24434280 : Time 284.71s : 14142.57 words/s
[2019-08-08 01:49:57] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-08 01:50:06] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter220000.npz
[2019-08-08 01:50:13] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-08 01:50:22] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-08 01:50:47] [valid] Ep. 4 : Up. 220000 : cross-entropy : 53.8631 : new best
[2019-08-08 01:50:53] [valid] Ep. 4 : Up. 220000 : perplexity : 8.24032 : new best
[2019-08-08 01:51:47] [valid] Ep. 4 : Up. 220000 : translation : 19.83 : new best
[2019-08-08 01:56:35] Ep. 4 : Up. 222000 : Sen. 5,783,335 : Cost 58.18494797 : Time 397.35s : 10161.94 words/s
[2019-08-08 02:01:18] Ep. 4 : Up. 224000 : Sen. 6,005,076 : Cost 57.85055542 : Time 283.85s : 14230.15 words/s
[2019-08-08 02:06:01] Ep. 4 : Up. 226000 : Sen. 6,226,143 : Cost 57.88969803 : Time 282.52s : 14238.96 words/s
[2019-08-08 02:06:43] Seen 6258441 samples
[2019-08-08 02:06:43] Starting epoch 5
[2019-08-08 02:06:43] [data] Shuffling data
[2019-08-08 02:06:46] [data] Done reading 6886952 sentences
[2019-08-08 02:07:07] [data] Done shuffling 6886952 sentences to temp files
[2019-08-08 02:11:26] Ep. 5 : Up. 228000 : Sen. 188,351 : Cost 57.27557373 : Time 324.82s : 12424.42 words/s
[2019-08-08 02:16:11] Ep. 5 : Up. 230000 : Sen. 410,689 : Cost 56.44285202 : Time 285.78s : 14160.79 words/s
[2019-08-08 02:20:55] Ep. 5 : Up. 232000 : Sen. 631,943 : Cost 57.02958679 : Time 283.22s : 14240.07 words/s
[2019-08-08 02:25:40] Ep. 5 : Up. 234000 : Sen. 853,831 : Cost 56.73549271 : Time 284.97s : 14181.83 words/s
[2019-08-08 02:30:23] Ep. 5 : Up. 236000 : Sen. 1,075,507 : Cost 56.99562836 : Time 282.98s : 14262.08 words/s
[2019-08-08 02:35:06] Ep. 5 : Up. 238000 : Sen. 1,296,697 : Cost 57.15905380 : Time 283.66s : 14218.69 words/s
[2019-08-08 02:39:52] Ep. 5 : Up. 240000 : Sen. 1,518,624 : Cost 56.85684586 : Time 285.68s : 14158.38 words/s
[2019-08-08 02:39:52] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-08 02:40:01] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter240000.npz
[2019-08-08 02:40:08] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-08 02:40:17] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-08 02:40:42] [valid] Ep. 5 : Up. 240000 : cross-entropy : 53.3975 : new best
[2019-08-08 02:40:48] [valid] Ep. 5 : Up. 240000 : perplexity : 8.09144 : new best
[2019-08-08 02:41:42] [valid] Ep. 5 : Up. 240000 : translation : 19.51 : stalled 1 times (last best: 19.83)
[2019-08-08 02:46:26] Ep. 5 : Up. 242000 : Sen. 1,739,789 : Cost 56.89438248 : Time 394.17s : 10218.58 words/s
[2019-08-08 02:51:12] Ep. 5 : Up. 244000 : Sen. 1,960,798 : Cost 57.02412033 : Time 285.48s : 14092.85 words/s
[2019-08-08 02:55:55] Ep. 5 : Up. 246000 : Sen. 2,181,859 : Cost 57.10859299 : Time 283.29s : 14242.85 words/s
[2019-08-08 03:00:37] Ep. 5 : Up. 248000 : Sen. 2,402,760 : Cost 57.07427597 : Time 281.99s : 14261.71 words/s
[2019-08-08 03:05:20] Ep. 5 : Up. 250000 : Sen. 2,623,509 : Cost 57.34843826 : Time 283.37s : 14215.68 words/s
[2019-08-08 03:10:05] Ep. 5 : Up. 252000 : Sen. 2,845,158 : Cost 56.86726379 : Time 285.04s : 14155.22 words/s
[2019-08-08 03:14:50] Ep. 5 : Up. 254000 : Sen. 3,066,096 : Cost 57.21022797 : Time 284.58s : 14180.39 words/s
[2019-08-08 03:19:33] Ep. 5 : Up. 256000 : Sen. 3,288,927 : Cost 56.59918213 : Time 283.26s : 14277.80 words/s
[2019-08-08 03:24:16] Ep. 5 : Up. 258000 : Sen. 3,509,985 : Cost 57.22573853 : Time 283.03s : 14257.74 words/s
[2019-08-08 03:28:58] Ep. 5 : Up. 260000 : Sen. 3,730,782 : Cost 57.17972183 : Time 281.70s : 14287.55 words/s
[2019-08-08 03:28:58] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-08 03:29:07] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter260000.npz
[2019-08-08 03:29:15] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-08 03:29:24] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-08 03:29:50] [valid] Ep. 5 : Up. 260000 : cross-entropy : 52.9325 : new best
[2019-08-08 03:29:56] [valid] Ep. 5 : Up. 260000 : perplexity : 7.94544 : new best
[2019-08-08 03:30:50] [valid] Ep. 5 : Up. 260000 : translation : 19.98 : new best
[2019-08-08 03:35:34] Ep. 5 : Up. 262000 : Sen. 3,952,084 : Cost 56.90668106 : Time 395.84s : 10166.49 words/s
[2019-08-08 03:40:17] Ep. 5 : Up. 264000 : Sen. 4,172,361 : Cost 57.14134979 : Time 282.94s : 14231.39 words/s
[2019-08-08 03:45:00] Ep. 5 : Up. 266000 : Sen. 4,392,845 : Cost 57.00657654 : Time 283.62s : 14166.81 words/s
[2019-08-08 03:49:43] Ep. 5 : Up. 268000 : Sen. 4,614,298 : Cost 56.91275406 : Time 282.21s : 14275.80 words/s
[2019-08-08 03:54:26] Ep. 5 : Up. 270000 : Sen. 4,835,588 : Cost 57.02212143 : Time 283.07s : 14239.65 words/s
[2019-08-08 03:59:09] Ep. 5 : Up. 272000 : Sen. 5,057,345 : Cost 56.99883652 : Time 283.17s : 14275.20 words/s
[2019-08-08 04:03:53] Ep. 5 : Up. 274000 : Sen. 5,278,280 : Cost 56.72239304 : Time 284.63s : 14142.96 words/s
[2019-08-08 04:08:36] Ep. 5 : Up. 276000 : Sen. 5,499,256 : Cost 57.02091980 : Time 282.24s : 14270.28 words/s
[2019-08-08 04:13:19] Ep. 5 : Up. 278000 : Sen. 5,720,416 : Cost 56.88688660 : Time 282.87s : 14258.82 words/s
[2019-08-08 04:18:02] Ep. 5 : Up. 280000 : Sen. 5,942,456 : Cost 56.65452194 : Time 283.69s : 14228.77 words/s
[2019-08-08 04:18:02] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-08 04:18:11] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter280000.npz
[2019-08-08 04:18:18] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-08 04:18:27] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-08 04:18:53] [valid] Ep. 5 : Up. 280000 : cross-entropy : 52.4645 : new best
[2019-08-08 04:18:59] [valid] Ep. 5 : Up. 280000 : perplexity : 7.80117 : new best
[2019-08-08 04:19:52] [valid] Ep. 5 : Up. 280000 : translation : 20.45 : new best
[2019-08-08 04:24:37] Ep. 5 : Up. 282000 : Sen. 6,163,381 : Cost 56.98878860 : Time 395.11s : 10196.24 words/s
[2019-08-08 04:26:39] Seen 6258441 samples
[2019-08-08 04:26:39] Starting epoch 6
[2019-08-08 04:26:39] [data] Shuffling data
[2019-08-08 04:26:42] [data] Done reading 6886952 sentences
[2019-08-08 04:27:02] [data] Done shuffling 6886952 sentences to temp files
[2019-08-08 04:29:56] Ep. 6 : Up. 284000 : Sen. 125,991 : Cost 56.03355408 : Time 318.80s : 12631.42 words/s
[2019-08-08 04:34:38] Ep. 6 : Up. 286000 : Sen. 346,836 : Cost 55.62720108 : Time 282.09s : 14263.28 words/s
[2019-08-08 04:39:21] Ep. 6 : Up. 288000 : Sen. 567,933 : Cost 56.01619339 : Time 282.49s : 14292.16 words/s
[2019-08-08 04:44:03] Ep. 6 : Up. 290000 : Sen. 789,926 : Cost 55.62872696 : Time 282.69s : 14298.69 words/s
[2019-08-08 04:48:46] Ep. 6 : Up. 292000 : Sen. 1,011,671 : Cost 55.77584457 : Time 282.66s : 14294.72 words/s
[2019-08-08 04:53:29] Ep. 6 : Up. 294000 : Sen. 1,232,975 : Cost 55.93238449 : Time 282.75s : 14266.02 words/s
[2019-08-08 04:58:11] Ep. 6 : Up. 296000 : Sen. 1,454,329 : Cost 55.77454758 : Time 282.56s : 14273.15 words/s
[2019-08-08 05:02:54] Ep. 6 : Up. 298000 : Sen. 1,675,671 : Cost 55.98638916 : Time 282.64s : 14267.28 words/s
[2019-08-08 05:07:38] Ep. 6 : Up. 300000 : Sen. 1,897,496 : Cost 56.05497742 : Time 284.34s : 14216.52 words/s
[2019-08-08 05:07:38] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-08 05:07:47] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter300000.npz
[2019-08-08 05:07:54] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-08 05:08:04] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-08 05:08:29] [valid] Ep. 6 : Up. 300000 : cross-entropy : 52.2291 : new best
[2019-08-08 05:08:35] [valid] Ep. 6 : Up. 300000 : perplexity : 7.7296 : new best
[2019-08-08 05:09:29] [valid] Ep. 6 : Up. 300000 : translation : 20.05 : stalled 1 times (last best: 20.45)
[2019-08-08 05:14:16] Ep. 6 : Up. 302000 : Sen. 2,118,309 : Cost 56.03960037 : Time 397.23s : 10140.72 words/s
[2019-08-08 05:18:59] Ep. 6 : Up. 304000 : Sen. 2,339,598 : Cost 56.04010010 : Time 283.41s : 14250.46 words/s
[2019-08-08 05:23:41] Ep. 6 : Up. 306000 : Sen. 2,560,641 : Cost 55.85087585 : Time 281.76s : 14274.32 words/s
[2019-08-08 05:28:24] Ep. 6 : Up. 308000 : Sen. 2,781,298 : Cost 56.15182114 : Time 283.61s : 14204.17 words/s
[2019-08-08 05:33:08] Ep. 6 : Up. 310000 : Sen. 3,003,735 : Cost 55.77373886 : Time 283.38s : 14263.34 words/s
[2019-08-08 05:37:52] Ep. 6 : Up. 312000 : Sen. 3,225,275 : Cost 56.17678833 : Time 284.43s : 14231.80 words/s
[2019-08-08 05:42:36] Ep. 6 : Up. 314000 : Sen. 3,446,246 : Cost 55.80740738 : Time 283.33s : 14190.57 words/s
[2019-08-08 05:47:20] Ep. 6 : Up. 316000 : Sen. 3,668,357 : Cost 55.75243378 : Time 284.25s : 14233.44 words/s
[2019-08-08 05:52:04] Ep. 6 : Up. 318000 : Sen. 3,890,747 : Cost 55.99705505 : Time 283.82s : 14250.37 words/s
[2019-08-08 05:56:47] Ep. 6 : Up. 320000 : Sen. 4,112,632 : Cost 55.90780640 : Time 283.29s : 14243.25 words/s
[2019-08-08 05:56:47] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-08 05:56:56] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter320000.npz
[2019-08-08 05:57:03] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-08 05:57:13] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-08 05:57:38] [valid] Ep. 6 : Up. 320000 : cross-entropy : 51.9364 : new best
[2019-08-08 05:57:44] [valid] Ep. 6 : Up. 320000 : perplexity : 7.64153 : new best
[2019-08-08 05:58:37] [valid] Ep. 6 : Up. 320000 : translation : 20.38 : stalled 2 times (last best: 20.45)
[2019-08-08 06:03:22] Ep. 6 : Up. 322000 : Sen. 4,333,951 : Cost 56.02269745 : Time 395.09s : 10216.19 words/s
[2019-08-08 06:08:05] Ep. 6 : Up. 324000 : Sen. 4,554,905 : Cost 55.78031921 : Time 282.97s : 14213.12 words/s
[2019-08-08 06:12:48] Ep. 6 : Up. 326000 : Sen. 4,774,730 : Cost 56.08343506 : Time 283.30s : 14170.70 words/s
[2019-08-08 06:17:32] Ep. 6 : Up. 328000 : Sen. 4,995,135 : Cost 56.00461960 : Time 283.78s : 14140.39 words/s
[2019-08-08 06:22:17] Ep. 6 : Up. 330000 : Sen. 5,216,614 : Cost 56.03864288 : Time 285.42s : 14129.70 words/s
[2019-08-08 06:27:03] Ep. 6 : Up. 332000 : Sen. 5,438,567 : Cost 55.96230698 : Time 285.13s : 14187.17 words/s
[2019-08-08 06:31:47] Ep. 6 : Up. 334000 : Sen. 5,659,088 : Cost 56.13138580 : Time 283.89s : 14160.52 words/s
[2019-08-08 06:36:30] Ep. 6 : Up. 336000 : Sen. 5,879,213 : Cost 56.00338364 : Time 283.94s : 14150.00 words/s
[2019-08-08 06:41:14] Ep. 6 : Up. 338000 : Sen. 6,100,213 : Cost 55.96672440 : Time 283.90s : 14167.22 words/s
[2019-08-08 06:44:38] Seen 6258441 samples
[2019-08-08 06:44:38] Starting epoch 7
[2019-08-08 06:44:38] [data] Shuffling data
[2019-08-08 06:44:41] [data] Done reading 6886952 sentences
[2019-08-08 06:45:06] [data] Done shuffling 6886952 sentences to temp files
[2019-08-08 06:46:36] Ep. 7 : Up. 340000 : Sen. 62,300 : Cost 55.81752396 : Time 321.39s : 12521.77 words/s
[2019-08-08 06:46:36] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-08 06:46:45] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter340000.npz
[2019-08-08 06:46:52] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-08 06:47:02] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-08 06:47:26] [valid] Ep. 7 : Up. 340000 : cross-entropy : 51.5941 : new best
[2019-08-08 06:47:33] [valid] Ep. 7 : Up. 340000 : perplexity : 7.53979 : new best
[2019-08-08 06:48:26] [valid] Ep. 7 : Up. 340000 : translation : 20.4 : stalled 3 times (last best: 20.45)
[2019-08-08 06:53:11] Ep. 7 : Up. 342000 : Sen. 284,056 : Cost 54.42944336 : Time 395.73s : 10167.79 words/s
[2019-08-08 06:57:56] Ep. 7 : Up. 344000 : Sen. 504,842 : Cost 54.80945969 : Time 284.31s : 14146.61 words/s
[2019-08-08 07:02:40] Ep. 7 : Up. 346000 : Sen. 726,342 : Cost 55.09209442 : Time 284.51s : 14218.40 words/s
[2019-08-08 07:07:23] Ep. 7 : Up. 348000 : Sen. 947,714 : Cost 54.91648865 : Time 282.95s : 14209.05 words/s
[2019-08-08 07:12:07] Ep. 7 : Up. 350000 : Sen. 1,168,491 : Cost 55.14954376 : Time 284.00s : 14191.32 words/s
[2019-08-08 07:16:51] Ep. 7 : Up. 352000 : Sen. 1,389,760 : Cost 54.80376816 : Time 283.56s : 14211.60 words/s
[2019-08-08 07:21:34] Ep. 7 : Up. 354000 : Sen. 1,609,924 : Cost 55.10698700 : Time 283.64s : 14150.44 words/s
[2019-08-08 07:26:19] Ep. 7 : Up. 356000 : Sen. 1,832,430 : Cost 54.89446259 : Time 284.52s : 14216.82 words/s
[2019-08-08 07:31:03] Ep. 7 : Up. 358000 : Sen. 2,053,619 : Cost 55.24613953 : Time 284.41s : 14188.90 words/s
[2019-08-08 07:35:48] Ep. 7 : Up. 360000 : Sen. 2,275,041 : Cost 55.17575455 : Time 284.33s : 14195.17 words/s
[2019-08-08 07:35:48] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-08 07:36:00] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter360000.npz
[2019-08-08 07:36:13] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-08 07:36:23] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-08 07:36:48] [valid] Ep. 7 : Up. 360000 : cross-entropy : 51.46 : new best
[2019-08-08 07:36:54] [valid] Ep. 7 : Up. 360000 : perplexity : 7.5003 : new best
[2019-08-08 07:37:48] [valid] Ep. 7 : Up. 360000 : translation : 20.24 : stalled 4 times (last best: 20.45)
[2019-08-08 07:42:34] Ep. 7 : Up. 362000 : Sen. 2,496,399 : Cost 55.16177368 : Time 406.23s : 9930.26 words/s
[2019-08-08 07:47:18] Ep. 7 : Up. 364000 : Sen. 2,717,964 : Cost 55.07081985 : Time 283.92s : 14200.75 words/s
[2019-08-08 07:52:02] Ep. 7 : Up. 366000 : Sen. 2,938,871 : Cost 55.52978134 : Time 283.83s : 14215.95 words/s
[2019-08-08 07:56:46] Ep. 7 : Up. 368000 : Sen. 3,160,681 : Cost 55.19401550 : Time 284.72s : 14218.18 words/s
[2019-08-08 08:01:29] Ep. 7 : Up. 370000 : Sen. 3,381,991 : Cost 55.15585327 : Time 283.04s : 14258.53 words/s
[2019-08-08 08:06:13] Ep. 7 : Up. 372000 : Sen. 3,602,224 : Cost 55.12368393 : Time 283.63s : 14155.71 words/s
[2019-08-08 08:10:57] Ep. 7 : Up. 374000 : Sen. 3,823,327 : Cost 55.19019318 : Time 284.31s : 14162.66 words/s
[2019-08-08 08:15:42] Ep. 7 : Up. 376000 : Sen. 4,044,255 : Cost 55.33752441 : Time 284.32s : 14177.47 words/s
[2019-08-08 08:20:26] Ep. 7 : Up. 378000 : Sen. 4,265,110 : Cost 55.41213989 : Time 283.99s : 14188.16 words/s
[2019-08-08 08:25:09] Ep. 7 : Up. 380000 : Sen. 4,485,937 : Cost 55.20949554 : Time 283.11s : 14186.68 words/s
[2019-08-08 08:25:09] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-08 08:25:18] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter380000.npz
[2019-08-08 08:25:24] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-08 08:25:34] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-08 08:25:59] [valid] Ep. 7 : Up. 380000 : cross-entropy : 51.2525 : new best
[2019-08-08 08:26:05] [valid] Ep. 7 : Up. 380000 : perplexity : 7.43961 : new best
[2019-08-08 08:26:59] [valid] Ep. 7 : Up. 380000 : translation : 20.47 : new best
[2019-08-08 08:31:47] Ep. 7 : Up. 382000 : Sen. 4,707,072 : Cost 55.46477509 : Time 398.17s : 10137.14 words/s
[2019-08-08 08:36:32] Ep. 7 : Up. 384000 : Sen. 4,927,426 : Cost 55.18122482 : Time 285.33s : 14061.44 words/s
[2019-08-08 08:41:18] Ep. 7 : Up. 386000 : Sen. 5,148,915 : Cost 55.12296295 : Time 285.96s : 14077.32 words/s
[2019-08-08 08:46:05] Ep. 7 : Up. 388000 : Sen. 5,370,379 : Cost 55.07276535 : Time 286.55s : 14097.08 words/s
[2019-08-08 08:50:50] Ep. 7 : Up. 390000 : Sen. 5,591,205 : Cost 55.22060013 : Time 285.34s : 14082.39 words/s
[2019-08-08 08:55:36] Ep. 7 : Up. 392000 : Sen. 5,811,976 : Cost 55.35685730 : Time 286.08s : 14073.18 words/s
[2019-08-08 09:00:23] Ep. 7 : Up. 394000 : Sen. 6,032,998 : Cost 55.30538177 : Time 286.51s : 14069.50 words/s
[2019-08-08 09:05:10] Ep. 7 : Up. 396000 : Sen. 6,254,239 : Cost 55.13995743 : Time 286.99s : 14016.89 words/s
[2019-08-08 09:05:15] Seen 6258441 samples
[2019-08-08 09:05:15] Starting epoch 8
[2019-08-08 09:05:15] [data] Shuffling data
[2019-08-08 09:05:19] [data] Done reading 6886952 sentences
[2019-08-08 09:05:51] [data] Done shuffling 6886952 sentences to temp files
[2019-08-08 09:10:40] Ep. 8 : Up. 398000 : Sen. 216,617 : Cost 54.19668198 : Time 330.12s : 12188.44 words/s
[2019-08-08 09:15:27] Ep. 8 : Up. 400000 : Sen. 437,844 : Cost 54.21002960 : Time 287.51s : 14063.59 words/s
[2019-08-08 09:15:27] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-08 09:15:40] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter400000.npz
[2019-08-08 09:15:48] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-08 09:15:59] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-08 09:16:28] [valid] Ep. 8 : Up. 400000 : cross-entropy : 50.9931 : new best
[2019-08-08 09:16:35] [valid] Ep. 8 : Up. 400000 : perplexity : 7.36444 : new best
[2019-08-08 09:17:39] [valid] Ep. 8 : Up. 400000 : translation : 20.07 : stalled 1 times (last best: 20.47)
[2019-08-08 09:22:28] Ep. 8 : Up. 402000 : Sen. 659,982 : Cost 54.01483154 : Time 420.19s : 9596.65 words/s
[2019-08-08 09:27:13] Ep. 8 : Up. 404000 : Sen. 880,619 : Cost 54.28931808 : Time 285.45s : 14114.25 words/s
[2019-08-08 09:32:00] Ep. 8 : Up. 406000 : Sen. 1,102,271 : Cost 54.23282623 : Time 286.53s : 14077.84 words/s
[2019-08-08 09:36:46] Ep. 8 : Up. 408000 : Sen. 1,323,074 : Cost 54.40988541 : Time 285.87s : 14072.18 words/s
[2019-08-08 09:41:33] Ep. 8 : Up. 410000 : Sen. 1,543,829 : Cost 54.24370193 : Time 286.96s : 13997.46 words/s
[2019-08-08 09:46:19] Ep. 8 : Up. 412000 : Sen. 1,764,948 : Cost 54.47770309 : Time 286.79s : 14058.92 words/s
[2019-08-08 09:51:05] Ep. 8 : Up. 414000 : Sen. 1,986,245 : Cost 54.45805740 : Time 286.13s : 14081.92 words/s
[2019-08-08 09:55:52] Ep. 8 : Up. 416000 : Sen. 2,206,844 : Cost 54.66330719 : Time 286.75s : 14051.73 words/s
[2019-08-08 10:00:38] Ep. 8 : Up. 418000 : Sen. 2,428,115 : Cost 54.23837280 : Time 285.86s : 14101.89 words/s
[2019-08-08 10:05:24] Ep. 8 : Up. 420000 : Sen. 2,648,981 : Cost 54.59323120 : Time 285.94s : 14066.15 words/s
[2019-08-08 10:05:24] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-08 10:05:36] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter420000.npz
[2019-08-08 10:05:44] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-08 10:05:56] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-08 10:06:27] [valid] Ep. 8 : Up. 420000 : cross-entropy : 50.9586 : new best
[2019-08-08 10:06:34] [valid] Ep. 8 : Up. 420000 : perplexity : 7.35448 : new best
[2019-08-08 10:07:32] [valid] Ep. 8 : Up. 420000 : translation : 20.15 : stalled 2 times (last best: 20.47)
[2019-08-08 10:12:21] Ep. 8 : Up. 422000 : Sen. 2,869,181 : Cost 54.59052277 : Time 416.99s : 9636.59 words/s
[2019-08-08 10:17:07] Ep. 8 : Up. 424000 : Sen. 3,091,200 : Cost 54.29552460 : Time 286.23s : 14099.48 words/s
[2019-08-08 10:21:53] Ep. 8 : Up. 426000 : Sen. 3,313,091 : Cost 54.50065231 : Time 286.16s : 14108.38 words/s
[2019-08-08 10:26:39] Ep. 8 : Up. 428000 : Sen. 3,534,464 : Cost 54.44819260 : Time 285.73s : 14085.28 words/s
[2019-08-08 10:31:27] Ep. 8 : Up. 430000 : Sen. 3,755,745 : Cost 54.94364548 : Time 287.39s : 14068.59 words/s
[2019-08-08 10:36:12] Ep. 8 : Up. 432000 : Sen. 3,976,459 : Cost 54.52211761 : Time 285.21s : 14095.69 words/s
[2019-08-08 10:40:58] Ep. 8 : Up. 434000 : Sen. 4,197,757 : Cost 54.55946350 : Time 286.00s : 14077.49 words/s
[2019-08-08 10:45:44] Ep. 8 : Up. 436000 : Sen. 4,418,680 : Cost 54.90395355 : Time 286.63s : 14083.03 words/s
[2019-08-08 10:50:34] Ep. 8 : Up. 438000 : Sen. 4,639,922 : Cost 54.50559235 : Time 289.34s : 13926.50 words/s
[2019-08-08 10:55:24] Ep. 8 : Up. 440000 : Sen. 4,862,093 : Cost 54.57228470 : Time 289.92s : 13939.06 words/s
[2019-08-08 10:55:24] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-08 10:55:35] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter440000.npz
[2019-08-08 10:55:44] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-08 10:55:54] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-08 10:56:23] [valid] Ep. 8 : Up. 440000 : cross-entropy : 50.7613 : new best
[2019-08-08 10:56:30] [valid] Ep. 8 : Up. 440000 : perplexity : 7.2979 : new best
[2019-08-08 10:57:31] [valid] Ep. 8 : Up. 440000 : translation : 20.29 : stalled 3 times (last best: 20.47)
[2019-08-08 11:02:21] Ep. 8 : Up. 442000 : Sen. 5,083,083 : Cost 54.80391312 : Time 417.24s : 9665.15 words/s
[2019-08-08 11:07:08] Ep. 8 : Up. 444000 : Sen. 5,303,472 : Cost 54.83960724 : Time 286.97s : 14038.17 words/s
[2019-08-08 11:11:57] Ep. 8 : Up. 446000 : Sen. 5,525,111 : Cost 54.40264893 : Time 288.92s : 13964.31 words/s
[2019-08-08 11:16:47] Ep. 8 : Up. 448000 : Sen. 5,746,777 : Cost 54.70757675 : Time 289.88s : 13909.86 words/s
[2019-08-08 11:21:36] Ep. 8 : Up. 450000 : Sen. 5,967,282 : Cost 54.73988342 : Time 288.79s : 13928.35 words/s
[2019-08-08 11:26:24] Ep. 8 : Up. 452000 : Sen. 6,188,351 : Cost 54.68647385 : Time 288.00s : 14003.31 words/s
[2019-08-08 11:27:55] Seen 6258441 samples
[2019-08-08 11:27:55] Starting epoch 9
[2019-08-08 11:27:55] [data] Shuffling data
[2019-08-08 11:28:18] [data] Done reading 6886952 sentences
[2019-08-08 11:29:02] [data] Done shuffling 6886952 sentences to temp files
[2019-08-08 11:32:22] Ep. 9 : Up. 454000 : Sen. 150,736 : Cost 53.86640930 : Time 357.88s : 11241.76 words/s
[2019-08-08 11:37:10] Ep. 9 : Up. 456000 : Sen. 373,146 : Cost 53.28353882 : Time 288.40s : 13992.39 words/s
[2019-08-08 11:41:57] Ep. 9 : Up. 458000 : Sen. 593,544 : Cost 53.64945984 : Time 287.36s : 13983.19 words/s
[2019-08-08 11:46:47] Ep. 9 : Up. 460000 : Sen. 815,477 : Cost 53.77918625 : Time 290.01s : 13960.55 words/s
[2019-08-08 11:46:47] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-08 11:46:59] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter460000.npz
[2019-08-08 11:47:07] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-08 11:47:18] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-08 11:47:47] [valid] Ep. 9 : Up. 460000 : cross-entropy : 50.5835 : new best
[2019-08-08 11:47:53] [valid] Ep. 9 : Up. 460000 : perplexity : 7.24726 : new best
[2019-08-08 11:48:51] [valid] Ep. 9 : Up. 460000 : translation : 20.66 : new best
[2019-08-08 11:53:39] Ep. 9 : Up. 462000 : Sen. 1,036,140 : Cost 53.86093903 : Time 411.85s : 9776.52 words/s
[2019-08-08 11:58:26] Ep. 9 : Up. 464000 : Sen. 1,256,969 : Cost 53.70107651 : Time 287.28s : 14014.66 words/s
[2019-08-08 12:03:14] Ep. 9 : Up. 466000 : Sen. 1,477,534 : Cost 53.92534256 : Time 287.43s : 13991.56 words/s
[2019-08-08 12:08:01] Ep. 9 : Up. 468000 : Sen. 1,699,629 : Cost 53.63649368 : Time 287.11s : 14069.56 words/s
[2019-08-08 12:12:49] Ep. 9 : Up. 470000 : Sen. 1,919,480 : Cost 53.81290054 : Time 287.54s : 13933.48 words/s
[2019-08-08 12:17:37] Ep. 9 : Up. 472000 : Sen. 2,141,558 : Cost 53.69817352 : Time 288.61s : 13988.51 words/s
[2019-08-08 12:22:26] Ep. 9 : Up. 474000 : Sen. 2,362,898 : Cost 53.98975372 : Time 288.59s : 13997.87 words/s
[2019-08-08 12:27:13] Ep. 9 : Up. 476000 : Sen. 2,583,311 : Cost 54.19125748 : Time 287.55s : 13995.66 words/s
[2019-08-08 12:32:03] Ep. 9 : Up. 478000 : Sen. 2,804,723 : Cost 53.85678101 : Time 289.72s : 13895.85 words/s
[2019-08-08 12:36:53] Ep. 9 : Up. 480000 : Sen. 3,026,140 : Cost 54.12712097 : Time 289.78s : 13946.98 words/s
[2019-08-08 12:36:53] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-08 12:37:05] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter480000.npz
[2019-08-08 12:37:14] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-08 12:37:25] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-08 12:38:01] [valid] Ep. 9 : Up. 480000 : cross-entropy : 50.4867 : new best
[2019-08-08 12:38:08] [valid] Ep. 9 : Up. 480000 : perplexity : 7.21984 : new best
[2019-08-08 12:39:15] [valid] Ep. 9 : Up. 480000 : translation : 20.39 : stalled 1 times (last best: 20.66)
[2019-08-08 12:44:04] Ep. 9 : Up. 482000 : Sen. 3,247,691 : Cost 53.68223190 : Time 431.16s : 9322.00 words/s
[2019-08-08 12:48:52] Ep. 9 : Up. 484000 : Sen. 3,469,013 : Cost 54.11252975 : Time 287.68s : 14024.51 words/s
[2019-08-08 12:53:41] Ep. 9 : Up. 486000 : Sen. 3,689,182 : Cost 54.26657867 : Time 288.98s : 13911.13 words/s
[2019-08-08 12:58:29] Ep. 9 : Up. 488000 : Sen. 3,910,888 : Cost 54.00803757 : Time 288.59s : 13990.89 words/s
[2019-08-08 13:03:17] Ep. 9 : Up. 490000 : Sen. 4,131,428 : Cost 54.32119370 : Time 287.58s : 13990.70 words/s
[2019-08-08 13:08:07] Ep. 9 : Up. 492000 : Sen. 4,353,147 : Cost 53.94860458 : Time 290.08s : 13867.70 words/s
[2019-08-08 13:12:58] Ep. 9 : Up. 494000 : Sen. 4,574,546 : Cost 54.01497269 : Time 290.95s : 13880.55 words/s
[2019-08-08 13:17:46] Ep. 9 : Up. 496000 : Sen. 4,795,185 : Cost 54.14462662 : Time 288.11s : 13953.87 words/s
[2019-08-08 13:22:33] Ep. 9 : Up. 498000 : Sen. 5,015,780 : Cost 53.98931503 : Time 287.46s : 13972.51 words/s
[2019-08-08 13:27:21] Ep. 9 : Up. 500000 : Sen. 5,236,365 : Cost 54.25792694 : Time 287.68s : 13993.06 words/s
[2019-08-08 13:27:21] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-08 13:27:33] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter500000.npz
[2019-08-08 13:27:41] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-08 13:27:52] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-08 13:28:22] [valid] Ep. 9 : Up. 500000 : cross-entropy : 50.2998 : new best
[2019-08-08 13:28:28] [valid] Ep. 9 : Up. 500000 : perplexity : 7.16719 : new best
[2019-08-08 13:29:26] [valid] Ep. 9 : Up. 500000 : translation : 20.37 : stalled 2 times (last best: 20.66)
[2019-08-08 13:34:18] Ep. 9 : Up. 502000 : Sen. 5,458,350 : Cost 54.21617508 : Time 416.67s : 9711.63 words/s
[2019-08-08 13:39:07] Ep. 9 : Up. 504000 : Sen. 5,678,640 : Cost 54.48147964 : Time 288.99s : 13929.95 words/s
[2019-08-08 22:38:32] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-08 22:38:32] [marian] Running on fulla as process 159773 with command line:
[2019-08-08 22:38:32] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/100M_random_hardrules_v1.0/model/model.npz -T . --devices 5 --train-sets ../experiments/100M_random_hardrules_v1.0/data/train.bpe.de ../experiments/100M_random_hardrules_v1.0/data/train.bpe.en --vocabs ../experiments/100M_random_hardrules_v1.0/data/train.bpe.de.json ../experiments/100M_random_hardrules_v1.0/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/100M_random_hardrules_v1.0/data/dev.bpe.de ../experiments/100M_random_hardrules_v1.0/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/100M_random_hardrules_v1.0/model/dev.out --valid-script-path ../experiments/100M_random_hardrules_v1.0/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/100M_random_hardrules_v1.0/model/train.log --valid-log ../experiments/100M_random_hardrules_v1.0/model/valid.log
[2019-08-08 22:38:33] [config] after-batches: 0
[2019-08-08 22:38:33] [config] after-epochs: 0
[2019-08-08 22:38:33] [config] allow-unk: false
[2019-08-08 22:38:33] [config] beam-size: 12
[2019-08-08 22:38:33] [config] bert-class-symbol: "[CLS]"
[2019-08-08 22:38:33] [config] bert-mask-symbol: "[MASK]"
[2019-08-08 22:38:33] [config] bert-masking-fraction: 0.15
[2019-08-08 22:38:33] [config] bert-sep-symbol: "[SEP]"
[2019-08-08 22:38:33] [config] bert-train-type-embeddings: true
[2019-08-08 22:38:33] [config] bert-type-vocab-size: 2
[2019-08-08 22:38:33] [config] best-deep: false
[2019-08-08 22:38:33] [config] clip-gemm: 0
[2019-08-08 22:38:33] [config] clip-norm: 1
[2019-08-08 22:38:33] [config] cost-type: ce-mean
[2019-08-08 22:38:33] [config] cpu-threads: 0
[2019-08-08 22:38:33] [config] data-weighting: ""
[2019-08-08 22:38:33] [config] data-weighting-type: sentence
[2019-08-08 22:38:33] [config] dec-cell: gru
[2019-08-08 22:38:33] [config] dec-cell-base-depth: 2
[2019-08-08 22:38:33] [config] dec-cell-high-depth: 1
[2019-08-08 22:38:33] [config] dec-depth: 1
[2019-08-08 22:38:33] [config] devices:
[2019-08-08 22:38:33] [config]   - 5
[2019-08-08 22:38:33] [config] dim-emb: 512
[2019-08-08 22:38:33] [config] dim-rnn: 1024
[2019-08-08 22:38:33] [config] dim-vocabs:
[2019-08-08 22:38:33] [config]   - 50000
[2019-08-08 22:38:33] [config]   - 50000
[2019-08-08 22:38:33] [config] disp-first: 0
[2019-08-08 22:38:33] [config] disp-freq: 2000
[2019-08-08 22:38:33] [config] disp-label-counts: false
[2019-08-08 22:38:33] [config] dropout-rnn: 0.2
[2019-08-08 22:38:33] [config] dropout-src: 0.1
[2019-08-08 22:38:33] [config] dropout-trg: 0.1
[2019-08-08 22:38:33] [config] dump-config: ""
[2019-08-08 22:38:33] [config] early-stopping: 5
[2019-08-08 22:38:33] [config] embedding-fix-src: false
[2019-08-08 22:38:33] [config] embedding-fix-trg: false
[2019-08-08 22:38:33] [config] embedding-normalization: false
[2019-08-08 22:38:33] [config] embedding-vectors:
[2019-08-08 22:38:33] [config]   []
[2019-08-08 22:38:33] [config] enc-cell: gru
[2019-08-08 22:38:33] [config] enc-cell-depth: 1
[2019-08-08 22:38:33] [config] enc-depth: 1
[2019-08-08 22:38:33] [config] enc-type: bidirectional
[2019-08-08 22:38:33] [config] exponential-smoothing: 0.0001
[2019-08-08 22:38:33] [config] grad-dropping-momentum: 0
[2019-08-08 22:38:33] [config] grad-dropping-rate: 0
[2019-08-08 22:38:33] [config] grad-dropping-warmup: 100
[2019-08-08 22:38:33] [config] guided-alignment: none
[2019-08-08 22:38:33] [config] guided-alignment-cost: mse
[2019-08-08 22:38:33] [config] guided-alignment-weight: 0.1
[2019-08-08 22:38:33] [config] ignore-model-config: false
[2019-08-08 22:38:33] [config] input-types:
[2019-08-08 22:38:33] [config]   []
[2019-08-08 22:38:33] [config] interpolate-env-vars: false
[2019-08-08 22:38:33] [config] keep-best: false
[2019-08-08 22:38:33] [config] label-smoothing: 0
[2019-08-08 22:38:33] [config] layer-normalization: true
[2019-08-08 22:38:33] [config] learn-rate: 0.0001
[2019-08-08 22:38:33] [config] log: ../experiments/100M_random_hardrules_v1.0/model/train.log
[2019-08-08 22:38:33] [config] log-level: info
[2019-08-08 22:38:33] [config] log-time-zone: ""
[2019-08-08 22:38:33] [config] lr-decay: 0
[2019-08-08 22:38:33] [config] lr-decay-freq: 50000
[2019-08-08 22:38:33] [config] lr-decay-inv-sqrt:
[2019-08-08 22:38:33] [config]   - 0
[2019-08-08 22:38:33] [config] lr-decay-repeat-warmup: false
[2019-08-08 22:38:33] [config] lr-decay-reset-optimizer: false
[2019-08-08 22:38:33] [config] lr-decay-start:
[2019-08-08 22:38:33] [config]   - 10
[2019-08-08 22:38:33] [config]   - 1
[2019-08-08 22:38:33] [config] lr-decay-strategy: epoch+stalled
[2019-08-08 22:38:33] [config] lr-report: false
[2019-08-08 22:38:33] [config] lr-warmup: 0
[2019-08-08 22:38:33] [config] lr-warmup-at-reload: false
[2019-08-08 22:38:33] [config] lr-warmup-cycle: false
[2019-08-08 22:38:33] [config] lr-warmup-start-rate: 0
[2019-08-08 22:38:33] [config] max-length: 50
[2019-08-08 22:38:33] [config] max-length-crop: false
[2019-08-08 22:38:33] [config] max-length-factor: 3
[2019-08-08 22:38:33] [config] maxi-batch: 100
[2019-08-08 22:38:33] [config] maxi-batch-sort: trg
[2019-08-08 22:38:33] [config] mini-batch: 64
[2019-08-08 22:38:33] [config] mini-batch-fit: true
[2019-08-08 22:38:33] [config] mini-batch-fit-step: 10
[2019-08-08 22:38:33] [config] mini-batch-overstuff: 1
[2019-08-08 22:38:33] [config] mini-batch-track-lr: false
[2019-08-08 22:38:33] [config] mini-batch-understuff: 1
[2019-08-08 22:38:33] [config] mini-batch-warmup: 0
[2019-08-08 22:38:33] [config] mini-batch-words: 0
[2019-08-08 22:38:33] [config] mini-batch-words-ref: 0
[2019-08-08 22:38:33] [config] model: ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-08 22:38:33] [config] multi-loss-type: sum
[2019-08-08 22:38:33] [config] multi-node: false
[2019-08-08 22:38:33] [config] multi-node-overlap: true
[2019-08-08 22:38:33] [config] n-best: false
[2019-08-08 22:38:33] [config] no-nccl: false
[2019-08-08 22:38:33] [config] no-reload: false
[2019-08-08 22:38:33] [config] no-restore-corpus: false
[2019-08-08 22:38:33] [config] no-shuffle: false
[2019-08-08 22:38:33] [config] normalize: 1
[2019-08-08 22:38:33] [config] num-devices: 0
[2019-08-08 22:38:33] [config] optimizer: adam
[2019-08-08 22:38:33] [config] optimizer-delay: 1
[2019-08-08 22:38:33] [config] optimizer-params:
[2019-08-08 22:38:33] [config]   []
[2019-08-08 22:38:33] [config] overwrite: false
[2019-08-08 22:38:33] [config] pretrained-model: ""
[2019-08-08 22:38:33] [config] quiet: false
[2019-08-08 22:38:33] [config] quiet-translation: true
[2019-08-08 22:38:33] [config] relative-paths: false
[2019-08-08 22:38:33] [config] right-left: false
[2019-08-08 22:38:33] [config] save-freq: 20000
[2019-08-08 22:38:33] [config] seed: 1111
[2019-08-08 22:38:33] [config] shuffle-in-ram: false
[2019-08-08 22:38:33] [config] skip: false
[2019-08-08 22:38:33] [config] sqlite: ""
[2019-08-08 22:38:33] [config] sqlite-drop: false
[2019-08-08 22:38:33] [config] sync-sgd: true
[2019-08-08 22:38:33] [config] tempdir: .
[2019-08-08 22:38:33] [config] tied-embeddings: false
[2019-08-08 22:38:33] [config] tied-embeddings-all: false
[2019-08-08 22:38:33] [config] tied-embeddings-src: false
[2019-08-08 22:38:33] [config] train-sets:
[2019-08-08 22:38:33] [config]   - ../experiments/100M_random_hardrules_v1.0/data/train.bpe.de
[2019-08-08 22:38:33] [config]   - ../experiments/100M_random_hardrules_v1.0/data/train.bpe.en
[2019-08-08 22:38:33] [config] transformer-aan-activation: swish
[2019-08-08 22:38:33] [config] transformer-aan-depth: 2
[2019-08-08 22:38:33] [config] transformer-aan-nogate: false
[2019-08-08 22:38:33] [config] transformer-decoder-autoreg: self-attention
[2019-08-08 22:38:33] [config] transformer-dim-aan: 2048
[2019-08-08 22:38:33] [config] transformer-dim-ffn: 2048
[2019-08-08 22:38:33] [config] transformer-dropout: 0
[2019-08-08 22:38:33] [config] transformer-dropout-attention: 0
[2019-08-08 22:38:33] [config] transformer-dropout-ffn: 0
[2019-08-08 22:38:33] [config] transformer-ffn-activation: swish
[2019-08-08 22:38:33] [config] transformer-ffn-depth: 2
[2019-08-08 22:38:33] [config] transformer-guided-alignment-layer: last
[2019-08-08 22:38:33] [config] transformer-heads: 8
[2019-08-08 22:38:33] [config] transformer-no-projection: false
[2019-08-08 22:38:33] [config] transformer-postprocess: dan
[2019-08-08 22:38:33] [config] transformer-postprocess-emb: d
[2019-08-08 22:38:33] [config] transformer-preprocess: ""
[2019-08-08 22:38:33] [config] transformer-tied-layers:
[2019-08-08 22:38:33] [config]   []
[2019-08-08 22:38:33] [config] transformer-train-position-embeddings: false
[2019-08-08 22:38:33] [config] type: amun
[2019-08-08 22:38:33] [config] ulr: false
[2019-08-08 22:38:33] [config] ulr-dim-emb: 0
[2019-08-08 22:38:33] [config] ulr-dropout: 0
[2019-08-08 22:38:33] [config] ulr-keys-vectors: ""
[2019-08-08 22:38:33] [config] ulr-query-vectors: ""
[2019-08-08 22:38:33] [config] ulr-softmax-temperature: 1
[2019-08-08 22:38:33] [config] ulr-trainable-transformation: false
[2019-08-08 22:38:33] [config] valid-freq: 20000
[2019-08-08 22:38:33] [config] valid-log: ../experiments/100M_random_hardrules_v1.0/model/valid.log
[2019-08-08 22:38:33] [config] valid-max-length: 1000
[2019-08-08 22:38:33] [config] valid-metrics:
[2019-08-08 22:38:33] [config]   - cross-entropy
[2019-08-08 22:38:33] [config]   - perplexity
[2019-08-08 22:38:33] [config]   - translation
[2019-08-08 22:38:33] [config] valid-mini-batch: 8
[2019-08-08 22:38:33] [config] valid-script-path: ../experiments/100M_random_hardrules_v1.0/score-dev.sh
[2019-08-08 22:38:33] [config] valid-sets:
[2019-08-08 22:38:33] [config]   - ../experiments/100M_random_hardrules_v1.0/data/dev.bpe.de
[2019-08-08 22:38:33] [config]   - ../experiments/100M_random_hardrules_v1.0/data/dev.bpe.en
[2019-08-08 22:38:33] [config] valid-translation-output: ../experiments/100M_random_hardrules_v1.0/model/dev.out
[2019-08-08 22:38:33] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-08 22:38:33] [config] vocabs:
[2019-08-08 22:38:33] [config]   - ../experiments/100M_random_hardrules_v1.0/data/train.bpe.de.json
[2019-08-08 22:38:33] [config]   - ../experiments/100M_random_hardrules_v1.0/data/train.bpe.en.json
[2019-08-08 22:38:33] [config] word-penalty: 0
[2019-08-08 22:38:33] [config] workspace: 3000
[2019-08-08 22:38:33] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-08 22:38:33] Using synchronous training
[2019-08-08 22:38:33] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_random_hardrules_v1.0/data/train.bpe.de.json
[2019-08-08 22:38:33] [data] Using unused word id eos for 0
[2019-08-08 22:38:33] [data] Using unused word id UNK for 1
[2019-08-08 22:38:33] [data] Setting vocabulary size for input 0 to 50000
[2019-08-08 22:38:33] [data] Loading vocabulary from JSON/Yaml file ../experiments/100M_random_hardrules_v1.0/data/train.bpe.en.json
[2019-08-08 22:38:33] [data] Using unused word id eos for 0
[2019-08-08 22:38:33] [data] Using unused word id UNK for 1
[2019-08-08 22:38:33] [data] Setting vocabulary size for input 1 to 50000
[2019-08-08 22:38:34] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-08 22:38:34] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-08 22:38:35] [memory] Extending reserved space to 3072 MB (device gpu5)
[2019-08-08 22:38:35] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-08 22:38:35] [comm] NCCLCommunicator constructed successfully.
[2019-08-08 22:38:35] [training] Using 1 GPUs
[2019-08-08 22:38:35] [memory] Reserving 422 MB, device gpu5
[2019-08-08 22:38:35] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-08 22:38:35] [memory] Reserving 422 MB, device gpu5
[2019-08-08 22:38:38] [batching] Done. Typical MB size is 4042 target words
[2019-08-08 22:38:38] [memory] Extending reserved space to 3072 MB (device gpu5)
[2019-08-08 22:38:38] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-08 22:38:38] [comm] NCCLCommunicator constructed successfully.
[2019-08-08 22:38:38] [training] Using 1 GPUs
[2019-08-08 22:38:38] Loading model from ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-08 22:38:51] Loading Adam parameters from ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-08 22:39:32] [memory] Reserving 844 MB, device gpu5
[2019-08-08 22:39:34] [training] Model reloaded from ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-08 22:39:34] [data] Restoring the corpus state to epoch 9, batch 500000
[2019-08-08 22:39:34] [data] Shuffling data
[2019-08-08 22:40:21] [data] Done reading 6886952 sentences
[2019-08-08 22:40:44] [data] Done shuffling 6886952 sentences to temp files
[2019-08-08 22:43:17] Training started
[2019-08-08 22:43:17] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-08 22:43:17] [memory] Reserving 422 MB, device gpu5
[2019-08-08 22:43:17] [memory] Reserving 422 MB, device gpu5
[2019-08-08 22:43:17] Loading model from ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-08 22:43:31] [memory] Reserving 422 MB, device cpu0
[2019-08-08 22:43:32] [memory] Reserving 422 MB, device gpu5
[2019-08-08 22:48:13] Ep. 9 : Up. 502000 : Sen. 5,458,350 : Cost 54.13756180 : Time 579.36s : 6984.48 words/s
[2019-08-08 22:52:55] Ep. 9 : Up. 504000 : Sen. 5,678,640 : Cost 54.33007050 : Time 281.96s : 14277.01 words/s
[2019-08-08 22:57:38] Ep. 9 : Up. 506000 : Sen. 5,899,295 : Cost 54.08481598 : Time 282.71s : 14212.54 words/s
[2019-08-08 23:02:20] Ep. 9 : Up. 508000 : Sen. 6,120,642 : Cost 54.21512222 : Time 282.69s : 14261.62 words/s
[2019-08-08 23:05:18] Seen 6258441 samples
[2019-08-08 23:05:18] Starting epoch 10
[2019-08-08 23:05:18] [data] Shuffling data
[2019-08-08 23:05:22] [data] Done reading 6886952 sentences
[2019-08-08 23:05:46] [data] Done shuffling 6886952 sentences to temp files
[2019-08-08 23:07:43] Ep. 10 : Up. 510000 : Sen. 83,122 : Cost 54.18836975 : Time 323.06s : 12502.23 words/s
[2019-08-08 23:12:26] Ep. 10 : Up. 512000 : Sen. 304,287 : Cost 53.14094543 : Time 282.41s : 14296.21 words/s
[2019-08-08 23:17:08] Ep. 10 : Up. 514000 : Sen. 525,374 : Cost 53.21839905 : Time 281.86s : 14286.02 words/s
[2019-08-08 23:21:49] Ep. 10 : Up. 516000 : Sen. 745,359 : Cost 53.10802460 : Time 281.59s : 14247.57 words/s
[2019-08-08 23:26:32] Ep. 10 : Up. 518000 : Sen. 965,990 : Cost 53.42227173 : Time 282.89s : 14205.73 words/s
[2019-08-08 23:31:17] Ep. 10 : Up. 520000 : Sen. 1,188,161 : Cost 53.26257324 : Time 285.11s : 14189.98 words/s
[2019-08-08 23:31:17] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-08 23:31:28] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter520000.npz
[2019-08-08 23:31:35] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-08 23:31:45] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-08 23:32:13] [valid] Ep. 10 : Up. 520000 : cross-entropy : 50.2225 : new best
[2019-08-08 23:32:20] [valid] Ep. 10 : Up. 520000 : perplexity : 7.14554 : new best
[2019-08-08 23:33:17] [valid] Ep. 10 : Up. 520000 : translation : 20.73 : new best
[2019-08-08 23:38:02] Ep. 10 : Up. 522000 : Sen. 1,410,104 : Cost 53.44507217 : Time 404.94s : 9994.88 words/s
[2019-08-08 23:42:45] Ep. 10 : Up. 524000 : Sen. 1,631,433 : Cost 53.32466125 : Time 283.04s : 14236.49 words/s
[2019-08-08 23:47:28] Ep. 10 : Up. 526000 : Sen. 1,852,547 : Cost 53.33032227 : Time 282.95s : 14224.22 words/s
[2019-08-08 23:52:12] Ep. 10 : Up. 528000 : Sen. 2,073,688 : Cost 53.30742645 : Time 283.99s : 14189.85 words/s
[2019-08-08 23:56:55] Ep. 10 : Up. 530000 : Sen. 2,295,206 : Cost 53.50002670 : Time 283.01s : 14228.88 words/s
[2019-08-09 00:01:38] Ep. 10 : Up. 532000 : Sen. 2,515,915 : Cost 53.59136963 : Time 283.13s : 14237.22 words/s
[2019-08-09 00:06:21] Ep. 10 : Up. 534000 : Sen. 2,737,296 : Cost 53.57681274 : Time 282.96s : 14236.90 words/s
[2019-08-09 00:11:05] Ep. 10 : Up. 536000 : Sen. 2,958,579 : Cost 53.46619415 : Time 283.21s : 14246.05 words/s
[2019-08-09 00:15:48] Ep. 10 : Up. 538000 : Sen. 3,181,098 : Cost 53.52870941 : Time 283.36s : 14290.88 words/s
[2019-08-09 00:20:31] Ep. 10 : Up. 540000 : Sen. 3,401,903 : Cost 53.44173431 : Time 282.94s : 14227.80 words/s
[2019-08-09 00:20:31] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 00:20:40] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter540000.npz
[2019-08-09 00:20:47] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 00:20:57] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-09 00:21:23] [valid] Ep. 10 : Up. 540000 : cross-entropy : 50.1766 : new best
[2019-08-09 00:21:30] [valid] Ep. 10 : Up. 540000 : perplexity : 7.13271 : new best
[2019-08-09 00:22:25] [valid] Ep. 10 : Up. 540000 : translation : 20.67 : stalled 1 times (last best: 20.73)
[2019-08-09 00:27:10] Ep. 10 : Up. 542000 : Sen. 3,622,187 : Cost 53.74013138 : Time 398.99s : 10078.15 words/s
[2019-08-09 00:31:53] Ep. 10 : Up. 544000 : Sen. 3,844,407 : Cost 53.53256226 : Time 283.18s : 14262.60 words/s
[2019-08-09 00:36:36] Ep. 10 : Up. 546000 : Sen. 4,065,293 : Cost 53.71961975 : Time 283.43s : 14225.92 words/s
[2019-08-09 00:41:20] Ep. 10 : Up. 548000 : Sen. 4,286,615 : Cost 53.55482101 : Time 283.53s : 14230.38 words/s
[2019-08-09 00:46:03] Ep. 10 : Up. 550000 : Sen. 4,507,907 : Cost 53.52851105 : Time 282.85s : 14249.80 words/s
[2019-08-09 00:50:47] Ep. 10 : Up. 552000 : Sen. 4,728,957 : Cost 53.70092010 : Time 283.84s : 14229.25 words/s
[2019-08-09 00:55:30] Ep. 10 : Up. 554000 : Sen. 4,950,139 : Cost 53.53095245 : Time 282.89s : 14247.84 words/s
[2019-08-09 01:00:12] Ep. 10 : Up. 556000 : Sen. 5,170,297 : Cost 53.67646790 : Time 282.41s : 14205.84 words/s
[2019-08-09 01:04:56] Ep. 10 : Up. 558000 : Sen. 5,392,354 : Cost 53.61198425 : Time 283.71s : 14236.64 words/s
[2019-08-09 01:09:39] Ep. 10 : Up. 560000 : Sen. 5,614,202 : Cost 53.53657150 : Time 283.07s : 14252.83 words/s
[2019-08-09 01:09:39] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 01:09:48] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter560000.npz
[2019-08-09 01:09:55] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 01:10:05] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-09 01:10:32] [valid] Ep. 10 : Up. 560000 : cross-entropy : 50.0084 : new best
[2019-08-09 01:10:38] [valid] Ep. 10 : Up. 560000 : perplexity : 7.0859 : new best
[2019-08-09 01:11:36] [valid] Ep. 10 : Up. 560000 : translation : 20.42 : stalled 2 times (last best: 20.73)
[2019-08-09 01:16:21] Ep. 10 : Up. 562000 : Sen. 5,834,802 : Cost 53.64882660 : Time 402.63s : 9978.72 words/s
[2019-08-09 01:21:05] Ep. 10 : Up. 564000 : Sen. 6,056,515 : Cost 53.71835709 : Time 284.09s : 14212.38 words/s
[2019-08-09 01:25:25] Seen 6258441 samples
[2019-08-09 01:25:25] Starting epoch 11
[2019-08-09 01:25:25] [data] Shuffling data
[2019-08-09 01:25:28] [data] Done reading 6886952 sentences
[2019-08-09 01:25:56] [data] Done shuffling 6886952 sentences to temp files
[2019-08-09 01:26:30] Ep. 11 : Up. 566000 : Sen. 18,963 : Cost 53.66559601 : Time 324.67s : 12409.82 words/s
[2019-08-09 01:31:13] Ep. 11 : Up. 568000 : Sen. 240,780 : Cost 52.37333298 : Time 283.28s : 14248.08 words/s
[2019-08-09 01:35:57] Ep. 11 : Up. 570000 : Sen. 461,636 : Cost 52.65615463 : Time 283.46s : 14200.45 words/s
[2019-08-09 01:40:41] Ep. 11 : Up. 572000 : Sen. 682,774 : Cost 52.81956100 : Time 284.59s : 14186.53 words/s
[2019-08-09 01:45:25] Ep. 11 : Up. 574000 : Sen. 903,784 : Cost 52.84669876 : Time 283.71s : 14204.67 words/s
[2019-08-09 01:50:13] Ep. 11 : Up. 576000 : Sen. 1,125,260 : Cost 53.21018982 : Time 288.07s : 14040.62 words/s
[2019-08-09 01:54:55] Ep. 11 : Up. 578000 : Sen. 1,345,229 : Cost 52.90740585 : Time 281.78s : 14228.86 words/s
[2019-08-09 01:59:38] Ep. 11 : Up. 580000 : Sen. 1,566,252 : Cost 52.94904709 : Time 283.28s : 14207.01 words/s
[2019-08-09 01:59:38] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 01:59:48] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter580000.npz
[2019-08-09 01:59:55] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 02:00:05] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-09 02:00:32] [valid] Ep. 11 : Up. 580000 : cross-entropy : 49.966 : new best
[2019-08-09 02:00:38] [valid] Ep. 11 : Up. 580000 : perplexity : 7.07412 : new best
[2019-08-09 02:01:34] [valid] Ep. 11 : Up. 580000 : translation : 20.5 : stalled 3 times (last best: 20.73)
[2019-08-09 02:06:19] Ep. 11 : Up. 582000 : Sen. 1,786,958 : Cost 53.14001465 : Time 400.77s : 10047.25 words/s
[2019-08-09 02:11:02] Ep. 11 : Up. 584000 : Sen. 2,008,220 : Cost 53.02560425 : Time 283.00s : 14244.79 words/s
[2019-08-09 02:15:45] Ep. 11 : Up. 586000 : Sen. 2,229,588 : Cost 53.05138397 : Time 282.64s : 14254.67 words/s
[2019-08-09 02:20:27] Ep. 11 : Up. 588000 : Sen. 2,450,311 : Cost 53.10210419 : Time 282.71s : 14195.41 words/s
[2019-08-09 02:25:11] Ep. 11 : Up. 590000 : Sen. 2,671,798 : Cost 53.06312943 : Time 283.96s : 14221.90 words/s
[2019-08-09 02:29:55] Ep. 11 : Up. 592000 : Sen. 2,893,594 : Cost 53.18196869 : Time 283.86s : 14228.97 words/s
[2019-08-09 02:34:38] Ep. 11 : Up. 594000 : Sen. 3,114,290 : Cost 53.20355606 : Time 283.10s : 14217.58 words/s
[2019-08-09 02:39:22] Ep. 11 : Up. 596000 : Sen. 3,336,466 : Cost 53.03831100 : Time 283.63s : 14252.46 words/s
[2019-08-09 02:44:06] Ep. 11 : Up. 598000 : Sen. 3,557,358 : Cost 53.33689499 : Time 283.56s : 14233.39 words/s
[2019-08-09 02:48:49] Ep. 11 : Up. 600000 : Sen. 3,779,083 : Cost 53.01170349 : Time 282.94s : 14245.80 words/s
[2019-08-09 02:48:49] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 02:48:58] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter600000.npz
[2019-08-09 02:49:05] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 02:49:15] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-09 02:49:43] [valid] Ep. 11 : Up. 600000 : cross-entropy : 49.9152 : new best
[2019-08-09 02:49:50] [valid] Ep. 11 : Up. 600000 : perplexity : 7.06008 : new best
[2019-08-09 02:50:45] [valid] Ep. 11 : Up. 600000 : translation : 20.57 : stalled 4 times (last best: 20.73)
[2019-08-09 02:55:30] Ep. 11 : Up. 602000 : Sen. 3,999,717 : Cost 53.33158112 : Time 401.95s : 10017.83 words/s
[2019-08-09 03:00:14] Ep. 11 : Up. 604000 : Sen. 4,221,013 : Cost 53.09562683 : Time 283.04s : 14234.24 words/s
[2019-08-09 03:04:56] Ep. 11 : Up. 606000 : Sen. 4,442,430 : Cost 53.09440994 : Time 282.74s : 14255.08 words/s
[2019-08-09 03:09:40] Ep. 11 : Up. 608000 : Sen. 4,664,101 : Cost 53.42947006 : Time 283.95s : 14256.02 words/s
[2019-08-09 03:14:22] Ep. 11 : Up. 610000 : Sen. 4,884,768 : Cost 53.34552002 : Time 282.18s : 14234.68 words/s
[2019-08-09 03:19:07] Ep. 11 : Up. 612000 : Sen. 5,107,111 : Cost 53.40152740 : Time 284.92s : 14221.20 words/s
[2019-08-09 03:23:51] Ep. 11 : Up. 614000 : Sen. 5,328,185 : Cost 53.60852814 : Time 283.65s : 14237.76 words/s
[2019-08-09 03:28:34] Ep. 11 : Up. 616000 : Sen. 5,549,337 : Cost 53.30440521 : Time 282.89s : 14206.59 words/s
[2019-08-09 03:33:17] Ep. 11 : Up. 618000 : Sen. 5,770,570 : Cost 53.34120941 : Time 282.71s : 14222.24 words/s
[2019-08-09 03:38:04] Ep. 11 : Up. 620000 : Sen. 5,991,825 : Cost 53.32366562 : Time 287.16s : 14049.97 words/s
[2019-08-09 03:38:04] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 03:38:14] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter620000.npz
[2019-08-09 03:38:21] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 03:38:31] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-09 03:38:59] [valid] Ep. 11 : Up. 620000 : cross-entropy : 49.7527 : new best
[2019-08-09 03:39:05] [valid] Ep. 11 : Up. 620000 : perplexity : 7.0153 : new best
[2019-08-09 03:40:00] [valid] Ep. 11 : Up. 620000 : translation : 20.7 : stalled 5 times (last best: 20.73)
[2019-08-09 03:44:47] Ep. 11 : Up. 622000 : Sen. 6,213,444 : Cost 53.52387619 : Time 403.07s : 10018.91 words/s
[2019-08-09 03:45:45] Seen 6258441 samples
[2019-08-09 03:45:45] Starting epoch 12
[2019-08-09 03:45:45] [data] Shuffling data
[2019-08-09 03:45:49] [data] Done reading 6886952 sentences
[2019-08-09 03:46:22] [data] Done shuffling 6886952 sentences to temp files
[2019-08-09 03:50:08] Ep. 12 : Up. 624000 : Sen. 174,922 : Cost 52.42186356 : Time 321.20s : 12463.96 words/s
[2019-08-09 03:54:53] Ep. 12 : Up. 626000 : Sen. 396,105 : Cost 52.26570892 : Time 285.27s : 14154.21 words/s
[2019-08-09 03:59:39] Ep. 12 : Up. 628000 : Sen. 616,612 : Cost 52.73276901 : Time 285.39s : 14081.27 words/s
[2019-08-09 04:04:22] Ep. 12 : Up. 630000 : Sen. 838,400 : Cost 52.47185135 : Time 283.21s : 14256.57 words/s
[2019-08-09 04:09:04] Ep. 12 : Up. 632000 : Sen. 1,059,483 : Cost 52.38301849 : Time 282.53s : 14215.32 words/s
[2019-08-09 04:13:48] Ep. 12 : Up. 634000 : Sen. 1,280,896 : Cost 52.69259262 : Time 283.84s : 14237.92 words/s
[2019-08-09 04:18:32] Ep. 12 : Up. 636000 : Sen. 1,501,923 : Cost 52.39817429 : Time 283.94s : 14169.75 words/s
[2019-08-09 04:23:17] Ep. 12 : Up. 638000 : Sen. 1,723,656 : Cost 52.62117767 : Time 284.33s : 14216.09 words/s
[2019-08-09 04:28:00] Ep. 12 : Up. 640000 : Sen. 1,943,989 : Cost 52.84663391 : Time 283.90s : 14190.71 words/s
[2019-08-09 04:28:00] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 04:28:11] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter640000.npz
[2019-08-09 04:28:23] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 04:28:34] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-09 04:29:04] [valid] Ep. 12 : Up. 640000 : cross-entropy : 49.8151 : stalled 1 times (last best: 49.7527)
[2019-08-09 04:29:11] [valid] Ep. 12 : Up. 640000 : perplexity : 7.03246 : stalled 1 times (last best: 7.0153)
[2019-08-09 04:30:07] [valid] Ep. 12 : Up. 640000 : translation : 20.45 : stalled 6 times (last best: 20.73)
[2019-08-09 04:34:52] Ep. 12 : Up. 642000 : Sen. 2,164,404 : Cost 52.68297958 : Time 411.43s : 9767.59 words/s
[2019-08-09 04:39:35] Ep. 12 : Up. 644000 : Sen. 2,385,668 : Cost 52.57403946 : Time 283.17s : 14225.52 words/s
[2019-08-09 04:44:19] Ep. 12 : Up. 646000 : Sen. 2,607,586 : Cost 52.71299362 : Time 284.25s : 14224.37 words/s
[2019-08-09 04:49:04] Ep. 12 : Up. 648000 : Sen. 2,829,161 : Cost 52.66516113 : Time 284.66s : 14181.96 words/s
[2019-08-09 04:53:48] Ep. 12 : Up. 650000 : Sen. 3,050,593 : Cost 52.85717392 : Time 283.83s : 14227.35 words/s
[2019-08-09 04:58:31] Ep. 12 : Up. 652000 : Sen. 3,271,819 : Cost 52.79590225 : Time 283.46s : 14216.45 words/s
[2019-08-09 05:03:16] Ep. 12 : Up. 654000 : Sen. 3,493,065 : Cost 52.87555313 : Time 284.49s : 14200.05 words/s
[2019-08-09 05:07:59] Ep. 12 : Up. 656000 : Sen. 3,713,922 : Cost 52.88842392 : Time 283.48s : 14213.68 words/s
[2019-08-09 05:12:43] Ep. 12 : Up. 658000 : Sen. 3,936,278 : Cost 52.87043762 : Time 283.64s : 14255.37 words/s
[2019-08-09 05:17:26] Ep. 12 : Up. 660000 : Sen. 4,157,985 : Cost 52.91117859 : Time 283.52s : 14229.93 words/s
[2019-08-09 05:17:26] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 05:17:38] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter660000.npz
[2019-08-09 05:17:45] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 05:17:56] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-09 05:18:22] [valid] Ep. 12 : Up. 660000 : cross-entropy : 49.6427 : new best
[2019-08-09 05:18:29] [valid] Ep. 12 : Up. 660000 : perplexity : 6.98515 : new best
[2019-08-09 05:19:24] [valid] Ep. 12 : Up. 660000 : translation : 20.57 : stalled 7 times (last best: 20.73)
[2019-08-09 05:24:11] Ep. 12 : Up. 662000 : Sen. 4,380,207 : Cost 52.86418533 : Time 404.43s : 9998.57 words/s
[2019-08-09 05:28:55] Ep. 12 : Up. 664000 : Sen. 4,602,312 : Cost 52.91543961 : Time 284.26s : 14223.44 words/s
[2019-08-09 05:33:40] Ep. 12 : Up. 666000 : Sen. 4,823,631 : Cost 53.05046463 : Time 284.36s : 14196.13 words/s
[2019-08-09 05:38:23] Ep. 12 : Up. 668000 : Sen. 5,043,704 : Cost 53.07691574 : Time 283.76s : 14131.35 words/s
[2019-08-09 05:43:08] Ep. 12 : Up. 670000 : Sen. 5,265,059 : Cost 53.13473511 : Time 284.81s : 14175.98 words/s
[2019-08-09 05:47:53] Ep. 12 : Up. 672000 : Sen. 5,485,907 : Cost 52.98261642 : Time 284.55s : 14133.11 words/s
[2019-08-09 05:52:36] Ep. 12 : Up. 674000 : Sen. 5,707,209 : Cost 53.08547592 : Time 283.84s : 14210.09 words/s
[2019-08-09 05:57:22] Ep. 12 : Up. 676000 : Sen. 5,928,527 : Cost 53.05577850 : Time 285.88s : 14096.77 words/s
[2019-08-09 06:02:06] Ep. 12 : Up. 678000 : Sen. 6,150,150 : Cost 52.93578339 : Time 284.06s : 14217.18 words/s
[2019-08-09 06:04:26] Seen 6258441 samples
[2019-08-09 06:04:26] Starting epoch 13
[2019-08-09 06:04:26] [data] Shuffling data
[2019-08-09 06:04:29] [data] Done reading 6886952 sentences
[2019-08-09 06:05:02] [data] Done shuffling 6886952 sentences to temp files
[2019-08-09 06:07:28] Ep. 13 : Up. 680000 : Sen. 112,736 : Cost 52.56789398 : Time 321.18s : 12543.50 words/s
[2019-08-09 06:07:28] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 06:07:40] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter680000.npz
[2019-08-09 06:07:49] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 06:08:02] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-09 06:08:35] [valid] Ep. 13 : Up. 680000 : cross-entropy : 49.5483 : new best
[2019-08-09 06:08:42] [valid] Ep. 13 : Up. 680000 : perplexity : 6.95939 : new best
[2019-08-09 06:09:37] [valid] Ep. 13 : Up. 680000 : translation : 20.52 : stalled 8 times (last best: 20.73)
[2019-08-09 06:14:24] Ep. 13 : Up. 682000 : Sen. 333,849 : Cost 52.14324951 : Time 416.61s : 9692.93 words/s
[2019-08-09 06:19:09] Ep. 13 : Up. 684000 : Sen. 555,661 : Cost 51.99411392 : Time 284.54s : 14163.27 words/s
[2019-08-09 06:23:53] Ep. 13 : Up. 686000 : Sen. 776,482 : Cost 52.31704712 : Time 284.17s : 14176.96 words/s
[2019-08-09 06:28:38] Ep. 13 : Up. 688000 : Sen. 996,297 : Cost 52.16335678 : Time 284.64s : 14067.99 words/s
[2019-08-09 06:33:22] Ep. 13 : Up. 690000 : Sen. 1,217,883 : Cost 52.21337128 : Time 284.74s : 14161.86 words/s
[2019-08-09 06:38:08] Ep. 13 : Up. 692000 : Sen. 1,438,754 : Cost 52.20308685 : Time 286.10s : 14050.60 words/s
[2019-08-09 06:42:53] Ep. 13 : Up. 694000 : Sen. 1,660,109 : Cost 52.35256577 : Time 284.52s : 14169.17 words/s
[2019-08-09 06:47:39] Ep. 13 : Up. 696000 : Sen. 1,881,402 : Cost 52.64004898 : Time 286.18s : 14138.90 words/s
[2019-08-09 06:52:24] Ep. 13 : Up. 698000 : Sen. 2,102,510 : Cost 52.41265869 : Time 284.96s : 14138.75 words/s
[2019-08-09 06:57:10] Ep. 13 : Up. 700000 : Sen. 2,324,382 : Cost 52.36269379 : Time 285.47s : 14133.75 words/s
[2019-08-09 06:57:10] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 06:57:20] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter700000.npz
[2019-08-09 06:57:27] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 06:57:37] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-09 06:58:05] [valid] Ep. 13 : Up. 700000 : cross-entropy : 49.6082 : stalled 1 times (last best: 49.5483)
[2019-08-09 06:58:11] [valid] Ep. 13 : Up. 700000 : perplexity : 6.97572 : stalled 1 times (last best: 6.95939)
[2019-08-09 06:59:08] [valid] Ep. 13 : Up. 700000 : translation : 20.58 : stalled 9 times (last best: 20.73)
[2019-08-09 07:03:56] Ep. 13 : Up. 702000 : Sen. 2,546,427 : Cost 52.20229721 : Time 405.96s : 9947.13 words/s
[2019-08-09 07:08:42] Ep. 13 : Up. 704000 : Sen. 2,767,504 : Cost 52.49272919 : Time 286.37s : 14081.51 words/s
[2019-08-09 07:13:26] Ep. 13 : Up. 706000 : Sen. 2,988,258 : Cost 52.20381165 : Time 283.99s : 14104.65 words/s
[2019-08-09 07:18:12] Ep. 13 : Up. 708000 : Sen. 3,208,398 : Cost 52.80916214 : Time 285.91s : 14087.86 words/s
[2019-08-09 07:22:56] Ep. 13 : Up. 710000 : Sen. 3,430,108 : Cost 52.40156937 : Time 284.57s : 14200.04 words/s
[2019-08-09 07:27:40] Ep. 13 : Up. 712000 : Sen. 3,651,442 : Cost 52.37321854 : Time 283.75s : 14175.30 words/s
[2019-08-09 07:32:29] Ep. 13 : Up. 714000 : Sen. 3,872,675 : Cost 52.73617935 : Time 288.65s : 14000.13 words/s
[2019-08-09 07:37:12] Ep. 13 : Up. 716000 : Sen. 4,092,686 : Cost 52.63546753 : Time 282.89s : 14175.88 words/s
[2019-08-09 07:41:55] Ep. 13 : Up. 718000 : Sen. 4,313,182 : Cost 52.82487488 : Time 283.73s : 14192.36 words/s
[2019-08-09 07:46:40] Ep. 13 : Up. 720000 : Sen. 4,534,279 : Cost 52.77365112 : Time 284.58s : 14172.30 words/s
[2019-08-09 07:46:40] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 07:46:53] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter720000.npz
[2019-08-09 07:47:00] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 07:47:10] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-09 07:47:38] [valid] Ep. 13 : Up. 720000 : cross-entropy : 49.5171 : new best
[2019-08-09 07:47:44] [valid] Ep. 13 : Up. 720000 : perplexity : 6.95088 : new best
[2019-08-09 07:48:40] [valid] Ep. 13 : Up. 720000 : translation : 20.47 : stalled 10 times (last best: 20.73)
[2019-08-09 07:53:26] Ep. 13 : Up. 722000 : Sen. 4,755,200 : Cost 52.73901367 : Time 406.23s : 9912.37 words/s
[2019-08-09 07:58:11] Ep. 13 : Up. 724000 : Sen. 4,976,921 : Cost 52.70916748 : Time 284.95s : 14156.47 words/s
[2019-08-09 08:02:57] Ep. 13 : Up. 726000 : Sen. 5,197,932 : Cost 52.66909027 : Time 285.78s : 14099.63 words/s
[2019-08-09 08:07:41] Ep. 13 : Up. 728000 : Sen. 5,419,190 : Cost 52.72533035 : Time 283.79s : 14200.85 words/s
[2019-08-09 08:12:25] Ep. 13 : Up. 730000 : Sen. 5,640,438 : Cost 52.74930954 : Time 284.12s : 14186.65 words/s
[2019-08-09 08:17:10] Ep. 13 : Up. 732000 : Sen. 5,861,732 : Cost 52.90192795 : Time 284.78s : 14175.84 words/s
[2019-08-09 08:21:54] Ep. 13 : Up. 734000 : Sen. 6,084,141 : Cost 52.71074295 : Time 284.60s : 14217.35 words/s
[2019-08-09 08:25:38] Seen 6258441 samples
[2019-08-09 08:25:38] Starting epoch 14
[2019-08-09 08:25:38] [data] Shuffling data
[2019-08-09 08:25:42] [data] Done reading 6886952 sentences
[2019-08-09 08:26:06] [data] Done shuffling 6886952 sentences to temp files
[2019-08-09 08:27:14] Ep. 14 : Up. 736000 : Sen. 46,484 : Cost 52.64054108 : Time 319.67s : 12576.49 words/s
[2019-08-09 08:31:57] Ep. 14 : Up. 738000 : Sen. 267,569 : Cost 51.68236160 : Time 283.46s : 14219.98 words/s
[2019-08-09 08:36:41] Ep. 14 : Up. 740000 : Sen. 487,840 : Cost 51.79563904 : Time 283.24s : 14174.13 words/s
[2019-08-09 08:36:41] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 08:36:50] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter740000.npz
[2019-08-09 08:36:57] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 08:37:07] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-09 08:37:34] [valid] Ep. 14 : Up. 740000 : cross-entropy : 49.4887 : new best
[2019-08-09 08:37:41] [valid] Ep. 14 : Up. 740000 : perplexity : 6.94316 : new best
[2019-08-09 08:38:36] [valid] Ep. 14 : Up. 740000 : translation : 20.5 : stalled 11 times (last best: 20.73)
[2019-08-09 08:43:24] Ep. 14 : Up. 742000 : Sen. 710,093 : Cost 51.76627350 : Time 403.16s : 10038.73 words/s
[2019-08-09 08:48:07] Ep. 14 : Up. 744000 : Sen. 930,854 : Cost 51.92944717 : Time 283.58s : 14166.94 words/s
[2019-08-09 08:52:52] Ep. 14 : Up. 746000 : Sen. 1,150,971 : Cost 51.87726593 : Time 284.79s : 14124.74 words/s
[2019-08-09 08:57:37] Ep. 14 : Up. 748000 : Sen. 1,373,048 : Cost 51.76274490 : Time 285.28s : 14147.27 words/s
[2019-08-09 09:02:23] Ep. 14 : Up. 750000 : Sen. 1,594,591 : Cost 52.25059509 : Time 285.63s : 14158.05 words/s
[2019-08-09 09:07:06] Ep. 14 : Up. 752000 : Sen. 1,815,751 : Cost 51.91906738 : Time 283.01s : 14186.78 words/s
[2019-08-09 09:11:52] Ep. 14 : Up. 754000 : Sen. 2,037,042 : Cost 52.41896439 : Time 285.56s : 14211.59 words/s
[2019-08-09 09:16:40] Ep. 14 : Up. 756000 : Sen. 2,259,817 : Cost 52.04033661 : Time 288.46s : 14057.08 words/s
[2019-08-09 09:21:24] Ep. 14 : Up. 758000 : Sen. 2,481,050 : Cost 52.10789490 : Time 284.36s : 14167.35 words/s
[2019-08-09 09:26:09] Ep. 14 : Up. 760000 : Sen. 2,702,580 : Cost 52.24569702 : Time 284.64s : 14165.37 words/s
[2019-08-09 09:26:09] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 09:26:19] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter760000.npz
[2019-08-09 09:26:26] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 09:26:36] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-09 09:27:03] [valid] Ep. 14 : Up. 760000 : cross-entropy : 49.515 : stalled 1 times (last best: 49.4887)
[2019-08-09 09:27:10] [valid] Ep. 14 : Up. 760000 : perplexity : 6.95032 : stalled 1 times (last best: 6.94316)
[2019-08-09 09:28:05] [valid] Ep. 14 : Up. 760000 : translation : 20.85 : new best
[2019-08-09 09:32:52] Ep. 14 : Up. 762000 : Sen. 2,923,277 : Cost 52.32169724 : Time 403.13s : 9993.29 words/s
[2019-08-09 09:37:36] Ep. 14 : Up. 764000 : Sen. 3,143,729 : Cost 52.27537918 : Time 284.05s : 14144.69 words/s
[2019-08-09 09:42:21] Ep. 14 : Up. 766000 : Sen. 3,365,619 : Cost 52.38893890 : Time 284.91s : 14185.51 words/s
[2019-08-09 09:47:06] Ep. 14 : Up. 768000 : Sen. 3,587,186 : Cost 52.05598450 : Time 284.87s : 14149.75 words/s
[2019-08-09 09:51:51] Ep. 14 : Up. 770000 : Sen. 3,808,390 : Cost 52.36914825 : Time 285.31s : 14143.86 words/s
[2019-08-09 09:56:38] Ep. 14 : Up. 772000 : Sen. 4,029,218 : Cost 52.43563461 : Time 286.93s : 14025.03 words/s
[2019-08-09 10:01:24] Ep. 14 : Up. 774000 : Sen. 4,250,398 : Cost 52.48819351 : Time 285.64s : 14110.50 words/s
[2019-08-09 10:06:10] Ep. 14 : Up. 776000 : Sen. 4,472,145 : Cost 52.45407867 : Time 286.07s : 14155.03 words/s
[2019-08-09 10:10:56] Ep. 14 : Up. 778000 : Sen. 4,692,235 : Cost 52.34270477 : Time 286.43s : 14001.09 words/s
[2019-08-09 10:15:41] Ep. 14 : Up. 780000 : Sen. 4,913,573 : Cost 52.28484344 : Time 284.70s : 14159.16 words/s
[2019-08-09 10:15:41] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 10:15:50] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter780000.npz
[2019-08-09 10:15:57] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 10:16:07] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-09 10:16:36] [valid] Ep. 14 : Up. 780000 : cross-entropy : 49.4729 : new best
[2019-08-09 10:16:42] [valid] Ep. 14 : Up. 780000 : perplexity : 6.93887 : new best
[2019-08-09 10:17:39] [valid] Ep. 14 : Up. 780000 : translation : 20.4 : stalled 1 times (last best: 20.85)
[2019-08-09 10:22:27] Ep. 14 : Up. 782000 : Sen. 5,135,236 : Cost 52.27730942 : Time 405.73s : 9921.98 words/s
[2019-08-09 10:27:12] Ep. 14 : Up. 784000 : Sen. 5,357,211 : Cost 52.49613571 : Time 285.42s : 14179.17 words/s
[2019-08-09 10:31:57] Ep. 14 : Up. 786000 : Sen. 5,578,337 : Cost 52.46138000 : Time 284.89s : 14131.74 words/s
[2019-08-09 10:36:42] Ep. 14 : Up. 788000 : Sen. 5,798,634 : Cost 52.79993057 : Time 284.91s : 14133.39 words/s
[2019-08-09 10:41:27] Ep. 14 : Up. 790000 : Sen. 6,021,211 : Cost 52.23828125 : Time 285.03s : 14177.60 words/s
[2019-08-09 10:46:13] Ep. 14 : Up. 792000 : Sen. 6,242,752 : Cost 52.84875107 : Time 285.57s : 14177.08 words/s
[2019-08-09 10:46:32] Seen 6258441 samples
[2019-08-09 10:46:32] Starting epoch 15
[2019-08-09 10:46:32] [data] Shuffling data
[2019-08-09 10:46:36] [data] Done reading 6886952 sentences
[2019-08-09 10:47:14] [data] Done shuffling 6886952 sentences to temp files
[2019-08-09 10:51:40] Ep. 15 : Up. 794000 : Sen. 205,495 : Cost 51.29566956 : Time 327.76s : 12250.64 words/s
[2019-08-09 10:56:25] Ep. 15 : Up. 796000 : Sen. 426,773 : Cost 51.30188751 : Time 284.25s : 14163.43 words/s
[2019-08-09 11:01:09] Ep. 15 : Up. 798000 : Sen. 647,380 : Cost 51.58933640 : Time 284.81s : 14133.84 words/s
[2019-08-09 11:05:55] Ep. 15 : Up. 800000 : Sen. 868,959 : Cost 51.84622574 : Time 285.48s : 14156.05 words/s
[2019-08-09 11:05:55] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 11:06:04] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter800000.npz
[2019-08-09 11:06:12] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 11:06:21] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-09 11:06:47] [valid] Ep. 15 : Up. 800000 : cross-entropy : 49.327 : new best
[2019-08-09 11:06:54] [valid] Ep. 15 : Up. 800000 : perplexity : 6.89933 : new best
[2019-08-09 11:07:49] [valid] Ep. 15 : Up. 800000 : translation : 20.32 : stalled 2 times (last best: 20.85)
[2019-08-09 11:12:37] Ep. 15 : Up. 802000 : Sen. 1,090,529 : Cost 51.95790482 : Time 401.68s : 10075.15 words/s
[2019-08-09 11:17:22] Ep. 15 : Up. 804000 : Sen. 1,312,408 : Cost 51.53225327 : Time 284.97s : 14156.91 words/s
[2019-08-09 11:22:07] Ep. 15 : Up. 806000 : Sen. 1,533,547 : Cost 51.80937195 : Time 285.30s : 14162.46 words/s
[2019-08-09 11:26:51] Ep. 15 : Up. 808000 : Sen. 1,755,069 : Cost 51.58567047 : Time 283.91s : 14200.01 words/s
[2019-08-09 11:31:35] Ep. 15 : Up. 810000 : Sen. 1,975,306 : Cost 52.12410355 : Time 284.30s : 14150.09 words/s
[2019-08-09 11:36:20] Ep. 15 : Up. 812000 : Sen. 2,196,928 : Cost 51.93423843 : Time 284.87s : 14163.34 words/s
[2019-08-09 11:41:05] Ep. 15 : Up. 814000 : Sen. 2,418,600 : Cost 51.82485199 : Time 284.64s : 14159.04 words/s
[2019-08-09 11:45:49] Ep. 15 : Up. 816000 : Sen. 2,640,155 : Cost 51.92652893 : Time 284.52s : 14172.29 words/s
[2019-08-09 11:50:38] Ep. 15 : Up. 818000 : Sen. 2,861,737 : Cost 52.27541351 : Time 289.21s : 14020.31 words/s
[2019-08-09 11:55:22] Ep. 15 : Up. 820000 : Sen. 3,082,355 : Cost 51.80988693 : Time 283.68s : 14140.06 words/s
[2019-08-09 11:55:22] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 11:55:32] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter820000.npz
[2019-08-09 11:55:42] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 11:55:54] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-09 11:56:20] [valid] Ep. 15 : Up. 820000 : cross-entropy : 49.385 : stalled 1 times (last best: 49.327)
[2019-08-09 11:56:27] [valid] Ep. 15 : Up. 820000 : perplexity : 6.91501 : stalled 1 times (last best: 6.89933)
[2019-08-09 11:57:21] [valid] Ep. 15 : Up. 820000 : translation : 20.5 : stalled 3 times (last best: 20.85)
[2019-08-09 12:02:08] Ep. 15 : Up. 822000 : Sen. 3,304,493 : Cost 52.28551483 : Time 406.44s : 9972.54 words/s
[2019-08-09 12:06:53] Ep. 15 : Up. 824000 : Sen. 3,525,442 : Cost 51.88917542 : Time 284.72s : 14141.84 words/s
[2019-08-09 12:11:38] Ep. 15 : Up. 826000 : Sen. 3,746,768 : Cost 52.07939529 : Time 284.89s : 14154.32 words/s
[2019-08-09 12:16:23] Ep. 15 : Up. 828000 : Sen. 3,969,181 : Cost 52.09799194 : Time 285.37s : 14180.26 words/s
[2019-08-09 12:21:08] Ep. 15 : Up. 830000 : Sen. 4,190,100 : Cost 52.18479919 : Time 284.48s : 14144.72 words/s
[2019-08-09 12:25:52] Ep. 15 : Up. 832000 : Sen. 4,411,820 : Cost 51.93036652 : Time 284.17s : 14183.30 words/s
[2019-08-09 12:30:36] Ep. 15 : Up. 834000 : Sen. 4,632,460 : Cost 52.25253677 : Time 284.40s : 14158.57 words/s
[2019-08-09 12:35:21] Ep. 15 : Up. 836000 : Sen. 4,853,835 : Cost 52.44233704 : Time 284.63s : 14162.21 words/s
[2019-08-09 12:40:06] Ep. 15 : Up. 838000 : Sen. 5,075,362 : Cost 52.36265182 : Time 284.56s : 14197.89 words/s
[2019-08-09 12:44:52] Ep. 15 : Up. 840000 : Sen. 5,295,584 : Cost 52.30123520 : Time 286.78s : 14009.32 words/s
[2019-08-09 12:44:52] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 12:45:02] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter840000.npz
[2019-08-09 12:45:09] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 12:45:19] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-09 12:45:46] [valid] Ep. 15 : Up. 840000 : cross-entropy : 49.2796 : new best
[2019-08-09 12:45:52] [valid] Ep. 15 : Up. 840000 : perplexity : 6.88653 : new best
[2019-08-09 12:46:48] [valid] Ep. 15 : Up. 840000 : translation : 20.73 : stalled 4 times (last best: 20.85)
[2019-08-09 12:51:35] Ep. 15 : Up. 842000 : Sen. 5,516,962 : Cost 52.39732361 : Time 402.42s : 10031.93 words/s
[2019-08-09 12:56:21] Ep. 15 : Up. 844000 : Sen. 5,737,180 : Cost 52.49388504 : Time 286.48s : 14041.25 words/s
[2019-08-09 13:01:05] Ep. 15 : Up. 846000 : Sen. 5,959,176 : Cost 52.16213989 : Time 283.85s : 14185.09 words/s
[2019-08-09 13:05:51] Ep. 15 : Up. 848000 : Sen. 6,180,630 : Cost 52.44813538 : Time 285.36s : 14149.75 words/s
[2019-08-09 13:07:31] Seen 6258441 samples
[2019-08-09 13:07:31] Starting epoch 16
[2019-08-09 13:07:31] [data] Shuffling data
[2019-08-09 13:07:35] [data] Done reading 6886952 sentences
[2019-08-09 13:08:07] [data] Done shuffling 6886952 sentences to temp files
[2019-08-09 13:11:12] Ep. 16 : Up. 850000 : Sen. 142,896 : Cost 51.62337875 : Time 321.78s : 12517.97 words/s
[2019-08-09 13:15:58] Ep. 16 : Up. 852000 : Sen. 364,587 : Cost 51.19886780 : Time 285.29s : 14150.75 words/s
[2019-08-09 13:20:43] Ep. 16 : Up. 854000 : Sen. 585,544 : Cost 51.55702209 : Time 285.55s : 14127.07 words/s
[2019-08-09 13:25:28] Ep. 16 : Up. 856000 : Sen. 806,400 : Cost 51.42411804 : Time 284.67s : 14135.98 words/s
[2019-08-09 13:30:12] Ep. 16 : Up. 858000 : Sen. 1,027,417 : Cost 51.34509659 : Time 284.13s : 14174.90 words/s
[2019-08-09 13:34:57] Ep. 16 : Up. 860000 : Sen. 1,248,792 : Cost 51.69391632 : Time 285.37s : 14158.19 words/s
[2019-08-09 13:34:57] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 13:35:07] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter860000.npz
[2019-08-09 13:35:14] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 13:35:24] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-09 13:35:51] [valid] Ep. 16 : Up. 860000 : cross-entropy : 49.3412 : stalled 1 times (last best: 49.2796)
[2019-08-09 13:35:57] [valid] Ep. 16 : Up. 860000 : perplexity : 6.90318 : stalled 1 times (last best: 6.88653)
[2019-08-09 13:36:52] [valid] Ep. 16 : Up. 860000 : translation : 21.13 : new best
[2019-08-09 13:41:39] Ep. 16 : Up. 862000 : Sen. 1,470,488 : Cost 51.31492233 : Time 401.20s : 10034.15 words/s
[2019-08-09 13:46:25] Ep. 16 : Up. 864000 : Sen. 1,691,883 : Cost 51.53860474 : Time 286.34s : 14066.04 words/s
[2019-08-09 13:51:10] Ep. 16 : Up. 866000 : Sen. 1,913,025 : Cost 51.64859390 : Time 285.30s : 14137.45 words/s
[2019-08-09 13:55:54] Ep. 16 : Up. 868000 : Sen. 2,134,298 : Cost 51.60058975 : Time 284.04s : 14150.87 words/s
[2019-08-09 14:00:40] Ep. 16 : Up. 870000 : Sen. 2,355,001 : Cost 51.81168747 : Time 285.46s : 14101.08 words/s
[2019-08-09 14:05:25] Ep. 16 : Up. 872000 : Sen. 2,575,558 : Cost 51.57024384 : Time 285.50s : 14055.82 words/s
[2019-08-09 14:10:12] Ep. 16 : Up. 874000 : Sen. 2,796,878 : Cost 51.93472672 : Time 286.22s : 14087.74 words/s
[2019-08-09 14:14:58] Ep. 16 : Up. 876000 : Sen. 3,018,033 : Cost 51.73838425 : Time 286.65s : 14061.38 words/s
[2019-08-09 14:19:45] Ep. 16 : Up. 878000 : Sen. 3,238,874 : Cost 51.97732925 : Time 286.72s : 14032.94 words/s
[2019-08-09 14:24:32] Ep. 16 : Up. 880000 : Sen. 3,459,770 : Cost 51.83048248 : Time 286.84s : 14025.90 words/s
[2019-08-09 14:24:32] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 14:24:41] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter880000.npz
[2019-08-09 14:24:49] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 14:24:58] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-09 14:25:25] [valid] Ep. 16 : Up. 880000 : cross-entropy : 49.3632 : stalled 2 times (last best: 49.2796)
[2019-08-09 14:25:31] [valid] Ep. 16 : Up. 880000 : perplexity : 6.90912 : stalled 2 times (last best: 6.88653)
[2019-08-09 14:26:29] [valid] Ep. 16 : Up. 880000 : translation : 20.59 : stalled 1 times (last best: 21.13)
[2019-08-09 14:31:19] Ep. 16 : Up. 882000 : Sen. 3,681,340 : Cost 52.02109146 : Time 407.35s : 9915.55 words/s
[2019-08-09 14:36:08] Ep. 16 : Up. 884000 : Sen. 3,902,988 : Cost 52.29384995 : Time 288.85s : 14027.24 words/s
[2019-08-09 14:40:55] Ep. 16 : Up. 886000 : Sen. 4,123,915 : Cost 51.81745911 : Time 287.57s : 13965.14 words/s
[2019-08-09 14:45:44] Ep. 16 : Up. 888000 : Sen. 4,345,192 : Cost 51.93776703 : Time 288.58s : 13967.46 words/s
[2019-08-09 14:50:32] Ep. 16 : Up. 890000 : Sen. 4,566,223 : Cost 51.89265823 : Time 288.18s : 13956.91 words/s
[2019-08-09 14:55:20] Ep. 16 : Up. 892000 : Sen. 4,787,639 : Cost 52.11716080 : Time 287.73s : 14050.91 words/s
[2019-08-09 15:00:07] Ep. 16 : Up. 894000 : Sen. 5,009,598 : Cost 51.94371796 : Time 287.20s : 14046.87 words/s
[2019-08-09 15:04:55] Ep. 16 : Up. 896000 : Sen. 5,230,525 : Cost 52.30977249 : Time 288.10s : 14017.78 words/s
[2019-08-09 15:09:42] Ep. 16 : Up. 898000 : Sen. 5,451,066 : Cost 52.02071762 : Time 286.50s : 14017.42 words/s
[2019-08-09 15:14:29] Ep. 16 : Up. 900000 : Sen. 5,672,232 : Cost 51.90367126 : Time 287.07s : 14019.35 words/s
[2019-08-09 15:14:29] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 15:14:38] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter900000.npz
[2019-08-09 15:14:46] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 15:14:55] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-09 15:15:22] [valid] Ep. 16 : Up. 900000 : cross-entropy : 49.2161 : new best
[2019-08-09 15:15:28] [valid] Ep. 16 : Up. 900000 : perplexity : 6.86943 : new best
[2019-08-09 15:16:26] [valid] Ep. 16 : Up. 900000 : translation : 20.83 : stalled 2 times (last best: 21.13)
[2019-08-09 15:21:16] Ep. 16 : Up. 902000 : Sen. 5,893,033 : Cost 52.13201141 : Time 407.00s : 9921.86 words/s
[2019-08-09 15:26:03] Ep. 16 : Up. 904000 : Sen. 6,114,650 : Cost 52.07685852 : Time 287.45s : 14032.57 words/s
[2019-08-09 15:29:10] Seen 6258441 samples
[2019-08-09 15:29:10] Starting epoch 17
[2019-08-09 15:29:10] [data] Shuffling data
[2019-08-09 15:29:13] [data] Done reading 6886952 sentences
[2019-08-09 15:29:36] [data] Done shuffling 6886952 sentences to temp files
[2019-08-09 15:31:33] Ep. 17 : Up. 906000 : Sen. 77,075 : Cost 51.67111206 : Time 329.24s : 12223.93 words/s
[2019-08-09 15:36:18] Ep. 17 : Up. 908000 : Sen. 298,594 : Cost 51.08541107 : Time 285.81s : 14108.14 words/s
[2019-08-09 15:41:04] Ep. 17 : Up. 910000 : Sen. 520,030 : Cost 51.10430908 : Time 285.24s : 14129.17 words/s
[2019-08-09 15:45:49] Ep. 17 : Up. 912000 : Sen. 741,084 : Cost 51.31739426 : Time 285.44s : 14109.74 words/s
[2019-08-09 15:50:34] Ep. 17 : Up. 914000 : Sen. 962,136 : Cost 51.23040390 : Time 285.08s : 14131.48 words/s
[2019-08-09 15:55:18] Ep. 17 : Up. 916000 : Sen. 1,183,718 : Cost 51.22286987 : Time 284.14s : 14195.79 words/s
[2019-08-09 16:00:01] Ep. 17 : Up. 918000 : Sen. 1,403,002 : Cost 51.70294952 : Time 283.00s : 14173.50 words/s
[2019-08-09 16:04:49] Ep. 17 : Up. 920000 : Sen. 1,624,642 : Cost 51.17536545 : Time 287.28s : 14030.01 words/s
[2019-08-09 16:04:49] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 16:05:06] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter920000.npz
[2019-08-09 16:05:13] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 16:05:24] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-09 16:05:51] [valid] Ep. 17 : Up. 920000 : cross-entropy : 49.2519 : stalled 1 times (last best: 49.2161)
[2019-08-09 16:05:58] [valid] Ep. 17 : Up. 920000 : perplexity : 6.87908 : stalled 1 times (last best: 6.86943)
[2019-08-09 16:06:52] [valid] Ep. 17 : Up. 920000 : translation : 20.69 : stalled 3 times (last best: 21.13)
[2019-08-09 16:11:39] Ep. 17 : Up. 922000 : Sen. 1,845,537 : Cost 51.43088913 : Time 409.96s : 9826.56 words/s
[2019-08-09 16:16:23] Ep. 17 : Up. 924000 : Sen. 2,067,434 : Cost 51.52107239 : Time 284.69s : 14192.22 words/s
[2019-08-09 16:21:07] Ep. 17 : Up. 926000 : Sen. 2,288,918 : Cost 51.33057404 : Time 283.88s : 14210.12 words/s
[2019-08-09 16:25:50] Ep. 17 : Up. 928000 : Sen. 2,509,202 : Cost 51.34311295 : Time 282.52s : 14200.37 words/s
[2019-08-09 16:30:33] Ep. 17 : Up. 930000 : Sen. 2,730,430 : Cost 51.59115982 : Time 283.77s : 14233.88 words/s
[2019-08-09 16:35:18] Ep. 17 : Up. 932000 : Sen. 2,952,053 : Cost 51.46506500 : Time 284.39s : 14190.87 words/s
[2019-08-09 16:40:02] Ep. 17 : Up. 934000 : Sen. 3,174,064 : Cost 51.63884354 : Time 284.43s : 14208.27 words/s
[2019-08-09 16:44:46] Ep. 17 : Up. 936000 : Sen. 3,394,710 : Cost 51.78652191 : Time 283.89s : 14167.02 words/s
[2019-08-09 16:49:31] Ep. 17 : Up. 938000 : Sen. 3,616,620 : Cost 51.79024887 : Time 284.70s : 14218.29 words/s
[2019-08-09 16:54:15] Ep. 17 : Up. 940000 : Sen. 3,837,761 : Cost 51.72422028 : Time 284.02s : 14186.24 words/s
[2019-08-09 16:54:15] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 16:54:24] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter940000.npz
[2019-08-09 16:54:31] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 16:54:41] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-09 16:55:08] [valid] Ep. 17 : Up. 940000 : cross-entropy : 49.1828 : new best
[2019-08-09 16:55:14] [valid] Ep. 17 : Up. 940000 : perplexity : 6.8605 : new best
[2019-08-09 16:56:08] [valid] Ep. 17 : Up. 940000 : translation : 20.58 : stalled 4 times (last best: 21.13)
[2019-08-09 17:00:55] Ep. 17 : Up. 942000 : Sen. 4,058,297 : Cost 51.72714233 : Time 400.23s : 10051.90 words/s
[2019-08-09 17:05:40] Ep. 17 : Up. 944000 : Sen. 4,279,614 : Cost 51.80547714 : Time 284.59s : 14193.06 words/s
[2019-08-09 17:10:24] Ep. 17 : Up. 946000 : Sen. 4,501,175 : Cost 51.73492813 : Time 284.74s : 14193.92 words/s
[2019-08-09 17:15:09] Ep. 17 : Up. 948000 : Sen. 4,721,563 : Cost 51.84232330 : Time 284.73s : 14138.24 words/s
[2019-08-09 17:19:54] Ep. 17 : Up. 950000 : Sen. 4,944,402 : Cost 51.63510895 : Time 284.44s : 14231.25 words/s
[2019-08-09 17:24:39] Ep. 17 : Up. 952000 : Sen. 5,165,639 : Cost 51.97609711 : Time 285.24s : 14162.90 words/s
[2019-08-09 17:29:22] Ep. 17 : Up. 954000 : Sen. 5,385,688 : Cost 51.60220337 : Time 283.02s : 14135.54 words/s
[2019-08-09 17:34:06] Ep. 17 : Up. 956000 : Sen. 5,607,724 : Cost 51.82619095 : Time 284.62s : 14209.48 words/s
[2019-08-09 17:38:51] Ep. 17 : Up. 958000 : Sen. 5,829,544 : Cost 52.09489059 : Time 284.18s : 14227.74 words/s
[2019-08-09 17:43:37] Ep. 17 : Up. 960000 : Sen. 6,050,974 : Cost 51.97137833 : Time 286.47s : 14064.04 words/s
[2019-08-09 17:43:37] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 17:43:46] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter960000.npz
[2019-08-09 17:43:53] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 17:44:04] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-09 17:44:31] [valid] Ep. 17 : Up. 960000 : cross-entropy : 49.0858 : new best
[2019-08-09 17:44:37] [valid] Ep. 17 : Up. 960000 : perplexity : 6.83449 : new best
[2019-08-09 17:45:32] [valid] Ep. 17 : Up. 960000 : translation : 20.74 : stalled 5 times (last best: 21.13)
[2019-08-09 17:50:00] Seen 6258441 samples
[2019-08-09 17:50:00] Starting epoch 18
[2019-08-09 17:50:00] [data] Shuffling data
[2019-08-09 17:50:04] [data] Done reading 6886952 sentences
[2019-08-09 17:50:30] [data] Done shuffling 6886952 sentences to temp files
[2019-08-09 17:50:57] Ep. 18 : Up. 962000 : Sen. 13,250 : Cost 51.81150818 : Time 439.52s : 9159.11 words/s
[2019-08-09 17:55:40] Ep. 18 : Up. 964000 : Sen. 234,526 : Cost 50.81640244 : Time 283.70s : 14199.99 words/s
[2019-08-09 18:00:24] Ep. 18 : Up. 966000 : Sen. 455,781 : Cost 50.58238983 : Time 283.83s : 14180.89 words/s
[2019-08-09 18:05:08] Ep. 18 : Up. 968000 : Sen. 677,289 : Cost 51.06699371 : Time 284.08s : 14188.00 words/s
[2019-08-09 18:09:53] Ep. 18 : Up. 970000 : Sen. 898,436 : Cost 51.06023026 : Time 284.24s : 14167.56 words/s
[2019-08-09 18:14:37] Ep. 18 : Up. 972000 : Sen. 1,119,607 : Cost 51.17938995 : Time 284.65s : 14180.85 words/s
[2019-08-09 18:19:22] Ep. 18 : Up. 974000 : Sen. 1,341,219 : Cost 51.27460480 : Time 284.65s : 14185.52 words/s
[2019-08-09 18:24:06] Ep. 18 : Up. 976000 : Sen. 1,561,522 : Cost 51.40079498 : Time 283.87s : 14149.13 words/s
[2019-08-09 18:28:50] Ep. 18 : Up. 978000 : Sen. 1,782,622 : Cost 51.28701019 : Time 284.66s : 14179.64 words/s
[2019-08-09 18:33:34] Ep. 18 : Up. 980000 : Sen. 2,003,590 : Cost 51.35162735 : Time 283.92s : 14173.75 words/s
[2019-08-09 18:33:34] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 18:33:44] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter980000.npz
[2019-08-09 18:33:51] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 18:34:00] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-09 18:34:27] [valid] Ep. 18 : Up. 980000 : cross-entropy : 49.1864 : stalled 1 times (last best: 49.0858)
[2019-08-09 18:34:33] [valid] Ep. 18 : Up. 980000 : perplexity : 6.86147 : stalled 1 times (last best: 6.83449)
[2019-08-09 18:35:27] [valid] Ep. 18 : Up. 980000 : translation : 21.03 : stalled 6 times (last best: 21.13)
[2019-08-09 18:40:15] Ep. 18 : Up. 982000 : Sen. 2,223,824 : Cost 51.17072296 : Time 400.80s : 9992.06 words/s
[2019-08-09 18:44:59] Ep. 18 : Up. 984000 : Sen. 2,445,207 : Cost 51.44655991 : Time 284.24s : 14191.33 words/s
[2019-08-09 18:49:44] Ep. 18 : Up. 986000 : Sen. 2,666,742 : Cost 51.59474182 : Time 284.15s : 14217.62 words/s
[2019-08-09 18:54:27] Ep. 18 : Up. 988000 : Sen. 2,887,833 : Cost 51.44440079 : Time 283.87s : 14196.65 words/s
[2019-08-09 18:59:12] Ep. 18 : Up. 990000 : Sen. 3,108,992 : Cost 51.49694061 : Time 284.98s : 14181.48 words/s
[2019-08-09 19:03:56] Ep. 18 : Up. 992000 : Sen. 3,330,533 : Cost 51.44834137 : Time 283.66s : 14208.12 words/s
[2019-08-09 19:08:41] Ep. 18 : Up. 994000 : Sen. 3,552,329 : Cost 51.60587692 : Time 284.86s : 14183.19 words/s
[2019-08-09 19:13:26] Ep. 18 : Up. 996000 : Sen. 3,773,727 : Cost 51.62516785 : Time 284.97s : 14168.56 words/s
[2019-08-09 19:18:10] Ep. 18 : Up. 998000 : Sen. 3,994,276 : Cost 51.87899017 : Time 283.97s : 14183.85 words/s
[2019-08-09 19:22:53] Ep. 18 : Up. 1000000 : Sen. 4,214,960 : Cost 51.36080551 : Time 282.98s : 14172.36 words/s
[2019-08-09 19:22:53] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 19:23:04] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter1000000.npz
[2019-08-09 19:23:11] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 19:23:21] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-09 19:23:47] [valid] Ep. 18 : Up. 1000000 : cross-entropy : 49.2367 : stalled 2 times (last best: 49.0858)
[2019-08-09 19:23:53] [valid] Ep. 18 : Up. 1000000 : perplexity : 6.87498 : stalled 2 times (last best: 6.83449)
[2019-08-09 19:24:46] [valid] Ep. 18 : Up. 1000000 : translation : 20.92 : stalled 7 times (last best: 21.13)
[2019-08-09 19:29:32] Ep. 18 : Up. 1002000 : Sen. 4,435,811 : Cost 51.64836121 : Time 398.78s : 10090.59 words/s
[2019-08-09 19:34:16] Ep. 18 : Up. 1004000 : Sen. 4,657,059 : Cost 51.68927765 : Time 283.91s : 14194.97 words/s
[2019-08-09 19:39:00] Ep. 18 : Up. 1006000 : Sen. 4,878,074 : Cost 51.88218307 : Time 284.12s : 14201.97 words/s
[2019-08-09 19:43:44] Ep. 18 : Up. 1008000 : Sen. 5,099,763 : Cost 51.75144577 : Time 284.57s : 14191.48 words/s
[2019-08-09 19:48:28] Ep. 18 : Up. 1010000 : Sen. 5,319,838 : Cost 51.85750580 : Time 283.96s : 14156.59 words/s
[2019-08-09 19:53:12] Ep. 18 : Up. 1012000 : Sen. 5,541,982 : Cost 51.62335587 : Time 284.02s : 14214.17 words/s
[2019-08-09 19:57:56] Ep. 18 : Up. 1014000 : Sen. 5,764,062 : Cost 51.73680115 : Time 283.93s : 14231.92 words/s
[2019-08-09 20:02:40] Ep. 18 : Up. 1016000 : Sen. 5,985,670 : Cost 51.67672729 : Time 284.22s : 14188.73 words/s
[2019-08-09 20:07:25] Ep. 18 : Up. 1018000 : Sen. 6,206,760 : Cost 51.65111542 : Time 284.41s : 14170.80 words/s
[2019-08-09 20:08:32] Seen 6258441 samples
[2019-08-09 20:08:32] Starting epoch 19
[2019-08-09 20:08:32] [data] Shuffling data
[2019-08-09 20:08:35] [data] Done reading 6886952 sentences
[2019-08-09 20:09:08] [data] Done shuffling 6886952 sentences to temp files
[2019-08-09 20:12:46] Ep. 19 : Up. 1020000 : Sen. 169,145 : Cost 50.90872955 : Time 320.82s : 12552.33 words/s
[2019-08-09 20:12:46] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 20:12:55] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter1020000.npz
[2019-08-09 20:13:03] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 20:13:12] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-09 20:13:39] [valid] Ep. 19 : Up. 1020000 : cross-entropy : 49.1832 : stalled 3 times (last best: 49.0858)
[2019-08-09 20:13:46] [valid] Ep. 19 : Up. 1020000 : perplexity : 6.8606 : stalled 3 times (last best: 6.83449)
[2019-08-09 20:14:40] [valid] Ep. 19 : Up. 1020000 : translation : 20.89 : stalled 8 times (last best: 21.13)
[2019-08-09 20:19:28] Ep. 19 : Up. 1022000 : Sen. 390,039 : Cost 50.92361832 : Time 402.29s : 10018.71 words/s
[2019-08-09 20:24:12] Ep. 19 : Up. 1024000 : Sen. 611,684 : Cost 50.75898361 : Time 284.09s : 14213.72 words/s
[2019-08-09 20:28:56] Ep. 19 : Up. 1026000 : Sen. 832,000 : Cost 51.28877258 : Time 283.47s : 14217.83 words/s
[2019-08-09 20:33:40] Ep. 19 : Up. 1028000 : Sen. 1,052,265 : Cost 51.18152618 : Time 284.13s : 14150.10 words/s
[2019-08-09 20:38:26] Ep. 19 : Up. 1030000 : Sen. 1,273,702 : Cost 51.03236008 : Time 286.31s : 14072.57 words/s
[2019-08-09 20:43:10] Ep. 19 : Up. 1032000 : Sen. 1,496,021 : Cost 50.82302475 : Time 283.70s : 14229.99 words/s
[2019-08-09 20:47:55] Ep. 19 : Up. 1034000 : Sen. 1,716,894 : Cost 51.61314392 : Time 284.94s : 14165.60 words/s
[2019-08-09 20:52:39] Ep. 19 : Up. 1036000 : Sen. 1,938,602 : Cost 51.17420197 : Time 284.20s : 14188.41 words/s
[2019-08-09 20:57:22] Ep. 19 : Up. 1038000 : Sen. 2,158,826 : Cost 51.23569107 : Time 283.08s : 14192.39 words/s
[2019-08-09 21:02:07] Ep. 19 : Up. 1040000 : Sen. 2,381,148 : Cost 51.24193573 : Time 284.76s : 14221.98 words/s
[2019-08-09 21:02:07] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 21:02:17] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter1040000.npz
[2019-08-09 21:02:24] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 21:02:40] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-09 21:03:13] [valid] Ep. 19 : Up. 1040000 : cross-entropy : 49.3585 : stalled 4 times (last best: 49.0858)
[2019-08-09 21:03:20] [valid] Ep. 19 : Up. 1040000 : perplexity : 6.90786 : stalled 4 times (last best: 6.83449)
[2019-08-09 21:04:13] [valid] Ep. 19 : Up. 1040000 : translation : 21.2 : new best
[2019-08-09 21:08:59] Ep. 19 : Up. 1042000 : Sen. 2,602,934 : Cost 51.29610443 : Time 412.40s : 9791.51 words/s
[2019-08-09 21:13:44] Ep. 19 : Up. 1044000 : Sen. 2,824,796 : Cost 51.30475998 : Time 285.07s : 14193.91 words/s
[2019-08-09 21:18:29] Ep. 19 : Up. 1046000 : Sen. 3,046,322 : Cost 51.31534576 : Time 284.36s : 14204.43 words/s
[2019-08-09 21:23:13] Ep. 19 : Up. 1048000 : Sen. 3,267,476 : Cost 51.33521271 : Time 283.87s : 14207.29 words/s
[2019-08-09 21:27:56] Ep. 19 : Up. 1050000 : Sen. 3,488,864 : Cost 51.14344406 : Time 283.28s : 14184.00 words/s
[2019-08-09 21:32:39] Ep. 19 : Up. 1052000 : Sen. 3,709,171 : Cost 51.35095978 : Time 283.00s : 14193.88 words/s
[2019-08-09 21:37:26] Ep. 19 : Up. 1054000 : Sen. 3,930,742 : Cost 51.14712524 : Time 287.26s : 13996.94 words/s
[2019-08-09 21:42:13] Ep. 19 : Up. 1056000 : Sen. 4,152,513 : Cost 51.59651184 : Time 287.17s : 14106.28 words/s
[2019-08-09 21:46:57] Ep. 19 : Up. 1058000 : Sen. 4,372,706 : Cost 51.54037476 : Time 283.23s : 14189.47 words/s
[2019-08-09 21:51:40] Ep. 19 : Up. 1060000 : Sen. 4,594,347 : Cost 51.48078156 : Time 283.64s : 14222.98 words/s
[2019-08-09 21:51:40] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 21:51:50] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.iter1060000.npz
[2019-08-09 21:51:57] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 21:52:07] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
[2019-08-09 21:52:33] [valid] Ep. 19 : Up. 1060000 : cross-entropy : 49.338 : stalled 5 times (last best: 49.0858)
[2019-08-09 21:52:40] [valid] Ep. 19 : Up. 1060000 : perplexity : 6.9023 : stalled 5 times (last best: 6.83449)
[2019-08-09 21:53:33] [valid] Ep. 19 : Up. 1060000 : translation : 20.92 : stalled 1 times (last best: 21.2)
[2019-08-09 21:53:35] Training finished
[2019-08-09 21:53:39] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz.orig.npz
[2019-08-09 21:53:49] Saving model to ../experiments/100M_random_hardrules_v1.0/model/model.npz
[2019-08-09 21:53:59] Saving Adam parameters to ../experiments/100M_random_hardrules_v1.0/model/model.npz.optimizer.npz
