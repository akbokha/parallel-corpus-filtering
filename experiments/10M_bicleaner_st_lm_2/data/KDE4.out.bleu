MT evaluation scorer began on 2019 Jul 26 at 22:38:37
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/10M_bicleaner_st_lm_2/data/KDE4.de.sgm -r ../experiments/10M_bicleaner_st_lm_2/data/KDE4.en.sgm -t ../experiments/10M_bicleaner_st_lm_2/data/KDE4.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 3000 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 0.901399416453508 (115234/127839), penalty (log): -0.109386118680251
NIST score = 5.8942  BLEU score = 0.1830 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.3967   1.1768   0.2566   0.0536   0.0105   0.0032   0.0014   0.0011   0.0005  "Edinburgh"

 BLEU:  0.5634   0.2617   0.1434   0.0821   0.0485   0.0300   0.0195   0.0134   0.0095  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.3967   5.5734   5.8301   5.8836   5.8942   5.8973   5.8987   5.8998   5.9002  "Edinburgh"

 BLEU:  0.5051   0.3442   0.2479   0.1830   0.1373   0.1046   0.0810   0.0638   0.0510  "Edinburgh"
MT evaluation scorer ended on 2019 Jul 26 at 22:39:09
