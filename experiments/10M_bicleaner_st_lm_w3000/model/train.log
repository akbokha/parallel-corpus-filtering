[2019-07-25 12:41:27] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-25 12:41:27] [marian] Running on rindr as process 12586 with command line:
[2019-07-25 12:41:27] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz -T . --devices 2 3 --train-sets ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.de ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.en --vocabs ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.de.json ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/10M_bicleaner_st_lm_w3000/data/dev.bpe.de ../experiments/10M_bicleaner_st_lm_w3000/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/10M_bicleaner_st_lm_w3000/model/dev.out --valid-script-path ../experiments/10M_bicleaner_st_lm_w3000/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/10M_bicleaner_st_lm_w3000/model/train.log --valid-log ../experiments/10M_bicleaner_st_lm_w3000/model/valid.log
[2019-07-25 12:41:27] [config] after-batches: 0
[2019-07-25 12:41:27] [config] after-epochs: 0
[2019-07-25 12:41:27] [config] allow-unk: false
[2019-07-25 12:41:27] [config] beam-size: 12
[2019-07-25 12:41:27] [config] bert-class-symbol: "[CLS]"
[2019-07-25 12:41:27] [config] bert-mask-symbol: "[MASK]"
[2019-07-25 12:41:27] [config] bert-masking-fraction: 0.15
[2019-07-25 12:41:27] [config] bert-sep-symbol: "[SEP]"
[2019-07-25 12:41:27] [config] bert-train-type-embeddings: true
[2019-07-25 12:41:27] [config] bert-type-vocab-size: 2
[2019-07-25 12:41:27] [config] best-deep: false
[2019-07-25 12:41:27] [config] clip-gemm: 0
[2019-07-25 12:41:27] [config] clip-norm: 1
[2019-07-25 12:41:27] [config] cost-type: ce-mean
[2019-07-25 12:41:27] [config] cpu-threads: 0
[2019-07-25 12:41:27] [config] data-weighting: ""
[2019-07-25 12:41:27] [config] data-weighting-type: sentence
[2019-07-25 12:41:27] [config] dec-cell: gru
[2019-07-25 12:41:27] [config] dec-cell-base-depth: 2
[2019-07-25 12:41:27] [config] dec-cell-high-depth: 1
[2019-07-25 12:41:27] [config] dec-depth: 1
[2019-07-25 12:41:27] [config] devices:
[2019-07-25 12:41:27] [config]   - 2
[2019-07-25 12:41:27] [config]   - 3
[2019-07-25 12:41:27] [config] dim-emb: 512
[2019-07-25 12:41:27] [config] dim-rnn: 1024
[2019-07-25 12:41:27] [config] dim-vocabs:
[2019-07-25 12:41:27] [config]   - 50000
[2019-07-25 12:41:27] [config]   - 50000
[2019-07-25 12:41:27] [config] disp-first: 0
[2019-07-25 12:41:27] [config] disp-freq: 2000
[2019-07-25 12:41:27] [config] disp-label-counts: false
[2019-07-25 12:41:27] [config] dropout-rnn: 0.2
[2019-07-25 12:41:27] [config] dropout-src: 0.1
[2019-07-25 12:41:27] [config] dropout-trg: 0.1
[2019-07-25 12:41:27] [config] dump-config: ""
[2019-07-25 12:41:27] [config] early-stopping: 5
[2019-07-25 12:41:27] [config] embedding-fix-src: false
[2019-07-25 12:41:27] [config] embedding-fix-trg: false
[2019-07-25 12:41:27] [config] embedding-normalization: false
[2019-07-25 12:41:27] [config] embedding-vectors:
[2019-07-25 12:41:27] [config]   []
[2019-07-25 12:41:27] [config] enc-cell: gru
[2019-07-25 12:41:27] [config] enc-cell-depth: 1
[2019-07-25 12:41:27] [config] enc-depth: 1
[2019-07-25 12:41:27] [config] enc-type: bidirectional
[2019-07-25 12:41:27] [config] exponential-smoothing: 0.0001
[2019-07-25 12:41:27] [config] grad-dropping-momentum: 0
[2019-07-25 12:41:27] [config] grad-dropping-rate: 0
[2019-07-25 12:41:27] [config] grad-dropping-warmup: 100
[2019-07-25 12:41:27] [config] guided-alignment: none
[2019-07-25 12:41:27] [config] guided-alignment-cost: mse
[2019-07-25 12:41:27] [config] guided-alignment-weight: 0.1
[2019-07-25 12:41:27] [config] ignore-model-config: false
[2019-07-25 12:41:27] [config] input-types:
[2019-07-25 12:41:27] [config]   []
[2019-07-25 12:41:27] [config] interpolate-env-vars: false
[2019-07-25 12:41:27] [config] keep-best: false
[2019-07-25 12:41:27] [config] label-smoothing: 0
[2019-07-25 12:41:27] [config] layer-normalization: true
[2019-07-25 12:41:27] [config] learn-rate: 0.0001
[2019-07-25 12:41:27] [config] log: ../experiments/10M_bicleaner_st_lm_w3000/model/train.log
[2019-07-25 12:41:27] [config] log-level: info
[2019-07-25 12:41:27] [config] log-time-zone: ""
[2019-07-25 12:41:27] [config] lr-decay: 0
[2019-07-25 12:41:27] [config] lr-decay-freq: 50000
[2019-07-25 12:41:27] [config] lr-decay-inv-sqrt:
[2019-07-25 12:41:27] [config]   - 0
[2019-07-25 12:41:27] [config] lr-decay-repeat-warmup: false
[2019-07-25 12:41:27] [config] lr-decay-reset-optimizer: false
[2019-07-25 12:41:27] [config] lr-decay-start:
[2019-07-25 12:41:27] [config]   - 10
[2019-07-25 12:41:27] [config]   - 1
[2019-07-25 12:41:27] [config] lr-decay-strategy: epoch+stalled
[2019-07-25 12:41:27] [config] lr-report: false
[2019-07-25 12:41:27] [config] lr-warmup: 0
[2019-07-25 12:41:27] [config] lr-warmup-at-reload: false
[2019-07-25 12:41:27] [config] lr-warmup-cycle: false
[2019-07-25 12:41:27] [config] lr-warmup-start-rate: 0
[2019-07-25 12:41:27] [config] max-length: 50
[2019-07-25 12:41:27] [config] max-length-crop: false
[2019-07-25 12:41:27] [config] max-length-factor: 3
[2019-07-25 12:41:27] [config] maxi-batch: 100
[2019-07-25 12:41:27] [config] maxi-batch-sort: trg
[2019-07-25 12:41:27] [config] mini-batch: 64
[2019-07-25 12:41:27] [config] mini-batch-fit: true
[2019-07-25 12:41:27] [config] mini-batch-fit-step: 10
[2019-07-25 12:41:27] [config] mini-batch-overstuff: 1
[2019-07-25 12:41:27] [config] mini-batch-track-lr: false
[2019-07-25 12:41:27] [config] mini-batch-understuff: 1
[2019-07-25 12:41:27] [config] mini-batch-warmup: 0
[2019-07-25 12:41:27] [config] mini-batch-words: 0
[2019-07-25 12:41:27] [config] mini-batch-words-ref: 0
[2019-07-25 12:41:27] [config] model: ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-25 12:41:27] [config] multi-loss-type: sum
[2019-07-25 12:41:27] [config] multi-node: false
[2019-07-25 12:41:27] [config] multi-node-overlap: true
[2019-07-25 12:41:27] [config] n-best: false
[2019-07-25 12:41:27] [config] no-nccl: false
[2019-07-25 12:41:27] [config] no-reload: false
[2019-07-25 12:41:27] [config] no-restore-corpus: false
[2019-07-25 12:41:27] [config] no-shuffle: false
[2019-07-25 12:41:27] [config] normalize: 1
[2019-07-25 12:41:27] [config] num-devices: 0
[2019-07-25 12:41:27] [config] optimizer: adam
[2019-07-25 12:41:27] [config] optimizer-delay: 1
[2019-07-25 12:41:27] [config] optimizer-params:
[2019-07-25 12:41:27] [config]   []
[2019-07-25 12:41:27] [config] overwrite: false
[2019-07-25 12:41:27] [config] pretrained-model: ""
[2019-07-25 12:41:27] [config] quiet: false
[2019-07-25 12:41:27] [config] quiet-translation: true
[2019-07-25 12:41:27] [config] relative-paths: false
[2019-07-25 12:41:27] [config] right-left: false
[2019-07-25 12:41:27] [config] save-freq: 20000
[2019-07-25 12:41:27] [config] seed: 1111
[2019-07-25 12:41:27] [config] shuffle-in-ram: false
[2019-07-25 12:41:27] [config] skip: false
[2019-07-25 12:41:27] [config] sqlite: ""
[2019-07-25 12:41:27] [config] sqlite-drop: false
[2019-07-25 12:41:27] [config] sync-sgd: true
[2019-07-25 12:41:27] [config] tempdir: .
[2019-07-25 12:41:27] [config] tied-embeddings: false
[2019-07-25 12:41:27] [config] tied-embeddings-all: false
[2019-07-25 12:41:27] [config] tied-embeddings-src: false
[2019-07-25 12:41:27] [config] train-sets:
[2019-07-25 12:41:27] [config]   - ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.de
[2019-07-25 12:41:27] [config]   - ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.en
[2019-07-25 12:41:27] [config] transformer-aan-activation: swish
[2019-07-25 12:41:27] [config] transformer-aan-depth: 2
[2019-07-25 12:41:27] [config] transformer-aan-nogate: false
[2019-07-25 12:41:27] [config] transformer-decoder-autoreg: self-attention
[2019-07-25 12:41:27] [config] transformer-dim-aan: 2048
[2019-07-25 12:41:27] [config] transformer-dim-ffn: 2048
[2019-07-25 12:41:27] [config] transformer-dropout: 0
[2019-07-25 12:41:27] [config] transformer-dropout-attention: 0
[2019-07-25 12:41:27] [config] transformer-dropout-ffn: 0
[2019-07-25 12:41:27] [config] transformer-ffn-activation: swish
[2019-07-25 12:41:27] [config] transformer-ffn-depth: 2
[2019-07-25 12:41:27] [config] transformer-guided-alignment-layer: last
[2019-07-25 12:41:27] [config] transformer-heads: 8
[2019-07-25 12:41:27] [config] transformer-no-projection: false
[2019-07-25 12:41:27] [config] transformer-postprocess: dan
[2019-07-25 12:41:27] [config] transformer-postprocess-emb: d
[2019-07-25 12:41:27] [config] transformer-preprocess: ""
[2019-07-25 12:41:27] [config] transformer-tied-layers:
[2019-07-25 12:41:27] [config]   []
[2019-07-25 12:41:27] [config] transformer-train-position-embeddings: false
[2019-07-25 12:41:27] [config] type: amun
[2019-07-25 12:41:27] [config] ulr: false
[2019-07-25 12:41:27] [config] ulr-dim-emb: 0
[2019-07-25 12:41:27] [config] ulr-dropout: 0
[2019-07-25 12:41:27] [config] ulr-keys-vectors: ""
[2019-07-25 12:41:27] [config] ulr-query-vectors: ""
[2019-07-25 12:41:27] [config] ulr-softmax-temperature: 1
[2019-07-25 12:41:27] [config] ulr-trainable-transformation: false
[2019-07-25 12:41:27] [config] valid-freq: 20000
[2019-07-25 12:41:27] [config] valid-log: ../experiments/10M_bicleaner_st_lm_w3000/model/valid.log
[2019-07-25 12:41:27] [config] valid-max-length: 1000
[2019-07-25 12:41:27] [config] valid-metrics:
[2019-07-25 12:41:27] [config]   - cross-entropy
[2019-07-25 12:41:27] [config]   - perplexity
[2019-07-25 12:41:27] [config]   - translation
[2019-07-25 12:41:27] [config] valid-mini-batch: 8
[2019-07-25 12:41:27] [config] valid-script-path: ../experiments/10M_bicleaner_st_lm_w3000/score-dev.sh
[2019-07-25 12:41:27] [config] valid-sets:
[2019-07-25 12:41:27] [config]   - ../experiments/10M_bicleaner_st_lm_w3000/data/dev.bpe.de
[2019-07-25 12:41:27] [config]   - ../experiments/10M_bicleaner_st_lm_w3000/data/dev.bpe.en
[2019-07-25 12:41:27] [config] valid-translation-output: ../experiments/10M_bicleaner_st_lm_w3000/model/dev.out
[2019-07-25 12:41:27] [config] vocabs:
[2019-07-25 12:41:27] [config]   - ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.de.json
[2019-07-25 12:41:27] [config]   - ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.en.json
[2019-07-25 12:41:27] [config] word-penalty: 0
[2019-07-25 12:41:27] [config] workspace: 3000
[2019-07-25 12:41:27] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-25 12:41:27] Using synchronous training
[2019-07-25 12:41:27] [data] Loading vocabulary from JSON/Yaml file ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.de.json
[2019-07-25 12:41:27] [data] Using unused word id eos for 0
[2019-07-25 12:41:27] [data] Using unused word id UNK for 1
[2019-07-25 12:41:27] [data] Setting vocabulary size for input 0 to 50000
[2019-07-25 12:41:27] [data] Loading vocabulary from JSON/Yaml file ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.en.json
[2019-07-25 12:41:27] [data] Using unused word id eos for 0
[2019-07-25 12:41:27] [data] Using unused word id UNK for 1
[2019-07-25 12:41:27] [data] Setting vocabulary size for input 1 to 50000
[2019-07-25 12:41:27] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-25 12:41:27] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-25 12:41:28] [memory] Extending reserved space to 3072 MB (device gpu2)
[2019-07-25 12:41:29] [memory] Extending reserved space to 3072 MB (device gpu3)
[2019-07-25 12:41:29] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-25 12:41:29] [comm] NCCLCommunicator constructed successfully.
[2019-07-25 12:41:29] [training] Using 2 GPUs
[2019-07-25 12:41:29] [memory] Reserving 422 MB, device gpu2
[2019-07-25 12:41:29] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-25 12:41:30] [memory] Reserving 422 MB, device gpu2
[2019-07-25 12:41:34] [batching] Done. Typical MB size is 8084 target words
[2019-07-25 12:41:34] [memory] Extending reserved space to 3072 MB (device gpu2)
[2019-07-25 12:41:34] [memory] Extending reserved space to 3072 MB (device gpu3)
[2019-07-25 12:41:34] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-25 12:41:35] [comm] NCCLCommunicator constructed successfully.
[2019-07-25 12:41:35] [training] Using 2 GPUs
[2019-07-25 12:41:35] Training started
[2019-07-25 12:41:35] [data] Shuffling data
[2019-07-25 12:41:35] [data] Done reading 632833 sentences
[2019-07-25 12:41:38] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 12:41:39] [training] Batches are processed as 1 process(es) x 2 devices/process
[2019-07-25 12:41:39] [memory] Reserving 422 MB, device gpu3
[2019-07-25 12:41:39] [memory] Reserving 422 MB, device gpu2
[2019-07-25 12:41:39] [memory] Reserving 422 MB, device gpu3
[2019-07-25 12:41:39] [memory] Reserving 422 MB, device gpu2
[2019-07-25 12:41:39] [memory] Reserving 211 MB, device gpu2
[2019-07-25 12:41:39] [memory] Reserving 211 MB, device gpu3
[2019-07-25 12:41:39] [memory] Reserving 422 MB, device gpu2
[2019-07-25 12:41:39] [memory] Reserving 422 MB, device gpu3
[2019-07-25 12:52:42] Ep. 1 : Up. 2000 : Sen. 503,520 : Cost 107.35917664 : Time 674.85s : 14662.06 words/s
[2019-07-25 12:54:49] Seen 599177 samples
[2019-07-25 12:54:49] Starting epoch 2
[2019-07-25 12:54:49] [data] Shuffling data
[2019-07-25 12:54:50] [data] Done reading 632833 sentences
[2019-07-25 12:54:52] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 13:03:50] Ep. 2 : Up. 4000 : Sen. 404,494 : Cost 72.64962769 : Time 667.62s : 14712.88 words/s
[2019-07-25 13:08:08] Seen 599177 samples
[2019-07-25 13:08:08] Starting epoch 3
[2019-07-25 13:08:08] [data] Shuffling data
[2019-07-25 13:08:08] [data] Done reading 632833 sentences
[2019-07-25 13:08:10] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 13:15:00] Ep. 3 : Up. 6000 : Sen. 307,610 : Cost 58.22374344 : Time 669.80s : 14724.19 words/s
[2019-07-25 13:21:27] Seen 599177 samples
[2019-07-25 13:21:27] Starting epoch 4
[2019-07-25 13:21:27] [data] Shuffling data
[2019-07-25 13:21:27] [data] Done reading 632833 sentences
[2019-07-25 13:21:29] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 13:26:11] Ep. 4 : Up. 8000 : Sen. 211,044 : Cost 50.48989105 : Time 671.70s : 14698.70 words/s
[2019-07-25 13:34:46] Seen 599177 samples
[2019-07-25 13:34:46] Starting epoch 5
[2019-07-25 13:34:46] [data] Shuffling data
[2019-07-25 13:34:46] [data] Done reading 632833 sentences
[2019-07-25 13:34:49] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 13:37:22] Ep. 5 : Up. 10000 : Sen. 113,062 : Cost 45.57715225 : Time 670.26s : 14701.43 words/s
[2019-07-25 13:48:07] Seen 599177 samples
[2019-07-25 13:48:07] Starting epoch 6
[2019-07-25 13:48:07] [data] Shuffling data
[2019-07-25 13:48:08] [data] Done reading 632833 sentences
[2019-07-25 13:48:10] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 13:48:37] Ep. 6 : Up. 12000 : Sen. 19,470 : Cost 42.30277634 : Time 675.35s : 14688.49 words/s
[2019-07-25 13:59:45] Ep. 6 : Up. 14000 : Sen. 522,474 : Cost 39.63068771 : Time 667.82s : 14792.33 words/s
[2019-07-25 14:01:27] Seen 599177 samples
[2019-07-25 14:01:27] Starting epoch 7
[2019-07-25 14:01:27] [data] Shuffling data
[2019-07-25 14:01:27] [data] Done reading 632833 sentences
[2019-07-25 14:01:29] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 14:10:55] Ep. 7 : Up. 16000 : Sen. 423,482 : Cost 37.61382675 : Time 670.06s : 14686.66 words/s
[2019-07-25 14:14:47] Seen 599177 samples
[2019-07-25 14:14:47] Starting epoch 8
[2019-07-25 14:14:47] [data] Shuffling data
[2019-07-25 14:14:48] [data] Done reading 632833 sentences
[2019-07-25 14:14:50] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 14:22:06] Ep. 8 : Up. 18000 : Sen. 328,468 : Cost 35.73726654 : Time 671.48s : 14713.06 words/s
[2019-07-25 14:28:06] Seen 599177 samples
[2019-07-25 14:28:06] Starting epoch 9
[2019-07-25 14:28:06] [data] Shuffling data
[2019-07-25 14:28:06] [data] Done reading 632833 sentences
[2019-07-25 14:28:09] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 14:33:17] Ep. 9 : Up. 20000 : Sen. 231,848 : Cost 34.43756485 : Time 671.03s : 14725.04 words/s
[2019-07-25 14:33:17] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-25 14:33:27] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.iter20000.npz
[2019-07-25 14:33:33] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-25 14:33:44] Saving Adam parameters to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-25 14:34:05] [valid] Ep. 9 : Up. 20000 : cross-entropy : 69.4869 : new best
[2019-07-25 14:34:09] [valid] Ep. 9 : Up. 20000 : perplexity : 15.2406 : new best
[2019-07-25 14:34:54] [valid] Ep. 9 : Up. 20000 : translation : 22.49 : new best
[2019-07-25 14:43:04] Seen 599177 samples
[2019-07-25 14:43:04] Starting epoch 10
[2019-07-25 14:43:04] [data] Shuffling data
[2019-07-25 14:43:04] [data] Done reading 632833 sentences
[2019-07-25 14:43:06] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 14:46:05] Ep. 10 : Up. 22000 : Sen. 133,990 : Cost 33.20066071 : Time 768.02s : 12823.05 words/s
[2019-07-25 14:56:23] Seen 599177 samples
[2019-07-25 14:56:23] Starting epoch 11
[2019-07-25 14:56:23] [data] Shuffling data
[2019-07-25 14:56:24] [data] Done reading 632833 sentences
[2019-07-25 14:56:26] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 14:57:19] Ep. 11 : Up. 24000 : Sen. 38,760 : Cost 32.17932510 : Time 673.96s : 14697.03 words/s

[CALL STACK]
[0x727f12]                                                            
[0x728ff8]          marian::data::Corpus::  next  ()                   + 0xd68
[0x716e4f]          marian::data::CorpusIterator::  increment  ()      + 0x2f
[0x681a7d]          marian::data::BatchGenerator<marian::data::CorpusBase>::  fetchBatches  () + 0x10dd
[0x682adb]          std::future<std::result_of<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1} ()>::type> marian::ThreadPool::enqueue<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}>(std::result_of&&,(marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}&&)...)::{lambda()#1}::  operator()  () const + 0x2b
[0x6834be]          std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base,std::__future_base::_Result_base::_Deleter> (),std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<std::deque<std::shared_ptr<marian::data::CorpusBatch>,std::allocator<std::shared_ptr<marian::data::CorpusBatch>>>>,std::__future_base::_Result_base::_Deleter>,std::_Bind_simple<std::reference_wrapper<std::future<std::result_of<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1} ()>::type> marian::ThreadPool::enqueue<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}>(std::result_of&&,(marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}&&)...)::{lambda()#1}> ()>,std::deque<std::shared_ptr<marian::data::CorpusBatch>,std::allocator<std::shared_ptr<marian::data::CorpusBatch>>>>>::  _M_invoke  (std::_Any_data const&) + 0x3e
[0x5a5f19]          std::__future_base::_State_baseV2::  _M_do_set  (std::function<std::unique_ptr<std::__future_base::_Result_base,std::__future_base::_Result_base::_Deleter> ()>*,  bool*) + 0x29
[0x7fad705caa99]                                                       + 0xea99
[0x59fac2]                                                            
[0x5a7341]          std::__future_base::_Task_state<std::future<std::result_of<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1} ()>::type> marian::ThreadPool::enqueue<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}>(std::result_of&&,(marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}&&)...)::{lambda()#1},std::allocator<int>,std::deque<std::shared_ptr<marian::data::CorpusBatch>,std::allocator<std::shared_ptr>> ()>::  _M_run  () + 0x51
[0x5d00b4]          std::thread::_Impl<std::_Bind_simple<marian::ThreadPool::reserve(unsigned long)::{lambda()#1} ()>>::  _M_run  () + 0x174
[0x7fad700eac80]                                                       + 0xb8c80
[0x7fad705c36ba]                                                       + 0x76ba
[0x7fad6f85041d]    clone                                              + 0x6d

[2019-07-25 17:16:51] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-25 17:16:51] [marian] Running on dagr as process 23590 with command line:
[2019-07-25 17:16:51] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz -T . --devices 2 3 --train-sets ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.de ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.en --vocabs ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.de.json ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/10M_bicleaner_st_lm_w3000/data/dev.bpe.de ../experiments/10M_bicleaner_st_lm_w3000/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/10M_bicleaner_st_lm_w3000/model/dev.out --valid-script-path ../experiments/10M_bicleaner_st_lm_w3000/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/10M_bicleaner_st_lm_w3000/model/train.log --valid-log ../experiments/10M_bicleaner_st_lm_w3000/model/valid.log
[2019-07-25 17:16:52] [config] after-batches: 0
[2019-07-25 17:16:52] [config] after-epochs: 0
[2019-07-25 17:16:52] [config] allow-unk: false
[2019-07-25 17:16:52] [config] beam-size: 12
[2019-07-25 17:16:52] [config] bert-class-symbol: "[CLS]"
[2019-07-25 17:16:52] [config] bert-mask-symbol: "[MASK]"
[2019-07-25 17:16:52] [config] bert-masking-fraction: 0.15
[2019-07-25 17:16:52] [config] bert-sep-symbol: "[SEP]"
[2019-07-25 17:16:52] [config] bert-train-type-embeddings: true
[2019-07-25 17:16:52] [config] bert-type-vocab-size: 2
[2019-07-25 17:16:52] [config] best-deep: false
[2019-07-25 17:16:52] [config] clip-gemm: 0
[2019-07-25 17:16:52] [config] clip-norm: 1
[2019-07-25 17:16:52] [config] cost-type: ce-mean
[2019-07-25 17:16:52] [config] cpu-threads: 0
[2019-07-25 17:16:52] [config] data-weighting: ""
[2019-07-25 17:16:52] [config] data-weighting-type: sentence
[2019-07-25 17:16:52] [config] dec-cell: gru
[2019-07-25 17:16:52] [config] dec-cell-base-depth: 2
[2019-07-25 17:16:52] [config] dec-cell-high-depth: 1
[2019-07-25 17:16:52] [config] dec-depth: 1
[2019-07-25 17:16:52] [config] devices:
[2019-07-25 17:16:52] [config]   - 2
[2019-07-25 17:16:52] [config]   - 3
[2019-07-25 17:16:52] [config] dim-emb: 512
[2019-07-25 17:16:52] [config] dim-rnn: 1024
[2019-07-25 17:16:52] [config] dim-vocabs:
[2019-07-25 17:16:52] [config]   - 50000
[2019-07-25 17:16:52] [config]   - 50000
[2019-07-25 17:16:52] [config] disp-first: 0
[2019-07-25 17:16:52] [config] disp-freq: 2000
[2019-07-25 17:16:52] [config] disp-label-counts: false
[2019-07-25 17:16:52] [config] dropout-rnn: 0.2
[2019-07-25 17:16:52] [config] dropout-src: 0.1
[2019-07-25 17:16:52] [config] dropout-trg: 0.1
[2019-07-25 17:16:52] [config] dump-config: ""
[2019-07-25 17:16:52] [config] early-stopping: 5
[2019-07-25 17:16:52] [config] embedding-fix-src: false
[2019-07-25 17:16:52] [config] embedding-fix-trg: false
[2019-07-25 17:16:52] [config] embedding-normalization: false
[2019-07-25 17:16:52] [config] embedding-vectors:
[2019-07-25 17:16:52] [config]   []
[2019-07-25 17:16:52] [config] enc-cell: gru
[2019-07-25 17:16:52] [config] enc-cell-depth: 1
[2019-07-25 17:16:52] [config] enc-depth: 1
[2019-07-25 17:16:52] [config] enc-type: bidirectional
[2019-07-25 17:16:52] [config] exponential-smoothing: 0.0001
[2019-07-25 17:16:52] [config] grad-dropping-momentum: 0
[2019-07-25 17:16:52] [config] grad-dropping-rate: 0
[2019-07-25 17:16:52] [config] grad-dropping-warmup: 100
[2019-07-25 17:16:52] [config] guided-alignment: none
[2019-07-25 17:16:52] [config] guided-alignment-cost: mse
[2019-07-25 17:16:52] [config] guided-alignment-weight: 0.1
[2019-07-25 17:16:52] [config] ignore-model-config: false
[2019-07-25 17:16:52] [config] input-types:
[2019-07-25 17:16:52] [config]   []
[2019-07-25 17:16:52] [config] interpolate-env-vars: false
[2019-07-25 17:16:52] [config] keep-best: false
[2019-07-25 17:16:52] [config] label-smoothing: 0
[2019-07-25 17:16:52] [config] layer-normalization: true
[2019-07-25 17:16:52] [config] learn-rate: 0.0001
[2019-07-25 17:16:52] [config] log: ../experiments/10M_bicleaner_st_lm_w3000/model/train.log
[2019-07-25 17:16:52] [config] log-level: info
[2019-07-25 17:16:52] [config] log-time-zone: ""
[2019-07-25 17:16:52] [config] lr-decay: 0
[2019-07-25 17:16:52] [config] lr-decay-freq: 50000
[2019-07-25 17:16:52] [config] lr-decay-inv-sqrt:
[2019-07-25 17:16:52] [config]   - 0
[2019-07-25 17:16:52] [config] lr-decay-repeat-warmup: false
[2019-07-25 17:16:52] [config] lr-decay-reset-optimizer: false
[2019-07-25 17:16:52] [config] lr-decay-start:
[2019-07-25 17:16:52] [config]   - 10
[2019-07-25 17:16:52] [config]   - 1
[2019-07-25 17:16:52] [config] lr-decay-strategy: epoch+stalled
[2019-07-25 17:16:52] [config] lr-report: false
[2019-07-25 17:16:52] [config] lr-warmup: 0
[2019-07-25 17:16:52] [config] lr-warmup-at-reload: false
[2019-07-25 17:16:52] [config] lr-warmup-cycle: false
[2019-07-25 17:16:52] [config] lr-warmup-start-rate: 0
[2019-07-25 17:16:52] [config] max-length: 50
[2019-07-25 17:16:52] [config] max-length-crop: false
[2019-07-25 17:16:52] [config] max-length-factor: 3
[2019-07-25 17:16:52] [config] maxi-batch: 100
[2019-07-25 17:16:52] [config] maxi-batch-sort: trg
[2019-07-25 17:16:52] [config] mini-batch: 64
[2019-07-25 17:16:52] [config] mini-batch-fit: true
[2019-07-25 17:16:52] [config] mini-batch-fit-step: 10
[2019-07-25 17:16:52] [config] mini-batch-overstuff: 1
[2019-07-25 17:16:52] [config] mini-batch-track-lr: false
[2019-07-25 17:16:52] [config] mini-batch-understuff: 1
[2019-07-25 17:16:52] [config] mini-batch-warmup: 0
[2019-07-25 17:16:52] [config] mini-batch-words: 0
[2019-07-25 17:16:52] [config] mini-batch-words-ref: 0
[2019-07-25 17:16:52] [config] model: ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-25 17:16:52] [config] multi-loss-type: sum
[2019-07-25 17:16:52] [config] multi-node: false
[2019-07-25 17:16:52] [config] multi-node-overlap: true
[2019-07-25 17:16:52] [config] n-best: false
[2019-07-25 17:16:52] [config] no-nccl: false
[2019-07-25 17:16:52] [config] no-reload: false
[2019-07-25 17:16:52] [config] no-restore-corpus: false
[2019-07-25 17:16:52] [config] no-shuffle: false
[2019-07-25 17:16:52] [config] normalize: 1
[2019-07-25 17:16:52] [config] num-devices: 0
[2019-07-25 17:16:52] [config] optimizer: adam
[2019-07-25 17:16:52] [config] optimizer-delay: 1
[2019-07-25 17:16:52] [config] optimizer-params:
[2019-07-25 17:16:52] [config]   []
[2019-07-25 17:16:52] [config] overwrite: false
[2019-07-25 17:16:52] [config] pretrained-model: ""
[2019-07-25 17:16:52] [config] quiet: false
[2019-07-25 17:16:52] [config] quiet-translation: true
[2019-07-25 17:16:52] [config] relative-paths: false
[2019-07-25 17:16:52] [config] right-left: false
[2019-07-25 17:16:52] [config] save-freq: 20000
[2019-07-25 17:16:52] [config] seed: 1111
[2019-07-25 17:16:52] [config] shuffle-in-ram: false
[2019-07-25 17:16:52] [config] skip: false
[2019-07-25 17:16:52] [config] sqlite: ""
[2019-07-25 17:16:52] [config] sqlite-drop: false
[2019-07-25 17:16:52] [config] sync-sgd: true
[2019-07-25 17:16:52] [config] tempdir: .
[2019-07-25 17:16:52] [config] tied-embeddings: false
[2019-07-25 17:16:52] [config] tied-embeddings-all: false
[2019-07-25 17:16:52] [config] tied-embeddings-src: false
[2019-07-25 17:16:52] [config] train-sets:
[2019-07-25 17:16:52] [config]   - ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.de
[2019-07-25 17:16:52] [config]   - ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.en
[2019-07-25 17:16:52] [config] transformer-aan-activation: swish
[2019-07-25 17:16:52] [config] transformer-aan-depth: 2
[2019-07-25 17:16:52] [config] transformer-aan-nogate: false
[2019-07-25 17:16:52] [config] transformer-decoder-autoreg: self-attention
[2019-07-25 17:16:52] [config] transformer-dim-aan: 2048
[2019-07-25 17:16:52] [config] transformer-dim-ffn: 2048
[2019-07-25 17:16:52] [config] transformer-dropout: 0
[2019-07-25 17:16:52] [config] transformer-dropout-attention: 0
[2019-07-25 17:16:52] [config] transformer-dropout-ffn: 0
[2019-07-25 17:16:52] [config] transformer-ffn-activation: swish
[2019-07-25 17:16:52] [config] transformer-ffn-depth: 2
[2019-07-25 17:16:52] [config] transformer-guided-alignment-layer: last
[2019-07-25 17:16:52] [config] transformer-heads: 8
[2019-07-25 17:16:52] [config] transformer-no-projection: false
[2019-07-25 17:16:52] [config] transformer-postprocess: dan
[2019-07-25 17:16:52] [config] transformer-postprocess-emb: d
[2019-07-25 17:16:52] [config] transformer-preprocess: ""
[2019-07-25 17:16:52] [config] transformer-tied-layers:
[2019-07-25 17:16:52] [config]   []
[2019-07-25 17:16:52] [config] transformer-train-position-embeddings: false
[2019-07-25 17:16:52] [config] type: amun
[2019-07-25 17:16:52] [config] ulr: false
[2019-07-25 17:16:52] [config] ulr-dim-emb: 0
[2019-07-25 17:16:52] [config] ulr-dropout: 0
[2019-07-25 17:16:52] [config] ulr-keys-vectors: ""
[2019-07-25 17:16:52] [config] ulr-query-vectors: ""
[2019-07-25 17:16:52] [config] ulr-softmax-temperature: 1
[2019-07-25 17:16:52] [config] ulr-trainable-transformation: false
[2019-07-25 17:16:52] [config] valid-freq: 20000
[2019-07-25 17:16:52] [config] valid-log: ../experiments/10M_bicleaner_st_lm_w3000/model/valid.log
[2019-07-25 17:16:52] [config] valid-max-length: 1000
[2019-07-25 17:16:52] [config] valid-metrics:
[2019-07-25 17:16:52] [config]   - cross-entropy
[2019-07-25 17:16:52] [config]   - perplexity
[2019-07-25 17:16:52] [config]   - translation
[2019-07-25 17:16:52] [config] valid-mini-batch: 8
[2019-07-25 17:16:52] [config] valid-script-path: ../experiments/10M_bicleaner_st_lm_w3000/score-dev.sh
[2019-07-25 17:16:52] [config] valid-sets:
[2019-07-25 17:16:52] [config]   - ../experiments/10M_bicleaner_st_lm_w3000/data/dev.bpe.de
[2019-07-25 17:16:52] [config]   - ../experiments/10M_bicleaner_st_lm_w3000/data/dev.bpe.en
[2019-07-25 17:16:52] [config] valid-translation-output: ../experiments/10M_bicleaner_st_lm_w3000/model/dev.out
[2019-07-25 17:16:52] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-25 17:16:52] [config] vocabs:
[2019-07-25 17:16:52] [config]   - ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.de.json
[2019-07-25 17:16:52] [config]   - ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.en.json
[2019-07-25 17:16:52] [config] word-penalty: 0
[2019-07-25 17:16:52] [config] workspace: 3000
[2019-07-25 17:16:52] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-25 17:16:52] Using synchronous training
[2019-07-25 17:16:52] [data] Loading vocabulary from JSON/Yaml file ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.de.json
[2019-07-25 17:16:52] [data] Using unused word id eos for 0
[2019-07-25 17:16:52] [data] Using unused word id UNK for 1
[2019-07-25 17:16:52] [data] Setting vocabulary size for input 0 to 50000
[2019-07-25 17:16:52] [data] Loading vocabulary from JSON/Yaml file ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.en.json
[2019-07-25 17:16:52] [data] Using unused word id eos for 0
[2019-07-25 17:16:52] [data] Using unused word id UNK for 1
[2019-07-25 17:16:52] [data] Setting vocabulary size for input 1 to 50000
[2019-07-25 17:16:52] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-25 17:16:52] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-25 17:16:53] [memory] Extending reserved space to 3072 MB (device gpu2)
[2019-07-25 17:16:54] [memory] Extending reserved space to 3072 MB (device gpu3)
[2019-07-25 17:16:55] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-25 17:16:55] [comm] NCCLCommunicator constructed successfully.
[2019-07-25 17:16:55] [training] Using 2 GPUs
[2019-07-25 17:16:55] [memory] Reserving 422 MB, device gpu2
[2019-07-25 17:16:55] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-25 17:16:55] [memory] Reserving 422 MB, device gpu2
[2019-07-25 17:17:00] [batching] Done. Typical MB size is 8084 target words
[2019-07-25 17:17:00] [memory] Extending reserved space to 3072 MB (device gpu2)
[2019-07-25 17:17:00] [memory] Extending reserved space to 3072 MB (device gpu3)
[2019-07-25 17:17:00] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-25 17:17:00] [comm] NCCLCommunicator constructed successfully.
[2019-07-25 17:17:00] [training] Using 2 GPUs
[2019-07-25 17:17:00] Loading model from ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-25 17:17:07] Loading model from ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-25 17:17:09] Loading Adam parameters from ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-25 17:17:22] [memory] Reserving 422 MB, device gpu2
[2019-07-25 17:17:22] [memory] Reserving 422 MB, device gpu3
[2019-07-25 17:17:23] [training] Model reloaded from ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-25 17:17:23] [data] Restoring the corpus state to epoch 9, batch 20000
[2019-07-25 17:17:23] [data] Shuffling data
[2019-07-25 17:17:24] [data] Done reading 632833 sentences
[2019-07-25 17:17:27] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 17:17:34] Training started
[2019-07-25 17:17:34] [training] Batches are processed as 1 process(es) x 2 devices/process
[2019-07-25 17:17:34] [memory] Reserving 422 MB, device gpu3
[2019-07-25 17:17:34] [memory] Reserving 422 MB, device gpu2
[2019-07-25 17:17:34] [memory] Reserving 422 MB, device gpu2
[2019-07-25 17:17:34] [memory] Reserving 422 MB, device gpu3
[2019-07-25 17:17:34] Loading model from ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-25 17:17:41] [memory] Reserving 422 MB, device cpu0
[2019-07-25 17:17:41] [memory] Reserving 211 MB, device gpu2
[2019-07-25 17:17:41] [memory] Reserving 211 MB, device gpu3
[2019-07-25 17:25:42] Seen 599177 samples
[2019-07-25 17:25:42] Starting epoch 10
[2019-07-25 17:25:42] [data] Shuffling data
[2019-07-25 17:25:43] [data] Done reading 632833 sentences
[2019-07-25 17:25:45] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 17:28:43] Ep. 10 : Up. 22000 : Sen. 133,990 : Cost 33.45669556 : Time 710.86s : 13854.19 words/s
[2019-07-25 17:38:56] Seen 599177 samples
[2019-07-25 17:38:56] Starting epoch 11
[2019-07-25 17:38:56] [data] Shuffling data
[2019-07-25 17:38:56] [data] Done reading 632833 sentences
[2019-07-25 17:38:58] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 20:31:07] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-25 20:31:07] [marian] Running on bil as process 2655 with command line:
[2019-07-25 20:31:07] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz -T . --devices 5 --train-sets ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.de ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.en --vocabs ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.de.json ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/10M_bicleaner_st_lm_w3000/data/dev.bpe.de ../experiments/10M_bicleaner_st_lm_w3000/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/10M_bicleaner_st_lm_w3000/model/dev.out --valid-script-path ../experiments/10M_bicleaner_st_lm_w3000/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/10M_bicleaner_st_lm_w3000/model/train.log --valid-log ../experiments/10M_bicleaner_st_lm_w3000/model/valid.log
[2019-07-25 20:31:07] [config] after-batches: 0
[2019-07-25 20:31:07] [config] after-epochs: 0
[2019-07-25 20:31:07] [config] allow-unk: false
[2019-07-25 20:31:07] [config] beam-size: 12
[2019-07-25 20:31:07] [config] bert-class-symbol: "[CLS]"
[2019-07-25 20:31:07] [config] bert-mask-symbol: "[MASK]"
[2019-07-25 20:31:07] [config] bert-masking-fraction: 0.15
[2019-07-25 20:31:07] [config] bert-sep-symbol: "[SEP]"
[2019-07-25 20:31:07] [config] bert-train-type-embeddings: true
[2019-07-25 20:31:07] [config] bert-type-vocab-size: 2
[2019-07-25 20:31:07] [config] best-deep: false
[2019-07-25 20:31:07] [config] clip-gemm: 0
[2019-07-25 20:31:07] [config] clip-norm: 1
[2019-07-25 20:31:07] [config] cost-type: ce-mean
[2019-07-25 20:31:07] [config] cpu-threads: 0
[2019-07-25 20:31:07] [config] data-weighting: ""
[2019-07-25 20:31:07] [config] data-weighting-type: sentence
[2019-07-25 20:31:07] [config] dec-cell: gru
[2019-07-25 20:31:07] [config] dec-cell-base-depth: 2
[2019-07-25 20:31:07] [config] dec-cell-high-depth: 1
[2019-07-25 20:31:07] [config] dec-depth: 1
[2019-07-25 20:31:07] [config] devices:
[2019-07-25 20:31:07] [config]   - 5
[2019-07-25 20:31:07] [config] dim-emb: 512
[2019-07-25 20:31:07] [config] dim-rnn: 1024
[2019-07-25 20:31:07] [config] dim-vocabs:
[2019-07-25 20:31:07] [config]   - 50000
[2019-07-25 20:31:07] [config]   - 50000
[2019-07-25 20:31:07] [config] disp-first: 0
[2019-07-25 20:31:07] [config] disp-freq: 2000
[2019-07-25 20:31:07] [config] disp-label-counts: false
[2019-07-25 20:31:07] [config] dropout-rnn: 0.2
[2019-07-25 20:31:07] [config] dropout-src: 0.1
[2019-07-25 20:31:07] [config] dropout-trg: 0.1
[2019-07-25 20:31:07] [config] dump-config: ""
[2019-07-25 20:31:07] [config] early-stopping: 5
[2019-07-25 20:31:07] [config] embedding-fix-src: false
[2019-07-25 20:31:07] [config] embedding-fix-trg: false
[2019-07-25 20:31:07] [config] embedding-normalization: false
[2019-07-25 20:31:07] [config] embedding-vectors:
[2019-07-25 20:31:07] [config]   []
[2019-07-25 20:31:07] [config] enc-cell: gru
[2019-07-25 20:31:07] [config] enc-cell-depth: 1
[2019-07-25 20:31:07] [config] enc-depth: 1
[2019-07-25 20:31:07] [config] enc-type: bidirectional
[2019-07-25 20:31:07] [config] exponential-smoothing: 0.0001
[2019-07-25 20:31:07] [config] grad-dropping-momentum: 0
[2019-07-25 20:31:07] [config] grad-dropping-rate: 0
[2019-07-25 20:31:07] [config] grad-dropping-warmup: 100
[2019-07-25 20:31:07] [config] guided-alignment: none
[2019-07-25 20:31:07] [config] guided-alignment-cost: mse
[2019-07-25 20:31:07] [config] guided-alignment-weight: 0.1
[2019-07-25 20:31:07] [config] ignore-model-config: false
[2019-07-25 20:31:07] [config] input-types:
[2019-07-25 20:31:07] [config]   []
[2019-07-25 20:31:07] [config] interpolate-env-vars: false
[2019-07-25 20:31:07] [config] keep-best: false
[2019-07-25 20:31:07] [config] label-smoothing: 0
[2019-07-25 20:31:07] [config] layer-normalization: true
[2019-07-25 20:31:07] [config] learn-rate: 0.0001
[2019-07-25 20:31:07] [config] log: ../experiments/10M_bicleaner_st_lm_w3000/model/train.log
[2019-07-25 20:31:07] [config] log-level: info
[2019-07-25 20:31:07] [config] log-time-zone: ""
[2019-07-25 20:31:07] [config] lr-decay: 0
[2019-07-25 20:31:07] [config] lr-decay-freq: 50000
[2019-07-25 20:31:07] [config] lr-decay-inv-sqrt:
[2019-07-25 20:31:07] [config]   - 0
[2019-07-25 20:31:07] [config] lr-decay-repeat-warmup: false
[2019-07-25 20:31:07] [config] lr-decay-reset-optimizer: false
[2019-07-25 20:31:07] [config] lr-decay-start:
[2019-07-25 20:31:07] [config]   - 10
[2019-07-25 20:31:07] [config]   - 1
[2019-07-25 20:31:07] [config] lr-decay-strategy: epoch+stalled
[2019-07-25 20:31:07] [config] lr-report: false
[2019-07-25 20:31:07] [config] lr-warmup: 0
[2019-07-25 20:31:07] [config] lr-warmup-at-reload: false
[2019-07-25 20:31:07] [config] lr-warmup-cycle: false
[2019-07-25 20:31:07] [config] lr-warmup-start-rate: 0
[2019-07-25 20:31:07] [config] max-length: 50
[2019-07-25 20:31:07] [config] max-length-crop: false
[2019-07-25 20:31:07] [config] max-length-factor: 3
[2019-07-25 20:31:07] [config] maxi-batch: 100
[2019-07-25 20:31:07] [config] maxi-batch-sort: trg
[2019-07-25 20:31:07] [config] mini-batch: 64
[2019-07-25 20:31:07] [config] mini-batch-fit: true
[2019-07-25 20:31:07] [config] mini-batch-fit-step: 10
[2019-07-25 20:31:07] [config] mini-batch-overstuff: 1
[2019-07-25 20:31:07] [config] mini-batch-track-lr: false
[2019-07-25 20:31:07] [config] mini-batch-understuff: 1
[2019-07-25 20:31:07] [config] mini-batch-warmup: 0
[2019-07-25 20:31:07] [config] mini-batch-words: 0
[2019-07-25 20:31:07] [config] mini-batch-words-ref: 0
[2019-07-25 20:31:07] [config] model: ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-25 20:31:07] [config] multi-loss-type: sum
[2019-07-25 20:31:07] [config] multi-node: false
[2019-07-25 20:31:07] [config] multi-node-overlap: true
[2019-07-25 20:31:07] [config] n-best: false
[2019-07-25 20:31:07] [config] no-nccl: false
[2019-07-25 20:31:07] [config] no-reload: false
[2019-07-25 20:31:07] [config] no-restore-corpus: false
[2019-07-25 20:31:07] [config] no-shuffle: false
[2019-07-25 20:31:07] [config] normalize: 1
[2019-07-25 20:31:07] [config] num-devices: 0
[2019-07-25 20:31:07] [config] optimizer: adam
[2019-07-25 20:31:07] [config] optimizer-delay: 1
[2019-07-25 20:31:07] [config] optimizer-params:
[2019-07-25 20:31:07] [config]   []
[2019-07-25 20:31:07] [config] overwrite: false
[2019-07-25 20:31:07] [config] pretrained-model: ""
[2019-07-25 20:31:07] [config] quiet: false
[2019-07-25 20:31:07] [config] quiet-translation: true
[2019-07-25 20:31:07] [config] relative-paths: false
[2019-07-25 20:31:07] [config] right-left: false
[2019-07-25 20:31:07] [config] save-freq: 20000
[2019-07-25 20:31:07] [config] seed: 1111
[2019-07-25 20:31:07] [config] shuffle-in-ram: false
[2019-07-25 20:31:07] [config] skip: false
[2019-07-25 20:31:07] [config] sqlite: ""
[2019-07-25 20:31:07] [config] sqlite-drop: false
[2019-07-25 20:31:07] [config] sync-sgd: true
[2019-07-25 20:31:07] [config] tempdir: .
[2019-07-25 20:31:07] [config] tied-embeddings: false
[2019-07-25 20:31:07] [config] tied-embeddings-all: false
[2019-07-25 20:31:07] [config] tied-embeddings-src: false
[2019-07-25 20:31:07] [config] train-sets:
[2019-07-25 20:31:07] [config]   - ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.de
[2019-07-25 20:31:07] [config]   - ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.en
[2019-07-25 20:31:07] [config] transformer-aan-activation: swish
[2019-07-25 20:31:07] [config] transformer-aan-depth: 2
[2019-07-25 20:31:07] [config] transformer-aan-nogate: false
[2019-07-25 20:31:07] [config] transformer-decoder-autoreg: self-attention
[2019-07-25 20:31:07] [config] transformer-dim-aan: 2048
[2019-07-25 20:31:07] [config] transformer-dim-ffn: 2048
[2019-07-25 20:31:07] [config] transformer-dropout: 0
[2019-07-25 20:31:07] [config] transformer-dropout-attention: 0
[2019-07-25 20:31:07] [config] transformer-dropout-ffn: 0
[2019-07-25 20:31:07] [config] transformer-ffn-activation: swish
[2019-07-25 20:31:07] [config] transformer-ffn-depth: 2
[2019-07-25 20:31:07] [config] transformer-guided-alignment-layer: last
[2019-07-25 20:31:07] [config] transformer-heads: 8
[2019-07-25 20:31:07] [config] transformer-no-projection: false
[2019-07-25 20:31:07] [config] transformer-postprocess: dan
[2019-07-25 20:31:07] [config] transformer-postprocess-emb: d
[2019-07-25 20:31:07] [config] transformer-preprocess: ""
[2019-07-25 20:31:07] [config] transformer-tied-layers:
[2019-07-25 20:31:07] [config]   []
[2019-07-25 20:31:07] [config] transformer-train-position-embeddings: false
[2019-07-25 20:31:07] [config] type: amun
[2019-07-25 20:31:07] [config] ulr: false
[2019-07-25 20:31:07] [config] ulr-dim-emb: 0
[2019-07-25 20:31:07] [config] ulr-dropout: 0
[2019-07-25 20:31:07] [config] ulr-keys-vectors: ""
[2019-07-25 20:31:07] [config] ulr-query-vectors: ""
[2019-07-25 20:31:07] [config] ulr-softmax-temperature: 1
[2019-07-25 20:31:07] [config] ulr-trainable-transformation: false
[2019-07-25 20:31:07] [config] valid-freq: 20000
[2019-07-25 20:31:07] [config] valid-log: ../experiments/10M_bicleaner_st_lm_w3000/model/valid.log
[2019-07-25 20:31:07] [config] valid-max-length: 1000
[2019-07-25 20:31:07] [config] valid-metrics:
[2019-07-25 20:31:07] [config]   - cross-entropy
[2019-07-25 20:31:07] [config]   - perplexity
[2019-07-25 20:31:07] [config]   - translation
[2019-07-25 20:31:07] [config] valid-mini-batch: 8
[2019-07-25 20:31:07] [config] valid-script-path: ../experiments/10M_bicleaner_st_lm_w3000/score-dev.sh
[2019-07-25 20:31:07] [config] valid-sets:
[2019-07-25 20:31:07] [config]   - ../experiments/10M_bicleaner_st_lm_w3000/data/dev.bpe.de
[2019-07-25 20:31:07] [config]   - ../experiments/10M_bicleaner_st_lm_w3000/data/dev.bpe.en
[2019-07-25 20:31:07] [config] valid-translation-output: ../experiments/10M_bicleaner_st_lm_w3000/model/dev.out
[2019-07-25 20:31:07] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-25 20:31:07] [config] vocabs:
[2019-07-25 20:31:07] [config]   - ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.de.json
[2019-07-25 20:31:07] [config]   - ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.en.json
[2019-07-25 20:31:07] [config] word-penalty: 0
[2019-07-25 20:31:07] [config] workspace: 3000
[2019-07-25 20:31:07] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-25 20:31:07] Using synchronous training
[2019-07-25 20:31:07] [data] Loading vocabulary from JSON/Yaml file ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.de.json
[2019-07-25 20:31:07] [data] Using unused word id eos for 0
[2019-07-25 20:31:07] [data] Using unused word id UNK for 1
[2019-07-25 20:31:07] [data] Setting vocabulary size for input 0 to 50000
[2019-07-25 20:31:07] [data] Loading vocabulary from JSON/Yaml file ../experiments/10M_bicleaner_st_lm_w3000/data/train.bpe.en.json
[2019-07-25 20:31:08] [data] Using unused word id eos for 0
[2019-07-25 20:31:08] [data] Using unused word id UNK for 1
[2019-07-25 20:31:08] [data] Setting vocabulary size for input 1 to 50000
[2019-07-25 20:31:08] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-25 20:31:08] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-25 20:31:09] [memory] Extending reserved space to 3072 MB (device gpu5)
[2019-07-25 20:31:09] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-25 20:31:09] [comm] NCCLCommunicator constructed successfully.
[2019-07-25 20:31:09] [training] Using 1 GPUs
[2019-07-25 20:31:09] [memory] Reserving 422 MB, device gpu5
[2019-07-25 20:31:09] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-25 20:31:09] [memory] Reserving 422 MB, device gpu5
[2019-07-25 20:31:12] [batching] Done. Typical MB size is 4042 target words
[2019-07-25 20:31:12] [memory] Extending reserved space to 3072 MB (device gpu5)
[2019-07-25 20:31:12] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-25 20:31:12] [comm] NCCLCommunicator constructed successfully.
[2019-07-25 20:31:12] [training] Using 1 GPUs
[2019-07-25 20:31:12] Loading model from ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-25 20:31:15] Loading Adam parameters from ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-25 20:31:20] [memory] Reserving 844 MB, device gpu5
[2019-07-25 20:31:21] [training] Model reloaded from ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-25 20:31:21] [data] Restoring the corpus state to epoch 9, batch 20000
[2019-07-25 20:31:21] [data] Shuffling data
[2019-07-25 20:31:22] [data] Done reading 632833 sentences
[2019-07-25 20:31:24] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 20:31:27] Training started
[2019-07-25 20:31:27] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-07-25 20:31:27] [memory] Reserving 422 MB, device gpu5
[2019-07-25 20:31:27] [memory] Reserving 422 MB, device gpu5
[2019-07-25 20:31:27] Loading model from ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-25 20:31:31] [memory] Reserving 422 MB, device cpu0
[2019-07-25 20:31:31] [memory] Reserving 422 MB, device gpu5
[2019-07-25 20:36:37] Ep. 9 : Up. 22000 : Sen. 495,937 : Cost 33.95201492 : Time 329.21s : 15772.62 words/s
[2019-07-25 20:40:43] Seen 708491 samples
[2019-07-25 20:40:43] Starting epoch 10
[2019-07-25 20:40:43] [data] Shuffling data
[2019-07-25 20:40:43] [data] Done reading 632833 sentences
[2019-07-25 20:40:46] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 20:41:47] Ep. 10 : Up. 24000 : Sen. 52,545 : Cost 33.84596252 : Time 310.39s : 16797.86 words/s
[2019-07-25 20:46:54] Ep. 10 : Up. 26000 : Sen. 317,852 : Cost 32.46479797 : Time 306.43s : 16998.98 words/s
[2019-07-25 20:52:01] Ep. 10 : Up. 28000 : Sen. 583,981 : Cost 32.25442505 : Time 307.03s : 17008.45 words/s
[2019-07-25 20:52:19] Seen 599177 samples
[2019-07-25 20:52:19] Starting epoch 11
[2019-07-25 20:52:19] [data] Shuffling data
[2019-07-25 20:52:19] [data] Done reading 632833 sentences
[2019-07-25 20:52:21] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 20:57:11] Ep. 11 : Up. 30000 : Sen. 250,246 : Cost 31.08699799 : Time 310.44s : 16818.22 words/s
[2019-07-25 21:02:18] Ep. 11 : Up. 32000 : Sen. 515,821 : Cost 30.76337051 : Time 306.93s : 16974.99 words/s
[2019-07-25 21:03:55] Seen 599177 samples
[2019-07-25 21:03:55] Starting epoch 12
[2019-07-25 21:03:55] [data] Shuffling data
[2019-07-25 21:03:55] [data] Done reading 632833 sentences
[2019-07-25 21:03:57] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 21:07:27] Ep. 12 : Up. 34000 : Sen. 181,375 : Cost 30.16102219 : Time 308.61s : 16872.29 words/s
[2019-07-25 21:12:34] Ep. 12 : Up. 36000 : Sen. 446,517 : Cost 29.77954292 : Time 306.84s : 16977.97 words/s
[2019-07-25 21:15:30] Seen 599177 samples
[2019-07-25 21:15:30] Starting epoch 13
[2019-07-25 21:15:30] [data] Shuffling data
[2019-07-25 21:15:31] [data] Done reading 632833 sentences
[2019-07-25 21:15:33] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 21:17:44] Ep. 13 : Up. 38000 : Sen. 112,076 : Cost 28.89665222 : Time 310.93s : 16724.91 words/s
[2019-07-25 21:22:54] Ep. 13 : Up. 40000 : Sen. 376,694 : Cost 28.58542442 : Time 309.16s : 16808.35 words/s
[2019-07-25 21:22:54] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-25 21:22:59] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.iter40000.npz
[2019-07-25 21:23:01] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-25 21:23:07] Saving Adam parameters to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-25 21:23:26] [valid] Ep. 13 : Up. 40000 : cross-entropy : 63.9866 : new best
[2019-07-25 21:23:33] [valid] Ep. 13 : Up. 40000 : perplexity : 12.2846 : new best
[2019-07-25 21:24:26] [valid] Ep. 13 : Up. 40000 : translation : 24.03 : new best
[2019-07-25 21:28:48] Seen 599177 samples
[2019-07-25 21:28:48] Starting epoch 14
[2019-07-25 21:28:48] [data] Shuffling data
[2019-07-25 21:28:49] [data] Done reading 632833 sentences
[2019-07-25 21:28:51] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 21:29:42] Ep. 14 : Up. 42000 : Sen. 42,983 : Cost 28.34178352 : Time 408.26s : 12757.88 words/s
[2019-07-25 21:34:52] Ep. 14 : Up. 44000 : Sen. 307,540 : Cost 27.38850021 : Time 310.36s : 16752.52 words/s
[2019-07-25 21:40:03] Ep. 14 : Up. 46000 : Sen. 572,636 : Cost 27.75046539 : Time 310.80s : 16758.18 words/s
[2019-07-25 21:40:34] Seen 599177 samples
[2019-07-25 21:40:34] Starting epoch 15
[2019-07-25 21:40:34] [data] Shuffling data
[2019-07-25 21:40:34] [data] Done reading 632833 sentences
[2019-07-25 21:40:37] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 21:45:19] Ep. 15 : Up. 48000 : Sen. 238,970 : Cost 26.49023438 : Time 315.85s : 16490.74 words/s
[2019-07-25 21:50:30] Ep. 15 : Up. 50000 : Sen. 504,269 : Cost 26.54876709 : Time 311.16s : 16765.89 words/s
[2019-07-25 21:52:21] Seen 599177 samples
[2019-07-25 21:52:21] Starting epoch 16
[2019-07-25 21:52:21] [data] Shuffling data
[2019-07-25 21:52:21] [data] Done reading 632833 sentences
[2019-07-25 21:52:24] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 21:55:43] Ep. 16 : Up. 52000 : Sen. 169,691 : Cost 26.01298714 : Time 312.86s : 16601.32 words/s
[2019-07-25 22:00:53] Ep. 16 : Up. 54000 : Sen. 434,942 : Cost 25.75267220 : Time 310.36s : 16775.79 words/s
[2019-07-25 22:04:06] Seen 599177 samples
[2019-07-25 22:04:06] Starting epoch 17
[2019-07-25 22:04:06] [data] Shuffling data
[2019-07-25 22:04:06] [data] Done reading 632833 sentences
[2019-07-25 22:04:09] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 22:06:07] Ep. 17 : Up. 56000 : Sen. 101,307 : Cost 25.47746086 : Time 314.11s : 16591.23 words/s
[2019-07-25 22:11:19] Ep. 17 : Up. 58000 : Sen. 365,593 : Cost 25.20202637 : Time 311.48s : 16699.71 words/s
[2019-07-25 22:15:52] Seen 599177 samples
[2019-07-25 22:15:52] Starting epoch 18
[2019-07-25 22:15:52] [data] Shuffling data
[2019-07-25 22:15:52] [data] Done reading 632833 sentences
[2019-07-25 22:15:55] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 22:16:32] Ep. 18 : Up. 60000 : Sen. 31,922 : Cost 25.33261871 : Time 313.55s : 16625.51 words/s
[2019-07-25 22:16:32] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-25 22:16:38] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.iter60000.npz
[2019-07-25 22:16:40] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-25 22:16:46] Saving Adam parameters to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-25 22:17:05] [valid] Ep. 18 : Up. 60000 : cross-entropy : 62.349 : new best
[2019-07-25 22:17:11] [valid] Ep. 18 : Up. 60000 : perplexity : 11.5207 : new best
[2019-07-25 22:18:04] [valid] Ep. 18 : Up. 60000 : translation : 24.52 : new best
[2019-07-25 22:23:18] Ep. 18 : Up. 62000 : Sen. 297,407 : Cost 24.36694908 : Time 405.69s : 12875.87 words/s
[2019-07-25 22:28:29] Ep. 18 : Up. 64000 : Sen. 562,826 : Cost 24.49526024 : Time 310.54s : 16761.78 words/s
[2019-07-25 22:29:12] Seen 599177 samples
[2019-07-25 22:29:12] Starting epoch 19
[2019-07-25 22:29:12] [data] Shuffling data
[2019-07-25 22:29:12] [data] Done reading 632833 sentences
[2019-07-25 22:29:15] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 22:33:45] Ep. 19 : Up. 66000 : Sen. 228,849 : Cost 23.82522392 : Time 316.17s : 16483.57 words/s
[2019-07-25 22:38:57] Ep. 19 : Up. 68000 : Sen. 494,727 : Cost 23.80131912 : Time 311.79s : 16753.44 words/s
[2019-07-25 22:41:00] Seen 599177 samples
[2019-07-25 22:41:00] Starting epoch 20
[2019-07-25 22:41:00] [data] Shuffling data
[2019-07-25 22:41:00] [data] Done reading 632833 sentences
[2019-07-25 22:41:03] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 22:44:10] Ep. 20 : Up. 70000 : Sen. 159,164 : Cost 23.31058884 : Time 313.38s : 16530.58 words/s
[2019-07-25 22:49:22] Ep. 20 : Up. 72000 : Sen. 424,647 : Cost 22.96087074 : Time 311.57s : 16750.94 words/s
[2019-07-25 22:52:45] Seen 599177 samples
[2019-07-25 22:52:45] Starting epoch 21
[2019-07-25 22:52:45] [data] Shuffling data
[2019-07-25 22:52:46] [data] Done reading 632833 sentences
[2019-07-25 22:52:49] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 22:54:34] Ep. 21 : Up. 74000 : Sen. 90,076 : Cost 22.84457207 : Time 312.46s : 16589.37 words/s
[2019-07-25 22:59:46] Ep. 21 : Up. 76000 : Sen. 355,887 : Cost 22.54679298 : Time 311.63s : 16771.51 words/s
[2019-07-25 23:04:32] Seen 599177 samples
[2019-07-25 23:04:32] Starting epoch 22
[2019-07-25 23:04:32] [data] Shuffling data
[2019-07-25 23:04:32] [data] Done reading 632833 sentences
[2019-07-25 23:04:35] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 23:05:02] Ep. 22 : Up. 78000 : Sen. 23,199 : Cost 22.83644104 : Time 316.68s : 16524.89 words/s
[2019-07-25 23:10:15] Ep. 22 : Up. 80000 : Sen. 288,853 : Cost 22.10548592 : Time 312.99s : 16693.04 words/s
[2019-07-25 23:10:15] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-25 23:10:21] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.iter80000.npz
[2019-07-25 23:10:24] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-25 23:10:30] Saving Adam parameters to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-25 23:10:49] [valid] Ep. 22 : Up. 80000 : cross-entropy : 62.208 : new best
[2019-07-25 23:10:56] [valid] Ep. 22 : Up. 80000 : perplexity : 11.4572 : new best
[2019-07-25 23:11:48] [valid] Ep. 22 : Up. 80000 : translation : 24.73 : new best
[2019-07-25 23:17:00] Ep. 22 : Up. 82000 : Sen. 553,261 : Cost 22.38785362 : Time 404.69s : 12836.79 words/s
[2019-07-25 23:17:54] Seen 599177 samples
[2019-07-25 23:17:54] Starting epoch 23
[2019-07-25 23:17:54] [data] Shuffling data
[2019-07-25 23:17:54] [data] Done reading 632833 sentences
[2019-07-25 23:17:57] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 23:22:13] Ep. 23 : Up. 84000 : Sen. 218,358 : Cost 21.48388100 : Time 313.09s : 16545.73 words/s
[2019-07-25 23:27:24] Ep. 23 : Up. 86000 : Sen. 482,818 : Cost 21.92623901 : Time 310.53s : 16736.63 words/s
[2019-07-25 23:29:40] Seen 599177 samples
[2019-07-25 23:29:40] Starting epoch 24
[2019-07-25 23:29:40] [data] Shuffling data
[2019-07-25 23:29:41] [data] Done reading 632833 sentences
[2019-07-25 23:29:44] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 23:32:40] Ep. 24 : Up. 88000 : Sen. 149,878 : Cost 21.45966339 : Time 316.27s : 16538.79 words/s
[2019-07-25 23:37:52] Ep. 24 : Up. 90000 : Sen. 415,370 : Cost 21.30994034 : Time 311.84s : 16719.68 words/s
[2019-07-25 23:41:28] Seen 599177 samples
[2019-07-25 23:41:28] Starting epoch 25
[2019-07-25 23:41:28] [data] Shuffling data
[2019-07-25 23:41:29] [data] Done reading 632833 sentences
[2019-07-25 23:41:32] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 23:43:07] Ep. 25 : Up. 92000 : Sen. 81,340 : Cost 21.19206429 : Time 315.70s : 16505.18 words/s
[2019-07-25 23:48:18] Ep. 25 : Up. 94000 : Sen. 345,678 : Cost 20.67257881 : Time 310.81s : 16699.48 words/s
[2019-07-25 23:53:16] Seen 599177 samples
[2019-07-25 23:53:16] Starting epoch 26
[2019-07-25 23:53:16] [data] Shuffling data
[2019-07-25 23:53:17] [data] Done reading 632833 sentences
[2019-07-25 23:53:19] [data] Done shuffling 632833 sentences to temp files
[2019-07-25 23:53:33] Ep. 26 : Up. 96000 : Sen. 11,016 : Cost 21.11217880 : Time 314.34s : 16538.18 words/s
[2019-07-25 23:58:44] Ep. 26 : Up. 98000 : Sen. 276,656 : Cost 19.94337273 : Time 311.58s : 16727.38 words/s
[2019-07-26 00:03:56] Ep. 26 : Up. 100000 : Sen. 542,250 : Cost 20.74507523 : Time 312.16s : 16708.07 words/s
[2019-07-26 00:03:56] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-26 00:04:02] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.iter100000.npz
[2019-07-26 00:04:04] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-26 00:04:10] Saving Adam parameters to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-26 00:04:28] [valid] Ep. 26 : Up. 100000 : cross-entropy : 62.7516 : stalled 1 times (last best: 62.208)
[2019-07-26 00:04:34] [valid] Ep. 26 : Up. 100000 : perplexity : 11.704 : stalled 1 times (last best: 11.4572)
[2019-07-26 00:05:27] [valid] Ep. 26 : Up. 100000 : translation : 24.56 : stalled 1 times (last best: 24.73)
[2019-07-26 00:06:36] Seen 599177 samples
[2019-07-26 00:06:36] Starting epoch 27
[2019-07-26 00:06:37] [data] Shuffling data
[2019-07-26 00:06:37] [data] Done reading 632833 sentences
[2019-07-26 00:06:40] [data] Done shuffling 632833 sentences to temp files
[2019-07-26 00:10:43] Ep. 27 : Up. 102000 : Sen. 207,795 : Cost 19.80501938 : Time 406.73s : 12773.12 words/s
[2019-07-26 00:15:55] Ep. 27 : Up. 104000 : Sen. 472,502 : Cost 20.08513832 : Time 311.63s : 16727.65 words/s
[2019-07-26 00:18:23] Seen 599177 samples
[2019-07-26 00:18:23] Starting epoch 28
[2019-07-26 00:18:23] [data] Shuffling data
[2019-07-26 00:18:24] [data] Done reading 632833 sentences
[2019-07-26 00:18:27] [data] Done shuffling 632833 sentences to temp files
[2019-07-26 00:21:09] Ep. 28 : Up. 106000 : Sen. 138,504 : Cost 19.68128014 : Time 314.09s : 16538.76 words/s
[2019-07-26 00:26:20] Ep. 28 : Up. 108000 : Sen. 403,065 : Cost 19.79819107 : Time 311.35s : 16719.78 words/s
[2019-07-26 00:30:11] Seen 599177 samples
[2019-07-26 00:30:11] Starting epoch 29
[2019-07-26 00:30:11] [data] Shuffling data
[2019-07-26 00:30:11] [data] Done reading 632833 sentences
[2019-07-26 00:30:14] [data] Done shuffling 632833 sentences to temp files
[2019-07-26 00:31:36] Ep. 29 : Up. 110000 : Sen. 69,379 : Cost 19.79274750 : Time 315.71s : 16518.00 words/s
[2019-07-26 00:36:46] Ep. 29 : Up. 112000 : Sen. 332,800 : Cost 19.21086121 : Time 310.26s : 16671.42 words/s
[2019-07-26 00:41:58] Ep. 29 : Up. 114000 : Sen. 598,329 : Cost 19.65030670 : Time 311.42s : 16756.39 words/s
[2019-07-26 00:41:59] Seen 599177 samples
[2019-07-26 00:41:59] Starting epoch 30
[2019-07-26 00:41:59] [data] Shuffling data
[2019-07-26 00:41:59] [data] Done reading 632833 sentences
[2019-07-26 00:42:02] [data] Done shuffling 632833 sentences to temp files
[2019-07-26 00:47:12] Ep. 30 : Up. 116000 : Sen. 265,009 : Cost 18.41438293 : Time 314.59s : 16557.38 words/s
[2019-07-26 00:52:22] Ep. 30 : Up. 118000 : Sen. 528,601 : Cost 19.44733620 : Time 310.05s : 16723.23 words/s
[2019-07-26 00:53:45] Seen 599177 samples
[2019-07-26 00:53:45] Starting epoch 31
[2019-07-26 00:53:45] [data] Shuffling data
[2019-07-26 00:53:46] [data] Done reading 632833 sentences
[2019-07-26 00:53:48] [data] Done shuffling 632833 sentences to temp files
[2019-07-26 00:57:37] Ep. 31 : Up. 120000 : Sen. 194,118 : Cost 18.78331375 : Time 314.96s : 16551.81 words/s
[2019-07-26 00:57:37] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-26 00:57:43] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.iter120000.npz
[2019-07-26 00:57:45] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-26 00:57:51] Saving Adam parameters to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-26 00:58:10] [valid] Ep. 31 : Up. 120000 : cross-entropy : 63.7419 : stalled 2 times (last best: 62.208)
[2019-07-26 00:58:17] [valid] Ep. 31 : Up. 120000 : perplexity : 12.1673 : stalled 2 times (last best: 11.4572)
[2019-07-26 00:59:10] [valid] Ep. 31 : Up. 120000 : translation : 24.5 : stalled 2 times (last best: 24.73)
[2019-07-26 01:04:23] Ep. 31 : Up. 122000 : Sen. 458,843 : Cost 18.87109947 : Time 406.15s : 12806.42 words/s
[2019-07-26 01:07:08] Seen 599177 samples
[2019-07-26 01:07:08] Starting epoch 32
[2019-07-26 01:07:08] [data] Shuffling data
[2019-07-26 01:07:08] [data] Done reading 632833 sentences
[2019-07-26 01:07:11] [data] Done shuffling 632833 sentences to temp files
[2019-07-26 01:09:39] Ep. 32 : Up. 124000 : Sen. 125,441 : Cost 18.44925117 : Time 316.11s : 16481.13 words/s
[2019-07-26 01:14:52] Ep. 32 : Up. 126000 : Sen. 391,228 : Cost 18.19243240 : Time 312.38s : 16701.03 words/s
[2019-07-26 01:18:57] Seen 599177 samples
[2019-07-26 01:18:57] Starting epoch 33
[2019-07-26 01:18:57] [data] Shuffling data
[2019-07-26 01:18:57] [data] Done reading 632833 sentences
[2019-07-26 01:19:00] [data] Done shuffling 632833 sentences to temp files
[2019-07-26 01:20:07] Ep. 33 : Up. 128000 : Sen. 56,378 : Cost 18.51364136 : Time 314.83s : 16513.12 words/s
[2019-07-26 01:25:19] Ep. 33 : Up. 130000 : Sen. 320,852 : Cost 18.20118523 : Time 312.11s : 16626.70 words/s
[2019-07-26 01:30:31] Ep. 33 : Up. 132000 : Sen. 586,156 : Cost 18.58204269 : Time 312.18s : 16704.69 words/s
[2019-07-26 01:30:46] Seen 599177 samples
[2019-07-26 01:30:46] Starting epoch 34
[2019-07-26 01:30:46] [data] Shuffling data
[2019-07-26 01:30:47] [data] Done reading 632833 sentences
[2019-07-26 01:30:49] [data] Done shuffling 632833 sentences to temp files
[2019-07-26 01:35:46] Ep. 34 : Up. 134000 : Sen. 251,463 : Cost 17.68949127 : Time 314.84s : 16517.70 words/s
[2019-07-26 01:40:57] Ep. 34 : Up. 136000 : Sen. 516,361 : Cost 18.11670685 : Time 311.48s : 16704.83 words/s
[2019-07-26 01:42:35] Seen 599177 samples
[2019-07-26 01:42:35] Starting epoch 35
[2019-07-26 01:42:35] [data] Shuffling data
[2019-07-26 01:42:35] [data] Done reading 632833 sentences
[2019-07-26 01:42:38] [data] Done shuffling 632833 sentences to temp files
[2019-07-26 01:46:13] Ep. 35 : Up. 138000 : Sen. 182,378 : Cost 17.62128067 : Time 315.78s : 16482.25 words/s
[2019-07-26 01:51:26] Ep. 35 : Up. 140000 : Sen. 447,678 : Cost 17.83567619 : Time 312.94s : 16652.82 words/s
[2019-07-26 01:51:26] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-26 01:51:32] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.iter140000.npz
[2019-07-26 01:51:34] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-26 01:51:40] Saving Adam parameters to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-26 01:52:00] [valid] Ep. 35 : Up. 140000 : cross-entropy : 64.9782 : stalled 3 times (last best: 62.208)
[2019-07-26 01:52:06] [valid] Ep. 35 : Up. 140000 : perplexity : 12.7715 : stalled 3 times (last best: 11.4572)
[2019-07-26 01:52:59] [valid] Ep. 35 : Up. 140000 : translation : 24.32 : stalled 3 times (last best: 24.73)
[2019-07-26 01:55:59] Seen 599177 samples
[2019-07-26 01:55:59] Starting epoch 36
[2019-07-26 01:55:59] [data] Shuffling data
[2019-07-26 01:55:59] [data] Done reading 632833 sentences
[2019-07-26 01:56:02] [data] Done shuffling 632833 sentences to temp files
[2019-07-26 01:58:15] Ep. 36 : Up. 142000 : Sen. 113,582 : Cost 17.49855232 : Time 408.83s : 12713.21 words/s
[2019-07-26 02:03:27] Ep. 36 : Up. 144000 : Sen. 378,333 : Cost 17.32307243 : Time 312.03s : 16697.08 words/s
[2019-07-26 02:07:46] Seen 599177 samples
[2019-07-26 02:07:46] Starting epoch 37
[2019-07-26 02:07:46] [data] Shuffling data
[2019-07-26 02:07:47] [data] Done reading 632833 sentences
[2019-07-26 02:07:49] [data] Done shuffling 632833 sentences to temp files
[2019-07-26 02:08:41] Ep. 37 : Up. 146000 : Sen. 44,338 : Cost 17.43528557 : Time 314.62s : 16535.65 words/s
[2019-07-26 02:13:52] Ep. 37 : Up. 148000 : Sen. 307,761 : Cost 17.13770294 : Time 310.75s : 16710.21 words/s
[2019-07-26 02:19:04] Ep. 37 : Up. 150000 : Sen. 573,847 : Cost 17.45781708 : Time 311.34s : 16745.44 words/s
[2019-07-26 02:19:33] Seen 599177 samples
[2019-07-26 02:19:33] Starting epoch 38
[2019-07-26 02:19:33] [data] Shuffling data
[2019-07-26 02:19:34] [data] Done reading 632833 sentences
[2019-07-26 02:19:37] [data] Done shuffling 632833 sentences to temp files
[2019-07-26 02:24:19] Ep. 38 : Up. 152000 : Sen. 240,139 : Cost 16.65561104 : Time 315.44s : 16528.65 words/s
[2019-07-26 02:29:30] Ep. 38 : Up. 154000 : Sen. 504,416 : Cost 17.16255760 : Time 310.86s : 16691.07 words/s
[2019-07-26 02:31:21] Seen 599177 samples
[2019-07-26 02:31:21] Starting epoch 39
[2019-07-26 02:31:21] [data] Shuffling data
[2019-07-26 02:31:22] [data] Done reading 632833 sentences
[2019-07-26 02:31:24] [data] Done shuffling 632833 sentences to temp files
[2019-07-26 02:34:44] Ep. 39 : Up. 156000 : Sen. 169,986 : Cost 16.65386963 : Time 313.99s : 16577.38 words/s
[2019-07-26 02:39:54] Ep. 39 : Up. 158000 : Sen. 433,991 : Cost 16.88920593 : Time 310.09s : 16726.20 words/s
[2019-07-26 02:43:08] Seen 599177 samples
[2019-07-26 02:43:08] Starting epoch 40
[2019-07-26 02:43:08] [data] Shuffling data
[2019-07-26 02:43:09] [data] Done reading 632833 sentences
[2019-07-26 02:43:11] [data] Done shuffling 632833 sentences to temp files
[2019-07-26 02:45:09] Ep. 40 : Up. 160000 : Sen. 99,717 : Cost 16.76170731 : Time 315.18s : 16486.79 words/s
[2019-07-26 02:45:09] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-26 02:45:15] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.iter160000.npz
[2019-07-26 02:45:17] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-26 02:45:23] Saving Adam parameters to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-26 02:45:43] [valid] Ep. 40 : Up. 160000 : cross-entropy : 66.296 : stalled 4 times (last best: 62.208)
[2019-07-26 02:45:49] [valid] Ep. 40 : Up. 160000 : perplexity : 13.4486 : stalled 4 times (last best: 11.4572)
[2019-07-26 02:46:42] [valid] Ep. 40 : Up. 160000 : translation : 24.23 : stalled 4 times (last best: 24.73)
[2019-07-26 02:51:58] Ep. 40 : Up. 162000 : Sen. 365,603 : Cost 16.44593811 : Time 408.92s : 12785.88 words/s
[2019-07-26 02:56:32] Seen 599177 samples
[2019-07-26 02:56:32] Starting epoch 41
[2019-07-26 02:56:32] [data] Shuffling data
[2019-07-26 02:56:33] [data] Done reading 632833 sentences
[2019-07-26 02:56:35] [data] Done shuffling 632833 sentences to temp files
[2019-07-26 02:57:13] Ep. 41 : Up. 164000 : Sen. 31,922 : Cost 16.64254379 : Time 314.98s : 16541.78 words/s
[2019-07-26 03:02:25] Ep. 41 : Up. 166000 : Sen. 298,259 : Cost 16.27044106 : Time 311.95s : 16765.73 words/s
[2019-07-26 03:07:36] Ep. 41 : Up. 168000 : Sen. 562,647 : Cost 16.54651642 : Time 310.63s : 16732.80 words/s
[2019-07-26 03:08:19] Seen 599177 samples
[2019-07-26 03:08:19] Starting epoch 42
[2019-07-26 03:08:19] [data] Shuffling data
[2019-07-26 03:08:19] [data] Done reading 632833 sentences
[2019-07-26 03:08:22] [data] Done shuffling 632833 sentences to temp files
[2019-07-26 03:12:52] Ep. 42 : Up. 170000 : Sen. 228,631 : Cost 15.93285370 : Time 316.48s : 16467.43 words/s
[2019-07-26 03:18:03] Ep. 42 : Up. 172000 : Sen. 493,509 : Cost 16.33451271 : Time 311.03s : 16715.30 words/s
[2019-07-26 03:20:07] Seen 599177 samples
[2019-07-26 03:20:07] Starting epoch 43
[2019-07-26 03:20:07] [data] Shuffling data
[2019-07-26 03:20:07] [data] Done reading 632833 sentences
[2019-07-26 03:20:10] [data] Done shuffling 632833 sentences to temp files
[2019-07-26 03:23:17] Ep. 43 : Up. 174000 : Sen. 159,464 : Cost 15.92021179 : Time 314.38s : 16562.83 words/s
[2019-07-26 03:28:30] Ep. 43 : Up. 176000 : Sen. 424,784 : Cost 15.95936966 : Time 312.65s : 16690.70 words/s
[2019-07-26 03:31:54] Seen 599177 samples
[2019-07-26 03:31:54] Starting epoch 44
[2019-07-26 03:31:54] [data] Shuffling data
[2019-07-26 03:31:55] [data] Done reading 632833 sentences
[2019-07-26 03:31:58] [data] Done shuffling 632833 sentences to temp files
[2019-07-26 03:33:45] Ep. 44 : Up. 178000 : Sen. 91,297 : Cost 16.08126259 : Time 314.76s : 16550.73 words/s
[2019-07-26 03:38:56] Ep. 44 : Up. 180000 : Sen. 355,552 : Cost 15.78930569 : Time 311.53s : 16686.81 words/s
[2019-07-26 03:38:56] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-26 03:39:02] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.iter180000.npz
[2019-07-26 03:39:04] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-26 03:39:10] Saving Adam parameters to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
[2019-07-26 03:39:30] [valid] Ep. 44 : Up. 180000 : cross-entropy : 67.6916 : stalled 5 times (last best: 62.208)
[2019-07-26 03:39:37] [valid] Ep. 44 : Up. 180000 : perplexity : 14.2048 : stalled 5 times (last best: 11.4572)
[2019-07-26 03:40:29] [valid] Ep. 44 : Up. 180000 : translation : 23.99 : stalled 5 times (last best: 24.73)
[2019-07-26 03:40:32] Training finished
[2019-07-26 03:40:36] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz.orig.npz
[2019-07-26 03:40:42] Saving model to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz
[2019-07-26 03:40:48] Saving Adam parameters to ../experiments/10M_bicleaner_st_lm_w3000/model/model.npz.optimizer.npz
