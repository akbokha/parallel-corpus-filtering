MT evaluation scorer began on 2019 Aug 10 at 10:56:20
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/10M_bicleaner_v1.1_+_bic1.0_x_biced_0.5_x_dcce/data/KDE4.de.sgm -r ../experiments/10M_bicleaner_v1.1_+_bic1.0_x_biced_0.5_x_dcce/data/KDE4.en.sgm -t ../experiments/10M_bicleaner_v1.1_+_bic1.0_x_biced_0.5_x_dcce/data/KDE4.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 3000 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 0.944625661965441 (120760/127839), penalty (log): -0.0586204041073204
NIST score = 6.2126  BLEU score = 0.2005 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.5943   1.2623   0.2834   0.0601   0.0125   0.0032   0.0012   0.0007   0.0003  "Edinburgh"

 BLEU:  0.5668   0.2693   0.1510   0.0886   0.0533   0.0332   0.0217   0.0147   0.0104  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.5943   5.8566   6.1400   6.2001   6.2126   6.2158   6.2170   6.2176   6.2179  "Edinburgh"

 BLEU:  0.5345   0.3685   0.2684   0.2005   0.1520   0.1168   0.0911   0.0720   0.0577  "Edinburgh"
MT evaluation scorer ended on 2019 Aug 10 at 10:56:53
