MT evaluation scorer began on 2019 Aug 11 at 10:45:09
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/10M_bicleaner_v1.1_+_bic1.1_arpa_x_biced_0.5/data/KDE4.de.sgm -r ../experiments/10M_bicleaner_v1.1_+_bic1.1_arpa_x_biced_0.5/data/KDE4.en.sgm -t ../experiments/10M_bicleaner_v1.1_+_bic1.1_arpa_x_biced_0.5/data/KDE4.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 3000 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 0.914071605691534 (116854/127839), penalty (log): -0.0940061957656564
NIST score = 6.2654  BLEU score = 0.2009 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.6380   1.2722   0.2830   0.0599   0.0123   0.0037   0.0017   0.0013   0.0007  "Edinburgh"

 BLEU:  0.5821   0.2794   0.1575   0.0926   0.0569   0.0369   0.0250   0.0178   0.0129  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.6380   5.9102   6.1932   6.2531   6.2654   6.2691   6.2708   6.2721   6.2729  "Edinburgh"

 BLEU:  0.5298   0.3671   0.2683   0.2009   0.1532   0.1189   0.0939   0.0754   0.0613  "Edinburgh"
MT evaluation scorer ended on 2019 Aug 11 at 10:45:45
