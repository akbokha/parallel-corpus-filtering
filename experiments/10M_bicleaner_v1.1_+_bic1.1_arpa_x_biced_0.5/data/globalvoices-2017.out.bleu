MT evaluation scorer began on 2019 Aug 11 at 10:40:03
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/10M_bicleaner_v1.1_+_bic1.1_arpa_x_biced_0.5/data/globalvoices-2017.de.sgm -r ../experiments/10M_bicleaner_v1.1_+_bic1.1_arpa_x_biced_0.5/data/globalvoices-2017.en.sgm -t ../experiments/10M_bicleaner_v1.1_+_bic1.1_arpa_x_biced_0.5/data/globalvoices-2017.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 3000 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 1.03836227497212 (65178/62770), penalty (log): 0
NIST score = 6.5689  BLEU score = 0.2305 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  5.0461   1.2899   0.2086   0.0207   0.0036   0.0008   0.0003   0.0001   0.0000  "Edinburgh"

 BLEU:  0.5500   0.2877   0.1700   0.1049   0.0661   0.0422   0.0271   0.0177   0.0115  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  5.0461   6.3360   6.5446   6.5653   6.5689   6.5697   6.5700   6.5701   6.5702  "Edinburgh"

 BLEU:  0.5500   0.3978   0.2997   0.2305   0.1796   0.1410   0.1114   0.0885   0.0706  "Edinburgh"
MT evaluation scorer ended on 2019 Aug 11 at 10:40:22
