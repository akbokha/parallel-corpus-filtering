MT evaluation scorer began on 2019 Aug 2 at 23:24:24
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/10M_bicleaner_v1.1_+_ced_0.25_x_bic1.1_w3000/data/EMEA.de.sgm -r ../experiments/10M_bicleaner_v1.1_+_ced_0.25_x_bic1.1_w3000/data/EMEA.en.sgm -t ../experiments/10M_bicleaner_v1.1_+_ced_0.25_x_bic1.1_w3000/data/EMEA.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 3000 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 0.968881694621975 (104148/107493), penalty (log): -0.032117755501786
NIST score = 7.0321  BLEU score = 0.2684 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  5.2178   1.4224   0.3005   0.0711   0.0203   0.0081   0.0037   0.0021   0.0019  "Edinburgh"

 BLEU:  0.6027   0.3375   0.2115   0.1372   0.0918   0.0626   0.0434   0.0318   0.0241  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  5.2178   6.6402   6.9407   7.0118   7.0321   7.0402   7.0439   7.0460   7.0480  "Edinburgh"

 BLEU:  0.5837   0.4368   0.3393   0.2684   0.2152   0.1742   0.1422   0.1174   0.0981  "Edinburgh"
MT evaluation scorer ended on 2019 Aug 2 at 23:24:51
