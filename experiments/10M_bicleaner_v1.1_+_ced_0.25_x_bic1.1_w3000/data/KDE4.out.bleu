MT evaluation scorer began on 2019 Aug 2 at 23:33:36
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/10M_bicleaner_v1.1_+_ced_0.25_x_bic1.1_w3000/data/KDE4.de.sgm -r ../experiments/10M_bicleaner_v1.1_+_ced_0.25_x_bic1.1_w3000/data/KDE4.en.sgm -t ../experiments/10M_bicleaner_v1.1_+_ced_0.25_x_bic1.1_w3000/data/KDE4.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 3000 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 0.924983768646501 (118249/127839), penalty (log): -0.0811000515860598
NIST score = 6.1919  BLEU score = 0.1964 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.5883   1.2585   0.2770   0.0565   0.0117   0.0034   0.0013   0.0009   0.0005  "Edinburgh"

 BLEU:  0.5729   0.2714   0.1511   0.0875   0.0529   0.0332   0.0215   0.0147   0.0103  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.5883   5.8467   6.1237   6.1802   6.1919   6.1953   6.1966   6.1975   6.1980  "Edinburgh"

 BLEU:  0.5283   0.3636   0.2641   0.1964   0.1486   0.1142   0.0889   0.0703   0.0563  "Edinburgh"
MT evaluation scorer ended on 2019 Aug 2 at 23:34:07
