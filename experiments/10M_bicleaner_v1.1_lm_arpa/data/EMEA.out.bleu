MT evaluation scorer began on 2019 Aug 11 at 18:37:48
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/10M_bicleaner_v1.1_lm_arpa/data/EMEA.de.sgm -r ../experiments/10M_bicleaner_v1.1_lm_arpa/data/EMEA.en.sgm -t ../experiments/10M_bicleaner_v1.1_lm_arpa/data/EMEA.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 3000 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 0.956006437628497 (102764/107493), penalty (log): -0.0460180607995018
NIST score = 6.8040  BLEU score = 0.2523 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  5.0823   1.3523   0.2823   0.0668   0.0203   0.0080   0.0032   0.0012   0.0009  "Edinburgh"

 BLEU:  0.5931   0.3238   0.1994   0.1273   0.0842   0.0565   0.0393   0.0291   0.0218  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  5.0823   6.4346   6.7169   6.7837   6.8040   6.8120   6.8152   6.8164   6.8173  "Edinburgh"

 BLEU:  0.5665   0.4185   0.3219   0.2523   0.2007   0.1613   0.1310   0.1079   0.0898  "Edinburgh"
MT evaluation scorer ended on 2019 Aug 11 at 18:38:17
