MT evaluation scorer began on 2019 Jul 3 at 14:14:18
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/10M_fasttext_prob_and_len_+_bic1.1_x_dcce/data/KDE4.de.sgm -r ../experiments/10M_fasttext_prob_and_len_+_bic1.1_x_dcce/data/KDE4.en.sgm -t ../experiments/10M_fasttext_prob_and_len_+_bic1.1_x_dcce/data/KDE4.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 3000 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 0.965652109293721 (123448/127839), penalty (log): -0.0355696325578381
NIST score = 6.0574  BLEU score = 0.1983 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.4727   1.2393   0.2768   0.0567   0.0120   0.0034   0.0016   0.0011   0.0007  "Edinburgh"

 BLEU:  0.5491   0.2606   0.1462   0.0852   0.0516   0.0320   0.0206   0.0135   0.0090  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.4727   5.7120   5.9888   6.0454   6.0574   6.0608   6.0624   6.0636   6.0642  "Edinburgh"

 BLEU:  0.5299   0.3650   0.2659   0.1983   0.1504   0.1155   0.0898   0.0706   0.0559  "Edinburgh"
MT evaluation scorer ended on 2019 Jul 3 at 14:14:52
