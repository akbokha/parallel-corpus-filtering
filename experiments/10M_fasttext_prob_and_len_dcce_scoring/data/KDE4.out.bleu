MT evaluation scorer began on 2019 Jul 2 at 15:31:25
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/10M_fasttext_prob_and_len_dcce_scoring/data/KDE4.de.sgm -r ../experiments/10M_fasttext_prob_and_len_dcce_scoring/data/KDE4.en.sgm -t ../experiments/10M_fasttext_prob_and_len_dcce_scoring/data/KDE4.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 3000 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 0.947793709274947 (121165/127839), penalty (log): -0.0550819130937153
NIST score = 5.9500  BLEU score = 0.1904 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.4139   1.2021   0.2679   0.0550   0.0110   0.0034   0.0013   0.0008   0.0004  "Edinburgh"

 BLEU:  0.5464   0.2555   0.1418   0.0826   0.0502   0.0317   0.0210   0.0146   0.0106  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.4139   5.6160   5.8839   5.9389   5.9500   5.9533   5.9546   5.9555   5.9559  "Edinburgh"

 BLEU:  0.5172   0.3536   0.2561   0.1904   0.1442   0.1110   0.0868   0.0690   0.0557  "Edinburgh"
MT evaluation scorer ended on 2019 Jul 2 at 15:31:58
