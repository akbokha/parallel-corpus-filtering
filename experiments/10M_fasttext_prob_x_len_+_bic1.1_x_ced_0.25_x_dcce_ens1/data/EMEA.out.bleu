MT evaluation scorer began on 2019 Jul 12 at 20:39:36
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/10M_fasttext_prob_x_len_+_bic1.1_x_ced_0.25_x_dcce_ens1/data/EMEA.de.sgm -r ../experiments/10M_fasttext_prob_x_len_+_bic1.1_x_ced_0.25_x_dcce_ens1/data/EMEA.en.sgm -t ../experiments/10M_fasttext_prob_x_len_+_bic1.1_x_ced_0.25_x_dcce_ens1/data/EMEA.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 3000 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 1.00280948526881 (107795/107493), penalty (log): 0
NIST score = 6.5779  BLEU score = 0.2538 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.8936   1.3241   0.2760   0.0643   0.0199   0.0073   0.0036   0.0020   0.0016  "Edinburgh"

 BLEU:  0.5669   0.3108   0.1917   0.1227   0.0817   0.0560   0.0397   0.0293   0.0220  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.8936   6.2177   6.4937   6.5580   6.5779   6.5852   6.5888   6.5909   6.5924  "Edinburgh"

 BLEU:  0.5669   0.4198   0.3233   0.2538   0.2023   0.1633   0.1334   0.1104   0.0923  "Edinburgh"
MT evaluation scorer ended on 2019 Jul 12 at 20:40:09
