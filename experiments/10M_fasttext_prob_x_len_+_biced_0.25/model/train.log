[2019-07-17 21:04:05] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-17 21:04:05] [marian] Running on lofn as process 9001 with command line:
[2019-07-17 21:04:05] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz -T . --devices 1 --train-sets ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.de ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.en --vocabs ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.de.json ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.en.json --mini-batch-fit -w 5000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/dev.bpe.de ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/dev.out --valid-script-path ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/train.log --valid-log ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/valid.log
[2019-07-17 21:04:05] [config] after-batches: 0
[2019-07-17 21:04:05] [config] after-epochs: 0
[2019-07-17 21:04:05] [config] allow-unk: false
[2019-07-17 21:04:05] [config] beam-size: 12
[2019-07-17 21:04:05] [config] bert-class-symbol: "[CLS]"
[2019-07-17 21:04:05] [config] bert-mask-symbol: "[MASK]"
[2019-07-17 21:04:05] [config] bert-masking-fraction: 0.15
[2019-07-17 21:04:05] [config] bert-sep-symbol: "[SEP]"
[2019-07-17 21:04:05] [config] bert-train-type-embeddings: true
[2019-07-17 21:04:05] [config] bert-type-vocab-size: 2
[2019-07-17 21:04:05] [config] best-deep: false
[2019-07-17 21:04:05] [config] clip-gemm: 0
[2019-07-17 21:04:05] [config] clip-norm: 1
[2019-07-17 21:04:05] [config] cost-type: ce-mean
[2019-07-17 21:04:05] [config] cpu-threads: 0
[2019-07-17 21:04:05] [config] data-weighting: ""
[2019-07-17 21:04:05] [config] data-weighting-type: sentence
[2019-07-17 21:04:05] [config] dec-cell: gru
[2019-07-17 21:04:05] [config] dec-cell-base-depth: 2
[2019-07-17 21:04:05] [config] dec-cell-high-depth: 1
[2019-07-17 21:04:05] [config] dec-depth: 1
[2019-07-17 21:04:05] [config] devices:
[2019-07-17 21:04:05] [config]   - 1
[2019-07-17 21:04:05] [config] dim-emb: 512
[2019-07-17 21:04:05] [config] dim-rnn: 1024
[2019-07-17 21:04:05] [config] dim-vocabs:
[2019-07-17 21:04:05] [config]   - 50000
[2019-07-17 21:04:05] [config]   - 50000
[2019-07-17 21:04:05] [config] disp-first: 0
[2019-07-17 21:04:05] [config] disp-freq: 2000
[2019-07-17 21:04:05] [config] disp-label-counts: false
[2019-07-17 21:04:05] [config] dropout-rnn: 0.2
[2019-07-17 21:04:05] [config] dropout-src: 0.1
[2019-07-17 21:04:05] [config] dropout-trg: 0.1
[2019-07-17 21:04:05] [config] dump-config: ""
[2019-07-17 21:04:05] [config] early-stopping: 5
[2019-07-17 21:04:05] [config] embedding-fix-src: false
[2019-07-17 21:04:05] [config] embedding-fix-trg: false
[2019-07-17 21:04:05] [config] embedding-normalization: false
[2019-07-17 21:04:05] [config] embedding-vectors:
[2019-07-17 21:04:05] [config]   []
[2019-07-17 21:04:05] [config] enc-cell: gru
[2019-07-17 21:04:05] [config] enc-cell-depth: 1
[2019-07-17 21:04:05] [config] enc-depth: 1
[2019-07-17 21:04:05] [config] enc-type: bidirectional
[2019-07-17 21:04:05] [config] exponential-smoothing: 0.0001
[2019-07-17 21:04:05] [config] grad-dropping-momentum: 0
[2019-07-17 21:04:05] [config] grad-dropping-rate: 0
[2019-07-17 21:04:05] [config] grad-dropping-warmup: 100
[2019-07-17 21:04:05] [config] guided-alignment: none
[2019-07-17 21:04:05] [config] guided-alignment-cost: mse
[2019-07-17 21:04:05] [config] guided-alignment-weight: 0.1
[2019-07-17 21:04:05] [config] ignore-model-config: false
[2019-07-17 21:04:05] [config] input-types:
[2019-07-17 21:04:05] [config]   []
[2019-07-17 21:04:05] [config] interpolate-env-vars: false
[2019-07-17 21:04:05] [config] keep-best: false
[2019-07-17 21:04:05] [config] label-smoothing: 0
[2019-07-17 21:04:05] [config] layer-normalization: true
[2019-07-17 21:04:05] [config] learn-rate: 0.0001
[2019-07-17 21:04:05] [config] log: ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/train.log
[2019-07-17 21:04:05] [config] log-level: info
[2019-07-17 21:04:05] [config] log-time-zone: ""
[2019-07-17 21:04:05] [config] lr-decay: 0
[2019-07-17 21:04:05] [config] lr-decay-freq: 50000
[2019-07-17 21:04:05] [config] lr-decay-inv-sqrt:
[2019-07-17 21:04:05] [config]   - 0
[2019-07-17 21:04:05] [config] lr-decay-repeat-warmup: false
[2019-07-17 21:04:05] [config] lr-decay-reset-optimizer: false
[2019-07-17 21:04:05] [config] lr-decay-start:
[2019-07-17 21:04:05] [config]   - 10
[2019-07-17 21:04:05] [config]   - 1
[2019-07-17 21:04:05] [config] lr-decay-strategy: epoch+stalled
[2019-07-17 21:04:05] [config] lr-report: false
[2019-07-17 21:04:05] [config] lr-warmup: 0
[2019-07-17 21:04:05] [config] lr-warmup-at-reload: false
[2019-07-17 21:04:05] [config] lr-warmup-cycle: false
[2019-07-17 21:04:05] [config] lr-warmup-start-rate: 0
[2019-07-17 21:04:05] [config] max-length: 50
[2019-07-17 21:04:05] [config] max-length-crop: false
[2019-07-17 21:04:05] [config] max-length-factor: 3
[2019-07-17 21:04:05] [config] maxi-batch: 100
[2019-07-17 21:04:05] [config] maxi-batch-sort: trg
[2019-07-17 21:04:05] [config] mini-batch: 64
[2019-07-17 21:04:05] [config] mini-batch-fit: true
[2019-07-17 21:04:05] [config] mini-batch-fit-step: 10
[2019-07-17 21:04:05] [config] mini-batch-overstuff: 1
[2019-07-17 21:04:05] [config] mini-batch-track-lr: false
[2019-07-17 21:04:05] [config] mini-batch-understuff: 1
[2019-07-17 21:04:05] [config] mini-batch-warmup: 0
[2019-07-17 21:04:05] [config] mini-batch-words: 0
[2019-07-17 21:04:05] [config] mini-batch-words-ref: 0
[2019-07-17 21:04:05] [config] model: ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-17 21:04:05] [config] multi-loss-type: sum
[2019-07-17 21:04:05] [config] multi-node: false
[2019-07-17 21:04:05] [config] multi-node-overlap: true
[2019-07-17 21:04:05] [config] n-best: false
[2019-07-17 21:04:05] [config] no-nccl: false
[2019-07-17 21:04:05] [config] no-reload: false
[2019-07-17 21:04:05] [config] no-restore-corpus: false
[2019-07-17 21:04:05] [config] no-shuffle: false
[2019-07-17 21:04:05] [config] normalize: 1
[2019-07-17 21:04:05] [config] num-devices: 0
[2019-07-17 21:04:05] [config] optimizer: adam
[2019-07-17 21:04:05] [config] optimizer-delay: 1
[2019-07-17 21:04:05] [config] optimizer-params:
[2019-07-17 21:04:05] [config]   []
[2019-07-17 21:04:05] [config] overwrite: false
[2019-07-17 21:04:05] [config] pretrained-model: ""
[2019-07-17 21:04:05] [config] quiet: false
[2019-07-17 21:04:05] [config] quiet-translation: true
[2019-07-17 21:04:05] [config] relative-paths: false
[2019-07-17 21:04:05] [config] right-left: false
[2019-07-17 21:04:05] [config] save-freq: 20000
[2019-07-17 21:04:05] [config] seed: 1111
[2019-07-17 21:04:05] [config] shuffle-in-ram: false
[2019-07-17 21:04:05] [config] skip: false
[2019-07-17 21:04:05] [config] sqlite: ""
[2019-07-17 21:04:05] [config] sqlite-drop: false
[2019-07-17 21:04:05] [config] sync-sgd: true
[2019-07-17 21:04:05] [config] tempdir: .
[2019-07-17 21:04:05] [config] tied-embeddings: false
[2019-07-17 21:04:05] [config] tied-embeddings-all: false
[2019-07-17 21:04:05] [config] tied-embeddings-src: false
[2019-07-17 21:04:05] [config] train-sets:
[2019-07-17 21:04:05] [config]   - ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.de
[2019-07-17 21:04:05] [config]   - ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.en
[2019-07-17 21:04:05] [config] transformer-aan-activation: swish
[2019-07-17 21:04:05] [config] transformer-aan-depth: 2
[2019-07-17 21:04:05] [config] transformer-aan-nogate: false
[2019-07-17 21:04:05] [config] transformer-decoder-autoreg: self-attention
[2019-07-17 21:04:05] [config] transformer-dim-aan: 2048
[2019-07-17 21:04:05] [config] transformer-dim-ffn: 2048
[2019-07-17 21:04:05] [config] transformer-dropout: 0
[2019-07-17 21:04:05] [config] transformer-dropout-attention: 0
[2019-07-17 21:04:05] [config] transformer-dropout-ffn: 0
[2019-07-17 21:04:05] [config] transformer-ffn-activation: swish
[2019-07-17 21:04:05] [config] transformer-ffn-depth: 2
[2019-07-17 21:04:05] [config] transformer-guided-alignment-layer: last
[2019-07-17 21:04:05] [config] transformer-heads: 8
[2019-07-17 21:04:05] [config] transformer-no-projection: false
[2019-07-17 21:04:05] [config] transformer-postprocess: dan
[2019-07-17 21:04:05] [config] transformer-postprocess-emb: d
[2019-07-17 21:04:05] [config] transformer-preprocess: ""
[2019-07-17 21:04:05] [config] transformer-tied-layers:
[2019-07-17 21:04:05] [config]   []
[2019-07-17 21:04:05] [config] transformer-train-position-embeddings: false
[2019-07-17 21:04:05] [config] type: amun
[2019-07-17 21:04:05] [config] ulr: false
[2019-07-17 21:04:05] [config] ulr-dim-emb: 0
[2019-07-17 21:04:05] [config] ulr-dropout: 0
[2019-07-17 21:04:05] [config] ulr-keys-vectors: ""
[2019-07-17 21:04:05] [config] ulr-query-vectors: ""
[2019-07-17 21:04:05] [config] ulr-softmax-temperature: 1
[2019-07-17 21:04:05] [config] ulr-trainable-transformation: false
[2019-07-17 21:04:05] [config] valid-freq: 20000
[2019-07-17 21:04:05] [config] valid-log: ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/valid.log
[2019-07-17 21:04:05] [config] valid-max-length: 1000
[2019-07-17 21:04:05] [config] valid-metrics:
[2019-07-17 21:04:05] [config]   - cross-entropy
[2019-07-17 21:04:05] [config]   - perplexity
[2019-07-17 21:04:05] [config]   - translation
[2019-07-17 21:04:05] [config] valid-mini-batch: 8
[2019-07-17 21:04:05] [config] valid-script-path: ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/score-dev.sh
[2019-07-17 21:04:05] [config] valid-sets:
[2019-07-17 21:04:05] [config]   - ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/dev.bpe.de
[2019-07-17 21:04:05] [config]   - ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/dev.bpe.en
[2019-07-17 21:04:05] [config] valid-translation-output: ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/dev.out
[2019-07-17 21:04:05] [config] vocabs:
[2019-07-17 21:04:05] [config]   - ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.de.json
[2019-07-17 21:04:05] [config]   - ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.en.json
[2019-07-17 21:04:05] [config] word-penalty: 0
[2019-07-17 21:04:05] [config] workspace: 5000
[2019-07-17 21:04:05] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-17 21:04:05] Using synchronous training
[2019-07-17 21:04:05] [data] Loading vocabulary from JSON/Yaml file ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.de.json
[2019-07-17 21:04:05] [data] Using unused word id eos for 0
[2019-07-17 21:04:05] [data] Using unused word id UNK for 1
[2019-07-17 21:04:05] [data] Setting vocabulary size for input 0 to 50000
[2019-07-17 21:04:05] [data] Loading vocabulary from JSON/Yaml file ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.en.json
[2019-07-17 21:04:06] [data] Using unused word id eos for 0
[2019-07-17 21:04:06] [data] Using unused word id UNK for 1
[2019-07-17 21:04:06] [data] Setting vocabulary size for input 1 to 50000
[2019-07-17 21:04:06] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-17 21:04:06] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-17 21:04:07] [memory] Extending reserved space to 5120 MB (device gpu1)
[2019-07-17 21:04:07] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-17 21:04:07] [comm] NCCLCommunicator constructed successfully.
[2019-07-17 21:04:07] [training] Using 1 GPUs
[2019-07-17 21:04:07] [memory] Reserving 422 MB, device gpu1
[2019-07-17 21:04:07] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-17 21:04:07] [memory] Reserving 422 MB, device gpu1
[2019-07-17 21:04:16] [batching] Done. Typical MB size is 6880 target words
[2019-07-17 21:04:16] [memory] Extending reserved space to 5120 MB (device gpu1)
[2019-07-17 21:04:16] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-17 21:04:16] [comm] NCCLCommunicator constructed successfully.
[2019-07-17 21:04:16] [training] Using 1 GPUs
[2019-07-17 21:04:16] Training started
[2019-07-17 21:04:16] [data] Shuffling data
[2019-07-17 21:04:22] [data] Done reading 12702121 sentences
[2019-07-17 21:05:20] [data] Done shuffling 12702121 sentences to temp files
[2019-07-17 21:05:23] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-07-17 21:05:23] [memory] Reserving 422 MB, device gpu1
[2019-07-17 21:05:23] [memory] Reserving 422 MB, device gpu1
[2019-07-17 21:05:23] [memory] Reserving 422 MB, device gpu1
[2019-07-17 21:05:23] [memory] Reserving 844 MB, device gpu1
[2019-07-17 21:18:37] Ep. 1 : Up. 2000 : Sen. 286,121 : Cost 140.24179077 : Time 871.30s : 7094.67 words/s
[2019-07-17 21:31:53] Ep. 1 : Up. 4000 : Sen. 572,447 : Cost 121.14846802 : Time 795.96s : 7758.97 words/s
[2019-07-17 21:45:15] Ep. 1 : Up. 6000 : Sen. 860,996 : Cost 112.63645172 : Time 802.33s : 7745.75 words/s
[2019-07-17 21:58:36] Ep. 1 : Up. 8000 : Sen. 1,148,247 : Cost 107.00382996 : Time 800.97s : 7748.61 words/s
[2019-07-17 22:11:55] Ep. 1 : Up. 10000 : Sen. 1,435,714 : Cost 102.52759552 : Time 798.48s : 7759.14 words/s
[2019-07-17 22:25:14] Ep. 1 : Up. 12000 : Sen. 1,723,266 : Cost 99.19766998 : Time 799.35s : 7758.12 words/s
[2019-07-17 22:38:32] Ep. 1 : Up. 14000 : Sen. 2,008,562 : Cost 96.79401398 : Time 797.64s : 7728.80 words/s
[2019-07-17 22:51:52] Ep. 1 : Up. 16000 : Sen. 2,295,275 : Cost 94.43436432 : Time 800.66s : 7737.38 words/s
[2019-07-17 23:05:12] Ep. 1 : Up. 18000 : Sen. 2,581,855 : Cost 92.35847473 : Time 799.43s : 7727.51 words/s
[2019-07-17 23:18:33] Ep. 1 : Up. 20000 : Sen. 2,869,300 : Cost 90.65602112 : Time 800.88s : 7745.26 words/s
[2019-07-17 23:18:33] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-17 23:18:42] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter20000.npz
[2019-07-17 23:18:48] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-17 23:18:57] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-17 23:19:22] [valid] Ep. 1 : Up. 20000 : cross-entropy : 90.3126 : new best
[2019-07-17 23:19:30] [valid] Ep. 1 : Up. 20000 : perplexity : 35.7529 : new best
[2019-07-17 23:20:50] [valid] Ep. 1 : Up. 20000 : translation : 12.29 : new best
[2019-07-17 23:34:14] Ep. 1 : Up. 22000 : Sen. 3,156,519 : Cost 89.27984619 : Time 941.19s : 6588.54 words/s
[2019-07-17 23:47:37] Ep. 1 : Up. 24000 : Sen. 3,443,332 : Cost 88.26626587 : Time 802.72s : 7723.43 words/s
[2019-07-18 00:00:54] Ep. 1 : Up. 26000 : Sen. 3,729,582 : Cost 86.75222015 : Time 797.73s : 7722.25 words/s
[2019-07-18 00:14:13] Ep. 1 : Up. 28000 : Sen. 4,015,973 : Cost 86.21739197 : Time 798.43s : 7759.75 words/s
[2019-07-18 00:27:35] Ep. 1 : Up. 30000 : Sen. 4,302,958 : Cost 85.22911835 : Time 801.79s : 7732.15 words/s
[2019-07-18 00:40:54] Ep. 1 : Up. 32000 : Sen. 4,590,269 : Cost 84.17500305 : Time 799.05s : 7745.91 words/s
[2019-07-18 00:54:14] Ep. 1 : Up. 34000 : Sen. 4,877,748 : Cost 83.57614899 : Time 800.77s : 7743.38 words/s
[2019-07-18 01:07:35] Ep. 1 : Up. 36000 : Sen. 5,165,837 : Cost 82.94927216 : Time 800.68s : 7759.95 words/s
[2019-07-18 01:20:57] Ep. 1 : Up. 38000 : Sen. 5,452,932 : Cost 82.43512726 : Time 801.38s : 7743.64 words/s
[2019-07-18 01:34:15] Ep. 1 : Up. 40000 : Sen. 5,739,660 : Cost 81.55504608 : Time 798.15s : 7743.77 words/s
[2019-07-18 01:34:15] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-18 01:34:23] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter40000.npz
[2019-07-18 01:34:30] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-18 01:34:39] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-18 01:35:05] [valid] Ep. 1 : Up. 40000 : cross-entropy : 73.1451 : new best
[2019-07-18 01:35:13] [valid] Ep. 1 : Up. 40000 : perplexity : 18.1152 : new best
[2019-07-18 01:36:22] [valid] Ep. 1 : Up. 40000 : translation : 19.6 : new best
[2019-07-18 01:49:45] Ep. 1 : Up. 42000 : Sen. 6,026,671 : Cost 81.17503357 : Time 930.22s : 6653.10 words/s
[2019-07-18 02:03:04] Ep. 1 : Up. 44000 : Sen. 6,313,060 : Cost 80.52310944 : Time 799.15s : 7731.39 words/s
[2019-07-18 02:16:25] Ep. 1 : Up. 46000 : Sen. 6,599,513 : Cost 80.46343994 : Time 800.74s : 7733.49 words/s
[2019-07-18 02:29:45] Ep. 1 : Up. 48000 : Sen. 6,886,780 : Cost 79.84452820 : Time 800.13s : 7741.48 words/s
[2019-07-18 02:43:07] Ep. 1 : Up. 50000 : Sen. 7,174,400 : Cost 79.28046417 : Time 802.50s : 7725.16 words/s
[2019-07-18 02:56:26] Ep. 1 : Up. 52000 : Sen. 7,461,464 : Cost 78.84967041 : Time 798.85s : 7731.37 words/s
[2019-07-18 03:09:48] Ep. 1 : Up. 54000 : Sen. 7,748,379 : Cost 78.88985443 : Time 801.38s : 7725.13 words/s
[2019-07-18 03:23:06] Ep. 1 : Up. 56000 : Sen. 8,035,518 : Cost 78.10633850 : Time 797.92s : 7743.26 words/s
[2019-07-18 03:36:25] Ep. 1 : Up. 58000 : Sen. 8,322,529 : Cost 78.01970673 : Time 799.21s : 7751.19 words/s
[2019-07-18 03:49:44] Ep. 1 : Up. 60000 : Sen. 8,608,660 : Cost 77.87905121 : Time 799.31s : 7732.23 words/s
[2019-07-18 03:49:44] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-18 03:49:54] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter60000.npz
[2019-07-18 03:50:01] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-18 03:50:13] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-18 03:50:40] [valid] Ep. 1 : Up. 60000 : cross-entropy : 66.1335 : new best
[2019-07-18 03:50:48] [valid] Ep. 1 : Up. 60000 : perplexity : 13.723 : new best
[2019-07-18 03:51:54] [valid] Ep. 1 : Up. 60000 : translation : 22.2 : new best
[2019-07-18 04:05:16] Ep. 1 : Up. 62000 : Sen. 8,895,868 : Cost 77.04608154 : Time 931.41s : 6635.60 words/s
[2019-07-18 04:18:34] Ep. 1 : Up. 64000 : Sen. 9,181,831 : Cost 77.10922241 : Time 798.34s : 7726.96 words/s
[2019-07-18 04:31:51] Ep. 1 : Up. 66000 : Sen. 9,467,666 : Cost 76.84173584 : Time 797.62s : 7739.02 words/s
[2019-07-18 04:45:09] Ep. 1 : Up. 68000 : Sen. 9,755,016 : Cost 76.46706390 : Time 797.95s : 7769.23 words/s
[2019-07-18 04:58:30] Ep. 1 : Up. 70000 : Sen. 10,042,195 : Cost 76.45571899 : Time 800.88s : 7753.43 words/s
[2019-07-18 05:11:53] Ep. 1 : Up. 72000 : Sen. 10,329,996 : Cost 76.04425049 : Time 802.29s : 7744.94 words/s
[2019-07-18 05:25:12] Ep. 1 : Up. 74000 : Sen. 10,617,204 : Cost 75.73169708 : Time 798.99s : 7736.53 words/s
[2019-07-18 05:25:40] Seen 10627013 samples
[2019-07-18 05:25:40] Starting epoch 2
[2019-07-18 05:25:40] [data] Shuffling data
[2019-07-18 05:25:53] [data] Done reading 12702121 sentences
[2019-07-18 05:26:51] [data] Done shuffling 12702121 sentences to temp files
[2019-07-18 05:39:47] Ep. 2 : Up. 76000 : Sen. 276,391 : Cost 75.13442230 : Time 875.00s : 7073.88 words/s
[2019-07-18 05:53:04] Ep. 2 : Up. 78000 : Sen. 562,672 : Cost 74.63756561 : Time 797.79s : 7743.71 words/s
[2019-07-18 06:06:27] Ep. 2 : Up. 80000 : Sen. 850,096 : Cost 74.45760345 : Time 802.61s : 7719.75 words/s
[2019-07-18 06:06:27] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-18 06:06:36] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter80000.npz
[2019-07-18 06:06:43] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-18 06:06:52] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-18 06:07:17] [valid] Ep. 2 : Up. 80000 : cross-entropy : 62.3884 : new best
[2019-07-18 06:07:25] [valid] Ep. 2 : Up. 80000 : perplexity : 11.8314 : new best
[2019-07-18 06:08:30] [valid] Ep. 2 : Up. 80000 : translation : 23.04 : new best
[2019-07-18 06:21:52] Ep. 2 : Up. 82000 : Sen. 1,135,795 : Cost 74.17368317 : Time 924.82s : 6671.12 words/s
[2019-07-18 06:35:12] Ep. 2 : Up. 84000 : Sen. 1,423,288 : Cost 74.07073212 : Time 800.59s : 7729.71 words/s
[2019-07-18 06:48:32] Ep. 2 : Up. 86000 : Sen. 1,710,311 : Cost 74.09438324 : Time 800.02s : 7736.79 words/s
[2019-07-18 07:01:53] Ep. 2 : Up. 88000 : Sen. 1,997,502 : Cost 74.03352356 : Time 800.97s : 7735.05 words/s
[2019-07-18 07:15:17] Ep. 2 : Up. 90000 : Sen. 2,284,536 : Cost 73.69618225 : Time 803.12s : 7713.94 words/s
[2019-07-18 07:28:38] Ep. 2 : Up. 92000 : Sen. 2,571,999 : Cost 73.44834900 : Time 801.64s : 7733.73 words/s
[2019-07-18 07:41:58] Ep. 2 : Up. 94000 : Sen. 2,858,944 : Cost 73.65512848 : Time 800.01s : 7756.59 words/s
[2019-07-18 07:55:18] Ep. 2 : Up. 96000 : Sen. 3,145,659 : Cost 73.48072815 : Time 800.27s : 7737.99 words/s
[2019-07-18 08:08:39] Ep. 2 : Up. 98000 : Sen. 3,432,479 : Cost 73.15670776 : Time 800.12s : 7731.09 words/s
[2019-07-18 08:21:58] Ep. 2 : Up. 100000 : Sen. 3,718,811 : Cost 72.87649536 : Time 799.86s : 7710.09 words/s
[2019-07-18 08:21:58] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-18 08:22:07] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter100000.npz
[2019-07-18 08:22:14] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-18 08:22:23] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-18 08:22:48] [valid] Ep. 2 : Up. 100000 : cross-entropy : 59.9247 : new best
[2019-07-18 08:22:56] [valid] Ep. 2 : Up. 100000 : perplexity : 10.7315 : new best
[2019-07-18 08:24:00] [valid] Ep. 2 : Up. 100000 : translation : 23.89 : new best
[2019-07-18 08:37:21] Ep. 2 : Up. 102000 : Sen. 4,006,244 : Cost 72.76714325 : Time 923.03s : 6706.27 words/s
[2019-07-18 08:50:40] Ep. 2 : Up. 104000 : Sen. 4,292,481 : Cost 72.86785126 : Time 798.98s : 7735.35 words/s
[2019-07-18 09:04:00] Ep. 2 : Up. 106000 : Sen. 4,578,630 : Cost 72.59302521 : Time 799.45s : 7715.91 words/s
[2019-07-18 09:17:22] Ep. 2 : Up. 108000 : Sen. 4,865,499 : Cost 72.81286621 : Time 802.11s : 7737.30 words/s
[2019-07-18 09:30:41] Ep. 2 : Up. 110000 : Sen. 5,151,736 : Cost 72.35820770 : Time 799.39s : 7717.92 words/s
[2019-07-18 09:44:02] Ep. 2 : Up. 112000 : Sen. 5,438,458 : Cost 72.26711273 : Time 800.21s : 7720.36 words/s
[2019-07-18 09:57:21] Ep. 2 : Up. 114000 : Sen. 5,725,282 : Cost 72.32765961 : Time 799.90s : 7738.03 words/s
[2019-07-18 10:10:38] Ep. 2 : Up. 116000 : Sen. 6,010,948 : Cost 72.16521454 : Time 796.04s : 7734.00 words/s
[2019-07-18 10:23:56] Ep. 2 : Up. 118000 : Sen. 6,296,940 : Cost 72.01463318 : Time 798.06s : 7724.33 words/s
[2019-07-18 10:37:15] Ep. 2 : Up. 120000 : Sen. 6,583,488 : Cost 72.12206268 : Time 799.88s : 7738.96 words/s
[2019-07-18 10:37:15] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-18 10:37:27] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter120000.npz
[2019-07-18 10:37:37] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-18 10:37:50] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-18 10:38:20] [valid] Ep. 2 : Up. 120000 : cross-entropy : 58.1449 : new best
[2019-07-18 10:38:28] [valid] Ep. 2 : Up. 120000 : perplexity : 10.0011 : new best
[2019-07-18 10:39:33] [valid] Ep. 2 : Up. 120000 : translation : 24.17 : new best
[2019-07-18 10:52:55] Ep. 2 : Up. 122000 : Sen. 6,869,509 : Cost 71.90139771 : Time 939.71s : 6568.77 words/s
[2019-07-18 11:06:15] Ep. 2 : Up. 124000 : Sen. 7,156,124 : Cost 71.80947113 : Time 799.71s : 7734.21 words/s
[2019-07-18 11:19:33] Ep. 2 : Up. 126000 : Sen. 7,442,662 : Cost 71.62020111 : Time 798.43s : 7735.92 words/s
[2019-07-18 11:32:57] Ep. 2 : Up. 128000 : Sen. 7,729,648 : Cost 71.66221619 : Time 803.43s : 7717.37 words/s
[2019-07-18 11:46:18] Ep. 2 : Up. 130000 : Sen. 8,017,108 : Cost 71.27198792 : Time 801.55s : 7733.00 words/s
[2019-07-18 11:59:40] Ep. 2 : Up. 132000 : Sen. 8,304,272 : Cost 71.02169037 : Time 801.25s : 7715.70 words/s
[2019-07-18 12:13:00] Ep. 2 : Up. 134000 : Sen. 8,590,801 : Cost 71.22160339 : Time 800.43s : 7732.17 words/s
[2019-07-18 12:26:20] Ep. 2 : Up. 136000 : Sen. 8,877,808 : Cost 71.15433502 : Time 799.96s : 7742.34 words/s
[2019-07-18 12:39:38] Ep. 2 : Up. 138000 : Sen. 9,165,066 : Cost 71.06288147 : Time 798.48s : 7769.93 words/s
[2019-07-18 12:52:57] Ep. 2 : Up. 140000 : Sen. 9,451,570 : Cost 70.87205505 : Time 798.74s : 7739.57 words/s
[2019-07-18 12:52:57] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-18 12:53:06] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter140000.npz
[2019-07-18 12:53:12] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-18 12:53:22] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-18 12:53:48] [valid] Ep. 2 : Up. 140000 : cross-entropy : 56.8289 : new best
[2019-07-18 12:53:55] [valid] Ep. 2 : Up. 140000 : perplexity : 9.49327 : new best
[2019-07-18 12:55:01] [valid] Ep. 2 : Up. 140000 : translation : 24.32 : new best
[2019-07-18 13:08:23] Ep. 2 : Up. 142000 : Sen. 9,738,566 : Cost 70.92480469 : Time 925.84s : 6684.19 words/s
[2019-07-18 13:21:46] Ep. 2 : Up. 144000 : Sen. 10,026,642 : Cost 70.78574371 : Time 802.54s : 7745.61 words/s
[2019-07-18 13:35:09] Ep. 2 : Up. 146000 : Sen. 10,314,274 : Cost 70.81636810 : Time 803.39s : 7730.50 words/s
[2019-07-18 13:48:30] Ep. 2 : Up. 148000 : Sen. 10,601,310 : Cost 70.56507874 : Time 801.38s : 7724.41 words/s
[2019-07-18 13:49:43] Seen 10627013 samples
[2019-07-18 13:49:43] Starting epoch 3
[2019-07-18 13:49:43] [data] Shuffling data
[2019-07-18 13:49:49] [data] Done reading 12702121 sentences
[2019-07-18 13:50:45] [data] Done shuffling 12702121 sentences to temp files
[2019-07-18 14:02:55] Ep. 3 : Up. 150000 : Sen. 260,689 : Cost 69.75663757 : Time 864.31s : 7145.16 words/s
[2019-07-18 14:16:12] Ep. 3 : Up. 152000 : Sen. 547,767 : Cost 69.64468384 : Time 797.19s : 7764.94 words/s
[2019-07-18 14:29:28] Ep. 3 : Up. 154000 : Sen. 833,949 : Cost 69.24577332 : Time 796.06s : 7735.69 words/s
[2019-07-18 14:42:51] Ep. 3 : Up. 156000 : Sen. 1,120,834 : Cost 69.83109283 : Time 803.45s : 7730.10 words/s
[2019-07-18 14:56:09] Ep. 3 : Up. 158000 : Sen. 1,406,603 : Cost 69.70628357 : Time 797.60s : 7728.63 words/s
[2019-07-18 15:09:28] Ep. 3 : Up. 160000 : Sen. 1,693,751 : Cost 69.50769043 : Time 798.98s : 7740.71 words/s
[2019-07-18 15:09:28] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-18 15:09:37] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter160000.npz
[2019-07-18 15:09:47] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-18 15:09:57] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-18 15:10:23] [valid] Ep. 3 : Up. 160000 : cross-entropy : 55.8442 : new best
[2019-07-18 15:10:31] [valid] Ep. 3 : Up. 160000 : perplexity : 9.13019 : new best
[2019-07-18 15:11:36] [valid] Ep. 3 : Up. 160000 : translation : 24.63 : new best
[2019-07-18 15:25:01] Ep. 3 : Up. 162000 : Sen. 1,980,415 : Cost 69.56148529 : Time 932.84s : 6637.07 words/s
[2019-07-18 15:38:24] Ep. 3 : Up. 164000 : Sen. 2,267,797 : Cost 69.60468292 : Time 802.82s : 7733.80 words/s
[2019-07-18 15:51:42] Ep. 3 : Up. 166000 : Sen. 2,554,724 : Cost 69.57849121 : Time 798.41s : 7755.64 words/s
[2019-07-18 16:05:04] Ep. 3 : Up. 168000 : Sen. 2,841,370 : Cost 69.41767883 : Time 801.60s : 7721.01 words/s
[2019-07-18 16:18:22] Ep. 3 : Up. 170000 : Sen. 3,128,399 : Cost 69.48347473 : Time 798.01s : 7749.68 words/s
[2019-07-18 16:31:41] Ep. 3 : Up. 172000 : Sen. 3,415,157 : Cost 69.49272919 : Time 799.70s : 7743.63 words/s
[2019-07-18 16:45:00] Ep. 3 : Up. 174000 : Sen. 3,701,806 : Cost 69.20724487 : Time 799.21s : 7723.92 words/s
[2019-07-18 16:58:23] Ep. 3 : Up. 176000 : Sen. 3,988,687 : Cost 69.22675323 : Time 802.42s : 7718.73 words/s
[2019-07-18 17:11:41] Ep. 3 : Up. 178000 : Sen. 4,274,437 : Cost 69.28022003 : Time 797.71s : 7724.45 words/s
[2019-07-18 17:25:04] Ep. 3 : Up. 180000 : Sen. 4,561,804 : Cost 69.11846161 : Time 803.74s : 7716.90 words/s
[2019-07-18 17:25:04] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-18 17:25:13] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter180000.npz
[2019-07-18 17:25:19] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-18 17:25:29] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-18 17:25:54] [valid] Ep. 3 : Up. 180000 : cross-entropy : 55.1952 : new best
[2019-07-18 17:26:02] [valid] Ep. 3 : Up. 180000 : perplexity : 8.89849 : new best
[2019-07-18 17:27:09] [valid] Ep. 3 : Up. 180000 : translation : 24.58 : stalled 1 times (last best: 24.63)
[2019-07-18 17:40:36] Ep. 3 : Up. 182000 : Sen. 4,848,826 : Cost 69.22115326 : Time 931.23s : 6653.86 words/s
[2019-07-18 17:53:58] Ep. 3 : Up. 184000 : Sen. 5,136,113 : Cost 69.01586151 : Time 802.07s : 7736.15 words/s
[2019-07-18 18:07:15] Ep. 3 : Up. 186000 : Sen. 5,423,248 : Cost 68.60166931 : Time 797.60s : 7738.73 words/s
[2019-07-18 18:20:40] Ep. 3 : Up. 188000 : Sen. 5,710,387 : Cost 69.18775940 : Time 804.50s : 7732.81 words/s
[2019-07-18 18:34:01] Ep. 3 : Up. 190000 : Sen. 5,997,373 : Cost 69.05558777 : Time 801.57s : 7726.63 words/s
[2019-07-18 18:47:21] Ep. 3 : Up. 192000 : Sen. 6,284,932 : Cost 68.65715027 : Time 799.82s : 7732.57 words/s
[2019-07-18 19:00:43] Ep. 3 : Up. 194000 : Sen. 6,571,843 : Cost 68.76631927 : Time 801.43s : 7716.54 words/s
[2019-07-18 19:14:01] Ep. 3 : Up. 196000 : Sen. 6,858,270 : Cost 68.64712524 : Time 798.64s : 7724.33 words/s
[2019-07-18 19:27:25] Ep. 3 : Up. 198000 : Sen. 7,144,724 : Cost 69.13540649 : Time 803.86s : 7710.67 words/s
[2019-07-18 19:40:46] Ep. 3 : Up. 200000 : Sen. 7,431,926 : Cost 68.59691620 : Time 800.56s : 7731.34 words/s
[2019-07-18 19:40:46] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-18 19:40:55] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter200000.npz
[2019-07-18 19:41:01] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-18 19:41:11] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-18 19:41:36] [valid] Ep. 3 : Up. 200000 : cross-entropy : 54.5071 : new best
[2019-07-18 19:41:44] [valid] Ep. 3 : Up. 200000 : perplexity : 8.6593 : new best
[2019-07-18 19:42:50] [valid] Ep. 3 : Up. 200000 : translation : 24.73 : new best
[2019-07-18 19:56:14] Ep. 3 : Up. 202000 : Sen. 7,719,464 : Cost 68.66000366 : Time 928.33s : 6685.58 words/s
[2019-07-18 20:09:33] Ep. 3 : Up. 204000 : Sen. 8,006,532 : Cost 68.51899719 : Time 799.33s : 7727.32 words/s
[2019-07-18 20:22:53] Ep. 3 : Up. 206000 : Sen. 8,292,664 : Cost 68.50155640 : Time 799.56s : 7728.79 words/s
[2019-07-18 20:36:13] Ep. 3 : Up. 208000 : Sen. 8,579,282 : Cost 68.49674988 : Time 800.22s : 7743.45 words/s
[2019-07-18 20:49:33] Ep. 3 : Up. 210000 : Sen. 8,866,001 : Cost 68.39733887 : Time 799.45s : 7730.06 words/s
[2019-07-18 21:02:51] Ep. 3 : Up. 212000 : Sen. 9,152,132 : Cost 68.45789337 : Time 798.59s : 7731.05 words/s
[2019-07-18 21:16:13] Ep. 3 : Up. 214000 : Sen. 9,439,132 : Cost 68.40676880 : Time 801.99s : 7727.34 words/s
[2019-07-18 21:29:32] Ep. 3 : Up. 216000 : Sen. 9,725,036 : Cost 68.49382019 : Time 798.43s : 7729.79 words/s
[2019-07-18 21:42:51] Ep. 3 : Up. 218000 : Sen. 10,010,962 : Cost 68.45262146 : Time 799.10s : 7722.45 words/s
[2019-07-18 21:56:08] Ep. 3 : Up. 220000 : Sen. 10,296,460 : Cost 68.15298462 : Time 796.87s : 7724.95 words/s
[2019-07-18 21:56:08] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-18 21:56:17] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter220000.npz
[2019-07-18 21:56:24] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-18 21:56:36] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-18 21:57:02] [valid] Ep. 3 : Up. 220000 : cross-entropy : 53.8904 : new best
[2019-07-18 21:57:10] [valid] Ep. 3 : Up. 220000 : perplexity : 8.45038 : new best
[2019-07-18 21:58:17] [valid] Ep. 3 : Up. 220000 : translation : 24.46 : stalled 1 times (last best: 24.73)
[2019-07-18 22:11:40] Ep. 3 : Up. 222000 : Sen. 10,583,839 : Cost 68.20676422 : Time 932.56s : 6646.75 words/s
[2019-07-18 22:13:41] Seen 10627013 samples
[2019-07-18 22:13:41] Starting epoch 4
[2019-07-18 22:13:41] [data] Shuffling data
[2019-07-18 22:13:48] [data] Done reading 12702121 sentences
[2019-07-18 22:14:44] [data] Done shuffling 12702121 sentences to temp files
[2019-07-18 22:26:05] Ep. 4 : Up. 224000 : Sen. 243,356 : Cost 67.46045685 : Time 865.16s : 7149.17 words/s
[2019-07-18 22:39:26] Ep. 4 : Up. 226000 : Sen. 530,844 : Cost 67.42777252 : Time 800.52s : 7746.01 words/s
[2019-07-18 22:52:49] Ep. 4 : Up. 228000 : Sen. 818,733 : Cost 67.54698181 : Time 803.55s : 7742.13 words/s
[2019-07-18 23:06:13] Ep. 4 : Up. 230000 : Sen. 1,106,408 : Cost 67.36242676 : Time 803.59s : 7726.67 words/s
[2019-07-18 23:19:35] Ep. 4 : Up. 232000 : Sen. 1,393,650 : Cost 67.53665924 : Time 801.68s : 7739.59 words/s
[2019-07-18 23:33:00] Ep. 4 : Up. 234000 : Sen. 1,681,206 : Cost 67.46642303 : Time 804.95s : 7711.14 words/s
[2019-07-18 23:46:24] Ep. 4 : Up. 236000 : Sen. 1,968,163 : Cost 67.35301208 : Time 804.76s : 7705.80 words/s
[2019-07-18 23:59:49] Ep. 4 : Up. 238000 : Sen. 2,255,746 : Cost 67.43748474 : Time 804.24s : 7717.89 words/s
[2019-07-19 00:13:09] Ep. 4 : Up. 240000 : Sen. 2,543,052 : Cost 67.36542511 : Time 800.31s : 7752.93 words/s
[2019-07-19 00:13:09] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-19 00:13:19] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter240000.npz
[2019-07-19 00:13:26] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 00:13:35] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-19 00:14:01] [valid] Ep. 4 : Up. 240000 : cross-entropy : 53.5851 : new best
[2019-07-19 00:14:08] [valid] Ep. 4 : Up. 240000 : perplexity : 8.34881 : new best
[2019-07-19 00:15:15] [valid] Ep. 4 : Up. 240000 : translation : 24.51 : stalled 2 times (last best: 24.73)
[2019-07-19 00:28:41] Ep. 4 : Up. 242000 : Sen. 2,830,138 : Cost 67.52643585 : Time 932.19s : 6655.28 words/s
[2019-07-19 00:42:02] Ep. 4 : Up. 244000 : Sen. 3,117,196 : Cost 67.41590881 : Time 800.68s : 7735.48 words/s
[2019-07-19 00:55:21] Ep. 4 : Up. 246000 : Sen. 3,403,722 : Cost 67.24354553 : Time 798.93s : 7722.75 words/s
[2019-07-19 01:08:44] Ep. 4 : Up. 248000 : Sen. 3,691,694 : Cost 67.44334412 : Time 803.56s : 7737.26 words/s
[2019-07-19 01:22:05] Ep. 4 : Up. 250000 : Sen. 3,978,667 : Cost 67.22285461 : Time 800.59s : 7733.10 words/s
[2019-07-19 01:35:22] Ep. 4 : Up. 252000 : Sen. 4,266,020 : Cost 67.01660156 : Time 797.35s : 7759.37 words/s
[2019-07-19 01:48:40] Ep. 4 : Up. 254000 : Sen. 4,552,335 : Cost 67.16531372 : Time 797.65s : 7744.53 words/s
[2019-07-19 02:01:59] Ep. 4 : Up. 256000 : Sen. 4,839,735 : Cost 67.16841125 : Time 799.14s : 7753.10 words/s
[2019-07-19 02:15:19] Ep. 4 : Up. 258000 : Sen. 5,126,400 : Cost 67.28303528 : Time 799.65s : 7735.12 words/s
[2019-07-19 02:28:41] Ep. 4 : Up. 260000 : Sen. 5,412,956 : Cost 67.33621979 : Time 802.08s : 7727.57 words/s
[2019-07-19 02:28:41] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-19 02:28:50] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter260000.npz
[2019-07-19 02:28:57] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 02:29:06] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-19 02:29:35] [valid] Ep. 4 : Up. 260000 : cross-entropy : 53.2669 : new best
[2019-07-19 02:29:43] [valid] Ep. 4 : Up. 260000 : perplexity : 8.24427 : new best
[2019-07-19 02:30:52] [valid] Ep. 4 : Up. 260000 : translation : 24.6 : stalled 3 times (last best: 24.73)
[2019-07-19 02:44:15] Ep. 4 : Up. 262000 : Sen. 5,699,668 : Cost 66.92301941 : Time 934.12s : 6605.87 words/s
[2019-07-19 02:57:34] Ep. 4 : Up. 264000 : Sen. 5,986,145 : Cost 67.01255035 : Time 799.16s : 7716.57 words/s
[2019-07-19 03:10:55] Ep. 4 : Up. 266000 : Sen. 6,272,664 : Cost 67.15467834 : Time 800.74s : 7722.14 words/s
[2019-07-19 03:24:15] Ep. 4 : Up. 268000 : Sen. 6,559,130 : Cost 67.14485931 : Time 799.87s : 7722.31 words/s
[2019-07-19 03:37:40] Ep. 4 : Up. 270000 : Sen. 6,847,232 : Cost 67.18299866 : Time 805.09s : 7727.17 words/s
[2019-07-19 03:51:00] Ep. 4 : Up. 272000 : Sen. 7,134,489 : Cost 67.10137939 : Time 800.65s : 7748.18 words/s
[2019-07-19 04:04:21] Ep. 4 : Up. 274000 : Sen. 7,421,691 : Cost 66.82735443 : Time 800.50s : 7721.93 words/s
[2019-07-19 04:17:39] Ep. 4 : Up. 276000 : Sen. 7,707,419 : Cost 67.00386047 : Time 797.85s : 7716.35 words/s
[2019-07-19 04:30:58] Ep. 4 : Up. 278000 : Sen. 7,994,226 : Cost 66.99703217 : Time 799.29s : 7744.84 words/s
[2019-07-19 04:44:23] Ep. 4 : Up. 280000 : Sen. 8,282,733 : Cost 66.85585785 : Time 805.03s : 7724.04 words/s
[2019-07-19 04:44:23] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-19 04:44:32] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter280000.npz
[2019-07-19 04:44:39] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 04:44:48] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-19 04:45:16] [valid] Ep. 4 : Up. 280000 : cross-entropy : 52.8678 : new best
[2019-07-19 04:45:24] [valid] Ep. 4 : Up. 280000 : perplexity : 8.11499 : new best
[2019-07-19 04:46:31] [valid] Ep. 4 : Up. 280000 : translation : 24.71 : stalled 4 times (last best: 24.73)
[2019-07-19 04:59:57] Ep. 4 : Up. 282000 : Sen. 8,569,204 : Cost 66.81938934 : Time 933.60s : 6621.30 words/s
[2019-07-19 05:13:17] Ep. 4 : Up. 284000 : Sen. 8,855,676 : Cost 67.04796600 : Time 800.68s : 7732.51 words/s
[2019-07-19 05:26:42] Ep. 4 : Up. 286000 : Sen. 9,142,895 : Cost 66.85867310 : Time 804.43s : 7699.11 words/s
[2019-07-19 05:40:00] Ep. 4 : Up. 288000 : Sen. 9,428,723 : Cost 66.70967865 : Time 798.76s : 7725.83 words/s
[2019-07-19 05:53:23] Ep. 4 : Up. 290000 : Sen. 9,715,464 : Cost 66.88191986 : Time 802.40s : 7720.16 words/s
[2019-07-19 06:06:43] Ep. 4 : Up. 292000 : Sen. 10,003,068 : Cost 66.53475952 : Time 799.91s : 7734.71 words/s
[2019-07-19 06:20:05] Ep. 4 : Up. 294000 : Sen. 10,290,116 : Cost 66.91245270 : Time 802.21s : 7737.09 words/s
[2019-07-19 06:33:25] Ep. 4 : Up. 296000 : Sen. 10,577,501 : Cost 66.75235748 : Time 799.84s : 7747.91 words/s
[2019-07-19 06:35:43] Seen 10627013 samples
[2019-07-19 06:35:43] Starting epoch 5
[2019-07-19 06:35:43] [data] Shuffling data
[2019-07-19 06:35:50] [data] Done reading 12702121 sentences
[2019-07-19 06:36:47] [data] Done shuffling 12702121 sentences to temp files
[2019-07-19 06:47:52] Ep. 5 : Up. 298000 : Sen. 237,328 : Cost 65.80264282 : Time 866.96s : 7124.50 words/s
[2019-07-19 07:01:10] Ep. 5 : Up. 300000 : Sen. 523,834 : Cost 65.93326569 : Time 798.63s : 7744.25 words/s
[2019-07-19 07:01:10] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-19 07:01:23] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter300000.npz
[2019-07-19 07:01:31] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 07:01:40] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-19 07:02:07] [valid] Ep. 5 : Up. 300000 : cross-entropy : 52.5701 : new best
[2019-07-19 07:02:15] [valid] Ep. 5 : Up. 300000 : perplexity : 8.01986 : new best
[2019-07-19 07:03:23] [valid] Ep. 5 : Up. 300000 : translation : 24.76 : new best
[2019-07-19 07:16:47] Ep. 5 : Up. 302000 : Sen. 811,194 : Cost 65.75083160 : Time 936.93s : 6603.68 words/s
[2019-07-19 07:30:06] Ep. 5 : Up. 304000 : Sen. 1,097,532 : Cost 66.00164032 : Time 798.94s : 7737.14 words/s
[2019-07-19 07:43:27] Ep. 5 : Up. 306000 : Sen. 1,384,034 : Cost 65.73177338 : Time 801.20s : 7714.90 words/s
[2019-07-19 07:56:50] Ep. 5 : Up. 308000 : Sen. 1,671,732 : Cost 65.87168121 : Time 802.29s : 7726.92 words/s
[2019-07-19 08:10:10] Ep. 5 : Up. 310000 : Sen. 1,958,094 : Cost 66.08821869 : Time 800.55s : 7725.70 words/s
[2019-07-19 08:23:33] Ep. 5 : Up. 312000 : Sen. 2,245,608 : Cost 66.29979706 : Time 802.48s : 7741.51 words/s
[2019-07-19 08:36:54] Ep. 5 : Up. 314000 : Sen. 2,531,203 : Cost 66.18472290 : Time 801.20s : 7707.34 words/s
[2019-07-19 08:50:14] Ep. 5 : Up. 316000 : Sen. 2,817,607 : Cost 65.93744659 : Time 799.60s : 7722.62 words/s
[2019-07-19 09:03:35] Ep. 5 : Up. 318000 : Sen. 3,105,497 : Cost 65.79754639 : Time 801.38s : 7732.49 words/s
[2019-07-19 09:16:58] Ep. 5 : Up. 320000 : Sen. 3,393,770 : Cost 65.92166138 : Time 802.77s : 7728.19 words/s
[2019-07-19 09:16:58] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-19 09:17:06] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter320000.npz
[2019-07-19 09:17:13] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 09:17:22] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-19 09:17:48] [valid] Ep. 5 : Up. 320000 : cross-entropy : 52.439 : new best
[2019-07-19 09:17:56] [valid] Ep. 5 : Up. 320000 : perplexity : 7.97833 : new best
[2019-07-19 09:19:03] [valid] Ep. 5 : Up. 320000 : translation : 24.71 : stalled 1 times (last best: 24.76)
[2019-07-19 09:32:28] Ep. 5 : Up. 322000 : Sen. 3,680,973 : Cost 66.18434143 : Time 930.65s : 6676.53 words/s
[2019-07-19 09:45:52] Ep. 5 : Up. 324000 : Sen. 3,969,067 : Cost 65.91950989 : Time 803.84s : 7725.77 words/s
[2019-07-19 09:59:12] Ep. 5 : Up. 326000 : Sen. 4,255,374 : Cost 66.14903259 : Time 799.25s : 7740.82 words/s
[2019-07-19 10:12:34] Ep. 5 : Up. 328000 : Sen. 4,542,889 : Cost 66.01859283 : Time 802.85s : 7724.00 words/s
[2019-07-19 10:25:55] Ep. 5 : Up. 330000 : Sen. 4,829,964 : Cost 66.16590881 : Time 800.26s : 7739.38 words/s
[2019-07-19 10:39:15] Ep. 5 : Up. 332000 : Sen. 5,116,724 : Cost 65.92450714 : Time 800.14s : 7727.41 words/s
[2019-07-19 10:52:39] Ep. 5 : Up. 334000 : Sen. 5,404,784 : Cost 65.77779388 : Time 804.59s : 7717.34 words/s
[2019-07-19 11:06:02] Ep. 5 : Up. 336000 : Sen. 5,691,930 : Cost 66.11405182 : Time 802.87s : 7726.27 words/s
[2019-07-19 11:19:20] Ep. 5 : Up. 338000 : Sen. 5,978,128 : Cost 65.79778290 : Time 797.94s : 7725.27 words/s
[2019-07-19 11:32:39] Ep. 5 : Up. 340000 : Sen. 6,264,411 : Cost 65.73719788 : Time 798.41s : 7724.10 words/s
[2019-07-19 11:32:39] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-19 11:32:47] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter340000.npz
[2019-07-19 11:32:54] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 11:33:03] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-19 11:33:28] [valid] Ep. 5 : Up. 340000 : cross-entropy : 52.2071 : new best
[2019-07-19 11:33:36] [valid] Ep. 5 : Up. 340000 : perplexity : 7.9054 : new best
[2019-07-19 11:34:43] [valid] Ep. 5 : Up. 340000 : translation : 24.64 : stalled 2 times (last best: 24.76)
[2019-07-19 11:48:05] Ep. 5 : Up. 342000 : Sen. 6,551,349 : Cost 65.72612762 : Time 926.51s : 6668.49 words/s
[2019-07-19 12:01:27] Ep. 5 : Up. 344000 : Sen. 6,837,650 : Cost 66.33786774 : Time 801.42s : 7733.95 words/s
[2019-07-19 12:14:49] Ep. 5 : Up. 346000 : Sen. 7,125,413 : Cost 65.72515869 : Time 802.46s : 7712.04 words/s
[2019-07-19 12:28:12] Ep. 5 : Up. 348000 : Sen. 7,411,332 : Cost 66.10272980 : Time 802.76s : 7698.15 words/s
[2019-07-19 12:41:34] Ep. 5 : Up. 350000 : Sen. 7,698,698 : Cost 66.02239990 : Time 802.39s : 7732.64 words/s
[2019-07-19 12:54:58] Ep. 5 : Up. 352000 : Sen. 7,986,783 : Cost 65.96783447 : Time 803.76s : 7735.90 words/s
[2019-07-19 13:08:16] Ep. 5 : Up. 354000 : Sen. 8,273,067 : Cost 66.10475159 : Time 798.57s : 7742.50 words/s
[2019-07-19 13:21:36] Ep. 5 : Up. 356000 : Sen. 8,560,264 : Cost 65.92623901 : Time 799.21s : 7741.66 words/s
[2019-07-19 13:34:56] Ep. 5 : Up. 358000 : Sen. 8,846,414 : Cost 65.89042664 : Time 800.50s : 7713.20 words/s
[2019-07-19 13:48:15] Ep. 5 : Up. 360000 : Sen. 9,132,281 : Cost 65.79972839 : Time 798.64s : 7724.59 words/s
[2019-07-19 13:48:15] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-19 13:48:24] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter360000.npz
[2019-07-19 13:48:32] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 13:48:41] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-19 13:49:08] [valid] Ep. 5 : Up. 360000 : cross-entropy : 52.0077 : new best
[2019-07-19 13:49:16] [valid] Ep. 5 : Up. 360000 : perplexity : 7.84321 : new best
[2019-07-19 13:50:23] [valid] Ep. 5 : Up. 360000 : translation : 24.92 : new best
[2019-07-19 14:03:45] Ep. 5 : Up. 362000 : Sen. 9,418,849 : Cost 65.76083374 : Time 930.32s : 6636.31 words/s
[2019-07-19 14:17:08] Ep. 5 : Up. 364000 : Sen. 9,706,357 : Cost 66.11664581 : Time 802.75s : 7756.49 words/s
[2019-07-19 14:30:27] Ep. 5 : Up. 366000 : Sen. 9,993,312 : Cost 65.93418884 : Time 799.54s : 7742.39 words/s
[2019-07-19 14:43:50] Ep. 5 : Up. 368000 : Sen. 10,281,045 : Cost 65.80433655 : Time 803.02s : 7726.02 words/s
[2019-07-19 14:57:11] Ep. 5 : Up. 370000 : Sen. 10,567,392 : Cost 65.81436920 : Time 800.18s : 7725.75 words/s
[2019-07-19 14:59:58] Seen 10627013 samples
[2019-07-19 14:59:58] Starting epoch 6
[2019-07-19 14:59:58] [data] Shuffling data
[2019-07-19 15:00:05] [data] Done reading 12702121 sentences
[2019-07-19 15:00:59] [data] Done shuffling 12702121 sentences to temp files
[2019-07-19 15:11:34] Ep. 6 : Up. 372000 : Sen. 226,504 : Cost 65.25767517 : Time 863.54s : 7164.20 words/s
[2019-07-19 15:24:58] Ep. 6 : Up. 374000 : Sen. 514,227 : Cost 64.79520416 : Time 803.45s : 7714.53 words/s
[2019-07-19 15:38:19] Ep. 6 : Up. 376000 : Sen. 801,012 : Cost 64.90422821 : Time 801.60s : 7710.49 words/s
[2019-07-19 15:51:38] Ep. 6 : Up. 378000 : Sen. 1,087,165 : Cost 64.73126984 : Time 798.83s : 7715.85 words/s
[2019-07-19 16:05:00] Ep. 6 : Up. 380000 : Sen. 1,374,293 : Cost 65.25019836 : Time 801.75s : 7739.76 words/s
[2019-07-19 16:05:00] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-19 16:05:08] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter380000.npz
[2019-07-19 16:05:15] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 16:05:24] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-19 16:05:49] [valid] Ep. 6 : Up. 380000 : cross-entropy : 51.8331 : new best
[2019-07-19 16:05:57] [valid] Ep. 6 : Up. 380000 : perplexity : 7.78918 : new best
[2019-07-19 16:07:03] [valid] Ep. 6 : Up. 380000 : translation : 24.94 : new best
[2019-07-19 16:20:27] Ep. 6 : Up. 382000 : Sen. 1,661,228 : Cost 64.98901367 : Time 927.10s : 6675.34 words/s
[2019-07-19 16:33:48] Ep. 6 : Up. 384000 : Sen. 1,948,628 : Cost 65.18444061 : Time 800.70s : 7741.89 words/s
[2019-07-19 15:36:04] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-19 15:36:04] [marian] Running on bil as process 7431 with command line:
[2019-07-19 15:36:04] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz -T . --devices 1 --train-sets ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.de ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.en --vocabs ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.de.json ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.en.json --mini-batch-fit -w 5000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/dev.bpe.de ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/dev.out --valid-script-path ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/train.log --valid-log ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/valid.log
[2019-07-19 15:36:04] [config] after-batches: 0
[2019-07-19 15:36:04] [config] after-epochs: 0
[2019-07-19 15:36:04] [config] allow-unk: false
[2019-07-19 15:36:04] [config] beam-size: 12
[2019-07-19 15:36:04] [config] bert-class-symbol: "[CLS]"
[2019-07-19 15:36:04] [config] bert-mask-symbol: "[MASK]"
[2019-07-19 15:36:04] [config] bert-masking-fraction: 0.15
[2019-07-19 15:36:04] [config] bert-sep-symbol: "[SEP]"
[2019-07-19 15:36:04] [config] bert-train-type-embeddings: true
[2019-07-19 15:36:04] [config] bert-type-vocab-size: 2
[2019-07-19 15:36:04] [config] best-deep: false
[2019-07-19 15:36:04] [config] clip-gemm: 0
[2019-07-19 15:36:04] [config] clip-norm: 1
[2019-07-19 15:36:04] [config] cost-type: ce-mean
[2019-07-19 15:36:04] [config] cpu-threads: 0
[2019-07-19 15:36:04] [config] data-weighting: ""
[2019-07-19 15:36:04] [config] data-weighting-type: sentence
[2019-07-19 15:36:04] [config] dec-cell: gru
[2019-07-19 15:36:04] [config] dec-cell-base-depth: 2
[2019-07-19 15:36:04] [config] dec-cell-high-depth: 1
[2019-07-19 15:36:04] [config] dec-depth: 1
[2019-07-19 15:36:04] [config] devices:
[2019-07-19 15:36:04] [config]   - 1
[2019-07-19 15:36:04] [config] dim-emb: 512
[2019-07-19 15:36:04] [config] dim-rnn: 1024
[2019-07-19 15:36:04] [config] dim-vocabs:
[2019-07-19 15:36:04] [config]   - 50000
[2019-07-19 15:36:04] [config]   - 50000
[2019-07-19 15:36:04] [config] disp-first: 0
[2019-07-19 15:36:04] [config] disp-freq: 2000
[2019-07-19 15:36:04] [config] disp-label-counts: false
[2019-07-19 15:36:04] [config] dropout-rnn: 0.2
[2019-07-19 15:36:04] [config] dropout-src: 0.1
[2019-07-19 15:36:04] [config] dropout-trg: 0.1
[2019-07-19 15:36:04] [config] dump-config: ""
[2019-07-19 15:36:04] [config] early-stopping: 5
[2019-07-19 15:36:04] [config] embedding-fix-src: false
[2019-07-19 15:36:04] [config] embedding-fix-trg: false
[2019-07-19 15:36:04] [config] embedding-normalization: false
[2019-07-19 15:36:04] [config] embedding-vectors:
[2019-07-19 15:36:04] [config]   []
[2019-07-19 15:36:04] [config] enc-cell: gru
[2019-07-19 15:36:04] [config] enc-cell-depth: 1
[2019-07-19 15:36:04] [config] enc-depth: 1
[2019-07-19 15:36:04] [config] enc-type: bidirectional
[2019-07-19 15:36:04] [config] exponential-smoothing: 0.0001
[2019-07-19 15:36:04] [config] grad-dropping-momentum: 0
[2019-07-19 15:36:04] [config] grad-dropping-rate: 0
[2019-07-19 15:36:04] [config] grad-dropping-warmup: 100
[2019-07-19 15:36:04] [config] guided-alignment: none
[2019-07-19 15:36:04] [config] guided-alignment-cost: mse
[2019-07-19 15:36:04] [config] guided-alignment-weight: 0.1
[2019-07-19 15:36:04] [config] ignore-model-config: false
[2019-07-19 15:36:04] [config] input-types:
[2019-07-19 15:36:04] [config]   []
[2019-07-19 15:36:04] [config] interpolate-env-vars: false
[2019-07-19 15:36:04] [config] keep-best: false
[2019-07-19 15:36:04] [config] label-smoothing: 0
[2019-07-19 15:36:04] [config] layer-normalization: true
[2019-07-19 15:36:04] [config] learn-rate: 0.0001
[2019-07-19 15:36:04] [config] log: ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/train.log
[2019-07-19 15:36:04] [config] log-level: info
[2019-07-19 15:36:04] [config] log-time-zone: ""
[2019-07-19 15:36:04] [config] lr-decay: 0
[2019-07-19 15:36:04] [config] lr-decay-freq: 50000
[2019-07-19 15:36:04] [config] lr-decay-inv-sqrt:
[2019-07-19 15:36:04] [config]   - 0
[2019-07-19 15:36:04] [config] lr-decay-repeat-warmup: false
[2019-07-19 15:36:04] [config] lr-decay-reset-optimizer: false
[2019-07-19 15:36:04] [config] lr-decay-start:
[2019-07-19 15:36:04] [config]   - 10
[2019-07-19 15:36:04] [config]   - 1
[2019-07-19 15:36:04] [config] lr-decay-strategy: epoch+stalled
[2019-07-19 15:36:04] [config] lr-report: false
[2019-07-19 15:36:04] [config] lr-warmup: 0
[2019-07-19 15:36:04] [config] lr-warmup-at-reload: false
[2019-07-19 15:36:04] [config] lr-warmup-cycle: false
[2019-07-19 15:36:04] [config] lr-warmup-start-rate: 0
[2019-07-19 15:36:04] [config] max-length: 50
[2019-07-19 15:36:04] [config] max-length-crop: false
[2019-07-19 15:36:04] [config] max-length-factor: 3
[2019-07-19 15:36:04] [config] maxi-batch: 100
[2019-07-19 15:36:04] [config] maxi-batch-sort: trg
[2019-07-19 15:36:04] [config] mini-batch: 64
[2019-07-19 15:36:04] [config] mini-batch-fit: true
[2019-07-19 15:36:04] [config] mini-batch-fit-step: 10
[2019-07-19 15:36:04] [config] mini-batch-overstuff: 1
[2019-07-19 15:36:04] [config] mini-batch-track-lr: false
[2019-07-19 15:36:04] [config] mini-batch-understuff: 1
[2019-07-19 15:36:04] [config] mini-batch-warmup: 0
[2019-07-19 15:36:04] [config] mini-batch-words: 0
[2019-07-19 15:36:04] [config] mini-batch-words-ref: 0
[2019-07-19 15:36:04] [config] model: ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 15:36:04] [config] multi-loss-type: sum
[2019-07-19 15:36:04] [config] multi-node: false
[2019-07-19 15:36:04] [config] multi-node-overlap: true
[2019-07-19 15:36:04] [config] n-best: false
[2019-07-19 15:36:04] [config] no-nccl: false
[2019-07-19 15:36:04] [config] no-reload: false
[2019-07-19 15:36:04] [config] no-restore-corpus: false
[2019-07-19 15:36:04] [config] no-shuffle: false
[2019-07-19 15:36:04] [config] normalize: 1
[2019-07-19 15:36:04] [config] num-devices: 0
[2019-07-19 15:36:04] [config] optimizer: adam
[2019-07-19 15:36:04] [config] optimizer-delay: 1
[2019-07-19 15:36:04] [config] optimizer-params:
[2019-07-19 15:36:04] [config]   []
[2019-07-19 15:36:04] [config] overwrite: false
[2019-07-19 15:36:04] [config] pretrained-model: ""
[2019-07-19 15:36:04] [config] quiet: false
[2019-07-19 15:36:04] [config] quiet-translation: true
[2019-07-19 15:36:04] [config] relative-paths: false
[2019-07-19 15:36:04] [config] right-left: false
[2019-07-19 15:36:04] [config] save-freq: 20000
[2019-07-19 15:36:04] [config] seed: 1111
[2019-07-19 15:36:04] [config] shuffle-in-ram: false
[2019-07-19 15:36:04] [config] skip: false
[2019-07-19 15:36:04] [config] sqlite: ""
[2019-07-19 15:36:04] [config] sqlite-drop: false
[2019-07-19 15:36:04] [config] sync-sgd: true
[2019-07-19 15:36:04] [config] tempdir: .
[2019-07-19 15:36:04] [config] tied-embeddings: false
[2019-07-19 15:36:04] [config] tied-embeddings-all: false
[2019-07-19 15:36:04] [config] tied-embeddings-src: false
[2019-07-19 15:36:04] [config] train-sets:
[2019-07-19 15:36:04] [config]   - ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.de
[2019-07-19 15:36:04] [config]   - ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.en
[2019-07-19 15:36:04] [config] transformer-aan-activation: swish
[2019-07-19 15:36:04] [config] transformer-aan-depth: 2
[2019-07-19 15:36:04] [config] transformer-aan-nogate: false
[2019-07-19 15:36:04] [config] transformer-decoder-autoreg: self-attention
[2019-07-19 15:36:04] [config] transformer-dim-aan: 2048
[2019-07-19 15:36:04] [config] transformer-dim-ffn: 2048
[2019-07-19 15:36:04] [config] transformer-dropout: 0
[2019-07-19 15:36:04] [config] transformer-dropout-attention: 0
[2019-07-19 15:36:04] [config] transformer-dropout-ffn: 0
[2019-07-19 15:36:04] [config] transformer-ffn-activation: swish
[2019-07-19 15:36:04] [config] transformer-ffn-depth: 2
[2019-07-19 15:36:04] [config] transformer-guided-alignment-layer: last
[2019-07-19 15:36:04] [config] transformer-heads: 8
[2019-07-19 15:36:04] [config] transformer-no-projection: false
[2019-07-19 15:36:04] [config] transformer-postprocess: dan
[2019-07-19 15:36:04] [config] transformer-postprocess-emb: d
[2019-07-19 15:36:04] [config] transformer-preprocess: ""
[2019-07-19 15:36:04] [config] transformer-tied-layers:
[2019-07-19 15:36:04] [config]   []
[2019-07-19 15:36:04] [config] transformer-train-position-embeddings: false
[2019-07-19 15:36:04] [config] type: amun
[2019-07-19 15:36:04] [config] ulr: false
[2019-07-19 15:36:04] [config] ulr-dim-emb: 0
[2019-07-19 15:36:04] [config] ulr-dropout: 0
[2019-07-19 15:36:04] [config] ulr-keys-vectors: ""
[2019-07-19 15:36:04] [config] ulr-query-vectors: ""
[2019-07-19 15:36:04] [config] ulr-softmax-temperature: 1
[2019-07-19 15:36:04] [config] ulr-trainable-transformation: false
[2019-07-19 15:36:04] [config] valid-freq: 20000
[2019-07-19 15:36:04] [config] valid-log: ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/valid.log
[2019-07-19 15:36:04] [config] valid-max-length: 1000
[2019-07-19 15:36:04] [config] valid-metrics:
[2019-07-19 15:36:04] [config]   - cross-entropy
[2019-07-19 15:36:04] [config]   - perplexity
[2019-07-19 15:36:04] [config]   - translation
[2019-07-19 15:36:04] [config] valid-mini-batch: 8
[2019-07-19 15:36:04] [config] valid-script-path: ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/score-dev.sh
[2019-07-19 15:36:04] [config] valid-sets:
[2019-07-19 15:36:04] [config]   - ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/dev.bpe.de
[2019-07-19 15:36:04] [config]   - ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/dev.bpe.en
[2019-07-19 15:36:04] [config] valid-translation-output: ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/dev.out
[2019-07-19 15:36:04] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-19 15:36:04] [config] vocabs:
[2019-07-19 15:36:04] [config]   - ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.de.json
[2019-07-19 15:36:04] [config]   - ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.en.json
[2019-07-19 15:36:04] [config] word-penalty: 0
[2019-07-19 15:36:04] [config] workspace: 5000
[2019-07-19 15:36:04] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-19 15:36:04] Using synchronous training
[2019-07-19 15:36:04] [data] Loading vocabulary from JSON/Yaml file ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.de.json
[2019-07-19 15:36:04] [data] Using unused word id eos for 0
[2019-07-19 15:36:04] [data] Using unused word id UNK for 1
[2019-07-19 15:36:04] [data] Setting vocabulary size for input 0 to 50000
[2019-07-19 15:36:04] [data] Loading vocabulary from JSON/Yaml file ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/data/train.bpe.en.json
[2019-07-19 15:36:05] [data] Using unused word id eos for 0
[2019-07-19 15:36:05] [data] Using unused word id UNK for 1
[2019-07-19 15:36:05] [data] Setting vocabulary size for input 1 to 50000
[2019-07-19 15:36:05] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-19 15:36:05] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-19 15:36:07] [memory] Extending reserved space to 5120 MB (device gpu1)
[2019-07-19 15:36:07] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-19 15:36:07] [comm] NCCLCommunicator constructed successfully.
[2019-07-19 15:36:07] [training] Using 1 GPUs
[2019-07-19 15:36:07] [memory] Reserving 422 MB, device gpu1
[2019-07-19 15:36:07] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-19 15:36:07] [memory] Reserving 422 MB, device gpu1
[2019-07-19 15:36:12] [batching] Done. Typical MB size is 6880 target words
[2019-07-19 15:36:12] [memory] Extending reserved space to 5120 MB (device gpu1)
[2019-07-19 15:36:12] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-19 15:36:12] [comm] NCCLCommunicator constructed successfully.
[2019-07-19 15:36:12] [training] Using 1 GPUs
[2019-07-19 15:36:12] Loading model from ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-19 15:36:16] Loading Adam parameters from ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-19 15:36:19] [memory] Reserving 844 MB, device gpu1
[2019-07-19 15:36:21] [training] Model reloaded from ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 15:36:21] [data] Restoring the corpus state to epoch 6, batch 380000
[2019-07-19 15:36:21] [data] Shuffling data
[2019-07-19 15:36:35] [data] Done reading 12702121 sentences
[2019-07-19 15:37:55] [data] Done shuffling 12702121 sentences to temp files
[2019-07-19 15:39:01] Training started
[2019-07-19 15:39:01] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-07-19 15:39:01] [memory] Reserving 422 MB, device gpu1
[2019-07-19 15:39:01] [memory] Reserving 422 MB, device gpu1
[2019-07-19 15:39:01] Loading model from ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 15:39:04] [memory] Reserving 422 MB, device cpu0
[2019-07-19 15:39:05] [memory] Reserving 422 MB, device gpu1
[2019-07-19 15:45:42] Ep. 6 : Up. 382000 : Sen. 1,661,228 : Cost 65.56139374 : Time 576.96s : 10726.43 words/s
[2019-07-19 15:52:19] Ep. 6 : Up. 384000 : Sen. 1,948,628 : Cost 65.29219055 : Time 397.13s : 15609.23 words/s
[2019-07-19 15:58:56] Ep. 6 : Up. 386000 : Sen. 2,235,010 : Cost 65.21013641 : Time 396.82s : 15577.38 words/s
[2019-07-19 16:05:32] Ep. 6 : Up. 388000 : Sen. 2,522,175 : Cost 65.07729340 : Time 396.21s : 15624.61 words/s
[2019-07-19 16:12:08] Ep. 6 : Up. 390000 : Sen. 2,808,808 : Cost 65.30188751 : Time 396.01s : 15611.97 words/s
[2019-07-19 16:18:44] Ep. 6 : Up. 392000 : Sen. 3,094,694 : Cost 65.28893280 : Time 395.68s : 15606.62 words/s
[2019-07-19 16:25:20] Ep. 6 : Up. 394000 : Sen. 3,381,768 : Cost 65.28874969 : Time 396.55s : 15647.01 words/s
[2019-07-19 16:31:57] Ep. 6 : Up. 396000 : Sen. 3,668,824 : Cost 64.96040344 : Time 396.39s : 15599.92 words/s
[2019-07-19 16:38:35] Ep. 6 : Up. 398000 : Sen. 3,955,464 : Cost 65.40760040 : Time 397.99s : 15554.11 words/s
[2019-07-19 16:45:13] Ep. 6 : Up. 400000 : Sen. 4,242,207 : Cost 65.05211639 : Time 398.47s : 15527.53 words/s
[2019-07-19 16:45:13] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-19 16:45:19] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter400000.npz
[2019-07-19 16:45:21] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 16:45:28] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-19 16:45:49] [valid] Ep. 6 : Up. 400000 : cross-entropy : 51.767 : new best
[2019-07-19 16:45:55] [valid] Ep. 6 : Up. 400000 : perplexity : 7.76881 : new best
[2019-07-19 16:46:50] [valid] Ep. 6 : Up. 400000 : translation : 25.15 : new best
[2019-07-19 16:53:29] Ep. 6 : Up. 402000 : Sen. 4,528,565 : Cost 65.32222748 : Time 495.58s : 12491.23 words/s
[2019-07-19 17:00:04] Ep. 6 : Up. 404000 : Sen. 4,815,012 : Cost 65.03961945 : Time 395.47s : 15575.94 words/s
[2019-07-19 17:06:42] Ep. 6 : Up. 406000 : Sen. 5,102,288 : Cost 65.58418274 : Time 398.20s : 15617.65 words/s
[2019-07-19 17:13:21] Ep. 6 : Up. 408000 : Sen. 5,389,586 : Cost 65.15734100 : Time 398.37s : 15556.73 words/s
[2019-07-19 17:19:56] Ep. 6 : Up. 410000 : Sen. 5,675,559 : Cost 65.07682800 : Time 395.09s : 15588.86 words/s
[2019-07-19 17:26:34] Ep. 6 : Up. 412000 : Sen. 5,963,282 : Cost 65.09567261 : Time 397.87s : 15601.94 words/s
[2019-07-19 17:33:12] Ep. 6 : Up. 414000 : Sen. 6,249,870 : Cost 65.15154266 : Time 397.93s : 15539.04 words/s
[2019-07-19 17:39:50] Ep. 6 : Up. 416000 : Sen. 6,537,043 : Cost 65.22864532 : Time 398.06s : 15572.24 words/s
[2019-07-19 17:46:27] Ep. 6 : Up. 418000 : Sen. 6,823,102 : Cost 65.31525421 : Time 396.96s : 15567.75 words/s
[2019-07-19 17:53:02] Ep. 6 : Up. 420000 : Sen. 7,109,437 : Cost 64.88813782 : Time 395.20s : 15612.09 words/s
[2019-07-19 17:53:02] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-19 17:53:08] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter420000.npz
[2019-07-19 17:53:11] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 17:53:17] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-19 17:53:38] [valid] Ep. 6 : Up. 420000 : cross-entropy : 51.6045 : new best
[2019-07-19 17:53:45] [valid] Ep. 6 : Up. 420000 : perplexity : 7.71898 : new best
[2019-07-19 17:54:39] [valid] Ep. 6 : Up. 420000 : translation : 25.05 : stalled 1 times (last best: 25.15)
[2019-07-19 18:01:18] Ep. 6 : Up. 422000 : Sen. 7,396,352 : Cost 64.82761383 : Time 496.11s : 12447.18 words/s
[2019-07-19 18:07:55] Ep. 6 : Up. 424000 : Sen. 7,682,834 : Cost 65.17443848 : Time 397.39s : 15555.01 words/s
[2019-07-19 18:14:33] Ep. 6 : Up. 426000 : Sen. 7,969,714 : Cost 65.20298004 : Time 397.44s : 15581.49 words/s
[2019-07-19 18:21:09] Ep. 6 : Up. 428000 : Sen. 8,256,616 : Cost 64.74993134 : Time 396.00s : 15583.83 words/s
[2019-07-19 18:27:46] Ep. 6 : Up. 430000 : Sen. 8,543,298 : Cost 64.96771240 : Time 397.27s : 15573.20 words/s
[2019-07-19 18:34:23] Ep. 6 : Up. 432000 : Sen. 8,828,905 : Cost 65.24475098 : Time 397.51s : 15508.66 words/s
[2019-07-19 18:41:02] Ep. 6 : Up. 434000 : Sen. 9,115,971 : Cost 64.97241974 : Time 398.25s : 15547.89 words/s
[2019-07-19 18:47:40] Ep. 6 : Up. 436000 : Sen. 9,402,268 : Cost 64.87143707 : Time 398.35s : 15499.22 words/s
[2019-07-19 18:54:20] Ep. 6 : Up. 438000 : Sen. 9,690,801 : Cost 65.21125031 : Time 399.69s : 15610.66 words/s
[2019-07-19 19:00:58] Ep. 6 : Up. 440000 : Sen. 9,978,038 : Cost 64.98481750 : Time 397.99s : 15578.04 words/s
[2019-07-19 19:00:58] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-19 19:01:04] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter440000.npz
[2019-07-19 19:01:06] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 19:01:12] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-19 19:01:33] [valid] Ep. 6 : Up. 440000 : cross-entropy : 51.4904 : new best
[2019-07-19 19:01:39] [valid] Ep. 6 : Up. 440000 : perplexity : 7.68417 : new best
[2019-07-19 19:02:33] [valid] Ep. 6 : Up. 440000 : translation : 25.07 : stalled 2 times (last best: 25.15)
[2019-07-19 19:09:12] Ep. 6 : Up. 442000 : Sen. 10,264,564 : Cost 65.13117218 : Time 494.69s : 12501.57 words/s
[2019-07-19 19:15:48] Ep. 6 : Up. 444000 : Sen. 10,550,679 : Cost 65.04418945 : Time 395.85s : 15612.17 words/s
[2019-07-19 19:17:34] Seen 10627013 samples
[2019-07-19 19:17:34] Starting epoch 7
[2019-07-19 19:17:34] [data] Shuffling data
[2019-07-19 19:17:49] [data] Done reading 12702121 sentences
[2019-07-19 19:19:08] [data] Done shuffling 12702121 sentences to temp files
[2019-07-19 19:24:04] Ep. 7 : Up. 446000 : Sen. 210,195 : Cost 64.28134918 : Time 495.29s : 12479.01 words/s
[2019-07-19 19:30:42] Ep. 7 : Up. 448000 : Sen. 497,082 : Cost 64.33388519 : Time 398.74s : 15539.46 words/s
[2019-07-19 19:37:20] Ep. 7 : Up. 450000 : Sen. 783,383 : Cost 64.37246704 : Time 397.24s : 15558.11 words/s
[2019-07-19 19:43:57] Ep. 7 : Up. 452000 : Sen. 1,070,410 : Cost 64.29691315 : Time 397.76s : 15561.26 words/s
[2019-07-19 19:50:35] Ep. 7 : Up. 454000 : Sen. 1,356,438 : Cost 64.45847321 : Time 398.13s : 15507.36 words/s
[2019-07-19 19:57:14] Ep. 7 : Up. 456000 : Sen. 1,643,295 : Cost 64.62007141 : Time 398.52s : 15562.23 words/s
[2019-07-19 20:03:52] Ep. 7 : Up. 458000 : Sen. 1,930,320 : Cost 64.30726624 : Time 397.85s : 15560.83 words/s
[2019-07-19 20:10:28] Ep. 7 : Up. 460000 : Sen. 2,216,614 : Cost 64.16470337 : Time 395.72s : 15559.34 words/s
[2019-07-19 20:10:28] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-19 20:10:34] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter460000.npz
[2019-07-19 20:10:36] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 20:10:42] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-19 20:11:03] [valid] Ep. 7 : Up. 460000 : cross-entropy : 51.43 : new best
[2019-07-19 20:11:10] [valid] Ep. 7 : Up. 460000 : perplexity : 7.66583 : new best
[2019-07-19 20:12:03] [valid] Ep. 7 : Up. 460000 : translation : 25.21 : new best
[2019-07-19 20:18:43] Ep. 7 : Up. 462000 : Sen. 2,502,873 : Cost 64.49327087 : Time 495.14s : 12482.31 words/s
[2019-07-19 20:25:20] Ep. 7 : Up. 464000 : Sen. 2,789,212 : Cost 64.34077454 : Time 397.06s : 15551.56 words/s
[2019-07-19 20:31:57] Ep. 7 : Up. 466000 : Sen. 3,075,315 : Cost 64.29845428 : Time 396.83s : 15539.28 words/s
[2019-07-19 20:38:35] Ep. 7 : Up. 468000 : Sen. 3,362,704 : Cost 64.25735474 : Time 398.35s : 15581.42 words/s
[2019-07-19 20:45:13] Ep. 7 : Up. 470000 : Sen. 3,649,678 : Cost 64.26587677 : Time 397.77s : 15560.83 words/s
[2019-07-19 20:51:50] Ep. 7 : Up. 472000 : Sen. 3,935,868 : Cost 64.51847076 : Time 397.63s : 15531.83 words/s
[2019-07-19 20:58:29] Ep. 7 : Up. 474000 : Sen. 4,222,938 : Cost 64.58235931 : Time 398.33s : 15583.29 words/s
[2019-07-19 21:05:08] Ep. 7 : Up. 476000 : Sen. 4,510,390 : Cost 64.24571228 : Time 399.05s : 15561.66 words/s
[2019-07-19 21:11:45] Ep. 7 : Up. 478000 : Sen. 4,796,712 : Cost 64.32538605 : Time 397.02s : 15555.45 words/s
[2019-07-19 21:18:24] Ep. 7 : Up. 480000 : Sen. 5,084,346 : Cost 64.50569916 : Time 399.07s : 15560.87 words/s
[2019-07-19 21:18:24] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-19 21:18:30] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter480000.npz
[2019-07-19 21:18:32] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 21:18:39] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-19 21:18:59] [valid] Ep. 7 : Up. 480000 : cross-entropy : 51.3763 : new best
[2019-07-19 21:19:06] [valid] Ep. 7 : Up. 480000 : perplexity : 7.64952 : new best
[2019-07-19 21:20:00] [valid] Ep. 7 : Up. 480000 : translation : 25.16 : stalled 1 times (last best: 25.21)
[2019-07-19 21:26:38] Ep. 7 : Up. 482000 : Sen. 5,369,996 : Cost 64.31430817 : Time 494.62s : 12456.72 words/s
[2019-07-19 21:33:15] Ep. 7 : Up. 484000 : Sen. 5,656,940 : Cost 64.43225861 : Time 396.60s : 15580.46 words/s
[2019-07-19 21:39:52] Ep. 7 : Up. 486000 : Sen. 5,943,585 : Cost 64.66914368 : Time 397.15s : 15576.09 words/s
[2019-07-19 21:46:32] Ep. 7 : Up. 488000 : Sen. 6,230,230 : Cost 64.63852692 : Time 399.37s : 15527.37 words/s
[2019-07-19 21:53:10] Ep. 7 : Up. 490000 : Sen. 6,518,318 : Cost 64.36124420 : Time 398.54s : 15575.78 words/s
[2019-07-19 21:59:50] Ep. 7 : Up. 492000 : Sen. 6,806,181 : Cost 64.64167786 : Time 399.95s : 15545.38 words/s
[2019-07-19 22:06:27] Ep. 7 : Up. 494000 : Sen. 7,093,357 : Cost 64.29811096 : Time 397.39s : 15591.74 words/s
[2019-07-19 22:13:05] Ep. 7 : Up. 496000 : Sen. 7,379,826 : Cost 64.45674896 : Time 397.65s : 15524.61 words/s
[2019-07-19 22:19:42] Ep. 7 : Up. 498000 : Sen. 7,665,306 : Cost 64.44029999 : Time 396.90s : 15534.27 words/s
[2019-07-19 22:26:20] Ep. 7 : Up. 500000 : Sen. 7,952,357 : Cost 64.55971527 : Time 398.40s : 15548.90 words/s
[2019-07-19 22:26:20] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-19 22:26:28] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter500000.npz
[2019-07-19 22:26:30] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 22:26:37] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-19 22:26:58] [valid] Ep. 7 : Up. 500000 : cross-entropy : 51.212 : new best
[2019-07-19 22:27:05] [valid] Ep. 7 : Up. 500000 : perplexity : 7.59991 : new best
[2019-07-19 22:27:59] [valid] Ep. 7 : Up. 500000 : translation : 25.11 : stalled 2 times (last best: 25.21)
[2019-07-19 22:34:40] Ep. 7 : Up. 502000 : Sen. 8,240,230 : Cost 64.23291016 : Time 499.64s : 12411.79 words/s
[2019-07-19 22:41:18] Ep. 7 : Up. 504000 : Sen. 8,527,729 : Cost 64.35249329 : Time 398.43s : 15582.43 words/s
[2019-07-19 22:47:56] Ep. 7 : Up. 506000 : Sen. 8,814,941 : Cost 64.36904144 : Time 397.60s : 15551.80 words/s
[2019-07-19 22:54:34] Ep. 7 : Up. 508000 : Sen. 9,101,935 : Cost 64.31668091 : Time 397.96s : 15555.78 words/s
[2019-07-19 23:01:12] Ep. 7 : Up. 510000 : Sen. 9,389,932 : Cost 64.38959503 : Time 398.37s : 15587.60 words/s
[2019-07-19 23:07:51] Ep. 7 : Up. 512000 : Sen. 9,677,258 : Cost 64.56185150 : Time 398.33s : 15580.22 words/s
[2019-07-19 23:14:29] Ep. 7 : Up. 514000 : Sen. 9,965,412 : Cost 64.38834381 : Time 397.83s : 15613.85 words/s
[2019-07-19 23:21:05] Ep. 7 : Up. 516000 : Sen. 10,251,702 : Cost 64.49798584 : Time 396.53s : 15548.12 words/s
[2019-07-19 23:27:43] Ep. 7 : Up. 518000 : Sen. 10,538,582 : Cost 64.39415741 : Time 397.66s : 15543.66 words/s
[2019-07-19 23:29:46] Seen 10627013 samples
[2019-07-19 23:29:46] Starting epoch 8
[2019-07-19 23:29:46] [data] Shuffling data
[2019-07-19 23:29:56] [data] Done reading 12702121 sentences
[2019-07-19 23:31:15] [data] Done shuffling 12702121 sentences to temp files
[2019-07-19 23:35:55] Ep. 8 : Up. 520000 : Sen. 198,749 : Cost 64.08098602 : Time 492.03s : 12610.87 words/s
[2019-07-19 23:35:55] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-19 23:36:01] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter520000.npz
[2019-07-19 23:36:04] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-19 23:36:09] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-19 23:36:30] [valid] Ep. 8 : Up. 520000 : cross-entropy : 51.0501 : new best
[2019-07-19 23:36:37] [valid] Ep. 8 : Up. 520000 : perplexity : 7.55135 : new best
[2019-07-19 23:37:32] [valid] Ep. 8 : Up. 520000 : translation : 25.11 : stalled 3 times (last best: 25.21)
[2019-07-19 23:44:11] Ep. 8 : Up. 522000 : Sen. 484,261 : Cost 63.89414215 : Time 496.55s : 12435.93 words/s
[2019-07-19 23:50:48] Ep. 8 : Up. 524000 : Sen. 770,267 : Cost 63.74395752 : Time 396.37s : 15564.65 words/s
[2019-07-19 23:57:26] Ep. 8 : Up. 526000 : Sen. 1,058,778 : Cost 63.43835831 : Time 398.68s : 15605.59 words/s
[2019-07-20 00:04:05] Ep. 8 : Up. 528000 : Sen. 1,345,984 : Cost 63.70075226 : Time 398.91s : 15541.24 words/s
[2019-07-20 00:10:44] Ep. 8 : Up. 530000 : Sen. 1,632,823 : Cost 63.77518463 : Time 398.35s : 15540.73 words/s
[2019-07-20 00:17:22] Ep. 8 : Up. 532000 : Sen. 1,919,408 : Cost 64.02254486 : Time 398.19s : 15546.14 words/s
[2019-07-20 00:24:00] Ep. 8 : Up. 534000 : Sen. 2,206,763 : Cost 63.34384155 : Time 397.72s : 15511.86 words/s
[2019-07-20 00:30:38] Ep. 8 : Up. 536000 : Sen. 2,493,375 : Cost 64.02239227 : Time 398.80s : 15539.26 words/s
[2019-07-20 00:37:17] Ep. 8 : Up. 538000 : Sen. 2,780,381 : Cost 63.81578827 : Time 398.86s : 15541.43 words/s
[2019-07-20 00:43:54] Ep. 8 : Up. 540000 : Sen. 3,066,518 : Cost 63.74823380 : Time 396.88s : 15542.54 words/s
[2019-07-20 00:43:54] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-20 00:44:00] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter540000.npz
[2019-07-20 00:44:02] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-20 00:44:08] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-20 00:44:29] [valid] Ep. 8 : Up. 540000 : cross-entropy : 51.036 : new best
[2019-07-20 00:44:36] [valid] Ep. 8 : Up. 540000 : perplexity : 7.54712 : new best
[2019-07-20 00:45:31] [valid] Ep. 8 : Up. 540000 : translation : 24.8 : stalled 4 times (last best: 25.21)
[2019-07-20 00:52:13] Ep. 8 : Up. 542000 : Sen. 3,354,178 : Cost 63.75660706 : Time 499.05s : 12445.57 words/s
[2019-07-20 00:58:51] Ep. 8 : Up. 544000 : Sen. 3,640,866 : Cost 64.06629944 : Time 397.83s : 15575.61 words/s
[2019-07-20 01:05:29] Ep. 8 : Up. 546000 : Sen. 3,927,077 : Cost 64.08285522 : Time 397.81s : 15520.05 words/s
[2019-07-20 01:12:08] Ep. 8 : Up. 548000 : Sen. 4,214,293 : Cost 63.91725540 : Time 399.24s : 15540.01 words/s
[2019-07-20 01:18:45] Ep. 8 : Up. 550000 : Sen. 4,500,898 : Cost 63.77510452 : Time 397.38s : 15512.64 words/s
[2019-07-20 01:25:23] Ep. 8 : Up. 552000 : Sen. 4,787,976 : Cost 63.69218826 : Time 398.08s : 15544.59 words/s
[2019-07-20 01:32:01] Ep. 8 : Up. 554000 : Sen. 5,074,308 : Cost 64.05149841 : Time 398.02s : 15547.52 words/s
[2019-07-20 01:38:39] Ep. 8 : Up. 556000 : Sen. 5,361,700 : Cost 63.79663849 : Time 397.45s : 15578.41 words/s
[2019-07-20 01:45:18] Ep. 8 : Up. 558000 : Sen. 5,649,311 : Cost 63.94443893 : Time 399.02s : 15535.33 words/s
[2019-07-20 01:51:56] Ep. 8 : Up. 560000 : Sen. 5,936,206 : Cost 63.98810196 : Time 398.45s : 15541.50 words/s
[2019-07-20 01:51:56] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-20 01:52:03] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter560000.npz
[2019-07-20 01:52:05] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-20 01:52:11] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-20 01:52:32] [valid] Ep. 8 : Up. 560000 : cross-entropy : 50.969 : new best
[2019-07-20 01:52:39] [valid] Ep. 8 : Up. 560000 : perplexity : 7.52713 : new best
[2019-07-20 01:53:34] [valid] Ep. 8 : Up. 560000 : translation : 24.84 : stalled 5 times (last best: 25.21)
[2019-07-20 02:00:14] Ep. 8 : Up. 562000 : Sen. 6,223,307 : Cost 64.02001953 : Time 498.01s : 12434.81 words/s
[2019-07-20 02:06:51] Ep. 8 : Up. 564000 : Sen. 6,510,525 : Cost 63.79060364 : Time 396.99s : 15572.54 words/s
[2019-07-20 02:13:30] Ep. 8 : Up. 566000 : Sen. 6,797,529 : Cost 63.97507477 : Time 398.63s : 15552.22 words/s
[2019-07-20 02:20:07] Ep. 8 : Up. 568000 : Sen. 7,083,702 : Cost 64.15830231 : Time 396.92s : 15560.24 words/s
[2019-07-20 02:26:45] Ep. 8 : Up. 570000 : Sen. 7,370,403 : Cost 64.13153076 : Time 397.93s : 15572.38 words/s
[2019-07-20 02:33:22] Ep. 8 : Up. 572000 : Sen. 7,657,608 : Cost 64.00195312 : Time 397.56s : 15567.20 words/s
[2019-07-20 02:39:58] Ep. 8 : Up. 574000 : Sen. 7,943,834 : Cost 64.00177002 : Time 396.01s : 15595.29 words/s
[2019-07-20 02:46:36] Ep. 8 : Up. 576000 : Sen. 8,230,796 : Cost 64.08702087 : Time 397.85s : 15574.21 words/s
[2019-07-20 02:53:14] Ep. 8 : Up. 578000 : Sen. 8,516,943 : Cost 63.98000336 : Time 397.83s : 15525.38 words/s
[2019-07-20 02:59:52] Ep. 8 : Up. 580000 : Sen. 8,804,690 : Cost 63.89090347 : Time 398.12s : 15579.93 words/s
[2019-07-20 02:59:52] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-20 02:59:58] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter580000.npz
[2019-07-20 03:00:01] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-20 03:00:07] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-20 03:00:27] [valid] Ep. 8 : Up. 580000 : cross-entropy : 50.8328 : new best
[2019-07-20 03:00:34] [valid] Ep. 8 : Up. 580000 : perplexity : 7.48663 : new best
[2019-07-20 03:01:29] [valid] Ep. 8 : Up. 580000 : translation : 24.95 : stalled 6 times (last best: 25.21)
[2019-07-20 03:08:09] Ep. 8 : Up. 582000 : Sen. 9,091,069 : Cost 64.04535675 : Time 497.11s : 12427.93 words/s
[2019-07-20 03:14:47] Ep. 8 : Up. 584000 : Sen. 9,378,747 : Cost 63.84884644 : Time 397.78s : 15592.19 words/s
[2019-07-20 03:21:24] Ep. 8 : Up. 586000 : Sen. 9,665,095 : Cost 63.96110153 : Time 397.36s : 15559.26 words/s
[2019-07-20 03:28:01] Ep. 8 : Up. 588000 : Sen. 9,951,546 : Cost 63.80080414 : Time 396.14s : 15581.29 words/s
[2019-07-20 03:34:40] Ep. 8 : Up. 590000 : Sen. 10,238,401 : Cost 64.11745453 : Time 398.99s : 15524.58 words/s
[2019-07-20 03:41:15] Ep. 8 : Up. 592000 : Sen. 10,523,762 : Cost 63.85428238 : Time 395.30s : 15545.68 words/s
[2019-07-20 03:43:39] Seen 10627013 samples
[2019-07-20 03:43:39] Starting epoch 9
[2019-07-20 03:43:39] [data] Shuffling data
[2019-07-20 03:43:48] [data] Done reading 12702121 sentences
[2019-07-20 03:45:08] [data] Done shuffling 12702121 sentences to temp files
[2019-07-20 03:49:29] Ep. 9 : Up. 594000 : Sen. 184,029 : Cost 63.74867630 : Time 493.63s : 12595.79 words/s
[2019-07-20 03:56:06] Ep. 9 : Up. 596000 : Sen. 471,113 : Cost 62.86817932 : Time 397.46s : 15535.20 words/s
[2019-07-20 04:02:43] Ep. 9 : Up. 598000 : Sen. 758,049 : Cost 63.17102051 : Time 397.03s : 15595.83 words/s
[2019-07-20 04:09:18] Ep. 9 : Up. 600000 : Sen. 1,043,464 : Cost 63.36865997 : Time 394.92s : 15621.63 words/s
[2019-07-20 04:09:18] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-20 04:09:25] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter600000.npz
[2019-07-20 04:09:27] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-20 04:09:33] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-20 04:09:55] [valid] Ep. 9 : Up. 600000 : cross-entropy : 50.8448 : stalled 1 times (last best: 50.8328)
[2019-07-20 04:10:02] [valid] Ep. 9 : Up. 600000 : perplexity : 7.4902 : stalled 1 times (last best: 7.48663)
[2019-07-20 04:10:56] [valid] Ep. 9 : Up. 600000 : translation : 25.06 : stalled 7 times (last best: 25.21)
[2019-07-20 04:17:37] Ep. 9 : Up. 602000 : Sen. 1,330,936 : Cost 63.12493134 : Time 498.67s : 12411.18 words/s
[2019-07-20 04:24:15] Ep. 9 : Up. 604000 : Sen. 1,617,880 : Cost 63.31984711 : Time 398.31s : 15537.19 words/s
[2019-07-20 04:30:55] Ep. 9 : Up. 606000 : Sen. 1,905,104 : Cost 63.43947601 : Time 399.96s : 15519.07 words/s
[2019-07-20 04:37:34] Ep. 9 : Up. 608000 : Sen. 2,192,461 : Cost 63.17346191 : Time 399.05s : 15497.27 words/s
[2019-07-20 04:44:12] Ep. 9 : Up. 610000 : Sen. 2,479,276 : Cost 63.36481094 : Time 398.49s : 15528.85 words/s
[2019-07-20 04:50:50] Ep. 9 : Up. 612000 : Sen. 2,765,328 : Cost 63.62431335 : Time 398.03s : 15532.19 words/s
[2019-07-20 04:57:29] Ep. 9 : Up. 614000 : Sen. 3,051,835 : Cost 63.49895096 : Time 398.13s : 15577.35 words/s
[2019-07-20 05:04:07] Ep. 9 : Up. 616000 : Sen. 3,338,883 : Cost 63.34369278 : Time 398.49s : 15531.23 words/s
[2019-07-20 05:10:45] Ep. 9 : Up. 618000 : Sen. 3,626,210 : Cost 63.21590424 : Time 398.22s : 15529.16 words/s
[2019-07-20 05:17:23] Ep. 9 : Up. 620000 : Sen. 3,912,974 : Cost 63.54506302 : Time 397.66s : 15579.08 words/s
[2019-07-20 05:17:23] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.orig.npz
[2019-07-20 05:17:29] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.iter620000.npz
[2019-07-20 05:17:32] Saving model to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz
[2019-07-20 05:17:38] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_biced_0.25/model/model.npz.optimizer.npz
[2019-07-20 05:18:00] [valid] Ep. 9 : Up. 620000 : cross-entropy : 50.7768 : new best
[2019-07-20 05:18:07] [valid] Ep. 9 : Up. 620000 : perplexity : 7.47005 : new best
[2019-07-20 05:19:00] [valid] Ep. 9 : Up. 620000 : translation : 25.17 : stalled 8 times (last best: 25.21)
[2019-07-20 05:25:40] Ep. 9 : Up. 622000 : Sen. 4,200,336 : Cost 63.28695679 : Time 497.21s : 12469.50 words/s
[2019-07-20 05:32:19] Ep. 9 : Up. 624000 : Sen. 4,487,845 : Cost 63.32631683 : Time 399.01s : 15523.06 words/s
[2019-07-20 05:38:57] Ep. 9 : Up. 626000 : Sen. 4,775,472 : Cost 63.28919601 : Time 397.70s : 15576.45 words/s
[2019-07-20 05:45:35] Ep. 9 : Up. 628000 : Sen. 5,062,268 : Cost 63.70264053 : Time 397.95s : 15573.26 words/s
[2019-07-20 05:52:14] Ep. 9 : Up. 630000 : Sen. 5,348,863 : Cost 63.65590286 : Time 398.81s : 15517.41 words/s
[2019-07-20 05:58:52] Ep. 9 : Up. 632000 : Sen. 5,636,361 : Cost 63.48822784 : Time 397.86s : 15544.70 words/s
[2019-07-20 06:05:30] Ep. 9 : Up. 634000 : Sen. 5,923,466 : Cost 63.66701508 : Time 398.62s : 15569.74 words/s
[2019-07-20 06:12:09] Ep. 9 : Up. 636000 : Sen. 6,210,797 : Cost 63.65538788 : Time 398.42s : 15597.74 words/s
[2019-07-20 06:18:47] Ep. 9 : Up. 638000 : Sen. 6,497,679 : Cost 63.38845062 : Time 398.23s : 15553.57 words/s
