MT evaluation scorer began on 2019 Jul 19 at 09:23:00
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/10M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1/data/KDE4.de.sgm -r ../experiments/10M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1/data/KDE4.en.sgm -t ../experiments/10M_fasttext_prob_x_len_+_biced_0.25_x_bic1.1/data/KDE4.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 3000 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 0.955240576037047 (122117/127839), penalty (log): -0.0468567029979445
NIST score = 5.9554  BLEU score = 0.1917 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.4164   1.2075   0.2662   0.0547   0.0107   0.0033   0.0013   0.0009   0.0005  "Edinburgh"

 BLEU:  0.5449   0.2557   0.1424   0.0821   0.0492   0.0308   0.0202   0.0139   0.0097  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.4164   5.6238   5.8900   5.9447   5.9554   5.9586   5.9600   5.9609   5.9614  "Edinburgh"

 BLEU:  0.5200   0.3562   0.2583   0.1917   0.1447   0.1110   0.0864   0.0684   0.0547  "Edinburgh"
MT evaluation scorer ended on 2019 Jul 19 at 09:23:37
