MT evaluation scorer began on 2019 Jul 19 at 09:17:43
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/10M_fasttext_prob_x_len_+_biced_0.25_x_dcce/data/globalvoices-2017.de.sgm -r ../experiments/10M_fasttext_prob_x_len_+_biced_0.25_x_dcce/data/globalvoices-2017.en.sgm -t ../experiments/10M_fasttext_prob_x_len_+_biced_0.25_x_dcce/data/globalvoices-2017.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 3000 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 1.07642185757527 (67567/62770), penalty (log): 0
NIST score = 6.0388  BLEU score = 0.2040 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.6680   1.1628   0.1861   0.0189   0.0031   0.0007   0.0003   0.0001   0.0000  "Edinburgh"

 BLEU:  0.5145   0.2586   0.1482   0.0879   0.0531   0.0325   0.0202   0.0128   0.0081  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.6680   5.8307   6.0168   6.0357   6.0388   6.0395   6.0397   6.0398   6.0398  "Edinburgh"

 BLEU:  0.5145   0.3647   0.2701   0.2040   0.1559   0.1200   0.0930   0.0726   0.0569  "Edinburgh"
MT evaluation scorer ended on 2019 Jul 19 at 09:18:03
