[2019-08-02 15:28:31] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-02 15:28:31] [marian] Running on lofn as process 1478 with command line:
[2019-08-02 15:28:31] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/model/model.npz -T . --devices 0 --train-sets ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/data/train.bpe.de ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/data/train.bpe.en --vocabs ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/data/train.bpe.de.json ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/data/train.bpe.en.json --mini-batch-fit -w 3000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/data/dev.bpe.de ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/model/dev.out --valid-script-path ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/model/train.log --valid-log ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/model/valid.log
[2019-08-02 15:28:31] [config] after-batches: 0
[2019-08-02 15:28:31] [config] after-epochs: 0
[2019-08-02 15:28:31] [config] allow-unk: false
[2019-08-02 15:28:31] [config] beam-size: 12
[2019-08-02 15:28:31] [config] bert-class-symbol: "[CLS]"
[2019-08-02 15:28:31] [config] bert-mask-symbol: "[MASK]"
[2019-08-02 15:28:31] [config] bert-masking-fraction: 0.15
[2019-08-02 15:28:31] [config] bert-sep-symbol: "[SEP]"
[2019-08-02 15:28:31] [config] bert-train-type-embeddings: true
[2019-08-02 15:28:31] [config] bert-type-vocab-size: 2
[2019-08-02 15:28:31] [config] best-deep: false
[2019-08-02 15:28:31] [config] clip-gemm: 0
[2019-08-02 15:28:31] [config] clip-norm: 1
[2019-08-02 15:28:31] [config] cost-type: ce-mean
[2019-08-02 15:28:31] [config] cpu-threads: 0
[2019-08-02 15:28:31] [config] data-weighting: ""
[2019-08-02 15:28:31] [config] data-weighting-type: sentence
[2019-08-02 15:28:31] [config] dec-cell: gru
[2019-08-02 15:28:31] [config] dec-cell-base-depth: 2
[2019-08-02 15:28:31] [config] dec-cell-high-depth: 1
[2019-08-02 15:28:31] [config] dec-depth: 1
[2019-08-02 15:28:31] [config] devices:
[2019-08-02 15:28:31] [config]   - 0
[2019-08-02 15:28:31] [config] dim-emb: 512
[2019-08-02 15:28:31] [config] dim-rnn: 1024
[2019-08-02 15:28:31] [config] dim-vocabs:
[2019-08-02 15:28:31] [config]   - 50000
[2019-08-02 15:28:31] [config]   - 50000
[2019-08-02 15:28:31] [config] disp-first: 0
[2019-08-02 15:28:31] [config] disp-freq: 2000
[2019-08-02 15:28:31] [config] disp-label-counts: false
[2019-08-02 15:28:31] [config] dropout-rnn: 0.2
[2019-08-02 15:28:31] [config] dropout-src: 0.1
[2019-08-02 15:28:31] [config] dropout-trg: 0.1
[2019-08-02 15:28:31] [config] dump-config: ""
[2019-08-02 15:28:31] [config] early-stopping: 5
[2019-08-02 15:28:31] [config] embedding-fix-src: false
[2019-08-02 15:28:31] [config] embedding-fix-trg: false
[2019-08-02 15:28:31] [config] embedding-normalization: false
[2019-08-02 15:28:31] [config] embedding-vectors:
[2019-08-02 15:28:31] [config]   []
[2019-08-02 15:28:31] [config] enc-cell: gru
[2019-08-02 15:28:31] [config] enc-cell-depth: 1
[2019-08-02 15:28:31] [config] enc-depth: 1
[2019-08-02 15:28:31] [config] enc-type: bidirectional
[2019-08-02 15:28:31] [config] exponential-smoothing: 0.0001
[2019-08-02 15:28:31] [config] grad-dropping-momentum: 0
[2019-08-02 15:28:31] [config] grad-dropping-rate: 0
[2019-08-02 15:28:31] [config] grad-dropping-warmup: 100
[2019-08-02 15:28:31] [config] guided-alignment: none
[2019-08-02 15:28:31] [config] guided-alignment-cost: mse
[2019-08-02 15:28:31] [config] guided-alignment-weight: 0.1
[2019-08-02 15:28:31] [config] ignore-model-config: false
[2019-08-02 15:28:31] [config] input-types:
[2019-08-02 15:28:31] [config]   []
[2019-08-02 15:28:31] [config] interpolate-env-vars: false
[2019-08-02 15:28:31] [config] keep-best: false
[2019-08-02 15:28:31] [config] label-smoothing: 0
[2019-08-02 15:28:31] [config] layer-normalization: true
[2019-08-02 15:28:31] [config] learn-rate: 0.0001
[2019-08-02 15:28:31] [config] log: ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/model/train.log
[2019-08-02 15:28:31] [config] log-level: info
[2019-08-02 15:28:31] [config] log-time-zone: ""
[2019-08-02 15:28:31] [config] lr-decay: 0
[2019-08-02 15:28:31] [config] lr-decay-freq: 50000
[2019-08-02 15:28:31] [config] lr-decay-inv-sqrt:
[2019-08-02 15:28:31] [config]   - 0
[2019-08-02 15:28:31] [config] lr-decay-repeat-warmup: false
[2019-08-02 15:28:31] [config] lr-decay-reset-optimizer: false
[2019-08-02 15:28:31] [config] lr-decay-start:
[2019-08-02 15:28:31] [config]   - 10
[2019-08-02 15:28:31] [config]   - 1
[2019-08-02 15:28:31] [config] lr-decay-strategy: epoch+stalled
[2019-08-02 15:28:31] [config] lr-report: false
[2019-08-02 15:28:31] [config] lr-warmup: 0
[2019-08-02 15:28:31] [config] lr-warmup-at-reload: false
[2019-08-02 15:28:31] [config] lr-warmup-cycle: false
[2019-08-02 15:28:31] [config] lr-warmup-start-rate: 0
[2019-08-02 15:28:31] [config] max-length: 50
[2019-08-02 15:28:31] [config] max-length-crop: false
[2019-08-02 15:28:31] [config] max-length-factor: 3
[2019-08-02 15:28:31] [config] maxi-batch: 100
[2019-08-02 15:28:31] [config] maxi-batch-sort: trg
[2019-08-02 15:28:31] [config] mini-batch: 64
[2019-08-02 15:28:31] [config] mini-batch-fit: true
[2019-08-02 15:28:31] [config] mini-batch-fit-step: 10
[2019-08-02 15:28:31] [config] mini-batch-overstuff: 1
[2019-08-02 15:28:31] [config] mini-batch-track-lr: false
[2019-08-02 15:28:31] [config] mini-batch-understuff: 1
[2019-08-02 15:28:31] [config] mini-batch-warmup: 0
[2019-08-02 15:28:31] [config] mini-batch-words: 0
[2019-08-02 15:28:31] [config] mini-batch-words-ref: 0
[2019-08-02 15:28:31] [config] model: ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/model/model.npz
[2019-08-02 15:28:31] [config] multi-loss-type: sum
[2019-08-02 15:28:31] [config] multi-node: false
[2019-08-02 15:28:31] [config] multi-node-overlap: true
[2019-08-02 15:28:31] [config] n-best: false
[2019-08-02 15:28:31] [config] no-nccl: false
[2019-08-02 15:28:31] [config] no-reload: false
[2019-08-02 15:28:31] [config] no-restore-corpus: false
[2019-08-02 15:28:31] [config] no-shuffle: false
[2019-08-02 15:28:31] [config] normalize: 1
[2019-08-02 15:28:31] [config] num-devices: 0
[2019-08-02 15:28:31] [config] optimizer: adam
[2019-08-02 15:28:31] [config] optimizer-delay: 1
[2019-08-02 15:28:31] [config] optimizer-params:
[2019-08-02 15:28:31] [config]   []
[2019-08-02 15:28:31] [config] overwrite: false
[2019-08-02 15:28:31] [config] pretrained-model: ""
[2019-08-02 15:28:31] [config] quiet: false
[2019-08-02 15:28:31] [config] quiet-translation: true
[2019-08-02 15:28:31] [config] relative-paths: false
[2019-08-02 15:28:31] [config] right-left: false
[2019-08-02 15:28:31] [config] save-freq: 20000
[2019-08-02 15:28:31] [config] seed: 1111
[2019-08-02 15:28:31] [config] shuffle-in-ram: false
[2019-08-02 15:28:31] [config] skip: false
[2019-08-02 15:28:31] [config] sqlite: ""
[2019-08-02 15:28:31] [config] sqlite-drop: false
[2019-08-02 15:28:31] [config] sync-sgd: true
[2019-08-02 15:28:31] [config] tempdir: .
[2019-08-02 15:28:31] [config] tied-embeddings: false
[2019-08-02 15:28:31] [config] tied-embeddings-all: false
[2019-08-02 15:28:31] [config] tied-embeddings-src: false
[2019-08-02 15:28:31] [config] train-sets:
[2019-08-02 15:28:31] [config]   - ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/data/train.bpe.de
[2019-08-02 15:28:31] [config]   - ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/data/train.bpe.en
[2019-08-02 15:28:31] [config] transformer-aan-activation: swish
[2019-08-02 15:28:31] [config] transformer-aan-depth: 2
[2019-08-02 15:28:31] [config] transformer-aan-nogate: false
[2019-08-02 15:28:31] [config] transformer-decoder-autoreg: self-attention
[2019-08-02 15:28:31] [config] transformer-dim-aan: 2048
[2019-08-02 15:28:31] [config] transformer-dim-ffn: 2048
[2019-08-02 15:28:31] [config] transformer-dropout: 0
[2019-08-02 15:28:31] [config] transformer-dropout-attention: 0
[2019-08-02 15:28:31] [config] transformer-dropout-ffn: 0
[2019-08-02 15:28:31] [config] transformer-ffn-activation: swish
[2019-08-02 15:28:31] [config] transformer-ffn-depth: 2
[2019-08-02 15:28:31] [config] transformer-guided-alignment-layer: last
[2019-08-02 15:28:31] [config] transformer-heads: 8
[2019-08-02 15:28:31] [config] transformer-no-projection: false
[2019-08-02 15:28:31] [config] transformer-postprocess: dan
[2019-08-02 15:28:31] [config] transformer-postprocess-emb: d
[2019-08-02 15:28:31] [config] transformer-preprocess: ""
[2019-08-02 15:28:31] [config] transformer-tied-layers:
[2019-08-02 15:28:31] [config]   []
[2019-08-02 15:28:31] [config] transformer-train-position-embeddings: false
[2019-08-02 15:28:31] [config] type: amun
[2019-08-02 15:28:31] [config] ulr: false
[2019-08-02 15:28:31] [config] ulr-dim-emb: 0
[2019-08-02 15:28:31] [config] ulr-dropout: 0
[2019-08-02 15:28:31] [config] ulr-keys-vectors: ""
[2019-08-02 15:28:31] [config] ulr-query-vectors: ""
[2019-08-02 15:28:31] [config] ulr-softmax-temperature: 1
[2019-08-02 15:28:31] [config] ulr-trainable-transformation: false
[2019-08-02 15:28:31] [config] valid-freq: 20000
[2019-08-02 15:28:31] [config] valid-log: ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/model/valid.log
[2019-08-02 15:28:31] [config] valid-max-length: 1000
[2019-08-02 15:28:31] [config] valid-metrics:
[2019-08-02 15:28:31] [config]   - cross-entropy
[2019-08-02 15:28:31] [config]   - perplexity
[2019-08-02 15:28:31] [config]   - translation
[2019-08-02 15:28:31] [config] valid-mini-batch: 8
[2019-08-02 15:28:31] [config] valid-script-path: ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/score-dev.sh
[2019-08-02 15:28:31] [config] valid-sets:
[2019-08-02 15:28:31] [config]   - ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/data/dev.bpe.de
[2019-08-02 15:28:31] [config]   - ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/data/dev.bpe.en
[2019-08-02 15:28:31] [config] valid-translation-output: ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/model/dev.out
[2019-08-02 15:28:31] [config] vocabs:
[2019-08-02 15:28:31] [config]   - ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/data/train.bpe.de.json
[2019-08-02 15:28:31] [config]   - ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/data/train.bpe.en.json
[2019-08-02 15:28:31] [config] word-penalty: 0
[2019-08-02 15:28:31] [config] workspace: 3000
[2019-08-02 15:28:31] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-08-02 15:28:31] Using synchronous training
[2019-08-02 15:28:31] [data] Loading vocabulary from JSON/Yaml file ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/data/train.bpe.de.json
[2019-08-02 15:28:31] [data] Using unused word id eos for 0
[2019-08-02 15:28:31] [data] Using unused word id UNK for 1
[2019-08-02 15:28:31] [data] Setting vocabulary size for input 0 to 50000
[2019-08-02 15:28:31] [data] Loading vocabulary from JSON/Yaml file ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/data/train.bpe.en.json
[2019-08-02 15:28:32] [data] Using unused word id eos for 0
[2019-08-02 15:28:32] [data] Using unused word id UNK for 1
[2019-08-02 15:28:32] [data] Setting vocabulary size for input 1 to 50000
[2019-08-02 15:28:32] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-08-02 15:28:32] [batching] Collecting statistics for batch fitting with step size 10
[2019-08-02 15:28:32] [memory] Extending reserved space to 3072 MB (device gpu0)
[2019-08-02 15:28:32] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-02 15:28:32] [comm] NCCLCommunicator constructed successfully.
[2019-08-02 15:28:32] [training] Using 1 GPUs
[2019-08-02 15:28:32] [memory] Reserving 422 MB, device gpu0
[2019-08-02 15:28:32] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-08-02 15:28:33] [memory] Reserving 422 MB, device gpu0
[2019-08-02 15:28:37] [batching] Done. Typical MB size is 4042 target words
[2019-08-02 15:28:38] [memory] Extending reserved space to 3072 MB (device gpu0)
[2019-08-02 15:28:38] [comm] Using NCCL 2.4.2 for GPU communication
[2019-08-02 15:28:38] [comm] NCCLCommunicator constructed successfully.
[2019-08-02 15:28:38] [training] Using 1 GPUs
[2019-08-02 15:28:38] Training started
[2019-08-02 15:28:38] [data] Shuffling data
[2019-08-02 15:28:38] [data] Done reading 679513 sentences
[2019-08-02 15:28:40] [data] Done shuffling 679513 sentences to temp files
[2019-08-02 15:28:43] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-08-02 15:28:43] [memory] Reserving 422 MB, device gpu0
[2019-08-02 15:28:43] [memory] Reserving 422 MB, device gpu0
[2019-08-02 15:28:43] [memory] Reserving 422 MB, device gpu0
[2019-08-02 15:28:43] [memory] Reserving 844 MB, device gpu0
[2019-08-02 15:39:02] Ep. 1 : Up. 2000 : Sen. 241,745 : Cost 107.10773468 : Time 630.00s : 8373.28 words/s
[2019-08-02 15:49:24] Ep. 1 : Up. 4000 : Sen. 482,878 : Cost 79.14243317 : Time 622.22s : 8453.18 words/s
[2019-08-02 15:55:46] Seen 632635 samples
[2019-08-02 15:55:46] Starting epoch 2
[2019-08-02 15:55:46] [data] Shuffling data
[2019-08-02 15:55:47] [data] Done reading 679513 sentences
[2019-08-02 15:55:49] [data] Done shuffling 679513 sentences to temp files
[2019-08-02 15:59:46] Ep. 2 : Up. 6000 : Sen. 90,714 : Cost 65.18670654 : Time 621.89s : 8433.24 words/s
[2019-08-02 16:10:05] Ep. 2 : Up. 8000 : Sen. 332,004 : Cost 56.23143768 : Time 618.89s : 8489.84 words/s
[2019-08-02 16:20:23] Ep. 2 : Up. 10000 : Sen. 571,892 : Cost 51.14615250 : Time 617.98s : 8478.94 words/s
[2019-08-02 16:22:58] Seen 632635 samples
[2019-08-02 16:22:58] Starting epoch 3
[2019-08-02 16:22:58] [data] Shuffling data
[2019-08-02 16:22:58] [data] Done reading 679513 sentences
[2019-08-02 16:23:00] [data] Done shuffling 679513 sentences to temp files
[2019-08-02 16:30:49] Ep. 3 : Up. 12000 : Sen. 180,514 : Cost 46.60231781 : Time 626.55s : 8397.29 words/s
[2019-08-02 16:41:09] Ep. 3 : Up. 14000 : Sen. 422,322 : Cost 43.79569244 : Time 619.76s : 8482.30 words/s
[2019-08-02 16:50:13] Seen 632635 samples
[2019-08-02 16:50:13] Starting epoch 4
[2019-08-02 16:50:13] [data] Shuffling data
[2019-08-02 16:50:13] [data] Done reading 679513 sentences
[2019-08-02 16:50:15] [data] Done shuffling 679513 sentences to temp files
[2019-08-02 16:51:36] Ep. 4 : Up. 16000 : Sen. 29,593 : Cost 41.95156479 : Time 626.88s : 8355.11 words/s
[2019-08-02 17:01:59] Ep. 4 : Up. 18000 : Sen. 270,644 : Cost 39.45948029 : Time 623.16s : 8459.04 words/s
[2019-08-02 17:12:18] Ep. 4 : Up. 20000 : Sen. 511,197 : Cost 38.53286743 : Time 619.06s : 8469.18 words/s
[2019-08-02 17:12:18] Saving model to ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/model/model.npz.orig.npz
[2019-08-02 17:12:28] Saving model to ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/model/model.iter20000.npz
[2019-08-02 17:12:35] Saving model to ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/model/model.npz
[2019-08-02 17:12:44] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/model/model.npz.optimizer.npz
[2019-08-02 17:13:12] [valid] Ep. 4 : Up. 20000 : cross-entropy : 75.7136 : new best
[2019-08-02 17:13:21] [valid] Ep. 4 : Up. 20000 : perplexity : 19.5739 : new best
[2019-08-02 17:14:45] [valid] Ep. 4 : Up. 20000 : translation : 15.51 : new best
[2019-08-02 17:19:59] Seen 632635 samples
[2019-08-02 17:19:59] Starting epoch 5
[2019-08-02 17:19:59] [data] Shuffling data
[2019-08-02 17:19:59] [data] Done reading 679513 sentences
[2019-08-02 17:20:01] [data] Done shuffling 679513 sentences to temp files
[2019-08-02 17:25:13] Ep. 5 : Up. 22000 : Sen. 119,639 : Cost 36.87059402 : Time 775.30s : 6764.70 words/s
[2019-08-02 17:35:36] Ep. 5 : Up. 24000 : Sen. 361,191 : Cost 35.54957962 : Time 622.65s : 8474.09 words/s
[2019-08-02 17:45:58] Ep. 5 : Up. 26000 : Sen. 603,187 : Cost 35.01057434 : Time 622.04s : 8473.12 words/s
[2019-08-02 17:47:13] Seen 632635 samples
[2019-08-02 17:47:13] Starting epoch 6
[2019-08-02 17:47:13] [data] Shuffling data
[2019-08-02 17:47:13] [data] Done reading 679513 sentences
[2019-08-02 17:47:15] [data] Done shuffling 679513 sentences to temp files
[2019-08-02 17:56:20] Ep. 6 : Up. 28000 : Sen. 211,065 : Cost 33.59039688 : Time 622.50s : 8426.33 words/s
[2019-08-02 18:06:40] Ep. 6 : Up. 30000 : Sen. 452,678 : Cost 33.12578583 : Time 620.06s : 8499.58 words/s
[2019-08-02 18:14:22] Seen 632635 samples
[2019-08-02 18:14:22] Starting epoch 7
[2019-08-02 18:14:22] [data] Shuffling data
[2019-08-02 18:14:22] [data] Done reading 679513 sentences
[2019-08-02 18:14:24] [data] Done shuffling 679513 sentences to temp files
[2019-08-02 18:17:05] Ep. 7 : Up. 32000 : Sen. 61,892 : Cost 32.35690689 : Time 624.07s : 8424.89 words/s
[2019-08-02 18:27:24] Ep. 7 : Up. 34000 : Sen. 302,123 : Cost 31.18782616 : Time 619.50s : 8455.94 words/s
[2019-08-02 18:37:46] Ep. 7 : Up. 36000 : Sen. 543,095 : Cost 31.39722443 : Time 622.27s : 8452.03 words/s
[2019-08-02 18:41:36] Seen 632635 samples
[2019-08-02 18:41:36] Starting epoch 8
[2019-08-02 18:41:36] [data] Shuffling data
[2019-08-02 18:41:37] [data] Done reading 679513 sentences
[2019-08-02 18:41:39] [data] Done shuffling 679513 sentences to temp files
[2019-08-02 18:48:12] Ep. 8 : Up. 38000 : Sen. 151,472 : Cost 30.12326431 : Time 625.29s : 8399.74 words/s
[2019-08-02 18:58:35] Ep. 8 : Up. 40000 : Sen. 393,268 : Cost 29.73984528 : Time 623.30s : 8472.10 words/s
[2019-08-02 18:58:35] Saving model to ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/model/model.npz.orig.npz
[2019-08-02 18:58:44] Saving model to ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/model/model.iter40000.npz
[2019-08-02 18:58:50] Saving model to ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/model/model.npz
[2019-08-02 18:59:00] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_bicleaner_dcce_biced_hdiff_w3000/model/model.npz.optimizer.npz
[2019-08-02 18:59:27] [valid] Ep. 8 : Up. 40000 : cross-entropy : 66.07 : new best
[2019-08-02 18:59:36] [valid] Ep. 8 : Up. 40000 : perplexity : 13.4016 : new best
[2019-08-02 19:00:58] [valid] Ep. 8 : Up. 40000 : translation : 18.04 : new best
[2019-08-02 19:11:17] Seen 632635 samples
[2019-08-02 19:11:17] Starting epoch 9
[2019-08-02 19:11:17] [data] Shuffling data
[2019-08-02 19:11:17] [data] Done reading 679513 sentences
[2019-08-02 19:11:20] [data] Done shuffling 679513 sentences to temp files
[2019-08-02 19:11:26] Ep. 9 : Up. 42000 : Sen. 1,344 : Cost 29.65667343 : Time 770.67s : 6809.41 words/s
[2019-08-02 19:21:46] Ep. 9 : Up. 44000 : Sen. 242,909 : Cost 28.39336014 : Time 620.63s : 8479.99 words/s
[2019-08-02 19:32:08] Ep. 9 : Up. 46000 : Sen. 483,397 : Cost 28.55309677 : Time 621.68s : 8456.10 words/s
[2019-08-02 19:38:35] Seen 632635 samples
[2019-08-02 19:38:35] Starting epoch 10
[2019-08-02 19:38:35] [data] Shuffling data
[2019-08-02 19:38:35] [data] Done reading 679513 sentences
[2019-08-02 19:38:37] [data] Done shuffling 679513 sentences to temp files
[2019-08-02 19:42:35] Ep. 10 : Up. 48000 : Sen. 91,378 : Cost 28.08010674 : Time 627.55s : 8349.41 words/s
[2019-08-02 19:52:56] Ep. 10 : Up. 50000 : Sen. 332,698 : Cost 27.10085106 : Time 620.25s : 8467.11 words/s
