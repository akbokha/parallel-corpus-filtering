[2019-07-16 20:03:49] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-16 20:03:49] [marian] Running on lofn as process 5642 with command line:
[2019-07-16 20:03:49] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.npz -T . --devices 0 --train-sets ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/data/train.bpe.de ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/data/train.bpe.en --vocabs ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/data/train.bpe.de.json ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/data/train.bpe.en.json --mini-batch-fit -w 5000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/data/dev.bpe.de ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/dev.out --valid-script-path ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/train.log --valid-log ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/valid.log
[2019-07-16 20:03:49] [config] after-batches: 0
[2019-07-16 20:03:49] [config] after-epochs: 0
[2019-07-16 20:03:49] [config] allow-unk: false
[2019-07-16 20:03:49] [config] beam-size: 12
[2019-07-16 20:03:49] [config] bert-class-symbol: "[CLS]"
[2019-07-16 20:03:49] [config] bert-mask-symbol: "[MASK]"
[2019-07-16 20:03:49] [config] bert-masking-fraction: 0.15
[2019-07-16 20:03:49] [config] bert-sep-symbol: "[SEP]"
[2019-07-16 20:03:49] [config] bert-train-type-embeddings: true
[2019-07-16 20:03:49] [config] bert-type-vocab-size: 2
[2019-07-16 20:03:49] [config] best-deep: false
[2019-07-16 20:03:49] [config] clip-gemm: 0
[2019-07-16 20:03:49] [config] clip-norm: 1
[2019-07-16 20:03:49] [config] cost-type: ce-mean
[2019-07-16 20:03:49] [config] cpu-threads: 0
[2019-07-16 20:03:49] [config] data-weighting: ""
[2019-07-16 20:03:49] [config] data-weighting-type: sentence
[2019-07-16 20:03:49] [config] dec-cell: gru
[2019-07-16 20:03:49] [config] dec-cell-base-depth: 2
[2019-07-16 20:03:49] [config] dec-cell-high-depth: 1
[2019-07-16 20:03:49] [config] dec-depth: 1
[2019-07-16 20:03:49] [config] devices:
[2019-07-16 20:03:49] [config]   - 0
[2019-07-16 20:03:49] [config] dim-emb: 512
[2019-07-16 20:03:49] [config] dim-rnn: 1024
[2019-07-16 20:03:49] [config] dim-vocabs:
[2019-07-16 20:03:49] [config]   - 50000
[2019-07-16 20:03:49] [config]   - 50000
[2019-07-16 20:03:49] [config] disp-first: 0
[2019-07-16 20:03:49] [config] disp-freq: 2000
[2019-07-16 20:03:49] [config] disp-label-counts: false
[2019-07-16 20:03:49] [config] dropout-rnn: 0.2
[2019-07-16 20:03:49] [config] dropout-src: 0.1
[2019-07-16 20:03:49] [config] dropout-trg: 0.1
[2019-07-16 20:03:49] [config] dump-config: ""
[2019-07-16 20:03:49] [config] early-stopping: 5
[2019-07-16 20:03:49] [config] embedding-fix-src: false
[2019-07-16 20:03:49] [config] embedding-fix-trg: false
[2019-07-16 20:03:49] [config] embedding-normalization: false
[2019-07-16 20:03:49] [config] embedding-vectors:
[2019-07-16 20:03:49] [config]   []
[2019-07-16 20:03:49] [config] enc-cell: gru
[2019-07-16 20:03:49] [config] enc-cell-depth: 1
[2019-07-16 20:03:49] [config] enc-depth: 1
[2019-07-16 20:03:49] [config] enc-type: bidirectional
[2019-07-16 20:03:49] [config] exponential-smoothing: 0.0001
[2019-07-16 20:03:49] [config] grad-dropping-momentum: 0
[2019-07-16 20:03:49] [config] grad-dropping-rate: 0
[2019-07-16 20:03:49] [config] grad-dropping-warmup: 100
[2019-07-16 20:03:49] [config] guided-alignment: none
[2019-07-16 20:03:49] [config] guided-alignment-cost: mse
[2019-07-16 20:03:49] [config] guided-alignment-weight: 0.1
[2019-07-16 20:03:49] [config] ignore-model-config: false
[2019-07-16 20:03:49] [config] input-types:
[2019-07-16 20:03:49] [config]   []
[2019-07-16 20:03:49] [config] interpolate-env-vars: false
[2019-07-16 20:03:49] [config] keep-best: false
[2019-07-16 20:03:49] [config] label-smoothing: 0
[2019-07-16 20:03:49] [config] layer-normalization: true
[2019-07-16 20:03:49] [config] learn-rate: 0.0001
[2019-07-16 20:03:49] [config] log: ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/train.log
[2019-07-16 20:03:49] [config] log-level: info
[2019-07-16 20:03:49] [config] log-time-zone: ""
[2019-07-16 20:03:49] [config] lr-decay: 0
[2019-07-16 20:03:49] [config] lr-decay-freq: 50000
[2019-07-16 20:03:49] [config] lr-decay-inv-sqrt:
[2019-07-16 20:03:49] [config]   - 0
[2019-07-16 20:03:49] [config] lr-decay-repeat-warmup: false
[2019-07-16 20:03:49] [config] lr-decay-reset-optimizer: false
[2019-07-16 20:03:49] [config] lr-decay-start:
[2019-07-16 20:03:49] [config]   - 10
[2019-07-16 20:03:49] [config]   - 1
[2019-07-16 20:03:49] [config] lr-decay-strategy: epoch+stalled
[2019-07-16 20:03:49] [config] lr-report: false
[2019-07-16 20:03:49] [config] lr-warmup: 0
[2019-07-16 20:03:49] [config] lr-warmup-at-reload: false
[2019-07-16 20:03:49] [config] lr-warmup-cycle: false
[2019-07-16 20:03:49] [config] lr-warmup-start-rate: 0
[2019-07-16 20:03:49] [config] max-length: 50
[2019-07-16 20:03:49] [config] max-length-crop: false
[2019-07-16 20:03:49] [config] max-length-factor: 3
[2019-07-16 20:03:49] [config] maxi-batch: 100
[2019-07-16 20:03:49] [config] maxi-batch-sort: trg
[2019-07-16 20:03:49] [config] mini-batch: 64
[2019-07-16 20:03:49] [config] mini-batch-fit: true
[2019-07-16 20:03:49] [config] mini-batch-fit-step: 10
[2019-07-16 20:03:49] [config] mini-batch-overstuff: 1
[2019-07-16 20:03:49] [config] mini-batch-track-lr: false
[2019-07-16 20:03:49] [config] mini-batch-understuff: 1
[2019-07-16 20:03:49] [config] mini-batch-warmup: 0
[2019-07-16 20:03:49] [config] mini-batch-words: 0
[2019-07-16 20:03:49] [config] mini-batch-words-ref: 0
[2019-07-16 20:03:49] [config] model: ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.npz
[2019-07-16 20:03:49] [config] multi-loss-type: sum
[2019-07-16 20:03:49] [config] multi-node: false
[2019-07-16 20:03:49] [config] multi-node-overlap: true
[2019-07-16 20:03:49] [config] n-best: false
[2019-07-16 20:03:49] [config] no-nccl: false
[2019-07-16 20:03:49] [config] no-reload: false
[2019-07-16 20:03:49] [config] no-restore-corpus: false
[2019-07-16 20:03:49] [config] no-shuffle: false
[2019-07-16 20:03:49] [config] normalize: 1
[2019-07-16 20:03:49] [config] num-devices: 0
[2019-07-16 20:03:49] [config] optimizer: adam
[2019-07-16 20:03:49] [config] optimizer-delay: 1
[2019-07-16 20:03:49] [config] optimizer-params:
[2019-07-16 20:03:49] [config]   []
[2019-07-16 20:03:49] [config] overwrite: false
[2019-07-16 20:03:49] [config] pretrained-model: ""
[2019-07-16 20:03:49] [config] quiet: false
[2019-07-16 20:03:49] [config] quiet-translation: true
[2019-07-16 20:03:49] [config] relative-paths: false
[2019-07-16 20:03:49] [config] right-left: false
[2019-07-16 20:03:49] [config] save-freq: 20000
[2019-07-16 20:03:49] [config] seed: 1111
[2019-07-16 20:03:49] [config] shuffle-in-ram: false
[2019-07-16 20:03:49] [config] skip: false
[2019-07-16 20:03:49] [config] sqlite: ""
[2019-07-16 20:03:49] [config] sqlite-drop: false
[2019-07-16 20:03:49] [config] sync-sgd: true
[2019-07-16 20:03:49] [config] tempdir: .
[2019-07-16 20:03:49] [config] tied-embeddings: false
[2019-07-16 20:03:49] [config] tied-embeddings-all: false
[2019-07-16 20:03:49] [config] tied-embeddings-src: false
[2019-07-16 20:03:49] [config] train-sets:
[2019-07-16 20:03:49] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/data/train.bpe.de
[2019-07-16 20:03:49] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/data/train.bpe.en
[2019-07-16 20:03:49] [config] transformer-aan-activation: swish
[2019-07-16 20:03:49] [config] transformer-aan-depth: 2
[2019-07-16 20:03:49] [config] transformer-aan-nogate: false
[2019-07-16 20:03:49] [config] transformer-decoder-autoreg: self-attention
[2019-07-16 20:03:49] [config] transformer-dim-aan: 2048
[2019-07-16 20:03:49] [config] transformer-dim-ffn: 2048
[2019-07-16 20:03:49] [config] transformer-dropout: 0
[2019-07-16 20:03:49] [config] transformer-dropout-attention: 0
[2019-07-16 20:03:49] [config] transformer-dropout-ffn: 0
[2019-07-16 20:03:49] [config] transformer-ffn-activation: swish
[2019-07-16 20:03:49] [config] transformer-ffn-depth: 2
[2019-07-16 20:03:49] [config] transformer-guided-alignment-layer: last
[2019-07-16 20:03:49] [config] transformer-heads: 8
[2019-07-16 20:03:49] [config] transformer-no-projection: false
[2019-07-16 20:03:49] [config] transformer-postprocess: dan
[2019-07-16 20:03:49] [config] transformer-postprocess-emb: d
[2019-07-16 20:03:49] [config] transformer-preprocess: ""
[2019-07-16 20:03:49] [config] transformer-tied-layers:
[2019-07-16 20:03:49] [config]   []
[2019-07-16 20:03:49] [config] transformer-train-position-embeddings: false
[2019-07-16 20:03:49] [config] type: amun
[2019-07-16 20:03:49] [config] ulr: false
[2019-07-16 20:03:49] [config] ulr-dim-emb: 0
[2019-07-16 20:03:49] [config] ulr-dropout: 0
[2019-07-16 20:03:49] [config] ulr-keys-vectors: ""
[2019-07-16 20:03:49] [config] ulr-query-vectors: ""
[2019-07-16 20:03:49] [config] ulr-softmax-temperature: 1
[2019-07-16 20:03:49] [config] ulr-trainable-transformation: false
[2019-07-16 20:03:49] [config] valid-freq: 20000
[2019-07-16 20:03:49] [config] valid-log: ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/valid.log
[2019-07-16 20:03:49] [config] valid-max-length: 1000
[2019-07-16 20:03:49] [config] valid-metrics:
[2019-07-16 20:03:49] [config]   - cross-entropy
[2019-07-16 20:03:49] [config]   - perplexity
[2019-07-16 20:03:49] [config]   - translation
[2019-07-16 20:03:49] [config] valid-mini-batch: 8
[2019-07-16 20:03:49] [config] valid-script-path: ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/score-dev.sh
[2019-07-16 20:03:49] [config] valid-sets:
[2019-07-16 20:03:49] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/data/dev.bpe.de
[2019-07-16 20:03:49] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/data/dev.bpe.en
[2019-07-16 20:03:49] [config] valid-translation-output: ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/dev.out
[2019-07-16 20:03:49] [config] vocabs:
[2019-07-16 20:03:49] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/data/train.bpe.de.json
[2019-07-16 20:03:49] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/data/train.bpe.en.json
[2019-07-16 20:03:49] [config] word-penalty: 0
[2019-07-16 20:03:49] [config] workspace: 5000
[2019-07-16 20:03:49] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-16 20:03:49] Using synchronous training
[2019-07-16 20:03:49] [data] Loading vocabulary from JSON/Yaml file ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/data/train.bpe.de.json
[2019-07-16 20:03:50] [data] Using unused word id eos for 0
[2019-07-16 20:03:50] [data] Using unused word id UNK for 1
[2019-07-16 20:03:50] [data] Setting vocabulary size for input 0 to 50000
[2019-07-16 20:03:50] [data] Loading vocabulary from JSON/Yaml file ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/data/train.bpe.en.json
[2019-07-16 20:03:50] [data] Using unused word id eos for 0
[2019-07-16 20:03:50] [data] Using unused word id UNK for 1
[2019-07-16 20:03:50] [data] Setting vocabulary size for input 1 to 50000
[2019-07-16 20:03:50] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-16 20:03:50] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-16 20:03:51] [memory] Extending reserved space to 5120 MB (device gpu0)
[2019-07-16 20:03:51] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-16 20:03:51] [comm] NCCLCommunicator constructed successfully.
[2019-07-16 20:03:51] [training] Using 1 GPUs
[2019-07-16 20:03:51] [memory] Reserving 422 MB, device gpu0
[2019-07-16 20:03:51] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-16 20:03:51] [memory] Reserving 422 MB, device gpu0
[2019-07-16 20:04:00] [batching] Done. Typical MB size is 6880 target words
[2019-07-16 20:04:00] [memory] Extending reserved space to 5120 MB (device gpu0)
[2019-07-16 20:04:00] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-16 20:04:00] [comm] NCCLCommunicator constructed successfully.
[2019-07-16 20:04:00] [training] Using 1 GPUs
[2019-07-16 20:04:00] Training started
[2019-07-16 20:04:00] [data] Shuffling data
[2019-07-16 20:04:07] [data] Done reading 13926791 sentences
[2019-07-16 20:05:06] [data] Done shuffling 13926791 sentences to temp files
[2019-07-16 20:05:12] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-07-16 20:05:12] [memory] Reserving 422 MB, device gpu0
[2019-07-16 20:05:12] [memory] Reserving 422 MB, device gpu0
[2019-07-16 20:05:12] [memory] Reserving 422 MB, device gpu0
[2019-07-16 20:05:12] [memory] Reserving 844 MB, device gpu0
[2019-07-16 20:18:17] Ep. 1 : Up. 2000 : Sen. 288,980 : Cost 136.67829895 : Time 866.86s : 7021.38 words/s
[2019-07-16 20:31:32] Ep. 1 : Up. 4000 : Sen. 578,204 : Cost 119.14485931 : Time 795.26s : 7700.74 words/s
[2019-07-16 20:44:46] Ep. 1 : Up. 6000 : Sen. 867,006 : Cost 110.54579163 : Time 794.05s : 7681.66 words/s
[2019-07-16 20:58:00] Ep. 1 : Up. 8000 : Sen. 1,156,506 : Cost 104.54887390 : Time 793.07s : 7686.02 words/s
[2019-07-16 21:11:17] Ep. 1 : Up. 10000 : Sen. 1,446,136 : Cost 101.04737854 : Time 797.19s : 7678.94 words/s
[2019-07-16 21:24:29] Ep. 1 : Up. 12000 : Sen. 1,735,144 : Cost 97.57967377 : Time 792.50s : 7703.89 words/s
[2019-07-16 21:37:45] Ep. 1 : Up. 14000 : Sen. 2,024,336 : Cost 94.93437958 : Time 796.05s : 7667.26 words/s
[2019-07-16 21:50:57] Ep. 1 : Up. 16000 : Sen. 2,313,410 : Cost 92.65753174 : Time 791.88s : 7713.48 words/s
[2019-07-16 22:04:12] Ep. 1 : Up. 18000 : Sen. 2,602,860 : Cost 90.86294556 : Time 794.48s : 7693.62 words/s
[2019-07-16 22:17:27] Ep. 1 : Up. 20000 : Sen. 2,892,404 : Cost 89.30216217 : Time 794.91s : 7702.16 words/s
[2019-07-16 22:17:27] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.orig.npz
[2019-07-16 22:17:38] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.iter20000.npz
[2019-07-16 22:17:45] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.npz
[2019-07-16 22:17:58] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.optimizer.npz
[2019-07-16 22:18:24] [valid] Ep. 1 : Up. 20000 : cross-entropy : 90.5272 : new best
[2019-07-16 22:18:32] [valid] Ep. 1 : Up. 20000 : perplexity : 36.1281 : new best
[2019-07-16 22:19:48] [valid] Ep. 1 : Up. 20000 : translation : 13.13 : new best
[2019-07-16 22:33:07] Ep. 1 : Up. 22000 : Sen. 3,182,203 : Cost 87.67019653 : Time 940.80s : 6495.29 words/s
[2019-07-16 22:46:20] Ep. 1 : Up. 24000 : Sen. 3,469,743 : Cost 86.90724945 : Time 793.03s : 7670.92 words/s
[2019-07-16 22:59:33] Ep. 1 : Up. 26000 : Sen. 3,758,773 : Cost 85.51733398 : Time 793.09s : 7691.19 words/s
[2019-07-16 23:12:44] Ep. 1 : Up. 28000 : Sen. 4,047,285 : Cost 84.47225952 : Time 790.63s : 7690.36 words/s
[2019-07-16 23:25:58] Ep. 1 : Up. 30000 : Sen. 4,336,110 : Cost 84.05615234 : Time 793.91s : 7707.41 words/s
[2019-07-16 23:39:15] Ep. 1 : Up. 32000 : Sen. 4,626,540 : Cost 82.79882050 : Time 797.21s : 7688.07 words/s
[2019-07-16 23:52:32] Ep. 1 : Up. 34000 : Sen. 4,916,290 : Cost 82.46490479 : Time 796.35s : 7686.50 words/s
[2019-07-17 00:05:45] Ep. 1 : Up. 36000 : Sen. 5,205,613 : Cost 81.55976868 : Time 793.87s : 7689.41 words/s
[2019-07-17 00:18:58] Ep. 1 : Up. 38000 : Sen. 5,493,181 : Cost 81.14848328 : Time 792.30s : 7668.00 words/s
[2019-07-17 00:32:13] Ep. 1 : Up. 40000 : Sen. 5,782,326 : Cost 80.44512939 : Time 795.17s : 7680.92 words/s
[2019-07-17 00:32:13] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.orig.npz
[2019-07-17 00:32:22] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.iter40000.npz
[2019-07-17 00:32:29] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.npz
[2019-07-17 00:32:38] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.optimizer.npz
[2019-07-17 00:33:05] [valid] Ep. 1 : Up. 40000 : cross-entropy : 73.0741 : new best
[2019-07-17 00:33:13] [valid] Ep. 1 : Up. 40000 : perplexity : 18.0927 : new best
[2019-07-17 00:34:22] [valid] Ep. 1 : Up. 40000 : translation : 19.61 : new best
[2019-07-17 00:47:36] Ep. 1 : Up. 42000 : Sen. 6,071,346 : Cost 79.80001831 : Time 922.97s : 6596.97 words/s
[2019-07-17 01:00:49] Ep. 1 : Up. 44000 : Sen. 6,359,892 : Cost 79.60376740 : Time 793.60s : 7675.69 words/s
[2019-07-17 01:14:01] Ep. 1 : Up. 46000 : Sen. 6,647,543 : Cost 79.23117828 : Time 791.50s : 7685.26 words/s
[2019-07-17 01:27:17] Ep. 1 : Up. 48000 : Sen. 6,936,766 : Cost 78.41207886 : Time 796.37s : 7652.60 words/s
[2019-07-17 01:40:32] Ep. 1 : Up. 50000 : Sen. 7,226,094 : Cost 78.05156708 : Time 794.98s : 7682.76 words/s
[2019-07-17 01:53:49] Ep. 1 : Up. 52000 : Sen. 7,515,492 : Cost 77.81907654 : Time 796.26s : 7685.82 words/s
[2019-07-17 02:07:01] Ep. 1 : Up. 54000 : Sen. 7,804,822 : Cost 77.47174072 : Time 792.88s : 7704.58 words/s
[2019-07-17 02:20:20] Ep. 1 : Up. 56000 : Sen. 8,094,301 : Cost 77.28858185 : Time 798.12s : 7664.54 words/s
[2019-07-17 02:33:32] Ep. 1 : Up. 58000 : Sen. 8,383,268 : Cost 76.64383698 : Time 792.89s : 7688.59 words/s
[2019-07-17 02:46:46] Ep. 1 : Up. 60000 : Sen. 8,672,000 : Cost 76.48521423 : Time 793.08s : 7703.52 words/s
[2019-07-17 02:46:46] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.orig.npz
[2019-07-17 02:46:54] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.iter60000.npz
[2019-07-17 02:47:01] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.npz
[2019-07-17 02:47:10] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.optimizer.npz
[2019-07-17 02:47:36] [valid] Ep. 1 : Up. 60000 : cross-entropy : 66.1466 : new best
[2019-07-17 02:47:44] [valid] Ep. 1 : Up. 60000 : perplexity : 13.7496 : new best
[2019-07-17 02:48:51] [valid] Ep. 1 : Up. 60000 : translation : 22.19 : new best
[2019-07-17 03:02:05] Ep. 1 : Up. 62000 : Sen. 8,960,438 : Cost 76.15307617 : Time 919.18s : 6628.63 words/s
[2019-07-17 03:15:21] Ep. 1 : Up. 64000 : Sen. 9,249,458 : Cost 76.08774567 : Time 796.65s : 7670.70 words/s
[2019-07-17 03:28:36] Ep. 1 : Up. 66000 : Sen. 9,538,745 : Cost 75.87182617 : Time 795.08s : 7697.91 words/s
[2019-07-17 03:41:49] Ep. 1 : Up. 68000 : Sen. 9,828,001 : Cost 75.24594879 : Time 793.03s : 7667.77 words/s
[2019-07-17 03:55:09] Ep. 1 : Up. 70000 : Sen. 10,119,290 : Cost 75.48818970 : Time 799.81s : 7707.31 words/s
[2019-07-17 04:08:22] Ep. 1 : Up. 72000 : Sen. 10,409,229 : Cost 74.96792603 : Time 792.37s : 7707.03 words/s
[2019-07-17 04:21:35] Ep. 1 : Up. 74000 : Sen. 10,697,999 : Cost 74.63105774 : Time 793.57s : 7690.14 words/s
[2019-07-17 04:34:52] Ep. 1 : Up. 76000 : Sen. 10,988,404 : Cost 74.62615204 : Time 797.27s : 7697.91 words/s
[2019-07-17 04:48:07] Ep. 1 : Up. 78000 : Sen. 11,278,841 : Cost 74.05445099 : Time 794.98s : 7701.60 words/s
[2019-07-17 05:01:25] Ep. 1 : Up. 80000 : Sen. 11,568,432 : Cost 74.31114197 : Time 797.70s : 7686.07 words/s
[2019-07-17 05:01:25] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.orig.npz
[2019-07-17 05:01:35] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.iter80000.npz
[2019-07-17 05:01:42] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.npz
[2019-07-17 05:01:51] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.optimizer.npz
[2019-07-17 05:02:17] [valid] Ep. 1 : Up. 80000 : cross-entropy : 62.2868 : new best
[2019-07-17 05:02:25] [valid] Ep. 1 : Up. 80000 : perplexity : 11.7996 : new best
[2019-07-17 05:03:31] [valid] Ep. 1 : Up. 80000 : translation : 23.25 : new best
[2019-07-17 05:13:56] Seen 11795649 samples
[2019-07-17 05:13:56] Starting epoch 2
[2019-07-17 05:13:56] [data] Shuffling data
[2019-07-17 05:14:03] [data] Done reading 13926791 sentences
[2019-07-17 05:15:04] [data] Done shuffling 13926791 sentences to temp files
[2019-07-17 05:17:58] Ep. 2 : Up. 82000 : Sen. 61,223 : Cost 73.69837952 : Time 993.12s : 6126.51 words/s
[2019-07-17 05:31:11] Ep. 2 : Up. 84000 : Sen. 350,353 : Cost 73.07001495 : Time 792.81s : 7701.30 words/s
[2019-07-17 05:44:23] Ep. 2 : Up. 86000 : Sen. 639,545 : Cost 72.72842407 : Time 791.96s : 7702.13 words/s
[2019-07-17 05:57:35] Ep. 2 : Up. 88000 : Sen. 928,000 : Cost 72.72512817 : Time 791.80s : 7702.63 words/s
[2019-07-17 06:10:49] Ep. 2 : Up. 90000 : Sen. 1,216,742 : Cost 72.80104828 : Time 793.77s : 7686.19 words/s
[2019-07-17 06:24:08] Ep. 2 : Up. 92000 : Sen. 1,506,006 : Cost 72.65460968 : Time 798.94s : 7654.82 words/s
[2019-07-17 06:37:24] Ep. 2 : Up. 94000 : Sen. 1,795,637 : Cost 72.19935608 : Time 796.70s : 7667.56 words/s
[2019-07-17 06:50:38] Ep. 2 : Up. 96000 : Sen. 2,084,478 : Cost 72.16092682 : Time 794.04s : 7684.95 words/s
[2019-07-17 07:03:52] Ep. 2 : Up. 98000 : Sen. 2,374,268 : Cost 71.86207581 : Time 793.68s : 7697.80 words/s
[2019-07-17 07:17:06] Ep. 2 : Up. 100000 : Sen. 2,663,537 : Cost 72.16983795 : Time 793.63s : 7701.11 words/s
[2019-07-17 07:17:06] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.orig.npz
[2019-07-17 07:17:15] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.iter100000.npz
[2019-07-17 07:17:22] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.npz
[2019-07-17 07:17:31] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.optimizer.npz
[2019-07-17 07:17:57] [valid] Ep. 2 : Up. 100000 : cross-entropy : 59.7798 : new best
[2019-07-17 07:18:05] [valid] Ep. 2 : Up. 100000 : perplexity : 10.6838 : new best
[2019-07-17 07:19:11] [valid] Ep. 2 : Up. 100000 : translation : 23.74 : new best
[2019-07-17 07:32:26] Ep. 2 : Up. 102000 : Sen. 2,952,416 : Cost 71.95311737 : Time 920.60s : 6624.76 words/s
[2019-07-17 07:45:43] Ep. 2 : Up. 104000 : Sen. 3,242,286 : Cost 71.89820099 : Time 796.60s : 7695.19 words/s
[2019-07-17 07:58:58] Ep. 2 : Up. 106000 : Sen. 3,531,098 : Cost 71.85934448 : Time 795.50s : 7686.10 words/s
[2019-07-17 08:12:13] Ep. 2 : Up. 108000 : Sen. 3,820,362 : Cost 71.47751617 : Time 794.40s : 7678.93 words/s
[2019-07-17 08:25:28] Ep. 2 : Up. 110000 : Sen. 4,110,268 : Cost 71.32852173 : Time 795.73s : 7690.07 words/s
[2019-07-17 08:38:41] Ep. 2 : Up. 112000 : Sen. 4,399,282 : Cost 71.45624542 : Time 792.33s : 7721.86 words/s
[2019-07-17 08:51:50] Ep. 2 : Up. 114000 : Sen. 4,688,109 : Cost 71.14813232 : Time 789.31s : 7716.13 words/s
[2019-07-17 09:05:02] Ep. 2 : Up. 116000 : Sen. 4,977,827 : Cost 70.94091034 : Time 792.26s : 7713.92 words/s
[2019-07-17 09:18:12] Ep. 2 : Up. 118000 : Sen. 5,267,200 : Cost 71.21791840 : Time 789.39s : 7748.90 words/s
[2019-07-17 09:31:22] Ep. 2 : Up. 120000 : Sen. 5,557,214 : Cost 70.96151733 : Time 790.29s : 7751.73 words/s
[2019-07-17 09:31:22] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.orig.npz
[2019-07-17 09:31:31] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.iter120000.npz
[2019-07-17 09:31:39] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.npz
[2019-07-17 09:31:49] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.optimizer.npz
[2019-07-17 09:32:16] [valid] Ep. 2 : Up. 120000 : cross-entropy : 57.9966 : new best
[2019-07-17 09:32:24] [valid] Ep. 2 : Up. 120000 : perplexity : 9.95494 : new best
[2019-07-17 09:33:28] [valid] Ep. 2 : Up. 120000 : translation : 24.01 : new best
[2019-07-17 09:46:41] Ep. 2 : Up. 122000 : Sen. 5,846,842 : Cost 70.66234589 : Time 919.40s : 6643.59 words/s
[2019-07-17 09:59:58] Ep. 2 : Up. 124000 : Sen. 6,135,855 : Cost 71.09463501 : Time 796.68s : 7680.36 words/s
[2019-07-17 10:13:08] Ep. 2 : Up. 126000 : Sen. 6,424,557 : Cost 70.40364838 : Time 789.41s : 7712.95 words/s
[2019-07-17 10:26:19] Ep. 2 : Up. 128000 : Sen. 6,713,774 : Cost 70.69631958 : Time 791.60s : 7719.96 words/s
[2019-07-17 10:39:29] Ep. 2 : Up. 130000 : Sen. 7,002,783 : Cost 70.59411621 : Time 790.03s : 7733.71 words/s
[2019-07-17 10:52:42] Ep. 2 : Up. 132000 : Sen. 7,293,024 : Cost 70.19287872 : Time 792.41s : 7722.83 words/s
[2019-07-17 11:05:51] Ep. 2 : Up. 134000 : Sen. 7,582,582 : Cost 70.27131653 : Time 789.02s : 7746.29 words/s
[2019-07-17 11:18:59] Ep. 2 : Up. 136000 : Sen. 7,871,575 : Cost 70.41398621 : Time 788.86s : 7739.20 words/s
[2019-07-17 11:32:07] Ep. 2 : Up. 138000 : Sen. 8,161,309 : Cost 70.16129303 : Time 787.46s : 7757.85 words/s
[2019-07-17 11:45:13] Ep. 2 : Up. 140000 : Sen. 8,449,778 : Cost 70.14060211 : Time 786.28s : 7745.00 words/s
[2019-07-17 11:45:13] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.orig.npz
[2019-07-17 11:45:23] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.iter140000.npz
[2019-07-17 11:45:34] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.npz
[2019-07-17 11:45:45] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.optimizer.npz
[2019-07-17 11:46:16] [valid] Ep. 2 : Up. 140000 : cross-entropy : 56.6689 : new best
[2019-07-17 11:46:24] [valid] Ep. 2 : Up. 140000 : perplexity : 9.44476 : new best
[2019-07-17 11:47:28] [valid] Ep. 2 : Up. 140000 : translation : 24 : stalled 1 times (last best: 24.01)
[2019-07-17 12:00:44] Ep. 2 : Up. 142000 : Sen. 8,739,591 : Cost 70.20008850 : Time 931.26s : 6592.08 words/s
[2019-07-17 12:13:57] Ep. 2 : Up. 144000 : Sen. 9,029,212 : Cost 69.50498199 : Time 793.03s : 7691.96 words/s
[2019-07-17 12:27:10] Ep. 2 : Up. 146000 : Sen. 9,317,375 : Cost 69.81149292 : Time 792.63s : 7687.73 words/s
[2019-07-17 12:40:24] Ep. 2 : Up. 148000 : Sen. 9,606,130 : Cost 69.65330505 : Time 794.04s : 7673.44 words/s
[2019-07-17 12:53:37] Ep. 2 : Up. 150000 : Sen. 9,894,532 : Cost 69.79360199 : Time 792.93s : 7690.37 words/s
[2019-07-17 13:06:52] Ep. 2 : Up. 152000 : Sen. 10,183,762 : Cost 69.48574066 : Time 794.97s : 7680.11 words/s
[2019-07-17 13:20:08] Ep. 2 : Up. 154000 : Sen. 10,473,598 : Cost 69.64910126 : Time 796.18s : 7691.92 words/s
[2019-07-17 13:33:24] Ep. 2 : Up. 156000 : Sen. 10,762,955 : Cost 69.21081543 : Time 795.41s : 7657.33 words/s
[2019-07-17 13:46:40] Ep. 2 : Up. 158000 : Sen. 11,052,404 : Cost 69.37084961 : Time 796.63s : 7671.00 words/s
[2019-07-17 13:59:57] Ep. 2 : Up. 160000 : Sen. 11,342,316 : Cost 69.15483093 : Time 797.16s : 7680.52 words/s
[2019-07-17 13:59:57] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.orig.npz
[2019-07-17 14:00:07] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.iter160000.npz
[2019-07-17 14:00:14] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.npz
[2019-07-17 14:00:24] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.0/model/model.npz.optimizer.npz
[2019-07-17 14:00:49] [valid] Ep. 2 : Up. 160000 : cross-entropy : 55.6266 : new best
[2019-07-17 14:00:57] [valid] Ep. 2 : Up. 160000 : perplexity : 9.06266 : new best
[2019-07-17 14:02:03] [valid] Ep. 2 : Up. 160000 : translation : 24.64 : new best
[2019-07-17 14:15:18] Ep. 2 : Up. 162000 : Sen. 11,631,622 : Cost 68.82612610 : Time 920.66s : 6610.21 words/s
[2019-07-17 14:22:51] Seen 11795649 samples
[2019-07-17 14:22:51] Starting epoch 3
[2019-07-17 14:22:51] [data] Shuffling data
[2019-07-17 14:22:58] [data] Done reading 13926791 sentences
[2019-07-17 14:24:02] [data] Done shuffling 13926791 sentences to temp files
[2019-07-17 14:30:08] Ep. 3 : Up. 164000 : Sen. 125,100 : Cost 68.68495178 : Time 890.00s : 6859.63 words/s
[2019-07-17 14:43:25] Ep. 3 : Up. 166000 : Sen. 413,717 : Cost 68.66392517 : Time 797.31s : 7667.21 words/s
[2019-07-17 14:56:41] Ep. 3 : Up. 168000 : Sen. 702,660 : Cost 68.39322662 : Time 795.46s : 7673.31 words/s
[2019-07-17 15:09:54] Ep. 3 : Up. 170000 : Sen. 991,736 : Cost 68.30237579 : Time 793.62s : 7699.10 words/s
[2019-07-17 15:23:09] Ep. 3 : Up. 172000 : Sen. 1,281,590 : Cost 67.98606873 : Time 794.32s : 7695.23 words/s
[2019-07-17 15:36:25] Ep. 3 : Up. 174000 : Sen. 1,571,279 : Cost 68.60224915 : Time 796.62s : 7699.34 words/s
[2019-07-17 15:49:41] Ep. 3 : Up. 176000 : Sen. 1,861,260 : Cost 68.14737701 : Time 795.52s : 7683.41 words/s
[2019-07-17 16:02:58] Ep. 3 : Up. 178000 : Sen. 2,151,081 : Cost 68.12436676 : Time 796.66s : 7666.70 words/s
