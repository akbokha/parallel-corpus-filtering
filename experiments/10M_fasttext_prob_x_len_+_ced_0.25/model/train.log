[2019-07-16 18:42:34] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-16 18:42:34] [marian] Running on dagr as process 35722 with command line:
[2019-07-16 18:42:34] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz -T . --devices 2 --train-sets ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.de ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.en --vocabs ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.de.json ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.en.json --mini-batch-fit -w 5000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/dev.bpe.de ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/dev.out --valid-script-path ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/train.log --valid-log ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/valid.log
[2019-07-16 18:42:34] [config] after-batches: 0
[2019-07-16 18:42:34] [config] after-epochs: 0
[2019-07-16 18:42:34] [config] allow-unk: false
[2019-07-16 18:42:34] [config] beam-size: 12
[2019-07-16 18:42:34] [config] bert-class-symbol: "[CLS]"
[2019-07-16 18:42:34] [config] bert-mask-symbol: "[MASK]"
[2019-07-16 18:42:34] [config] bert-masking-fraction: 0.15
[2019-07-16 18:42:34] [config] bert-sep-symbol: "[SEP]"
[2019-07-16 18:42:34] [config] bert-train-type-embeddings: true
[2019-07-16 18:42:34] [config] bert-type-vocab-size: 2
[2019-07-16 18:42:34] [config] best-deep: false
[2019-07-16 18:42:34] [config] clip-gemm: 0
[2019-07-16 18:42:34] [config] clip-norm: 1
[2019-07-16 18:42:34] [config] cost-type: ce-mean
[2019-07-16 18:42:34] [config] cpu-threads: 0
[2019-07-16 18:42:34] [config] data-weighting: ""
[2019-07-16 18:42:34] [config] data-weighting-type: sentence
[2019-07-16 18:42:34] [config] dec-cell: gru
[2019-07-16 18:42:34] [config] dec-cell-base-depth: 2
[2019-07-16 18:42:34] [config] dec-cell-high-depth: 1
[2019-07-16 18:42:34] [config] dec-depth: 1
[2019-07-16 18:42:34] [config] devices:
[2019-07-16 18:42:34] [config]   - 2
[2019-07-16 18:42:34] [config] dim-emb: 512
[2019-07-16 18:42:34] [config] dim-rnn: 1024
[2019-07-16 18:42:34] [config] dim-vocabs:
[2019-07-16 18:42:34] [config]   - 50000
[2019-07-16 18:42:34] [config]   - 50000
[2019-07-16 18:42:34] [config] disp-first: 0
[2019-07-16 18:42:34] [config] disp-freq: 2000
[2019-07-16 18:42:34] [config] disp-label-counts: false
[2019-07-16 18:42:34] [config] dropout-rnn: 0.2
[2019-07-16 18:42:34] [config] dropout-src: 0.1
[2019-07-16 18:42:34] [config] dropout-trg: 0.1
[2019-07-16 18:42:34] [config] dump-config: ""
[2019-07-16 18:42:34] [config] early-stopping: 5
[2019-07-16 18:42:34] [config] embedding-fix-src: false
[2019-07-16 18:42:34] [config] embedding-fix-trg: false
[2019-07-16 18:42:34] [config] embedding-normalization: false
[2019-07-16 18:42:34] [config] embedding-vectors:
[2019-07-16 18:42:34] [config]   []
[2019-07-16 18:42:34] [config] enc-cell: gru
[2019-07-16 18:42:34] [config] enc-cell-depth: 1
[2019-07-16 18:42:34] [config] enc-depth: 1
[2019-07-16 18:42:34] [config] enc-type: bidirectional
[2019-07-16 18:42:34] [config] exponential-smoothing: 0.0001
[2019-07-16 18:42:34] [config] grad-dropping-momentum: 0
[2019-07-16 18:42:34] [config] grad-dropping-rate: 0
[2019-07-16 18:42:34] [config] grad-dropping-warmup: 100
[2019-07-16 18:42:34] [config] guided-alignment: none
[2019-07-16 18:42:34] [config] guided-alignment-cost: mse
[2019-07-16 18:42:34] [config] guided-alignment-weight: 0.1
[2019-07-16 18:42:34] [config] ignore-model-config: false
[2019-07-16 18:42:34] [config] input-types:
[2019-07-16 18:42:34] [config]   []
[2019-07-16 18:42:34] [config] interpolate-env-vars: false
[2019-07-16 18:42:34] [config] keep-best: false
[2019-07-16 18:42:34] [config] label-smoothing: 0
[2019-07-16 18:42:34] [config] layer-normalization: true
[2019-07-16 18:42:34] [config] learn-rate: 0.0001
[2019-07-16 18:42:34] [config] log: ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/train.log
[2019-07-16 18:42:34] [config] log-level: info
[2019-07-16 18:42:34] [config] log-time-zone: ""
[2019-07-16 18:42:34] [config] lr-decay: 0
[2019-07-16 18:42:34] [config] lr-decay-freq: 50000
[2019-07-16 18:42:34] [config] lr-decay-inv-sqrt:
[2019-07-16 18:42:34] [config]   - 0
[2019-07-16 18:42:34] [config] lr-decay-repeat-warmup: false
[2019-07-16 18:42:34] [config] lr-decay-reset-optimizer: false
[2019-07-16 18:42:34] [config] lr-decay-start:
[2019-07-16 18:42:34] [config]   - 10
[2019-07-16 18:42:34] [config]   - 1
[2019-07-16 18:42:34] [config] lr-decay-strategy: epoch+stalled
[2019-07-16 18:42:34] [config] lr-report: false
[2019-07-16 18:42:34] [config] lr-warmup: 0
[2019-07-16 18:42:34] [config] lr-warmup-at-reload: false
[2019-07-16 18:42:34] [config] lr-warmup-cycle: false
[2019-07-16 18:42:34] [config] lr-warmup-start-rate: 0
[2019-07-16 18:42:34] [config] max-length: 50
[2019-07-16 18:42:34] [config] max-length-crop: false
[2019-07-16 18:42:34] [config] max-length-factor: 3
[2019-07-16 18:42:34] [config] maxi-batch: 100
[2019-07-16 18:42:34] [config] maxi-batch-sort: trg
[2019-07-16 18:42:34] [config] mini-batch: 64
[2019-07-16 18:42:34] [config] mini-batch-fit: true
[2019-07-16 18:42:34] [config] mini-batch-fit-step: 10
[2019-07-16 18:42:34] [config] mini-batch-overstuff: 1
[2019-07-16 18:42:34] [config] mini-batch-track-lr: false
[2019-07-16 18:42:34] [config] mini-batch-understuff: 1
[2019-07-16 18:42:34] [config] mini-batch-warmup: 0
[2019-07-16 18:42:34] [config] mini-batch-words: 0
[2019-07-16 18:42:34] [config] mini-batch-words-ref: 0
[2019-07-16 18:42:34] [config] model: ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-16 18:42:34] [config] multi-loss-type: sum
[2019-07-16 18:42:34] [config] multi-node: false
[2019-07-16 18:42:34] [config] multi-node-overlap: true
[2019-07-16 18:42:34] [config] n-best: false
[2019-07-16 18:42:34] [config] no-nccl: false
[2019-07-16 18:42:34] [config] no-reload: false
[2019-07-16 18:42:34] [config] no-restore-corpus: false
[2019-07-16 18:42:34] [config] no-shuffle: false
[2019-07-16 18:42:34] [config] normalize: 1
[2019-07-16 18:42:34] [config] num-devices: 0
[2019-07-16 18:42:34] [config] optimizer: adam
[2019-07-16 18:42:34] [config] optimizer-delay: 1
[2019-07-16 18:42:34] [config] optimizer-params:
[2019-07-16 18:42:34] [config]   []
[2019-07-16 18:42:34] [config] overwrite: false
[2019-07-16 18:42:34] [config] pretrained-model: ""
[2019-07-16 18:42:34] [config] quiet: false
[2019-07-16 18:42:34] [config] quiet-translation: true
[2019-07-16 18:42:34] [config] relative-paths: false
[2019-07-16 18:42:34] [config] right-left: false
[2019-07-16 18:42:34] [config] save-freq: 20000
[2019-07-16 18:42:34] [config] seed: 1111
[2019-07-16 18:42:34] [config] shuffle-in-ram: false
[2019-07-16 18:42:34] [config] skip: false
[2019-07-16 18:42:34] [config] sqlite: ""
[2019-07-16 18:42:34] [config] sqlite-drop: false
[2019-07-16 18:42:34] [config] sync-sgd: true
[2019-07-16 18:42:34] [config] tempdir: .
[2019-07-16 18:42:34] [config] tied-embeddings: false
[2019-07-16 18:42:34] [config] tied-embeddings-all: false
[2019-07-16 18:42:34] [config] tied-embeddings-src: false
[2019-07-16 18:42:34] [config] train-sets:
[2019-07-16 18:42:34] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.de
[2019-07-16 18:42:34] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.en
[2019-07-16 18:42:34] [config] transformer-aan-activation: swish
[2019-07-16 18:42:34] [config] transformer-aan-depth: 2
[2019-07-16 18:42:34] [config] transformer-aan-nogate: false
[2019-07-16 18:42:34] [config] transformer-decoder-autoreg: self-attention
[2019-07-16 18:42:34] [config] transformer-dim-aan: 2048
[2019-07-16 18:42:34] [config] transformer-dim-ffn: 2048
[2019-07-16 18:42:34] [config] transformer-dropout: 0
[2019-07-16 18:42:34] [config] transformer-dropout-attention: 0
[2019-07-16 18:42:34] [config] transformer-dropout-ffn: 0
[2019-07-16 18:42:34] [config] transformer-ffn-activation: swish
[2019-07-16 18:42:34] [config] transformer-ffn-depth: 2
[2019-07-16 18:42:34] [config] transformer-guided-alignment-layer: last
[2019-07-16 18:42:34] [config] transformer-heads: 8
[2019-07-16 18:42:34] [config] transformer-no-projection: false
[2019-07-16 18:42:34] [config] transformer-postprocess: dan
[2019-07-16 18:42:34] [config] transformer-postprocess-emb: d
[2019-07-16 18:42:34] [config] transformer-preprocess: ""
[2019-07-16 18:42:34] [config] transformer-tied-layers:
[2019-07-16 18:42:34] [config]   []
[2019-07-16 18:42:34] [config] transformer-train-position-embeddings: false
[2019-07-16 18:42:34] [config] type: amun
[2019-07-16 18:42:34] [config] ulr: false
[2019-07-16 18:42:34] [config] ulr-dim-emb: 0
[2019-07-16 18:42:34] [config] ulr-dropout: 0
[2019-07-16 18:42:34] [config] ulr-keys-vectors: ""
[2019-07-16 18:42:34] [config] ulr-query-vectors: ""
[2019-07-16 18:42:34] [config] ulr-softmax-temperature: 1
[2019-07-16 18:42:34] [config] ulr-trainable-transformation: false
[2019-07-16 18:42:34] [config] valid-freq: 20000
[2019-07-16 18:42:34] [config] valid-log: ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/valid.log
[2019-07-16 18:42:34] [config] valid-max-length: 1000
[2019-07-16 18:42:34] [config] valid-metrics:
[2019-07-16 18:42:34] [config]   - cross-entropy
[2019-07-16 18:42:34] [config]   - perplexity
[2019-07-16 18:42:34] [config]   - translation
[2019-07-16 18:42:34] [config] valid-mini-batch: 8
[2019-07-16 18:42:34] [config] valid-script-path: ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/score-dev.sh
[2019-07-16 18:42:34] [config] valid-sets:
[2019-07-16 18:42:34] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/dev.bpe.de
[2019-07-16 18:42:34] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/dev.bpe.en
[2019-07-16 18:42:34] [config] valid-translation-output: ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/dev.out
[2019-07-16 18:42:34] [config] vocabs:
[2019-07-16 18:42:34] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.de.json
[2019-07-16 18:42:34] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.en.json
[2019-07-16 18:42:34] [config] word-penalty: 0
[2019-07-16 18:42:34] [config] workspace: 5000
[2019-07-16 18:42:34] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-16 18:42:34] Using synchronous training
[2019-07-16 18:42:34] [data] Loading vocabulary from JSON/Yaml file ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.de.json
[2019-07-16 18:42:34] [data] Using unused word id eos for 0
[2019-07-16 18:42:34] [data] Using unused word id UNK for 1
[2019-07-16 18:42:34] [data] Setting vocabulary size for input 0 to 50000
[2019-07-16 18:42:34] [data] Loading vocabulary from JSON/Yaml file ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.en.json
[2019-07-16 18:42:34] [data] Using unused word id eos for 0
[2019-07-16 18:42:34] [data] Using unused word id UNK for 1
[2019-07-16 18:42:34] [data] Setting vocabulary size for input 1 to 50000
[2019-07-16 18:42:34] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-16 18:42:34] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-16 18:42:36] [memory] Extending reserved space to 5120 MB (device gpu2)
[2019-07-16 18:42:36] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-16 18:42:36] [comm] NCCLCommunicator constructed successfully.
[2019-07-16 18:42:36] [training] Using 1 GPUs
[2019-07-16 18:42:36] [memory] Reserving 422 MB, device gpu2
[2019-07-16 18:42:36] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-16 18:42:36] [memory] Reserving 422 MB, device gpu2
[2019-07-16 18:42:45] [batching] Done. Typical MB size is 6880 target words
[2019-07-16 18:42:45] [memory] Extending reserved space to 5120 MB (device gpu2)
[2019-07-16 18:42:45] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-16 18:42:45] [comm] NCCLCommunicator constructed successfully.
[2019-07-16 18:42:45] [training] Using 1 GPUs
[2019-07-16 18:42:45] Training started
[2019-07-16 18:42:45] [data] Shuffling data
[2019-07-16 18:42:54] [data] Done reading 13926791 sentences
[2019-07-16 18:44:09] [data] Done shuffling 13926791 sentences to temp files
[2019-07-16 18:44:15] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-07-16 18:44:15] [memory] Reserving 422 MB, device gpu2
[2019-07-16 18:44:15] [memory] Reserving 422 MB, device gpu2
[2019-07-16 18:44:15] [memory] Reserving 422 MB, device gpu2
[2019-07-16 18:44:15] [memory] Reserving 844 MB, device gpu2
[2019-07-16 18:58:03] Ep. 1 : Up. 2000 : Sen. 288,980 : Cost 136.75701904 : Time 928.84s : 6553.05 words/s
[2019-07-16 19:12:04] Ep. 1 : Up. 4000 : Sen. 578,204 : Cost 119.14662933 : Time 841.01s : 7281.78 words/s
[2019-07-16 19:26:05] Ep. 1 : Up. 6000 : Sen. 867,303 : Cost 110.50666046 : Time 840.49s : 7258.97 words/s
[2019-07-16 19:40:06] Ep. 1 : Up. 8000 : Sen. 1,156,777 : Cost 104.86098480 : Time 840.94s : 7257.45 words/s
[2019-07-16 19:54:06] Ep. 1 : Up. 10000 : Sen. 1,446,723 : Cost 101.05861664 : Time 840.48s : 7288.99 words/s
[2019-07-16 20:08:05] Ep. 1 : Up. 12000 : Sen. 1,735,724 : Cost 97.64866638 : Time 839.05s : 7271.03 words/s
[2019-07-16 20:22:07] Ep. 1 : Up. 14000 : Sen. 2,024,932 : Cost 95.12207031 : Time 841.60s : 7256.94 words/s
[2019-07-16 20:36:07] Ep. 1 : Up. 16000 : Sen. 2,313,959 : Cost 92.84384918 : Time 840.65s : 7258.39 words/s
[2019-07-16 20:50:11] Ep. 1 : Up. 18000 : Sen. 2,603,653 : Cost 91.15547943 : Time 843.19s : 7264.05 words/s
[2019-07-16 21:04:14] Ep. 1 : Up. 20000 : Sen. 2,893,238 : Cost 89.63602448 : Time 843.39s : 7258.18 words/s
[2019-07-16 21:04:14] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-16 21:04:23] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter20000.npz
[2019-07-16 21:04:30] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-16 21:04:39] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-16 21:05:04] [valid] Ep. 1 : Up. 20000 : cross-entropy : 90.8601 : new best
[2019-07-16 21:05:11] [valid] Ep. 1 : Up. 20000 : perplexity : 36.6078 : new best
[2019-07-16 21:06:36] [valid] Ep. 1 : Up. 20000 : translation : 12.17 : new best
[2019-07-16 21:20:40] Ep. 1 : Up. 22000 : Sen. 3,182,468 : Cost 88.00970459 : Time 986.40s : 6188.45 words/s
[2019-07-16 21:34:39] Ep. 1 : Up. 24000 : Sen. 3,469,988 : Cost 87.03524017 : Time 838.90s : 7244.76 words/s
[2019-07-16 21:48:42] Ep. 1 : Up. 26000 : Sen. 3,758,814 : Cost 85.73952484 : Time 842.44s : 7240.17 words/s
[2019-07-16 22:02:39] Ep. 1 : Up. 28000 : Sen. 4,047,578 : Cost 84.69268036 : Time 837.38s : 7262.29 words/s
[2019-07-16 22:16:43] Ep. 1 : Up. 30000 : Sen. 4,336,226 : Cost 84.44776917 : Time 843.80s : 7253.87 words/s
[2019-07-16 22:30:46] Ep. 1 : Up. 32000 : Sen. 4,626,630 : Cost 82.86391449 : Time 843.09s : 7263.53 words/s
[2019-07-16 22:44:49] Ep. 1 : Up. 34000 : Sen. 4,916,289 : Cost 82.65140533 : Time 842.78s : 7258.69 words/s
[2019-07-16 22:58:51] Ep. 1 : Up. 36000 : Sen. 5,205,535 : Cost 81.85598755 : Time 842.10s : 7249.95 words/s
[2019-07-16 23:12:47] Ep. 1 : Up. 38000 : Sen. 5,492,817 : Cost 81.16600037 : Time 836.28s : 7247.86 words/s
[2019-07-16 23:26:50] Ep. 1 : Up. 40000 : Sen. 5,781,877 : Cost 80.56988525 : Time 843.18s : 7243.94 words/s
[2019-07-16 23:26:50] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-16 23:26:59] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter40000.npz
[2019-07-16 23:27:06] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-16 23:27:16] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-16 23:27:40] [valid] Ep. 1 : Up. 40000 : cross-entropy : 73.3961 : new best
[2019-07-16 23:27:48] [valid] Ep. 1 : Up. 40000 : perplexity : 18.3249 : new best
[2019-07-16 23:29:02] [valid] Ep. 1 : Up. 40000 : translation : 19.55 : new best
[2019-07-16 23:43:01] Ep. 1 : Up. 42000 : Sen. 6,070,179 : Cost 79.79265594 : Time 971.01s : 6255.03 words/s
[2019-07-16 23:57:03] Ep. 1 : Up. 44000 : Sen. 6,358,711 : Cost 79.79811859 : Time 841.26s : 7249.47 words/s
[2019-07-17 00:11:01] Ep. 1 : Up. 46000 : Sen. 6,646,578 : Cost 79.21067810 : Time 837.84s : 7252.49 words/s
[2019-07-17 00:25:01] Ep. 1 : Up. 48000 : Sen. 6,935,181 : Cost 78.89852142 : Time 840.47s : 7250.41 words/s
[2019-07-17 00:39:02] Ep. 1 : Up. 50000 : Sen. 7,224,299 : Cost 78.09456635 : Time 841.11s : 7244.83 words/s
[2019-07-17 00:53:08] Ep. 1 : Up. 52000 : Sen. 7,514,104 : Cost 78.21887207 : Time 845.57s : 7253.63 words/s
[2019-07-17 01:07:10] Ep. 1 : Up. 54000 : Sen. 7,803,587 : Cost 77.47589874 : Time 841.87s : 7250.49 words/s
[2019-07-17 01:21:11] Ep. 1 : Up. 56000 : Sen. 8,092,507 : Cost 77.51848602 : Time 841.77s : 7261.16 words/s
[2019-07-17 01:35:13] Ep. 1 : Up. 58000 : Sen. 8,381,422 : Cost 76.90616608 : Time 841.24s : 7247.35 words/s
[2019-07-17 01:49:16] Ep. 1 : Up. 60000 : Sen. 8,670,242 : Cost 76.79135895 : Time 843.88s : 7236.10 words/s
[2019-07-17 01:49:16] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-17 01:49:26] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter60000.npz
[2019-07-17 01:49:33] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-17 01:49:42] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-17 01:50:07] [valid] Ep. 1 : Up. 60000 : cross-entropy : 66.4769 : new best
[2019-07-17 01:50:14] [valid] Ep. 1 : Up. 60000 : perplexity : 13.9307 : new best
[2019-07-17 01:51:25] [valid] Ep. 1 : Up. 60000 : translation : 21.92 : new best
[2019-07-17 02:05:30] Ep. 1 : Up. 62000 : Sen. 8,958,748 : Cost 76.37639618 : Time 974.02s : 6271.37 words/s
[2019-07-17 02:19:35] Ep. 1 : Up. 64000 : Sen. 9,247,562 : Cost 76.25269318 : Time 844.13s : 7224.68 words/s
[2019-07-17 02:33:38] Ep. 1 : Up. 66000 : Sen. 9,536,854 : Cost 75.97511292 : Time 843.12s : 7249.68 words/s
[2019-07-17 02:47:40] Ep. 1 : Up. 68000 : Sen. 9,826,627 : Cost 75.20000458 : Time 841.90s : 7241.54 words/s
[2019-07-17 03:01:46] Ep. 1 : Up. 70000 : Sen. 10,117,566 : Cost 75.50884247 : Time 846.78s : 7265.14 words/s
[2019-07-17 03:15:52] Ep. 1 : Up. 72000 : Sen. 10,407,642 : Cost 75.12265778 : Time 845.68s : 7237.48 words/s
[2019-07-17 03:29:55] Ep. 1 : Up. 74000 : Sen. 10,697,114 : Cost 74.85155487 : Time 842.90s : 7246.93 words/s
[2019-07-17 03:44:00] Ep. 1 : Up. 76000 : Sen. 10,987,024 : Cost 74.63420105 : Time 844.78s : 7246.76 words/s
[2019-07-17 03:58:07] Ep. 1 : Up. 78000 : Sen. 11,277,900 : Cost 74.65672302 : Time 847.61s : 7249.42 words/s
[2019-07-17 04:12:12] Ep. 1 : Up. 80000 : Sen. 11,567,749 : Cost 74.19778442 : Time 844.49s : 7252.56 words/s
[2019-07-17 04:12:12] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-17 04:12:21] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter80000.npz
[2019-07-17 04:12:28] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-17 04:12:37] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-17 04:13:02] [valid] Ep. 1 : Up. 80000 : cross-entropy : 62.6195 : new best
[2019-07-17 04:13:09] [valid] Ep. 1 : Up. 80000 : perplexity : 11.9562 : new best
[2019-07-17 04:14:19] [valid] Ep. 1 : Up. 80000 : translation : 23.23 : new best
[2019-07-17 04:25:25] Seen 11795613 samples
[2019-07-17 04:25:25] Starting epoch 2
[2019-07-17 04:25:25] [data] Shuffling data
[2019-07-17 04:25:32] [data] Done reading 13926791 sentences
[2019-07-17 04:26:40] [data] Done shuffling 13926791 sentences to temp files
[2019-07-17 04:29:39] Ep. 2 : Up. 82000 : Sen. 60,413 : Cost 73.91910553 : Time 1047.05s : 5811.49 words/s
[2019-07-17 04:43:43] Ep. 2 : Up. 84000 : Sen. 349,577 : Cost 73.28546906 : Time 843.62s : 7241.19 words/s
[2019-07-17 04:57:45] Ep. 2 : Up. 86000 : Sen. 638,746 : Cost 73.02408600 : Time 842.43s : 7239.63 words/s
[2019-07-17 05:11:46] Ep. 2 : Up. 88000 : Sen. 927,110 : Cost 72.94388580 : Time 840.79s : 7250.45 words/s
[2019-07-17 05:25:48] Ep. 2 : Up. 90000 : Sen. 1,215,777 : Cost 72.96342468 : Time 841.82s : 7244.91 words/s
[2019-07-17 05:39:52] Ep. 2 : Up. 92000 : Sen. 1,505,130 : Cost 72.64910889 : Time 844.57s : 7238.31 words/s
[2019-07-17 05:53:56] Ep. 2 : Up. 94000 : Sen. 1,794,761 : Cost 72.33586121 : Time 843.86s : 7239.44 words/s
[2019-07-17 06:08:00] Ep. 2 : Up. 96000 : Sen. 2,083,543 : Cost 72.40852356 : Time 843.67s : 7238.63 words/s
[2019-07-17 06:22:03] Ep. 2 : Up. 98000 : Sen. 2,373,405 : Cost 72.06594086 : Time 843.50s : 7251.17 words/s
[2019-07-17 06:36:05] Ep. 2 : Up. 100000 : Sen. 2,662,664 : Cost 72.14463806 : Time 841.56s : 7255.79 words/s
[2019-07-17 06:36:05] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-17 06:36:15] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter100000.npz
[2019-07-17 06:36:22] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-17 06:36:32] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-17 06:36:59] [valid] Ep. 2 : Up. 100000 : cross-entropy : 60.2333 : new best
[2019-07-17 06:37:06] [valid] Ep. 2 : Up. 100000 : perplexity : 10.8775 : new best
[2019-07-17 06:38:16] [valid] Ep. 2 : Up. 100000 : translation : 23.84 : new best
[2019-07-17 06:52:22] Ep. 2 : Up. 102000 : Sen. 2,951,999 : Cost 72.12772369 : Time 977.27s : 6255.11 words/s
[2019-07-17 07:06:27] Ep. 2 : Up. 104000 : Sen. 3,242,063 : Cost 71.91580963 : Time 844.71s : 7249.80 words/s
[2019-07-17 07:20:31] Ep. 2 : Up. 106000 : Sen. 3,530,802 : Cost 71.98169708 : Time 844.04s : 7241.86 words/s
[2019-07-17 07:34:37] Ep. 2 : Up. 108000 : Sen. 3,820,130 : Cost 71.72251892 : Time 845.91s : 7225.69 words/s
[2019-07-17 07:48:39] Ep. 2 : Up. 110000 : Sen. 4,109,911 : Cost 71.25982666 : Time 842.46s : 7249.02 words/s
[2019-07-17 08:02:41] Ep. 2 : Up. 112000 : Sen. 4,398,873 : Cost 71.47452545 : Time 841.42s : 7257.85 words/s
[2019-07-17 08:16:43] Ep. 2 : Up. 114000 : Sen. 4,687,364 : Cost 71.46831512 : Time 842.39s : 7239.25 words/s
[2019-07-17 08:30:45] Ep. 2 : Up. 116000 : Sen. 4,977,180 : Cost 70.87658691 : Time 842.09s : 7247.51 words/s
[2019-07-17 08:44:49] Ep. 2 : Up. 118000 : Sen. 5,266,268 : Cost 71.57441711 : Time 843.81s : 7263.21 words/s
[2019-07-17 08:58:52] Ep. 2 : Up. 120000 : Sen. 5,556,340 : Cost 71.16921234 : Time 843.51s : 7261.31 words/s
[2019-07-17 08:58:52] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-17 08:59:02] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter120000.npz
[2019-07-17 08:59:08] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-17 08:59:18] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-17 08:59:43] [valid] Ep. 2 : Up. 120000 : cross-entropy : 58.4178 : new best
[2019-07-17 08:59:50] [valid] Ep. 2 : Up. 120000 : perplexity : 10.1225 : new best
[2019-07-17 09:01:00] [valid] Ep. 2 : Up. 120000 : translation : 24.07 : new best
[2019-07-17 09:15:05] Ep. 2 : Up. 122000 : Sen. 5,845,587 : Cost 70.95701599 : Time 972.62s : 6277.89 words/s
[2019-07-17 09:29:10] Ep. 2 : Up. 124000 : Sen. 6,135,076 : Cost 70.73576355 : Time 845.49s : 7226.14 words/s
[2019-07-17 09:43:12] Ep. 2 : Up. 126000 : Sen. 6,423,918 : Cost 70.59671783 : Time 841.22s : 7245.29 words/s
[2019-07-17 09:57:13] Ep. 2 : Up. 128000 : Sen. 6,712,686 : Cost 70.81116486 : Time 841.79s : 7256.17 words/s
[2019-07-17 10:11:19] Ep. 2 : Up. 130000 : Sen. 7,001,864 : Cost 70.49243164 : Time 845.71s : 7227.79 words/s
[2019-07-17 10:25:28] Ep. 2 : Up. 132000 : Sen. 7,292,765 : Cost 70.33087158 : Time 849.21s : 7229.77 words/s
[2019-07-17 10:39:31] Ep. 2 : Up. 134000 : Sen. 7,582,209 : Cost 70.16883087 : Time 842.25s : 7246.98 words/s
[2019-07-17 10:53:33] Ep. 2 : Up. 136000 : Sen. 7,870,860 : Cost 70.56362152 : Time 842.09s : 7246.45 words/s
[2019-07-17 11:07:37] Ep. 2 : Up. 138000 : Sen. 8,160,574 : Cost 70.25899506 : Time 844.14s : 7239.09 words/s
[2019-07-17 11:21:40] Ep. 2 : Up. 140000 : Sen. 8,449,524 : Cost 70.10806274 : Time 842.70s : 7224.78 words/s
[2019-07-17 11:21:40] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-17 11:21:49] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter140000.npz
[2019-07-17 11:21:56] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-17 11:22:06] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-17 11:22:31] [valid] Ep. 2 : Up. 140000 : cross-entropy : 57.0989 : new best
[2019-07-17 11:22:39] [valid] Ep. 2 : Up. 140000 : perplexity : 9.60708 : new best
[2019-07-17 11:23:48] [valid] Ep. 2 : Up. 140000 : translation : 24.24 : new best
[2019-07-17 11:37:55] Ep. 2 : Up. 142000 : Sen. 8,739,147 : Cost 70.35657501 : Time 975.45s : 6288.75 words/s
[2019-07-17 11:52:00] Ep. 2 : Up. 144000 : Sen. 9,028,861 : Cost 69.77267456 : Time 845.08s : 7233.55 words/s
[2019-07-17 12:06:01] Ep. 2 : Up. 146000 : Sen. 9,316,784 : Cost 69.90512085 : Time 840.69s : 7236.32 words/s
[2019-07-17 12:20:06] Ep. 2 : Up. 148000 : Sen. 9,606,004 : Cost 69.72819519 : Time 845.25s : 7215.73 words/s
[2019-07-17 12:34:12] Ep. 2 : Up. 150000 : Sen. 9,894,796 : Cost 70.02679443 : Time 845.91s : 7226.62 words/s
[2019-07-17 12:48:16] Ep. 2 : Up. 152000 : Sen. 10,184,490 : Cost 69.33224487 : Time 843.59s : 7239.87 words/s
[2019-07-17 13:02:20] Ep. 2 : Up. 154000 : Sen. 10,473,597 : Cost 69.86600494 : Time 844.31s : 7241.48 words/s
[2019-07-17 13:16:24] Ep. 2 : Up. 156000 : Sen. 10,762,926 : Cost 69.25230408 : Time 843.88s : 7213.41 words/s
[2019-07-17 13:30:27] Ep. 2 : Up. 158000 : Sen. 11,052,008 : Cost 69.47306061 : Time 843.39s : 7241.74 words/s
[2019-07-17 13:44:29] Ep. 2 : Up. 160000 : Sen. 11,341,502 : Cost 69.20060730 : Time 842.35s : 7252.75 words/s
[2019-07-17 13:44:29] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-17 13:44:39] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter160000.npz
[2019-07-17 13:44:45] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-17 13:44:55] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-17 13:45:19] [valid] Ep. 2 : Up. 160000 : cross-entropy : 56.1797 : new best
[2019-07-17 13:45:26] [valid] Ep. 2 : Up. 160000 : perplexity : 9.26345 : new best
[2019-07-17 13:46:36] [valid] Ep. 2 : Up. 160000 : translation : 24.56 : new best
[2019-07-17 14:00:42] Ep. 2 : Up. 162000 : Sen. 11,631,397 : Cost 68.98062897 : Time 972.71s : 6276.65 words/s
[2019-07-17 14:08:41] Seen 11795613 samples
[2019-07-17 14:08:41] Starting epoch 3
[2019-07-17 14:08:41] [data] Shuffling data
[2019-07-17 14:08:49] [data] Done reading 13926791 sentences
[2019-07-17 14:09:56] [data] Done shuffling 13926791 sentences to temp files
[2019-07-17 14:16:04] Ep. 3 : Up. 164000 : Sen. 124,795 : Cost 68.69310760 : Time 921.76s : 6611.20 words/s
[2019-07-17 14:30:09] Ep. 3 : Up. 166000 : Sen. 413,408 : Cost 68.51149750 : Time 845.29s : 7227.13 words/s
[2019-07-17 14:44:12] Ep. 3 : Up. 168000 : Sen. 702,503 : Cost 68.33521271 : Time 842.90s : 7238.98 words/s
[2019-07-17 14:58:16] Ep. 3 : Up. 170000 : Sen. 991,256 : Cost 68.52637482 : Time 843.57s : 7249.99 words/s
[2019-07-17 15:12:21] Ep. 3 : Up. 172000 : Sen. 1,280,792 : Cost 68.15972137 : Time 845.57s : 7230.47 words/s
[2019-07-17 15:26:28] Ep. 3 : Up. 174000 : Sen. 1,570,931 : Cost 68.55447388 : Time 846.33s : 7245.82 words/s
[2019-07-17 15:40:30] Ep. 3 : Up. 176000 : Sen. 1,860,522 : Cost 68.23023224 : Time 842.40s : 7242.86 words/s
[2019-07-17 15:54:32] Ep. 3 : Up. 178000 : Sen. 2,150,400 : Cost 68.16640472 : Time 842.38s : 7254.43 words/s
[2019-07-17 16:08:35] Ep. 3 : Up. 180000 : Sen. 2,439,438 : Cost 68.26760864 : Time 843.09s : 7247.59 words/s
[2019-07-17 16:08:35] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-17 16:08:45] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter180000.npz
[2019-07-17 16:08:53] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-17 16:09:10] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-17 16:09:35] [valid] Ep. 3 : Up. 180000 : cross-entropy : 55.3651 : new best
[2019-07-17 16:09:42] [valid] Ep. 3 : Up. 180000 : perplexity : 8.96922 : new best
[2019-07-17 16:10:53] [valid] Ep. 3 : Up. 180000 : translation : 24.52 : stalled 1 times (last best: 24.56)
[2019-07-17 16:24:57] Ep. 3 : Up. 182000 : Sen. 2,727,752 : Cost 67.97146606 : Time 981.81s : 6200.05 words/s
[2019-07-17 16:39:03] Ep. 3 : Up. 184000 : Sen. 3,016,604 : Cost 68.32720947 : Time 845.23s : 7239.74 words/s
[2019-07-17 16:53:07] Ep. 3 : Up. 186000 : Sen. 3,305,671 : Cost 68.17120361 : Time 844.89s : 7218.26 words/s
[2019-07-17 17:07:11] Ep. 3 : Up. 188000 : Sen. 3,595,626 : Cost 67.85560608 : Time 843.88s : 7263.86 words/s
[2019-07-17 17:21:18] Ep. 3 : Up. 190000 : Sen. 3,885,935 : Cost 67.94227600 : Time 846.45s : 7242.02 words/s
[2019-07-17 17:35:24] Ep. 3 : Up. 192000 : Sen. 4,176,012 : Cost 67.65278625 : Time 846.30s : 7212.27 words/s
[2019-07-17 17:49:27] Ep. 3 : Up. 194000 : Sen. 4,465,426 : Cost 68.01559448 : Time 843.24s : 7249.75 words/s
[2019-07-17 18:03:32] Ep. 3 : Up. 196000 : Sen. 4,754,540 : Cost 68.01472473 : Time 844.48s : 7237.85 words/s
[2019-07-17 18:17:34] Ep. 3 : Up. 198000 : Sen. 5,043,665 : Cost 67.88052368 : Time 842.49s : 7235.90 words/s
[2019-07-17 18:31:34] Ep. 3 : Up. 200000 : Sen. 5,333,001 : Cost 67.67360687 : Time 839.64s : 7265.09 words/s
[2019-07-17 18:31:34] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-17 18:31:43] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter200000.npz
[2019-07-17 18:31:50] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-17 18:31:59] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-17 18:32:25] [valid] Ep. 3 : Up. 200000 : cross-entropy : 54.8148 : new best
[2019-07-17 18:32:32] [valid] Ep. 3 : Up. 200000 : perplexity : 8.77577 : new best
[2019-07-17 18:33:42] [valid] Ep. 3 : Up. 200000 : translation : 24.57 : new best
[2019-07-17 18:47:49] Ep. 3 : Up. 202000 : Sen. 5,622,517 : Cost 67.81035614 : Time 975.05s : 6275.40 words/s
[2019-07-17 19:01:56] Ep. 3 : Up. 204000 : Sen. 5,911,741 : Cost 68.02012634 : Time 846.66s : 7240.94 words/s
[2019-07-17 19:15:58] Ep. 3 : Up. 206000 : Sen. 6,201,043 : Cost 67.61312866 : Time 842.45s : 7243.79 words/s
[2019-07-17 19:30:03] Ep. 3 : Up. 208000 : Sen. 6,491,049 : Cost 67.53726959 : Time 845.40s : 7235.25 words/s
[2019-07-17 19:44:09] Ep. 3 : Up. 210000 : Sen. 6,780,647 : Cost 67.64810944 : Time 845.53s : 7236.91 words/s
[2019-07-17 19:58:16] Ep. 3 : Up. 212000 : Sen. 7,070,616 : Cost 67.68246460 : Time 846.67s : 7232.89 words/s
[2019-07-17 20:12:22] Ep. 3 : Up. 214000 : Sen. 7,359,944 : Cost 67.64479065 : Time 846.24s : 7220.84 words/s
[2019-07-17 20:26:23] Ep. 3 : Up. 216000 : Sen. 7,648,668 : Cost 67.31478882 : Time 841.04s : 7239.13 words/s
[2019-07-17 20:40:30] Ep. 3 : Up. 218000 : Sen. 7,938,192 : Cost 67.65277100 : Time 846.72s : 7222.55 words/s
[2019-07-17 20:54:37] Ep. 3 : Up. 220000 : Sen. 8,228,029 : Cost 67.59249878 : Time 847.31s : 7226.57 words/s
[2019-07-17 20:54:37] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-17 20:54:47] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter220000.npz
[2019-07-17 20:54:54] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-17 20:55:04] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-17 20:55:29] [valid] Ep. 3 : Up. 220000 : cross-entropy : 54.3106 : new best
[2019-07-17 20:55:37] [valid] Ep. 3 : Up. 220000 : perplexity : 8.60219 : new best
[2019-07-17 20:56:47] [valid] Ep. 3 : Up. 220000 : translation : 24.74 : new best
[2019-07-17 21:10:48] Ep. 3 : Up. 222000 : Sen. 8,516,890 : Cost 67.08221436 : Time 971.22s : 6267.45 words/s
[2019-07-17 21:24:56] Ep. 3 : Up. 224000 : Sen. 8,806,400 : Cost 67.45167542 : Time 847.85s : 7215.54 words/s
[2019-07-17 21:39:01] Ep. 3 : Up. 226000 : Sen. 9,096,121 : Cost 67.19412994 : Time 844.65s : 7234.65 words/s
[2019-07-17 21:53:02] Ep. 3 : Up. 228000 : Sen. 9,384,116 : Cost 67.36512756 : Time 841.11s : 7235.39 words/s
[2019-07-17 22:07:09] Ep. 3 : Up. 230000 : Sen. 9,673,978 : Cost 67.37593079 : Time 847.42s : 7230.07 words/s
[2019-07-17 22:21:13] Ep. 3 : Up. 232000 : Sen. 9,964,056 : Cost 67.06817627 : Time 844.18s : 7244.57 words/s
[2019-07-17 22:35:15] Ep. 3 : Up. 234000 : Sen. 10,253,030 : Cost 67.15351105 : Time 841.93s : 7243.58 words/s
[2019-07-17 22:49:23] Ep. 3 : Up. 236000 : Sen. 10,542,520 : Cost 67.02990723 : Time 847.29s : 7211.51 words/s
[2019-07-17 23:03:27] Ep. 3 : Up. 238000 : Sen. 10,831,459 : Cost 67.05042267 : Time 844.74s : 7233.67 words/s
[2019-07-17 23:17:32] Ep. 3 : Up. 240000 : Sen. 11,120,248 : Cost 67.15318298 : Time 844.19s : 7230.53 words/s
[2019-07-17 23:17:32] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-17 23:17:41] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter240000.npz
[2019-07-17 23:17:48] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-17 23:17:57] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-17 23:18:30] [valid] Ep. 3 : Up. 240000 : cross-entropy : 53.7551 : new best
[2019-07-17 23:18:38] [valid] Ep. 3 : Up. 240000 : perplexity : 8.4149 : new best
[2019-07-17 23:19:50] [valid] Ep. 3 : Up. 240000 : translation : 24.84 : new best
[2019-07-17 23:33:55] Ep. 3 : Up. 242000 : Sen. 11,408,321 : Cost 67.27829742 : Time 983.62s : 6197.63 words/s
[2019-07-17 23:47:54] Ep. 3 : Up. 244000 : Sen. 11,696,511 : Cost 66.84992981 : Time 838.93s : 7238.61 words/s
[2019-07-17 23:52:44] Seen 11795613 samples
[2019-07-17 23:52:44] Starting epoch 4
[2019-07-17 23:52:44] [data] Shuffling data
[2019-07-17 23:52:55] [data] Done reading 13926791 sentences
[2019-07-17 23:54:02] [data] Done shuffling 13926791 sentences to temp files
[2019-07-18 00:03:16] Ep. 4 : Up. 246000 : Sen. 189,189 : Cost 66.19489288 : Time 922.22s : 6595.12 words/s
[2019-07-18 00:17:22] Ep. 4 : Up. 248000 : Sen. 478,639 : Cost 66.15205383 : Time 845.70s : 7230.95 words/s
[2019-07-18 00:31:25] Ep. 4 : Up. 250000 : Sen. 768,174 : Cost 66.06209564 : Time 843.34s : 7239.86 words/s
[2019-07-18 00:45:31] Ep. 4 : Up. 252000 : Sen. 1,057,366 : Cost 66.11219025 : Time 845.83s : 7216.56 words/s
[2019-07-18 00:59:38] Ep. 4 : Up. 254000 : Sen. 1,346,823 : Cost 66.25604248 : Time 847.09s : 7229.19 words/s
[2019-07-18 01:13:43] Ep. 4 : Up. 256000 : Sen. 1,636,228 : Cost 65.93502045 : Time 844.23s : 7222.92 words/s
[2019-07-18 01:27:49] Ep. 4 : Up. 258000 : Sen. 1,925,902 : Cost 66.22577667 : Time 846.92s : 7213.00 words/s
[2019-07-18 01:41:54] Ep. 4 : Up. 260000 : Sen. 2,215,059 : Cost 66.27350616 : Time 844.37s : 7235.36 words/s
[2019-07-18 01:41:54] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-18 01:42:05] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter260000.npz
[2019-07-18 01:42:12] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-18 01:42:21] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-18 01:42:46] [valid] Ep. 4 : Up. 260000 : cross-entropy : 53.4531 : new best
[2019-07-18 01:42:53] [valid] Ep. 4 : Up. 260000 : perplexity : 8.31482 : new best
[2019-07-18 01:44:04] [valid] Ep. 4 : Up. 260000 : translation : 24.78 : stalled 1 times (last best: 24.84)
[2019-07-18 01:58:07] Ep. 4 : Up. 262000 : Sen. 2,503,192 : Cost 66.22932434 : Time 973.68s : 6256.29 words/s
[2019-07-18 02:12:09] Ep. 4 : Up. 264000 : Sen. 2,792,376 : Cost 66.07970428 : Time 841.89s : 7248.54 words/s
[2019-07-18 02:26:11] Ep. 4 : Up. 266000 : Sen. 3,081,103 : Cost 66.19133759 : Time 842.00s : 7228.62 words/s
[2019-07-18 02:40:13] Ep. 4 : Up. 268000 : Sen. 3,369,956 : Cost 66.20831299 : Time 841.36s : 7243.35 words/s
[2019-07-18 02:54:17] Ep. 4 : Up. 270000 : Sen. 3,658,943 : Cost 66.22378540 : Time 843.85s : 7239.71 words/s
[2019-07-18 03:08:23] Ep. 4 : Up. 272000 : Sen. 3,948,925 : Cost 66.01498413 : Time 846.35s : 7241.55 words/s
[2019-07-18 03:22:26] Ep. 4 : Up. 274000 : Sen. 4,237,978 : Cost 66.06945801 : Time 842.96s : 7237.72 words/s
[2019-07-18 03:36:29] Ep. 4 : Up. 276000 : Sen. 4,527,010 : Cost 66.15314484 : Time 843.05s : 7243.35 words/s
[2019-07-18 03:50:31] Ep. 4 : Up. 278000 : Sen. 4,815,589 : Cost 65.94366455 : Time 841.91s : 7233.23 words/s
[2019-07-18 04:04:35] Ep. 4 : Up. 280000 : Sen. 5,104,940 : Cost 66.03813171 : Time 843.77s : 7233.01 words/s
[2019-07-18 04:04:35] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-18 04:04:44] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter280000.npz
[2019-07-18 04:04:51] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-18 04:05:00] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-18 04:05:25] [valid] Ep. 4 : Up. 280000 : cross-entropy : 53.1569 : new best
[2019-07-18 04:05:33] [valid] Ep. 4 : Up. 280000 : perplexity : 8.21779 : new best
[2019-07-18 04:06:43] [valid] Ep. 4 : Up. 280000 : translation : 24.75 : stalled 2 times (last best: 24.84)
[2019-07-18 04:20:49] Ep. 4 : Up. 282000 : Sen. 5,393,654 : Cost 66.03991699 : Time 974.77s : 6259.33 words/s
[2019-07-18 04:34:55] Ep. 4 : Up. 284000 : Sen. 5,683,374 : Cost 65.90821838 : Time 845.70s : 7235.18 words/s
[2019-07-18 04:48:59] Ep. 4 : Up. 286000 : Sen. 5,972,520 : Cost 66.09349823 : Time 844.12s : 7232.92 words/s
[2019-07-18 05:03:06] Ep. 4 : Up. 288000 : Sen. 6,262,280 : Cost 66.11801910 : Time 846.71s : 7238.04 words/s
[2019-07-18 05:17:08] Ep. 4 : Up. 290000 : Sen. 6,550,951 : Cost 65.87449646 : Time 841.82s : 7226.70 words/s
[2019-07-18 05:31:14] Ep. 4 : Up. 292000 : Sen. 6,840,841 : Cost 65.69998932 : Time 846.54s : 7228.55 words/s
[2019-07-18 05:45:19] Ep. 4 : Up. 294000 : Sen. 7,130,204 : Cost 66.01026917 : Time 845.12s : 7235.60 words/s
[2019-07-18 05:59:28] Ep. 4 : Up. 296000 : Sen. 7,420,476 : Cost 66.04504395 : Time 848.36s : 7244.15 words/s
[2019-07-18 06:13:32] Ep. 4 : Up. 298000 : Sen. 7,709,831 : Cost 65.83609772 : Time 844.67s : 7236.54 words/s
[2019-07-18 06:27:37] Ep. 4 : Up. 300000 : Sen. 7,999,638 : Cost 65.97133636 : Time 844.67s : 7247.00 words/s
[2019-07-18 06:27:37] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-18 06:27:47] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter300000.npz
[2019-07-18 06:27:54] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-18 06:28:05] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-18 06:28:30] [valid] Ep. 4 : Up. 300000 : cross-entropy : 52.8115 : new best
[2019-07-18 06:28:37] [valid] Ep. 4 : Up. 300000 : perplexity : 8.1061 : new best
[2019-07-18 06:29:47] [valid] Ep. 4 : Up. 300000 : translation : 25.02 : new best
[2019-07-18 06:43:52] Ep. 4 : Up. 302000 : Sen. 8,289,370 : Cost 65.73223877 : Time 974.50s : 6261.22 words/s
[2019-07-18 06:57:56] Ep. 4 : Up. 304000 : Sen. 8,577,723 : Cost 66.01861572 : Time 844.57s : 7230.02 words/s
[2019-07-18 07:12:02] Ep. 4 : Up. 306000 : Sen. 8,867,871 : Cost 65.87880707 : Time 845.74s : 7246.40 words/s
[2019-07-18 07:26:05] Ep. 4 : Up. 308000 : Sen. 9,157,476 : Cost 65.74268341 : Time 842.65s : 7255.98 words/s
[2019-07-18 07:40:07] Ep. 4 : Up. 310000 : Sen. 9,446,824 : Cost 65.62076569 : Time 842.59s : 7244.84 words/s
[2019-07-18 07:54:13] Ep. 4 : Up. 312000 : Sen. 9,735,647 : Cost 65.69314575 : Time 845.47s : 7216.04 words/s
[2019-07-18 08:08:16] Ep. 4 : Up. 314000 : Sen. 10,024,736 : Cost 65.83767700 : Time 843.39s : 7233.85 words/s
[2019-07-18 08:22:19] Ep. 4 : Up. 316000 : Sen. 10,315,093 : Cost 65.72866058 : Time 842.64s : 7263.70 words/s
[2019-07-18 08:36:24] Ep. 4 : Up. 318000 : Sen. 10,605,562 : Cost 65.62871552 : Time 845.82s : 7241.96 words/s
[2019-07-18 08:50:25] Ep. 4 : Up. 320000 : Sen. 10,893,654 : Cost 65.48962402 : Time 840.24s : 7244.05 words/s
[2019-07-18 08:50:25] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-18 08:50:37] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter320000.npz
[2019-07-18 08:50:43] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-18 08:50:53] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-18 08:51:21] [valid] Ep. 4 : Up. 320000 : cross-entropy : 52.5442 : new best
[2019-07-18 08:51:29] [valid] Ep. 4 : Up. 320000 : perplexity : 8.02069 : new best
[2019-07-18 08:52:39] [valid] Ep. 4 : Up. 320000 : translation : 24.83 : stalled 1 times (last best: 25.02)
[2019-07-18 09:06:47] Ep. 4 : Up. 322000 : Sen. 11,182,024 : Cost 66.03944397 : Time 982.43s : 6221.67 words/s
[2019-07-18 09:20:54] Ep. 4 : Up. 324000 : Sen. 11,472,491 : Cost 65.60808563 : Time 846.61s : 7239.40 words/s
[2019-07-18 09:34:59] Ep. 4 : Up. 326000 : Sen. 11,761,825 : Cost 65.55074310 : Time 845.04s : 7235.86 words/s
[2019-07-18 09:36:38] Seen 11795613 samples
[2019-07-18 09:36:38] Starting epoch 5
[2019-07-18 09:36:38] [data] Shuffling data
[2019-07-18 09:36:52] [data] Done reading 13926791 sentences
[2019-07-18 09:38:10] [data] Done shuffling 13926791 sentences to temp files
[2019-07-18 09:50:40] Ep. 5 : Up. 328000 : Sen. 255,364 : Cost 65.00905609 : Time 940.74s : 6494.57 words/s
[2019-07-18 10:04:44] Ep. 5 : Up. 330000 : Sen. 544,459 : Cost 64.90835571 : Time 844.24s : 7223.18 words/s
[2019-07-18 10:18:49] Ep. 5 : Up. 332000 : Sen. 833,589 : Cost 64.93974304 : Time 845.21s : 7224.08 words/s
[2019-07-18 10:32:58] Ep. 5 : Up. 334000 : Sen. 1,122,341 : Cost 65.16365814 : Time 849.42s : 7198.94 words/s
[2019-07-18 10:47:04] Ep. 5 : Up. 336000 : Sen. 1,412,078 : Cost 64.53629303 : Time 845.24s : 7215.31 words/s
[2019-07-18 11:01:09] Ep. 5 : Up. 338000 : Sen. 1,700,863 : Cost 64.77616882 : Time 845.14s : 7212.18 words/s
[2019-07-18 11:15:09] Ep. 5 : Up. 340000 : Sen. 1,989,476 : Cost 65.06165314 : Time 840.71s : 7248.71 words/s
[2019-07-18 11:15:09] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-18 11:15:19] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter340000.npz
[2019-07-18 11:15:27] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-18 11:15:38] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-18 11:16:04] [valid] Ep. 5 : Up. 340000 : cross-entropy : 52.3587 : new best
[2019-07-18 11:16:12] [valid] Ep. 5 : Up. 340000 : perplexity : 7.96193 : new best
[2019-07-18 11:17:24] [valid] Ep. 5 : Up. 340000 : translation : 24.8 : stalled 2 times (last best: 25.02)
[2019-07-18 11:31:32] Ep. 5 : Up. 342000 : Sen. 2,279,456 : Cost 64.89620209 : Time 982.06s : 6234.33 words/s
[2019-07-18 11:45:34] Ep. 5 : Up. 344000 : Sen. 2,567,728 : Cost 64.85998535 : Time 842.32s : 7225.19 words/s
[2019-07-18 11:59:38] Ep. 5 : Up. 346000 : Sen. 2,857,460 : Cost 64.80175018 : Time 844.40s : 7241.83 words/s
[2019-07-18 12:13:46] Ep. 5 : Up. 348000 : Sen. 3,148,008 : Cost 65.03247833 : Time 847.50s : 7235.65 words/s
[2019-07-18 12:27:50] Ep. 5 : Up. 350000 : Sen. 3,436,781 : Cost 64.91703796 : Time 843.79s : 7227.22 words/s
[2019-07-18 12:41:53] Ep. 5 : Up. 352000 : Sen. 3,725,822 : Cost 64.90852356 : Time 843.38s : 7240.11 words/s
[2019-07-18 12:55:54] Ep. 5 : Up. 354000 : Sen. 4,015,114 : Cost 64.75140381 : Time 841.54s : 7251.51 words/s
[2019-07-18 13:10:01] Ep. 5 : Up. 356000 : Sen. 4,304,691 : Cost 65.16485596 : Time 846.61s : 7239.35 words/s
[2019-07-18 13:24:06] Ep. 5 : Up. 358000 : Sen. 4,593,914 : Cost 64.99468231 : Time 845.23s : 7221.75 words/s
[2019-07-18 13:38:09] Ep. 5 : Up. 360000 : Sen. 4,883,649 : Cost 64.81009674 : Time 842.32s : 7261.61 words/s
[2019-07-18 13:38:09] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-18 13:38:20] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter360000.npz
[2019-07-18 13:38:27] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-18 13:38:40] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-18 13:39:04] [valid] Ep. 5 : Up. 360000 : cross-entropy : 52.2688 : new best
[2019-07-18 13:39:12] [valid] Ep. 5 : Up. 360000 : perplexity : 7.93363 : new best
[2019-07-18 13:40:23] [valid] Ep. 5 : Up. 360000 : translation : 24.92 : stalled 3 times (last best: 25.02)
[2019-07-18 13:54:28] Ep. 5 : Up. 362000 : Sen. 5,173,057 : Cost 64.79273224 : Time 979.66s : 6235.14 words/s
[2019-07-18 14:08:31] Ep. 5 : Up. 364000 : Sen. 5,461,241 : Cost 65.01854706 : Time 842.76s : 7238.64 words/s
[2019-07-18 14:22:32] Ep. 5 : Up. 366000 : Sen. 5,750,264 : Cost 64.60010529 : Time 840.82s : 7229.62 words/s
[2019-07-18 14:36:34] Ep. 5 : Up. 368000 : Sen. 6,039,178 : Cost 65.02346039 : Time 841.71s : 7261.92 words/s
[2019-07-18 14:50:37] Ep. 5 : Up. 370000 : Sen. 6,328,756 : Cost 64.83670807 : Time 843.55s : 7230.92 words/s
[2019-07-18 15:04:41] Ep. 5 : Up. 372000 : Sen. 6,618,490 : Cost 64.92474365 : Time 844.12s : 7252.99 words/s
[2019-07-18 15:18:44] Ep. 5 : Up. 374000 : Sen. 6,907,448 : Cost 64.91904449 : Time 842.96s : 7244.24 words/s
[2019-07-18 15:32:47] Ep. 5 : Up. 376000 : Sen. 7,197,011 : Cost 64.98454285 : Time 842.48s : 7262.27 words/s
[2019-07-18 15:46:50] Ep. 5 : Up. 378000 : Sen. 7,487,117 : Cost 64.80984497 : Time 843.28s : 7258.60 words/s
[2019-07-18 16:00:52] Ep. 5 : Up. 380000 : Sen. 7,776,635 : Cost 64.98814392 : Time 841.76s : 7257.28 words/s
[2019-07-18 16:00:52] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-18 16:01:01] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter380000.npz
[2019-07-18 16:01:08] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-18 16:01:17] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-18 16:01:41] [valid] Ep. 5 : Up. 380000 : cross-entropy : 52.0048 : new best
[2019-07-18 16:01:49] [valid] Ep. 5 : Up. 380000 : perplexity : 7.85108 : new best
[2019-07-18 16:02:58] [valid] Ep. 5 : Up. 380000 : translation : 24.9 : stalled 4 times (last best: 25.02)
[2019-07-18 16:17:03] Ep. 5 : Up. 382000 : Sen. 8,065,413 : Cost 64.79661560 : Time 971.45s : 6282.72 words/s
[2019-07-18 16:31:08] Ep. 5 : Up. 384000 : Sen. 8,355,094 : Cost 65.04931641 : Time 844.44s : 7242.82 words/s
[2019-07-18 16:45:12] Ep. 5 : Up. 386000 : Sen. 8,644,349 : Cost 64.81024170 : Time 844.78s : 7229.45 words/s
[2019-07-18 16:59:20] Ep. 5 : Up. 388000 : Sen. 8,934,400 : Cost 64.81725311 : Time 847.42s : 7223.62 words/s
[2019-07-18 17:13:21] Ep. 5 : Up. 390000 : Sen. 9,222,532 : Cost 64.66014099 : Time 840.90s : 7224.46 words/s
[2019-07-18 17:27:29] Ep. 5 : Up. 392000 : Sen. 9,512,468 : Cost 64.90663910 : Time 847.87s : 7228.87 words/s
[2019-07-18 17:41:37] Ep. 5 : Up. 394000 : Sen. 9,802,223 : Cost 64.97053528 : Time 847.89s : 7216.32 words/s
[2019-07-18 17:55:43] Ep. 5 : Up. 396000 : Sen. 10,090,913 : Cost 64.94821167 : Time 846.54s : 7214.34 words/s
[2019-07-18 18:09:47] Ep. 5 : Up. 398000 : Sen. 10,379,680 : Cost 64.84474945 : Time 844.27s : 7231.59 words/s
[2019-07-18 18:23:54] Ep. 5 : Up. 400000 : Sen. 10,670,175 : Cost 64.85834503 : Time 846.24s : 7256.44 words/s
[2019-07-18 18:23:54] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-18 18:24:03] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter400000.npz
[2019-07-18 18:24:10] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-18 18:24:20] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-18 18:24:46] [valid] Ep. 5 : Up. 400000 : cross-entropy : 51.7806 : new best
[2019-07-18 18:24:53] [valid] Ep. 5 : Up. 400000 : perplexity : 7.78163 : new best
[2019-07-18 18:26:04] [valid] Ep. 5 : Up. 400000 : translation : 24.97 : stalled 5 times (last best: 25.02)
[2019-07-18 18:40:10] Ep. 5 : Up. 402000 : Sen. 10,960,151 : Cost 64.71835327 : Time 976.54s : 6268.20 words/s
[2019-07-18 18:54:17] Ep. 5 : Up. 404000 : Sen. 11,249,606 : Cost 64.72649384 : Time 846.56s : 7225.78 words/s
[2019-07-18 19:08:23] Ep. 5 : Up. 406000 : Sen. 11,539,200 : Cost 64.61819458 : Time 846.11s : 7227.94 words/s
[2019-07-18 19:20:52] Seen 11795613 samples
[2019-07-18 19:20:52] Starting epoch 6
[2019-07-18 19:20:52] [data] Shuffling data
[2019-07-18 19:22:01] [data] Done reading 13926791 sentences
[2019-07-18 19:23:20] [data] Done shuffling 13926791 sentences to temp files
[2019-07-18 19:25:00] Ep. 6 : Up. 408000 : Sen. 33,204 : Cost 64.60903168 : Time 996.95s : 6133.89 words/s
[2019-07-18 19:39:00] Ep. 6 : Up. 410000 : Sen. 322,713 : Cost 63.92963791 : Time 840.23s : 7270.97 words/s
[2019-07-18 19:52:59] Ep. 6 : Up. 412000 : Sen. 611,564 : Cost 63.98331451 : Time 838.81s : 7269.06 words/s
[2019-07-18 20:06:56] Ep. 6 : Up. 414000 : Sen. 900,328 : Cost 63.80973434 : Time 836.96s : 7284.24 words/s
[2019-07-18 20:20:59] Ep. 6 : Up. 416000 : Sen. 1,189,582 : Cost 64.21013641 : Time 842.93s : 7258.71 words/s
[2019-07-18 20:34:59] Ep. 6 : Up. 418000 : Sen. 1,479,772 : Cost 63.91586304 : Time 840.46s : 7286.04 words/s
[2019-07-18 20:48:58] Ep. 6 : Up. 420000 : Sen. 1,768,239 : Cost 64.21704865 : Time 838.44s : 7275.61 words/s
[2019-07-18 20:48:58] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-18 20:49:07] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter420000.npz
[2019-07-18 20:49:14] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-18 20:49:24] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-18 20:49:49] [valid] Ep. 6 : Up. 420000 : cross-entropy : 51.6747 : new best
[2019-07-18 20:49:57] [valid] Ep. 6 : Up. 420000 : perplexity : 7.74906 : new best
[2019-07-18 20:51:09] [valid] Ep. 6 : Up. 420000 : translation : 24.65 : stalled 6 times (last best: 25.02)
[2019-07-18 21:05:10] Ep. 6 : Up. 422000 : Sen. 2,056,303 : Cost 64.02402496 : Time 972.04s : 6265.60 words/s
[2019-07-18 21:19:08] Ep. 6 : Up. 424000 : Sen. 2,344,636 : Cost 64.08485413 : Time 838.42s : 7275.89 words/s
[2019-07-18 21:33:03] Ep. 6 : Up. 426000 : Sen. 2,633,408 : Cost 63.88907623 : Time 835.44s : 7289.94 words/s
[2019-07-18 21:47:01] Ep. 6 : Up. 428000 : Sen. 2,921,666 : Cost 64.21644592 : Time 837.23s : 7281.77 words/s
[2019-07-18 22:00:58] Ep. 6 : Up. 430000 : Sen. 3,210,512 : Cost 64.28911591 : Time 837.68s : 7290.68 words/s
[2019-07-18 22:14:56] Ep. 6 : Up. 432000 : Sen. 3,499,876 : Cost 64.15403748 : Time 837.84s : 7294.14 words/s
[2019-07-18 22:28:54] Ep. 6 : Up. 434000 : Sen. 3,788,800 : Cost 64.11833191 : Time 837.85s : 7287.37 words/s
[2019-07-18 22:42:54] Ep. 6 : Up. 436000 : Sen. 4,078,375 : Cost 64.24578094 : Time 839.63s : 7292.68 words/s
[2019-07-18 22:56:52] Ep. 6 : Up. 438000 : Sen. 4,368,135 : Cost 64.09357452 : Time 838.24s : 7291.05 words/s
[2019-07-18 23:10:50] Ep. 6 : Up. 440000 : Sen. 4,656,715 : Cost 64.30609131 : Time 838.20s : 7269.51 words/s
[2019-07-18 23:10:50] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-18 23:11:01] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter440000.npz
[2019-07-18 23:11:08] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-18 23:11:21] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-18 23:11:47] [valid] Ep. 6 : Up. 440000 : cross-entropy : 51.7563 : stalled 1 times (last best: 51.6747)
[2019-07-18 23:11:54] [valid] Ep. 6 : Up. 440000 : perplexity : 7.77415 : stalled 1 times (last best: 7.74906)
[2019-07-18 23:13:05] [valid] Ep. 6 : Up. 440000 : translation : 24.68 : stalled 7 times (last best: 25.02)
[2019-07-18 23:27:04] Ep. 6 : Up. 442000 : Sen. 4,946,720 : Cost 64.18115234 : Time 974.04s : 6288.97 words/s
[2019-07-18 23:40:58] Ep. 6 : Up. 444000 : Sen. 5,234,762 : Cost 64.09699249 : Time 834.03s : 7298.71 words/s
[2019-07-18 23:54:55] Ep. 6 : Up. 446000 : Sen. 5,524,458 : Cost 63.85717392 : Time 836.37s : 7299.55 words/s
[2019-07-19 00:08:54] Ep. 6 : Up. 448000 : Sen. 5,813,484 : Cost 64.14825439 : Time 838.90s : 7280.62 words/s
[2019-07-19 00:22:52] Ep. 6 : Up. 450000 : Sen. 6,103,015 : Cost 64.04795074 : Time 838.01s : 7288.44 words/s
[2019-07-19 00:36:52] Ep. 6 : Up. 452000 : Sen. 6,392,549 : Cost 64.24717712 : Time 840.07s : 7290.55 words/s
[2019-07-19 00:50:53] Ep. 6 : Up. 454000 : Sen. 6,682,337 : Cost 64.05186462 : Time 841.61s : 7274.09 words/s
[2019-07-19 01:04:52] Ep. 6 : Up. 456000 : Sen. 6,971,282 : Cost 64.20928192 : Time 838.95s : 7275.92 words/s
[2019-07-19 01:18:53] Ep. 6 : Up. 458000 : Sen. 7,261,522 : Cost 63.71787643 : Time 840.49s : 7278.42 words/s
[2019-07-19 01:32:54] Ep. 6 : Up. 460000 : Sen. 7,552,000 : Cost 64.17250824 : Time 841.82s : 7285.11 words/s
[2019-07-19 01:32:54] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-19 01:33:03] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter460000.npz
[2019-07-19 01:33:10] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-19 01:33:20] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-19 01:33:45] [valid] Ep. 6 : Up. 460000 : cross-entropy : 51.481 : new best
[2019-07-19 01:33:53] [valid] Ep. 6 : Up. 460000 : perplexity : 7.68981 : new best
[2019-07-19 01:35:04] [valid] Ep. 6 : Up. 460000 : translation : 24.64 : stalled 8 times (last best: 25.02)
[2019-07-19 01:49:04] Ep. 6 : Up. 462000 : Sen. 7,840,702 : Cost 64.11908722 : Time 969.31s : 6294.26 words/s
[2019-07-19 02:03:02] Ep. 6 : Up. 464000 : Sen. 8,130,054 : Cost 64.13515472 : Time 837.98s : 7287.46 words/s
[2019-07-19 02:17:02] Ep. 6 : Up. 466000 : Sen. 8,420,070 : Cost 63.87668228 : Time 839.72s : 7276.68 words/s
[2019-07-19 02:30:57] Ep. 6 : Up. 468000 : Sen. 8,709,070 : Cost 64.08232880 : Time 835.95s : 7287.95 words/s
[2019-07-19 02:44:56] Ep. 6 : Up. 470000 : Sen. 8,998,664 : Cost 64.22959137 : Time 838.15s : 7303.88 words/s
[2019-07-19 02:58:54] Ep. 6 : Up. 472000 : Sen. 9,287,858 : Cost 64.06529236 : Time 837.92s : 7283.18 words/s
[2019-07-19 03:12:56] Ep. 6 : Up. 474000 : Sen. 9,578,644 : Cost 64.04608154 : Time 842.23s : 7289.78 words/s
[2019-07-19 03:26:55] Ep. 6 : Up. 476000 : Sen. 9,868,025 : Cost 64.01714325 : Time 838.72s : 7286.23 words/s
[2019-07-19 03:40:55] Ep. 6 : Up. 478000 : Sen. 10,157,592 : Cost 64.27284241 : Time 840.07s : 7287.04 words/s
[2019-07-19 03:54:53] Ep. 6 : Up. 480000 : Sen. 10,448,091 : Cost 63.99407196 : Time 838.16s : 7313.06 words/s
[2019-07-19 03:54:53] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-19 03:55:02] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter480000.npz
[2019-07-19 03:55:09] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-19 03:55:20] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-19 03:55:49] [valid] Ep. 6 : Up. 480000 : cross-entropy : 51.3542 : new best
[2019-07-19 03:55:57] [valid] Ep. 6 : Up. 480000 : perplexity : 7.65125 : new best
[2019-07-19 03:57:07] [valid] Ep. 6 : Up. 480000 : translation : 24.93 : stalled 9 times (last best: 25.02)
[2019-07-19 04:11:06] Ep. 6 : Up. 482000 : Sen. 10,737,740 : Cost 63.84084320 : Time 973.26s : 6276.12 words/s
[2019-07-19 04:25:05] Ep. 6 : Up. 484000 : Sen. 11,027,464 : Cost 63.91872787 : Time 839.24s : 7287.21 words/s
[2019-07-19 04:39:04] Ep. 6 : Up. 486000 : Sen. 11,317,148 : Cost 64.00527191 : Time 838.82s : 7285.73 words/s
[2019-07-19 04:52:59] Ep. 6 : Up. 488000 : Sen. 11,606,164 : Cost 63.88766098 : Time 835.30s : 7313.36 words/s
[2019-07-19 05:02:05] Seen 11795613 samples
[2019-07-19 05:02:05] Starting epoch 7
[2019-07-19 05:02:05] [data] Shuffling data
[2019-07-19 05:02:45] [data] Done reading 13926791 sentences
[2019-07-19 05:03:47] [data] Done shuffling 13926791 sentences to temp files
[2019-07-19 05:08:39] Ep. 7 : Up. 490000 : Sen. 99,405 : Cost 63.57770538 : Time 939.72s : 6489.59 words/s
[2019-07-19 05:22:33] Ep. 7 : Up. 492000 : Sen. 388,262 : Cost 63.47503281 : Time 833.82s : 7327.60 words/s
[2019-07-19 05:36:27] Ep. 7 : Up. 494000 : Sen. 677,658 : Cost 63.12004471 : Time 834.00s : 7321.21 words/s
[2019-07-19 05:50:23] Ep. 7 : Up. 496000 : Sen. 968,233 : Cost 63.37414551 : Time 835.63s : 7340.35 words/s
[2019-07-19 06:04:12] Ep. 7 : Up. 498000 : Sen. 1,257,299 : Cost 63.30027008 : Time 829.46s : 7344.95 words/s
[2019-07-19 06:18:09] Ep. 7 : Up. 500000 : Sen. 1,547,691 : Cost 63.42808151 : Time 836.60s : 7339.60 words/s
[2019-07-19 06:18:09] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-19 06:18:18] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter500000.npz
[2019-07-19 06:18:25] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-19 06:18:35] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-19 06:18:59] [valid] Ep. 7 : Up. 500000 : cross-entropy : 51.3606 : stalled 1 times (last best: 51.3542)
[2019-07-19 06:19:06] [valid] Ep. 7 : Up. 500000 : perplexity : 7.6532 : stalled 1 times (last best: 7.65125)
[2019-07-19 06:20:14] [valid] Ep. 7 : Up. 500000 : translation : 24.99 : stalled 10 times (last best: 25.02)
[2019-07-19 06:34:11] Ep. 7 : Up. 502000 : Sen. 1,837,198 : Cost 63.48490906 : Time 962.23s : 6357.13 words/s
[2019-07-19 06:48:07] Ep. 7 : Up. 504000 : Sen. 2,127,060 : Cost 63.11587524 : Time 835.82s : 7317.62 words/s
[2019-07-19 07:02:00] Ep. 7 : Up. 506000 : Sen. 2,415,980 : Cost 63.26626205 : Time 833.70s : 7313.42 words/s
[2019-07-19 07:15:51] Ep. 7 : Up. 508000 : Sen. 2,704,495 : Cost 63.44971848 : Time 830.52s : 7336.84 words/s
[2019-07-19 07:29:45] Ep. 7 : Up. 510000 : Sen. 2,993,898 : Cost 63.51971436 : Time 833.88s : 7340.65 words/s
[2019-07-19 07:43:38] Ep. 7 : Up. 512000 : Sen. 3,283,694 : Cost 63.62059402 : Time 833.33s : 7337.61 words/s
[2019-07-19 07:57:33] Ep. 7 : Up. 514000 : Sen. 3,573,935 : Cost 63.45909882 : Time 835.23s : 7331.80 words/s
[2019-07-19 08:11:26] Ep. 7 : Up. 516000 : Sen. 3,863,345 : Cost 63.52099228 : Time 832.58s : 7341.27 words/s
[2019-07-19 08:25:16] Ep. 7 : Up. 518000 : Sen. 4,151,443 : Cost 63.49753952 : Time 830.33s : 7326.87 words/s
[2019-07-19 08:39:11] Ep. 7 : Up. 520000 : Sen. 4,440,010 : Cost 63.50556183 : Time 834.63s : 7303.26 words/s
[2019-07-19 08:39:11] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-19 08:39:20] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter520000.npz
[2019-07-19 08:39:27] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-19 08:39:36] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-19 08:40:01] [valid] Ep. 7 : Up. 520000 : cross-entropy : 51.3307 : new best
[2019-07-19 08:40:08] [valid] Ep. 7 : Up. 520000 : perplexity : 7.64415 : new best
[2019-07-19 08:41:16] [valid] Ep. 7 : Up. 520000 : translation : 25.03 : new best
[2019-07-19 08:55:08] Ep. 7 : Up. 522000 : Sen. 4,730,128 : Cost 63.63104630 : Time 957.16s : 6407.67 words/s
[2019-07-19 09:09:00] Ep. 7 : Up. 524000 : Sen. 5,019,322 : Cost 63.24593353 : Time 831.60s : 7333.69 words/s
[2019-07-19 09:22:57] Ep. 7 : Up. 526000 : Sen. 5,308,847 : Cost 63.60988617 : Time 837.34s : 7309.05 words/s
[2019-07-19 09:36:48] Ep. 7 : Up. 528000 : Sen. 5,598,412 : Cost 63.56426239 : Time 830.87s : 7364.14 words/s
[2019-07-19 09:50:37] Ep. 7 : Up. 530000 : Sen. 5,888,264 : Cost 63.29253006 : Time 829.23s : 7355.86 words/s
[2019-07-19 10:04:27] Ep. 7 : Up. 532000 : Sen. 6,178,286 : Cost 63.26012421 : Time 830.00s : 7377.49 words/s
[2019-07-19 10:18:03] Ep. 7 : Up. 534000 : Sen. 6,467,319 : Cost 63.62259674 : Time 815.47s : 7485.89 words/s
[2019-07-19 10:31:39] Ep. 7 : Up. 536000 : Sen. 6,756,841 : Cost 63.60266876 : Time 816.37s : 7483.50 words/s
[2019-07-19 10:45:15] Ep. 7 : Up. 538000 : Sen. 7,046,532 : Cost 63.77859879 : Time 815.86s : 7498.89 words/s
[2019-07-19 10:58:48] Ep. 7 : Up. 540000 : Sen. 7,334,664 : Cost 63.53153229 : Time 813.19s : 7488.24 words/s
[2019-07-19 10:58:48] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-19 10:58:57] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter540000.npz
[2019-07-19 10:59:04] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-19 10:59:14] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-19 10:59:41] [valid] Ep. 7 : Up. 540000 : cross-entropy : 51.1941 : new best
[2019-07-19 10:59:49] [valid] Ep. 7 : Up. 540000 : perplexity : 7.60288 : new best
[2019-07-19 11:00:55] [valid] Ep. 7 : Up. 540000 : translation : 25.01 : stalled 1 times (last best: 25.03)
[2019-07-19 11:14:37] Ep. 7 : Up. 542000 : Sen. 7,624,613 : Cost 63.51763153 : Time 949.09s : 6448.19 words/s
[2019-07-19 11:28:19] Ep. 7 : Up. 544000 : Sen. 7,913,597 : Cost 63.62768173 : Time 822.10s : 7440.28 words/s
[2019-07-19 11:42:06] Ep. 7 : Up. 546000 : Sen. 8,202,747 : Cost 63.43190002 : Time 826.60s : 7386.13 words/s
[2019-07-19 11:55:47] Ep. 7 : Up. 548000 : Sen. 8,493,328 : Cost 63.55808640 : Time 821.71s : 7461.77 words/s
[2019-07-19 12:09:22] Ep. 7 : Up. 550000 : Sen. 8,781,948 : Cost 63.27935028 : Time 814.61s : 7466.89 words/s
[2019-07-19 12:22:58] Ep. 7 : Up. 552000 : Sen. 9,071,773 : Cost 63.55307007 : Time 815.59s : 7504.31 words/s
[2019-07-19 12:36:32] Ep. 7 : Up. 554000 : Sen. 9,360,646 : Cost 63.58435822 : Time 814.00s : 7497.89 words/s
[2019-07-19 12:50:08] Ep. 7 : Up. 556000 : Sen. 9,649,309 : Cost 63.60386276 : Time 816.37s : 7476.29 words/s
[2019-07-19 13:03:43] Ep. 7 : Up. 558000 : Sen. 9,938,304 : Cost 63.64196777 : Time 815.36s : 7502.98 words/s
[2019-07-19 13:17:19] Ep. 7 : Up. 560000 : Sen. 10,227,536 : Cost 63.40035629 : Time 815.31s : 7474.27 words/s
[2019-07-19 13:17:19] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-19 13:17:28] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter560000.npz
[2019-07-19 13:17:35] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-19 13:17:45] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-19 13:18:09] [valid] Ep. 7 : Up. 560000 : cross-entropy : 50.9951 : new best
[2019-07-19 13:18:16] [valid] Ep. 7 : Up. 560000 : perplexity : 7.54316 : new best
[2019-07-19 13:19:23] [valid] Ep. 7 : Up. 560000 : translation : 24.88 : stalled 2 times (last best: 25.03)
[2019-07-19 13:33:01] Ep. 7 : Up. 562000 : Sen. 10,516,252 : Cost 63.42463684 : Time 941.95s : 6475.73 words/s
[2019-07-19 13:46:32] Ep. 7 : Up. 564000 : Sen. 10,805,899 : Cost 63.53633118 : Time 811.52s : 7533.21 words/s
[2019-07-19 14:00:08] Ep. 7 : Up. 566000 : Sen. 11,095,384 : Cost 63.51827621 : Time 815.43s : 7502.42 words/s
[2019-07-19 14:13:42] Ep. 7 : Up. 568000 : Sen. 11,384,625 : Cost 63.67980957 : Time 814.85s : 7498.04 words/s
[2019-07-19 14:27:16] Ep. 7 : Up. 570000 : Sen. 11,673,468 : Cost 63.52962112 : Time 813.18s : 7494.99 words/s
[2019-07-19 14:32:58] Seen 11795613 samples
[2019-07-19 14:32:58] Starting epoch 8
[2019-07-19 14:32:58] [data] Shuffling data
[2019-07-19 14:33:27] [data] Done reading 13926791 sentences
[2019-07-19 14:34:30] [data] Done shuffling 13926791 sentences to temp files
[2019-07-19 14:42:24] Ep. 8 : Up. 572000 : Sen. 167,171 : Cost 62.87957001 : Time 907.98s : 6718.47 words/s
[2019-07-19 14:46:19] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-19 14:46:19] [marian] Running on dagr as process 6222 with command line:
[2019-07-19 14:46:19] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz -T . --devices 0 1 2 3 --train-sets ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.de ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.en --vocabs ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.de.json ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.en.json --mini-batch-fit -w 5000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/dev.bpe.de ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/dev.out --valid-script-path ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/train.log --valid-log ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/valid.log
[2019-07-19 14:46:20] [config] after-batches: 0
[2019-07-19 14:46:20] [config] after-epochs: 0
[2019-07-19 14:46:20] [config] allow-unk: false
[2019-07-19 14:46:20] [config] beam-size: 12
[2019-07-19 14:46:20] [config] bert-class-symbol: "[CLS]"
[2019-07-19 14:46:20] [config] bert-mask-symbol: "[MASK]"
[2019-07-19 14:46:20] [config] bert-masking-fraction: 0.15
[2019-07-19 14:46:20] [config] bert-sep-symbol: "[SEP]"
[2019-07-19 14:46:20] [config] bert-train-type-embeddings: true
[2019-07-19 14:46:20] [config] bert-type-vocab-size: 2
[2019-07-19 14:46:20] [config] best-deep: false
[2019-07-19 14:46:20] [config] clip-gemm: 0
[2019-07-19 14:46:20] [config] clip-norm: 1
[2019-07-19 14:46:20] [config] cost-type: ce-mean
[2019-07-19 14:46:20] [config] cpu-threads: 0
[2019-07-19 14:46:20] [config] data-weighting: ""
[2019-07-19 14:46:20] [config] data-weighting-type: sentence
[2019-07-19 14:46:20] [config] dec-cell: gru
[2019-07-19 14:46:20] [config] dec-cell-base-depth: 2
[2019-07-19 14:46:20] [config] dec-cell-high-depth: 1
[2019-07-19 14:46:20] [config] dec-depth: 1
[2019-07-19 14:46:20] [config] devices:
[2019-07-19 14:46:20] [config]   - 0
[2019-07-19 14:46:20] [config]   - 1
[2019-07-19 14:46:20] [config]   - 2
[2019-07-19 14:46:20] [config]   - 3
[2019-07-19 14:46:20] [config] dim-emb: 512
[2019-07-19 14:46:20] [config] dim-rnn: 1024
[2019-07-19 14:46:20] [config] dim-vocabs:
[2019-07-19 14:46:20] [config]   - 50000
[2019-07-19 14:46:20] [config]   - 50000
[2019-07-19 14:46:20] [config] disp-first: 0
[2019-07-19 14:46:20] [config] disp-freq: 2000
[2019-07-19 14:46:20] [config] disp-label-counts: false
[2019-07-19 14:46:20] [config] dropout-rnn: 0.2
[2019-07-19 14:46:20] [config] dropout-src: 0.1
[2019-07-19 14:46:20] [config] dropout-trg: 0.1
[2019-07-19 14:46:20] [config] dump-config: ""
[2019-07-19 14:46:20] [config] early-stopping: 5
[2019-07-19 14:46:20] [config] embedding-fix-src: false
[2019-07-19 14:46:20] [config] embedding-fix-trg: false
[2019-07-19 14:46:20] [config] embedding-normalization: false
[2019-07-19 14:46:20] [config] embedding-vectors:
[2019-07-19 14:46:20] [config]   []
[2019-07-19 14:46:20] [config] enc-cell: gru
[2019-07-19 14:46:20] [config] enc-cell-depth: 1
[2019-07-19 14:46:20] [config] enc-depth: 1
[2019-07-19 14:46:20] [config] enc-type: bidirectional
[2019-07-19 14:46:20] [config] exponential-smoothing: 0.0001
[2019-07-19 14:46:20] [config] grad-dropping-momentum: 0
[2019-07-19 14:46:20] [config] grad-dropping-rate: 0
[2019-07-19 14:46:20] [config] grad-dropping-warmup: 100
[2019-07-19 14:46:20] [config] guided-alignment: none
[2019-07-19 14:46:20] [config] guided-alignment-cost: mse
[2019-07-19 14:46:20] [config] guided-alignment-weight: 0.1
[2019-07-19 14:46:20] [config] ignore-model-config: false
[2019-07-19 14:46:20] [config] input-types:
[2019-07-19 14:46:20] [config]   []
[2019-07-19 14:46:20] [config] interpolate-env-vars: false
[2019-07-19 14:46:20] [config] keep-best: false
[2019-07-19 14:46:20] [config] label-smoothing: 0
[2019-07-19 14:46:20] [config] layer-normalization: true
[2019-07-19 14:46:20] [config] learn-rate: 0.0001
[2019-07-19 14:46:20] [config] log: ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/train.log
[2019-07-19 14:46:20] [config] log-level: info
[2019-07-19 14:46:20] [config] log-time-zone: ""
[2019-07-19 14:46:20] [config] lr-decay: 0
[2019-07-19 14:46:20] [config] lr-decay-freq: 50000
[2019-07-19 14:46:20] [config] lr-decay-inv-sqrt:
[2019-07-19 14:46:20] [config]   - 0
[2019-07-19 14:46:20] [config] lr-decay-repeat-warmup: false
[2019-07-19 14:46:20] [config] lr-decay-reset-optimizer: false
[2019-07-19 14:46:20] [config] lr-decay-start:
[2019-07-19 14:46:20] [config]   - 10
[2019-07-19 14:46:20] [config]   - 1
[2019-07-19 14:46:20] [config] lr-decay-strategy: epoch+stalled
[2019-07-19 14:46:20] [config] lr-report: false
[2019-07-19 14:46:20] [config] lr-warmup: 0
[2019-07-19 14:46:20] [config] lr-warmup-at-reload: false
[2019-07-19 14:46:20] [config] lr-warmup-cycle: false
[2019-07-19 14:46:20] [config] lr-warmup-start-rate: 0
[2019-07-19 14:46:20] [config] max-length: 50
[2019-07-19 14:46:20] [config] max-length-crop: false
[2019-07-19 14:46:20] [config] max-length-factor: 3
[2019-07-19 14:46:20] [config] maxi-batch: 100
[2019-07-19 14:46:20] [config] maxi-batch-sort: trg
[2019-07-19 14:46:20] [config] mini-batch: 64
[2019-07-19 14:46:20] [config] mini-batch-fit: true
[2019-07-19 14:46:20] [config] mini-batch-fit-step: 10
[2019-07-19 14:46:20] [config] mini-batch-overstuff: 1
[2019-07-19 14:46:20] [config] mini-batch-track-lr: false
[2019-07-19 14:46:20] [config] mini-batch-understuff: 1
[2019-07-19 14:46:20] [config] mini-batch-warmup: 0
[2019-07-19 14:46:20] [config] mini-batch-words: 0
[2019-07-19 14:46:20] [config] mini-batch-words-ref: 0
[2019-07-19 14:46:20] [config] model: ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-19 14:46:20] [config] multi-loss-type: sum
[2019-07-19 14:46:20] [config] multi-node: false
[2019-07-19 14:46:20] [config] multi-node-overlap: true
[2019-07-19 14:46:20] [config] n-best: false
[2019-07-19 14:46:20] [config] no-nccl: false
[2019-07-19 14:46:20] [config] no-reload: false
[2019-07-19 14:46:20] [config] no-restore-corpus: false
[2019-07-19 14:46:20] [config] no-shuffle: false
[2019-07-19 14:46:20] [config] normalize: 1
[2019-07-19 14:46:20] [config] num-devices: 0
[2019-07-19 14:46:20] [config] optimizer: adam
[2019-07-19 14:46:20] [config] optimizer-delay: 1
[2019-07-19 14:46:20] [config] optimizer-params:
[2019-07-19 14:46:20] [config]   []
[2019-07-19 14:46:20] [config] overwrite: false
[2019-07-19 14:46:20] [config] pretrained-model: ""
[2019-07-19 14:46:20] [config] quiet: false
[2019-07-19 14:46:20] [config] quiet-translation: true
[2019-07-19 14:46:20] [config] relative-paths: false
[2019-07-19 14:46:20] [config] right-left: false
[2019-07-19 14:46:20] [config] save-freq: 20000
[2019-07-19 14:46:20] [config] seed: 1111
[2019-07-19 14:46:20] [config] shuffle-in-ram: false
[2019-07-19 14:46:20] [config] skip: false
[2019-07-19 14:46:20] [config] sqlite: ""
[2019-07-19 14:46:20] [config] sqlite-drop: false
[2019-07-19 14:46:20] [config] sync-sgd: true
[2019-07-19 14:46:20] [config] tempdir: .
[2019-07-19 14:46:20] [config] tied-embeddings: false
[2019-07-19 14:46:20] [config] tied-embeddings-all: false
[2019-07-19 14:46:20] [config] tied-embeddings-src: false
[2019-07-19 14:46:20] [config] train-sets:
[2019-07-19 14:46:20] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.de
[2019-07-19 14:46:20] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.en
[2019-07-19 14:46:20] [config] transformer-aan-activation: swish
[2019-07-19 14:46:20] [config] transformer-aan-depth: 2
[2019-07-19 14:46:20] [config] transformer-aan-nogate: false
[2019-07-19 14:46:20] [config] transformer-decoder-autoreg: self-attention
[2019-07-19 14:46:20] [config] transformer-dim-aan: 2048
[2019-07-19 14:46:20] [config] transformer-dim-ffn: 2048
[2019-07-19 14:46:20] [config] transformer-dropout: 0
[2019-07-19 14:46:20] [config] transformer-dropout-attention: 0
[2019-07-19 14:46:20] [config] transformer-dropout-ffn: 0
[2019-07-19 14:46:20] [config] transformer-ffn-activation: swish
[2019-07-19 14:46:20] [config] transformer-ffn-depth: 2
[2019-07-19 14:46:20] [config] transformer-guided-alignment-layer: last
[2019-07-19 14:46:20] [config] transformer-heads: 8
[2019-07-19 14:46:20] [config] transformer-no-projection: false
[2019-07-19 14:46:20] [config] transformer-postprocess: dan
[2019-07-19 14:46:20] [config] transformer-postprocess-emb: d
[2019-07-19 14:46:20] [config] transformer-preprocess: ""
[2019-07-19 14:46:20] [config] transformer-tied-layers:
[2019-07-19 14:46:20] [config]   []
[2019-07-19 14:46:20] [config] transformer-train-position-embeddings: false
[2019-07-19 14:46:20] [config] type: amun
[2019-07-19 14:46:20] [config] ulr: false
[2019-07-19 14:46:20] [config] ulr-dim-emb: 0
[2019-07-19 14:46:20] [config] ulr-dropout: 0
[2019-07-19 14:46:20] [config] ulr-keys-vectors: ""
[2019-07-19 14:46:20] [config] ulr-query-vectors: ""
[2019-07-19 14:46:20] [config] ulr-softmax-temperature: 1
[2019-07-19 14:46:20] [config] ulr-trainable-transformation: false
[2019-07-19 14:46:20] [config] valid-freq: 20000
[2019-07-19 14:46:20] [config] valid-log: ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/valid.log
[2019-07-19 14:46:20] [config] valid-max-length: 1000
[2019-07-19 14:46:20] [config] valid-metrics:
[2019-07-19 14:46:20] [config]   - cross-entropy
[2019-07-19 14:46:20] [config]   - perplexity
[2019-07-19 14:46:20] [config]   - translation
[2019-07-19 14:46:20] [config] valid-mini-batch: 8
[2019-07-19 14:46:20] [config] valid-script-path: ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/score-dev.sh
[2019-07-19 14:46:20] [config] valid-sets:
[2019-07-19 14:46:20] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/dev.bpe.de
[2019-07-19 14:46:20] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/dev.bpe.en
[2019-07-19 14:46:20] [config] valid-translation-output: ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/dev.out
[2019-07-19 14:46:20] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-19 14:46:20] [config] vocabs:
[2019-07-19 14:46:20] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.de.json
[2019-07-19 14:46:20] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.en.json
[2019-07-19 14:46:20] [config] word-penalty: 0
[2019-07-19 14:46:20] [config] workspace: 5000
[2019-07-19 14:46:20] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-19 14:46:20] Using synchronous training
[2019-07-19 14:46:20] [data] Loading vocabulary from JSON/Yaml file ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.de.json
[2019-07-19 14:46:20] [data] Using unused word id eos for 0
[2019-07-19 14:46:20] [data] Using unused word id UNK for 1
[2019-07-19 14:46:20] [data] Setting vocabulary size for input 0 to 50000
[2019-07-19 14:46:20] [data] Loading vocabulary from JSON/Yaml file ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.en.json
[2019-07-19 14:46:21] [data] Using unused word id eos for 0
[2019-07-19 14:46:21] [data] Using unused word id UNK for 1
[2019-07-19 14:46:21] [data] Setting vocabulary size for input 1 to 50000
[2019-07-19 14:46:21] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-19 14:46:21] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-19 14:46:22] [memory] Extending reserved space to 5120 MB (device gpu0)
[2019-07-19 14:46:23] [memory] Extending reserved space to 5120 MB (device gpu1)
[2019-07-19 14:46:24] [memory] Extending reserved space to 5120 MB (device gpu2)
[2019-07-19 14:46:25] [memory] Extending reserved space to 5120 MB (device gpu3)
[2019-07-19 14:46:25] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-19 14:46:25] [comm] NCCLCommunicator constructed successfully.
[2019-07-19 14:46:25] [training] Using 4 GPUs
[2019-07-19 14:46:25] [memory] Reserving 422 MB, device gpu0
[2019-07-19 14:46:25] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-19 14:46:25] [memory] Reserving 422 MB, device gpu0
[2019-07-19 14:46:34] [batching] Done. Typical MB size is 27520 target words
[2019-07-19 14:46:34] [memory] Extending reserved space to 5120 MB (device gpu0)
[2019-07-19 14:46:34] [memory] Extending reserved space to 5120 MB (device gpu1)
[2019-07-19 14:46:34] [memory] Extending reserved space to 5120 MB (device gpu2)
[2019-07-19 14:46:34] [memory] Extending reserved space to 5120 MB (device gpu3)
[2019-07-19 14:46:34] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-19 14:46:34] [comm] NCCLCommunicator constructed successfully.
[2019-07-19 14:46:34] [training] Using 4 GPUs
[2019-07-19 14:46:34] Loading model from ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-19 14:46:41] Loading model from ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-19 14:46:43] Loading model from ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-19 14:46:46] Loading model from ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-19 14:46:49] Loading Adam parameters from ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-19 14:47:00] [memory] Reserving 211 MB, device gpu0
[2019-07-19 14:47:00] [memory] Reserving 211 MB, device gpu1
[2019-07-19 14:47:00] [memory] Reserving 211 MB, device gpu2
[2019-07-19 14:47:01] [memory] Reserving 211 MB, device gpu3
[2019-07-19 14:47:02] [training] Model reloaded from ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-19 14:47:02] [data] Restoring the corpus state to epoch 7, batch 560000
[2019-07-19 14:47:02] [data] Shuffling data
[2019-07-19 14:47:09] [data] Done reading 13926791 sentences
[2019-07-19 14:48:11] [data] Done shuffling 13926791 sentences to temp files
[2019-07-19 14:53:25] Error: attempted to wait for futureBufferedBatches_ when none pending
[2019-07-19 14:53:25] Error: Aborted from marian::data::BatchGenerator<DataSet>::BatchPtr marian::data::BatchGenerator<DataSet>::next() [with DataSet = marian::data::CorpusBase; marian::data::BatchGenerator<DataSet>::BatchPtr = std::shared_ptr<marian::data::CorpusBatch>] in /fs/bil0/abdel/marian-dev/src/data/batch_generator.h:236

[CALL STACK]
[0x627611]          marian::data::BatchGenerator<marian::data::CorpusBase>::  next  () + 0x631
[0x63f87c]          marian::data::BatchGenerator<marian::data::CorpusBase>::  restore  (std::shared_ptr<marian::TrainingState>,  bool) + 0x27c
[0x670192]          marian::Train<marian::SyncGraphGroup>::  run  ()   + 0x12a2
[0x5a13aa]          mainTrainer  (int,  char**)                        + 0x2ca
[0x57dd1a]          main                                               + 0x8a
[0x7fb8ed53b830]    __libc_start_main                                  + 0xf0
[0x59edc9]          _start                                             + 0x29

[2019-07-19 15:23:45] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-19 15:23:45] [marian] Running on dagr as process 8375 with command line:
[2019-07-19 15:23:45] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz -T . --devices 0 1 --train-sets ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.de ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.en --vocabs ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.de.json ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.en.json --mini-batch-fit -w 5000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/dev.bpe.de ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/dev.out --valid-script-path ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/train.log --valid-log ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/valid.log
[2019-07-19 15:23:45] [config] after-batches: 0
[2019-07-19 15:23:45] [config] after-epochs: 0
[2019-07-19 15:23:45] [config] allow-unk: false
[2019-07-19 15:23:45] [config] beam-size: 12
[2019-07-19 15:23:45] [config] bert-class-symbol: "[CLS]"
[2019-07-19 15:23:45] [config] bert-mask-symbol: "[MASK]"
[2019-07-19 15:23:45] [config] bert-masking-fraction: 0.15
[2019-07-19 15:23:45] [config] bert-sep-symbol: "[SEP]"
[2019-07-19 15:23:45] [config] bert-train-type-embeddings: true
[2019-07-19 15:23:45] [config] bert-type-vocab-size: 2
[2019-07-19 15:23:45] [config] best-deep: false
[2019-07-19 15:23:45] [config] clip-gemm: 0
[2019-07-19 15:23:45] [config] clip-norm: 1
[2019-07-19 15:23:45] [config] cost-type: ce-mean
[2019-07-19 15:23:45] [config] cpu-threads: 0
[2019-07-19 15:23:45] [config] data-weighting: ""
[2019-07-19 15:23:45] [config] data-weighting-type: sentence
[2019-07-19 15:23:45] [config] dec-cell: gru
[2019-07-19 15:23:45] [config] dec-cell-base-depth: 2
[2019-07-19 15:23:45] [config] dec-cell-high-depth: 1
[2019-07-19 15:23:45] [config] dec-depth: 1
[2019-07-19 15:23:45] [config] devices:
[2019-07-19 15:23:45] [config]   - 0
[2019-07-19 15:23:45] [config]   - 1
[2019-07-19 15:23:45] [config] dim-emb: 512
[2019-07-19 15:23:45] [config] dim-rnn: 1024
[2019-07-19 15:23:45] [config] dim-vocabs:
[2019-07-19 15:23:45] [config]   - 50000
[2019-07-19 15:23:45] [config]   - 50000
[2019-07-19 15:23:45] [config] disp-first: 0
[2019-07-19 15:23:45] [config] disp-freq: 2000
[2019-07-19 15:23:45] [config] disp-label-counts: false
[2019-07-19 15:23:45] [config] dropout-rnn: 0.2
[2019-07-19 15:23:45] [config] dropout-src: 0.1
[2019-07-19 15:23:45] [config] dropout-trg: 0.1
[2019-07-19 15:23:45] [config] dump-config: ""
[2019-07-19 15:23:45] [config] early-stopping: 5
[2019-07-19 15:23:45] [config] embedding-fix-src: false
[2019-07-19 15:23:45] [config] embedding-fix-trg: false
[2019-07-19 15:23:45] [config] embedding-normalization: false
[2019-07-19 15:23:45] [config] embedding-vectors:
[2019-07-19 15:23:45] [config]   []
[2019-07-19 15:23:45] [config] enc-cell: gru
[2019-07-19 15:23:45] [config] enc-cell-depth: 1
[2019-07-19 15:23:45] [config] enc-depth: 1
[2019-07-19 15:23:45] [config] enc-type: bidirectional
[2019-07-19 15:23:45] [config] exponential-smoothing: 0.0001
[2019-07-19 15:23:45] [config] grad-dropping-momentum: 0
[2019-07-19 15:23:45] [config] grad-dropping-rate: 0
[2019-07-19 15:23:45] [config] grad-dropping-warmup: 100
[2019-07-19 15:23:45] [config] guided-alignment: none
[2019-07-19 15:23:45] [config] guided-alignment-cost: mse
[2019-07-19 15:23:45] [config] guided-alignment-weight: 0.1
[2019-07-19 15:23:45] [config] ignore-model-config: false
[2019-07-19 15:23:45] [config] input-types:
[2019-07-19 15:23:45] [config]   []
[2019-07-19 15:23:45] [config] interpolate-env-vars: false
[2019-07-19 15:23:45] [config] keep-best: false
[2019-07-19 15:23:45] [config] label-smoothing: 0
[2019-07-19 15:23:45] [config] layer-normalization: true
[2019-07-19 15:23:45] [config] learn-rate: 0.0001
[2019-07-19 15:23:45] [config] log: ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/train.log
[2019-07-19 15:23:45] [config] log-level: info
[2019-07-19 15:23:45] [config] log-time-zone: ""
[2019-07-19 15:23:45] [config] lr-decay: 0
[2019-07-19 15:23:45] [config] lr-decay-freq: 50000
[2019-07-19 15:23:45] [config] lr-decay-inv-sqrt:
[2019-07-19 15:23:45] [config]   - 0
[2019-07-19 15:23:45] [config] lr-decay-repeat-warmup: false
[2019-07-19 15:23:45] [config] lr-decay-reset-optimizer: false
[2019-07-19 15:23:45] [config] lr-decay-start:
[2019-07-19 15:23:45] [config]   - 10
[2019-07-19 15:23:45] [config]   - 1
[2019-07-19 15:23:45] [config] lr-decay-strategy: epoch+stalled
[2019-07-19 15:23:45] [config] lr-report: false
[2019-07-19 15:23:45] [config] lr-warmup: 0
[2019-07-19 15:23:45] [config] lr-warmup-at-reload: false
[2019-07-19 15:23:45] [config] lr-warmup-cycle: false
[2019-07-19 15:23:45] [config] lr-warmup-start-rate: 0
[2019-07-19 15:23:45] [config] max-length: 50
[2019-07-19 15:23:45] [config] max-length-crop: false
[2019-07-19 15:23:45] [config] max-length-factor: 3
[2019-07-19 15:23:45] [config] maxi-batch: 100
[2019-07-19 15:23:45] [config] maxi-batch-sort: trg
[2019-07-19 15:23:45] [config] mini-batch: 64
[2019-07-19 15:23:45] [config] mini-batch-fit: true
[2019-07-19 15:23:45] [config] mini-batch-fit-step: 10
[2019-07-19 15:23:45] [config] mini-batch-overstuff: 1
[2019-07-19 15:23:45] [config] mini-batch-track-lr: false
[2019-07-19 15:23:45] [config] mini-batch-understuff: 1
[2019-07-19 15:23:45] [config] mini-batch-warmup: 0
[2019-07-19 15:23:45] [config] mini-batch-words: 0
[2019-07-19 15:23:45] [config] mini-batch-words-ref: 0
[2019-07-19 15:23:45] [config] model: ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-19 15:23:45] [config] multi-loss-type: sum
[2019-07-19 15:23:45] [config] multi-node: false
[2019-07-19 15:23:45] [config] multi-node-overlap: true
[2019-07-19 15:23:45] [config] n-best: false
[2019-07-19 15:23:45] [config] no-nccl: false
[2019-07-19 15:23:45] [config] no-reload: false
[2019-07-19 15:23:45] [config] no-restore-corpus: false
[2019-07-19 15:23:45] [config] no-shuffle: false
[2019-07-19 15:23:45] [config] normalize: 1
[2019-07-19 15:23:45] [config] num-devices: 0
[2019-07-19 15:23:45] [config] optimizer: adam
[2019-07-19 15:23:45] [config] optimizer-delay: 1
[2019-07-19 15:23:45] [config] optimizer-params:
[2019-07-19 15:23:45] [config]   []
[2019-07-19 15:23:45] [config] overwrite: false
[2019-07-19 15:23:45] [config] pretrained-model: ""
[2019-07-19 15:23:45] [config] quiet: false
[2019-07-19 15:23:45] [config] quiet-translation: true
[2019-07-19 15:23:45] [config] relative-paths: false
[2019-07-19 15:23:45] [config] right-left: false
[2019-07-19 15:23:45] [config] save-freq: 20000
[2019-07-19 15:23:45] [config] seed: 1111
[2019-07-19 15:23:45] [config] shuffle-in-ram: false
[2019-07-19 15:23:45] [config] skip: false
[2019-07-19 15:23:45] [config] sqlite: ""
[2019-07-19 15:23:45] [config] sqlite-drop: false
[2019-07-19 15:23:45] [config] sync-sgd: true
[2019-07-19 15:23:45] [config] tempdir: .
[2019-07-19 15:23:45] [config] tied-embeddings: false
[2019-07-19 15:23:45] [config] tied-embeddings-all: false
[2019-07-19 15:23:45] [config] tied-embeddings-src: false
[2019-07-19 15:23:45] [config] train-sets:
[2019-07-19 15:23:45] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.de
[2019-07-19 15:23:45] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.en
[2019-07-19 15:23:45] [config] transformer-aan-activation: swish
[2019-07-19 15:23:45] [config] transformer-aan-depth: 2
[2019-07-19 15:23:45] [config] transformer-aan-nogate: false
[2019-07-19 15:23:45] [config] transformer-decoder-autoreg: self-attention
[2019-07-19 15:23:45] [config] transformer-dim-aan: 2048
[2019-07-19 15:23:45] [config] transformer-dim-ffn: 2048
[2019-07-19 15:23:45] [config] transformer-dropout: 0
[2019-07-19 15:23:45] [config] transformer-dropout-attention: 0
[2019-07-19 15:23:45] [config] transformer-dropout-ffn: 0
[2019-07-19 15:23:45] [config] transformer-ffn-activation: swish
[2019-07-19 15:23:45] [config] transformer-ffn-depth: 2
[2019-07-19 15:23:45] [config] transformer-guided-alignment-layer: last
[2019-07-19 15:23:45] [config] transformer-heads: 8
[2019-07-19 15:23:45] [config] transformer-no-projection: false
[2019-07-19 15:23:45] [config] transformer-postprocess: dan
[2019-07-19 15:23:45] [config] transformer-postprocess-emb: d
[2019-07-19 15:23:45] [config] transformer-preprocess: ""
[2019-07-19 15:23:45] [config] transformer-tied-layers:
[2019-07-19 15:23:45] [config]   []
[2019-07-19 15:23:45] [config] transformer-train-position-embeddings: false
[2019-07-19 15:23:45] [config] type: amun
[2019-07-19 15:23:45] [config] ulr: false
[2019-07-19 15:23:45] [config] ulr-dim-emb: 0
[2019-07-19 15:23:45] [config] ulr-dropout: 0
[2019-07-19 15:23:45] [config] ulr-keys-vectors: ""
[2019-07-19 15:23:45] [config] ulr-query-vectors: ""
[2019-07-19 15:23:45] [config] ulr-softmax-temperature: 1
[2019-07-19 15:23:45] [config] ulr-trainable-transformation: false
[2019-07-19 15:23:45] [config] valid-freq: 20000
[2019-07-19 15:23:45] [config] valid-log: ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/valid.log
[2019-07-19 15:23:45] [config] valid-max-length: 1000
[2019-07-19 15:23:45] [config] valid-metrics:
[2019-07-19 15:23:45] [config]   - cross-entropy
[2019-07-19 15:23:45] [config]   - perplexity
[2019-07-19 15:23:45] [config]   - translation
[2019-07-19 15:23:45] [config] valid-mini-batch: 8
[2019-07-19 15:23:45] [config] valid-script-path: ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/score-dev.sh
[2019-07-19 15:23:45] [config] valid-sets:
[2019-07-19 15:23:45] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/dev.bpe.de
[2019-07-19 15:23:45] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/dev.bpe.en
[2019-07-19 15:23:45] [config] valid-translation-output: ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/dev.out
[2019-07-19 15:23:45] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-19 15:23:45] [config] vocabs:
[2019-07-19 15:23:45] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.de.json
[2019-07-19 15:23:45] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.en.json
[2019-07-19 15:23:45] [config] word-penalty: 0
[2019-07-19 15:23:45] [config] workspace: 5000
[2019-07-19 15:23:45] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-19 15:23:45] Using synchronous training
[2019-07-19 15:23:45] [data] Loading vocabulary from JSON/Yaml file ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.de.json
[2019-07-19 15:23:46] [data] Using unused word id eos for 0
[2019-07-19 15:23:46] [data] Using unused word id UNK for 1
[2019-07-19 15:23:46] [data] Setting vocabulary size for input 0 to 50000
[2019-07-19 15:23:46] [data] Loading vocabulary from JSON/Yaml file ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.en.json
[2019-07-19 15:23:46] [data] Using unused word id eos for 0
[2019-07-19 15:23:46] [data] Using unused word id UNK for 1
[2019-07-19 15:23:46] [data] Setting vocabulary size for input 1 to 50000
[2019-07-19 15:23:46] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-19 15:23:46] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-19 15:23:48] [memory] Extending reserved space to 5120 MB (device gpu0)
[2019-07-19 15:23:48] Error: CUDA error 2 'out of memory' - /fs/bil0/abdel/marian-dev/src/tensors/gpu/device.cu:38: cudaMalloc(&data_, size)
[2019-07-19 15:23:48] Error: Aborted from virtual void marian::gpu::Device::reserve(size_t) in /fs/bil0/abdel/marian-dev/src/tensors/gpu/device.cu:38

[CALL STACK]
[0x19f32c1]         marian::gpu::Device::  reserve  (unsigned long)    + 0x1401
[0x93c8cb]          marian::SyncGraphGroup::  SyncGraphGroup  (std::shared_ptr<marian::Options>,  std::shared_ptr<marian::IMPIWrapper>) + 0xdcb
[0x605a90]          std::shared_ptr<marian::SyncGraphGroup> marian::  New  <marian::SyncGraphGroup,std::shared_ptr<marian::Options>&,std::shared_ptr<marian::IMPIWrapper>&>(std::shared_ptr<marian::Options>&,  std::shared_ptr<marian::IMPIWrapper>&) + 0x70
[0x66f24c]          marian::Train<marian::SyncGraphGroup>::  run  ()   + 0x35c
[0x5a13aa]          mainTrainer  (int,  char**)                        + 0x2ca
[0x57dd1a]          main                                               + 0x8a
[0x7ff504fbb830]    __libc_start_main                                  + 0xf0
[0x59edc9]          _start                                             + 0x29

[2019-07-19 15:28:34] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-19 15:28:34] [marian] Running on bil as process 6933 with command line:
[2019-07-19 15:28:34] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz -T . --devices 0 --train-sets ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.de ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.en --vocabs ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.de.json ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.en.json --mini-batch-fit -w 5000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/dev.bpe.de ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/dev.out --valid-script-path ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/train.log --valid-log ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/valid.log
[2019-07-19 15:28:34] [config] after-batches: 0
[2019-07-19 15:28:34] [config] after-epochs: 0
[2019-07-19 15:28:34] [config] allow-unk: false
[2019-07-19 15:28:34] [config] beam-size: 12
[2019-07-19 15:28:34] [config] bert-class-symbol: "[CLS]"
[2019-07-19 15:28:34] [config] bert-mask-symbol: "[MASK]"
[2019-07-19 15:28:34] [config] bert-masking-fraction: 0.15
[2019-07-19 15:28:34] [config] bert-sep-symbol: "[SEP]"
[2019-07-19 15:28:34] [config] bert-train-type-embeddings: true
[2019-07-19 15:28:34] [config] bert-type-vocab-size: 2
[2019-07-19 15:28:34] [config] best-deep: false
[2019-07-19 15:28:34] [config] clip-gemm: 0
[2019-07-19 15:28:34] [config] clip-norm: 1
[2019-07-19 15:28:34] [config] cost-type: ce-mean
[2019-07-19 15:28:34] [config] cpu-threads: 0
[2019-07-19 15:28:34] [config] data-weighting: ""
[2019-07-19 15:28:34] [config] data-weighting-type: sentence
[2019-07-19 15:28:34] [config] dec-cell: gru
[2019-07-19 15:28:34] [config] dec-cell-base-depth: 2
[2019-07-19 15:28:34] [config] dec-cell-high-depth: 1
[2019-07-19 15:28:34] [config] dec-depth: 1
[2019-07-19 15:28:34] [config] devices:
[2019-07-19 15:28:34] [config]   - 0
[2019-07-19 15:28:34] [config] dim-emb: 512
[2019-07-19 15:28:34] [config] dim-rnn: 1024
[2019-07-19 15:28:34] [config] dim-vocabs:
[2019-07-19 15:28:34] [config]   - 50000
[2019-07-19 15:28:34] [config]   - 50000
[2019-07-19 15:28:34] [config] disp-first: 0
[2019-07-19 15:28:34] [config] disp-freq: 2000
[2019-07-19 15:28:34] [config] disp-label-counts: false
[2019-07-19 15:28:34] [config] dropout-rnn: 0.2
[2019-07-19 15:28:34] [config] dropout-src: 0.1
[2019-07-19 15:28:34] [config] dropout-trg: 0.1
[2019-07-19 15:28:34] [config] dump-config: ""
[2019-07-19 15:28:34] [config] early-stopping: 5
[2019-07-19 15:28:34] [config] embedding-fix-src: false
[2019-07-19 15:28:34] [config] embedding-fix-trg: false
[2019-07-19 15:28:34] [config] embedding-normalization: false
[2019-07-19 15:28:34] [config] embedding-vectors:
[2019-07-19 15:28:34] [config]   []
[2019-07-19 15:28:34] [config] enc-cell: gru
[2019-07-19 15:28:34] [config] enc-cell-depth: 1
[2019-07-19 15:28:34] [config] enc-depth: 1
[2019-07-19 15:28:34] [config] enc-type: bidirectional
[2019-07-19 15:28:34] [config] exponential-smoothing: 0.0001
[2019-07-19 15:28:34] [config] grad-dropping-momentum: 0
[2019-07-19 15:28:34] [config] grad-dropping-rate: 0
[2019-07-19 15:28:34] [config] grad-dropping-warmup: 100
[2019-07-19 15:28:34] [config] guided-alignment: none
[2019-07-19 15:28:34] [config] guided-alignment-cost: mse
[2019-07-19 15:28:34] [config] guided-alignment-weight: 0.1
[2019-07-19 15:28:34] [config] ignore-model-config: false
[2019-07-19 15:28:34] [config] input-types:
[2019-07-19 15:28:34] [config]   []
[2019-07-19 15:28:34] [config] interpolate-env-vars: false
[2019-07-19 15:28:34] [config] keep-best: false
[2019-07-19 15:28:34] [config] label-smoothing: 0
[2019-07-19 15:28:34] [config] layer-normalization: true
[2019-07-19 15:28:34] [config] learn-rate: 0.0001
[2019-07-19 15:28:34] [config] log: ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/train.log
[2019-07-19 15:28:34] [config] log-level: info
[2019-07-19 15:28:34] [config] log-time-zone: ""
[2019-07-19 15:28:34] [config] lr-decay: 0
[2019-07-19 15:28:34] [config] lr-decay-freq: 50000
[2019-07-19 15:28:34] [config] lr-decay-inv-sqrt:
[2019-07-19 15:28:34] [config]   - 0
[2019-07-19 15:28:34] [config] lr-decay-repeat-warmup: false
[2019-07-19 15:28:34] [config] lr-decay-reset-optimizer: false
[2019-07-19 15:28:34] [config] lr-decay-start:
[2019-07-19 15:28:34] [config]   - 10
[2019-07-19 15:28:34] [config]   - 1
[2019-07-19 15:28:34] [config] lr-decay-strategy: epoch+stalled
[2019-07-19 15:28:34] [config] lr-report: false
[2019-07-19 15:28:34] [config] lr-warmup: 0
[2019-07-19 15:28:34] [config] lr-warmup-at-reload: false
[2019-07-19 15:28:34] [config] lr-warmup-cycle: false
[2019-07-19 15:28:34] [config] lr-warmup-start-rate: 0
[2019-07-19 15:28:34] [config] max-length: 50
[2019-07-19 15:28:34] [config] max-length-crop: false
[2019-07-19 15:28:34] [config] max-length-factor: 3
[2019-07-19 15:28:34] [config] maxi-batch: 100
[2019-07-19 15:28:34] [config] maxi-batch-sort: trg
[2019-07-19 15:28:34] [config] mini-batch: 64
[2019-07-19 15:28:34] [config] mini-batch-fit: true
[2019-07-19 15:28:34] [config] mini-batch-fit-step: 10
[2019-07-19 15:28:34] [config] mini-batch-overstuff: 1
[2019-07-19 15:28:34] [config] mini-batch-track-lr: false
[2019-07-19 15:28:34] [config] mini-batch-understuff: 1
[2019-07-19 15:28:34] [config] mini-batch-warmup: 0
[2019-07-19 15:28:34] [config] mini-batch-words: 0
[2019-07-19 15:28:34] [config] mini-batch-words-ref: 0
[2019-07-19 15:28:34] [config] model: ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-19 15:28:34] [config] multi-loss-type: sum
[2019-07-19 15:28:34] [config] multi-node: false
[2019-07-19 15:28:34] [config] multi-node-overlap: true
[2019-07-19 15:28:34] [config] n-best: false
[2019-07-19 15:28:34] [config] no-nccl: false
[2019-07-19 15:28:34] [config] no-reload: false
[2019-07-19 15:28:34] [config] no-restore-corpus: false
[2019-07-19 15:28:34] [config] no-shuffle: false
[2019-07-19 15:28:34] [config] normalize: 1
[2019-07-19 15:28:34] [config] num-devices: 0
[2019-07-19 15:28:34] [config] optimizer: adam
[2019-07-19 15:28:34] [config] optimizer-delay: 1
[2019-07-19 15:28:34] [config] optimizer-params:
[2019-07-19 15:28:34] [config]   []
[2019-07-19 15:28:34] [config] overwrite: false
[2019-07-19 15:28:34] [config] pretrained-model: ""
[2019-07-19 15:28:34] [config] quiet: false
[2019-07-19 15:28:34] [config] quiet-translation: true
[2019-07-19 15:28:34] [config] relative-paths: false
[2019-07-19 15:28:34] [config] right-left: false
[2019-07-19 15:28:34] [config] save-freq: 20000
[2019-07-19 15:28:34] [config] seed: 1111
[2019-07-19 15:28:34] [config] shuffle-in-ram: false
[2019-07-19 15:28:34] [config] skip: false
[2019-07-19 15:28:34] [config] sqlite: ""
[2019-07-19 15:28:34] [config] sqlite-drop: false
[2019-07-19 15:28:34] [config] sync-sgd: true
[2019-07-19 15:28:34] [config] tempdir: .
[2019-07-19 15:28:34] [config] tied-embeddings: false
[2019-07-19 15:28:34] [config] tied-embeddings-all: false
[2019-07-19 15:28:34] [config] tied-embeddings-src: false
[2019-07-19 15:28:34] [config] train-sets:
[2019-07-19 15:28:34] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.de
[2019-07-19 15:28:34] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.en
[2019-07-19 15:28:34] [config] transformer-aan-activation: swish
[2019-07-19 15:28:34] [config] transformer-aan-depth: 2
[2019-07-19 15:28:34] [config] transformer-aan-nogate: false
[2019-07-19 15:28:34] [config] transformer-decoder-autoreg: self-attention
[2019-07-19 15:28:34] [config] transformer-dim-aan: 2048
[2019-07-19 15:28:34] [config] transformer-dim-ffn: 2048
[2019-07-19 15:28:34] [config] transformer-dropout: 0
[2019-07-19 15:28:34] [config] transformer-dropout-attention: 0
[2019-07-19 15:28:34] [config] transformer-dropout-ffn: 0
[2019-07-19 15:28:34] [config] transformer-ffn-activation: swish
[2019-07-19 15:28:34] [config] transformer-ffn-depth: 2
[2019-07-19 15:28:34] [config] transformer-guided-alignment-layer: last
[2019-07-19 15:28:34] [config] transformer-heads: 8
[2019-07-19 15:28:34] [config] transformer-no-projection: false
[2019-07-19 15:28:34] [config] transformer-postprocess: dan
[2019-07-19 15:28:34] [config] transformer-postprocess-emb: d
[2019-07-19 15:28:34] [config] transformer-preprocess: ""
[2019-07-19 15:28:34] [config] transformer-tied-layers:
[2019-07-19 15:28:34] [config]   []
[2019-07-19 15:28:34] [config] transformer-train-position-embeddings: false
[2019-07-19 15:28:34] [config] type: amun
[2019-07-19 15:28:34] [config] ulr: false
[2019-07-19 15:28:34] [config] ulr-dim-emb: 0
[2019-07-19 15:28:34] [config] ulr-dropout: 0
[2019-07-19 15:28:34] [config] ulr-keys-vectors: ""
[2019-07-19 15:28:34] [config] ulr-query-vectors: ""
[2019-07-19 15:28:34] [config] ulr-softmax-temperature: 1
[2019-07-19 15:28:34] [config] ulr-trainable-transformation: false
[2019-07-19 15:28:34] [config] valid-freq: 20000
[2019-07-19 15:28:34] [config] valid-log: ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/valid.log
[2019-07-19 15:28:34] [config] valid-max-length: 1000
[2019-07-19 15:28:34] [config] valid-metrics:
[2019-07-19 15:28:34] [config]   - cross-entropy
[2019-07-19 15:28:34] [config]   - perplexity
[2019-07-19 15:28:34] [config]   - translation
[2019-07-19 15:28:34] [config] valid-mini-batch: 8
[2019-07-19 15:28:34] [config] valid-script-path: ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/score-dev.sh
[2019-07-19 15:28:34] [config] valid-sets:
[2019-07-19 15:28:34] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/dev.bpe.de
[2019-07-19 15:28:34] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/dev.bpe.en
[2019-07-19 15:28:34] [config] valid-translation-output: ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/dev.out
[2019-07-19 15:28:34] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-19 15:28:34] [config] vocabs:
[2019-07-19 15:28:34] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.de.json
[2019-07-19 15:28:34] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.en.json
[2019-07-19 15:28:34] [config] word-penalty: 0
[2019-07-19 15:28:34] [config] workspace: 5000
[2019-07-19 15:28:34] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-19 15:28:34] Using synchronous training
[2019-07-19 15:28:34] [data] Loading vocabulary from JSON/Yaml file ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.de.json
[2019-07-19 15:28:35] [data] Using unused word id eos for 0
[2019-07-19 15:28:35] [data] Using unused word id UNK for 1
[2019-07-19 15:28:35] [data] Setting vocabulary size for input 0 to 50000
[2019-07-19 15:28:35] [data] Loading vocabulary from JSON/Yaml file ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/data/train.bpe.en.json
[2019-07-19 15:28:35] [data] Using unused word id eos for 0
[2019-07-19 15:28:35] [data] Using unused word id UNK for 1
[2019-07-19 15:28:35] [data] Setting vocabulary size for input 1 to 50000
[2019-07-19 15:28:35] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-19 15:28:35] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-19 15:28:37] [memory] Extending reserved space to 5120 MB (device gpu0)
[2019-07-19 15:28:38] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-19 15:28:38] [comm] NCCLCommunicator constructed successfully.
[2019-07-19 15:28:38] [training] Using 1 GPUs
[2019-07-19 15:28:38] [memory] Reserving 422 MB, device gpu0
[2019-07-19 15:28:38] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-19 15:28:38] [memory] Reserving 422 MB, device gpu0
[2019-07-19 15:28:42] [batching] Done. Typical MB size is 6880 target words
[2019-07-19 15:28:43] [memory] Extending reserved space to 5120 MB (device gpu0)
[2019-07-19 15:28:43] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-19 15:28:43] [comm] NCCLCommunicator constructed successfully.
[2019-07-19 15:28:43] [training] Using 1 GPUs
[2019-07-19 15:28:43] Loading model from ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-19 15:28:46] Loading Adam parameters from ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-19 15:28:49] [memory] Reserving 844 MB, device gpu0
[2019-07-19 15:28:51] [training] Model reloaded from ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-19 15:28:51] [data] Restoring the corpus state to epoch 7, batch 560000
[2019-07-19 15:28:51] [data] Shuffling data
[2019-07-19 15:29:03] [data] Done reading 13926791 sentences
[2019-07-19 15:30:11] [data] Done shuffling 13926791 sentences to temp files
[2019-07-19 15:36:17] Training started
[2019-07-19 15:36:17] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-07-19 15:36:17] [memory] Reserving 422 MB, device gpu0
[2019-07-19 15:36:18] [memory] Reserving 422 MB, device gpu0
[2019-07-19 15:36:18] Loading model from ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-19 15:36:21] [memory] Reserving 422 MB, device cpu0
[2019-07-19 15:36:22] [memory] Reserving 422 MB, device gpu0
[2019-07-19 15:42:39] Ep. 7 : Up. 562000 : Sen. 10,516,252 : Cost 63.75486755 : Time 844.21s : 7225.45 words/s
[2019-07-19 15:48:58] Ep. 7 : Up. 564000 : Sen. 10,805,899 : Cost 63.74524689 : Time 378.97s : 16131.76 words/s
[2019-07-19 15:55:18] Ep. 7 : Up. 566000 : Sen. 11,095,384 : Cost 63.50547409 : Time 379.44s : 16122.97 words/s
[2019-07-19 16:01:37] Ep. 7 : Up. 568000 : Sen. 11,384,625 : Cost 63.69618988 : Time 379.30s : 16108.25 words/s
[2019-07-19 16:07:55] Ep. 7 : Up. 570000 : Sen. 11,673,468 : Cost 63.47478867 : Time 378.31s : 16110.38 words/s
[2019-07-19 16:10:36] Seen 11795613 samples
[2019-07-19 16:10:36] Starting epoch 8
[2019-07-19 16:10:36] [data] Shuffling data
[2019-07-19 16:10:49] [data] Done reading 13926791 sentences
[2019-07-19 16:12:11] [data] Done shuffling 13926791 sentences to temp files
[2019-07-19 16:15:54] Ep. 8 : Up. 572000 : Sen. 167,171 : Cost 62.93577957 : Time 478.18s : 12757.28 words/s
[2019-07-19 16:22:12] Ep. 8 : Up. 574000 : Sen. 455,852 : Cost 62.86049271 : Time 378.19s : 16148.52 words/s
[2019-07-19 16:28:31] Ep. 8 : Up. 576000 : Sen. 746,492 : Cost 62.60940170 : Time 379.59s : 16132.94 words/s
[2019-07-19 16:34:50] Ep. 8 : Up. 578000 : Sen. 1,036,438 : Cost 62.87985992 : Time 378.95s : 16163.93 words/s
[2019-07-19 16:41:09] Ep. 8 : Up. 580000 : Sen. 1,325,317 : Cost 62.62737656 : Time 378.41s : 16115.06 words/s
[2019-07-19 16:41:09] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-19 16:41:15] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter580000.npz
[2019-07-19 16:41:17] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-19 16:41:22] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-19 16:41:42] [valid] Ep. 8 : Up. 580000 : cross-entropy : 50.9468 : new best
[2019-07-19 16:41:48] [valid] Ep. 8 : Up. 580000 : perplexity : 7.52875 : new best
[2019-07-19 16:42:42] [valid] Ep. 8 : Up. 580000 : translation : 25.14 : new best
[2019-07-19 16:49:04] Ep. 8 : Up. 582000 : Sen. 1,614,082 : Cost 62.86219025 : Time 474.92s : 12845.78 words/s
[2019-07-19 16:55:23] Ep. 8 : Up. 584000 : Sen. 1,902,994 : Cost 62.78999710 : Time 379.07s : 16093.34 words/s
[2019-07-19 17:01:43] Ep. 8 : Up. 586000 : Sen. 2,192,711 : Cost 62.84380341 : Time 380.36s : 16087.32 words/s
[2019-07-19 17:08:03] Ep. 8 : Up. 588000 : Sen. 2,481,449 : Cost 62.88435364 : Time 379.37s : 16115.90 words/s
[2019-07-19 17:14:23] Ep. 8 : Up. 590000 : Sen. 2,771,728 : Cost 62.79491806 : Time 380.05s : 16107.09 words/s
[2019-07-19 17:20:42] Ep. 8 : Up. 592000 : Sen. 3,061,977 : Cost 62.81682968 : Time 378.98s : 16154.91 words/s
[2019-07-19 17:27:00] Ep. 8 : Up. 594000 : Sen. 3,352,370 : Cost 62.65640640 : Time 378.74s : 16120.76 words/s
[2019-07-19 17:33:20] Ep. 8 : Up. 596000 : Sen. 3,641,732 : Cost 63.13137817 : Time 379.48s : 16118.68 words/s
[2019-07-19 17:39:39] Ep. 8 : Up. 598000 : Sen. 3,930,513 : Cost 62.87939835 : Time 379.64s : 16060.48 words/s
[2019-07-19 17:46:00] Ep. 8 : Up. 600000 : Sen. 4,220,321 : Cost 63.05059052 : Time 380.35s : 16110.08 words/s
[2019-07-19 17:46:00] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-19 17:46:05] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter600000.npz
[2019-07-19 17:46:07] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-19 17:46:13] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-19 17:46:32] [valid] Ep. 8 : Up. 600000 : cross-entropy : 50.8943 : new best
[2019-07-19 17:46:38] [valid] Ep. 8 : Up. 600000 : perplexity : 7.5131 : new best
[2019-07-19 17:47:31] [valid] Ep. 8 : Up. 600000 : translation : 25.19 : new best
[2019-07-19 17:53:53] Ep. 8 : Up. 602000 : Sen. 4,509,029 : Cost 62.92828751 : Time 472.90s : 12896.84 words/s
[2019-07-19 18:00:13] Ep. 8 : Up. 604000 : Sen. 4,797,957 : Cost 62.82873917 : Time 380.39s : 16037.24 words/s
[2019-07-19 18:06:34] Ep. 8 : Up. 606000 : Sen. 5,087,506 : Cost 62.81856155 : Time 380.92s : 16055.06 words/s
[2019-07-19 18:12:56] Ep. 8 : Up. 608000 : Sen. 5,377,614 : Cost 63.15290070 : Time 381.70s : 16046.99 words/s
[2019-07-19 18:19:15] Ep. 8 : Up. 610000 : Sen. 5,666,418 : Cost 62.83224487 : Time 379.55s : 16049.97 words/s
[2019-07-19 18:25:36] Ep. 8 : Up. 612000 : Sen. 5,956,140 : Cost 62.88685608 : Time 380.39s : 16076.79 words/s
[2019-07-19 18:31:56] Ep. 8 : Up. 614000 : Sen. 6,245,434 : Cost 62.62734222 : Time 380.22s : 16029.78 words/s
[2019-07-19 18:38:17] Ep. 8 : Up. 616000 : Sen. 6,535,257 : Cost 63.03296661 : Time 380.86s : 16086.41 words/s
[2019-07-19 18:44:38] Ep. 8 : Up. 618000 : Sen. 6,824,694 : Cost 63.22177124 : Time 381.50s : 16067.35 words/s
[2019-07-19 18:50:59] Ep. 8 : Up. 620000 : Sen. 7,114,397 : Cost 63.19211578 : Time 381.13s : 16059.07 words/s
[2019-07-19 18:50:59] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-19 18:51:05] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter620000.npz
[2019-07-19 18:51:08] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-19 18:51:13] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-19 18:51:33] [valid] Ep. 8 : Up. 620000 : cross-entropy : 50.76 : new best
[2019-07-19 18:51:40] [valid] Ep. 8 : Up. 620000 : perplexity : 7.47321 : new best
[2019-07-19 18:52:33] [valid] Ep. 8 : Up. 620000 : translation : 25.3 : new best
[2019-07-19 18:58:54] Ep. 8 : Up. 622000 : Sen. 7,403,016 : Cost 62.99629593 : Time 474.25s : 12841.28 words/s
[2019-07-19 19:05:15] Ep. 8 : Up. 624000 : Sen. 7,692,668 : Cost 63.35622787 : Time 381.27s : 16075.66 words/s
[2019-07-19 19:11:34] Ep. 8 : Up. 626000 : Sen. 7,981,106 : Cost 63.08501816 : Time 378.74s : 16115.27 words/s
[2019-07-19 19:17:54] Ep. 8 : Up. 628000 : Sen. 8,270,478 : Cost 63.29530716 : Time 380.09s : 16106.30 words/s
[2019-07-19 19:24:13] Ep. 8 : Up. 630000 : Sen. 8,560,211 : Cost 62.79725266 : Time 379.12s : 16085.91 words/s
[2019-07-19 19:30:33] Ep. 8 : Up. 632000 : Sen. 8,849,116 : Cost 63.22830582 : Time 380.28s : 16042.47 words/s
[2019-07-19 19:36:53] Ep. 8 : Up. 634000 : Sen. 9,138,276 : Cost 63.05632019 : Time 380.15s : 16068.49 words/s
[2019-07-19 19:43:13] Ep. 8 : Up. 636000 : Sen. 9,427,369 : Cost 62.87842941 : Time 379.72s : 16056.95 words/s
[2019-07-19 19:49:34] Ep. 8 : Up. 638000 : Sen. 9,717,047 : Cost 62.88631439 : Time 380.75s : 16059.10 words/s
[2019-07-19 19:55:54] Ep. 8 : Up. 640000 : Sen. 10,006,349 : Cost 62.99710846 : Time 380.64s : 16077.75 words/s
[2019-07-19 19:55:54] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-19 19:56:00] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter640000.npz
[2019-07-19 19:56:02] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-19 19:56:08] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-19 19:56:27] [valid] Ep. 8 : Up. 640000 : cross-entropy : 50.724 : new best
[2019-07-19 19:56:34] [valid] Ep. 8 : Up. 640000 : perplexity : 7.46256 : new best
[2019-07-19 19:57:26] [valid] Ep. 8 : Up. 640000 : translation : 25.34 : new best
[2019-07-19 20:03:49] Ep. 8 : Up. 642000 : Sen. 10,295,523 : Cost 62.93510437 : Time 474.77s : 12858.95 words/s
[2019-07-19 20:10:09] Ep. 8 : Up. 644000 : Sen. 10,585,336 : Cost 62.95950699 : Time 379.61s : 16087.24 words/s
[2019-07-19 20:16:28] Ep. 8 : Up. 646000 : Sen. 10,874,269 : Cost 62.93831253 : Time 379.39s : 16080.40 words/s
[2019-07-19 20:22:48] Ep. 8 : Up. 648000 : Sen. 11,162,698 : Cost 63.05420685 : Time 379.42s : 16075.50 words/s
[2019-07-19 20:29:07] Ep. 8 : Up. 650000 : Sen. 11,451,183 : Cost 63.24244308 : Time 379.43s : 16072.07 words/s
[2019-07-19 20:35:27] Ep. 8 : Up. 652000 : Sen. 11,741,214 : Cost 62.76075363 : Time 379.99s : 16077.27 words/s
[2019-07-19 20:36:39] Seen 11795613 samples
[2019-07-19 20:36:39] Starting epoch 9
[2019-07-19 20:36:39] [data] Shuffling data
[2019-07-19 20:36:50] [data] Done reading 13926791 sentences
[2019-07-19 20:37:57] [data] Done shuffling 13926791 sentences to temp files
[2019-07-19 20:43:09] Ep. 9 : Up. 654000 : Sen. 235,528 : Cost 62.51517868 : Time 462.24s : 13259.31 words/s
[2019-07-19 20:49:29] Ep. 9 : Up. 656000 : Sen. 524,018 : Cost 62.27040100 : Time 379.87s : 16046.16 words/s
[2019-07-19 20:55:49] Ep. 9 : Up. 658000 : Sen. 812,932 : Cost 62.34065628 : Time 380.26s : 16053.90 words/s
[2019-07-19 21:02:09] Ep. 9 : Up. 660000 : Sen. 1,102,530 : Cost 62.29088593 : Time 379.80s : 16056.73 words/s
[2019-07-19 21:02:09] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-19 21:02:15] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter660000.npz
[2019-07-19 21:02:17] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-19 21:02:23] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-19 21:02:42] [valid] Ep. 9 : Up. 660000 : cross-entropy : 50.6708 : new best
[2019-07-19 21:02:48] [valid] Ep. 9 : Up. 660000 : perplexity : 7.44687 : new best
[2019-07-19 21:03:41] [valid] Ep. 9 : Up. 660000 : translation : 25.34 : stalled 1 times (last best: 25.34)
[2019-07-19 21:10:04] Ep. 9 : Up. 662000 : Sen. 1,391,507 : Cost 62.58184433 : Time 474.58s : 12874.63 words/s
[2019-07-19 21:16:24] Ep. 9 : Up. 664000 : Sen. 1,680,860 : Cost 62.26958847 : Time 380.28s : 16073.72 words/s
[2019-07-19 21:22:43] Ep. 9 : Up. 666000 : Sen. 1,970,102 : Cost 62.23649979 : Time 378.93s : 16084.62 words/s
[2019-07-19 21:29:03] Ep. 9 : Up. 668000 : Sen. 2,259,332 : Cost 62.18121719 : Time 380.05s : 16066.03 words/s
[2019-07-19 21:35:24] Ep. 9 : Up. 670000 : Sen. 2,549,188 : Cost 62.48476410 : Time 381.04s : 16053.86 words/s
[2019-07-19 21:41:44] Ep. 9 : Up. 672000 : Sen. 2,839,085 : Cost 62.34613037 : Time 379.58s : 16071.43 words/s
[2019-07-19 21:48:05] Ep. 9 : Up. 674000 : Sen. 3,128,898 : Cost 62.74537659 : Time 381.59s : 16095.14 words/s
[2019-07-19 21:54:25] Ep. 9 : Up. 676000 : Sen. 3,418,094 : Cost 62.19576263 : Time 380.26s : 16049.13 words/s
[2019-07-19 22:00:46] Ep. 9 : Up. 678000 : Sen. 3,708,080 : Cost 62.37180328 : Time 380.16s : 16070.94 words/s
[2019-07-19 22:07:07] Ep. 9 : Up. 680000 : Sen. 3,997,587 : Cost 62.57017517 : Time 380.98s : 16078.84 words/s
[2019-07-19 22:07:07] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-19 22:07:14] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter680000.npz
[2019-07-19 22:07:16] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-19 22:07:22] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-19 22:07:41] [valid] Ep. 9 : Up. 680000 : cross-entropy : 50.6124 : new best
[2019-07-19 22:07:47] [valid] Ep. 9 : Up. 680000 : perplexity : 7.42963 : new best
[2019-07-19 22:08:40] [valid] Ep. 9 : Up. 680000 : translation : 24.99 : stalled 2 times (last best: 25.34)
[2019-07-19 22:15:02] Ep. 9 : Up. 682000 : Sen. 4,286,978 : Cost 62.37353516 : Time 475.62s : 12845.39 words/s
[2019-07-19 22:21:23] Ep. 9 : Up. 684000 : Sen. 4,576,528 : Cost 62.56991196 : Time 380.58s : 16078.59 words/s
[2019-07-19 22:27:43] Ep. 9 : Up. 686000 : Sen. 4,865,862 : Cost 62.63396454 : Time 379.85s : 16075.13 words/s
[2019-07-19 22:34:03] Ep. 9 : Up. 688000 : Sen. 5,154,730 : Cost 62.78130341 : Time 380.33s : 16048.49 words/s
[2019-07-19 22:40:24] Ep. 9 : Up. 690000 : Sen. 5,444,373 : Cost 62.90640640 : Time 381.35s : 16099.64 words/s
[2019-07-19 22:46:45] Ep. 9 : Up. 692000 : Sen. 5,733,872 : Cost 62.58617020 : Time 380.51s : 16064.97 words/s
[2019-07-19 22:53:05] Ep. 9 : Up. 694000 : Sen. 6,023,036 : Cost 62.40829468 : Time 380.09s : 16065.74 words/s
[2019-07-19 22:59:24] Ep. 9 : Up. 696000 : Sen. 6,312,023 : Cost 62.80656052 : Time 379.58s : 16084.59 words/s
[2019-07-19 23:05:45] Ep. 9 : Up. 698000 : Sen. 6,600,972 : Cost 62.47553635 : Time 380.19s : 16041.86 words/s
[2019-07-19 23:12:04] Ep. 9 : Up. 700000 : Sen. 6,889,410 : Cost 62.65454102 : Time 379.75s : 16030.17 words/s
[2019-07-19 23:12:04] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-19 23:12:11] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter700000.npz
[2019-07-19 23:12:13] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-19 23:12:19] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-19 23:12:38] [valid] Ep. 9 : Up. 700000 : cross-entropy : 50.5416 : new best
[2019-07-19 23:12:45] [valid] Ep. 9 : Up. 700000 : perplexity : 7.40882 : new best
[2019-07-19 23:13:38] [valid] Ep. 9 : Up. 700000 : translation : 25.23 : stalled 3 times (last best: 25.34)
[2019-07-19 23:19:59] Ep. 9 : Up. 702000 : Sen. 7,178,890 : Cost 62.48396301 : Time 474.65s : 12869.85 words/s
[2019-07-19 23:26:19] Ep. 9 : Up. 704000 : Sen. 7,467,919 : Cost 62.71152115 : Time 379.68s : 16108.47 words/s
[2019-07-19 23:32:38] Ep. 9 : Up. 706000 : Sen. 7,757,900 : Cost 62.54940033 : Time 379.38s : 16149.89 words/s
[2019-07-19 23:38:55] Ep. 9 : Up. 708000 : Sen. 8,046,452 : Cost 62.52784348 : Time 377.28s : 16113.97 words/s
[2019-07-19 23:45:16] Ep. 9 : Up. 710000 : Sen. 8,336,619 : Cost 62.60855484 : Time 380.17s : 16124.46 words/s
[2019-07-19 23:51:34] Ep. 9 : Up. 712000 : Sen. 8,625,704 : Cost 62.43730927 : Time 378.35s : 16106.19 words/s
[2019-07-19 23:57:53] Ep. 9 : Up. 714000 : Sen. 8,914,936 : Cost 62.57990646 : Time 378.98s : 16136.67 words/s
[2019-07-20 00:04:11] Ep. 9 : Up. 716000 : Sen. 9,204,000 : Cost 62.62220764 : Time 378.27s : 16104.34 words/s
[2019-07-20 00:10:33] Ep. 9 : Up. 718000 : Sen. 9,494,061 : Cost 62.75426865 : Time 381.64s : 16055.28 words/s
[2019-07-20 00:16:54] Ep. 9 : Up. 720000 : Sen. 9,783,778 : Cost 62.88769531 : Time 381.45s : 16076.58 words/s
[2019-07-20 00:16:54] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-20 00:17:01] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter720000.npz
[2019-07-20 00:17:04] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-20 00:17:10] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-20 00:17:29] [valid] Ep. 9 : Up. 720000 : cross-entropy : 50.4078 : new best
[2019-07-20 00:17:35] [valid] Ep. 9 : Up. 720000 : perplexity : 7.36965 : new best
[2019-07-20 00:18:28] [valid] Ep. 9 : Up. 720000 : translation : 25.25 : stalled 4 times (last best: 25.34)
[2019-07-20 00:24:48] Ep. 9 : Up. 722000 : Sen. 10,072,808 : Cost 62.57621765 : Time 473.75s : 12851.33 words/s
[2019-07-20 00:31:07] Ep. 9 : Up. 724000 : Sen. 10,361,996 : Cost 62.78223038 : Time 379.43s : 16114.85 words/s
[2019-07-20 00:37:27] Ep. 9 : Up. 726000 : Sen. 10,651,250 : Cost 62.85612106 : Time 379.91s : 16105.02 words/s
[2019-07-20 00:43:46] Ep. 9 : Up. 728000 : Sen. 10,940,843 : Cost 62.40392685 : Time 378.37s : 16136.76 words/s
[2019-07-20 00:50:05] Ep. 9 : Up. 730000 : Sen. 11,231,327 : Cost 62.58582306 : Time 379.73s : 16148.06 words/s
[2019-07-20 00:56:24] Ep. 9 : Up. 732000 : Sen. 11,520,204 : Cost 62.77192688 : Time 378.55s : 16116.66 words/s
[2019-07-20 01:02:25] Seen 11795613 samples
[2019-07-20 01:02:25] Starting epoch 10
[2019-07-20 01:02:25] [data] Shuffling data
[2019-07-20 01:02:35] [data] Done reading 13926791 sentences
[2019-07-20 01:03:48] [data] Done shuffling 13926791 sentences to temp files
[2019-07-20 01:04:11] Ep. 10 : Up. 734000 : Sen. 15,239 : Cost 62.66909790 : Time 467.46s : 13146.99 words/s
[2019-07-20 01:10:30] Ep. 10 : Up. 736000 : Sen. 304,444 : Cost 61.85235214 : Time 378.48s : 16131.55 words/s
[2019-07-20 01:16:49] Ep. 10 : Up. 738000 : Sen. 593,364 : Cost 61.96572113 : Time 379.28s : 16096.08 words/s
[2019-07-20 01:23:09] Ep. 10 : Up. 740000 : Sen. 881,924 : Cost 62.10129547 : Time 379.79s : 16088.83 words/s
[2019-07-20 01:23:09] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-20 01:23:15] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter740000.npz
[2019-07-20 01:23:17] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-20 01:23:23] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-20 01:23:42] [valid] Ep. 10 : Up. 740000 : cross-entropy : 50.4413 : stalled 1 times (last best: 50.4078)
[2019-07-20 01:23:48] [valid] Ep. 10 : Up. 740000 : perplexity : 7.37944 : stalled 1 times (last best: 7.36965)
[2019-07-20 01:24:41] [valid] Ep. 10 : Up. 740000 : translation : 25.32 : stalled 5 times (last best: 25.34)
[2019-07-20 01:31:03] Ep. 10 : Up. 742000 : Sen. 1,172,317 : Cost 61.81666946 : Time 474.19s : 12909.32 words/s
[2019-07-20 01:37:23] Ep. 10 : Up. 744000 : Sen. 1,461,483 : Cost 62.13636398 : Time 379.90s : 16088.04 words/s
[2019-07-20 01:43:42] Ep. 10 : Up. 746000 : Sen. 1,751,178 : Cost 61.84736252 : Time 378.83s : 16126.19 words/s
[2019-07-20 01:50:00] Ep. 10 : Up. 748000 : Sen. 2,039,418 : Cost 61.88682938 : Time 378.01s : 16075.80 words/s
[2019-07-20 01:56:20] Ep. 10 : Up. 750000 : Sen. 2,329,025 : Cost 62.46449661 : Time 380.20s : 16135.10 words/s
[2019-07-20 02:02:39] Ep. 10 : Up. 752000 : Sen. 2,617,906 : Cost 61.88990784 : Time 378.78s : 16075.62 words/s
[2019-07-20 02:08:58] Ep. 10 : Up. 754000 : Sen. 2,906,829 : Cost 62.05039978 : Time 379.22s : 16094.78 words/s
[2019-07-20 02:15:17] Ep. 10 : Up. 756000 : Sen. 3,195,536 : Cost 62.12709808 : Time 378.46s : 16118.49 words/s
[2019-07-20 02:21:35] Ep. 10 : Up. 758000 : Sen. 3,483,581 : Cost 62.07680130 : Time 378.15s : 16082.64 words/s
[2019-07-20 02:27:54] Ep. 10 : Up. 760000 : Sen. 3,772,843 : Cost 62.26363754 : Time 379.41s : 16105.94 words/s
[2019-07-20 02:27:54] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-20 02:28:00] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter760000.npz
[2019-07-20 02:28:02] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-20 02:28:07] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-20 02:28:28] [valid] Ep. 10 : Up. 760000 : cross-entropy : 50.4356 : stalled 2 times (last best: 50.4078)
[2019-07-20 02:28:34] [valid] Ep. 10 : Up. 760000 : perplexity : 7.37779 : stalled 2 times (last best: 7.36965)
[2019-07-20 02:29:27] [valid] Ep. 10 : Up. 760000 : translation : 25.4 : new best
[2019-07-20 02:35:47] Ep. 10 : Up. 762000 : Sen. 4,061,118 : Cost 62.32437134 : Time 472.88s : 12890.06 words/s
[2019-07-20 02:42:08] Ep. 10 : Up. 764000 : Sen. 4,352,000 : Cost 62.13959503 : Time 380.64s : 16114.89 words/s
[2019-07-20 02:48:27] Ep. 10 : Up. 766000 : Sen. 4,640,855 : Cost 62.21184158 : Time 379.49s : 16091.66 words/s
[2019-07-20 02:54:47] Ep. 10 : Up. 768000 : Sen. 4,930,128 : Cost 61.92066193 : Time 379.63s : 16067.64 words/s
[2019-07-20 03:01:06] Ep. 10 : Up. 770000 : Sen. 5,219,706 : Cost 62.07144928 : Time 379.28s : 16105.10 words/s
[2019-07-20 03:07:25] Ep. 10 : Up. 772000 : Sen. 5,508,783 : Cost 62.09114456 : Time 378.55s : 16101.52 words/s
[2019-07-20 03:13:45] Ep. 10 : Up. 774000 : Sen. 5,798,104 : Cost 62.58707047 : Time 380.50s : 16107.73 words/s
[2019-07-20 03:20:04] Ep. 10 : Up. 776000 : Sen. 6,087,965 : Cost 62.01916122 : Time 378.82s : 16116.89 words/s
[2019-07-20 03:26:22] Ep. 10 : Up. 778000 : Sen. 6,376,449 : Cost 62.31883240 : Time 378.49s : 16108.90 words/s
[2019-07-20 03:32:42] Ep. 10 : Up. 780000 : Sen. 6,665,499 : Cost 62.67192459 : Time 379.82s : 16116.87 words/s
[2019-07-20 03:32:42] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-20 03:32:48] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter780000.npz
[2019-07-20 03:32:50] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-20 03:32:55] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-20 03:33:16] [valid] Ep. 10 : Up. 780000 : cross-entropy : 50.4186 : stalled 3 times (last best: 50.4078)
[2019-07-20 03:33:22] [valid] Ep. 10 : Up. 780000 : perplexity : 7.3728 : stalled 3 times (last best: 7.36965)
[2019-07-20 03:34:15] [valid] Ep. 10 : Up. 780000 : translation : 25.27 : stalled 1 times (last best: 25.4)
[2019-07-20 03:40:36] Ep. 10 : Up. 782000 : Sen. 6,955,050 : Cost 62.00558853 : Time 473.92s : 12879.04 words/s
[2019-07-20 03:46:56] Ep. 10 : Up. 784000 : Sen. 7,243,979 : Cost 62.14219284 : Time 379.28s : 16085.64 words/s
[2019-07-20 03:53:15] Ep. 10 : Up. 786000 : Sen. 7,533,954 : Cost 62.11511230 : Time 379.48s : 16118.78 words/s
[2019-07-20 03:59:35] Ep. 10 : Up. 788000 : Sen. 7,823,976 : Cost 62.26983643 : Time 379.83s : 16125.56 words/s
[2019-07-20 04:05:54] Ep. 10 : Up. 790000 : Sen. 8,113,984 : Cost 62.23006821 : Time 379.27s : 16155.08 words/s
[2019-07-20 04:12:14] Ep. 10 : Up. 792000 : Sen. 8,403,995 : Cost 62.32149124 : Time 379.92s : 16128.29 words/s
[2019-07-20 04:18:35] Ep. 10 : Up. 794000 : Sen. 8,694,059 : Cost 62.46586990 : Time 380.52s : 16110.69 words/s
[2019-07-20 04:24:52] Ep. 10 : Up. 796000 : Sen. 8,983,669 : Cost 61.87430573 : Time 377.94s : 16126.26 words/s
[2019-07-20 04:31:12] Ep. 10 : Up. 798000 : Sen. 9,272,893 : Cost 62.06155777 : Time 379.08s : 16104.96 words/s
[2019-07-20 04:37:31] Ep. 10 : Up. 800000 : Sen. 9,561,600 : Cost 62.28464127 : Time 379.55s : 16081.32 words/s
[2019-07-20 04:37:31] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-20 04:37:36] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter800000.npz
[2019-07-20 04:37:39] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-20 04:37:44] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-20 04:38:04] [valid] Ep. 10 : Up. 800000 : cross-entropy : 50.3406 : new best
[2019-07-20 04:38:10] [valid] Ep. 10 : Up. 800000 : perplexity : 7.35005 : new best
[2019-07-20 04:39:03] [valid] Ep. 10 : Up. 800000 : translation : 25.56 : new best
[2019-07-20 04:45:25] Ep. 10 : Up. 802000 : Sen. 9,851,876 : Cost 62.32196808 : Time 474.28s : 12931.85 words/s
[2019-07-20 04:51:44] Ep. 10 : Up. 804000 : Sen. 10,140,597 : Cost 62.35650253 : Time 378.85s : 16097.02 words/s
[2019-07-20 04:58:04] Ep. 10 : Up. 806000 : Sen. 10,430,321 : Cost 62.50236130 : Time 379.44s : 16127.36 words/s
[2019-07-20 05:04:24] Ep. 10 : Up. 808000 : Sen. 10,720,478 : Cost 62.10690689 : Time 379.98s : 16104.23 words/s
[2019-07-20 05:10:43] Ep. 10 : Up. 810000 : Sen. 11,009,705 : Cost 62.32073212 : Time 379.25s : 16100.66 words/s
[2019-07-20 05:17:04] Ep. 10 : Up. 812000 : Sen. 11,300,302 : Cost 62.41465759 : Time 381.33s : 16099.10 words/s
[2019-07-20 05:23:25] Ep. 10 : Up. 814000 : Sen. 11,590,004 : Cost 62.36654282 : Time 380.50s : 16086.93 words/s
[2019-07-20 05:27:54] Seen 11795613 samples
[2019-07-20 05:27:54] Starting epoch 11
[2019-07-20 05:27:54] [data] Shuffling data
[2019-07-20 05:28:03] [data] Done reading 13926791 sentences
[2019-07-20 05:29:11] [data] Done shuffling 13926791 sentences to temp files
[2019-07-20 05:31:04] Ep. 11 : Up. 816000 : Sen. 83,851 : Cost 62.01928329 : Time 459.34s : 13288.85 words/s
[2019-07-20 05:37:23] Ep. 11 : Up. 818000 : Sen. 374,008 : Cost 61.43259811 : Time 379.36s : 16125.22 words/s
[2019-07-20 05:43:43] Ep. 11 : Up. 820000 : Sen. 663,031 : Cost 61.87201691 : Time 379.42s : 16118.24 words/s
[2019-07-20 05:43:43] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.orig.npz
[2019-07-20 05:43:48] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.iter820000.npz
[2019-07-20 05:43:51] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz
[2019-07-20 05:43:56] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.25/model/model.npz.optimizer.npz
[2019-07-20 05:44:15] [valid] Ep. 11 : Up. 820000 : cross-entropy : 50.2133 : new best
[2019-07-20 05:44:21] [valid] Ep. 11 : Up. 820000 : perplexity : 7.31309 : new best
[2019-07-20 05:45:14] [valid] Ep. 11 : Up. 820000 : translation : 25.69 : new best
[2019-07-20 05:51:34] Ep. 11 : Up. 822000 : Sen. 951,227 : Cost 61.51094437 : Time 471.26s : 12893.88 words/s
[2019-07-20 05:57:54] Ep. 11 : Up. 824000 : Sen. 1,240,173 : Cost 61.64677811 : Time 380.10s : 16083.16 words/s
[2019-07-20 06:04:13] Ep. 11 : Up. 826000 : Sen. 1,529,468 : Cost 61.72287750 : Time 378.49s : 16107.31 words/s
[2019-07-20 06:10:34] Ep. 11 : Up. 828000 : Sen. 1,820,167 : Cost 61.55307007 : Time 381.13s : 16087.93 words/s
[2019-07-20 06:16:53] Ep. 11 : Up. 830000 : Sen. 2,109,804 : Cost 61.63421631 : Time 379.44s : 16094.52 words/s
