MT evaluation scorer began on 2019 Jul 13 at 16:21:31
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/10M_fasttext_prob_x_len_+_ced_0.25_x_dcce_ens1/data/globalvoices-2017.de.sgm -r ../experiments/10M_fasttext_prob_x_len_+_ced_0.25_x_dcce_ens1/data/globalvoices-2017.en.sgm -t ../experiments/10M_fasttext_prob_x_len_+_ced_0.25_x_dcce_ens1/data/globalvoices-2017.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 3000 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 1.06821730125856 (67052/62770), penalty (log): 0
NIST score = 6.0529  BLEU score = 0.2049 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.6759   1.1676   0.1875   0.0186   0.0032   0.0005   0.0002   0.0001   0.0000  "Edinburgh"

 BLEU:  0.5150   0.2589   0.1487   0.0889   0.0544   0.0339   0.0212   0.0135   0.0087  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.6759   5.8435   6.0311   6.0497   6.0529   6.0534   6.0536   6.0537   6.0537  "Edinburgh"

 BLEU:  0.5150   0.3652   0.2707   0.2049   0.1572   0.1217   0.0948   0.0744   0.0586  "Edinburgh"
MT evaluation scorer ended on 2019 Jul 13 at 16:21:47
