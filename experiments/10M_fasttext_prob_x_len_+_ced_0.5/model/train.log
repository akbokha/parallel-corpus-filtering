[2019-07-16 19:18:55] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-16 19:18:55] [marian] Running on hodor as process 138411 with command line:
[2019-07-16 19:18:55] [marian] /fs/bil0/abdel/marian-dev/build/marian --sync-sgd --model ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz -T . --devices 2 --train-sets ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/data/train.bpe.de ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/data/train.bpe.en --vocabs ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/data/train.bpe.de.json ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/data/train.bpe.en.json --mini-batch-fit -w 5000 --dim-vocabs 50000 50000 --layer-normalization --dropout-rnn 0.2 --dropout-src 0.1 --dropout-trg 0.1 --learn-rate 0.0001 --after-epochs 0 --early-stopping 5 --valid-freq 20000 --save-freq 20000 --disp-freq 2000 --valid-mini-batch 8 --valid-sets ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/data/dev.bpe.de ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/data/dev.bpe.en --valid-metrics cross-entropy perplexity translation --valid-translation-output ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/dev.out --valid-script-path ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/score-dev.sh --seed 1111 --exponential-smoothing --normalize=1 --beam-size=12 --quiet-translation --log ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/train.log --valid-log ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/valid.log
[2019-07-16 19:18:55] [config] after-batches: 0
[2019-07-16 19:18:55] [config] after-epochs: 0
[2019-07-16 19:18:55] [config] allow-unk: false
[2019-07-16 19:18:55] [config] beam-size: 12
[2019-07-16 19:18:55] [config] bert-class-symbol: "[CLS]"
[2019-07-16 19:18:55] [config] bert-mask-symbol: "[MASK]"
[2019-07-16 19:18:55] [config] bert-masking-fraction: 0.15
[2019-07-16 19:18:55] [config] bert-sep-symbol: "[SEP]"
[2019-07-16 19:18:55] [config] bert-train-type-embeddings: true
[2019-07-16 19:18:55] [config] bert-type-vocab-size: 2
[2019-07-16 19:18:55] [config] best-deep: false
[2019-07-16 19:18:55] [config] clip-gemm: 0
[2019-07-16 19:18:55] [config] clip-norm: 1
[2019-07-16 19:18:55] [config] cost-type: ce-mean
[2019-07-16 19:18:55] [config] cpu-threads: 0
[2019-07-16 19:18:55] [config] data-weighting: ""
[2019-07-16 19:18:55] [config] data-weighting-type: sentence
[2019-07-16 19:18:55] [config] dec-cell: gru
[2019-07-16 19:18:55] [config] dec-cell-base-depth: 2
[2019-07-16 19:18:55] [config] dec-cell-high-depth: 1
[2019-07-16 19:18:55] [config] dec-depth: 1
[2019-07-16 19:18:55] [config] devices:
[2019-07-16 19:18:55] [config]   - 2
[2019-07-16 19:18:55] [config] dim-emb: 512
[2019-07-16 19:18:55] [config] dim-rnn: 1024
[2019-07-16 19:18:55] [config] dim-vocabs:
[2019-07-16 19:18:55] [config]   - 50000
[2019-07-16 19:18:55] [config]   - 50000
[2019-07-16 19:18:55] [config] disp-first: 0
[2019-07-16 19:18:55] [config] disp-freq: 2000
[2019-07-16 19:18:55] [config] disp-label-counts: false
[2019-07-16 19:18:55] [config] dropout-rnn: 0.2
[2019-07-16 19:18:55] [config] dropout-src: 0.1
[2019-07-16 19:18:55] [config] dropout-trg: 0.1
[2019-07-16 19:18:55] [config] dump-config: ""
[2019-07-16 19:18:55] [config] early-stopping: 5
[2019-07-16 19:18:55] [config] embedding-fix-src: false
[2019-07-16 19:18:55] [config] embedding-fix-trg: false
[2019-07-16 19:18:55] [config] embedding-normalization: false
[2019-07-16 19:18:55] [config] embedding-vectors:
[2019-07-16 19:18:55] [config]   []
[2019-07-16 19:18:55] [config] enc-cell: gru
[2019-07-16 19:18:55] [config] enc-cell-depth: 1
[2019-07-16 19:18:55] [config] enc-depth: 1
[2019-07-16 19:18:55] [config] enc-type: bidirectional
[2019-07-16 19:18:55] [config] exponential-smoothing: 0.0001
[2019-07-16 19:18:55] [config] grad-dropping-momentum: 0
[2019-07-16 19:18:55] [config] grad-dropping-rate: 0
[2019-07-16 19:18:55] [config] grad-dropping-warmup: 100
[2019-07-16 19:18:55] [config] guided-alignment: none
[2019-07-16 19:18:55] [config] guided-alignment-cost: mse
[2019-07-16 19:18:55] [config] guided-alignment-weight: 0.1
[2019-07-16 19:18:55] [config] ignore-model-config: false
[2019-07-16 19:18:55] [config] input-types:
[2019-07-16 19:18:55] [config]   []
[2019-07-16 19:18:55] [config] interpolate-env-vars: false
[2019-07-16 19:18:55] [config] keep-best: false
[2019-07-16 19:18:55] [config] label-smoothing: 0
[2019-07-16 19:18:55] [config] layer-normalization: true
[2019-07-16 19:18:55] [config] learn-rate: 0.0001
[2019-07-16 19:18:55] [config] log: ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/train.log
[2019-07-16 19:18:55] [config] log-level: info
[2019-07-16 19:18:55] [config] log-time-zone: ""
[2019-07-16 19:18:55] [config] lr-decay: 0
[2019-07-16 19:18:55] [config] lr-decay-freq: 50000
[2019-07-16 19:18:55] [config] lr-decay-inv-sqrt:
[2019-07-16 19:18:55] [config]   - 0
[2019-07-16 19:18:55] [config] lr-decay-repeat-warmup: false
[2019-07-16 19:18:55] [config] lr-decay-reset-optimizer: false
[2019-07-16 19:18:55] [config] lr-decay-start:
[2019-07-16 19:18:55] [config]   - 10
[2019-07-16 19:18:55] [config]   - 1
[2019-07-16 19:18:55] [config] lr-decay-strategy: epoch+stalled
[2019-07-16 19:18:55] [config] lr-report: false
[2019-07-16 19:18:55] [config] lr-warmup: 0
[2019-07-16 19:18:55] [config] lr-warmup-at-reload: false
[2019-07-16 19:18:55] [config] lr-warmup-cycle: false
[2019-07-16 19:18:55] [config] lr-warmup-start-rate: 0
[2019-07-16 19:18:55] [config] max-length: 50
[2019-07-16 19:18:55] [config] max-length-crop: false
[2019-07-16 19:18:55] [config] max-length-factor: 3
[2019-07-16 19:18:55] [config] maxi-batch: 100
[2019-07-16 19:18:55] [config] maxi-batch-sort: trg
[2019-07-16 19:18:55] [config] mini-batch: 64
[2019-07-16 19:18:55] [config] mini-batch-fit: true
[2019-07-16 19:18:55] [config] mini-batch-fit-step: 10
[2019-07-16 19:18:55] [config] mini-batch-overstuff: 1
[2019-07-16 19:18:55] [config] mini-batch-track-lr: false
[2019-07-16 19:18:55] [config] mini-batch-understuff: 1
[2019-07-16 19:18:55] [config] mini-batch-warmup: 0
[2019-07-16 19:18:55] [config] mini-batch-words: 0
[2019-07-16 19:18:55] [config] mini-batch-words-ref: 0
[2019-07-16 19:18:55] [config] model: ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-16 19:18:55] [config] multi-loss-type: sum
[2019-07-16 19:18:55] [config] multi-node: false
[2019-07-16 19:18:55] [config] multi-node-overlap: true
[2019-07-16 19:18:55] [config] n-best: false
[2019-07-16 19:18:55] [config] no-nccl: false
[2019-07-16 19:18:55] [config] no-reload: false
[2019-07-16 19:18:55] [config] no-restore-corpus: false
[2019-07-16 19:18:55] [config] no-shuffle: false
[2019-07-16 19:18:55] [config] normalize: 1
[2019-07-16 19:18:55] [config] num-devices: 0
[2019-07-16 19:18:55] [config] optimizer: adam
[2019-07-16 19:18:55] [config] optimizer-delay: 1
[2019-07-16 19:18:55] [config] optimizer-params:
[2019-07-16 19:18:55] [config]   []
[2019-07-16 19:18:55] [config] overwrite: false
[2019-07-16 19:18:55] [config] pretrained-model: ""
[2019-07-16 19:18:55] [config] quiet: false
[2019-07-16 19:18:55] [config] quiet-translation: true
[2019-07-16 19:18:55] [config] relative-paths: false
[2019-07-16 19:18:55] [config] right-left: false
[2019-07-16 19:18:55] [config] save-freq: 20000
[2019-07-16 19:18:55] [config] seed: 1111
[2019-07-16 19:18:55] [config] shuffle-in-ram: false
[2019-07-16 19:18:55] [config] skip: false
[2019-07-16 19:18:55] [config] sqlite: ""
[2019-07-16 19:18:55] [config] sqlite-drop: false
[2019-07-16 19:18:55] [config] sync-sgd: true
[2019-07-16 19:18:55] [config] tempdir: .
[2019-07-16 19:18:55] [config] tied-embeddings: false
[2019-07-16 19:18:55] [config] tied-embeddings-all: false
[2019-07-16 19:18:55] [config] tied-embeddings-src: false
[2019-07-16 19:18:55] [config] train-sets:
[2019-07-16 19:18:55] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/data/train.bpe.de
[2019-07-16 19:18:55] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/data/train.bpe.en
[2019-07-16 19:18:55] [config] transformer-aan-activation: swish
[2019-07-16 19:18:55] [config] transformer-aan-depth: 2
[2019-07-16 19:18:55] [config] transformer-aan-nogate: false
[2019-07-16 19:18:55] [config] transformer-decoder-autoreg: self-attention
[2019-07-16 19:18:55] [config] transformer-dim-aan: 2048
[2019-07-16 19:18:55] [config] transformer-dim-ffn: 2048
[2019-07-16 19:18:55] [config] transformer-dropout: 0
[2019-07-16 19:18:55] [config] transformer-dropout-attention: 0
[2019-07-16 19:18:55] [config] transformer-dropout-ffn: 0
[2019-07-16 19:18:55] [config] transformer-ffn-activation: swish
[2019-07-16 19:18:55] [config] transformer-ffn-depth: 2
[2019-07-16 19:18:55] [config] transformer-guided-alignment-layer: last
[2019-07-16 19:18:55] [config] transformer-heads: 8
[2019-07-16 19:18:55] [config] transformer-no-projection: false
[2019-07-16 19:18:55] [config] transformer-postprocess: dan
[2019-07-16 19:18:55] [config] transformer-postprocess-emb: d
[2019-07-16 19:18:55] [config] transformer-preprocess: ""
[2019-07-16 19:18:55] [config] transformer-tied-layers:
[2019-07-16 19:18:55] [config]   []
[2019-07-16 19:18:55] [config] transformer-train-position-embeddings: false
[2019-07-16 19:18:55] [config] type: amun
[2019-07-16 19:18:55] [config] ulr: false
[2019-07-16 19:18:55] [config] ulr-dim-emb: 0
[2019-07-16 19:18:55] [config] ulr-dropout: 0
[2019-07-16 19:18:55] [config] ulr-keys-vectors: ""
[2019-07-16 19:18:55] [config] ulr-query-vectors: ""
[2019-07-16 19:18:55] [config] ulr-softmax-temperature: 1
[2019-07-16 19:18:55] [config] ulr-trainable-transformation: false
[2019-07-16 19:18:55] [config] valid-freq: 20000
[2019-07-16 19:18:55] [config] valid-log: ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/valid.log
[2019-07-16 19:18:55] [config] valid-max-length: 1000
[2019-07-16 19:18:55] [config] valid-metrics:
[2019-07-16 19:18:55] [config]   - cross-entropy
[2019-07-16 19:18:55] [config]   - perplexity
[2019-07-16 19:18:55] [config]   - translation
[2019-07-16 19:18:55] [config] valid-mini-batch: 8
[2019-07-16 19:18:55] [config] valid-script-path: ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/score-dev.sh
[2019-07-16 19:18:55] [config] valid-sets:
[2019-07-16 19:18:55] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/data/dev.bpe.de
[2019-07-16 19:18:55] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/data/dev.bpe.en
[2019-07-16 19:18:55] [config] valid-translation-output: ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/dev.out
[2019-07-16 19:18:55] [config] vocabs:
[2019-07-16 19:18:55] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/data/train.bpe.de.json
[2019-07-16 19:18:55] [config]   - ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/data/train.bpe.en.json
[2019-07-16 19:18:55] [config] word-penalty: 0
[2019-07-16 19:18:55] [config] workspace: 5000
[2019-07-16 19:18:55] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-16 19:18:55] Using synchronous training
[2019-07-16 19:18:55] [data] Loading vocabulary from JSON/Yaml file ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/data/train.bpe.de.json
[2019-07-16 19:18:56] [data] Using unused word id eos for 0
[2019-07-16 19:18:56] [data] Using unused word id UNK for 1
[2019-07-16 19:18:56] [data] Setting vocabulary size for input 0 to 50000
[2019-07-16 19:18:56] [data] Loading vocabulary from JSON/Yaml file ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/data/train.bpe.en.json
[2019-07-16 19:18:56] [data] Using unused word id eos for 0
[2019-07-16 19:18:56] [data] Using unused word id UNK for 1
[2019-07-16 19:18:56] [data] Setting vocabulary size for input 1 to 50000
[2019-07-16 19:18:56] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-16 19:18:56] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-16 19:18:57] [memory] Extending reserved space to 5120 MB (device gpu2)
[2019-07-16 19:18:57] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-16 19:18:57] [comm] NCCLCommunicator constructed successfully.
[2019-07-16 19:18:57] [training] Using 1 GPUs
[2019-07-16 19:18:57] [memory] Reserving 422 MB, device gpu2
[2019-07-16 19:18:57] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-16 19:18:57] [memory] Reserving 422 MB, device gpu2
[2019-07-16 19:19:06] [batching] Done. Typical MB size is 6880 target words
[2019-07-16 19:19:06] [memory] Extending reserved space to 5120 MB (device gpu2)
[2019-07-16 19:19:06] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-16 19:19:06] [comm] NCCLCommunicator constructed successfully.
[2019-07-16 19:19:06] [training] Using 1 GPUs
[2019-07-16 19:19:06] Training started
[2019-07-16 19:19:06] [data] Shuffling data
[2019-07-16 19:19:15] [data] Done reading 13926791 sentences
[2019-07-16 19:20:34] [data] Done shuffling 13926791 sentences to temp files
[2019-07-16 19:28:35] [training] Batches are processed as 1 process(es) x 1 devices/process
[2019-07-16 19:28:35] [memory] Reserving 422 MB, device gpu2
[2019-07-16 19:28:35] [memory] Reserving 422 MB, device gpu2
[2019-07-16 19:28:35] [memory] Reserving 422 MB, device gpu2
[2019-07-16 19:28:35] [memory] Reserving 844 MB, device gpu2
[2019-07-16 19:42:12] Ep. 1 : Up. 2000 : Sen. 288,980 : Cost 136.62452698 : Time 1396.09s : 4359.68 words/s
[2019-07-16 19:55:59] Ep. 1 : Up. 4000 : Sen. 578,204 : Cost 119.16773224 : Time 826.45s : 7409.96 words/s
[2019-07-16 20:09:45] Ep. 1 : Up. 6000 : Sen. 867,195 : Cost 110.65970612 : Time 826.13s : 7384.02 words/s
[2019-07-16 20:23:32] Ep. 1 : Up. 8000 : Sen. 1,156,773 : Cost 104.72293091 : Time 826.99s : 7376.25 words/s
[2019-07-16 20:37:16] Ep. 1 : Up. 10000 : Sen. 1,446,400 : Cost 101.09782410 : Time 824.53s : 7428.55 words/s
[2019-07-16 20:50:58] Ep. 1 : Up. 12000 : Sen. 1,735,540 : Cost 97.63807678 : Time 821.85s : 7426.62 words/s
[2019-07-16 21:04:40] Ep. 1 : Up. 14000 : Sen. 2,024,932 : Cost 94.92061615 : Time 821.84s : 7434.00 words/s
[2019-07-16 21:18:22] Ep. 1 : Up. 16000 : Sen. 2,313,850 : Cost 92.86993408 : Time 821.53s : 7432.15 words/s
[2019-07-16 21:32:05] Ep. 1 : Up. 18000 : Sen. 2,603,358 : Cost 90.79431152 : Time 823.03s : 7430.78 words/s
[2019-07-16 21:45:48] Ep. 1 : Up. 20000 : Sen. 2,893,081 : Cost 89.36719513 : Time 823.73s : 7435.59 words/s
[2019-07-16 21:45:48] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-16 21:45:58] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter20000.npz
[2019-07-16 21:46:04] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-16 21:46:13] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-16 21:46:36] [valid] Ep. 1 : Up. 20000 : cross-entropy : 90.349 : new best
[2019-07-16 21:46:44] [valid] Ep. 1 : Up. 20000 : perplexity : 35.8756 : new best
[2019-07-16 21:48:06] [valid] Ep. 1 : Up. 20000 : translation : 12.28 : new best
[2019-07-16 22:01:50] Ep. 1 : Up. 22000 : Sen. 3,182,468 : Cost 87.83905029 : Time 961.27s : 6351.98 words/s
[2019-07-16 22:15:29] Ep. 1 : Up. 24000 : Sen. 3,470,162 : Cost 86.87938690 : Time 819.05s : 7426.85 words/s
[2019-07-16 22:29:08] Ep. 1 : Up. 26000 : Sen. 3,759,351 : Cost 85.33298492 : Time 818.85s : 7448.48 words/s
[2019-07-16 22:42:47] Ep. 1 : Up. 28000 : Sen. 4,047,723 : Cost 84.48619843 : Time 819.06s : 7428.28 words/s
[2019-07-16 22:56:27] Ep. 1 : Up. 30000 : Sen. 4,336,492 : Cost 84.10002136 : Time 820.67s : 7453.49 words/s
[2019-07-16 23:10:10] Ep. 1 : Up. 32000 : Sen. 4,626,630 : Cost 82.78398895 : Time 823.07s : 7434.91 words/s
[2019-07-16 23:23:52] Ep. 1 : Up. 34000 : Sen. 4,916,290 : Cost 82.29768372 : Time 821.94s : 7442.62 words/s
[2019-07-16 23:37:34] Ep. 1 : Up. 36000 : Sen. 5,205,537 : Cost 81.53311920 : Time 821.89s : 7428.39 words/s
[2019-07-16 23:51:12] Ep. 1 : Up. 38000 : Sen. 5,492,818 : Cost 80.97732544 : Time 817.76s : 7411.89 words/s
[2019-07-17 00:04:54] Ep. 1 : Up. 40000 : Sen. 5,782,148 : Cost 80.28613281 : Time 821.86s : 7436.37 words/s
[2019-07-17 00:04:54] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-17 00:05:03] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter40000.npz
[2019-07-17 00:05:10] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-17 00:05:20] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-17 00:05:43] [valid] Ep. 1 : Up. 40000 : cross-entropy : 72.8121 : new best
[2019-07-17 00:05:51] [valid] Ep. 1 : Up. 40000 : perplexity : 17.9065 : new best
[2019-07-17 00:07:01] [valid] Ep. 1 : Up. 40000 : translation : 19.71 : new best
[2019-07-17 00:20:42] Ep. 1 : Up. 42000 : Sen. 6,070,775 : Cost 79.88948822 : Time 948.23s : 6423.72 words/s
[2019-07-17 00:34:22] Ep. 1 : Up. 44000 : Sen. 6,359,473 : Cost 79.44146729 : Time 819.41s : 7433.84 words/s
[2019-07-17 00:48:00] Ep. 1 : Up. 46000 : Sen. 6,646,841 : Cost 79.19536591 : Time 818.01s : 7424.91 words/s
[2019-07-17 01:01:39] Ep. 1 : Up. 48000 : Sen. 6,936,012 : Cost 78.38624573 : Time 819.66s : 7428.86 words/s
[2019-07-17 01:15:20] Ep. 1 : Up. 50000 : Sen. 7,225,030 : Cost 78.05609894 : Time 821.05s : 7432.34 words/s
[2019-07-17 01:29:02] Ep. 1 : Up. 52000 : Sen. 7,514,444 : Cost 77.93701935 : Time 821.98s : 7452.72 words/s
[2019-07-17 01:42:42] Ep. 1 : Up. 54000 : Sen. 7,804,046 : Cost 77.27222443 : Time 819.38s : 7449.49 words/s
[2019-07-17 01:56:23] Ep. 1 : Up. 56000 : Sen. 8,092,764 : Cost 77.37424469 : Time 821.19s : 7447.21 words/s
[2019-07-17 02:10:01] Ep. 1 : Up. 58000 : Sen. 8,382,362 : Cost 76.54847717 : Time 818.44s : 7456.86 words/s
[2019-07-17 02:23:43] Ep. 1 : Up. 60000 : Sen. 8,670,900 : Cost 76.43180084 : Time 821.27s : 7428.53 words/s
[2019-07-17 02:23:43] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-17 02:23:51] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter60000.npz
[2019-07-17 02:23:58] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-17 02:24:07] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-17 02:24:30] [valid] Ep. 1 : Up. 60000 : cross-entropy : 65.8003 : new best
[2019-07-17 02:24:38] [valid] Ep. 1 : Up. 60000 : perplexity : 13.5627 : new best
[2019-07-17 02:25:46] [valid] Ep. 1 : Up. 60000 : translation : 22.01 : new best
[2019-07-17 02:39:28] Ep. 1 : Up. 62000 : Sen. 8,959,398 : Cost 76.28929138 : Time 945.93s : 6457.26 words/s
[2019-07-17 02:53:12] Ep. 1 : Up. 64000 : Sen. 9,248,575 : Cost 75.99856567 : Time 823.21s : 7417.13 words/s
[2019-07-17 03:06:55] Ep. 1 : Up. 66000 : Sen. 9,537,777 : Cost 75.94011688 : Time 823.27s : 7434.61 words/s
[2019-07-17 03:20:34] Ep. 1 : Up. 68000 : Sen. 9,827,260 : Cost 75.09325409 : Time 819.29s : 7428.85 words/s
[2019-07-17 03:34:21] Ep. 1 : Up. 70000 : Sen. 10,118,400 : Cost 75.31320953 : Time 827.09s : 7444.13 words/s
[2019-07-17 03:48:04] Ep. 1 : Up. 72000 : Sen. 10,408,567 : Cost 74.94480896 : Time 822.58s : 7438.55 words/s
[2019-07-17 04:01:43] Ep. 1 : Up. 74000 : Sen. 10,697,490 : Cost 74.56430817 : Time 819.46s : 7437.79 words/s
[2019-07-17 04:15:28] Ep. 1 : Up. 76000 : Sen. 10,987,778 : Cost 74.48430634 : Time 824.91s : 7438.07 words/s
[2019-07-17 04:29:14] Ep. 1 : Up. 78000 : Sen. 11,278,400 : Cost 74.19329071 : Time 825.64s : 7425.85 words/s
[2019-07-17 04:42:57] Ep. 1 : Up. 80000 : Sen. 11,567,590 : Cost 74.13132477 : Time 823.34s : 7430.83 words/s
[2019-07-17 04:42:57] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-17 04:43:08] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter80000.npz
[2019-07-17 04:43:14] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-17 04:43:23] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-17 04:43:47] [valid] Ep. 1 : Up. 80000 : cross-entropy : 61.9437 : new best
[2019-07-17 04:43:55] [valid] Ep. 1 : Up. 80000 : perplexity : 11.6407 : new best
[2019-07-17 04:45:01] [valid] Ep. 1 : Up. 80000 : translation : 23.2 : new best
[2019-07-17 04:55:51] Seen 11795642 samples
[2019-07-17 04:55:51] Starting epoch 2
[2019-07-17 04:55:51] [data] Shuffling data
[2019-07-17 04:55:58] [data] Done reading 13926791 sentences
[2019-07-17 04:56:54] [data] Done shuffling 13926791 sentences to temp files
[2019-07-17 04:59:51] Ep. 2 : Up. 82000 : Sen. 60,410 : Cost 73.61170197 : Time 1013.50s : 6003.09 words/s
[2019-07-17 05:13:36] Ep. 2 : Up. 84000 : Sen. 349,577 : Cost 73.21417236 : Time 825.18s : 7403.09 words/s
[2019-07-17 05:27:19] Ep. 2 : Up. 86000 : Sen. 638,748 : Cost 72.79898071 : Time 822.84s : 7412.00 words/s
[2019-07-17 05:41:02] Ep. 2 : Up. 88000 : Sen. 927,107 : Cost 72.82216644 : Time 823.37s : 7403.56 words/s
[2019-07-17 05:54:45] Ep. 2 : Up. 90000 : Sen. 1,215,778 : Cost 72.65888977 : Time 822.79s : 7412.49 words/s
[2019-07-17 06:08:32] Ep. 2 : Up. 92000 : Sen. 1,505,435 : Cost 72.47507477 : Time 827.31s : 7396.29 words/s
[2019-07-17 06:22:17] Ep. 2 : Up. 94000 : Sen. 1,795,155 : Cost 72.24263763 : Time 824.88s : 7415.26 words/s
[2019-07-17 06:36:00] Ep. 2 : Up. 96000 : Sen. 2,083,865 : Cost 72.03442383 : Time 823.24s : 7409.62 words/s
[2019-07-17 06:49:43] Ep. 2 : Up. 98000 : Sen. 2,373,740 : Cost 71.76277161 : Time 822.86s : 7427.57 words/s
[2019-07-17 07:03:29] Ep. 2 : Up. 100000 : Sen. 2,662,865 : Cost 72.10218048 : Time 825.30s : 7403.67 words/s
[2019-07-17 07:03:29] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-17 07:03:41] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter100000.npz
[2019-07-17 07:03:49] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-17 07:03:59] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-17 07:04:22] [valid] Ep. 2 : Up. 100000 : cross-entropy : 59.5456 : new best
[2019-07-17 07:04:30] [valid] Ep. 2 : Up. 100000 : perplexity : 10.5854 : new best
[2019-07-17 07:05:37] [valid] Ep. 2 : Up. 100000 : translation : 23.75 : new best
[2019-07-17 07:19:21] Ep. 2 : Up. 102000 : Sen. 2,951,874 : Cost 72.00003815 : Time 952.22s : 6410.96 words/s
[2019-07-17 07:33:04] Ep. 2 : Up. 104000 : Sen. 3,241,797 : Cost 71.74525452 : Time 823.43s : 7435.20 words/s
[2019-07-17 07:46:45] Ep. 2 : Up. 106000 : Sen. 3,530,776 : Cost 71.67417145 : Time 821.18s : 7442.29 words/s
[2019-07-17 08:00:28] Ep. 2 : Up. 108000 : Sen. 3,819,694 : Cost 71.70529175 : Time 822.60s : 7427.63 words/s
[2019-07-17 08:14:10] Ep. 2 : Up. 110000 : Sen. 4,109,642 : Cost 71.12937927 : Time 822.11s : 7430.69 words/s
[2019-07-17 08:28:14] Ep. 2 : Up. 112000 : Sen. 4,398,482 : Cost 71.20397186 : Time 843.90s : 7238.45 words/s
[2019-07-17 08:41:54] Ep. 2 : Up. 114000 : Sen. 4,687,361 : Cost 71.20008087 : Time 820.23s : 7439.11 words/s
[2019-07-17 08:55:37] Ep. 2 : Up. 116000 : Sen. 4,977,397 : Cost 70.83625793 : Time 822.67s : 7427.96 words/s
[2019-07-17 09:09:19] Ep. 2 : Up. 118000 : Sen. 5,266,804 : Cost 71.16506195 : Time 822.34s : 7445.79 words/s
[2019-07-17 09:23:03] Ep. 2 : Up. 120000 : Sen. 5,556,778 : Cost 71.16334534 : Time 823.86s : 7439.15 words/s
[2019-07-17 09:23:03] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-17 09:23:12] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter120000.npz
[2019-07-17 09:23:18] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-17 09:23:27] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-17 09:23:57] [valid] Ep. 2 : Up. 120000 : cross-entropy : 57.7754 : new best
[2019-07-17 09:24:05] [valid] Ep. 2 : Up. 120000 : perplexity : 9.8684 : new best
[2019-07-17 09:25:12] [valid] Ep. 2 : Up. 120000 : translation : 23.93 : new best
[2019-07-17 09:38:55] Ep. 2 : Up. 122000 : Sen. 5,846,025 : Cost 70.73973083 : Time 951.77s : 6420.82 words/s
[2019-07-17 09:52:34] Ep. 2 : Up. 124000 : Sen. 6,135,253 : Cost 70.66624451 : Time 819.63s : 7444.73 words/s
[2019-07-17 10:06:14] Ep. 2 : Up. 126000 : Sen. 6,423,918 : Cost 70.30908966 : Time 819.60s : 7432.06 words/s
[2019-07-17 10:19:58] Ep. 2 : Up. 128000 : Sen. 6,712,684 : Cost 70.56787109 : Time 824.12s : 7411.73 words/s
[2019-07-17 10:33:42] Ep. 2 : Up. 130000 : Sen. 7,001,732 : Cost 70.39695740 : Time 824.08s : 7409.84 words/s
[2019-07-17 10:47:29] Ep. 2 : Up. 132000 : Sen. 7,292,187 : Cost 70.23033905 : Time 826.35s : 7425.57 words/s
[2019-07-17 11:01:14] Ep. 2 : Up. 134000 : Sen. 7,581,804 : Cost 70.00615692 : Time 825.32s : 7398.84 words/s
[2019-07-17 11:14:58] Ep. 2 : Up. 136000 : Sen. 7,870,488 : Cost 70.28710938 : Time 823.69s : 7406.58 words/s
[2019-07-17 11:28:41] Ep. 2 : Up. 138000 : Sen. 8,160,536 : Cost 69.84732056 : Time 823.79s : 7423.37 words/s
[2019-07-17 11:42:23] Ep. 2 : Up. 140000 : Sen. 8,449,374 : Cost 69.94077301 : Time 821.60s : 7410.44 words/s
[2019-07-17 11:42:23] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-17 11:42:31] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter140000.npz
[2019-07-17 11:42:38] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-17 11:42:48] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-17 11:43:11] [valid] Ep. 2 : Up. 140000 : cross-entropy : 56.4733 : new best
[2019-07-17 11:43:19] [valid] Ep. 2 : Up. 140000 : perplexity : 9.37212 : new best
[2019-07-17 11:44:27] [valid] Ep. 2 : Up. 140000 : translation : 24.18 : new best
[2019-07-17 11:58:12] Ep. 2 : Up. 142000 : Sen. 8,739,039 : Cost 69.85530090 : Time 948.76s : 6460.31 words/s
[2019-07-17 12:11:54] Ep. 2 : Up. 144000 : Sen. 9,028,525 : Cost 69.70816040 : Time 822.25s : 7432.05 words/s
[2019-07-17 12:25:34] Ep. 2 : Up. 146000 : Sen. 9,316,786 : Cost 69.75769043 : Time 820.19s : 7429.88 words/s
[2019-07-17 12:39:16] Ep. 2 : Up. 148000 : Sen. 9,605,740 : Cost 69.60867310 : Time 821.43s : 7413.12 words/s
[2019-07-17 12:52:59] Ep. 2 : Up. 150000 : Sen. 9,894,532 : Cost 69.97401428 : Time 823.31s : 7426.90 words/s
[2019-07-17 13:06:42] Ep. 2 : Up. 152000 : Sen. 10,184,073 : Cost 69.37326050 : Time 822.85s : 7424.37 words/s
[2019-07-17 13:20:25] Ep. 2 : Up. 154000 : Sen. 10,473,354 : Cost 69.59738922 : Time 823.34s : 7424.72 words/s
[2019-07-17 13:34:09] Ep. 2 : Up. 156000 : Sen. 10,762,665 : Cost 68.97890472 : Time 823.70s : 7393.31 words/s
[2019-07-17 13:47:54] Ep. 2 : Up. 158000 : Sen. 11,052,008 : Cost 69.12144470 : Time 824.95s : 7409.24 words/s
[2019-07-17 14:01:40] Ep. 2 : Up. 160000 : Sen. 11,341,996 : Cost 69.12372589 : Time 826.15s : 7406.57 words/s
[2019-07-17 14:01:40] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-17 14:01:48] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter160000.npz
[2019-07-17 14:01:55] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-17 14:02:04] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-17 14:02:29] [valid] Ep. 2 : Up. 160000 : cross-entropy : 55.4458 : new best
[2019-07-17 14:02:36] [valid] Ep. 2 : Up. 160000 : perplexity : 8.99822 : new best
[2019-07-17 14:03:44] [valid] Ep. 2 : Up. 160000 : translation : 24.46 : new best
[2019-07-17 14:17:28] Ep. 2 : Up. 162000 : Sen. 11,631,223 : Cost 69.00500488 : Time 948.35s : 6429.61 words/s
[2019-07-17 14:25:17] Seen 11795642 samples
[2019-07-17 14:25:17] Starting epoch 3
[2019-07-17 14:25:17] [data] Shuffling data
[2019-07-17 14:25:25] [data] Done reading 13926791 sentences
[2019-07-17 14:26:25] [data] Done shuffling 13926791 sentences to temp files
[2019-07-17 14:32:23] Ep. 3 : Up. 164000 : Sen. 124,299 : Cost 68.56048584 : Time 894.71s : 6804.14 words/s
[2019-07-17 14:46:08] Ep. 3 : Up. 166000 : Sen. 412,997 : Cost 68.38823700 : Time 825.18s : 7400.06 words/s
[2019-07-17 14:59:52] Ep. 3 : Up. 168000 : Sen. 701,894 : Cost 68.12295532 : Time 824.08s : 7404.20 words/s
[2019-07-17 15:13:35] Ep. 3 : Up. 170000 : Sen. 990,672 : Cost 68.30613708 : Time 822.52s : 7427.62 words/s
[2019-07-17 15:27:21] Ep. 3 : Up. 172000 : Sen. 1,280,396 : Cost 68.04550171 : Time 826.01s : 7408.97 words/s
[2019-07-17 15:41:05] Ep. 3 : Up. 174000 : Sen. 1,570,270 : Cost 68.21260071 : Time 824.60s : 7420.67 words/s
[2019-07-17 15:54:48] Ep. 3 : Up. 176000 : Sen. 1,859,977 : Cost 68.10139465 : Time 822.47s : 7435.25 words/s
[2019-07-17 16:08:32] Ep. 3 : Up. 178000 : Sen. 2,150,004 : Cost 68.01539612 : Time 824.43s : 7407.59 words/s
[2019-07-17 16:22:16] Ep. 3 : Up. 180000 : Sen. 2,438,796 : Cost 68.25176239 : Time 823.97s : 7416.73 words/s
[2019-07-17 16:22:16] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-17 16:22:26] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter180000.npz
[2019-07-17 16:22:32] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-17 16:22:41] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-17 16:23:06] [valid] Ep. 3 : Up. 180000 : cross-entropy : 54.7912 : new best
[2019-07-17 16:23:13] [valid] Ep. 3 : Up. 180000 : perplexity : 8.76782 : new best
[2019-07-17 16:24:21] [valid] Ep. 3 : Up. 180000 : translation : 24.33 : stalled 1 times (last best: 24.46)
[2019-07-17 16:38:06] Ep. 3 : Up. 182000 : Sen. 2,727,131 : Cost 67.99961090 : Time 950.05s : 6415.67 words/s
[2019-07-17 16:51:51] Ep. 3 : Up. 184000 : Sen. 3,016,122 : Cost 68.12815857 : Time 824.57s : 7405.90 words/s
[2019-07-17 17:05:31] Ep. 3 : Up. 186000 : Sen. 3,304,864 : Cost 67.91064453 : Time 820.33s : 7417.84 words/s
[2019-07-17 17:19:15] Ep. 3 : Up. 188000 : Sen. 3,594,555 : Cost 68.03187561 : Time 823.85s : 7446.00 words/s
[2019-07-17 17:33:00] Ep. 3 : Up. 190000 : Sen. 3,884,619 : Cost 67.90557861 : Time 825.04s : 7423.45 words/s
[2019-07-17 17:46:44] Ep. 3 : Up. 192000 : Sen. 4,174,975 : Cost 67.60050201 : Time 823.87s : 7421.02 words/s
[2019-07-17 18:00:27] Ep. 3 : Up. 194000 : Sen. 4,464,227 : Cost 67.73016357 : Time 823.31s : 7418.66 words/s
[2019-07-17 18:14:12] Ep. 3 : Up. 196000 : Sen. 4,753,299 : Cost 68.01105499 : Time 825.07s : 7410.04 words/s
[2019-07-17 18:27:50] Ep. 3 : Up. 198000 : Sen. 5,042,672 : Cost 67.68650055 : Time 817.97s : 7452.08 words/s
[2019-07-17 18:41:30] Ep. 3 : Up. 200000 : Sen. 5,331,644 : Cost 67.54775238 : Time 819.51s : 7435.55 words/s
[2019-07-17 18:41:30] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-17 18:41:39] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter200000.npz
[2019-07-17 18:41:46] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-17 18:41:55] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-17 18:42:18] [valid] Ep. 3 : Up. 200000 : cross-entropy : 54.2973 : new best
[2019-07-17 18:42:26] [valid] Ep. 3 : Up. 200000 : perplexity : 8.59789 : new best
[2019-07-17 18:43:33] [valid] Ep. 3 : Up. 200000 : translation : 24.7 : new best
[2019-07-17 18:57:22] Ep. 3 : Up. 202000 : Sen. 5,620,847 : Cost 67.69783020 : Time 951.75s : 6424.05 words/s
[2019-07-17 19:11:08] Ep. 3 : Up. 204000 : Sen. 5,910,226 : Cost 67.84300995 : Time 826.61s : 7414.96 words/s
[2019-07-17 19:24:51] Ep. 3 : Up. 206000 : Sen. 6,199,316 : Cost 67.44494629 : Time 823.17s : 7407.94 words/s
[2019-07-17 19:38:34] Ep. 3 : Up. 208000 : Sen. 6,489,336 : Cost 67.47077179 : Time 822.99s : 7442.03 words/s
[2019-07-17 19:52:20] Ep. 3 : Up. 210000 : Sen. 6,779,001 : Cost 67.47630310 : Time 825.91s : 7419.04 words/s
[2019-07-17 20:06:06] Ep. 3 : Up. 212000 : Sen. 7,068,633 : Cost 67.28771973 : Time 825.27s : 7400.71 words/s
[2019-07-17 20:19:51] Ep. 3 : Up. 214000 : Sen. 7,358,116 : Cost 67.70753479 : Time 825.30s : 7410.38 words/s
[2019-07-17 20:33:34] Ep. 3 : Up. 216000 : Sen. 7,646,811 : Cost 67.27250671 : Time 823.37s : 7397.34 words/s
[2019-07-17 20:47:17] Ep. 3 : Up. 218000 : Sen. 7,936,347 : Cost 67.15679932 : Time 822.65s : 7420.39 words/s
[2019-07-17 21:01:02] Ep. 3 : Up. 220000 : Sen. 8,226,294 : Cost 67.31976318 : Time 825.20s : 7415.33 words/s
[2019-07-17 21:01:02] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-17 21:01:11] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter220000.npz
[2019-07-17 21:01:18] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-17 21:01:27] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-17 21:01:55] [valid] Ep. 3 : Up. 220000 : cross-entropy : 53.7342 : new best
[2019-07-17 21:02:03] [valid] Ep. 3 : Up. 220000 : perplexity : 8.40819 : new best
[2019-07-17 21:03:10] [valid] Ep. 3 : Up. 220000 : translation : 24.61 : stalled 1 times (last best: 24.7)
[2019-07-17 21:16:55] Ep. 3 : Up. 222000 : Sen. 8,514,953 : Cost 67.24191284 : Time 952.54s : 6403.30 words/s
[2019-07-17 21:30:36] Ep. 3 : Up. 224000 : Sen. 8,803,936 : Cost 67.28440094 : Time 821.62s : 7420.74 words/s
[2019-07-17 21:44:19] Ep. 3 : Up. 226000 : Sen. 9,093,608 : Cost 66.99916077 : Time 823.03s : 7415.73 words/s
[2019-07-17 21:58:01] Ep. 3 : Up. 228000 : Sen. 9,382,004 : Cost 67.24056244 : Time 821.31s : 7419.38 words/s
[2019-07-17 22:11:44] Ep. 3 : Up. 230000 : Sen. 9,671,634 : Cost 67.17304993 : Time 823.66s : 7431.51 words/s
[2019-07-17 22:25:27] Ep. 3 : Up. 232000 : Sen. 9,961,351 : Cost 67.00343323 : Time 823.17s : 7425.95 words/s
[2019-07-17 22:39:10] Ep. 3 : Up. 234000 : Sen. 10,250,531 : Cost 67.31454468 : Time 823.10s : 7429.10 words/s
[2019-07-17 22:52:52] Ep. 3 : Up. 236000 : Sen. 10,540,071 : Cost 66.90386200 : Time 821.90s : 7424.90 words/s
[2019-07-17 23:06:37] Ep. 3 : Up. 238000 : Sen. 10,828,494 : Cost 67.03627777 : Time 824.54s : 7398.80 words/s
[2019-07-17 23:20:25] Ep. 3 : Up. 240000 : Sen. 11,117,064 : Cost 67.05963135 : Time 828.37s : 7368.20 words/s
[2019-07-17 23:20:25] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-17 23:20:34] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter240000.npz
[2019-07-17 23:20:41] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-17 23:20:50] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-17 23:21:14] [valid] Ep. 3 : Up. 240000 : cross-entropy : 53.1625 : new best
[2019-07-17 23:21:22] [valid] Ep. 3 : Up. 240000 : perplexity : 8.21984 : new best
[2019-07-17 23:22:29] [valid] Ep. 3 : Up. 240000 : translation : 25.04 : new best
[2019-07-17 23:36:10] Ep. 3 : Up. 242000 : Sen. 11,405,328 : Cost 67.00415802 : Time 944.73s : 6453.99 words/s
[2019-07-17 23:49:53] Ep. 3 : Up. 244000 : Sen. 11,693,502 : Cost 66.81100464 : Time 822.63s : 7380.09 words/s
[2019-07-17 23:54:42] Seen 11795642 samples
[2019-07-17 23:54:42] Starting epoch 4
[2019-07-17 23:54:42] [data] Shuffling data
[2019-07-17 23:54:50] [data] Done reading 13926791 sentences
[2019-07-17 23:56:07] [data] Done shuffling 13926791 sentences to temp files
[2019-07-18 00:04:59] Ep. 4 : Up. 246000 : Sen. 186,128 : Cost 66.28433228 : Time 906.70s : 6712.03 words/s
[2019-07-18 00:18:43] Ep. 4 : Up. 248000 : Sen. 475,813 : Cost 65.90098572 : Time 823.81s : 7422.91 words/s
[2019-07-18 00:32:27] Ep. 4 : Up. 250000 : Sen. 765,530 : Cost 66.05545044 : Time 824.17s : 7414.82 words/s
[2019-07-18 00:46:13] Ep. 4 : Up. 252000 : Sen. 1,054,898 : Cost 65.99875641 : Time 825.56s : 7406.20 words/s
[2019-07-18 00:59:57] Ep. 4 : Up. 254000 : Sen. 1,344,438 : Cost 65.89187622 : Time 824.49s : 7407.15 words/s
[2019-07-18 01:13:42] Ep. 4 : Up. 256000 : Sen. 1,633,493 : Cost 66.08100891 : Time 824.14s : 7412.55 words/s
[2019-07-18 01:27:26] Ep. 4 : Up. 258000 : Sen. 1,923,572 : Cost 66.01564789 : Time 824.68s : 7424.21 words/s
[2019-07-18 01:41:08] Ep. 4 : Up. 260000 : Sen. 2,212,385 : Cost 66.01734924 : Time 821.56s : 7414.01 words/s
[2019-07-18 01:41:08] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-18 01:41:16] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter260000.npz
[2019-07-18 01:41:23] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-18 01:41:32] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-18 01:41:56] [valid] Ep. 4 : Up. 260000 : cross-entropy : 52.9597 : new best
[2019-07-18 01:42:04] [valid] Ep. 4 : Up. 260000 : perplexity : 8.15406 : new best
[2019-07-18 01:43:11] [valid] Ep. 4 : Up. 260000 : translation : 24.94 : stalled 1 times (last best: 25.04)
[2019-07-18 01:56:53] Ep. 4 : Up. 262000 : Sen. 2,500,684 : Cost 65.81638336 : Time 945.33s : 6428.76 words/s
[2019-07-18 02:10:37] Ep. 4 : Up. 264000 : Sen. 2,789,872 : Cost 66.03394318 : Time 823.81s : 7419.06 words/s
[2019-07-18 02:24:19] Ep. 4 : Up. 266000 : Sen. 3,078,549 : Cost 66.14640045 : Time 822.26s : 7413.42 words/s
[2019-07-18 02:38:04] Ep. 4 : Up. 268000 : Sen. 3,367,234 : Cost 66.25048065 : Time 825.31s : 7390.39 words/s
[2019-07-18 02:51:46] Ep. 4 : Up. 270000 : Sen. 3,656,607 : Cost 65.92247772 : Time 821.08s : 7432.17 words/s
[2019-07-18 03:05:30] Ep. 4 : Up. 272000 : Sen. 3,946,631 : Cost 65.91073608 : Time 824.89s : 7431.18 words/s
[2019-07-18 03:19:13] Ep. 4 : Up. 274000 : Sen. 4,235,390 : Cost 66.01421356 : Time 822.44s : 7415.04 words/s
[2019-07-18 03:32:57] Ep. 4 : Up. 276000 : Sen. 4,524,536 : Cost 66.10063171 : Time 824.02s : 7404.68 words/s
[2019-07-18 03:46:40] Ep. 4 : Up. 278000 : Sen. 4,813,336 : Cost 66.00646210 : Time 823.56s : 7400.80 words/s
[2019-07-18 04:00:25] Ep. 4 : Up. 280000 : Sen. 5,102,032 : Cost 65.86898041 : Time 825.01s : 7378.44 words/s
[2019-07-18 04:00:25] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-18 04:00:34] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter280000.npz
[2019-07-18 04:00:41] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-18 04:00:50] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-18 04:01:14] [valid] Ep. 4 : Up. 280000 : cross-entropy : 52.7033 : new best
[2019-07-18 04:01:22] [valid] Ep. 4 : Up. 280000 : perplexity : 8.07163 : new best
[2019-07-18 04:02:30] [valid] Ep. 4 : Up. 280000 : translation : 25.07 : new best
[2019-07-18 04:16:16] Ep. 4 : Up. 282000 : Sen. 5,390,679 : Cost 65.93869781 : Time 950.93s : 6414.67 words/s
[2019-07-18 04:30:03] Ep. 4 : Up. 284000 : Sen. 5,680,351 : Cost 65.87899780 : Time 826.29s : 7421.46 words/s
[2019-07-18 04:43:45] Ep. 4 : Up. 286000 : Sen. 5,969,533 : Cost 65.83103180 : Time 822.36s : 7415.97 words/s
[2019-07-18 04:57:30] Ep. 4 : Up. 288000 : Sen. 6,259,018 : Cost 65.85594940 : Time 824.96s : 7416.58 words/s
[2019-07-18 05:11:13] Ep. 4 : Up. 290000 : Sen. 6,548,393 : Cost 65.63397980 : Time 822.92s : 7404.58 words/s
[2019-07-18 05:24:58] Ep. 4 : Up. 292000 : Sen. 6,837,966 : Cost 65.73825073 : Time 824.83s : 7421.28 words/s
[2019-07-18 05:38:43] Ep. 4 : Up. 294000 : Sen. 7,127,145 : Cost 65.99318695 : Time 825.69s : 7408.03 words/s
[2019-07-18 05:52:30] Ep. 4 : Up. 296000 : Sen. 7,417,336 : Cost 65.88545227 : Time 827.04s : 7411.76 words/s
[2019-07-18 06:06:15] Ep. 4 : Up. 298000 : Sen. 7,706,808 : Cost 65.69522095 : Time 824.14s : 7424.47 words/s
[2019-07-18 06:19:59] Ep. 4 : Up. 300000 : Sen. 7,996,499 : Cost 65.86005402 : Time 824.09s : 7433.64 words/s
[2019-07-18 06:19:59] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-18 06:20:12] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter300000.npz
[2019-07-18 06:20:21] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-18 06:20:34] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-18 06:21:03] [valid] Ep. 4 : Up. 300000 : cross-entropy : 52.4504 : new best
[2019-07-18 06:21:11] [valid] Ep. 4 : Up. 300000 : perplexity : 7.99115 : new best
[2019-07-18 06:22:18] [valid] Ep. 4 : Up. 300000 : translation : 25.35 : new best
[2019-07-18 06:36:03] Ep. 4 : Up. 302000 : Sen. 8,285,769 : Cost 65.86156464 : Time 964.12s : 6326.57 words/s
[2019-07-18 06:49:47] Ep. 4 : Up. 304000 : Sen. 8,574,223 : Cost 65.86100006 : Time 824.39s : 7395.25 words/s
[2019-07-18 07:03:34] Ep. 4 : Up. 306000 : Sen. 8,864,661 : Cost 65.91175079 : Time 826.60s : 7430.52 words/s
[2019-07-18 07:17:16] Ep. 4 : Up. 308000 : Sen. 9,153,862 : Cost 65.79570007 : Time 822.54s : 7428.84 words/s
[2019-07-18 07:31:00] Ep. 4 : Up. 310000 : Sen. 9,443,665 : Cost 65.36962128 : Time 823.32s : 7415.70 words/s
[2019-07-18 07:44:45] Ep. 4 : Up. 312000 : Sen. 9,732,144 : Cost 65.55696106 : Time 824.90s : 7383.45 words/s
[2019-07-18 07:58:28] Ep. 4 : Up. 314000 : Sen. 10,020,735 : Cost 65.60671234 : Time 823.49s : 7403.40 words/s
[2019-07-18 08:12:14] Ep. 4 : Up. 316000 : Sen. 10,311,668 : Cost 65.49497223 : Time 825.42s : 7423.29 words/s
[2019-07-18 08:25:57] Ep. 4 : Up. 318000 : Sen. 10,601,762 : Cost 65.40210724 : Time 823.00s : 7438.88 words/s
[2019-07-18 08:39:36] Ep. 4 : Up. 320000 : Sen. 10,889,968 : Cost 65.77316284 : Time 819.85s : 7437.10 words/s
[2019-07-18 08:39:36] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-18 08:39:45] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter320000.npz
[2019-07-18 08:39:52] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-18 08:40:01] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-18 08:40:25] [valid] Ep. 4 : Up. 320000 : cross-entropy : 52.1769 : new best
[2019-07-18 08:40:33] [valid] Ep. 4 : Up. 320000 : perplexity : 7.90503 : new best
[2019-07-18 08:41:40] [valid] Ep. 4 : Up. 320000 : translation : 25.43 : new best
[2019-07-18 08:55:29] Ep. 4 : Up. 322000 : Sen. 11,178,583 : Cost 65.77945709 : Time 952.30s : 6411.79 words/s
[2019-07-18 09:09:16] Ep. 4 : Up. 324000 : Sen. 11,468,800 : Cost 65.37361145 : Time 827.30s : 7405.47 words/s
[2019-07-18 09:23:05] Ep. 4 : Up. 326000 : Sen. 11,758,451 : Cost 65.60210419 : Time 828.94s : 7386.92 words/s
[2019-07-18 09:24:51] Seen 11795642 samples
[2019-07-18 09:24:51] Starting epoch 5
[2019-07-18 09:24:51] [data] Shuffling data
[2019-07-18 09:24:58] [data] Done reading 13926791 sentences
[2019-07-18 09:25:59] [data] Done shuffling 13926791 sentences to temp files
[2019-07-18 09:37:56] Ep. 5 : Up. 328000 : Sen. 252,052 : Cost 64.69727325 : Time 891.34s : 6838.17 words/s
[2019-07-18 09:51:41] Ep. 5 : Up. 330000 : Sen. 541,410 : Cost 64.73400879 : Time 824.41s : 7408.50 words/s
[2019-07-18 10:05:26] Ep. 5 : Up. 332000 : Sen. 830,311 : Cost 65.19583893 : Time 824.98s : 7407.29 words/s
[2019-07-18 10:19:12] Ep. 5 : Up. 334000 : Sen. 1,119,280 : Cost 64.79788971 : Time 825.85s : 7400.08 words/s
[2019-07-18 10:32:52] Ep. 5 : Up. 336000 : Sen. 1,408,576 : Cost 64.67382812 : Time 820.70s : 7425.68 words/s
[2019-07-18 10:46:36] Ep. 5 : Up. 338000 : Sen. 1,697,519 : Cost 64.73203278 : Time 824.20s : 7395.55 words/s
[2019-07-18 11:00:17] Ep. 5 : Up. 340000 : Sen. 1,986,452 : Cost 64.98538208 : Time 821.05s : 7429.49 words/s
[2019-07-18 11:00:17] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-18 11:00:26] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter340000.npz
[2019-07-18 11:00:33] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-18 11:00:42] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-18 11:01:13] [valid] Ep. 5 : Up. 340000 : cross-entropy : 51.9849 : new best
[2019-07-18 11:01:21] [valid] Ep. 5 : Up. 340000 : perplexity : 7.8451 : new best
[2019-07-18 11:02:29] [valid] Ep. 5 : Up. 340000 : translation : 25.31 : stalled 1 times (last best: 25.43)
[2019-07-18 11:16:15] Ep. 5 : Up. 342000 : Sen. 2,276,356 : Cost 64.76839447 : Time 957.39s : 6389.09 words/s
[2019-07-18 11:29:56] Ep. 5 : Up. 344000 : Sen. 2,564,672 : Cost 64.77524567 : Time 821.61s : 7412.73 words/s
[2019-07-18 11:43:41] Ep. 5 : Up. 346000 : Sen. 2,854,268 : Cost 64.79305267 : Time 824.28s : 7417.80 words/s
[2019-07-18 11:57:27] Ep. 5 : Up. 348000 : Sen. 3,144,324 : Cost 65.04279327 : Time 826.23s : 7421.80 words/s
[2019-07-18 12:11:10] Ep. 5 : Up. 350000 : Sen. 3,433,114 : Cost 64.67214966 : Time 822.84s : 7398.58 words/s
[2019-07-18 12:24:54] Ep. 5 : Up. 352000 : Sen. 3,722,277 : Cost 65.05764771 : Time 824.32s : 7430.06 words/s
[2019-07-18 12:38:37] Ep. 5 : Up. 354000 : Sen. 4,011,966 : Cost 64.67902374 : Time 822.86s : 7414.47 words/s
[2019-07-18 12:52:25] Ep. 5 : Up. 356000 : Sen. 4,301,345 : Cost 64.96129608 : Time 827.99s : 7397.00 words/s
[2019-07-18 13:06:07] Ep. 5 : Up. 358000 : Sen. 4,590,321 : Cost 64.75917816 : Time 822.38s : 7413.36 words/s
[2019-07-18 13:19:51] Ep. 5 : Up. 360000 : Sen. 4,880,147 : Cost 64.81954956 : Time 823.62s : 7432.36 words/s
[2019-07-18 13:19:51] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-18 13:19:59] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter360000.npz
[2019-07-18 13:20:06] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-18 13:20:15] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-18 13:20:39] [valid] Ep. 5 : Up. 360000 : cross-entropy : 51.7818 : new best
[2019-07-18 13:20:47] [valid] Ep. 5 : Up. 360000 : perplexity : 7.78221 : new best
[2019-07-18 13:21:54] [valid] Ep. 5 : Up. 360000 : translation : 25.47 : new best
[2019-07-18 13:35:44] Ep. 5 : Up. 362000 : Sen. 5,170,310 : Cost 64.55042267 : Time 953.02s : 6417.90 words/s
[2019-07-18 13:49:28] Ep. 5 : Up. 364000 : Sen. 5,458,672 : Cost 64.65107727 : Time 823.96s : 7393.90 words/s
[2019-07-18 14:03:12] Ep. 5 : Up. 366000 : Sen. 5,747,332 : Cost 64.73452759 : Time 824.50s : 7391.84 words/s
[2019-07-18 14:16:58] Ep. 5 : Up. 368000 : Sen. 6,036,554 : Cost 64.93058777 : Time 825.58s : 7396.77 words/s
[2019-07-18 14:30:43] Ep. 5 : Up. 370000 : Sen. 6,326,435 : Cost 64.61802673 : Time 824.63s : 7416.67 words/s
[2019-07-18 14:44:29] Ep. 5 : Up. 372000 : Sen. 6,615,924 : Cost 64.66637421 : Time 826.24s : 7384.09 words/s
[2019-07-18 14:58:15] Ep. 5 : Up. 374000 : Sen. 6,904,842 : Cost 64.96641541 : Time 826.26s : 7399.53 words/s
[2019-07-18 15:12:03] Ep. 5 : Up. 376000 : Sen. 7,194,476 : Cost 64.80760956 : Time 827.74s : 7393.97 words/s
[2019-07-18 15:25:49] Ep. 5 : Up. 378000 : Sen. 7,484,357 : Cost 64.73342896 : Time 826.51s : 7394.19 words/s
[2019-07-18 15:39:38] Ep. 5 : Up. 380000 : Sen. 7,773,705 : Cost 64.77456665 : Time 829.02s : 7372.18 words/s
[2019-07-18 15:39:38] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-18 15:39:47] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter380000.npz
[2019-07-18 15:39:54] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-18 15:40:03] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-18 15:40:27] [valid] Ep. 5 : Up. 380000 : cross-entropy : 51.6548 : new best
[2019-07-18 15:40:35] [valid] Ep. 5 : Up. 380000 : perplexity : 7.74315 : new best
[2019-07-18 15:41:42] [valid] Ep. 5 : Up. 380000 : translation : 25.46 : stalled 1 times (last best: 25.47)
[2019-07-18 15:55:29] Ep. 5 : Up. 382000 : Sen. 8,062,188 : Cost 64.65817261 : Time 950.92s : 6411.08 words/s
[2019-07-18 16:09:15] Ep. 5 : Up. 384000 : Sen. 8,351,416 : Cost 64.89506531 : Time 825.58s : 7391.88 words/s
[2019-07-18 16:23:03] Ep. 5 : Up. 386000 : Sen. 8,641,285 : Cost 64.69098663 : Time 828.38s : 7396.70 words/s
[2019-07-18 16:36:52] Ep. 5 : Up. 388000 : Sen. 8,931,001 : Cost 64.95223236 : Time 828.27s : 7392.02 words/s
[2019-07-18 16:50:33] Ep. 5 : Up. 390000 : Sen. 9,219,182 : Cost 64.37213898 : Time 821.14s : 7378.48 words/s
[2019-07-18 17:04:20] Ep. 5 : Up. 392000 : Sen. 9,509,128 : Cost 64.82638550 : Time 827.37s : 7408.89 words/s
[2019-07-18 17:18:07] Ep. 5 : Up. 394000 : Sen. 9,798,970 : Cost 64.91028595 : Time 827.35s : 7405.90 words/s
[2019-07-18 17:31:52] Ep. 5 : Up. 396000 : Sen. 10,087,808 : Cost 64.84967041 : Time 824.81s : 7407.95 words/s
[2019-07-18 17:45:37] Ep. 5 : Up. 398000 : Sen. 10,376,853 : Cost 64.59494781 : Time 824.26s : 7408.98 words/s
[2019-07-18 17:59:24] Ep. 5 : Up. 400000 : Sen. 10,667,208 : Cost 64.71772003 : Time 827.11s : 7424.41 words/s
[2019-07-18 17:59:24] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-18 17:59:32] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter400000.npz
[2019-07-18 17:59:39] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-18 17:59:48] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-18 18:00:17] [valid] Ep. 5 : Up. 400000 : cross-entropy : 51.4115 : new best
[2019-07-18 18:00:24] [valid] Ep. 5 : Up. 400000 : perplexity : 7.66885 : new best
[2019-07-18 18:01:33] [valid] Ep. 5 : Up. 400000 : translation : 25.33 : stalled 2 times (last best: 25.47)
[2019-07-18 18:15:19] Ep. 5 : Up. 402000 : Sen. 10,957,428 : Cost 64.54529572 : Time 954.93s : 6420.07 words/s
[2019-07-18 18:29:02] Ep. 5 : Up. 404000 : Sen. 11,246,691 : Cost 64.55079651 : Time 822.94s : 7416.87 words/s
[2019-07-18 18:42:47] Ep. 5 : Up. 406000 : Sen. 11,535,848 : Cost 64.42993927 : Time 825.22s : 7400.43 words/s
[2019-07-18 18:55:08] Seen 11795642 samples
[2019-07-18 18:55:08] Starting epoch 6
[2019-07-18 18:55:08] [data] Shuffling data
[2019-07-18 18:55:16] [data] Done reading 13926791 sentences
[2019-07-18 18:56:29] [data] Done shuffling 13926791 sentences to temp files
[2019-07-18 18:57:59] Ep. 6 : Up. 408000 : Sen. 29,152 : Cost 64.67773438 : Time 911.75s : 6706.24 words/s
[2019-07-18 19:11:41] Ep. 6 : Up. 410000 : Sen. 319,001 : Cost 63.69585419 : Time 822.88s : 7427.67 words/s
[2019-07-18 19:25:21] Ep. 6 : Up. 412000 : Sen. 607,590 : Cost 63.97490692 : Time 819.30s : 7434.15 words/s
[2019-07-18 19:39:04] Ep. 6 : Up. 414000 : Sen. 896,528 : Cost 63.92136765 : Time 823.16s : 7414.46 words/s
[2019-07-18 19:52:49] Ep. 6 : Up. 416000 : Sen. 1,186,095 : Cost 63.94694901 : Time 825.48s : 7412.81 words/s
[2019-07-18 20:06:33] Ep. 6 : Up. 418000 : Sen. 1,475,993 : Cost 63.70434570 : Time 824.00s : 7424.69 words/s
[2019-07-18 20:20:18] Ep. 6 : Up. 420000 : Sen. 1,764,634 : Cost 64.12908936 : Time 824.30s : 7416.43 words/s
[2019-07-18 20:20:18] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-18 20:20:28] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter420000.npz
[2019-07-18 20:20:35] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-18 20:20:44] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-18 20:21:08] [valid] Ep. 6 : Up. 420000 : cross-entropy : 51.3427 : new best
[2019-07-18 20:21:15] [valid] Ep. 6 : Up. 420000 : perplexity : 7.64797 : new best
[2019-07-18 20:22:23] [valid] Ep. 6 : Up. 420000 : translation : 25.39 : stalled 3 times (last best: 25.47)
[2019-07-18 20:36:06] Ep. 6 : Up. 422000 : Sen. 2,052,714 : Cost 64.04569244 : Time 948.81s : 6410.37 words/s
[2019-07-18 20:49:49] Ep. 6 : Up. 424000 : Sen. 2,341,160 : Cost 64.09410095 : Time 822.60s : 7409.36 words/s
[2019-07-18 21:03:30] Ep. 6 : Up. 426000 : Sen. 2,629,698 : Cost 63.88577652 : Time 821.26s : 7418.63 words/s
[2019-07-18 21:17:15] Ep. 6 : Up. 428000 : Sen. 2,918,136 : Cost 63.96824265 : Time 824.72s : 7401.11 words/s
[2019-07-18 21:30:58] Ep. 6 : Up. 430000 : Sen. 3,207,488 : Cost 64.05612183 : Time 822.75s : 7425.46 words/s
[2019-07-18 21:44:42] Ep. 6 : Up. 432000 : Sen. 3,496,534 : Cost 64.12218475 : Time 823.85s : 7408.76 words/s
[2019-07-18 21:58:23] Ep. 6 : Up. 434000 : Sen. 3,785,523 : Cost 63.91722107 : Time 821.52s : 7438.66 words/s
[2019-07-18 22:12:09] Ep. 6 : Up. 436000 : Sen. 4,075,004 : Cost 64.27577972 : Time 825.86s : 7405.36 words/s
[2019-07-18 22:25:54] Ep. 6 : Up. 438000 : Sen. 4,364,800 : Cost 63.77412415 : Time 824.98s : 7413.66 words/s
[2019-07-18 22:39:36] Ep. 6 : Up. 440000 : Sen. 4,653,238 : Cost 64.23770905 : Time 821.80s : 7417.43 words/s
[2019-07-18 22:39:36] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-18 22:39:45] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter440000.npz
[2019-07-18 22:39:54] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-18 22:40:04] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-18 22:40:34] [valid] Ep. 6 : Up. 440000 : cross-entropy : 51.2997 : new best
[2019-07-18 22:40:41] [valid] Ep. 6 : Up. 440000 : perplexity : 7.63495 : new best
[2019-07-18 22:41:49] [valid] Ep. 6 : Up. 440000 : translation : 25.33 : stalled 4 times (last best: 25.47)
[2019-07-18 22:55:36] Ep. 6 : Up. 442000 : Sen. 4,943,239 : Cost 63.67059326 : Time 960.53s : 6367.86 words/s
[2019-07-18 23:09:20] Ep. 6 : Up. 444000 : Sen. 5,231,180 : Cost 64.08065033 : Time 824.02s : 7387.82 words/s
[2019-07-18 23:23:04] Ep. 6 : Up. 446000 : Sen. 5,520,560 : Cost 64.01922607 : Time 824.01s : 7409.96 words/s
[2019-07-18 23:36:53] Ep. 6 : Up. 448000 : Sen. 5,809,936 : Cost 64.02140808 : Time 828.25s : 7387.23 words/s
[2019-07-18 23:50:38] Ep. 6 : Up. 450000 : Sen. 6,099,200 : Cost 63.87602234 : Time 825.71s : 7388.42 words/s
[2019-07-19 00:04:23] Ep. 6 : Up. 452000 : Sen. 6,388,407 : Cost 63.91218185 : Time 824.63s : 7403.43 words/s
[2019-07-19 00:18:09] Ep. 6 : Up. 454000 : Sen. 6,678,040 : Cost 64.02365112 : Time 825.94s : 7409.44 words/s
[2019-07-19 00:31:56] Ep. 6 : Up. 456000 : Sen. 6,967,339 : Cost 63.99217606 : Time 826.82s : 7389.90 words/s
[2019-07-19 00:45:42] Ep. 6 : Up. 458000 : Sen. 7,257,106 : Cost 63.72985077 : Time 826.22s : 7404.60 words/s
[2019-07-19 00:59:29] Ep. 6 : Up. 460000 : Sen. 7,547,321 : Cost 64.13996124 : Time 827.19s : 7400.59 words/s
[2019-07-19 00:59:29] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-19 00:59:39] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter460000.npz
[2019-07-19 00:59:46] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-19 00:59:55] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-19 01:00:19] [valid] Ep. 6 : Up. 460000 : cross-entropy : 51.15 : new best
[2019-07-19 01:00:27] [valid] Ep. 6 : Up. 460000 : perplexity : 7.58982 : new best
[2019-07-19 01:01:34] [valid] Ep. 6 : Up. 460000 : translation : 25.13 : stalled 5 times (last best: 25.47)
[2019-07-19 01:15:23] Ep. 6 : Up. 462000 : Sen. 7,836,150 : Cost 64.15158081 : Time 953.89s : 6410.12 words/s
[2019-07-19 01:29:12] Ep. 6 : Up. 464000 : Sen. 8,125,520 : Cost 64.02861023 : Time 828.93s : 7360.87 words/s
[2019-07-19 01:43:00] Ep. 6 : Up. 466000 : Sen. 8,415,604 : Cost 63.79058456 : Time 827.87s : 7379.98 words/s
[2019-07-19 01:56:46] Ep. 6 : Up. 468000 : Sen. 8,704,834 : Cost 63.72209549 : Time 826.40s : 7379.92 words/s
[2019-07-19 02:10:35] Ep. 6 : Up. 470000 : Sen. 8,994,384 : Cost 63.95911026 : Time 828.57s : 7386.46 words/s
[2019-07-19 02:24:22] Ep. 6 : Up. 472000 : Sen. 9,284,341 : Cost 63.82813263 : Time 827.56s : 7372.52 words/s
[2019-07-19 02:38:13] Ep. 6 : Up. 474000 : Sen. 9,574,204 : Cost 64.37969971 : Time 830.24s : 7384.02 words/s
[2019-07-19 02:52:01] Ep. 6 : Up. 476000 : Sen. 9,863,659 : Cost 63.85263443 : Time 827.92s : 7386.62 words/s
[2019-07-19 03:05:51] Ep. 6 : Up. 478000 : Sen. 10,153,605 : Cost 64.02759552 : Time 830.59s : 7381.61 words/s
[2019-07-19 03:19:42] Ep. 6 : Up. 480000 : Sen. 10,443,464 : Cost 63.92249298 : Time 831.10s : 7361.62 words/s
[2019-07-19 03:19:42] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-19 03:19:52] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter480000.npz
[2019-07-19 03:20:03] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-19 03:20:13] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-19 03:20:37] [valid] Ep. 6 : Up. 480000 : cross-entropy : 50.9526 : new best
[2019-07-19 03:20:45] [valid] Ep. 6 : Up. 480000 : perplexity : 7.53067 : new best
[2019-07-19 03:21:55] [valid] Ep. 6 : Up. 480000 : translation : 25.46 : stalled 6 times (last best: 25.47)
[2019-07-19 03:35:45] Ep. 6 : Up. 482000 : Sen. 10,733,238 : Cost 63.71752548 : Time 962.42s : 6344.15 words/s
[2019-07-19 03:49:34] Ep. 6 : Up. 484000 : Sen. 11,022,617 : Cost 63.89728928 : Time 829.66s : 7369.49 words/s
[2019-07-19 04:03:24] Ep. 6 : Up. 486000 : Sen. 11,312,721 : Cost 63.79482651 : Time 829.23s : 7376.55 words/s
[2019-07-19 04:17:14] Ep. 6 : Up. 488000 : Sen. 11,602,192 : Cost 63.82570267 : Time 830.75s : 7364.89 words/s
[2019-07-19 04:26:26] Seen 11795642 samples
[2019-07-19 04:26:26] Starting epoch 7
[2019-07-19 04:26:26] [data] Shuffling data
[2019-07-19 04:26:34] [data] Done reading 13926791 sentences
[2019-07-19 04:27:50] [data] Done shuffling 13926791 sentences to temp files
[2019-07-19 04:32:27] Ep. 7 : Up. 490000 : Sen. 95,419 : Cost 63.56353760 : Time 912.81s : 6682.81 words/s
[2019-07-19 04:46:09] Ep. 7 : Up. 492000 : Sen. 384,536 : Cost 62.99803162 : Time 821.71s : 7421.04 words/s
[2019-07-19 04:59:55] Ep. 7 : Up. 494000 : Sen. 673,609 : Cost 63.18149948 : Time 826.46s : 7396.32 words/s
[2019-07-19 05:13:43] Ep. 7 : Up. 496000 : Sen. 964,044 : Cost 63.16730499 : Time 827.21s : 7411.13 words/s
[2019-07-19 05:27:25] Ep. 7 : Up. 498000 : Sen. 1,252,667 : Cost 63.14796066 : Time 822.84s : 7397.92 words/s
[2019-07-19 05:41:12] Ep. 7 : Up. 500000 : Sen. 1,543,014 : Cost 63.44101334 : Time 826.82s : 7427.02 words/s
[2019-07-19 05:41:12] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-19 05:41:20] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter500000.npz
[2019-07-19 05:41:27] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-19 05:41:39] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-19 05:42:04] [valid] Ep. 7 : Up. 500000 : cross-entropy : 50.9574 : stalled 1 times (last best: 50.9526)
[2019-07-19 05:42:12] [valid] Ep. 7 : Up. 500000 : perplexity : 7.5321 : stalled 1 times (last best: 7.53067)
[2019-07-19 05:43:21] [valid] Ep. 7 : Up. 500000 : translation : 25.39 : stalled 7 times (last best: 25.47)
[2019-07-19 05:57:08] Ep. 7 : Up. 502000 : Sen. 1,832,729 : Cost 63.35433960 : Time 955.63s : 6407.29 words/s
[2019-07-19 06:10:51] Ep. 7 : Up. 504000 : Sen. 2,122,520 : Cost 63.05498886 : Time 823.38s : 7415.17 words/s
[2019-07-19 06:24:38] Ep. 7 : Up. 506000 : Sen. 2,411,694 : Cost 63.12567520 : Time 827.13s : 7388.31 words/s
[2019-07-19 06:38:20] Ep. 7 : Up. 508000 : Sen. 2,699,845 : Cost 63.45705414 : Time 821.47s : 7420.88 words/s
[2019-07-19 06:52:04] Ep. 7 : Up. 510000 : Sen. 2,989,558 : Cost 63.25577545 : Time 824.21s : 7416.38 words/s
[2019-07-19 07:05:49] Ep. 7 : Up. 512000 : Sen. 3,279,397 : Cost 63.23543930 : Time 825.46s : 7403.15 words/s
[2019-07-19 07:19:37] Ep. 7 : Up. 514000 : Sen. 3,569,626 : Cost 63.07582092 : Time 827.61s : 7393.98 words/s
[2019-07-19 07:33:23] Ep. 7 : Up. 516000 : Sen. 3,858,672 : Cost 63.31267548 : Time 826.18s : 7392.86 words/s
[2019-07-19 07:47:09] Ep. 7 : Up. 518000 : Sen. 4,147,200 : Cost 63.50557327 : Time 826.11s : 7381.85 words/s
[2019-07-19 08:00:56] Ep. 7 : Up. 520000 : Sen. 4,435,553 : Cost 63.38237381 : Time 826.62s : 7368.52 words/s
[2019-07-19 08:00:56] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-19 08:01:06] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter520000.npz
[2019-07-19 08:01:14] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-19 08:01:24] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-19 08:01:56] [valid] Ep. 7 : Up. 520000 : cross-entropy : 50.9594 : stalled 2 times (last best: 50.9526)
[2019-07-19 08:02:04] [valid] Ep. 7 : Up. 520000 : perplexity : 7.53269 : stalled 2 times (last best: 7.53067)
[2019-07-19 08:03:13] [valid] Ep. 7 : Up. 520000 : translation : 25.27 : stalled 8 times (last best: 25.47)
[2019-07-19 08:17:02] Ep. 7 : Up. 522000 : Sen. 4,725,518 : Cost 63.20456696 : Time 966.38s : 6337.98 words/s
[2019-07-19 08:30:48] Ep. 7 : Up. 524000 : Sen. 5,014,998 : Cost 63.09194565 : Time 825.97s : 7400.47 words/s
[2019-07-19 08:44:35] Ep. 7 : Up. 526000 : Sen. 5,304,648 : Cost 63.47471619 : Time 826.97s : 7392.23 words/s
[2019-07-19 08:58:21] Ep. 7 : Up. 528000 : Sen. 5,594,476 : Cost 63.52574539 : Time 825.34s : 7419.83 words/s
[2019-07-19 09:12:00] Ep. 7 : Up. 530000 : Sen. 5,883,912 : Cost 63.08000565 : Time 819.47s : 7441.36 words/s
[2019-07-19 09:25:46] Ep. 7 : Up. 532000 : Sen. 6,173,975 : Cost 63.33007812 : Time 825.99s : 7421.17 words/s
[2019-07-19 09:39:20] Ep. 7 : Up. 534000 : Sen. 6,463,115 : Cost 63.28063965 : Time 813.50s : 7500.99 words/s
[2019-07-19 09:52:52] Ep. 7 : Up. 536000 : Sen. 6,752,744 : Cost 63.25950241 : Time 812.23s : 7522.78 words/s
[2019-07-19 10:06:26] Ep. 7 : Up. 538000 : Sen. 7,042,721 : Cost 63.62189484 : Time 814.02s : 7527.03 words/s
[2019-07-19 10:19:56] Ep. 7 : Up. 540000 : Sen. 7,330,955 : Cost 63.43618774 : Time 809.82s : 7510.23 words/s
[2019-07-19 10:19:56] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-19 10:20:04] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter540000.npz
[2019-07-19 10:20:11] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-19 10:20:20] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-19 10:20:42] [valid] Ep. 7 : Up. 540000 : cross-entropy : 50.8689 : new best
[2019-07-19 10:20:50] [valid] Ep. 7 : Up. 540000 : perplexity : 7.50574 : new best
[2019-07-19 10:21:57] [valid] Ep. 7 : Up. 540000 : translation : 25.29 : stalled 9 times (last best: 25.47)
[2019-07-19 10:35:36] Ep. 7 : Up. 542000 : Sen. 7,620,773 : Cost 63.75955963 : Time 940.64s : 6519.19 words/s
[2019-07-19 10:49:13] Ep. 7 : Up. 544000 : Sen. 7,910,268 : Cost 63.30245590 : Time 816.22s : 7485.77 words/s
[2019-07-19 11:02:49] Ep. 7 : Up. 546000 : Sen. 8,199,686 : Cost 63.40403748 : Time 816.02s : 7494.10 words/s
[2019-07-19 11:16:26] Ep. 7 : Up. 548000 : Sen. 8,490,367 : Cost 63.25944138 : Time 817.53s : 7490.53 words/s
[2019-07-19 11:30:02] Ep. 7 : Up. 550000 : Sen. 8,778,847 : Cost 63.41846848 : Time 816.01s : 7470.45 words/s
[2019-07-19 11:43:38] Ep. 7 : Up. 552000 : Sen. 9,068,204 : Cost 63.40092087 : Time 815.47s : 7501.86 words/s
[2019-07-19 11:57:14] Ep. 7 : Up. 554000 : Sen. 9,357,782 : Cost 63.35009384 : Time 816.02s : 7493.41 words/s
[2019-07-19 12:10:48] Ep. 7 : Up. 556000 : Sen. 9,646,974 : Cost 63.34749222 : Time 814.58s : 7497.68 words/s
[2019-07-19 12:24:22] Ep. 7 : Up. 558000 : Sen. 9,935,697 : Cost 63.45356750 : Time 814.30s : 7507.54 words/s
[2019-07-19 12:38:00] Ep. 7 : Up. 560000 : Sen. 10,225,363 : Cost 63.12960434 : Time 817.84s : 7468.39 words/s
[2019-07-19 12:38:00] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-19 12:38:09] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter560000.npz
[2019-07-19 12:38:16] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-19 12:38:25] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-19 12:38:48] [valid] Ep. 7 : Up. 560000 : cross-entropy : 50.7576 : new best
[2019-07-19 12:38:55] [valid] Ep. 7 : Up. 560000 : perplexity : 7.4727 : new best
[2019-07-19 12:40:08] [valid] Ep. 7 : Up. 560000 : translation : 25.4 : stalled 10 times (last best: 25.47)
[2019-07-19 12:53:43] Ep. 7 : Up. 562000 : Sen. 10,513,727 : Cost 63.33789825 : Time 942.63s : 6457.90 words/s
[2019-07-19 13:07:17] Ep. 7 : Up. 564000 : Sen. 10,802,936 : Cost 63.40035248 : Time 813.78s : 7502.37 words/s
[2019-07-19 13:20:53] Ep. 7 : Up. 566000 : Sen. 11,092,388 : Cost 63.32891083 : Time 816.39s : 7485.09 words/s
[2019-07-19 13:34:30] Ep. 7 : Up. 568000 : Sen. 11,382,010 : Cost 63.38494873 : Time 816.77s : 7481.84 words/s
[2019-07-19 13:48:05] Ep. 7 : Up. 570000 : Sen. 11,670,745 : Cost 63.55723572 : Time 815.13s : 7492.24 words/s
[2019-07-19 13:53:56] Seen 11795642 samples
[2019-07-19 13:53:56] Starting epoch 8
[2019-07-19 13:53:56] [data] Shuffling data
[2019-07-19 13:54:04] [data] Done reading 13926791 sentences
[2019-07-19 13:55:06] [data] Done shuffling 13926791 sentences to temp files
[2019-07-19 14:02:51] Ep. 8 : Up. 572000 : Sen. 164,042 : Cost 63.02409744 : Time 886.35s : 6878.47 words/s
[2019-07-19 14:16:31] Ep. 8 : Up. 574000 : Sen. 453,081 : Cost 62.49091721 : Time 820.03s : 7432.70 words/s
[2019-07-19 14:30:10] Ep. 8 : Up. 576000 : Sen. 743,595 : Cost 62.66780090 : Time 818.48s : 7492.30 words/s
[2019-07-19 14:43:46] Ep. 8 : Up. 578000 : Sen. 1,033,628 : Cost 62.79783249 : Time 816.10s : 7506.56 words/s
[2019-07-19 14:57:22] Ep. 8 : Up. 580000 : Sen. 1,322,561 : Cost 62.50011063 : Time 815.53s : 7470.89 words/s
[2019-07-19 14:57:22] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-19 14:57:30] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter580000.npz
[2019-07-19 14:57:37] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-19 14:57:45] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-19 14:58:08] [valid] Ep. 8 : Up. 580000 : cross-entropy : 50.7524 : new best
[2019-07-19 14:58:16] [valid] Ep. 8 : Up. 580000 : perplexity : 7.47117 : new best
[2019-07-19 14:59:23] [valid] Ep. 8 : Up. 580000 : translation : 25.12 : stalled 11 times (last best: 25.47)
[2019-07-19 15:13:04] Ep. 8 : Up. 582000 : Sen. 1,611,383 : Cost 62.68511963 : Time 942.48s : 6481.73 words/s
[2019-07-19 15:26:46] Ep. 8 : Up. 584000 : Sen. 1,900,404 : Cost 62.73317337 : Time 822.36s : 7422.64 words/s
[2019-07-19 15:40:34] Ep. 8 : Up. 586000 : Sen. 2,190,338 : Cost 62.90560532 : Time 827.16s : 7412.16 words/s
[2019-07-19 15:54:17] Ep. 8 : Up. 588000 : Sen. 2,478,986 : Cost 62.72424698 : Time 823.31s : 7402.57 words/s
[2019-07-19 16:08:01] Ep. 8 : Up. 590000 : Sen. 2,769,461 : Cost 62.63674927 : Time 824.59s : 7420.29 words/s
[2019-07-19 16:21:46] Ep. 8 : Up. 592000 : Sen. 3,059,596 : Cost 62.70312119 : Time 824.95s : 7424.70 words/s
[2019-07-19 16:35:31] Ep. 8 : Up. 594000 : Sen. 3,349,778 : Cost 62.72588348 : Time 824.14s : 7421.23 words/s
[2019-07-19 16:49:14] Ep. 8 : Up. 596000 : Sen. 3,639,323 : Cost 63.01928711 : Time 823.64s : 7425.11 words/s
[2019-07-19 17:02:53] Ep. 8 : Up. 598000 : Sen. 3,927,995 : Cost 62.62424469 : Time 818.81s : 7441.04 words/s
[2019-07-19 17:16:37] Ep. 8 : Up. 600000 : Sen. 4,218,170 : Cost 63.02873611 : Time 824.26s : 7445.55 words/s
[2019-07-19 17:16:37] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-19 17:16:46] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter600000.npz
[2019-07-19 17:16:53] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-19 17:17:02] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-19 17:17:25] [valid] Ep. 8 : Up. 600000 : cross-entropy : 50.6199 : new best
[2019-07-19 17:17:33] [valid] Ep. 8 : Up. 600000 : perplexity : 7.43206 : new best
[2019-07-19 17:18:40] [valid] Ep. 8 : Up. 600000 : translation : 25.13 : stalled 12 times (last best: 25.47)
[2019-07-19 17:32:24] Ep. 8 : Up. 602000 : Sen. 4,506,976 : Cost 62.54771042 : Time 946.78s : 6430.41 words/s
[2019-07-19 17:46:06] Ep. 8 : Up. 604000 : Sen. 4,795,496 : Cost 63.02853775 : Time 822.02s : 7429.78 words/s
[2019-07-19 17:59:48] Ep. 8 : Up. 606000 : Sen. 5,085,373 : Cost 62.68527603 : Time 821.70s : 7434.92 words/s
[2019-07-19 18:13:33] Ep. 8 : Up. 608000 : Sen. 5,375,374 : Cost 63.06024551 : Time 825.37s : 7433.36 words/s
[2019-07-19 18:27:15] Ep. 8 : Up. 610000 : Sen. 5,664,293 : Cost 62.74335861 : Time 822.33s : 7412.28 words/s
[2019-07-19 18:40:55] Ep. 8 : Up. 612000 : Sen. 5,953,953 : Cost 62.81512833 : Time 819.69s : 7447.91 words/s
[2019-07-19 18:54:36] Ep. 8 : Up. 614000 : Sen. 6,243,127 : Cost 62.85709763 : Time 820.50s : 7439.27 words/s
[2019-07-19 19:08:18] Ep. 8 : Up. 616000 : Sen. 6,532,822 : Cost 63.06962967 : Time 822.68s : 7437.63 words/s
[2019-07-19 19:22:01] Ep. 8 : Up. 618000 : Sen. 6,822,532 : Cost 62.93185043 : Time 822.49s : 7447.80 words/s
[2019-07-19 19:35:43] Ep. 8 : Up. 620000 : Sen. 7,112,376 : Cost 63.07836533 : Time 821.82s : 7448.61 words/s
[2019-07-19 19:35:43] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-19 19:35:52] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter620000.npz
[2019-07-19 19:35:59] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-19 19:36:08] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-19 19:36:32] [valid] Ep. 8 : Up. 620000 : cross-entropy : 50.4873 : new best
[2019-07-19 19:36:39] [valid] Ep. 8 : Up. 620000 : perplexity : 7.39309 : new best
[2019-07-19 19:37:46] [valid] Ep. 8 : Up. 620000 : translation : 25.32 : stalled 13 times (last best: 25.47)
[2019-07-19 19:51:29] Ep. 8 : Up. 622000 : Sen. 7,401,224 : Cost 63.03576279 : Time 945.98s : 6458.81 words/s
[2019-07-19 20:05:11] Ep. 8 : Up. 624000 : Sen. 7,691,019 : Cost 63.09280777 : Time 822.40s : 7449.40 words/s
[2019-07-19 20:18:52] Ep. 8 : Up. 626000 : Sen. 7,979,432 : Cost 63.35138702 : Time 820.59s : 7442.61 words/s
[2019-07-19 20:32:34] Ep. 8 : Up. 628000 : Sen. 8,269,106 : Cost 62.89659500 : Time 822.51s : 7438.42 words/s
[2019-07-19 20:46:16] Ep. 8 : Up. 630000 : Sen. 8,558,294 : Cost 62.95148468 : Time 822.27s : 7424.83 words/s
[2019-07-19 20:59:56] Ep. 8 : Up. 632000 : Sen. 8,847,550 : Cost 63.03059006 : Time 819.84s : 7442.40 words/s
[2019-07-19 21:13:36] Ep. 8 : Up. 634000 : Sen. 9,136,446 : Cost 62.87370682 : Time 820.27s : 7444.33 words/s
[2019-07-19 21:27:15] Ep. 8 : Up. 636000 : Sen. 9,425,297 : Cost 62.52747726 : Time 818.56s : 7426.61 words/s
[2019-07-19 21:41:01] Ep. 8 : Up. 638000 : Sen. 9,714,970 : Cost 62.87971497 : Time 825.51s : 7415.91 words/s
[2019-07-19 21:54:43] Ep. 8 : Up. 640000 : Sen. 10,004,430 : Cost 62.99829865 : Time 822.66s : 7427.47 words/s
[2019-07-19 21:54:43] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-19 21:54:52] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter640000.npz
[2019-07-19 21:54:59] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-19 21:55:08] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-19 21:55:31] [valid] Ep. 8 : Up. 640000 : cross-entropy : 50.4471 : new best
[2019-07-19 21:55:39] [valid] Ep. 8 : Up. 640000 : perplexity : 7.38133 : new best
[2019-07-19 21:56:46] [valid] Ep. 8 : Up. 640000 : translation : 25.45 : stalled 14 times (last best: 25.47)
[2019-07-19 22:10:29] Ep. 8 : Up. 642000 : Sen. 10,293,361 : Cost 62.83479309 : Time 945.64s : 6460.62 words/s
[2019-07-19 22:24:11] Ep. 8 : Up. 644000 : Sen. 10,583,461 : Cost 62.89442825 : Time 822.14s : 7437.62 words/s
[2019-07-19 22:37:52] Ep. 8 : Up. 646000 : Sen. 10,872,317 : Cost 62.87484360 : Time 820.65s : 7424.07 words/s
[2019-07-19 22:51:33] Ep. 8 : Up. 648000 : Sen. 11,160,614 : Cost 63.11962128 : Time 821.64s : 7426.16 words/s
[2019-07-19 23:05:15] Ep. 8 : Up. 650000 : Sen. 11,449,732 : Cost 63.10783768 : Time 821.56s : 7431.09 words/s
[2019-07-19 23:18:58] Ep. 8 : Up. 652000 : Sen. 11,739,675 : Cost 62.78775406 : Time 822.95s : 7447.34 words/s
[2019-07-19 23:21:37] Seen 11795642 samples
[2019-07-19 23:21:37] Starting epoch 9
[2019-07-19 23:21:37] [data] Shuffling data
[2019-07-19 23:21:45] [data] Done reading 13926791 sentences
[2019-07-19 23:22:51] [data] Done shuffling 13926791 sentences to temp files
[2019-07-19 23:34:02] Ep. 9 : Up. 654000 : Sen. 233,992 : Cost 62.18065262 : Time 904.42s : 6750.96 words/s
[2019-07-19 23:47:46] Ep. 9 : Up. 656000 : Sen. 522,782 : Cost 62.22725677 : Time 823.38s : 7409.72 words/s
[2019-07-20 00:01:31] Ep. 9 : Up. 658000 : Sen. 811,430 : Cost 62.58753967 : Time 825.75s : 7401.58 words/s
[2019-07-20 00:15:17] Ep. 9 : Up. 660000 : Sen. 1,100,800 : Cost 62.22928619 : Time 825.81s : 7379.26 words/s
[2019-07-20 00:15:17] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-20 00:15:28] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter660000.npz
[2019-07-20 00:15:34] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-20 00:15:43] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-20 00:16:06] [valid] Ep. 9 : Up. 660000 : cross-entropy : 50.3675 : new best
[2019-07-20 00:16:14] [valid] Ep. 9 : Up. 660000 : perplexity : 7.35808 : new best
[2019-07-20 00:17:22] [valid] Ep. 9 : Up. 660000 : translation : 25.58 : new best
[2019-07-20 00:31:08] Ep. 9 : Up. 662000 : Sen. 1,390,042 : Cost 62.34058762 : Time 950.93s : 6426.52 words/s
[2019-07-20 00:44:54] Ep. 9 : Up. 664000 : Sen. 1,679,711 : Cost 62.35852814 : Time 826.17s : 7393.54 words/s
[2019-07-20 00:58:40] Ep. 9 : Up. 666000 : Sen. 1,968,746 : Cost 62.29534149 : Time 825.97s : 7386.49 words/s
[2019-07-20 01:12:27] Ep. 9 : Up. 668000 : Sen. 2,257,970 : Cost 62.30277634 : Time 826.68s : 7382.85 words/s
[2019-07-20 01:26:16] Ep. 9 : Up. 670000 : Sen. 2,547,986 : Cost 62.29949951 : Time 829.53s : 7373.34 words/s
[2019-07-20 01:40:05] Ep. 9 : Up. 672000 : Sen. 2,837,981 : Cost 62.43477249 : Time 828.91s : 7383.24 words/s
[2019-07-20 01:53:55] Ep. 9 : Up. 674000 : Sen. 3,127,675 : Cost 62.70006943 : Time 829.89s : 7396.47 words/s
[2019-07-20 02:07:41] Ep. 9 : Up. 676000 : Sen. 3,416,710 : Cost 62.04308319 : Time 825.48s : 7377.16 words/s
[2019-07-20 02:21:28] Ep. 9 : Up. 678000 : Sen. 3,706,796 : Cost 62.23749542 : Time 826.92s : 7389.27 words/s
[2019-07-20 02:35:15] Ep. 9 : Up. 680000 : Sen. 3,996,585 : Cost 62.58029938 : Time 826.93s : 7416.89 words/s
[2019-07-20 02:35:15] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-20 02:35:24] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter680000.npz
[2019-07-20 02:35:30] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-20 02:35:40] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-20 02:36:03] [valid] Ep. 9 : Up. 680000 : cross-entropy : 50.4302 : stalled 1 times (last best: 50.3675)
[2019-07-20 02:36:11] [valid] Ep. 9 : Up. 680000 : perplexity : 7.37638 : stalled 1 times (last best: 7.35808)
[2019-07-20 02:37:19] [valid] Ep. 9 : Up. 680000 : translation : 25.6 : new best
[2019-07-20 02:51:10] Ep. 9 : Up. 682000 : Sen. 4,285,930 : Cost 62.64700699 : Time 955.57s : 6405.44 words/s
[2019-07-20 03:04:56] Ep. 9 : Up. 684000 : Sen. 4,575,562 : Cost 62.39604187 : Time 826.08s : 7395.88 words/s
[2019-07-20 03:18:44] Ep. 9 : Up. 686000 : Sen. 4,864,887 : Cost 62.63062668 : Time 827.38s : 7384.54 words/s
[2019-07-20 03:32:31] Ep. 9 : Up. 688000 : Sen. 5,153,246 : Cost 62.78619385 : Time 827.41s : 7370.90 words/s
[2019-07-20 03:46:21] Ep. 9 : Up. 690000 : Sen. 5,443,171 : Cost 62.74333191 : Time 829.51s : 7391.40 words/s
[2019-07-20 04:00:11] Ep. 9 : Up. 692000 : Sen. 5,732,762 : Cost 62.67417145 : Time 830.36s : 7376.34 words/s
[2019-07-20 04:14:00] Ep. 9 : Up. 694000 : Sen. 6,021,872 : Cost 62.34806061 : Time 829.03s : 7355.67 words/s
[2019-07-20 04:27:49] Ep. 9 : Up. 696000 : Sen. 6,311,587 : Cost 62.63191223 : Time 828.84s : 7377.66 words/s
[2019-07-20 04:41:36] Ep. 9 : Up. 698000 : Sen. 6,600,524 : Cost 62.66481781 : Time 827.36s : 7385.61 words/s
[2019-07-20 04:55:23] Ep. 9 : Up. 700000 : Sen. 6,889,325 : Cost 62.32181168 : Time 826.41s : 7364.26 words/s
[2019-07-20 04:55:23] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.orig.npz
[2019-07-20 04:55:32] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.iter700000.npz
[2019-07-20 04:55:39] Saving model to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz
[2019-07-20 04:55:48] Saving Adam parameters to ../experiments/10M_fasttext_prob_x_len_+_ced_0.5/model/model.npz.optimizer.npz
[2019-07-20 04:56:12] [valid] Ep. 9 : Up. 700000 : cross-entropy : 50.4333 : stalled 2 times (last best: 50.3675)
[2019-07-20 04:56:19] [valid] Ep. 9 : Up. 700000 : perplexity : 7.37731 : stalled 2 times (last best: 7.35808)
[2019-07-20 04:57:26] [valid] Ep. 9 : Up. 700000 : translation : 25.31 : stalled 1 times (last best: 25.6)
[2019-07-20 05:11:11] Ep. 9 : Up. 702000 : Sen. 7,178,512 : Cost 62.35908127 : Time 948.32s : 6436.60 words/s
[2019-07-20 05:24:55] Ep. 9 : Up. 704000 : Sen. 7,467,915 : Cost 62.79970169 : Time 824.61s : 7429.57 words/s
[2019-07-20 05:38:39] Ep. 9 : Up. 706000 : Sen. 7,757,748 : Cost 62.54491425 : Time 823.21s : 7427.34 words/s
[2019-07-20 05:52:20] Ep. 9 : Up. 708000 : Sen. 8,046,170 : Cost 62.61801147 : Time 821.42s : 7404.92 words/s
[2019-07-20 06:06:05] Ep. 9 : Up. 710000 : Sen. 8,336,303 : Cost 62.55603409 : Time 825.17s : 7433.75 words/s
[2019-07-20 06:19:46] Ep. 9 : Up. 712000 : Sen. 8,625,706 : Cost 62.33876801 : Time 820.39s : 7434.88 words/s
