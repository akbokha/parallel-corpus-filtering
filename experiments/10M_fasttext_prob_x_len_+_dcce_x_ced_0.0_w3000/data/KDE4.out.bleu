MT evaluation scorer began on 2019 Jul 28 at 16:26:56
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/10M_fasttext_prob_x_len_+_dcce_x_ced_0.0_w3000/data/KDE4.de.sgm -r ../experiments/10M_fasttext_prob_x_len_+_dcce_x_ced_0.0_w3000/data/KDE4.en.sgm -t ../experiments/10M_fasttext_prob_x_len_+_dcce_x_ced_0.0_w3000/data/KDE4.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 3000 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 0.943201996260922 (120578/127839), penalty (log): -0.0602182819419794
NIST score = 5.9500  BLEU score = 0.1909 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.4060   1.2053   0.2709   0.0568   0.0110   0.0031   0.0012   0.0007   0.0004  "Edinburgh"

 BLEU:  0.5474   0.2569   0.1437   0.0837   0.0508   0.0323   0.0215   0.0149   0.0108  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.4060   5.6113   5.8822   5.9390   5.9500   5.9531   5.9543   5.9550   5.9553  "Edinburgh"

 BLEU:  0.5154   0.3531   0.2565   0.1909   0.1448   0.1116   0.0875   0.0696   0.0562  "Edinburgh"
MT evaluation scorer ended on 2019 Jul 28 at 16:27:33
