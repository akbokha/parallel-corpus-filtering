MT evaluation scorer began on 2019 Jul 10 at 09:19:01
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/10M_fasttext_prob_x_len_+_dcce_x_ced_0.25/data/KDE4.de.sgm -r ../experiments/10M_fasttext_prob_x_len_+_dcce_x_ced_0.25/data/KDE4.en.sgm -t ../experiments/10M_fasttext_prob_x_len_+_dcce_x_ced_0.25/data/KDE4.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 3000 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 0.951869147912609 (121686/127839), penalty (log): -0.0505645678220994
NIST score = 5.9614  BLEU score = 0.1923 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.4157   1.2095   0.2687   0.0561   0.0114   0.0036   0.0014   0.0010   0.0006  "Edinburgh"

 BLEU:  0.5456   0.2567   0.1432   0.0835   0.0511   0.0330   0.0222   0.0155   0.0111  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.4157   5.6252   5.8939   5.9500   5.9614   5.9650   5.9663   5.9673   5.9680  "Edinburgh"

 BLEU:  0.5187   0.3558   0.2583   0.1923   0.1461   0.1130   0.0889   0.0711   0.0575  "Edinburgh"
MT evaluation scorer ended on 2019 Jul 10 at 09:19:40
