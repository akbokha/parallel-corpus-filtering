MT evaluation scorer began on 2019 Jul 11 at 11:48:34
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/10M_fasttext_prob_x_len_+_dcce_x_ced_0.5/data/KDE4.de.sgm -r ../experiments/10M_fasttext_prob_x_len_+_dcce_x_ced_0.5/data/KDE4.en.sgm -t ../experiments/10M_fasttext_prob_x_len_+_dcce_x_ced_0.5/data/KDE4.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 3000 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 0.940675380752353 (120255/127839), penalty (log): -0.0630659847823376
NIST score = 5.9712  BLEU score = 0.1915 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.4252   1.2107   0.2683   0.0558   0.0112   0.0032   0.0013   0.0009   0.0006  "Edinburgh"

 BLEU:  0.5514   0.2591   0.1446   0.0838   0.0508   0.0323   0.0214   0.0147   0.0104  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.4252   5.6359   5.9042   5.9600   5.9712   5.9744   5.9757   5.9766   5.9772  "Edinburgh"

 BLEU:  0.5177   0.3549   0.2576   0.1915   0.1450   0.1117   0.0874   0.0694   0.0558  "Edinburgh"
MT evaluation scorer ended on 2019 Jul 11 at 11:49:11
