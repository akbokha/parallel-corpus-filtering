MT evaluation scorer began on 2019 Aug 7 at 09:34:11
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/10M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/iwslt2017-tst2017.mltlng.en-de.de.sgm -r ../experiments/10M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/iwslt2017-tst2017.mltlng.en-de.en.sgm -t ../experiments/10M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.25/data/iwslt2017-tst2017.mltlng.en-de.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 1138 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 0.904491703223345 (18969/20972), penalty (log): -0.105593336496389
NIST score = 5.6085  BLEU score = 0.1820 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.4022   1.0316   0.1550   0.0173   0.0025   0.0006   0.0004   0.0000   0.0000  "Edinburgh"

 BLEU:  0.5629   0.2681   0.1431   0.0775   0.0428   0.0247   0.0138   0.0083   0.0045  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.4022   5.4338   5.5888   5.6060   5.6085   5.6091   5.6095   5.6095   5.6095  "Edinburgh"

 BLEU:  0.5065   0.3495   0.2506   0.1820   0.1334   0.0989   0.0736   0.0553   0.0413  "Edinburgh"
MT evaluation scorer ended on 2019 Aug 7 at 09:34:16
