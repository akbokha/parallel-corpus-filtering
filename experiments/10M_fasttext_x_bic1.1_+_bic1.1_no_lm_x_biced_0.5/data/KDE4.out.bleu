MT evaluation scorer began on 2019 Aug 8 at 09:43:20
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/10M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.5/data/KDE4.de.sgm -r ../experiments/10M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.5/data/KDE4.en.sgm -t ../experiments/10M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.5/data/KDE4.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 3000 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 0.900077441156455 (115065/127839), penalty (log): -0.111015512970929
NIST score = 5.8822  BLEU score = 0.1833 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.3918   1.1721   0.2522   0.0548   0.0113   0.0036   0.0014   0.0010   0.0006  "Edinburgh"

 BLEU:  0.5643   0.2615   0.1437   0.0831   0.0509   0.0332   0.0232   0.0170   0.0130  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.3918   5.5639   5.8161   5.8709   5.8822   5.8858   5.8872   5.8882   5.8888  "Edinburgh"

 BLEU:  0.5050   0.3438   0.2477   0.1833   0.1388   0.1074   0.0849   0.0685   0.0563  "Edinburgh"
MT evaluation scorer ended on 2019 Aug 8 at 09:43:59
