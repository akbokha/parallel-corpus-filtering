MT evaluation scorer began on 2019 Aug 7 at 12:01:59
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/10M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.5/data/globalvoices-2017.de.sgm -r ../experiments/10M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.5/data/globalvoices-2017.en.sgm -t ../experiments/10M_fasttext_x_bic1.1_+_bic1.1_no_lm_x_biced_0.5/data/globalvoices-2017.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 3000 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 1.01293611597897 (63582/62770), penalty (log): 0
NIST score = 6.1383  BLEU score = 0.2021 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.7794   1.1576   0.1802   0.0182   0.0030   0.0006   0.0002   0.0000   0.0000  "Edinburgh"

 BLEU:  0.5307   0.2590   0.1443   0.0840   0.0504   0.0308   0.0190   0.0120   0.0077  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.7794   5.9369   6.1171   6.1353   6.1383   6.1389   6.1390   6.1391   6.1391  "Edinburgh"

 BLEU:  0.5307   0.3708   0.2707   0.2021   0.1531   0.1172   0.0904   0.0702   0.0549  "Edinburgh"
MT evaluation scorer ended on 2019 Aug 7 at 12:02:20
