MT evaluation scorer began on 2019 Jul 1 at 15:43:19
command line:  /fs/bil0/abdel/mosesdecoder/scripts/generic/mteval-v13a.pl -c -s ../experiments/10M_hardrules_v1.0_dcce_scoring/data/EMEA.de.sgm -r ../experiments/10M_hardrules_v1.0_dcce_scoring/data/EMEA.en.sgm -t ../experiments/10M_hardrules_v1.0_dcce_scoring/data/EMEA.out.sgm
  Evaluation of any-to-any translation using:
    src set "test" (1 docs, 3000 segs)
    ref set "test" (1 refs)
    tst set "test" (1 systems)

length ratio: 0.951382880745723 (102267/107493), penalty (log): -0.0511015283522544
NIST score = 6.2217  BLEU score = 0.2182 for system "Edinburgh"

# ------------------------------------------------------------------------

Individual N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.6966   1.2117   0.2410   0.0555   0.0169   0.0062   0.0030   0.0019   0.0016  "Edinburgh"

 BLEU:  0.5617   0.2878   0.1678   0.1025   0.0651   0.0428   0.0291   0.0212   0.0162  "Edinburgh"

# ------------------------------------------------------------------------
Cumulative N-gram scoring
        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram
        ------   ------   ------   ------   ------   ------   ------   ------   ------
 NIST:  4.6966   5.9083   6.1493   6.2048   6.2217   6.2279   6.2309   6.2328   6.2344  "Edinburgh"

 BLEU:  0.5338   0.3821   0.2855   0.2182   0.1696   0.1337   0.1068   0.0867   0.0716  "Edinburgh"
MT evaluation scorer ended on 2019 Jul 1 at 15:43:52
