[2019-06-23 23:20:17] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-06-23 23:20:17] [marian] Running on elli as process 107857 with command line:
[2019-06-23 23:20:17] [marian] /fs/bil0/abdel/marian-dev/build/marian --model models/transformer-model-de-en/model/model.npz --type transformer --train-sets models/transformer-model-de-en/data/corpus.bpe.de models/transformer-model-de-en/data/corpus.bpe.en --max-length 100 --vocabs models/transformer-model-de-en/model/vocab.ende.yml models/transformer-model-de-en/model/vocab.ende.yml --mini-batch-fit -w 6000 --maxi-batch 1000 --early-stopping 10 --cost-type=ce-mean-words --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics cross-entropy ce-mean-words perplexity translation bleu --valid-sets models/transformer-model-de-en/data/valid.bpe.de models/transformer-model-de-en/data/valid.bpe.en --valid-script-path 'bash ../scripts/validate.sh en models/transformer-model-de-en/data' --valid-translation-output models/transformer-model-de-en/data/valid.bpe.de.output --quiet-translation --valid-mini-batch 64 --beam-size 6 --normalize 0.6 --log models/transformer-model-de-en/model/train.log --valid-log models/transformer-model-de-en/model/valid.log --enc-depth 6 --dec-depth 6 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --devices 1 2 --sync-sgd --seed 1111 --exponential-smoothing
[2019-06-23 23:20:17] [config] after-batches: 0
[2019-06-23 23:20:17] [config] after-epochs: 0
[2019-06-23 23:20:17] [config] allow-unk: false
[2019-06-23 23:20:17] [config] beam-size: 6
[2019-06-23 23:20:17] [config] bert-class-symbol: "[CLS]"
[2019-06-23 23:20:17] [config] bert-mask-symbol: "[MASK]"
[2019-06-23 23:20:17] [config] bert-masking-fraction: 0.15
[2019-06-23 23:20:17] [config] bert-sep-symbol: "[SEP]"
[2019-06-23 23:20:17] [config] bert-train-type-embeddings: true
[2019-06-23 23:20:17] [config] bert-type-vocab-size: 2
[2019-06-23 23:20:17] [config] best-deep: false
[2019-06-23 23:20:17] [config] clip-gemm: 0
[2019-06-23 23:20:17] [config] clip-norm: 5
[2019-06-23 23:20:17] [config] cost-type: ce-mean-words
[2019-06-23 23:20:17] [config] cpu-threads: 0
[2019-06-23 23:20:17] [config] data-weighting: ""
[2019-06-23 23:20:17] [config] data-weighting-type: sentence
[2019-06-23 23:20:17] [config] dec-cell: gru
[2019-06-23 23:20:17] [config] dec-cell-base-depth: 2
[2019-06-23 23:20:17] [config] dec-cell-high-depth: 1
[2019-06-23 23:20:17] [config] dec-depth: 6
[2019-06-23 23:20:17] [config] devices:
[2019-06-23 23:20:17] [config]   - 1
[2019-06-23 23:20:17] [config]   - 2
[2019-06-23 23:20:17] [config] dim-emb: 512
[2019-06-23 23:20:17] [config] dim-rnn: 1024
[2019-06-23 23:20:17] [config] dim-vocabs:
[2019-06-23 23:20:17] [config]   - 0
[2019-06-23 23:20:17] [config]   - 0
[2019-06-23 23:20:17] [config] disp-first: 0
[2019-06-23 23:20:17] [config] disp-freq: 500
[2019-06-23 23:20:17] [config] disp-label-counts: false
[2019-06-23 23:20:17] [config] dropout-rnn: 0
[2019-06-23 23:20:17] [config] dropout-src: 0
[2019-06-23 23:20:17] [config] dropout-trg: 0
[2019-06-23 23:20:17] [config] dump-config: ""
[2019-06-23 23:20:17] [config] early-stopping: 10
[2019-06-23 23:20:17] [config] embedding-fix-src: false
[2019-06-23 23:20:17] [config] embedding-fix-trg: false
[2019-06-23 23:20:17] [config] embedding-normalization: false
[2019-06-23 23:20:17] [config] embedding-vectors:
[2019-06-23 23:20:17] [config]   []
[2019-06-23 23:20:17] [config] enc-cell: gru
[2019-06-23 23:20:17] [config] enc-cell-depth: 1
[2019-06-23 23:20:17] [config] enc-depth: 6
[2019-06-23 23:20:17] [config] enc-type: bidirectional
[2019-06-23 23:20:17] [config] exponential-smoothing: 0.0001
[2019-06-23 23:20:17] [config] grad-dropping-momentum: 0
[2019-06-23 23:20:17] [config] grad-dropping-rate: 0
[2019-06-23 23:20:17] [config] grad-dropping-warmup: 100
[2019-06-23 23:20:17] [config] guided-alignment: none
[2019-06-23 23:20:17] [config] guided-alignment-cost: mse
[2019-06-23 23:20:17] [config] guided-alignment-weight: 0.1
[2019-06-23 23:20:17] [config] ignore-model-config: false
[2019-06-23 23:20:17] [config] input-types:
[2019-06-23 23:20:17] [config]   []
[2019-06-23 23:20:17] [config] interpolate-env-vars: false
[2019-06-23 23:20:17] [config] keep-best: false
[2019-06-23 23:20:17] [config] label-smoothing: 0.1
[2019-06-23 23:20:17] [config] layer-normalization: false
[2019-06-23 23:20:17] [config] learn-rate: 0.0003
[2019-06-23 23:20:17] [config] log: models/transformer-model-de-en/model/train.log
[2019-06-23 23:20:17] [config] log-level: info
[2019-06-23 23:20:17] [config] log-time-zone: ""
[2019-06-23 23:20:17] [config] lr-decay: 0
[2019-06-23 23:20:17] [config] lr-decay-freq: 50000
[2019-06-23 23:20:17] [config] lr-decay-inv-sqrt:
[2019-06-23 23:20:17] [config]   - 16000
[2019-06-23 23:20:17] [config] lr-decay-repeat-warmup: false
[2019-06-23 23:20:17] [config] lr-decay-reset-optimizer: false
[2019-06-23 23:20:17] [config] lr-decay-start:
[2019-06-23 23:20:17] [config]   - 10
[2019-06-23 23:20:17] [config]   - 1
[2019-06-23 23:20:17] [config] lr-decay-strategy: epoch+stalled
[2019-06-23 23:20:17] [config] lr-report: true
[2019-06-23 23:20:17] [config] lr-warmup: 16000
[2019-06-23 23:20:17] [config] lr-warmup-at-reload: false
[2019-06-23 23:20:17] [config] lr-warmup-cycle: false
[2019-06-23 23:20:17] [config] lr-warmup-start-rate: 0
[2019-06-23 23:20:17] [config] max-length: 100
[2019-06-23 23:20:17] [config] max-length-crop: false
[2019-06-23 23:20:17] [config] max-length-factor: 3
[2019-06-23 23:20:17] [config] maxi-batch: 1000
[2019-06-23 23:20:17] [config] maxi-batch-sort: trg
[2019-06-23 23:20:17] [config] mini-batch: 64
[2019-06-23 23:20:17] [config] mini-batch-fit: true
[2019-06-23 23:20:17] [config] mini-batch-fit-step: 10
[2019-06-23 23:20:17] [config] mini-batch-overstuff: 1
[2019-06-23 23:20:17] [config] mini-batch-track-lr: false
[2019-06-23 23:20:17] [config] mini-batch-understuff: 1
[2019-06-23 23:20:17] [config] mini-batch-warmup: 0
[2019-06-23 23:20:17] [config] mini-batch-words: 0
[2019-06-23 23:20:17] [config] mini-batch-words-ref: 0
[2019-06-23 23:20:17] [config] model: models/transformer-model-de-en/model/model.npz
[2019-06-23 23:20:17] [config] multi-loss-type: sum
[2019-06-23 23:20:17] [config] multi-node: false
[2019-06-23 23:20:17] [config] multi-node-overlap: true
[2019-06-23 23:20:17] [config] n-best: false
[2019-06-23 23:20:17] [config] no-nccl: false
[2019-06-23 23:20:17] [config] no-reload: false
[2019-06-23 23:20:17] [config] no-restore-corpus: false
[2019-06-23 23:20:17] [config] no-shuffle: false
[2019-06-23 23:20:17] [config] normalize: 0.6
[2019-06-23 23:20:17] [config] num-devices: 0
[2019-06-23 23:20:17] [config] optimizer: adam
[2019-06-23 23:20:17] [config] optimizer-delay: 1
[2019-06-23 23:20:17] [config] optimizer-params:
[2019-06-23 23:20:17] [config]   - 0.9
[2019-06-23 23:20:17] [config]   - 0.98
[2019-06-23 23:20:17] [config]   - 1e-09
[2019-06-23 23:20:17] [config] overwrite: false
[2019-06-23 23:20:17] [config] pretrained-model: ""
[2019-06-23 23:20:17] [config] quiet: false
[2019-06-23 23:20:17] [config] quiet-translation: true
[2019-06-23 23:20:17] [config] relative-paths: false
[2019-06-23 23:20:17] [config] right-left: false
[2019-06-23 23:20:17] [config] save-freq: 5000
[2019-06-23 23:20:17] [config] seed: 1111
[2019-06-23 23:20:17] [config] shuffle-in-ram: false
[2019-06-23 23:20:17] [config] skip: false
[2019-06-23 23:20:17] [config] sqlite: ""
[2019-06-23 23:20:17] [config] sqlite-drop: false
[2019-06-23 23:20:17] [config] sync-sgd: true
[2019-06-23 23:20:17] [config] tempdir: /tmp
[2019-06-23 23:20:17] [config] tied-embeddings: false
[2019-06-23 23:20:17] [config] tied-embeddings-all: true
[2019-06-23 23:20:17] [config] tied-embeddings-src: false
[2019-06-23 23:20:17] [config] train-sets:
[2019-06-23 23:20:17] [config]   - models/transformer-model-de-en/data/corpus.bpe.de
[2019-06-23 23:20:17] [config]   - models/transformer-model-de-en/data/corpus.bpe.en
[2019-06-23 23:20:17] [config] transformer-aan-activation: swish
[2019-06-23 23:20:17] [config] transformer-aan-depth: 2
[2019-06-23 23:20:17] [config] transformer-aan-nogate: false
[2019-06-23 23:20:17] [config] transformer-decoder-autoreg: self-attention
[2019-06-23 23:20:17] [config] transformer-dim-aan: 2048
[2019-06-23 23:20:17] [config] transformer-dim-ffn: 2048
[2019-06-23 23:20:17] [config] transformer-dropout: 0.1
[2019-06-23 23:20:17] [config] transformer-dropout-attention: 0
[2019-06-23 23:20:17] [config] transformer-dropout-ffn: 0
[2019-06-23 23:20:17] [config] transformer-ffn-activation: swish
[2019-06-23 23:20:17] [config] transformer-ffn-depth: 2
[2019-06-23 23:20:17] [config] transformer-guided-alignment-layer: last
[2019-06-23 23:20:17] [config] transformer-heads: 8
[2019-06-23 23:20:17] [config] transformer-no-projection: false
[2019-06-23 23:20:17] [config] transformer-postprocess: dan
[2019-06-23 23:20:17] [config] transformer-postprocess-emb: d
[2019-06-23 23:20:17] [config] transformer-preprocess: ""
[2019-06-23 23:20:17] [config] transformer-tied-layers:
[2019-06-23 23:20:17] [config]   []
[2019-06-23 23:20:17] [config] transformer-train-position-embeddings: false
[2019-06-23 23:20:17] [config] type: transformer
[2019-06-23 23:20:17] [config] ulr: false
[2019-06-23 23:20:17] [config] ulr-dim-emb: 0
[2019-06-23 23:20:17] [config] ulr-dropout: 0
[2019-06-23 23:20:17] [config] ulr-keys-vectors: ""
[2019-06-23 23:20:17] [config] ulr-query-vectors: ""
[2019-06-23 23:20:17] [config] ulr-softmax-temperature: 1
[2019-06-23 23:20:17] [config] ulr-trainable-transformation: false
[2019-06-23 23:20:17] [config] valid-freq: 5000
[2019-06-23 23:20:17] [config] valid-log: models/transformer-model-de-en/model/valid.log
[2019-06-23 23:20:17] [config] valid-max-length: 1000
[2019-06-23 23:20:17] [config] valid-metrics:
[2019-06-23 23:20:17] [config]   - cross-entropy
[2019-06-23 23:20:17] [config]   - ce-mean-words
[2019-06-23 23:20:17] [config]   - perplexity
[2019-06-23 23:20:17] [config]   - translation
[2019-06-23 23:20:17] [config]   - bleu
[2019-06-23 23:20:17] [config] valid-mini-batch: 64
[2019-06-23 23:20:17] [config] valid-script-path: bash ../scripts/validate.sh en models/transformer-model-de-en/data
[2019-06-23 23:20:17] [config] valid-sets:
[2019-06-23 23:20:17] [config]   - models/transformer-model-de-en/data/valid.bpe.de
[2019-06-23 23:20:17] [config]   - models/transformer-model-de-en/data/valid.bpe.en
[2019-06-23 23:20:17] [config] valid-translation-output: models/transformer-model-de-en/data/valid.bpe.de.output
[2019-06-23 23:20:17] [config] vocabs:
[2019-06-23 23:20:17] [config]   - models/transformer-model-de-en/model/vocab.ende.yml
[2019-06-23 23:20:17] [config]   - models/transformer-model-de-en/model/vocab.ende.yml
[2019-06-23 23:20:17] [config] word-penalty: 0
[2019-06-23 23:20:17] [config] workspace: 6000
[2019-06-23 23:20:17] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-06-23 23:20:17] Using synchronous training
[2019-06-23 23:20:17] [data] Loading vocabulary from JSON/Yaml file models/transformer-model-de-en/model/vocab.ende.yml
[2019-06-23 23:20:17] [data] Setting vocabulary size for input 0 to 36000
[2019-06-23 23:20:17] [data] Loading vocabulary from JSON/Yaml file models/transformer-model-de-en/model/vocab.ende.yml
[2019-06-23 23:20:17] [data] Setting vocabulary size for input 1 to 36000
[2019-06-23 23:20:17] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-06-23 23:20:17] [batching] Collecting statistics for batch fitting with step size 10
[2019-06-23 23:20:19] [memory] Extending reserved space to 6016 MB (device gpu1)
[2019-06-23 23:20:21] [memory] Extending reserved space to 6016 MB (device gpu2)
[2019-06-23 23:20:21] [comm] Using NCCL 2.4.2 for GPU communication
[2019-06-23 23:20:21] [comm] NCCLCommunicator constructed successfully.
[2019-06-23 23:20:21] [training] Using 2 GPUs
[2019-06-23 23:20:21] [memory] Reserving 238 MB, device gpu1
[2019-06-23 23:20:21] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-06-23 23:20:21] [memory] Reserving 238 MB, device gpu1
[2019-06-23 23:20:30] [batching] Done. Typical MB size is 7578 target words
[2019-06-23 23:20:30] [memory] Extending reserved space to 6016 MB (device gpu1)
[2019-06-23 23:20:30] [memory] Extending reserved space to 6016 MB (device gpu2)
[2019-06-23 23:20:30] [comm] Using NCCL 2.4.2 for GPU communication
[2019-06-23 23:20:30] [comm] NCCLCommunicator constructed successfully.
[2019-06-23 23:20:30] [training] Using 2 GPUs
[2019-06-23 23:20:30] Training started
[2019-06-23 23:20:30] [data] Shuffling data
[2019-06-23 23:20:33] [data] Done reading 4561263 sentences
[2019-06-23 23:20:53] [data] Done shuffling 4561263 sentences to temp files
[2019-06-23 23:20:56] [training] Batches are processed as 1 process(es) x 2 devices/process
[2019-06-23 23:20:56] [memory] Reserving 238 MB, device gpu1
[2019-06-23 23:20:56] [memory] Reserving 238 MB, device gpu2
[2019-06-23 23:20:56] [memory] Reserving 238 MB, device gpu1
[2019-06-23 23:20:56] [memory] Reserving 238 MB, device gpu2
[2019-06-23 23:20:56] [memory] Reserving 119 MB, device gpu1
[2019-06-23 23:20:56] [memory] Reserving 119 MB, device gpu2
[2019-06-23 23:20:57] [memory] Reserving 238 MB, device gpu2
[2019-06-23 23:20:57] [memory] Reserving 238 MB, device gpu1
[2019-06-23 23:23:32] Ep. 1 : Up. 500 : Sen. 85,555 : Cost 9.21728420 : Time 195.17s : 12901.90 words/s : L.r. 9.3750e-06
[2019-06-23 23:28:44] Ep. 1 : Up. 1000 : Sen. 172,189 : Cost 7.74996853 : Time 311.76s : 8266.22 words/s : L.r. 1.8750e-05
[2019-06-23 23:34:39] Ep. 1 : Up. 1500 : Sen. 258,643 : Cost 7.25697231 : Time 354.80s : 7141.23 words/s : L.r. 2.8125e-05
[2019-06-23 23:40:43] Ep. 1 : Up. 2000 : Sen. 344,497 : Cost 6.99816513 : Time 363.61s : 7024.35 words/s : L.r. 3.7500e-05
[2019-06-23 23:46:48] Ep. 1 : Up. 2500 : Sen. 431,538 : Cost 6.76066494 : Time 365.32s : 6939.89 words/s : L.r. 4.6875e-05
[2019-06-23 23:53:03] Ep. 1 : Up. 3000 : Sen. 517,517 : Cost 6.57524395 : Time 375.20s : 6777.54 words/s : L.r. 5.6250e-05
[2019-06-23 23:59:12] Ep. 1 : Up. 3500 : Sen. 605,156 : Cost 6.40377760 : Time 369.24s : 6926.88 words/s : L.r. 6.5625e-05
[2019-06-24 00:05:11] Ep. 1 : Up. 4000 : Sen. 689,422 : Cost 6.26376915 : Time 358.67s : 7083.62 words/s : L.r. 7.5000e-05
[2019-06-24 00:11:07] Ep. 1 : Up. 4500 : Sen. 776,392 : Cost 6.12974453 : Time 356.16s : 7144.39 words/s : L.r. 8.4375e-05
[2019-06-24 00:17:16] Ep. 1 : Up. 5000 : Sen. 864,405 : Cost 6.01540804 : Time 368.69s : 6964.72 words/s : L.r. 9.3750e-05
[2019-06-24 00:17:16] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.npz.orig.npz
[2019-06-24 00:17:22] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.iter5000.npz
[2019-06-24 00:17:26] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.npz
[2019-06-24 00:17:32] Saving Adam parameters to models/transformer-model-de-en/model/model.npz.optimizer.npz
[2019-06-24 00:17:45] [valid] Ep. 1 : Up. 5000 : cross-entropy : 141.917 : new best
[2019-06-24 00:17:47] [valid] Ep. 1 : Up. 5000 : ce-mean-words : 5.46239 : new best
[2019-06-24 00:17:48] [valid] Ep. 1 : Up. 5000 : perplexity : 235.66 : new best
[2019-06-24 00:26:55] [valid] Ep. 1 : Up. 5000 : translation : 0 : new best
[2019-06-24 00:34:36] [valid] Ep. 1 : Up. 5000 : bleu : 1.2659 : new best
[2019-06-24 00:40:24] Ep. 1 : Up. 5500 : Sen. 949,099 : Cost 5.92546320 : Time 1388.25s : 1830.08 words/s : L.r. 1.0313e-04
[2019-06-24 00:46:17] Ep. 1 : Up. 6000 : Sen. 1,034,192 : Cost 5.84204769 : Time 352.46s : 7107.84 words/s : L.r. 1.1250e-04
[2019-06-24 00:52:23] Ep. 1 : Up. 6500 : Sen. 1,121,619 : Cost 5.73560524 : Time 366.22s : 6973.31 words/s : L.r. 1.2188e-04
[2019-06-24 00:58:17] Ep. 1 : Up. 7000 : Sen. 1,206,940 : Cost 5.68436432 : Time 353.75s : 7125.30 words/s : L.r. 1.3125e-04
[2019-06-24 01:04:10] Ep. 1 : Up. 7500 : Sen. 1,293,035 : Cost 5.60026360 : Time 353.07s : 7214.77 words/s : L.r. 1.4063e-04
[2019-06-24 01:10:05] Ep. 1 : Up. 8000 : Sen. 1,379,258 : Cost 5.53071356 : Time 355.29s : 7127.00 words/s : L.r. 1.5000e-04
[2019-06-24 01:15:58] Ep. 1 : Up. 8500 : Sen. 1,466,090 : Cost 5.46148348 : Time 353.42s : 7208.37 words/s : L.r. 1.5938e-04
[2019-06-24 01:21:56] Ep. 1 : Up. 9000 : Sen. 1,552,317 : Cost 5.37048674 : Time 357.35s : 7163.12 words/s : L.r. 1.6875e-04
[2019-06-24 01:27:53] Ep. 1 : Up. 9500 : Sen. 1,638,260 : Cost 5.27670193 : Time 357.44s : 7112.30 words/s : L.r. 1.7813e-04
[2019-06-24 01:33:48] Ep. 1 : Up. 10000 : Sen. 1,723,478 : Cost 5.16969013 : Time 354.79s : 7139.27 words/s : L.r. 1.8750e-04
[2019-06-24 01:33:48] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.npz.orig.npz
[2019-06-24 01:33:54] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.iter10000.npz
[2019-06-24 01:33:58] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.npz
[2019-06-24 01:34:04] Saving Adam parameters to models/transformer-model-de-en/model/model.npz.optimizer.npz
[2019-06-24 01:34:17] [valid] Ep. 1 : Up. 10000 : cross-entropy : 117.74 : new best
[2019-06-24 01:34:19] [valid] Ep. 1 : Up. 10000 : ce-mean-words : 4.53183 : new best
[2019-06-24 01:34:21] [valid] Ep. 1 : Up. 10000 : perplexity : 92.9285 : new best
[2019-06-24 01:39:56] [valid] Ep. 1 : Up. 10000 : translation : 0 : stalled 1 times (last best: 0)
[2019-06-24 01:45:47] [valid] Ep. 1 : Up. 10000 : bleu : 3.08107 : new best
[2019-06-24 01:51:39] Ep. 1 : Up. 10500 : Sen. 1,810,477 : Cost 5.04754305 : Time 1071.36s : 2355.37 words/s : L.r. 1.9688e-04
[2019-06-24 01:57:38] Ep. 1 : Up. 11000 : Sen. 1,896,414 : Cost 4.95039463 : Time 358.99s : 7090.50 words/s : L.r. 2.0625e-04
[2019-06-24 02:03:38] Ep. 1 : Up. 11500 : Sen. 1,982,497 : Cost 4.80457067 : Time 359.42s : 7076.49 words/s : L.r. 2.1563e-04
[2019-06-24 02:09:26] Ep. 1 : Up. 12000 : Sen. 2,067,235 : Cost 4.68044472 : Time 348.04s : 7230.17 words/s : L.r. 2.2500e-04
[2019-06-24 02:15:13] Ep. 1 : Up. 12500 : Sen. 2,153,773 : Cost 4.55612803 : Time 346.82s : 7306.31 words/s : L.r. 2.3438e-04
[2019-06-24 02:21:12] Ep. 1 : Up. 13000 : Sen. 2,239,888 : Cost 4.44300747 : Time 359.64s : 7095.00 words/s : L.r. 2.4375e-04
[2019-06-24 02:27:03] Ep. 1 : Up. 13500 : Sen. 2,325,034 : Cost 4.37964010 : Time 350.77s : 7228.88 words/s : L.r. 2.5313e-04
[2019-06-24 02:32:51] Ep. 1 : Up. 14000 : Sen. 2,413,087 : Cost 4.26413536 : Time 348.19s : 7360.22 words/s : L.r. 2.6250e-04
[2019-06-24 02:38:40] Ep. 1 : Up. 14500 : Sen. 2,497,810 : Cost 4.22349596 : Time 348.46s : 7277.69 words/s : L.r. 2.7188e-04
[2019-06-24 02:44:28] Ep. 1 : Up. 15000 : Sen. 2,584,762 : Cost 4.17522335 : Time 348.18s : 7238.28 words/s : L.r. 2.8125e-04
[2019-06-24 02:44:28] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.npz.orig.npz
[2019-06-24 02:44:35] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.iter15000.npz
[2019-06-24 02:44:40] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.npz
[2019-06-24 02:44:47] Saving Adam parameters to models/transformer-model-de-en/model/model.npz.optimizer.npz
[2019-06-24 02:44:59] [valid] Ep. 1 : Up. 15000 : cross-entropy : 77.0203 : new best
[2019-06-24 02:45:01] [valid] Ep. 1 : Up. 15000 : ce-mean-words : 2.96453 : new best
[2019-06-24 02:45:03] [valid] Ep. 1 : Up. 15000 : perplexity : 19.3855 : new best
[2019-06-24 02:47:24] [valid] Ep. 1 : Up. 15000 : translation : 0 : stalled 2 times (last best: 0)
[2019-06-24 02:49:58] [valid] Ep. 1 : Up. 15000 : bleu : 17.7731 : new best
[2019-06-24 02:55:49] Ep. 1 : Up. 15500 : Sen. 2,669,758 : Cost 4.12593555 : Time 680.95s : 3714.97 words/s : L.r. 2.9063e-04
[2019-06-24 03:01:54] Ep. 1 : Up. 16000 : Sen. 2,756,641 : Cost 4.04937601 : Time 364.80s : 7116.59 words/s : L.r. 3.0000e-04
[2019-06-24 03:07:49] Ep. 1 : Up. 16500 : Sen. 2,842,389 : Cost 4.04718685 : Time 355.04s : 7147.71 words/s : L.r. 2.9542e-04
[2019-06-24 03:13:53] Ep. 1 : Up. 17000 : Sen. 2,928,604 : Cost 3.97204757 : Time 364.85s : 6955.25 words/s : L.r. 2.9104e-04
[2019-06-24 03:19:23] Ep. 1 : Up. 17500 : Sen. 3,013,152 : Cost 3.96938157 : Time 329.16s : 7725.64 words/s : L.r. 2.8685e-04
[2019-06-24 03:24:35] Ep. 1 : Up. 18000 : Sen. 3,100,100 : Cost 3.90178871 : Time 312.88s : 8105.43 words/s : L.r. 2.8284e-04
[2019-06-24 03:29:48] Ep. 1 : Up. 18500 : Sen. 3,186,010 : Cost 3.87929821 : Time 312.13s : 8123.92 words/s : L.r. 2.7899e-04
[2019-06-24 03:35:01] Ep. 1 : Up. 19000 : Sen. 3,272,778 : Cost 3.84582686 : Time 313.76s : 8149.35 words/s : L.r. 2.7530e-04
[2019-06-24 03:40:13] Ep. 1 : Up. 19500 : Sen. 3,359,271 : Cost 3.84263945 : Time 311.53s : 8035.53 words/s : L.r. 2.7175e-04
[2019-06-24 03:45:30] Ep. 1 : Up. 20000 : Sen. 3,444,410 : Cost 3.81423187 : Time 316.64s : 8041.65 words/s : L.r. 2.6833e-04
[2019-06-24 03:45:30] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.npz.orig.npz
[2019-06-24 03:45:36] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.iter20000.npz
[2019-06-24 03:45:40] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.npz
[2019-06-24 03:45:48] Saving Adam parameters to models/transformer-model-de-en/model/model.npz.optimizer.npz
[2019-06-24 03:46:01] [valid] Ep. 1 : Up. 20000 : cross-entropy : 63.5291 : new best
[2019-06-24 03:46:02] [valid] Ep. 1 : Up. 20000 : ce-mean-words : 2.44524 : new best
[2019-06-24 03:46:04] [valid] Ep. 1 : Up. 20000 : perplexity : 11.5334 : new best
[2019-06-24 03:46:52] [valid] Ep. 1 : Up. 20000 : translation : 0 : stalled 3 times (last best: 0)
[2019-06-24 03:47:53] [valid] Ep. 1 : Up. 20000 : bleu : 24.8217 : new best
[2019-06-24 03:53:03] Ep. 1 : Up. 20500 : Sen. 3,531,383 : Cost 3.77863336 : Time 452.99s : 5584.65 words/s : L.r. 2.6504e-04
[2019-06-24 03:58:20] Ep. 1 : Up. 21000 : Sen. 3,616,804 : Cost 3.76856375 : Time 316.99s : 8099.98 words/s : L.r. 2.6186e-04
[2019-06-24 04:03:33] Ep. 1 : Up. 21500 : Sen. 3,703,371 : Cost 3.74084115 : Time 313.56s : 8055.41 words/s : L.r. 2.5880e-04
[2019-06-24 04:08:46] Ep. 1 : Up. 22000 : Sen. 3,791,150 : Cost 3.72220159 : Time 312.97s : 8125.56 words/s : L.r. 2.5584e-04
[2019-06-24 04:14:01] Ep. 1 : Up. 22500 : Sen. 3,875,257 : Cost 3.70345831 : Time 315.35s : 8064.16 words/s : L.r. 2.5298e-04
[2019-06-24 04:19:20] Ep. 1 : Up. 23000 : Sen. 3,961,513 : Cost 3.71314406 : Time 318.60s : 7913.90 words/s : L.r. 2.5022e-04
[2019-06-24 04:24:38] Ep. 1 : Up. 23500 : Sen. 4,046,786 : Cost 3.70745349 : Time 318.39s : 7903.94 words/s : L.r. 2.4754e-04
[2019-06-24 04:30:06] Ep. 1 : Up. 24000 : Sen. 4,132,397 : Cost 3.64403892 : Time 327.51s : 7804.69 words/s : L.r. 2.4495e-04
[2019-06-24 04:36:13] Ep. 1 : Up. 24500 : Sen. 4,217,940 : Cost 3.66986156 : Time 367.40s : 6818.61 words/s : L.r. 2.4244e-04
[2019-06-24 04:42:35] Ep. 1 : Up. 25000 : Sen. 4,304,961 : Cost 3.62713480 : Time 381.57s : 6695.40 words/s : L.r. 2.4000e-04
[2019-06-24 04:42:35] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.npz.orig.npz
[2019-06-24 04:42:41] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.iter25000.npz
[2019-06-24 04:42:45] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.npz
[2019-06-24 04:42:50] Saving Adam parameters to models/transformer-model-de-en/model/model.npz.optimizer.npz
[2019-06-24 04:43:03] [valid] Ep. 1 : Up. 25000 : cross-entropy : 58.0501 : new best
[2019-06-24 04:43:05] [valid] Ep. 1 : Up. 25000 : ce-mean-words : 2.23436 : new best
[2019-06-24 04:43:07] [valid] Ep. 1 : Up. 25000 : perplexity : 9.34047 : new best
[2019-06-24 04:44:02] [valid] Ep. 1 : Up. 25000 : translation : 0 : stalled 4 times (last best: 0)
[2019-06-24 04:45:04] [valid] Ep. 1 : Up. 25000 : bleu : 27.2778 : new best
[2019-06-24 04:51:20] Ep. 1 : Up. 25500 : Sen. 4,389,939 : Cost 3.65105391 : Time 524.70s : 4773.02 words/s : L.r. 2.3764e-04
[2019-06-24 04:57:35] Ep. 1 : Up. 26000 : Sen. 4,476,657 : Cost 3.61793041 : Time 375.89s : 6786.53 words/s : L.r. 2.3534e-04
[2019-06-24 05:01:40] Seen 4532796 samples
[2019-06-24 05:01:40] Starting epoch 2
[2019-06-24 05:01:40] [data] Shuffling data
[2019-06-24 05:01:45] [data] Done reading 4561263 sentences
[2019-06-24 05:02:00] [data] Done shuffling 4561263 sentences to temp files
[2019-06-24 05:03:49] Ep. 2 : Up. 26500 : Sen. 27,341 : Cost 3.60521197 : Time 373.30s : 6681.20 words/s : L.r. 2.3311e-04
[2019-06-24 05:09:54] Ep. 2 : Up. 27000 : Sen. 113,503 : Cost 3.57926917 : Time 364.96s : 6833.72 words/s : L.r. 2.3094e-04
[2019-06-24 05:16:14] Ep. 2 : Up. 27500 : Sen. 198,278 : Cost 3.59076667 : Time 380.44s : 6723.28 words/s : L.r. 2.2883e-04
[2019-06-24 05:22:40] Ep. 2 : Up. 28000 : Sen. 285,658 : Cost 3.56024361 : Time 385.44s : 6612.43 words/s : L.r. 2.2678e-04
[2019-06-24 05:28:58] Ep. 2 : Up. 28500 : Sen. 372,571 : Cost 3.54197359 : Time 378.54s : 6776.65 words/s : L.r. 2.2478e-04
[2019-06-24 05:35:12] Ep. 2 : Up. 29000 : Sen. 456,382 : Cost 3.56055856 : Time 373.57s : 6729.16 words/s : L.r. 2.2283e-04
[2019-06-24 05:41:35] Ep. 2 : Up. 29500 : Sen. 542,700 : Cost 3.54941821 : Time 382.78s : 6627.50 words/s : L.r. 2.2094e-04
[2019-06-24 05:47:58] Ep. 2 : Up. 30000 : Sen. 629,675 : Cost 3.53402472 : Time 383.76s : 6639.05 words/s : L.r. 2.1909e-04
[2019-06-24 05:47:58] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.npz.orig.npz
[2019-06-24 05:48:04] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.iter30000.npz
[2019-06-24 05:48:09] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.npz
[2019-06-24 05:48:15] Saving Adam parameters to models/transformer-model-de-en/model/model.npz.optimizer.npz
[2019-06-24 05:48:28] [valid] Ep. 2 : Up. 30000 : cross-entropy : 54.9434 : new best
[2019-06-24 05:48:30] [valid] Ep. 2 : Up. 30000 : ce-mean-words : 2.11478 : new best
[2019-06-24 05:48:32] [valid] Ep. 2 : Up. 30000 : perplexity : 8.28778 : new best
[2019-06-24 05:49:28] [valid] Ep. 2 : Up. 30000 : translation : 0 : stalled 5 times (last best: 0)
[2019-06-24 05:50:36] [valid] Ep. 2 : Up. 30000 : bleu : 28.6764 : new best
[2019-06-24 05:56:53] Ep. 2 : Up. 30500 : Sen. 714,366 : Cost 3.55345321 : Time 534.53s : 4706.61 words/s : L.r. 2.1729e-04
[2019-06-24 06:03:05] Ep. 2 : Up. 31000 : Sen. 798,948 : Cost 3.53020430 : Time 372.07s : 6696.37 words/s : L.r. 2.1553e-04
[2019-06-24 06:09:14] Ep. 2 : Up. 31500 : Sen. 884,879 : Cost 3.49460173 : Time 368.81s : 6922.85 words/s : L.r. 2.1381e-04
[2019-06-24 06:15:28] Ep. 2 : Up. 32000 : Sen. 970,141 : Cost 3.52530980 : Time 374.43s : 6739.19 words/s : L.r. 2.1213e-04
[2019-06-24 06:21:36] Ep. 2 : Up. 32500 : Sen. 1,057,153 : Cost 3.48401976 : Time 368.22s : 6918.46 words/s : L.r. 2.1049e-04
[2019-06-24 06:27:47] Ep. 2 : Up. 33000 : Sen. 1,142,682 : Cost 3.52748394 : Time 370.90s : 6822.34 words/s : L.r. 2.0889e-04
[2019-06-24 06:34:05] Ep. 2 : Up. 33500 : Sen. 1,230,365 : Cost 3.47519040 : Time 377.90s : 6786.07 words/s : L.r. 2.0733e-04
[2019-06-24 06:40:16] Ep. 2 : Up. 34000 : Sen. 1,316,414 : Cost 3.48769426 : Time 370.91s : 6830.75 words/s : L.r. 2.0580e-04
[2019-06-24 06:46:33] Ep. 2 : Up. 34500 : Sen. 1,402,325 : Cost 3.48467469 : Time 377.43s : 6737.53 words/s : L.r. 2.0430e-04
[2019-06-24 06:52:43] Ep. 2 : Up. 35000 : Sen. 1,487,435 : Cost 3.47815180 : Time 369.50s : 6832.52 words/s : L.r. 2.0284e-04
[2019-06-24 06:52:43] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.npz.orig.npz
[2019-06-24 06:52:49] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.iter35000.npz
[2019-06-24 06:52:55] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.npz
[2019-06-24 06:53:01] Saving Adam parameters to models/transformer-model-de-en/model/model.npz.optimizer.npz
[2019-06-24 06:53:15] [valid] Ep. 2 : Up. 35000 : cross-entropy : 52.783 : new best
[2019-06-24 06:53:16] [valid] Ep. 2 : Up. 35000 : ce-mean-words : 2.03163 : new best
[2019-06-24 06:53:18] [valid] Ep. 2 : Up. 35000 : perplexity : 7.62648 : new best
[2019-06-24 06:54:14] [valid] Ep. 2 : Up. 35000 : translation : 0 : stalled 6 times (last best: 0)
[2019-06-24 06:55:15] [valid] Ep. 2 : Up. 35000 : bleu : 29.6804 : new best
[2019-06-24 07:01:30] Ep. 2 : Up. 35500 : Sen. 1,574,940 : Cost 3.46745944 : Time 527.35s : 4795.69 words/s : L.r. 2.0140e-04
[2019-06-24 07:07:50] Ep. 2 : Up. 36000 : Sen. 1,660,637 : Cost 3.46610093 : Time 379.52s : 6737.39 words/s : L.r. 2.0000e-04
[2019-06-24 07:14:09] Ep. 2 : Up. 36500 : Sen. 1,746,775 : Cost 3.46328902 : Time 378.75s : 6722.81 words/s : L.r. 1.9863e-04
[2019-06-24 07:20:18] Ep. 2 : Up. 37000 : Sen. 1,829,860 : Cost 3.45781422 : Time 369.62s : 6807.45 words/s : L.r. 1.9728e-04
[2019-06-24 07:26:45] Ep. 2 : Up. 37500 : Sen. 1,918,552 : Cost 3.44523835 : Time 387.00s : 6580.14 words/s : L.r. 1.9596e-04
[2019-06-24 07:33:05] Ep. 2 : Up. 38000 : Sen. 2,006,543 : Cost 3.42759061 : Time 379.49s : 6720.11 words/s : L.r. 1.9467e-04
[2019-06-24 07:39:11] Ep. 2 : Up. 38500 : Sen. 2,089,836 : Cost 3.48552656 : Time 366.39s : 6849.70 words/s : L.r. 1.9340e-04
[2019-06-24 07:45:37] Ep. 2 : Up. 39000 : Sen. 2,177,886 : Cost 3.41844606 : Time 385.64s : 6673.33 words/s : L.r. 1.9215e-04
[2019-06-24 07:51:55] Ep. 2 : Up. 39500 : Sen. 2,264,057 : Cost 3.44514561 : Time 378.71s : 6737.36 words/s : L.r. 1.9093e-04
[2019-06-24 07:58:12] Ep. 2 : Up. 40000 : Sen. 2,348,780 : Cost 3.42948270 : Time 376.82s : 6713.57 words/s : L.r. 1.8974e-04
[2019-06-24 07:58:12] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.npz.orig.npz
[2019-06-24 07:58:18] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.iter40000.npz
[2019-06-24 07:58:22] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.npz
[2019-06-24 07:58:28] Saving Adam parameters to models/transformer-model-de-en/model/model.npz.optimizer.npz
[2019-06-24 07:58:41] [valid] Ep. 2 : Up. 40000 : cross-entropy : 51.2505 : new best
[2019-06-24 07:58:43] [valid] Ep. 2 : Up. 40000 : ce-mean-words : 1.97264 : new best
[2019-06-24 07:58:45] [valid] Ep. 2 : Up. 40000 : perplexity : 7.18963 : new best
[2019-06-24 07:59:42] [valid] Ep. 2 : Up. 40000 : translation : 0 : stalled 7 times (last best: 0)
[2019-06-24 08:00:45] [valid] Ep. 2 : Up. 40000 : bleu : 30.1652 : new best
[2019-06-24 08:06:48] Ep. 2 : Up. 40500 : Sen. 2,435,807 : Cost 3.41398001 : Time 515.76s : 4919.11 words/s : L.r. 1.8856e-04
[2019-06-24 08:12:57] Ep. 2 : Up. 41000 : Sen. 2,520,280 : Cost 3.42354822 : Time 369.45s : 6851.50 words/s : L.r. 1.8741e-04
[2019-06-24 08:19:05] Ep. 2 : Up. 41500 : Sen. 2,608,246 : Cost 3.42273140 : Time 367.18s : 6871.64 words/s : L.r. 1.8628e-04
[2019-06-24 08:25:11] Ep. 2 : Up. 42000 : Sen. 2,692,913 : Cost 3.40325594 : Time 366.42s : 6929.09 words/s : L.r. 1.8516e-04
[2019-06-24 08:31:14] Ep. 2 : Up. 42500 : Sen. 2,779,891 : Cost 3.40493250 : Time 363.36s : 7018.49 words/s : L.r. 1.8407e-04
[2019-06-24 08:37:13] Ep. 2 : Up. 43000 : Sen. 2,864,731 : Cost 3.40992808 : Time 358.17s : 7018.62 words/s : L.r. 1.8300e-04
[2019-06-24 08:43:20] Ep. 2 : Up. 43500 : Sen. 2,951,666 : Cost 3.40167546 : Time 367.20s : 7015.90 words/s : L.r. 1.8194e-04
[2019-06-24 08:49:30] Ep. 2 : Up. 44000 : Sen. 3,037,062 : Cost 3.38302255 : Time 369.76s : 6885.60 words/s : L.r. 1.8091e-04
[2019-06-24 08:55:33] Ep. 2 : Up. 44500 : Sen. 3,123,017 : Cost 3.40642357 : Time 363.26s : 6911.34 words/s : L.r. 1.7989e-04
[2019-06-24 09:01:48] Ep. 2 : Up. 45000 : Sen. 3,209,264 : Cost 3.39246225 : Time 374.75s : 6754.26 words/s : L.r. 1.7889e-04
[2019-06-24 09:01:48] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.npz.orig.npz
[2019-06-24 09:01:54] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.iter45000.npz
[2019-06-24 09:01:58] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.npz
[2019-06-24 09:02:04] Saving Adam parameters to models/transformer-model-de-en/model/model.npz.optimizer.npz
[2019-06-24 09:02:18] [valid] Ep. 2 : Up. 45000 : cross-entropy : 50.0545 : new best
[2019-06-24 09:02:19] [valid] Ep. 2 : Up. 45000 : ce-mean-words : 1.92661 : new best
[2019-06-24 09:02:21] [valid] Ep. 2 : Up. 45000 : perplexity : 6.86616 : new best
[2019-06-24 09:03:18] [valid] Ep. 2 : Up. 45000 : translation : 0 : stalled 8 times (last best: 0)
[2019-06-24 09:04:19] [valid] Ep. 2 : Up. 45000 : bleu : 30.7874 : new best
[2019-06-24 09:10:42] Ep. 2 : Up. 45500 : Sen. 3,293,516 : Cost 3.38926840 : Time 534.03s : 4721.58 words/s : L.r. 1.7790e-04
[2019-06-24 09:17:05] Ep. 2 : Up. 46000 : Sen. 3,381,557 : Cost 3.36892080 : Time 383.11s : 6733.21 words/s : L.r. 1.7693e-04
[2019-06-24 09:23:30] Ep. 2 : Up. 46500 : Sen. 3,468,238 : Cost 3.37754202 : Time 385.68s : 6551.21 words/s : L.r. 1.7598e-04
[2019-06-24 09:29:58] Ep. 2 : Up. 47000 : Sen. 3,552,372 : Cost 3.37867165 : Time 387.63s : 6545.33 words/s : L.r. 1.7504e-04
[2019-06-24 09:36:26] Ep. 2 : Up. 47500 : Sen. 3,639,889 : Cost 3.37274599 : Time 388.34s : 6559.31 words/s : L.r. 1.7411e-04
[2019-06-24 09:42:58] Ep. 2 : Up. 48000 : Sen. 3,727,181 : Cost 3.36658216 : Time 391.91s : 6472.21 words/s : L.r. 1.7321e-04
[2019-06-24 09:49:37] Ep. 2 : Up. 48500 : Sen. 3,810,855 : Cost 3.38894558 : Time 398.82s : 6376.11 words/s : L.r. 1.7231e-04
[2019-06-24 09:56:05] Ep. 2 : Up. 49000 : Sen. 3,897,951 : Cost 3.35431552 : Time 388.12s : 6595.86 words/s : L.r. 1.7143e-04
[2019-06-24 10:02:22] Ep. 2 : Up. 49500 : Sen. 3,984,956 : Cost 3.36649799 : Time 376.55s : 6746.05 words/s : L.r. 1.7056e-04
[2019-06-24 10:07:46] Ep. 2 : Up. 50000 : Sen. 4,071,953 : Cost 3.36183739 : Time 323.84s : 7889.74 words/s : L.r. 1.6971e-04
[2019-06-24 10:07:46] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.npz.orig.npz
[2019-06-24 10:07:51] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.iter50000.npz
[2019-06-24 10:07:56] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.npz
[2019-06-24 10:08:02] Saving Adam parameters to models/transformer-model-de-en/model/model.npz.optimizer.npz
[2019-06-24 10:08:15] [valid] Ep. 2 : Up. 50000 : cross-entropy : 49.1003 : new best
[2019-06-24 10:08:16] [valid] Ep. 2 : Up. 50000 : ce-mean-words : 1.88988 : new best
[2019-06-24 10:08:18] [valid] Ep. 2 : Up. 50000 : perplexity : 6.61857 : new best
[2019-06-24 10:09:12] [valid] Ep. 2 : Up. 50000 : translation : 0 : stalled 9 times (last best: 0)
[2019-06-24 10:10:14] [valid] Ep. 2 : Up. 50000 : bleu : 31.1518 : new best
[2019-06-24 10:15:44] Ep. 2 : Up. 50500 : Sen. 4,157,322 : Cost 3.35873652 : Time 477.96s : 5307.03 words/s : L.r. 1.6886e-04
[2019-06-24 10:21:11] Ep. 2 : Up. 51000 : Sen. 4,243,600 : Cost 3.36083055 : Time 327.07s : 7744.71 words/s : L.r. 1.6803e-04
[2019-06-24 10:26:31] Ep. 2 : Up. 51500 : Sen. 4,328,602 : Cost 3.36421657 : Time 320.39s : 7832.40 words/s : L.r. 1.6722e-04
[2019-06-24 10:31:59] Ep. 2 : Up. 52000 : Sen. 4,414,946 : Cost 3.34422874 : Time 327.48s : 7785.90 words/s : L.r. 1.6641e-04
[2019-06-24 10:37:24] Ep. 2 : Up. 52500 : Sen. 4,502,291 : Cost 3.33265424 : Time 325.78s : 7770.50 words/s : L.r. 1.6562e-04
[2019-06-24 10:39:28] Seen 4532796 samples
[2019-06-24 10:39:28] Starting epoch 3
[2019-06-24 10:39:28] [data] Shuffling data
[2019-06-24 10:39:41] [data] Done reading 4561263 sentences
[2019-06-24 10:39:58] [data] Done shuffling 4561263 sentences to temp files
[2019-06-24 10:43:00] Ep. 3 : Up. 53000 : Sen. 54,021 : Cost 3.33443022 : Time 335.22s : 7565.72 words/s : L.r. 1.6483e-04
[2019-06-24 10:48:25] Ep. 3 : Up. 53500 : Sen. 139,293 : Cost 3.31483793 : Time 325.61s : 7777.22 words/s : L.r. 1.6406e-04
[2019-06-24 10:53:55] Ep. 3 : Up. 54000 : Sen. 225,946 : Cost 3.32385826 : Time 329.63s : 7700.16 words/s : L.r. 1.6330e-04
[2019-06-24 10:59:23] Ep. 3 : Up. 54500 : Sen. 311,616 : Cost 3.32230544 : Time 328.34s : 7718.14 words/s : L.r. 1.6255e-04
[2019-06-24 11:04:48] Ep. 3 : Up. 55000 : Sen. 396,770 : Cost 3.32893467 : Time 325.11s : 7707.49 words/s : L.r. 1.6181e-04
[2019-06-24 11:04:48] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.npz.orig.npz
[2019-06-24 11:04:55] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.iter55000.npz
[2019-06-24 11:04:59] Saving model weights and runtime parameters to models/transformer-model-de-en/model/model.npz
[2019-06-24 11:05:05] Saving Adam parameters to models/transformer-model-de-en/model/model.npz.optimizer.npz
[2019-06-24 11:05:17] [valid] Ep. 3 : Up. 55000 : cross-entropy : 48.3541 : new best
[2019-06-24 11:05:19] [valid] Ep. 3 : Up. 55000 : ce-mean-words : 1.86116 : new best
[2019-06-24 11:05:21] [valid] Ep. 3 : Up. 55000 : perplexity : 6.43117 : new best
[2019-06-24 11:06:16] [valid] Ep. 3 : Up. 55000 : translation : 0 : stalled 10 times (last best: 0)
[2019-06-24 11:07:18] [valid] Ep. 3 : Up. 55000 : bleu : 31.3786 : new best
[2019-06-24 11:12:48] Ep. 3 : Up. 55500 : Sen. 483,338 : Cost 3.30426812 : Time 479.46s : 5341.59 words/s : L.r. 1.6108e-04
[2019-06-24 11:19:06] Ep. 3 : Up. 56000 : Sen. 568,919 : Cost 3.31283784 : Time 378.62s : 6716.18 words/s : L.r. 1.6036e-04
[2019-06-24 11:25:43] Ep. 3 : Up. 56500 : Sen. 655,724 : Cost 3.29176068 : Time 396.64s : 6453.17 words/s : L.r. 1.5965e-04
[2019-06-24 11:32:13] Ep. 3 : Up. 57000 : Sen. 742,144 : Cost 3.31026244 : Time 389.66s : 6537.19 words/s : L.r. 1.5894e-04
[2019-06-24 11:38:36] Ep. 3 : Up. 57500 : Sen. 829,005 : Cost 3.30715251 : Time 383.29s : 6606.56 words/s : L.r. 1.5825e-04
[2019-06-24 11:45:05] Ep. 3 : Up. 58000 : Sen. 913,844 : Cost 3.31806397 : Time 388.97s : 6512.59 words/s : L.r. 1.5757e-04
