[2019-07-10 02:32:09] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-10 02:32:09] [marian] Running on fulla as process 144051 with command line:
[2019-07-10 02:32:09] [marian] /fs/bil0/abdel/marian-dev/build/marian --model models/wmt2017-transformer-de-en/model/model/ens2/model.npz --type transformer --train-sets models/wmt2017-transformer-de-en/data/all.bpe.de models/wmt2017-transformer-de-en/data/all.bpe.en --max-length 100 --vocabs models/wmt2017-transformer-de-en/model/vocab.ende.yml models/wmt2017-transformer-de-en/model/vocab.ende.yml --mini-batch-fit -w 6000 --mini-batch 1000 --maxi-batch 1000 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics ce-mean-words perplexity translation --valid-sets models/wmt2017-transformer-de-en/data/valid.bpe.de models/wmt2017-transformer-de-en/data/valid.bpe.en --valid-script-path 'bash ./models/wmt2017-transformer-de-en/validate.sh' --valid-translation-output models/wmt2017-transformer-de-en/data/valid.bpe.de.output --quiet-translation --beam-size 12 --normalize=1 --valid-mini-batch 64 --overwrite --keep-best --early-stopping 5 --after-epochs 8 --cost-type=ce-mean-words --log models/wmt2017-transformer-de-en/model/model/ens2/train.log --valid-log models/wmt2017-transformer-de-en/model/model/ens2/valid.log --enc-depth 6 --dec-depth 6 --tied-embeddings-all --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --devices 5 6 --sync-sgd --seed 2222 --exponential-smoothing
[2019-07-10 02:32:09] [config] after-batches: 0
[2019-07-10 02:32:09] [config] after-epochs: 8
[2019-07-10 02:32:09] [config] allow-unk: false
[2019-07-10 02:32:09] [config] beam-size: 12
[2019-07-10 02:32:09] [config] bert-class-symbol: "[CLS]"
[2019-07-10 02:32:09] [config] bert-mask-symbol: "[MASK]"
[2019-07-10 02:32:09] [config] bert-masking-fraction: 0.15
[2019-07-10 02:32:09] [config] bert-sep-symbol: "[SEP]"
[2019-07-10 02:32:09] [config] bert-train-type-embeddings: true
[2019-07-10 02:32:09] [config] bert-type-vocab-size: 2
[2019-07-10 02:32:09] [config] best-deep: false
[2019-07-10 02:32:09] [config] clip-gemm: 0
[2019-07-10 02:32:09] [config] clip-norm: 5
[2019-07-10 02:32:09] [config] cost-type: ce-mean-words
[2019-07-10 02:32:09] [config] cpu-threads: 0
[2019-07-10 02:32:09] [config] data-weighting: ""
[2019-07-10 02:32:09] [config] data-weighting-type: sentence
[2019-07-10 02:32:09] [config] dec-cell: gru
[2019-07-10 02:32:09] [config] dec-cell-base-depth: 2
[2019-07-10 02:32:09] [config] dec-cell-high-depth: 1
[2019-07-10 02:32:09] [config] dec-depth: 6
[2019-07-10 02:32:09] [config] devices:
[2019-07-10 02:32:09] [config]   - 5
[2019-07-10 02:32:09] [config]   - 6
[2019-07-10 02:32:09] [config] dim-emb: 512
[2019-07-10 02:32:09] [config] dim-rnn: 1024
[2019-07-10 02:32:09] [config] dim-vocabs:
[2019-07-10 02:32:09] [config]   - 0
[2019-07-10 02:32:09] [config]   - 0
[2019-07-10 02:32:09] [config] disp-first: 0
[2019-07-10 02:32:09] [config] disp-freq: 500
[2019-07-10 02:32:09] [config] disp-label-counts: false
[2019-07-10 02:32:09] [config] dropout-rnn: 0
[2019-07-10 02:32:09] [config] dropout-src: 0
[2019-07-10 02:32:09] [config] dropout-trg: 0
[2019-07-10 02:32:09] [config] dump-config: ""
[2019-07-10 02:32:09] [config] early-stopping: 5
[2019-07-10 02:32:09] [config] embedding-fix-src: false
[2019-07-10 02:32:09] [config] embedding-fix-trg: false
[2019-07-10 02:32:09] [config] embedding-normalization: false
[2019-07-10 02:32:09] [config] embedding-vectors:
[2019-07-10 02:32:09] [config]   []
[2019-07-10 02:32:09] [config] enc-cell: gru
[2019-07-10 02:32:09] [config] enc-cell-depth: 1
[2019-07-10 02:32:09] [config] enc-depth: 6
[2019-07-10 02:32:09] [config] enc-type: bidirectional
[2019-07-10 02:32:09] [config] exponential-smoothing: 0.0001
[2019-07-10 02:32:09] [config] grad-dropping-momentum: 0
[2019-07-10 02:32:09] [config] grad-dropping-rate: 0
[2019-07-10 02:32:09] [config] grad-dropping-warmup: 100
[2019-07-10 02:32:09] [config] guided-alignment: none
[2019-07-10 02:32:09] [config] guided-alignment-cost: mse
[2019-07-10 02:32:09] [config] guided-alignment-weight: 0.1
[2019-07-10 02:32:09] [config] ignore-model-config: false
[2019-07-10 02:32:09] [config] input-types:
[2019-07-10 02:32:09] [config]   []
[2019-07-10 02:32:09] [config] interpolate-env-vars: false
[2019-07-10 02:32:09] [config] keep-best: true
[2019-07-10 02:32:09] [config] label-smoothing: 0.1
[2019-07-10 02:32:09] [config] layer-normalization: false
[2019-07-10 02:32:09] [config] learn-rate: 0.0003
[2019-07-10 02:32:09] [config] log: models/wmt2017-transformer-de-en/model/model/ens2/train.log
[2019-07-10 02:32:09] [config] log-level: info
[2019-07-10 02:32:09] [config] log-time-zone: ""
[2019-07-10 02:32:09] [config] lr-decay: 0
[2019-07-10 02:32:09] [config] lr-decay-freq: 50000
[2019-07-10 02:32:09] [config] lr-decay-inv-sqrt:
[2019-07-10 02:32:09] [config]   - 16000
[2019-07-10 02:32:09] [config] lr-decay-repeat-warmup: false
[2019-07-10 02:32:09] [config] lr-decay-reset-optimizer: false
[2019-07-10 02:32:09] [config] lr-decay-start:
[2019-07-10 02:32:09] [config]   - 10
[2019-07-10 02:32:09] [config]   - 1
[2019-07-10 02:32:09] [config] lr-decay-strategy: epoch+stalled
[2019-07-10 02:32:09] [config] lr-report: true
[2019-07-10 02:32:09] [config] lr-warmup: 16000
[2019-07-10 02:32:09] [config] lr-warmup-at-reload: false
[2019-07-10 02:32:09] [config] lr-warmup-cycle: false
[2019-07-10 02:32:09] [config] lr-warmup-start-rate: 0
[2019-07-10 02:32:09] [config] max-length: 100
[2019-07-10 02:32:09] [config] max-length-crop: false
[2019-07-10 02:32:09] [config] max-length-factor: 3
[2019-07-10 02:32:09] [config] maxi-batch: 1000
[2019-07-10 02:32:09] [config] maxi-batch-sort: trg
[2019-07-10 02:32:09] [config] mini-batch: 1000
[2019-07-10 02:32:09] [config] mini-batch-fit: true
[2019-07-10 02:32:09] [config] mini-batch-fit-step: 10
[2019-07-10 02:32:09] [config] mini-batch-overstuff: 1
[2019-07-10 02:32:09] [config] mini-batch-track-lr: false
[2019-07-10 02:32:09] [config] mini-batch-understuff: 1
[2019-07-10 02:32:09] [config] mini-batch-warmup: 0
[2019-07-10 02:32:09] [config] mini-batch-words: 0
[2019-07-10 02:32:09] [config] mini-batch-words-ref: 0
[2019-07-10 02:32:09] [config] model: models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 02:32:09] [config] multi-loss-type: sum
[2019-07-10 02:32:09] [config] multi-node: false
[2019-07-10 02:32:09] [config] multi-node-overlap: true
[2019-07-10 02:32:09] [config] n-best: false
[2019-07-10 02:32:09] [config] no-nccl: false
[2019-07-10 02:32:09] [config] no-reload: false
[2019-07-10 02:32:09] [config] no-restore-corpus: false
[2019-07-10 02:32:09] [config] no-shuffle: false
[2019-07-10 02:32:09] [config] normalize: 1
[2019-07-10 02:32:09] [config] num-devices: 0
[2019-07-10 02:32:09] [config] optimizer: adam
[2019-07-10 02:32:09] [config] optimizer-delay: 1
[2019-07-10 02:32:09] [config] optimizer-params:
[2019-07-10 02:32:09] [config]   - 0.9
[2019-07-10 02:32:09] [config]   - 0.98
[2019-07-10 02:32:09] [config]   - 1e-09
[2019-07-10 02:32:09] [config] overwrite: true
[2019-07-10 02:32:09] [config] pretrained-model: ""
[2019-07-10 02:32:09] [config] quiet: false
[2019-07-10 02:32:09] [config] quiet-translation: true
[2019-07-10 02:32:09] [config] relative-paths: false
[2019-07-10 02:32:09] [config] right-left: false
[2019-07-10 02:32:09] [config] save-freq: 5000
[2019-07-10 02:32:09] [config] seed: 2222
[2019-07-10 02:32:09] [config] shuffle-in-ram: false
[2019-07-10 02:32:09] [config] skip: false
[2019-07-10 02:32:09] [config] sqlite: ""
[2019-07-10 02:32:09] [config] sqlite-drop: false
[2019-07-10 02:32:09] [config] sync-sgd: true
[2019-07-10 02:32:09] [config] tempdir: /tmp
[2019-07-10 02:32:09] [config] tied-embeddings: false
[2019-07-10 02:32:09] [config] tied-embeddings-all: true
[2019-07-10 02:32:09] [config] tied-embeddings-src: false
[2019-07-10 02:32:09] [config] train-sets:
[2019-07-10 02:32:09] [config]   - models/wmt2017-transformer-de-en/data/all.bpe.de
[2019-07-10 02:32:09] [config]   - models/wmt2017-transformer-de-en/data/all.bpe.en
[2019-07-10 02:32:09] [config] transformer-aan-activation: swish
[2019-07-10 02:32:09] [config] transformer-aan-depth: 2
[2019-07-10 02:32:09] [config] transformer-aan-nogate: false
[2019-07-10 02:32:09] [config] transformer-decoder-autoreg: self-attention
[2019-07-10 02:32:09] [config] transformer-dim-aan: 2048
[2019-07-10 02:32:09] [config] transformer-dim-ffn: 2048
[2019-07-10 02:32:09] [config] transformer-dropout: 0.1
[2019-07-10 02:32:09] [config] transformer-dropout-attention: 0
[2019-07-10 02:32:09] [config] transformer-dropout-ffn: 0
[2019-07-10 02:32:09] [config] transformer-ffn-activation: swish
[2019-07-10 02:32:09] [config] transformer-ffn-depth: 2
[2019-07-10 02:32:09] [config] transformer-guided-alignment-layer: last
[2019-07-10 02:32:09] [config] transformer-heads: 8
[2019-07-10 02:32:09] [config] transformer-no-projection: false
[2019-07-10 02:32:09] [config] transformer-postprocess: dan
[2019-07-10 02:32:09] [config] transformer-postprocess-emb: d
[2019-07-10 02:32:09] [config] transformer-preprocess: ""
[2019-07-10 02:32:09] [config] transformer-tied-layers:
[2019-07-10 02:32:09] [config]   []
[2019-07-10 02:32:09] [config] transformer-train-position-embeddings: false
[2019-07-10 02:32:09] [config] type: transformer
[2019-07-10 02:32:09] [config] ulr: false
[2019-07-10 02:32:09] [config] ulr-dim-emb: 0
[2019-07-10 02:32:09] [config] ulr-dropout: 0
[2019-07-10 02:32:09] [config] ulr-keys-vectors: ""
[2019-07-10 02:32:09] [config] ulr-query-vectors: ""
[2019-07-10 02:32:09] [config] ulr-softmax-temperature: 1
[2019-07-10 02:32:09] [config] ulr-trainable-transformation: false
[2019-07-10 02:32:09] [config] valid-freq: 5000
[2019-07-10 02:32:09] [config] valid-log: models/wmt2017-transformer-de-en/model/model/ens2/valid.log
[2019-07-10 02:32:09] [config] valid-max-length: 1000
[2019-07-10 02:32:09] [config] valid-metrics:
[2019-07-10 02:32:09] [config]   - ce-mean-words
[2019-07-10 02:32:09] [config]   - perplexity
[2019-07-10 02:32:09] [config]   - translation
[2019-07-10 02:32:09] [config] valid-mini-batch: 64
[2019-07-10 02:32:09] [config] valid-script-path: bash ./models/wmt2017-transformer-de-en/validate.sh
[2019-07-10 02:32:09] [config] valid-sets:
[2019-07-10 02:32:09] [config]   - models/wmt2017-transformer-de-en/data/valid.bpe.de
[2019-07-10 02:32:09] [config]   - models/wmt2017-transformer-de-en/data/valid.bpe.en
[2019-07-10 02:32:09] [config] valid-translation-output: models/wmt2017-transformer-de-en/data/valid.bpe.de.output
[2019-07-10 02:32:09] [config] vocabs:
[2019-07-10 02:32:09] [config]   - models/wmt2017-transformer-de-en/model/vocab.ende.yml
[2019-07-10 02:32:09] [config]   - models/wmt2017-transformer-de-en/model/vocab.ende.yml
[2019-07-10 02:32:09] [config] word-penalty: 0
[2019-07-10 02:32:09] [config] workspace: 6000
[2019-07-10 02:32:09] [config] Model is being created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-10 02:32:09] Using synchronous training
[2019-07-10 02:32:09] [data] Loading vocabulary from JSON/Yaml file models/wmt2017-transformer-de-en/model/vocab.ende.yml
[2019-07-10 02:32:09] [data] Setting vocabulary size for input 0 to 36000
[2019-07-10 02:32:09] [data] Loading vocabulary from JSON/Yaml file models/wmt2017-transformer-de-en/model/vocab.ende.yml
[2019-07-10 02:32:09] [data] Setting vocabulary size for input 1 to 36000
[2019-07-10 02:32:09] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-10 02:32:09] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-10 02:32:10] [memory] Extending reserved space to 6016 MB (device gpu5)
[2019-07-10 02:32:11] [memory] Extending reserved space to 6016 MB (device gpu6)
[2019-07-10 02:32:12] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-10 02:32:12] [comm] NCCLCommunicator constructed successfully.
[2019-07-10 02:32:12] [training] Using 2 GPUs
[2019-07-10 02:32:12] [memory] Reserving 238 MB, device gpu5
[2019-07-10 02:32:12] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-10 02:32:12] [memory] Reserving 238 MB, device gpu5
[2019-07-10 02:32:17] [batching] Done. Typical MB size is 7578 target words
[2019-07-10 02:32:17] [memory] Extending reserved space to 6016 MB (device gpu5)
[2019-07-10 02:32:17] [memory] Extending reserved space to 6016 MB (device gpu6)
[2019-07-10 02:32:17] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-10 02:32:17] [comm] NCCLCommunicator constructed successfully.
[2019-07-10 02:32:17] [training] Using 2 GPUs
[2019-07-10 02:32:17] Training started
[2019-07-10 02:32:17] [data] Shuffling data
[2019-07-10 02:32:31] [data] Done reading 19122526 sentences
[2019-07-10 02:34:45] [data] Done shuffling 19122526 sentences to temp files
[2019-07-10 02:35:26] [training] Batches are processed as 1 process(es) x 2 devices/process
[2019-07-10 02:35:26] [memory] Reserving 238 MB, device gpu5
[2019-07-10 02:35:26] [memory] Reserving 238 MB, device gpu6
[2019-07-10 02:35:26] [memory] Reserving 238 MB, device gpu5
[2019-07-10 02:35:26] [memory] Reserving 238 MB, device gpu6
[2019-07-10 02:35:26] [memory] Reserving 119 MB, device gpu5
[2019-07-10 02:35:26] [memory] Reserving 119 MB, device gpu6
[2019-07-10 02:35:26] [memory] Reserving 238 MB, device gpu5
[2019-07-10 02:35:26] [memory] Reserving 238 MB, device gpu6
[2019-07-10 02:37:08] Ep. 1 : Up. 500 : Sen. 107,384 : Cost 9.35169411 : Time 299.17s : 10432.34 words/s : L.r. 9.3750e-06
[2019-07-10 02:38:50] Ep. 1 : Up. 1000 : Sen. 218,600 : Cost 7.90758467 : Time 101.77s : 30094.19 words/s : L.r. 1.8750e-05
[2019-07-10 02:40:32] Ep. 1 : Up. 1500 : Sen. 328,814 : Cost 7.44302130 : Time 101.81s : 30265.21 words/s : L.r. 2.8125e-05
[2019-07-10 02:42:13] Ep. 1 : Up. 2000 : Sen. 436,675 : Cost 7.18329811 : Time 100.77s : 29938.30 words/s : L.r. 3.7500e-05
[2019-07-10 02:43:55] Ep. 1 : Up. 2500 : Sen. 550,562 : Cost 6.91902971 : Time 102.56s : 30377.87 words/s : L.r. 4.6875e-05
[2019-07-10 02:45:37] Ep. 1 : Up. 3000 : Sen. 658,466 : Cost 6.70521641 : Time 101.73s : 30161.98 words/s : L.r. 5.6250e-05
[2019-07-10 02:47:19] Ep. 1 : Up. 3500 : Sen. 760,249 : Cost 6.53176737 : Time 102.06s : 30391.37 words/s : L.r. 6.5625e-05
[2019-07-10 02:49:02] Ep. 1 : Up. 4000 : Sen. 867,281 : Cost 6.33219862 : Time 102.79s : 30400.72 words/s : L.r. 7.5000e-05
[2019-07-10 02:50:43] Ep. 1 : Up. 4500 : Sen. 968,800 : Cost 6.19159651 : Time 101.63s : 30079.58 words/s : L.r. 8.4375e-05
[2019-07-10 02:52:25] Ep. 1 : Up. 5000 : Sen. 1,077,181 : Cost 5.94622040 : Time 101.54s : 30178.44 words/s : L.r. 9.3750e-05
[2019-07-10 02:52:25] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 02:52:31] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 02:52:38] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 02:52:52] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 02:52:56] [valid] Ep. 1 : Up. 5000 : ce-mean-words : 5.11681 : new best
[2019-07-10 02:52:57] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 02:53:06] [valid] Ep. 1 : Up. 5000 : perplexity : 166.803 : new best
[2019-07-10 02:58:34] Error: CUDA error 2 'out of memory' - /fs/bil0/abdel/marian-dev/src/tensors/gpu/device.cu:32: cudaMalloc(&data_, size)
[2019-07-10 02:58:34] Error: Aborted from virtual void marian::gpu::Device::reserve(size_t) in /fs/bil0/abdel/marian-dev/src/tensors/gpu/device.cu:32

[CALL STACK]
[0x19f2e87]         marian::gpu::Device::  reserve  (unsigned long)    + 0xfc7
[0x74e76d]          marian::TensorAllocator::  allocate  (std::shared_ptr<marian::TensorBase>&,  marian::Shape,  marian::Type) + 0x5fd
[0x8076b3]          marian::Tensors::  allocateForward  (std::shared_ptr<marian::Chainable<std::shared_ptr<marian::TensorBase>>>) + 0x163
[0x80607e]          marian::Node::  allocate  ()                       + 0x12e
[0x64050a]          marian::ExpressionGraph::  forwardNext  ()         + 0xaa
[0x657027]          marian::BeamSearch::  search  (std::shared_ptr<marian::ExpressionGraph>,  std::shared_ptr<marian::data::CorpusBatch>) + 0x57d7
[0x979b55]          marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}::  operator()  (unsigned long) const + 0x1e5
[0x97a2d9]          std::future<std::result_of<marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}& (unsigned long&)>::type> marian::ThreadPool::enqueue<marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}&,unsigned long&>(std::result_of&&,(marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}&)...)::{lambda()#1}::  operator()  () const + 0x29
[0x97acdc]          std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base,std::__future_base::_Result_base::_Deleter> (),std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<void>,std::__future_base::_Result_base::_Deleter>,std::_Bind_simple<std::reference_wrapper<std::future<std::result_of<marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}& (unsigned long&)>::type> marian::ThreadPool::enqueue<marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}&,unsigned long&>(std::result_of&&,(marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}&)...)::{lambda()#1}> ()>,void>>::  _M_invoke [0x5a5f19]          std::__future_base::_State_baseV2::  _M_do_set  (std::function<std::unique_ptr<std::__future_base::_Result_base,std::__future_base::_Result_base::_Deleter> ()>*,  bool*) + 0x29
[0x7f94b02bea99]                                                       + 0xea99
[0x96d04f]          std::__future_base::_Task_state<std::future<std::result_of<marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}& (unsigned long&)>::type> marian::ThreadPool::enqueue<marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}&,unsigned long&>(std::result_of&&,(marian::TranslationValidator::validate(std::vector<std::shared_ptr<marian::ExpressionGraph>,std::allocator<std::shared_ptr<marian::ExpressionGraph>>> const&)::{lambda(unsigned long)#1}&)...)::{lambda()#1},std::allocator<int>,void ()>::  _M_run  () + 0xcf
[0x5d00b4]          std::thread::_Impl<std::_Bind_simple<marian::ThreadPool::reserve(unsigned long)::{lambda()#1} ()>>::  _M_run  () + 0x174
[0x7f94afddec80]                                                       + 0xb8c80
[0x7f94b02b76ba]                                                       + 0x76ba
[0x7f94af54441d]    clone                                              + 0x6d

[2019-07-10 09:19:23] [marian] Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-10 09:19:23] [marian] Running on fulla as process 205694 with command line:
[2019-07-10 09:19:23] [marian] /fs/bil0/abdel/marian-dev/build/marian --model models/wmt2017-transformer-de-en/model/model/ens2/model.npz --type transformer --train-sets models/wmt2017-transformer-de-en/data/all.bpe.de models/wmt2017-transformer-de-en/data/all.bpe.en --max-length 50 --valid-max-length 50 --vocabs models/wmt2017-transformer-de-en/model/vocab.ende.yml models/wmt2017-transformer-de-en/model/vocab.ende.yml --mini-batch-fit -w 8000 --mini-batch 1000 --maxi-batch 1000 --valid-freq 5000 --save-freq 5000 --disp-freq 500 --valid-metrics ce-mean-words perplexity translation --valid-sets models/wmt2017-transformer-de-en/data/valid.bpe.de models/wmt2017-transformer-de-en/data/valid.bpe.en --valid-script-path 'bash ./models/wmt2017-transformer-de-en/validate.sh' --valid-translation-output models/wmt2017-transformer-de-en/data/valid.bpe.de.output --quiet-translation --beam-size 12 --normalize=1 --valid-mini-batch 64 --overwrite --keep-best --early-stopping 5 --after-epochs 8 --cost-type=ce-mean-words --log models/wmt2017-transformer-de-en/model/model/ens2/train.log --valid-log models/wmt2017-transformer-de-en/model/model/ens2/valid.log --enc-depth 6 --dec-depth 6 --tied-embeddings-all --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --devices 5 7 --sync-sgd --seed 2222 --exponential-smoothing
[2019-07-10 09:19:24] [config] after-batches: 0
[2019-07-10 09:19:24] [config] after-epochs: 8
[2019-07-10 09:19:24] [config] allow-unk: false
[2019-07-10 09:19:24] [config] beam-size: 12
[2019-07-10 09:19:24] [config] bert-class-symbol: "[CLS]"
[2019-07-10 09:19:24] [config] bert-mask-symbol: "[MASK]"
[2019-07-10 09:19:24] [config] bert-masking-fraction: 0.15
[2019-07-10 09:19:24] [config] bert-sep-symbol: "[SEP]"
[2019-07-10 09:19:24] [config] bert-train-type-embeddings: true
[2019-07-10 09:19:24] [config] bert-type-vocab-size: 2
[2019-07-10 09:19:24] [config] best-deep: false
[2019-07-10 09:19:24] [config] clip-gemm: 0
[2019-07-10 09:19:24] [config] clip-norm: 5
[2019-07-10 09:19:24] [config] cost-type: ce-mean-words
[2019-07-10 09:19:24] [config] cpu-threads: 0
[2019-07-10 09:19:24] [config] data-weighting: ""
[2019-07-10 09:19:24] [config] data-weighting-type: sentence
[2019-07-10 09:19:24] [config] dec-cell: gru
[2019-07-10 09:19:24] [config] dec-cell-base-depth: 2
[2019-07-10 09:19:24] [config] dec-cell-high-depth: 1
[2019-07-10 09:19:24] [config] dec-depth: 6
[2019-07-10 09:19:24] [config] devices:
[2019-07-10 09:19:24] [config]   - 5
[2019-07-10 09:19:24] [config]   - 7
[2019-07-10 09:19:24] [config] dim-emb: 512
[2019-07-10 09:19:24] [config] dim-rnn: 1024
[2019-07-10 09:19:24] [config] dim-vocabs:
[2019-07-10 09:19:24] [config]   - 36000
[2019-07-10 09:19:24] [config]   - 36000
[2019-07-10 09:19:24] [config] disp-first: 0
[2019-07-10 09:19:24] [config] disp-freq: 500
[2019-07-10 09:19:24] [config] disp-label-counts: false
[2019-07-10 09:19:24] [config] dropout-rnn: 0
[2019-07-10 09:19:24] [config] dropout-src: 0
[2019-07-10 09:19:24] [config] dropout-trg: 0
[2019-07-10 09:19:24] [config] dump-config: ""
[2019-07-10 09:19:24] [config] early-stopping: 5
[2019-07-10 09:19:24] [config] embedding-fix-src: false
[2019-07-10 09:19:24] [config] embedding-fix-trg: false
[2019-07-10 09:19:24] [config] embedding-normalization: false
[2019-07-10 09:19:24] [config] embedding-vectors:
[2019-07-10 09:19:24] [config]   []
[2019-07-10 09:19:24] [config] enc-cell: gru
[2019-07-10 09:19:24] [config] enc-cell-depth: 1
[2019-07-10 09:19:24] [config] enc-depth: 6
[2019-07-10 09:19:24] [config] enc-type: bidirectional
[2019-07-10 09:19:24] [config] exponential-smoothing: 0.0001
[2019-07-10 09:19:24] [config] grad-dropping-momentum: 0
[2019-07-10 09:19:24] [config] grad-dropping-rate: 0
[2019-07-10 09:19:24] [config] grad-dropping-warmup: 100
[2019-07-10 09:19:24] [config] guided-alignment: none
[2019-07-10 09:19:24] [config] guided-alignment-cost: mse
[2019-07-10 09:19:24] [config] guided-alignment-weight: 0.1
[2019-07-10 09:19:24] [config] ignore-model-config: false
[2019-07-10 09:19:24] [config] input-types:
[2019-07-10 09:19:24] [config]   []
[2019-07-10 09:19:24] [config] interpolate-env-vars: false
[2019-07-10 09:19:24] [config] keep-best: true
[2019-07-10 09:19:24] [config] label-smoothing: 0.1
[2019-07-10 09:19:24] [config] layer-normalization: false
[2019-07-10 09:19:24] [config] learn-rate: 0.0003
[2019-07-10 09:19:24] [config] log: models/wmt2017-transformer-de-en/model/model/ens2/train.log
[2019-07-10 09:19:24] [config] log-level: info
[2019-07-10 09:19:24] [config] log-time-zone: ""
[2019-07-10 09:19:24] [config] lr-decay: 0
[2019-07-10 09:19:24] [config] lr-decay-freq: 50000
[2019-07-10 09:19:24] [config] lr-decay-inv-sqrt:
[2019-07-10 09:19:24] [config]   - 16000
[2019-07-10 09:19:24] [config] lr-decay-repeat-warmup: false
[2019-07-10 09:19:24] [config] lr-decay-reset-optimizer: false
[2019-07-10 09:19:24] [config] lr-decay-start:
[2019-07-10 09:19:24] [config]   - 10
[2019-07-10 09:19:24] [config]   - 1
[2019-07-10 09:19:24] [config] lr-decay-strategy: epoch+stalled
[2019-07-10 09:19:24] [config] lr-report: true
[2019-07-10 09:19:24] [config] lr-warmup: 16000
[2019-07-10 09:19:24] [config] lr-warmup-at-reload: false
[2019-07-10 09:19:24] [config] lr-warmup-cycle: false
[2019-07-10 09:19:24] [config] lr-warmup-start-rate: 0
[2019-07-10 09:19:24] [config] max-length: 50
[2019-07-10 09:19:24] [config] max-length-crop: false
[2019-07-10 09:19:24] [config] max-length-factor: 3
[2019-07-10 09:19:24] [config] maxi-batch: 1000
[2019-07-10 09:19:24] [config] maxi-batch-sort: trg
[2019-07-10 09:19:24] [config] mini-batch: 1000
[2019-07-10 09:19:24] [config] mini-batch-fit: true
[2019-07-10 09:19:24] [config] mini-batch-fit-step: 10
[2019-07-10 09:19:24] [config] mini-batch-overstuff: 1
[2019-07-10 09:19:24] [config] mini-batch-track-lr: false
[2019-07-10 09:19:24] [config] mini-batch-understuff: 1
[2019-07-10 09:19:24] [config] mini-batch-warmup: 0
[2019-07-10 09:19:24] [config] mini-batch-words: 0
[2019-07-10 09:19:24] [config] mini-batch-words-ref: 0
[2019-07-10 09:19:24] [config] model: models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 09:19:24] [config] multi-loss-type: sum
[2019-07-10 09:19:24] [config] multi-node: false
[2019-07-10 09:19:24] [config] multi-node-overlap: true
[2019-07-10 09:19:24] [config] n-best: false
[2019-07-10 09:19:24] [config] no-nccl: false
[2019-07-10 09:19:24] [config] no-reload: false
[2019-07-10 09:19:24] [config] no-restore-corpus: false
[2019-07-10 09:19:24] [config] no-shuffle: false
[2019-07-10 09:19:24] [config] normalize: 1
[2019-07-10 09:19:24] [config] num-devices: 0
[2019-07-10 09:19:24] [config] optimizer: adam
[2019-07-10 09:19:24] [config] optimizer-delay: 1
[2019-07-10 09:19:24] [config] optimizer-params:
[2019-07-10 09:19:24] [config]   - 0.9
[2019-07-10 09:19:24] [config]   - 0.98
[2019-07-10 09:19:24] [config]   - 1e-09
[2019-07-10 09:19:24] [config] overwrite: true
[2019-07-10 09:19:24] [config] pretrained-model: ""
[2019-07-10 09:19:24] [config] quiet: false
[2019-07-10 09:19:24] [config] quiet-translation: true
[2019-07-10 09:19:24] [config] relative-paths: false
[2019-07-10 09:19:24] [config] right-left: false
[2019-07-10 09:19:24] [config] save-freq: 5000
[2019-07-10 09:19:24] [config] seed: 2222
[2019-07-10 09:19:24] [config] shuffle-in-ram: false
[2019-07-10 09:19:24] [config] skip: false
[2019-07-10 09:19:24] [config] sqlite: ""
[2019-07-10 09:19:24] [config] sqlite-drop: false
[2019-07-10 09:19:24] [config] sync-sgd: true
[2019-07-10 09:19:24] [config] tempdir: /tmp
[2019-07-10 09:19:24] [config] tied-embeddings: false
[2019-07-10 09:19:24] [config] tied-embeddings-all: true
[2019-07-10 09:19:24] [config] tied-embeddings-src: false
[2019-07-10 09:19:24] [config] train-sets:
[2019-07-10 09:19:24] [config]   - models/wmt2017-transformer-de-en/data/all.bpe.de
[2019-07-10 09:19:24] [config]   - models/wmt2017-transformer-de-en/data/all.bpe.en
[2019-07-10 09:19:24] [config] transformer-aan-activation: swish
[2019-07-10 09:19:24] [config] transformer-aan-depth: 2
[2019-07-10 09:19:24] [config] transformer-aan-nogate: false
[2019-07-10 09:19:24] [config] transformer-decoder-autoreg: self-attention
[2019-07-10 09:19:24] [config] transformer-dim-aan: 2048
[2019-07-10 09:19:24] [config] transformer-dim-ffn: 2048
[2019-07-10 09:19:24] [config] transformer-dropout: 0.1
[2019-07-10 09:19:24] [config] transformer-dropout-attention: 0
[2019-07-10 09:19:24] [config] transformer-dropout-ffn: 0
[2019-07-10 09:19:24] [config] transformer-ffn-activation: swish
[2019-07-10 09:19:24] [config] transformer-ffn-depth: 2
[2019-07-10 09:19:24] [config] transformer-guided-alignment-layer: last
[2019-07-10 09:19:24] [config] transformer-heads: 8
[2019-07-10 09:19:24] [config] transformer-no-projection: false
[2019-07-10 09:19:24] [config] transformer-postprocess: dan
[2019-07-10 09:19:24] [config] transformer-postprocess-emb: d
[2019-07-10 09:19:24] [config] transformer-preprocess: ""
[2019-07-10 09:19:24] [config] transformer-tied-layers:
[2019-07-10 09:19:24] [config]   []
[2019-07-10 09:19:24] [config] transformer-train-position-embeddings: false
[2019-07-10 09:19:24] [config] type: transformer
[2019-07-10 09:19:24] [config] ulr: false
[2019-07-10 09:19:24] [config] ulr-dim-emb: 0
[2019-07-10 09:19:24] [config] ulr-dropout: 0
[2019-07-10 09:19:24] [config] ulr-keys-vectors: ""
[2019-07-10 09:19:24] [config] ulr-query-vectors: ""
[2019-07-10 09:19:24] [config] ulr-softmax-temperature: 1
[2019-07-10 09:19:24] [config] ulr-trainable-transformation: false
[2019-07-10 09:19:24] [config] valid-freq: 5000
[2019-07-10 09:19:24] [config] valid-log: models/wmt2017-transformer-de-en/model/model/ens2/valid.log
[2019-07-10 09:19:24] [config] valid-max-length: 50
[2019-07-10 09:19:24] [config] valid-metrics:
[2019-07-10 09:19:24] [config]   - ce-mean-words
[2019-07-10 09:19:24] [config]   - perplexity
[2019-07-10 09:19:24] [config]   - translation
[2019-07-10 09:19:24] [config] valid-mini-batch: 64
[2019-07-10 09:19:24] [config] valid-script-path: bash ./models/wmt2017-transformer-de-en/validate.sh
[2019-07-10 09:19:24] [config] valid-sets:
[2019-07-10 09:19:24] [config]   - models/wmt2017-transformer-de-en/data/valid.bpe.de
[2019-07-10 09:19:24] [config]   - models/wmt2017-transformer-de-en/data/valid.bpe.en
[2019-07-10 09:19:24] [config] valid-translation-output: models/wmt2017-transformer-de-en/data/valid.bpe.de.output
[2019-07-10 09:19:24] [config] version: v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-10 09:19:24] [config] vocabs:
[2019-07-10 09:19:24] [config]   - models/wmt2017-transformer-de-en/model/vocab.ende.yml
[2019-07-10 09:19:24] [config]   - models/wmt2017-transformer-de-en/model/vocab.ende.yml
[2019-07-10 09:19:24] [config] word-penalty: 0
[2019-07-10 09:19:24] [config] workspace: 8000
[2019-07-10 09:19:24] [config] Loaded model has been created with Marian v1.7.8 ec2d66e 2019-05-27 14:52:11 +0100
[2019-07-10 09:19:24] Using synchronous training
[2019-07-10 09:19:24] [data] Loading vocabulary from JSON/Yaml file models/wmt2017-transformer-de-en/model/vocab.ende.yml
[2019-07-10 09:19:24] [data] Setting vocabulary size for input 0 to 36000
[2019-07-10 09:19:24] [data] Loading vocabulary from JSON/Yaml file models/wmt2017-transformer-de-en/model/vocab.ende.yml
[2019-07-10 09:19:25] [data] Setting vocabulary size for input 1 to 36000
[2019-07-10 09:19:25] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-07-10 09:19:25] [batching] Collecting statistics for batch fitting with step size 10
[2019-07-10 09:19:26] [memory] Extending reserved space to 8064 MB (device gpu5)
[2019-07-10 09:19:27] [memory] Extending reserved space to 8064 MB (device gpu7)
[2019-07-10 09:19:28] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-10 09:19:28] [comm] NCCLCommunicator constructed successfully.
[2019-07-10 09:19:28] [training] Using 2 GPUs
[2019-07-10 09:19:28] [memory] Reserving 238 MB, device gpu5
[2019-07-10 09:19:28] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-07-10 09:19:28] [memory] Reserving 238 MB, device gpu5
[2019-07-10 09:19:32] [batching] Done. Typical MB size is 11380 target words
[2019-07-10 09:19:32] [memory] Extending reserved space to 8064 MB (device gpu5)
[2019-07-10 09:19:33] [memory] Extending reserved space to 8064 MB (device gpu7)
[2019-07-10 09:19:33] [comm] Using NCCL 2.4.2 for GPU communication
[2019-07-10 09:19:33] [comm] NCCLCommunicator constructed successfully.
[2019-07-10 09:19:33] [training] Using 2 GPUs
[2019-07-10 09:19:33] Loading model from models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 09:19:37] Loading model from models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 09:19:38] Loading Adam parameters from models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 09:19:45] [memory] Reserving 238 MB, device gpu5
[2019-07-10 09:19:46] [memory] Reserving 238 MB, device gpu7
[2019-07-10 09:19:46] [training] Model reloaded from models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 09:19:46] [data] Restoring the corpus state to epoch 1, batch 5000
[2019-07-10 09:19:46] [data] Shuffling data
[2019-07-10 09:20:00] [data] Done reading 19122526 sentences
[2019-07-10 09:21:42] [data] Done shuffling 19122526 sentences to temp files
[2019-07-10 09:23:04] Training started
[2019-07-10 09:23:04] [training] Batches are processed as 1 process(es) x 2 devices/process
[2019-07-10 09:23:04] [memory] Reserving 238 MB, device gpu5
[2019-07-10 09:23:04] [memory] Reserving 238 MB, device gpu7
[2019-07-10 09:23:04] [memory] Reserving 238 MB, device gpu5
[2019-07-10 09:23:04] [memory] Reserving 238 MB, device gpu7
[2019-07-10 09:23:04] Loading model from models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 09:23:08] [memory] Reserving 238 MB, device cpu0
[2019-07-10 09:23:08] [memory] Reserving 119 MB, device gpu5
[2019-07-10 09:23:08] [memory] Reserving 119 MB, device gpu7
[2019-07-10 09:25:20] Ep. 1 : Up. 5500 : Sen. 1,255,928 : Cost 5.50159836 : Time 355.39s : 12425.43 words/s : L.r. 1.0313e-04
[2019-07-10 09:27:32] Ep. 1 : Up. 6000 : Sen. 1,433,946 : Cost 5.19353724 : Time 131.47s : 33411.36 words/s : L.r. 1.1250e-04
[2019-07-10 09:29:43] Ep. 1 : Up. 6500 : Sen. 1,613,507 : Cost 4.84656286 : Time 131.63s : 33315.45 words/s : L.r. 1.2188e-04
[2019-07-10 09:31:55] Ep. 1 : Up. 7000 : Sen. 1,789,404 : Cost 4.50953531 : Time 131.89s : 33430.21 words/s : L.r. 1.3125e-04
[2019-07-10 09:34:06] Ep. 1 : Up. 7500 : Sen. 1,965,908 : Cost 4.18767357 : Time 131.35s : 33339.68 words/s : L.r. 1.4063e-04
[2019-07-10 09:36:18] Ep. 1 : Up. 8000 : Sen. 2,146,736 : Cost 3.94880390 : Time 131.07s : 33621.26 words/s : L.r. 1.5000e-04
[2019-07-10 09:38:43] Ep. 1 : Up. 8500 : Sen. 2,324,881 : Cost 3.82037973 : Time 145.62s : 30179.28 words/s : L.r. 1.5938e-04
[2019-07-10 09:40:53] Ep. 1 : Up. 9000 : Sen. 2,498,559 : Cost 3.72910619 : Time 129.96s : 33887.75 words/s : L.r. 1.6875e-04
[2019-07-10 09:43:00] Ep. 1 : Up. 9500 : Sen. 2,681,619 : Cost 3.57154131 : Time 126.88s : 34472.25 words/s : L.r. 1.7813e-04
[2019-07-10 09:45:07] Ep. 1 : Up. 10000 : Sen. 2,865,154 : Cost 3.50086093 : Time 126.61s : 34412.51 words/s : L.r. 1.8750e-04
[2019-07-10 09:45:07] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 09:45:13] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 09:45:19] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 09:45:32] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 09:45:36] [valid] Ep. 1 : Up. 10000 : ce-mean-words : 2.4356 : new best
[2019-07-10 09:45:37] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 09:45:42] [valid] Ep. 1 : Up. 10000 : perplexity : 11.4226 : new best
[2019-07-10 09:46:20] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-translation.npz
[2019-07-10 09:46:24] [valid] Ep. 1 : Up. 10000 : translation : 27.23 : new best
[2019-07-10 09:48:34] Ep. 1 : Up. 10500 : Sen. 3,046,774 : Cost 3.41617775 : Time 206.90s : 21172.08 words/s : L.r. 1.9688e-04
[2019-07-10 09:50:41] Ep. 1 : Up. 11000 : Sen. 3,217,303 : Cost 3.39087367 : Time 127.63s : 34670.86 words/s : L.r. 2.0625e-04
[2019-07-10 09:52:49] Ep. 1 : Up. 11500 : Sen. 3,395,587 : Cost 3.32333207 : Time 127.30s : 34408.56 words/s : L.r. 2.1563e-04
[2019-07-10 09:54:55] Ep. 1 : Up. 12000 : Sen. 3,574,943 : Cost 3.30057025 : Time 126.81s : 34283.14 words/s : L.r. 2.2500e-04
[2019-07-10 09:57:02] Ep. 1 : Up. 12500 : Sen. 3,759,235 : Cost 3.22586370 : Time 126.77s : 34232.47 words/s : L.r. 2.3438e-04
[2019-07-10 09:59:10] Ep. 1 : Up. 13000 : Sen. 3,938,326 : Cost 3.23683810 : Time 127.90s : 34608.81 words/s : L.r. 2.4375e-04
[2019-07-10 10:01:17] Ep. 1 : Up. 13500 : Sen. 4,115,885 : Cost 3.20152569 : Time 127.32s : 34602.34 words/s : L.r. 2.5313e-04
[2019-07-10 10:03:25] Ep. 1 : Up. 14000 : Sen. 4,290,325 : Cost 3.13550162 : Time 127.90s : 34954.82 words/s : L.r. 2.6250e-04
[2019-07-10 10:05:32] Ep. 1 : Up. 14500 : Sen. 4,469,090 : Cost 3.11567426 : Time 127.19s : 34497.16 words/s : L.r. 2.7188e-04
[2019-07-10 10:07:40] Ep. 1 : Up. 15000 : Sen. 4,652,925 : Cost 3.12524414 : Time 127.26s : 34634.28 words/s : L.r. 2.8125e-04
[2019-07-10 10:07:40] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 10:07:46] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 10:07:52] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 10:08:05] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 10:08:10] [valid] Ep. 1 : Up. 15000 : ce-mean-words : 1.93418 : new best
[2019-07-10 10:08:11] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 10:08:15] [valid] Ep. 1 : Up. 15000 : perplexity : 6.91834 : new best
[2019-07-10 10:08:47] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-translation.npz
[2019-07-10 10:08:52] [valid] Ep. 1 : Up. 15000 : translation : 28.36 : new best
[2019-07-10 10:11:00] Ep. 1 : Up. 15500 : Sen. 4,827,492 : Cost 3.06984782 : Time 200.63s : 21879.02 words/s : L.r. 2.9063e-04
[2019-07-10 10:13:07] Ep. 1 : Up. 16000 : Sen. 5,010,666 : Cost 3.05806017 : Time 127.20s : 34370.34 words/s : L.r. 3.0000e-04
[2019-07-10 10:15:14] Ep. 1 : Up. 16500 : Sen. 5,187,385 : Cost 3.10882282 : Time 126.99s : 34643.39 words/s : L.r. 2.9542e-04
[2019-07-10 10:17:22] Ep. 1 : Up. 17000 : Sen. 5,364,416 : Cost 3.05819345 : Time 127.15s : 34546.78 words/s : L.r. 2.9104e-04
[2019-07-10 10:19:29] Ep. 1 : Up. 17500 : Sen. 5,546,208 : Cost 3.01499152 : Time 127.25s : 34321.56 words/s : L.r. 2.8685e-04
[2019-07-10 10:21:36] Ep. 1 : Up. 18000 : Sen. 5,720,886 : Cost 2.99156880 : Time 127.42s : 34452.74 words/s : L.r. 2.8284e-04
[2019-07-10 10:23:44] Ep. 1 : Up. 18500 : Sen. 5,900,833 : Cost 2.97135425 : Time 127.52s : 34294.33 words/s : L.r. 2.7899e-04
[2019-07-10 10:25:52] Ep. 1 : Up. 19000 : Sen. 6,082,657 : Cost 2.97424483 : Time 128.47s : 34321.74 words/s : L.r. 2.7530e-04
[2019-07-10 10:28:01] Ep. 1 : Up. 19500 : Sen. 6,258,597 : Cost 2.94841623 : Time 129.16s : 34352.60 words/s : L.r. 2.7175e-04
[2019-07-10 10:30:10] Ep. 1 : Up. 20000 : Sen. 6,440,317 : Cost 2.96817565 : Time 128.68s : 34407.21 words/s : L.r. 2.6833e-04
[2019-07-10 10:30:10] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 10:30:16] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 10:30:23] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 10:30:36] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 10:30:41] [valid] Ep. 1 : Up. 20000 : ce-mean-words : 1.72978 : new best
[2019-07-10 10:30:41] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 10:30:46] [valid] Ep. 1 : Up. 20000 : perplexity : 5.63942 : new best
[2019-07-10 10:31:20] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-translation.npz
[2019-07-10 10:31:25] [valid] Ep. 1 : Up. 20000 : translation : 34.32 : new best
[2019-07-10 10:33:35] Ep. 1 : Up. 20500 : Sen. 6,619,714 : Cost 2.89508295 : Time 204.47s : 21427.20 words/s : L.r. 2.6504e-04
[2019-07-10 10:35:44] Ep. 1 : Up. 21000 : Sen. 6,793,065 : Cost 2.91840601 : Time 128.87s : 34277.17 words/s : L.r. 2.6186e-04
[2019-07-10 10:37:51] Ep. 1 : Up. 21500 : Sen. 6,968,952 : Cost 2.89012146 : Time 127.98s : 34108.68 words/s : L.r. 2.5880e-04
[2019-07-10 10:40:00] Ep. 1 : Up. 22000 : Sen. 7,148,066 : Cost 2.89357567 : Time 128.30s : 33874.35 words/s : L.r. 2.5584e-04
[2019-07-10 10:42:09] Ep. 1 : Up. 22500 : Sen. 7,328,174 : Cost 2.91438198 : Time 129.47s : 34051.56 words/s : L.r. 2.5298e-04
[2019-07-10 10:44:18] Ep. 1 : Up. 23000 : Sen. 7,507,702 : Cost 2.86840177 : Time 128.82s : 33999.13 words/s : L.r. 2.5022e-04
[2019-07-10 10:46:28] Ep. 1 : Up. 23500 : Sen. 7,680,101 : Cost 2.85052013 : Time 130.11s : 33858.76 words/s : L.r. 2.4754e-04
[2019-07-10 10:48:57] Ep. 1 : Up. 24000 : Sen. 7,859,938 : Cost 2.83398676 : Time 148.75s : 29509.46 words/s : L.r. 2.4495e-04
[2019-07-10 10:51:24] Ep. 1 : Up. 24500 : Sen. 8,033,373 : Cost 2.85849404 : Time 147.52s : 29934.18 words/s : L.r. 2.4244e-04
[2019-07-10 10:53:33] Ep. 1 : Up. 25000 : Sen. 8,221,807 : Cost 2.85434151 : Time 128.28s : 34006.45 words/s : L.r. 2.4000e-04
[2019-07-10 10:53:33] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 10:53:39] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 10:53:46] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 10:53:59] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 10:54:03] [valid] Ep. 1 : Up. 25000 : ce-mean-words : 1.6181 : new best
[2019-07-10 10:54:04] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 10:54:09] [valid] Ep. 1 : Up. 25000 : perplexity : 5.04349 : new best
[2019-07-10 10:54:45] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-translation.npz
[2019-07-10 10:54:50] [valid] Ep. 1 : Up. 25000 : translation : 36.93 : new best
[2019-07-10 10:57:02] Ep. 1 : Up. 25500 : Sen. 8,397,636 : Cost 2.81861377 : Time 208.78s : 21170.71 words/s : L.r. 2.3764e-04
[2019-07-10 10:59:13] Ep. 1 : Up. 26000 : Sen. 8,582,111 : Cost 2.79856825 : Time 131.70s : 33505.95 words/s : L.r. 2.3534e-04
[2019-07-10 11:01:43] Ep. 1 : Up. 26500 : Sen. 8,762,200 : Cost 2.84400892 : Time 150.04s : 29374.60 words/s : L.r. 2.3311e-04
[2019-07-10 11:04:22] Ep. 1 : Up. 27000 : Sen. 8,942,009 : Cost 2.82111669 : Time 158.97s : 27335.68 words/s : L.r. 2.3094e-04
[2019-07-10 11:06:54] Ep. 1 : Up. 27500 : Sen. 9,116,136 : Cost 2.81901526 : Time 151.37s : 29001.46 words/s : L.r. 2.2883e-04
[2019-07-10 11:09:04] Ep. 1 : Up. 28000 : Sen. 9,291,891 : Cost 2.79508066 : Time 130.43s : 33810.06 words/s : L.r. 2.2678e-04
[2019-07-10 11:11:31] Ep. 1 : Up. 28500 : Sen. 9,475,210 : Cost 2.79542828 : Time 146.65s : 30237.58 words/s : L.r. 2.2478e-04
[2019-07-10 11:14:01] Ep. 1 : Up. 29000 : Sen. 9,650,590 : Cost 2.76343393 : Time 150.47s : 29289.39 words/s : L.r. 2.2283e-04
[2019-07-10 11:16:44] Ep. 1 : Up. 29500 : Sen. 9,832,428 : Cost 2.76020932 : Time 162.90s : 26982.14 words/s : L.r. 2.2094e-04
[2019-07-10 11:18:52] Ep. 1 : Up. 30000 : Sen. 10,009,223 : Cost 2.79418421 : Time 128.31s : 33905.56 words/s : L.r. 2.1909e-04
[2019-07-10 11:18:52] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 11:18:59] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 11:19:05] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 11:19:18] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 11:19:23] [valid] Ep. 1 : Up. 30000 : ce-mean-words : 1.55145 : new best
[2019-07-10 11:19:24] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 11:19:28] [valid] Ep. 1 : Up. 30000 : perplexity : 4.71832 : new best
[2019-07-10 11:20:06] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-translation.npz
[2019-07-10 11:20:11] [valid] Ep. 1 : Up. 30000 : translation : 36.98 : new best
[2019-07-10 11:22:21] Ep. 1 : Up. 30500 : Sen. 10,184,553 : Cost 2.78240013 : Time 209.01s : 21088.31 words/s : L.r. 2.1729e-04
[2019-07-10 11:24:30] Ep. 1 : Up. 31000 : Sen. 10,365,602 : Cost 2.78530669 : Time 128.48s : 33804.54 words/s : L.r. 2.1553e-04
[2019-07-10 11:26:39] Ep. 1 : Up. 31500 : Sen. 10,545,361 : Cost 2.81302428 : Time 129.57s : 33944.32 words/s : L.r. 2.1381e-04
[2019-07-10 11:28:48] Ep. 1 : Up. 32000 : Sen. 10,718,202 : Cost 2.75188684 : Time 128.47s : 33746.87 words/s : L.r. 2.1213e-04
[2019-07-10 11:30:57] Ep. 1 : Up. 32500 : Sen. 10,893,894 : Cost 2.79301977 : Time 128.62s : 33809.47 words/s : L.r. 2.1049e-04
[2019-07-10 11:33:06] Ep. 1 : Up. 33000 : Sen. 11,075,530 : Cost 2.72523832 : Time 129.70s : 34234.43 words/s : L.r. 2.0889e-04
[2019-07-10 11:35:16] Ep. 1 : Up. 33500 : Sen. 11,255,003 : Cost 2.72677183 : Time 129.89s : 34331.33 words/s : L.r. 2.0733e-04
[2019-07-10 11:37:26] Ep. 1 : Up. 34000 : Sen. 11,432,907 : Cost 2.75737000 : Time 129.72s : 33914.26 words/s : L.r. 2.0580e-04
[2019-07-10 11:39:35] Ep. 1 : Up. 34500 : Sen. 11,610,052 : Cost 2.75289631 : Time 128.69s : 34004.50 words/s : L.r. 2.0430e-04
[2019-07-10 11:41:44] Ep. 1 : Up. 35000 : Sen. 11,784,480 : Cost 2.70840001 : Time 129.04s : 33988.29 words/s : L.r. 2.0284e-04
[2019-07-10 11:41:44] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 11:41:50] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 11:41:56] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 11:42:09] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 11:42:14] [valid] Ep. 1 : Up. 35000 : ce-mean-words : 1.50486 : new best
[2019-07-10 11:42:15] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 11:42:19] [valid] Ep. 1 : Up. 35000 : perplexity : 4.50351 : new best
[2019-07-10 11:42:54] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-translation.npz
[2019-07-10 11:42:59] [valid] Ep. 1 : Up. 35000 : translation : 40.4 : new best
[2019-07-10 11:45:11] Ep. 1 : Up. 35500 : Sen. 11,965,369 : Cost 2.72758985 : Time 207.06s : 21568.31 words/s : L.r. 2.0140e-04
[2019-07-10 11:47:19] Ep. 1 : Up. 36000 : Sen. 12,145,540 : Cost 2.71766829 : Time 128.57s : 33737.93 words/s : L.r. 2.0000e-04
[2019-07-10 11:49:28] Ep. 1 : Up. 36500 : Sen. 12,326,255 : Cost 2.73912525 : Time 128.91s : 34010.87 words/s : L.r. 1.9863e-04
[2019-07-10 11:51:38] Ep. 1 : Up. 37000 : Sen. 12,506,156 : Cost 2.71570587 : Time 129.46s : 33760.98 words/s : L.r. 1.9728e-04
[2019-07-10 11:53:46] Ep. 1 : Up. 37500 : Sen. 12,681,701 : Cost 2.72988081 : Time 128.38s : 33750.53 words/s : L.r. 1.9596e-04
[2019-07-10 11:55:56] Ep. 1 : Up. 38000 : Sen. 12,857,601 : Cost 2.71410632 : Time 129.74s : 34163.08 words/s : L.r. 1.9467e-04
[2019-07-10 11:58:05] Ep. 1 : Up. 38500 : Sen. 13,035,499 : Cost 2.73305392 : Time 129.00s : 33818.72 words/s : L.r. 1.9340e-04
[2019-07-10 12:00:16] Ep. 1 : Up. 39000 : Sen. 13,218,364 : Cost 2.66655445 : Time 131.27s : 34133.82 words/s : L.r. 1.9215e-04
[2019-07-10 12:02:25] Ep. 1 : Up. 39500 : Sen. 13,396,084 : Cost 2.69560552 : Time 129.36s : 33996.61 words/s : L.r. 1.9093e-04
[2019-07-10 12:04:35] Ep. 1 : Up. 40000 : Sen. 13,576,319 : Cost 2.68978000 : Time 129.17s : 34070.45 words/s : L.r. 1.8974e-04
[2019-07-10 12:04:35] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 12:04:41] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 12:04:47] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 12:05:00] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 12:05:05] [valid] Ep. 1 : Up. 40000 : ce-mean-words : 1.47181 : new best
[2019-07-10 12:05:06] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 12:05:11] [valid] Ep. 1 : Up. 40000 : perplexity : 4.35713 : new best
[2019-07-10 12:05:49] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-translation.npz
[2019-07-10 12:05:53] [valid] Ep. 1 : Up. 40000 : translation : 40.42 : new best
[2019-07-10 12:08:04] Ep. 1 : Up. 40500 : Sen. 13,756,576 : Cost 2.69149733 : Time 209.76s : 20900.72 words/s : L.r. 1.8856e-04
[2019-07-10 12:10:13] Ep. 1 : Up. 41000 : Sen. 13,936,249 : Cost 2.70445585 : Time 129.02s : 33983.75 words/s : L.r. 1.8741e-04
[2019-07-10 12:12:22] Ep. 1 : Up. 41500 : Sen. 14,110,161 : Cost 2.75068951 : Time 128.53s : 34032.55 words/s : L.r. 1.8628e-04
[2019-07-10 12:14:31] Ep. 1 : Up. 42000 : Sen. 14,290,541 : Cost 2.70556760 : Time 129.42s : 33985.93 words/s : L.r. 1.8516e-04
[2019-07-10 12:16:40] Ep. 1 : Up. 42500 : Sen. 14,466,949 : Cost 2.68216228 : Time 128.78s : 34001.51 words/s : L.r. 1.8407e-04
[2019-07-10 12:18:50] Ep. 1 : Up. 43000 : Sen. 14,645,427 : Cost 2.70215511 : Time 130.05s : 34122.16 words/s : L.r. 1.8300e-04
[2019-07-10 12:20:59] Ep. 1 : Up. 43500 : Sen. 14,824,621 : Cost 2.69432211 : Time 129.22s : 33936.87 words/s : L.r. 1.8194e-04
[2019-07-10 12:23:09] Ep. 1 : Up. 44000 : Sen. 15,010,289 : Cost 2.68979049 : Time 129.55s : 33962.57 words/s : L.r. 1.8091e-04
[2019-07-10 12:25:17] Ep. 1 : Up. 44500 : Sen. 15,181,989 : Cost 2.68984079 : Time 128.63s : 33950.72 words/s : L.r. 1.7989e-04
[2019-07-10 12:27:26] Ep. 1 : Up. 45000 : Sen. 15,361,065 : Cost 2.64388061 : Time 128.75s : 33852.22 words/s : L.r. 1.7889e-04
[2019-07-10 12:27:26] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 12:27:33] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 12:27:39] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 12:27:53] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 12:27:57] [valid] Ep. 1 : Up. 45000 : ce-mean-words : 1.44469 : new best
[2019-07-10 12:27:58] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 12:28:03] [valid] Ep. 1 : Up. 45000 : perplexity : 4.24052 : new best
[2019-07-10 12:28:43] [valid] Ep. 1 : Up. 45000 : translation : 40.06 : stalled 1 times (last best: 40.42)
[2019-07-10 12:30:53] Ep. 1 : Up. 45500 : Sen. 15,539,164 : Cost 2.70854187 : Time 206.89s : 21042.29 words/s : L.r. 1.7790e-04
[2019-07-10 12:33:02] Ep. 1 : Up. 46000 : Sen. 15,715,004 : Cost 2.66255522 : Time 129.12s : 33841.64 words/s : L.r. 1.7693e-04
[2019-07-10 12:34:31] Seen 15838281 samples
[2019-07-10 12:34:31] Starting epoch 2
[2019-07-10 12:34:31] [data] Shuffling data
[2019-07-10 12:34:44] [data] Done reading 19122526 sentences
[2019-07-10 12:36:32] [data] Done shuffling 19122526 sentences to temp files
[2019-07-10 12:37:50] Ep. 2 : Up. 46500 : Sen. 54,800 : Cost 2.68016386 : Time 287.98s : 15192.25 words/s : L.r. 1.7598e-04
[2019-07-10 12:39:59] Ep. 2 : Up. 47000 : Sen. 230,777 : Cost 2.68126059 : Time 128.86s : 33862.38 words/s : L.r. 1.7504e-04
[2019-07-10 12:42:09] Ep. 2 : Up. 47500 : Sen. 408,649 : Cost 2.65431571 : Time 129.97s : 34116.19 words/s : L.r. 1.7411e-04
[2019-07-10 12:44:18] Ep. 2 : Up. 48000 : Sen. 581,338 : Cost 2.64100361 : Time 128.89s : 34012.83 words/s : L.r. 1.7321e-04
[2019-07-10 12:46:27] Ep. 2 : Up. 48500 : Sen. 767,240 : Cost 2.64125276 : Time 128.77s : 33658.62 words/s : L.r. 1.7231e-04
[2019-07-10 12:48:36] Ep. 2 : Up. 49000 : Sen. 943,814 : Cost 2.68381214 : Time 129.74s : 34262.47 words/s : L.r. 1.7143e-04
[2019-07-10 12:50:46] Ep. 2 : Up. 49500 : Sen. 1,124,683 : Cost 2.63681030 : Time 129.28s : 33876.51 words/s : L.r. 1.7056e-04
[2019-07-10 12:52:56] Ep. 2 : Up. 50000 : Sen. 1,301,656 : Cost 2.63731956 : Time 130.08s : 34088.79 words/s : L.r. 1.6971e-04
[2019-07-10 12:52:56] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 12:53:02] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 12:53:09] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 12:53:22] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 12:53:27] [valid] Ep. 2 : Up. 50000 : ce-mean-words : 1.42331 : new best
[2019-07-10 12:53:28] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 12:53:33] [valid] Ep. 2 : Up. 50000 : perplexity : 4.15085 : new best
[2019-07-10 12:54:11] [valid] Ep. 2 : Up. 50000 : translation : 36.55 : stalled 2 times (last best: 40.42)
[2019-07-10 12:56:22] Ep. 2 : Up. 50500 : Sen. 1,480,668 : Cost 2.64227653 : Time 206.06s : 21315.09 words/s : L.r. 1.6886e-04
[2019-07-10 12:58:31] Ep. 2 : Up. 51000 : Sen. 1,658,160 : Cost 2.63547015 : Time 129.16s : 33955.42 words/s : L.r. 1.6803e-04
[2019-07-10 13:00:41] Ep. 2 : Up. 51500 : Sen. 1,840,344 : Cost 2.66458535 : Time 130.22s : 34081.76 words/s : L.r. 1.6722e-04
[2019-07-10 13:02:50] Ep. 2 : Up. 52000 : Sen. 2,020,986 : Cost 2.65042210 : Time 128.40s : 33756.85 words/s : L.r. 1.6641e-04
[2019-07-10 13:04:58] Ep. 2 : Up. 52500 : Sen. 2,196,269 : Cost 2.69316936 : Time 128.74s : 34070.54 words/s : L.r. 1.6562e-04
[2019-07-10 13:07:09] Ep. 2 : Up. 53000 : Sen. 2,375,599 : Cost 2.58685517 : Time 130.37s : 33953.44 words/s : L.r. 1.6483e-04
[2019-07-10 13:09:19] Ep. 2 : Up. 53500 : Sen. 2,553,943 : Cost 2.62831736 : Time 130.45s : 34042.87 words/s : L.r. 1.6406e-04
[2019-07-10 13:11:28] Ep. 2 : Up. 54000 : Sen. 2,731,048 : Cost 2.64214396 : Time 128.86s : 34017.56 words/s : L.r. 1.6330e-04
[2019-07-10 13:13:37] Ep. 2 : Up. 54500 : Sen. 2,912,764 : Cost 2.62521815 : Time 128.65s : 33677.78 words/s : L.r. 1.6255e-04
[2019-07-10 13:15:47] Ep. 2 : Up. 55000 : Sen. 3,094,368 : Cost 2.66655111 : Time 130.02s : 33826.12 words/s : L.r. 1.6181e-04
[2019-07-10 13:15:47] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 13:15:53] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 13:16:00] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 13:16:12] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 13:16:17] [valid] Ep. 2 : Up. 55000 : ce-mean-words : 1.40576 : new best
[2019-07-10 13:16:18] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 13:16:23] [valid] Ep. 2 : Up. 55000 : perplexity : 4.07864 : new best
[2019-07-10 13:17:00] [valid] Ep. 2 : Up. 55000 : translation : 36.86 : stalled 3 times (last best: 40.42)
[2019-07-10 13:19:11] Ep. 2 : Up. 55500 : Sen. 3,274,012 : Cost 2.66194177 : Time 204.31s : 21567.44 words/s : L.r. 1.6108e-04
[2019-07-10 13:21:21] Ep. 2 : Up. 56000 : Sen. 3,452,023 : Cost 2.59674668 : Time 129.60s : 34121.69 words/s : L.r. 1.6036e-04
[2019-07-10 13:23:29] Ep. 2 : Up. 56500 : Sen. 3,632,189 : Cost 2.62163568 : Time 128.73s : 34071.94 words/s : L.r. 1.5965e-04
[2019-07-10 13:25:39] Ep. 2 : Up. 57000 : Sen. 3,806,711 : Cost 2.65563989 : Time 129.19s : 33855.36 words/s : L.r. 1.5894e-04
[2019-07-10 13:27:48] Ep. 2 : Up. 57500 : Sen. 3,983,870 : Cost 2.64194751 : Time 128.96s : 33880.34 words/s : L.r. 1.5825e-04
[2019-07-10 13:29:58] Ep. 2 : Up. 58000 : Sen. 4,159,118 : Cost 2.62324142 : Time 129.99s : 33967.99 words/s : L.r. 1.5757e-04
[2019-07-10 13:32:07] Ep. 2 : Up. 58500 : Sen. 4,335,267 : Cost 2.60961676 : Time 129.08s : 33879.84 words/s : L.r. 1.5689e-04
[2019-07-10 13:34:16] Ep. 2 : Up. 59000 : Sen. 4,519,570 : Cost 2.59610772 : Time 129.84s : 34011.36 words/s : L.r. 1.5623e-04
[2019-07-10 13:36:26] Ep. 2 : Up. 59500 : Sen. 4,698,832 : Cost 2.62726116 : Time 129.41s : 33903.02 words/s : L.r. 1.5557e-04
[2019-07-10 13:38:35] Ep. 2 : Up. 60000 : Sen. 4,876,436 : Cost 2.68184257 : Time 128.93s : 33825.38 words/s : L.r. 1.5492e-04
[2019-07-10 13:38:35] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 13:38:44] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 13:38:51] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 13:39:11] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 13:39:16] [valid] Ep. 2 : Up. 60000 : ce-mean-words : 1.38999 : new best
[2019-07-10 13:39:17] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 13:39:22] [valid] Ep. 2 : Up. 60000 : perplexity : 4.01483 : new best
[2019-07-10 13:40:05] [valid] Ep. 2 : Up. 60000 : translation : 36.8 : stalled 4 times (last best: 40.42)
[2019-07-10 13:42:15] Ep. 2 : Up. 60500 : Sen. 5,056,978 : Cost 2.65461373 : Time 220.61s : 19969.18 words/s : L.r. 1.5428e-04
[2019-07-10 13:44:25] Ep. 2 : Up. 61000 : Sen. 5,231,363 : Cost 2.60903668 : Time 129.65s : 34073.93 words/s : L.r. 1.5364e-04
[2019-07-10 13:46:34] Ep. 2 : Up. 61500 : Sen. 5,408,817 : Cost 2.61972284 : Time 128.80s : 34108.28 words/s : L.r. 1.5302e-04
[2019-07-10 13:48:43] Ep. 2 : Up. 62000 : Sen. 5,592,742 : Cost 2.58560514 : Time 129.05s : 33866.27 words/s : L.r. 1.5240e-04
[2019-07-10 13:50:52] Ep. 2 : Up. 62500 : Sen. 5,769,904 : Cost 2.64671445 : Time 129.46s : 33921.40 words/s : L.r. 1.5179e-04
[2019-07-10 13:53:02] Ep. 2 : Up. 63000 : Sen. 5,950,352 : Cost 2.61209202 : Time 129.47s : 33982.85 words/s : L.r. 1.5119e-04
[2019-07-10 13:55:10] Ep. 2 : Up. 63500 : Sen. 6,123,164 : Cost 2.64129114 : Time 127.93s : 33801.47 words/s : L.r. 1.5059e-04
[2019-07-10 13:57:19] Ep. 2 : Up. 64000 : Sen. 6,306,579 : Cost 2.61742425 : Time 128.86s : 33904.39 words/s : L.r. 1.5000e-04
[2019-07-10 13:59:28] Ep. 2 : Up. 64500 : Sen. 6,489,338 : Cost 2.59256959 : Time 129.50s : 33816.94 words/s : L.r. 1.4942e-04
[2019-07-10 14:01:39] Ep. 2 : Up. 65000 : Sen. 6,660,980 : Cost 2.61634922 : Time 130.45s : 34195.04 words/s : L.r. 1.4884e-04
[2019-07-10 14:01:39] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 14:01:45] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 14:01:51] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 14:02:04] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 14:02:09] [valid] Ep. 2 : Up. 65000 : ce-mean-words : 1.3761 : new best
[2019-07-10 14:02:10] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 14:02:16] [valid] Ep. 2 : Up. 65000 : perplexity : 3.95945 : new best
[2019-07-10 14:02:54] [valid] Ep. 2 : Up. 65000 : translation : 36.93 : stalled 5 times (last best: 40.42)
[2019-07-10 14:05:05] Ep. 2 : Up. 65500 : Sen. 6,840,330 : Cost 2.61852169 : Time 206.85s : 21379.93 words/s : L.r. 1.4827e-04
[2019-07-10 14:07:15] Ep. 2 : Up. 66000 : Sen. 7,022,618 : Cost 2.60005283 : Time 129.88s : 34113.38 words/s : L.r. 1.4771e-04
[2019-07-10 14:09:25] Ep. 2 : Up. 66500 : Sen. 7,198,745 : Cost 2.64736557 : Time 129.71s : 34110.74 words/s : L.r. 1.4715e-04
[2019-07-10 14:11:33] Ep. 2 : Up. 67000 : Sen. 7,380,568 : Cost 2.62011790 : Time 128.27s : 33784.31 words/s : L.r. 1.4660e-04
[2019-07-10 14:13:42] Ep. 2 : Up. 67500 : Sen. 7,554,056 : Cost 2.60732102 : Time 129.16s : 34073.81 words/s : L.r. 1.4606e-04
[2019-07-10 14:15:52] Ep. 2 : Up. 68000 : Sen. 7,738,667 : Cost 2.58215690 : Time 129.70s : 34053.18 words/s : L.r. 1.4552e-04
[2019-07-10 14:18:01] Ep. 2 : Up. 68500 : Sen. 7,912,102 : Cost 2.60310936 : Time 128.57s : 33812.36 words/s : L.r. 1.4499e-04
[2019-07-10 14:20:11] Ep. 2 : Up. 69000 : Sen. 8,093,219 : Cost 2.62598205 : Time 130.20s : 34187.20 words/s : L.r. 1.4446e-04
[2019-07-10 14:22:20] Ep. 2 : Up. 69500 : Sen. 8,277,219 : Cost 2.59308839 : Time 129.53s : 33846.46 words/s : L.r. 1.4394e-04
[2019-07-10 14:24:30] Ep. 2 : Up. 70000 : Sen. 8,454,382 : Cost 2.59602284 : Time 129.19s : 33726.61 words/s : L.r. 1.4343e-04
[2019-07-10 14:24:30] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 14:24:36] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 14:24:43] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 14:24:55] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 14:25:00] [valid] Ep. 2 : Up. 70000 : ce-mean-words : 1.36544 : new best
[2019-07-10 14:25:01] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 14:25:06] [valid] Ep. 2 : Up. 70000 : perplexity : 3.91743 : new best
[2019-07-10 14:25:43] [valid] Ep. 2 : Up. 70000 : translation : 37.56 : stalled 6 times (last best: 40.42)
[2019-07-10 14:27:55] Ep. 2 : Up. 70500 : Sen. 8,635,819 : Cost 2.60629654 : Time 205.56s : 21697.73 words/s : L.r. 1.4292e-04
[2019-07-10 14:30:03] Ep. 2 : Up. 71000 : Sen. 8,813,524 : Cost 2.59497499 : Time 128.16s : 33677.33 words/s : L.r. 1.4241e-04
[2019-07-10 14:32:12] Ep. 2 : Up. 71500 : Sen. 8,984,970 : Cost 2.61134076 : Time 129.00s : 34213.37 words/s : L.r. 1.4191e-04
[2019-07-10 14:34:22] Ep. 2 : Up. 72000 : Sen. 9,161,096 : Cost 2.63665581 : Time 130.12s : 34273.67 words/s : L.r. 1.4142e-04
[2019-07-10 14:36:32] Ep. 2 : Up. 72500 : Sen. 9,341,661 : Cost 2.55357456 : Time 129.85s : 33781.88 words/s : L.r. 1.4093e-04
[2019-07-10 14:38:42] Ep. 2 : Up. 73000 : Sen. 9,523,956 : Cost 2.57979703 : Time 129.57s : 33949.03 words/s : L.r. 1.4045e-04
[2019-07-10 14:40:51] Ep. 2 : Up. 73500 : Sen. 9,694,614 : Cost 2.61497784 : Time 128.89s : 34034.10 words/s : L.r. 1.3997e-04
[2019-07-10 14:43:00] Ep. 2 : Up. 74000 : Sen. 9,875,236 : Cost 2.59081459 : Time 128.74s : 33975.50 words/s : L.r. 1.3950e-04
[2019-07-10 14:45:09] Ep. 2 : Up. 74500 : Sen. 10,052,576 : Cost 2.58061838 : Time 129.69s : 33826.71 words/s : L.r. 1.3903e-04
[2019-07-10 14:47:18] Ep. 2 : Up. 75000 : Sen. 10,229,635 : Cost 2.58250952 : Time 129.10s : 33711.08 words/s : L.r. 1.3856e-04
[2019-07-10 14:47:18] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 14:47:25] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 14:47:31] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 14:47:45] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 14:47:50] [valid] Ep. 2 : Up. 75000 : ce-mean-words : 1.35402 : new best
[2019-07-10 14:47:50] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 14:47:55] [valid] Ep. 2 : Up. 75000 : perplexity : 3.87298 : new best
[2019-07-10 14:48:32] [valid] Ep. 2 : Up. 75000 : translation : 38.13 : stalled 7 times (last best: 40.42)
[2019-07-10 14:50:43] Ep. 2 : Up. 75500 : Sen. 10,407,046 : Cost 2.59779763 : Time 204.30s : 21557.75 words/s : L.r. 1.3810e-04
[2019-07-10 14:52:52] Ep. 2 : Up. 76000 : Sen. 10,586,051 : Cost 2.58347249 : Time 129.28s : 34007.85 words/s : L.r. 1.3765e-04
[2019-07-10 14:55:01] Ep. 2 : Up. 76500 : Sen. 10,766,314 : Cost 2.60474491 : Time 129.10s : 33928.39 words/s : L.r. 1.3720e-04
[2019-07-10 14:57:11] Ep. 2 : Up. 77000 : Sen. 10,947,218 : Cost 2.58820653 : Time 129.80s : 34081.29 words/s : L.r. 1.3675e-04
[2019-07-10 14:59:21] Ep. 2 : Up. 77500 : Sen. 11,125,365 : Cost 2.62301755 : Time 130.25s : 34101.26 words/s : L.r. 1.3631e-04
[2019-07-10 15:01:31] Ep. 2 : Up. 78000 : Sen. 11,304,035 : Cost 2.57841182 : Time 129.52s : 34112.22 words/s : L.r. 1.3587e-04
[2019-07-10 15:03:40] Ep. 2 : Up. 78500 : Sen. 11,482,703 : Cost 2.57332563 : Time 129.08s : 33946.05 words/s : L.r. 1.3544e-04
[2019-07-10 15:05:48] Ep. 2 : Up. 79000 : Sen. 11,664,595 : Cost 2.58686590 : Time 128.50s : 34006.40 words/s : L.r. 1.3501e-04
[2019-07-10 15:07:56] Ep. 2 : Up. 79500 : Sen. 11,840,369 : Cost 2.59822416 : Time 128.14s : 33766.15 words/s : L.r. 1.3459e-04
[2019-07-10 15:10:06] Ep. 2 : Up. 80000 : Sen. 12,019,298 : Cost 2.56813216 : Time 129.31s : 34014.96 words/s : L.r. 1.3416e-04
[2019-07-10 15:10:06] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 15:10:12] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 15:10:19] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 15:10:31] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 15:10:36] [valid] Ep. 2 : Up. 80000 : ce-mean-words : 1.34456 : new best
[2019-07-10 15:10:37] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 15:10:42] [valid] Ep. 2 : Up. 80000 : perplexity : 3.83648 : new best
[2019-07-10 15:11:18] [valid] Ep. 2 : Up. 80000 : translation : 39.31 : stalled 8 times (last best: 40.42)
[2019-07-10 15:13:30] Ep. 2 : Up. 80500 : Sen. 12,198,774 : Cost 2.56615782 : Time 204.33s : 21739.19 words/s : L.r. 1.3375e-04
[2019-07-10 15:15:39] Ep. 2 : Up. 81000 : Sen. 12,379,328 : Cost 2.60704899 : Time 129.42s : 33994.43 words/s : L.r. 1.3333e-04
[2019-07-10 15:17:49] Ep. 2 : Up. 81500 : Sen. 12,555,939 : Cost 2.59767365 : Time 129.52s : 34044.60 words/s : L.r. 1.3292e-04
[2019-07-10 15:19:58] Ep. 2 : Up. 82000 : Sen. 12,730,508 : Cost 2.58923411 : Time 129.04s : 33941.01 words/s : L.r. 1.3252e-04
[2019-07-10 15:22:07] Ep. 2 : Up. 82500 : Sen. 12,912,229 : Cost 2.54195595 : Time 129.35s : 33736.83 words/s : L.r. 1.3212e-04
[2019-07-10 15:24:16] Ep. 2 : Up. 83000 : Sen. 13,097,954 : Cost 2.60792756 : Time 128.65s : 34023.68 words/s : L.r. 1.3172e-04
[2019-07-10 15:26:26] Ep. 2 : Up. 83500 : Sen. 13,272,402 : Cost 2.59032631 : Time 129.68s : 33796.04 words/s : L.r. 1.3132e-04
[2019-07-10 15:28:35] Ep. 2 : Up. 84000 : Sen. 13,451,301 : Cost 2.58499479 : Time 129.72s : 33904.12 words/s : L.r. 1.3093e-04
[2019-07-10 15:30:45] Ep. 2 : Up. 84500 : Sen. 13,629,853 : Cost 2.54064226 : Time 129.48s : 33952.81 words/s : L.r. 1.3054e-04
[2019-07-10 15:32:54] Ep. 2 : Up. 85000 : Sen. 13,809,902 : Cost 2.60093594 : Time 129.46s : 34226.65 words/s : L.r. 1.3016e-04
[2019-07-10 15:32:54] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 15:33:01] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 15:33:07] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 15:33:20] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 15:33:25] [valid] Ep. 2 : Up. 85000 : ce-mean-words : 1.33652 : new best
[2019-07-10 15:33:26] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 15:33:30] [valid] Ep. 2 : Up. 85000 : perplexity : 3.80579 : new best
[2019-07-10 15:34:08] [valid] Ep. 2 : Up. 85000 : translation : 39.86 : stalled 9 times (last best: 40.42)
[2019-07-10 15:36:19] Ep. 2 : Up. 85500 : Sen. 13,985,182 : Cost 2.57238221 : Time 204.65s : 21443.60 words/s : L.r. 1.2978e-04
[2019-07-10 15:38:28] Ep. 2 : Up. 86000 : Sen. 14,166,881 : Cost 2.53912187 : Time 129.37s : 33829.17 words/s : L.r. 1.2940e-04
[2019-07-10 15:40:38] Ep. 2 : Up. 86500 : Sen. 14,342,714 : Cost 2.56531048 : Time 129.44s : 33775.93 words/s : L.r. 1.2902e-04
[2019-07-10 15:42:47] Ep. 2 : Up. 87000 : Sen. 14,524,066 : Cost 2.58595276 : Time 129.57s : 33972.46 words/s : L.r. 1.2865e-04
[2019-07-10 15:44:57] Ep. 2 : Up. 87500 : Sen. 14,701,894 : Cost 2.58944273 : Time 129.25s : 33885.66 words/s : L.r. 1.2829e-04
[2019-07-10 15:47:06] Ep. 2 : Up. 88000 : Sen. 14,879,496 : Cost 2.59671116 : Time 129.07s : 34058.23 words/s : L.r. 1.2792e-04
[2019-07-10 15:49:16] Ep. 2 : Up. 88500 : Sen. 15,060,651 : Cost 2.56203365 : Time 130.72s : 33767.35 words/s : L.r. 1.2756e-04
[2019-07-10 15:51:28] Ep. 2 : Up. 89000 : Sen. 15,239,128 : Cost 2.55649924 : Time 131.25s : 33462.57 words/s : L.r. 1.2720e-04
[2019-07-10 15:53:39] Ep. 2 : Up. 89500 : Sen. 15,422,462 : Cost 2.55480337 : Time 131.25s : 33392.88 words/s : L.r. 1.2684e-04
[2019-07-10 15:55:50] Ep. 2 : Up. 90000 : Sen. 15,598,842 : Cost 2.58251476 : Time 131.38s : 33406.60 words/s : L.r. 1.2649e-04
[2019-07-10 15:55:50] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 15:55:57] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 15:56:05] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 15:56:19] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 15:56:23] [valid] Ep. 2 : Up. 90000 : ce-mean-words : 1.32901 : new best
[2019-07-10 15:56:24] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 15:56:29] [valid] Ep. 2 : Up. 90000 : perplexity : 3.77732 : new best
[2019-07-10 15:57:08] [valid] Ep. 2 : Up. 90000 : translation : 38.52 : stalled 10 times (last best: 40.42)
[2019-07-10 15:59:20] Ep. 2 : Up. 90500 : Sen. 15,779,339 : Cost 2.59822488 : Time 209.73s : 20749.24 words/s : L.r. 1.2614e-04
[2019-07-10 16:01:31] Ep. 2 : Up. 91000 : Sen. 15,953,817 : Cost 2.57824469 : Time 130.60s : 33882.96 words/s : L.r. 1.2579e-04
[2019-07-10 16:03:42] Ep. 2 : Up. 91500 : Sen. 16,129,022 : Cost 2.54451966 : Time 131.42s : 33922.26 words/s : L.r. 1.2545e-04
[2019-07-10 16:05:52] Ep. 2 : Up. 92000 : Sen. 16,302,941 : Cost 2.59287238 : Time 130.02s : 33410.57 words/s : L.r. 1.2511e-04
[2019-07-10 16:08:03] Ep. 2 : Up. 92500 : Sen. 16,483,494 : Cost 2.57412887 : Time 130.69s : 33592.79 words/s : L.r. 1.2477e-04
[2019-07-10 16:08:50] Seen 16548172 samples
[2019-07-10 16:08:50] Starting epoch 3
[2019-07-10 16:08:50] [data] Shuffling data
[2019-07-10 16:09:05] [data] Done reading 19122526 sentences
[2019-07-10 16:11:19] [data] Done shuffling 19122526 sentences to temp files
[2019-07-10 16:13:35] Ep. 3 : Up. 93000 : Sen. 115,175 : Cost 2.52509141 : Time 332.08s : 13199.74 words/s : L.r. 1.2443e-04
[2019-07-10 16:15:43] Ep. 3 : Up. 93500 : Sen. 284,867 : Cost 2.56462979 : Time 128.44s : 33683.56 words/s : L.r. 1.2410e-04
[2019-07-10 16:17:53] Ep. 3 : Up. 94000 : Sen. 463,001 : Cost 2.56890941 : Time 130.15s : 33967.11 words/s : L.r. 1.2377e-04
[2019-07-10 16:20:04] Ep. 3 : Up. 94500 : Sen. 658,512 : Cost 2.53140974 : Time 130.09s : 34022.49 words/s : L.r. 1.2344e-04
[2019-07-10 16:22:13] Ep. 3 : Up. 95000 : Sen. 830,845 : Cost 2.57470512 : Time 129.57s : 33971.91 words/s : L.r. 1.2312e-04
[2019-07-10 16:22:13] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 16:22:20] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 16:22:26] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 16:22:40] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 16:22:45] [valid] Ep. 3 : Up. 95000 : ce-mean-words : 1.32211 : new best
[2019-07-10 16:22:46] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 16:22:51] [valid] Ep. 3 : Up. 95000 : perplexity : 3.75132 : new best
[2019-07-10 16:23:29] [valid] Ep. 3 : Up. 95000 : translation : 38.58 : stalled 11 times (last best: 40.42)
[2019-07-10 16:25:40] Ep. 3 : Up. 95500 : Sen. 1,005,352 : Cost 2.56426024 : Time 206.64s : 21129.29 words/s : L.r. 1.2279e-04
[2019-07-10 16:27:49] Ep. 3 : Up. 96000 : Sen. 1,180,124 : Cost 2.55788708 : Time 129.24s : 33851.20 words/s : L.r. 1.2247e-04
[2019-07-10 16:29:59] Ep. 3 : Up. 96500 : Sen. 1,357,540 : Cost 2.54652309 : Time 129.88s : 33959.95 words/s : L.r. 1.2216e-04
[2019-07-10 16:32:08] Ep. 3 : Up. 97000 : Sen. 1,532,421 : Cost 2.55091023 : Time 129.54s : 33892.96 words/s : L.r. 1.2184e-04
[2019-07-10 16:34:18] Ep. 3 : Up. 97500 : Sen. 1,712,753 : Cost 2.53960109 : Time 129.40s : 33849.80 words/s : L.r. 1.2153e-04
[2019-07-10 16:36:27] Ep. 3 : Up. 98000 : Sen. 1,897,059 : Cost 2.57056808 : Time 129.60s : 33805.21 words/s : L.r. 1.2122e-04
[2019-07-10 16:38:37] Ep. 3 : Up. 98500 : Sen. 2,077,271 : Cost 2.54745126 : Time 130.04s : 33817.44 words/s : L.r. 1.2091e-04
[2019-07-10 16:40:47] Ep. 3 : Up. 99000 : Sen. 2,257,684 : Cost 2.54564786 : Time 130.02s : 33871.67 words/s : L.r. 1.2060e-04
[2019-07-10 16:42:58] Ep. 3 : Up. 99500 : Sen. 2,434,880 : Cost 2.57109118 : Time 130.18s : 33862.55 words/s : L.r. 1.2030e-04
[2019-07-10 16:45:07] Ep. 3 : Up. 100000 : Sen. 2,618,786 : Cost 2.52031922 : Time 129.25s : 33825.43 words/s : L.r. 1.2000e-04
[2019-07-10 16:45:07] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 16:45:13] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 16:45:21] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 16:45:36] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 16:45:45] [valid] Ep. 3 : Up. 100000 : ce-mean-words : 1.31611 : new best
[2019-07-10 16:45:45] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 16:45:50] [valid] Ep. 3 : Up. 100000 : perplexity : 3.72888 : new best
[2019-07-10 16:46:30] [valid] Ep. 3 : Up. 100000 : translation : 40.1 : stalled 12 times (last best: 40.42)
[2019-07-10 16:48:41] Ep. 3 : Up. 100500 : Sen. 2,798,972 : Cost 2.56697345 : Time 214.05s : 20638.00 words/s : L.r. 1.1970e-04
[2019-07-10 16:50:50] Ep. 3 : Up. 101000 : Sen. 2,970,508 : Cost 2.54552627 : Time 129.46s : 33856.91 words/s : L.r. 1.1940e-04
[2019-07-10 16:53:00] Ep. 3 : Up. 101500 : Sen. 3,144,727 : Cost 2.54073930 : Time 129.57s : 33851.23 words/s : L.r. 1.1911e-04
[2019-07-10 16:55:09] Ep. 3 : Up. 102000 : Sen. 3,323,370 : Cost 2.57916856 : Time 129.28s : 33681.36 words/s : L.r. 1.1882e-04
[2019-07-10 16:57:20] Ep. 3 : Up. 102500 : Sen. 3,508,309 : Cost 2.55214953 : Time 130.45s : 33997.59 words/s : L.r. 1.1853e-04
[2019-07-10 16:59:30] Ep. 3 : Up. 103000 : Sen. 3,685,443 : Cost 2.52212906 : Time 130.61s : 33897.71 words/s : L.r. 1.1824e-04
[2019-07-10 17:01:40] Ep. 3 : Up. 103500 : Sen. 3,865,754 : Cost 2.53774071 : Time 129.81s : 33799.39 words/s : L.r. 1.1795e-04
[2019-07-10 17:03:50] Ep. 3 : Up. 104000 : Sen. 4,044,252 : Cost 2.54970837 : Time 129.43s : 33900.82 words/s : L.r. 1.1767e-04
[2019-07-10 17:05:59] Ep. 3 : Up. 104500 : Sen. 4,220,934 : Cost 2.55426383 : Time 129.83s : 33865.62 words/s : L.r. 1.1739e-04
[2019-07-10 17:08:09] Ep. 3 : Up. 105000 : Sen. 4,405,021 : Cost 2.53488708 : Time 129.40s : 33883.59 words/s : L.r. 1.1711e-04
[2019-07-10 17:08:09] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 17:08:16] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 17:08:22] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 17:08:36] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 17:08:41] [valid] Ep. 3 : Up. 105000 : ce-mean-words : 1.3107 : new best
[2019-07-10 17:08:42] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 17:08:47] [valid] Ep. 3 : Up. 105000 : perplexity : 3.70875 : new best
[2019-07-10 17:09:24] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-translation.npz
[2019-07-10 17:09:30] [valid] Ep. 3 : Up. 105000 : translation : 40.98 : new best
[2019-07-10 17:11:41] Ep. 3 : Up. 105500 : Sen. 4,580,191 : Cost 2.52017379 : Time 212.27s : 20658.61 words/s : L.r. 1.1683e-04
[2019-07-10 17:13:50] Ep. 3 : Up. 106000 : Sen. 4,757,420 : Cost 2.57779169 : Time 129.26s : 33917.16 words/s : L.r. 1.1655e-04
[2019-07-10 17:16:01] Ep. 3 : Up. 106500 : Sen. 4,931,850 : Cost 2.54971385 : Time 130.60s : 33972.08 words/s : L.r. 1.1628e-04
[2019-07-10 17:18:11] Ep. 3 : Up. 107000 : Sen. 5,116,798 : Cost 2.52843761 : Time 130.34s : 33978.67 words/s : L.r. 1.1601e-04
[2019-07-10 17:20:21] Ep. 3 : Up. 107500 : Sen. 5,294,604 : Cost 2.53996110 : Time 129.28s : 33756.99 words/s : L.r. 1.1574e-04
[2019-07-10 17:22:30] Ep. 3 : Up. 108000 : Sen. 5,474,967 : Cost 2.54389381 : Time 129.05s : 33984.94 words/s : L.r. 1.1547e-04
[2019-07-10 17:24:39] Ep. 3 : Up. 108500 : Sen. 5,643,012 : Cost 2.56787300 : Time 129.63s : 34047.29 words/s : L.r. 1.1520e-04
[2019-07-10 17:26:49] Ep. 3 : Up. 109000 : Sen. 5,826,530 : Cost 2.56176901 : Time 129.63s : 33770.45 words/s : L.r. 1.1494e-04
[2019-07-10 17:28:59] Ep. 3 : Up. 109500 : Sen. 6,006,660 : Cost 2.50971794 : Time 130.01s : 33804.24 words/s : L.r. 1.1468e-04
[2019-07-10 17:31:09] Ep. 3 : Up. 110000 : Sen. 6,182,154 : Cost 2.55208111 : Time 130.19s : 34068.65 words/s : L.r. 1.1442e-04
[2019-07-10 17:31:09] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 17:31:16] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 17:31:23] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 17:31:36] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 17:31:41] [valid] Ep. 3 : Up. 110000 : ce-mean-words : 1.30605 : new best
[2019-07-10 17:31:42] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 17:31:47] [valid] Ep. 3 : Up. 110000 : perplexity : 3.69156 : new best
[2019-07-10 17:32:25] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-translation.npz
[2019-07-10 17:32:30] [valid] Ep. 3 : Up. 110000 : translation : 43.32 : new best
[2019-07-10 17:34:41] Ep. 3 : Up. 110500 : Sen. 6,358,894 : Cost 2.51598120 : Time 211.66s : 20721.02 words/s : L.r. 1.1416e-04
[2019-07-10 17:36:50] Ep. 3 : Up. 111000 : Sen. 6,534,750 : Cost 2.58066678 : Time 129.67s : 34092.80 words/s : L.r. 1.1390e-04
[2019-07-10 17:38:59] Ep. 3 : Up. 111500 : Sen. 6,713,405 : Cost 2.52918530 : Time 128.73s : 33860.41 words/s : L.r. 1.1364e-04
[2019-07-10 17:41:09] Ep. 3 : Up. 112000 : Sen. 6,902,435 : Cost 2.52920771 : Time 129.84s : 33910.09 words/s : L.r. 1.1339e-04
[2019-07-10 17:43:18] Ep. 3 : Up. 112500 : Sen. 7,077,972 : Cost 2.57216740 : Time 129.09s : 33796.40 words/s : L.r. 1.1314e-04
[2019-07-10 17:45:28] Ep. 3 : Up. 113000 : Sen. 7,255,532 : Cost 2.56782269 : Time 129.94s : 33955.71 words/s : L.r. 1.1289e-04
[2019-07-10 17:47:37] Ep. 3 : Up. 113500 : Sen. 7,426,240 : Cost 2.56288433 : Time 129.20s : 34037.14 words/s : L.r. 1.1264e-04
[2019-07-10 17:49:47] Ep. 3 : Up. 114000 : Sen. 7,606,889 : Cost 2.52659059 : Time 129.35s : 33766.79 words/s : L.r. 1.1239e-04
[2019-07-10 17:51:56] Ep. 3 : Up. 114500 : Sen. 7,790,609 : Cost 2.50267673 : Time 129.66s : 34007.38 words/s : L.r. 1.1214e-04
[2019-07-10 17:54:06] Ep. 3 : Up. 115000 : Sen. 7,972,798 : Cost 2.52672362 : Time 129.36s : 33786.06 words/s : L.r. 1.1190e-04
[2019-07-10 17:54:06] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 17:54:12] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 17:54:19] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 17:54:32] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 17:54:37] [valid] Ep. 3 : Up. 115000 : ce-mean-words : 1.30114 : new best
[2019-07-10 17:54:38] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 17:54:43] [valid] Ep. 3 : Up. 115000 : perplexity : 3.67349 : new best
[2019-07-10 17:55:23] [valid] Ep. 3 : Up. 115000 : translation : 43.2 : stalled 1 times (last best: 43.32)
[2019-07-10 17:57:33] Ep. 3 : Up. 115500 : Sen. 8,152,577 : Cost 2.55578136 : Time 207.44s : 21001.45 words/s : L.r. 1.1166e-04
[2019-07-10 17:59:43] Ep. 3 : Up. 116000 : Sen. 8,331,551 : Cost 2.55982375 : Time 129.92s : 33931.94 words/s : L.r. 1.1142e-04
[2019-07-10 18:01:53] Ep. 3 : Up. 116500 : Sen. 8,508,793 : Cost 2.53735113 : Time 130.17s : 34193.78 words/s : L.r. 1.1118e-04
[2019-07-10 18:04:03] Ep. 3 : Up. 117000 : Sen. 8,689,938 : Cost 2.50395465 : Time 129.75s : 33983.70 words/s : L.r. 1.1094e-04
[2019-07-10 18:06:12] Ep. 3 : Up. 117500 : Sen. 8,868,339 : Cost 2.54162407 : Time 128.95s : 33799.06 words/s : L.r. 1.1070e-04
[2019-07-10 18:08:21] Ep. 3 : Up. 118000 : Sen. 9,041,429 : Cost 2.55227661 : Time 129.18s : 33928.49 words/s : L.r. 1.1047e-04
[2019-07-10 18:10:31] Ep. 3 : Up. 118500 : Sen. 9,215,184 : Cost 2.56424546 : Time 129.80s : 33861.48 words/s : L.r. 1.1024e-04
[2019-07-10 18:12:40] Ep. 3 : Up. 119000 : Sen. 9,399,788 : Cost 2.52599812 : Time 129.46s : 34015.39 words/s : L.r. 1.1000e-04
[2019-07-10 18:14:50] Ep. 3 : Up. 119500 : Sen. 9,575,252 : Cost 2.55231094 : Time 129.58s : 34045.87 words/s : L.r. 1.0977e-04
[2019-07-10 18:17:00] Ep. 3 : Up. 120000 : Sen. 9,757,875 : Cost 2.50238824 : Time 129.75s : 33997.00 words/s : L.r. 1.0954e-04
[2019-07-10 18:17:00] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 18:17:06] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 18:17:12] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 18:17:25] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 18:17:30] [valid] Ep. 3 : Up. 120000 : ce-mean-words : 1.29653 : new best
[2019-07-10 18:17:31] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 18:17:36] [valid] Ep. 3 : Up. 120000 : perplexity : 3.65657 : new best
[2019-07-10 18:18:15] [valid] Ep. 3 : Up. 120000 : translation : 40.7 : stalled 2 times (last best: 43.32)
[2019-07-10 18:20:25] Ep. 3 : Up. 120500 : Sen. 9,936,431 : Cost 2.54222417 : Time 205.89s : 21194.71 words/s : L.r. 1.0932e-04
[2019-07-10 18:22:35] Ep. 3 : Up. 121000 : Sen. 10,118,623 : Cost 2.52638865 : Time 129.24s : 33919.33 words/s : L.r. 1.0909e-04
[2019-07-10 18:24:44] Ep. 3 : Up. 121500 : Sen. 10,292,767 : Cost 2.54944897 : Time 129.40s : 34073.67 words/s : L.r. 1.0887e-04
[2019-07-10 18:26:53] Ep. 3 : Up. 122000 : Sen. 10,473,183 : Cost 2.56968546 : Time 129.00s : 34155.36 words/s : L.r. 1.0864e-04
[2019-07-10 18:29:03] Ep. 3 : Up. 122500 : Sen. 10,647,444 : Cost 2.46303654 : Time 129.61s : 33828.04 words/s : L.r. 1.0842e-04
[2019-07-10 18:31:12] Ep. 3 : Up. 123000 : Sen. 10,831,918 : Cost 2.55298972 : Time 128.83s : 33853.26 words/s : L.r. 1.0820e-04
[2019-07-10 18:33:21] Ep. 3 : Up. 123500 : Sen. 11,010,585 : Cost 2.51369715 : Time 129.71s : 33980.24 words/s : L.r. 1.0798e-04
[2019-07-10 18:35:31] Ep. 3 : Up. 124000 : Sen. 11,189,914 : Cost 2.51352215 : Time 129.98s : 34015.37 words/s : L.r. 1.0776e-04
[2019-07-10 18:37:41] Ep. 3 : Up. 124500 : Sen. 11,368,433 : Cost 2.52609205 : Time 129.48s : 33982.39 words/s : L.r. 1.0755e-04
[2019-07-10 18:39:51] Ep. 3 : Up. 125000 : Sen. 11,545,722 : Cost 2.55812359 : Time 130.08s : 34100.18 words/s : L.r. 1.0733e-04
[2019-07-10 18:39:51] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 18:39:57] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 18:40:04] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 18:40:17] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 18:40:22] [valid] Ep. 3 : Up. 125000 : ce-mean-words : 1.29155 : new best
[2019-07-10 18:40:23] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 18:40:27] [valid] Ep. 3 : Up. 125000 : perplexity : 3.63843 : new best
[2019-07-10 18:41:06] [valid] Ep. 3 : Up. 125000 : translation : 42.14 : stalled 3 times (last best: 43.32)
[2019-07-10 18:43:16] Ep. 3 : Up. 125500 : Sen. 11,727,152 : Cost 2.52397990 : Time 205.32s : 21185.62 words/s : L.r. 1.0712e-04
[2019-07-10 18:45:25] Ep. 3 : Up. 126000 : Sen. 11,903,116 : Cost 2.54649997 : Time 129.22s : 33990.24 words/s : L.r. 1.0690e-04
[2019-07-10 18:47:34] Ep. 3 : Up. 126500 : Sen. 12,082,078 : Cost 2.52666306 : Time 129.14s : 33784.96 words/s : L.r. 1.0669e-04
[2019-07-10 18:49:45] Ep. 3 : Up. 127000 : Sen. 12,258,587 : Cost 2.53959465 : Time 130.25s : 33958.77 words/s : L.r. 1.0648e-04
[2019-07-10 18:51:53] Ep. 3 : Up. 127500 : Sen. 12,434,439 : Cost 2.53809142 : Time 128.63s : 34068.54 words/s : L.r. 1.0627e-04
[2019-07-10 18:54:02] Ep. 3 : Up. 128000 : Sen. 12,616,942 : Cost 2.50003028 : Time 128.64s : 33833.40 words/s : L.r. 1.0607e-04
[2019-07-10 18:56:11] Ep. 3 : Up. 128500 : Sen. 12,795,982 : Cost 2.55577302 : Time 129.37s : 34028.23 words/s : L.r. 1.0586e-04
[2019-07-10 18:58:21] Ep. 3 : Up. 129000 : Sen. 12,974,848 : Cost 2.51301003 : Time 130.06s : 33970.11 words/s : L.r. 1.0565e-04
[2019-07-10 19:00:31] Ep. 3 : Up. 129500 : Sen. 13,155,824 : Cost 2.51671219 : Time 129.61s : 34040.14 words/s : L.r. 1.0545e-04
[2019-07-10 19:02:40] Ep. 3 : Up. 130000 : Sen. 13,334,461 : Cost 2.52186728 : Time 129.18s : 33828.42 words/s : L.r. 1.0525e-04
[2019-07-10 19:02:40] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 19:02:47] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 19:02:54] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 19:03:08] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 19:03:16] [valid] Ep. 3 : Up. 130000 : ce-mean-words : 1.2871 : new best
[2019-07-10 19:03:17] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 19:03:25] [valid] Ep. 3 : Up. 130000 : perplexity : 3.62228 : new best
[2019-07-10 19:04:03] [valid] Ep. 3 : Up. 130000 : translation : 41.66 : stalled 4 times (last best: 43.32)
[2019-07-10 19:06:14] Ep. 3 : Up. 130500 : Sen. 13,512,168 : Cost 2.57934117 : Time 213.65s : 20548.83 words/s : L.r. 1.0505e-04
[2019-07-10 19:08:24] Ep. 3 : Up. 131000 : Sen. 13,688,706 : Cost 2.50670457 : Time 130.43s : 34007.38 words/s : L.r. 1.0484e-04
[2019-07-10 19:10:33] Ep. 3 : Up. 131500 : Sen. 13,867,761 : Cost 2.54842091 : Time 128.65s : 33921.44 words/s : L.r. 1.0464e-04
[2019-07-10 19:12:43] Ep. 3 : Up. 132000 : Sen. 14,044,504 : Cost 2.49101901 : Time 130.11s : 33905.81 words/s : L.r. 1.0445e-04
[2019-07-10 19:14:53] Ep. 3 : Up. 132500 : Sen. 14,224,471 : Cost 2.54252815 : Time 129.96s : 34267.57 words/s : L.r. 1.0425e-04
[2019-07-10 19:17:02] Ep. 3 : Up. 133000 : Sen. 14,401,711 : Cost 2.51052117 : Time 129.01s : 33914.26 words/s : L.r. 1.0405e-04
[2019-07-10 19:19:12] Ep. 3 : Up. 133500 : Sen. 14,586,634 : Cost 2.48095202 : Time 129.83s : 33779.81 words/s : L.r. 1.0386e-04
[2019-07-10 19:21:21] Ep. 3 : Up. 134000 : Sen. 14,765,178 : Cost 2.54821610 : Time 129.26s : 33957.33 words/s : L.r. 1.0366e-04
[2019-07-10 19:23:30] Ep. 3 : Up. 134500 : Sen. 14,940,378 : Cost 2.53315377 : Time 128.67s : 33814.08 words/s : L.r. 1.0347e-04
[2019-07-10 19:25:39] Ep. 3 : Up. 135000 : Sen. 15,116,698 : Cost 2.56808162 : Time 128.90s : 33677.19 words/s : L.r. 1.0328e-04
[2019-07-10 19:25:39] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 19:25:45] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 19:25:51] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 19:26:05] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 19:26:10] [valid] Ep. 3 : Up. 135000 : ce-mean-words : 1.28375 : new best
[2019-07-10 19:26:10] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 19:26:15] [valid] Ep. 3 : Up. 135000 : perplexity : 3.61015 : new best
[2019-07-10 19:26:55] [valid] Ep. 3 : Up. 135000 : translation : 40.53 : stalled 5 times (last best: 43.32)
[2019-07-10 19:29:07] Ep. 3 : Up. 135500 : Sen. 15,293,745 : Cost 2.53645635 : Time 208.82s : 21481.54 words/s : L.r. 1.0309e-04
[2019-07-10 19:31:16] Ep. 3 : Up. 136000 : Sen. 15,473,919 : Cost 2.51632690 : Time 128.82s : 33961.49 words/s : L.r. 1.0290e-04
[2019-07-10 19:33:25] Ep. 3 : Up. 136500 : Sen. 15,650,217 : Cost 2.50752640 : Time 128.66s : 33886.00 words/s : L.r. 1.0271e-04
[2019-07-10 19:35:35] Ep. 3 : Up. 137000 : Sen. 15,829,941 : Cost 2.53393936 : Time 129.50s : 33988.44 words/s : L.r. 1.0252e-04
[2019-07-10 19:37:44] Ep. 3 : Up. 137500 : Sen. 16,008,024 : Cost 2.50802612 : Time 129.00s : 33909.76 words/s : L.r. 1.0234e-04
[2019-07-10 19:39:53] Ep. 3 : Up. 138000 : Sen. 16,184,008 : Cost 2.52956486 : Time 129.03s : 33675.51 words/s : L.r. 1.0215e-04
[2019-07-10 19:42:02] Ep. 3 : Up. 138500 : Sen. 16,363,113 : Cost 2.48628569 : Time 129.58s : 33903.94 words/s : L.r. 1.0197e-04
[2019-07-10 19:44:11] Ep. 3 : Up. 139000 : Sen. 16,540,010 : Cost 2.53599501 : Time 129.05s : 33910.45 words/s : L.r. 1.0178e-04
[2019-07-10 19:44:15] Seen 16548172 samples
[2019-07-10 19:44:15] Starting epoch 4
[2019-07-10 19:44:15] [data] Shuffling data
[2019-07-10 19:44:30] [data] Done reading 19122526 sentences
[2019-07-10 19:46:39] [data] Done shuffling 19122526 sentences to temp files
[2019-07-10 19:49:27] Ep. 4 : Up. 139500 : Sen. 175,315 : Cost 2.52108502 : Time 316.03s : 14037.68 words/s : L.r. 1.0160e-04
[2019-07-10 19:51:35] Ep. 4 : Up. 140000 : Sen. 352,573 : Cost 2.49002862 : Time 128.13s : 33824.29 words/s : L.r. 1.0142e-04
[2019-07-10 19:51:35] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 19:51:42] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 19:51:48] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 19:52:01] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 19:52:06] [valid] Ep. 4 : Up. 140000 : ce-mean-words : 1.28059 : new best
[2019-07-10 19:52:07] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 19:52:12] [valid] Ep. 4 : Up. 140000 : perplexity : 3.59876 : new best
[2019-07-10 19:52:50] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-translation.npz
[2019-07-10 19:52:54] [valid] Ep. 4 : Up. 140000 : translation : 43.46 : new best
[2019-07-10 19:55:05] Ep. 4 : Up. 140500 : Sen. 525,850 : Cost 2.48921418 : Time 209.74s : 21136.20 words/s : L.r. 1.0124e-04
[2019-07-10 19:57:13] Ep. 4 : Up. 141000 : Sen. 709,601 : Cost 2.51732278 : Time 127.94s : 34100.90 words/s : L.r. 1.0106e-04
[2019-07-10 19:59:22] Ep. 4 : Up. 141500 : Sen. 886,511 : Cost 2.50459480 : Time 128.60s : 33974.04 words/s : L.r. 1.0088e-04
[2019-07-10 20:01:31] Ep. 4 : Up. 142000 : Sen. 1,068,485 : Cost 2.51965213 : Time 129.13s : 34105.06 words/s : L.r. 1.0070e-04
[2019-07-10 20:03:40] Ep. 4 : Up. 142500 : Sen. 1,246,554 : Cost 2.49441981 : Time 129.04s : 34148.09 words/s : L.r. 1.0052e-04
[2019-07-10 20:05:49] Ep. 4 : Up. 143000 : Sen. 1,428,082 : Cost 2.48373151 : Time 129.51s : 34112.24 words/s : L.r. 1.0035e-04
[2019-07-10 20:07:58] Ep. 4 : Up. 143500 : Sen. 1,605,657 : Cost 2.55245686 : Time 128.29s : 34289.17 words/s : L.r. 1.0017e-04
[2019-07-10 20:10:06] Ep. 4 : Up. 144000 : Sen. 1,777,659 : Cost 2.52390718 : Time 128.35s : 34103.41 words/s : L.r. 1.0000e-04
[2019-07-10 20:12:14] Ep. 4 : Up. 144500 : Sen. 1,957,750 : Cost 2.48948431 : Time 128.17s : 33977.35 words/s : L.r. 9.9827e-05
[2019-07-10 20:14:24] Ep. 4 : Up. 145000 : Sen. 2,136,092 : Cost 2.49008918 : Time 129.44s : 34155.69 words/s : L.r. 9.9655e-05
[2019-07-10 20:14:24] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 20:14:30] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 20:14:36] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 20:14:49] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 20:14:54] [valid] Ep. 4 : Up. 145000 : ce-mean-words : 1.2783 : new best
[2019-07-10 20:14:54] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 20:14:59] [valid] Ep. 4 : Up. 145000 : perplexity : 3.59052 : new best
[2019-07-10 20:15:38] [valid] Ep. 4 : Up. 145000 : translation : 39.7 : stalled 1 times (last best: 43.46)
[2019-07-10 20:17:49] Ep. 4 : Up. 145500 : Sen. 2,312,016 : Cost 2.53799415 : Time 205.17s : 21499.12 words/s : L.r. 9.9483e-05
[2019-07-10 20:19:58] Ep. 4 : Up. 146000 : Sen. 2,496,080 : Cost 2.52547359 : Time 128.81s : 33719.66 words/s : L.r. 9.9313e-05
[2019-07-10 20:22:07] Ep. 4 : Up. 146500 : Sen. 2,670,518 : Cost 2.51944327 : Time 129.28s : 33954.24 words/s : L.r. 9.9143e-05
[2019-07-10 20:24:16] Ep. 4 : Up. 147000 : Sen. 2,844,860 : Cost 2.48925757 : Time 129.02s : 34024.91 words/s : L.r. 9.8974e-05
[2019-07-10 20:26:25] Ep. 4 : Up. 147500 : Sen. 3,027,438 : Cost 2.50837684 : Time 129.58s : 34055.63 words/s : L.r. 9.8806e-05
[2019-07-10 20:28:35] Ep. 4 : Up. 148000 : Sen. 3,209,688 : Cost 2.49151063 : Time 129.84s : 34013.86 words/s : L.r. 9.8639e-05
[2019-07-10 20:30:45] Ep. 4 : Up. 148500 : Sen. 3,392,374 : Cost 2.48208237 : Time 129.34s : 33842.09 words/s : L.r. 9.8473e-05
[2019-07-10 20:32:54] Ep. 4 : Up. 149000 : Sen. 3,568,713 : Cost 2.51913118 : Time 129.79s : 34062.59 words/s : L.r. 9.8308e-05
[2019-07-10 20:35:03] Ep. 4 : Up. 149500 : Sen. 3,747,173 : Cost 2.51344013 : Time 128.79s : 33823.47 words/s : L.r. 9.8143e-05
[2019-07-10 20:37:12] Ep. 4 : Up. 150000 : Sen. 3,923,870 : Cost 2.52651834 : Time 129.03s : 33910.23 words/s : L.r. 9.7980e-05
[2019-07-10 20:37:12] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 20:37:19] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 20:37:25] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 20:37:38] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 20:37:43] [valid] Ep. 4 : Up. 150000 : ce-mean-words : 1.27588 : new best
[2019-07-10 20:37:44] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 20:37:48] [valid] Ep. 4 : Up. 150000 : perplexity : 3.58185 : new best
[2019-07-10 20:38:26] [valid] Ep. 4 : Up. 150000 : translation : 40.35 : stalled 2 times (last best: 43.46)
[2019-07-10 20:40:37] Ep. 4 : Up. 150500 : Sen. 4,098,901 : Cost 2.51041293 : Time 204.73s : 21439.16 words/s : L.r. 9.7817e-05
[2019-07-10 20:42:47] Ep. 4 : Up. 151000 : Sen. 4,280,237 : Cost 2.50515437 : Time 129.68s : 34107.86 words/s : L.r. 9.7655e-05
[2019-07-10 20:44:56] Ep. 4 : Up. 151500 : Sen. 4,456,352 : Cost 2.51027751 : Time 129.32s : 33869.09 words/s : L.r. 9.7493e-05
[2019-07-10 20:47:06] Ep. 4 : Up. 152000 : Sen. 4,638,546 : Cost 2.54550767 : Time 129.89s : 34206.46 words/s : L.r. 9.7333e-05
[2019-07-10 20:49:15] Ep. 4 : Up. 152500 : Sen. 4,819,181 : Cost 2.47940373 : Time 129.16s : 33755.60 words/s : L.r. 9.7173e-05
[2019-07-10 20:51:24] Ep. 4 : Up. 153000 : Sen. 4,994,662 : Cost 2.50481606 : Time 129.46s : 33959.15 words/s : L.r. 9.7014e-05
[2019-07-10 20:53:33] Ep. 4 : Up. 153500 : Sen. 5,170,846 : Cost 2.51523447 : Time 128.67s : 33870.16 words/s : L.r. 9.6856e-05
[2019-07-10 20:55:43] Ep. 4 : Up. 154000 : Sen. 5,351,132 : Cost 2.48449183 : Time 129.41s : 33918.19 words/s : L.r. 9.6699e-05
[2019-07-10 20:57:52] Ep. 4 : Up. 154500 : Sen. 5,533,022 : Cost 2.48606777 : Time 129.23s : 33962.51 words/s : L.r. 9.6542e-05
[2019-07-10 21:00:01] Ep. 4 : Up. 155000 : Sen. 5,711,555 : Cost 2.54124427 : Time 129.31s : 33897.87 words/s : L.r. 9.6386e-05
[2019-07-10 21:00:01] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 21:00:09] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 21:00:16] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 21:00:31] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 21:00:40] [valid] Ep. 4 : Up. 155000 : ce-mean-words : 1.27345 : new best
[2019-07-10 21:00:41] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 21:00:46] [valid] Ep. 4 : Up. 155000 : perplexity : 3.57316 : new best
[2019-07-10 21:01:27] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-translation.npz
[2019-07-10 21:01:32] [valid] Ep. 4 : Up. 155000 : translation : 43.77 : new best
[2019-07-10 21:03:44] Ep. 4 : Up. 155500 : Sen. 5,890,079 : Cost 2.50710559 : Time 223.34s : 19834.18 words/s : L.r. 9.6231e-05
[2019-07-10 21:05:55] Ep. 4 : Up. 156000 : Sen. 6,063,235 : Cost 2.49642682 : Time 130.55s : 34079.28 words/s : L.r. 9.6077e-05
[2019-07-10 21:08:04] Ep. 4 : Up. 156500 : Sen. 6,246,138 : Cost 2.48722124 : Time 129.38s : 33845.94 words/s : L.r. 9.5923e-05
[2019-07-10 21:10:14] Ep. 4 : Up. 157000 : Sen. 6,424,686 : Cost 2.53488541 : Time 129.44s : 34031.11 words/s : L.r. 9.5770e-05
[2019-07-10 21:12:24] Ep. 4 : Up. 157500 : Sen. 6,606,989 : Cost 2.47828031 : Time 130.42s : 33820.30 words/s : L.r. 9.5618e-05
[2019-07-10 21:14:33] Ep. 4 : Up. 158000 : Sen. 6,781,912 : Cost 2.48875237 : Time 129.10s : 33856.65 words/s : L.r. 9.5467e-05
[2019-07-10 21:16:43] Ep. 4 : Up. 158500 : Sen. 6,957,160 : Cost 2.56410408 : Time 129.25s : 33783.19 words/s : L.r. 9.5316e-05
[2019-07-10 21:18:52] Ep. 4 : Up. 159000 : Sen. 7,138,690 : Cost 2.49061394 : Time 129.39s : 33837.91 words/s : L.r. 9.5166e-05
[2019-07-10 21:21:02] Ep. 4 : Up. 159500 : Sen. 7,313,854 : Cost 2.54623294 : Time 129.84s : 34190.95 words/s : L.r. 9.5017e-05
[2019-07-10 21:23:12] Ep. 4 : Up. 160000 : Sen. 7,490,049 : Cost 2.48949409 : Time 129.84s : 33913.39 words/s : L.r. 9.4868e-05
[2019-07-10 21:23:12] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 21:23:18] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 21:23:25] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 21:23:37] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 21:23:42] [valid] Ep. 4 : Up. 160000 : ce-mean-words : 1.27095 : new best
[2019-07-10 21:23:43] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 21:23:48] [valid] Ep. 4 : Up. 160000 : perplexity : 3.56423 : new best
[2019-07-10 21:24:27] [valid] Ep. 4 : Up. 160000 : translation : 42.25 : stalled 1 times (last best: 43.77)
[2019-07-10 21:26:38] Ep. 4 : Up. 160500 : Sen. 7,673,103 : Cost 2.50182247 : Time 206.71s : 21275.33 words/s : L.r. 9.4720e-05
[2019-07-10 21:28:49] Ep. 4 : Up. 161000 : Sen. 7,850,676 : Cost 2.49690056 : Time 130.74s : 33548.78 words/s : L.r. 9.4573e-05
[2019-07-10 21:30:58] Ep. 4 : Up. 161500 : Sen. 8,031,886 : Cost 2.49054480 : Time 129.24s : 33763.83 words/s : L.r. 9.4427e-05
[2019-07-10 21:33:08] Ep. 4 : Up. 162000 : Sen. 8,209,989 : Cost 2.51326227 : Time 129.23s : 34067.11 words/s : L.r. 9.4281e-05
[2019-07-10 21:35:17] Ep. 4 : Up. 162500 : Sen. 8,388,405 : Cost 2.51332235 : Time 129.49s : 33894.07 words/s : L.r. 9.4136e-05
[2019-07-10 21:37:27] Ep. 4 : Up. 163000 : Sen. 8,561,790 : Cost 2.52426338 : Time 130.21s : 33949.72 words/s : L.r. 9.3991e-05
[2019-07-10 21:39:36] Ep. 4 : Up. 163500 : Sen. 8,741,248 : Cost 2.51382899 : Time 128.83s : 33717.00 words/s : L.r. 9.3847e-05
[2019-07-10 21:41:46] Ep. 4 : Up. 164000 : Sen. 8,922,982 : Cost 2.50767255 : Time 129.73s : 34040.65 words/s : L.r. 9.3704e-05
[2019-07-10 21:43:56] Ep. 4 : Up. 164500 : Sen. 9,102,669 : Cost 2.46658635 : Time 129.80s : 33809.47 words/s : L.r. 9.3562e-05
[2019-07-10 21:46:06] Ep. 4 : Up. 165000 : Sen. 9,279,834 : Cost 2.49201250 : Time 130.01s : 34082.05 words/s : L.r. 9.3420e-05
[2019-07-10 21:46:06] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 21:46:16] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 21:46:23] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 21:46:36] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 21:46:41] [valid] Ep. 4 : Up. 165000 : ce-mean-words : 1.26833 : new best
[2019-07-10 21:46:42] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 21:46:50] [valid] Ep. 4 : Up. 165000 : perplexity : 3.55492 : new best
[2019-07-10 21:47:28] [valid] Ep. 4 : Up. 165000 : translation : 42.74 : stalled 2 times (last best: 43.77)
[2019-07-10 21:49:38] Ep. 4 : Up. 165500 : Sen. 9,455,880 : Cost 2.50987101 : Time 212.22s : 20606.81 words/s : L.r. 9.3279e-05
[2019-07-10 21:51:47] Ep. 4 : Up. 166000 : Sen. 9,638,146 : Cost 2.53479242 : Time 128.73s : 34035.29 words/s : L.r. 9.3138e-05
[2019-07-10 21:53:55] Ep. 4 : Up. 166500 : Sen. 9,818,503 : Cost 2.48101544 : Time 128.63s : 33853.05 words/s : L.r. 9.2998e-05
[2019-07-10 21:56:05] Ep. 4 : Up. 167000 : Sen. 9,995,618 : Cost 2.48792911 : Time 129.68s : 34055.50 words/s : L.r. 9.2859e-05
[2019-07-10 21:58:14] Ep. 4 : Up. 167500 : Sen. 10,170,930 : Cost 2.50482655 : Time 128.77s : 33925.20 words/s : L.r. 9.2720e-05
[2019-07-10 22:00:23] Ep. 4 : Up. 168000 : Sen. 10,347,590 : Cost 2.51131892 : Time 129.59s : 34004.64 words/s : L.r. 9.2582e-05
[2019-07-10 22:02:33] Ep. 4 : Up. 168500 : Sen. 10,535,114 : Cost 2.51622391 : Time 129.30s : 34028.08 words/s : L.r. 9.2445e-05
[2019-07-10 22:04:43] Ep. 4 : Up. 169000 : Sen. 10,710,005 : Cost 2.51331496 : Time 129.93s : 34029.15 words/s : L.r. 9.2308e-05
[2019-07-10 22:06:52] Ep. 4 : Up. 169500 : Sen. 10,887,370 : Cost 2.48466706 : Time 129.62s : 33978.08 words/s : L.r. 9.2171e-05
[2019-07-10 22:09:01] Ep. 4 : Up. 170000 : Sen. 11,063,792 : Cost 2.49652958 : Time 128.65s : 33807.22 words/s : L.r. 9.2036e-05
[2019-07-10 22:09:01] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 22:09:07] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 22:09:14] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 22:09:27] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 22:09:32] [valid] Ep. 4 : Up. 170000 : ce-mean-words : 1.26516 : new best
[2019-07-10 22:09:33] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 22:09:38] [valid] Ep. 4 : Up. 170000 : perplexity : 3.54367 : new best
[2019-07-10 22:10:15] [valid] Ep. 4 : Up. 170000 : translation : 40.85 : stalled 3 times (last best: 43.77)
[2019-07-10 22:12:26] Ep. 4 : Up. 170500 : Sen. 11,241,586 : Cost 2.49987841 : Time 205.22s : 21319.05 words/s : L.r. 9.1901e-05
[2019-07-10 22:14:36] Ep. 4 : Up. 171000 : Sen. 11,423,484 : Cost 2.50456238 : Time 130.00s : 33964.22 words/s : L.r. 9.1766e-05
[2019-07-10 22:16:46] Ep. 4 : Up. 171500 : Sen. 11,605,008 : Cost 2.48145127 : Time 129.66s : 34001.13 words/s : L.r. 9.1632e-05
[2019-07-10 22:18:56] Ep. 4 : Up. 172000 : Sen. 11,786,906 : Cost 2.49908972 : Time 129.86s : 33762.63 words/s : L.r. 9.1499e-05
[2019-07-10 22:21:05] Ep. 4 : Up. 172500 : Sen. 11,961,295 : Cost 2.51370454 : Time 129.46s : 34015.74 words/s : L.r. 9.1366e-05
[2019-07-10 22:23:16] Ep. 4 : Up. 173000 : Sen. 12,138,946 : Cost 2.50520420 : Time 130.54s : 33926.31 words/s : L.r. 9.1234e-05
[2019-07-10 22:25:26] Ep. 4 : Up. 173500 : Sen. 12,317,762 : Cost 2.51022649 : Time 130.49s : 33969.31 words/s : L.r. 9.1103e-05
[2019-07-10 22:27:36] Ep. 4 : Up. 174000 : Sen. 12,496,431 : Cost 2.46470165 : Time 130.29s : 34044.92 words/s : L.r. 9.0972e-05
[2019-07-10 22:29:45] Ep. 4 : Up. 174500 : Sen. 12,680,596 : Cost 2.48427844 : Time 128.80s : 33689.37 words/s : L.r. 9.0841e-05
[2019-07-10 22:31:54] Ep. 4 : Up. 175000 : Sen. 12,856,494 : Cost 2.53020000 : Time 128.44s : 34151.27 words/s : L.r. 9.0711e-05
[2019-07-10 22:31:54] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 22:32:01] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 22:32:13] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 22:32:26] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 22:32:31] [valid] Ep. 4 : Up. 175000 : ce-mean-words : 1.26185 : new best
[2019-07-10 22:32:32] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 22:32:37] [valid] Ep. 4 : Up. 175000 : perplexity : 3.53194 : new best
[2019-07-10 22:33:16] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-translation.npz
[2019-07-10 22:33:21] [valid] Ep. 4 : Up. 175000 : translation : 43.94 : new best
[2019-07-10 22:35:31] Ep. 4 : Up. 175500 : Sen. 13,030,174 : Cost 2.51698804 : Time 217.00s : 20039.01 words/s : L.r. 9.0582e-05
[2019-07-10 22:37:40] Ep. 4 : Up. 176000 : Sen. 13,211,283 : Cost 2.51538420 : Time 129.73s : 34329.21 words/s : L.r. 9.0453e-05
[2019-07-10 22:39:49] Ep. 4 : Up. 176500 : Sen. 13,388,224 : Cost 2.51445985 : Time 129.10s : 34126.09 words/s : L.r. 9.0325e-05
[2019-07-10 22:41:58] Ep. 4 : Up. 177000 : Sen. 13,566,663 : Cost 2.48540139 : Time 128.46s : 34044.37 words/s : L.r. 9.0198e-05
[2019-07-10 22:44:07] Ep. 4 : Up. 177500 : Sen. 13,747,777 : Cost 2.49167228 : Time 128.69s : 33992.98 words/s : L.r. 9.0070e-05
[2019-07-10 22:46:15] Ep. 4 : Up. 178000 : Sen. 13,926,860 : Cost 2.49502873 : Time 128.09s : 34114.53 words/s : L.r. 8.9944e-05
[2019-07-10 22:48:23] Ep. 4 : Up. 178500 : Sen. 14,101,073 : Cost 2.48965049 : Time 128.69s : 33886.75 words/s : L.r. 8.9818e-05
[2019-07-10 22:50:31] Ep. 4 : Up. 179000 : Sen. 14,280,629 : Cost 2.51434135 : Time 128.13s : 34034.13 words/s : L.r. 8.9692e-05
[2019-07-10 22:52:41] Ep. 4 : Up. 179500 : Sen. 14,461,490 : Cost 2.47147155 : Time 129.08s : 34138.02 words/s : L.r. 8.9567e-05
[2019-07-10 22:54:50] Ep. 4 : Up. 180000 : Sen. 14,639,944 : Cost 2.50114703 : Time 129.63s : 34082.35 words/s : L.r. 8.9443e-05
[2019-07-10 22:54:50] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 22:54:57] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 22:55:04] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 22:55:17] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 22:55:23] [valid] Ep. 4 : Up. 180000 : ce-mean-words : 1.25925 : new best
[2019-07-10 22:55:24] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 22:55:29] [valid] Ep. 4 : Up. 180000 : perplexity : 3.52279 : new best
[2019-07-10 22:56:08] [valid] Ep. 4 : Up. 180000 : translation : 43.58 : stalled 1 times (last best: 43.94)
[2019-07-10 22:58:19] Ep. 4 : Up. 180500 : Sen. 14,820,279 : Cost 2.52642751 : Time 208.44s : 21209.64 words/s : L.r. 8.9319e-05
[2019-07-10 23:00:28] Ep. 4 : Up. 181000 : Sen. 14,995,942 : Cost 2.48430896 : Time 129.23s : 34273.87 words/s : L.r. 8.9195e-05
[2019-07-10 23:02:36] Ep. 4 : Up. 181500 : Sen. 15,172,260 : Cost 2.50050402 : Time 128.53s : 33945.31 words/s : L.r. 8.9072e-05
[2019-07-10 23:04:46] Ep. 4 : Up. 182000 : Sen. 15,345,875 : Cost 2.54315209 : Time 129.25s : 34348.94 words/s : L.r. 8.8950e-05
[2019-07-10 23:06:54] Ep. 4 : Up. 182500 : Sen. 15,524,393 : Cost 2.50763607 : Time 128.67s : 33977.11 words/s : L.r. 8.8828e-05
[2019-07-10 23:09:04] Ep. 4 : Up. 183000 : Sen. 15,711,585 : Cost 2.48083663 : Time 129.27s : 33992.71 words/s : L.r. 8.8707e-05
[2019-07-10 23:11:12] Ep. 4 : Up. 183500 : Sen. 15,891,877 : Cost 2.45421910 : Time 128.70s : 34093.36 words/s : L.r. 8.8586e-05
[2019-07-10 23:13:22] Ep. 4 : Up. 184000 : Sen. 16,066,075 : Cost 2.48302603 : Time 129.21s : 34093.02 words/s : L.r. 8.8465e-05
[2019-07-10 23:15:30] Ep. 4 : Up. 184500 : Sen. 16,246,572 : Cost 2.48009539 : Time 128.85s : 34118.39 words/s : L.r. 8.8345e-05
[2019-07-10 23:17:39] Ep. 4 : Up. 185000 : Sen. 16,424,467 : Cost 2.53435516 : Time 128.25s : 33947.32 words/s : L.r. 8.8226e-05
[2019-07-10 23:17:39] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 23:17:45] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 23:17:52] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 23:18:05] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 23:18:13] [valid] Ep. 4 : Up. 185000 : ce-mean-words : 1.25693 : new best
[2019-07-10 23:18:14] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 23:18:20] [valid] Ep. 4 : Up. 185000 : perplexity : 3.51463 : new best
[2019-07-10 23:18:58] [valid] Ep. 4 : Up. 185000 : translation : 43.35 : stalled 2 times (last best: 43.94)
[2019-07-10 23:20:29] Seen 16548172 samples
[2019-07-10 23:20:29] Starting epoch 5
[2019-07-10 23:20:29] [data] Shuffling data
[2019-07-10 23:20:43] [data] Done reading 19122526 sentences
[2019-07-10 23:22:53] [data] Done shuffling 19122526 sentences to temp files
[2019-07-10 23:24:17] Ep. 5 : Up. 185500 : Sen. 53,516 : Cost 2.47795486 : Time 398.14s : 10813.93 words/s : L.r. 8.8107e-05
[2019-07-10 23:26:26] Ep. 5 : Up. 186000 : Sen. 227,970 : Cost 2.48159671 : Time 128.78s : 34423.89 words/s : L.r. 8.7988e-05
[2019-07-10 23:28:34] Ep. 5 : Up. 186500 : Sen. 405,941 : Cost 2.48665762 : Time 128.73s : 34189.45 words/s : L.r. 8.7870e-05
[2019-07-10 23:30:44] Ep. 5 : Up. 187000 : Sen. 590,200 : Cost 2.46792221 : Time 129.25s : 34213.27 words/s : L.r. 8.7753e-05
[2019-07-10 23:32:51] Ep. 5 : Up. 187500 : Sen. 765,690 : Cost 2.49573040 : Time 127.92s : 34133.76 words/s : L.r. 8.7636e-05
[2019-07-10 23:35:00] Ep. 5 : Up. 188000 : Sen. 943,166 : Cost 2.49219036 : Time 128.34s : 34069.22 words/s : L.r. 8.7519e-05
[2019-07-10 23:37:08] Ep. 5 : Up. 188500 : Sen. 1,123,238 : Cost 2.46051407 : Time 128.18s : 33965.20 words/s : L.r. 8.7403e-05
[2019-07-10 23:39:17] Ep. 5 : Up. 189000 : Sen. 1,300,790 : Cost 2.50516772 : Time 128.95s : 34172.74 words/s : L.r. 8.7287e-05
[2019-07-10 23:41:27] Ep. 5 : Up. 189500 : Sen. 1,480,777 : Cost 2.46491408 : Time 129.59s : 34189.16 words/s : L.r. 8.7172e-05
[2019-07-10 23:43:35] Ep. 5 : Up. 190000 : Sen. 1,658,694 : Cost 2.48456073 : Time 128.48s : 34070.47 words/s : L.r. 8.7057e-05
[2019-07-10 23:43:35] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-10 23:43:42] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-10 23:43:48] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-10 23:44:02] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-10 23:44:06] [valid] Ep. 5 : Up. 190000 : ce-mean-words : 1.25582 : new best
[2019-07-10 23:44:07] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-10 23:44:12] [valid] Ep. 5 : Up. 190000 : perplexity : 3.5107 : new best
[2019-07-10 23:44:49] [valid] Ep. 5 : Up. 190000 : translation : 43.42 : stalled 3 times (last best: 43.94)
[2019-07-10 23:47:00] Ep. 5 : Up. 190500 : Sen. 1,838,778 : Cost 2.47473598 : Time 204.64s : 21536.64 words/s : L.r. 8.6943e-05
[2019-07-10 23:49:09] Ep. 5 : Up. 191000 : Sen. 2,017,392 : Cost 2.49854159 : Time 128.90s : 34074.37 words/s : L.r. 8.6829e-05
[2019-07-10 23:51:17] Ep. 5 : Up. 191500 : Sen. 2,191,924 : Cost 2.49696469 : Time 128.41s : 34307.74 words/s : L.r. 8.6716e-05
[2019-07-10 23:53:26] Ep. 5 : Up. 192000 : Sen. 2,365,999 : Cost 2.48852944 : Time 128.88s : 34009.80 words/s : L.r. 8.6603e-05
[2019-07-10 23:55:35] Ep. 5 : Up. 192500 : Sen. 2,546,574 : Cost 2.47331357 : Time 128.76s : 34209.65 words/s : L.r. 8.6490e-05
[2019-07-10 23:57:44] Ep. 5 : Up. 193000 : Sen. 2,726,527 : Cost 2.49389100 : Time 129.15s : 34094.90 words/s : L.r. 8.6378e-05
[2019-07-10 23:59:53] Ep. 5 : Up. 193500 : Sen. 2,911,153 : Cost 2.44586539 : Time 128.98s : 33783.49 words/s : L.r. 8.6266e-05
[2019-07-11 00:02:02] Ep. 5 : Up. 194000 : Sen. 3,092,358 : Cost 2.48016763 : Time 128.95s : 34327.94 words/s : L.r. 8.6155e-05
[2019-07-11 00:04:11] Ep. 5 : Up. 194500 : Sen. 3,270,230 : Cost 2.49636269 : Time 128.91s : 34037.87 words/s : L.r. 8.6044e-05
[2019-07-11 00:06:19] Ep. 5 : Up. 195000 : Sen. 3,443,995 : Cost 2.51690602 : Time 128.66s : 33875.66 words/s : L.r. 8.5934e-05
[2019-07-11 00:06:19] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 00:06:26] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 00:06:32] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 00:06:47] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 00:06:52] [valid] Ep. 5 : Up. 195000 : ce-mean-words : 1.25408 : new best
[2019-07-11 00:06:52] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 00:06:57] [valid] Ep. 5 : Up. 195000 : perplexity : 3.50462 : new best
[2019-07-11 00:07:37] [valid] Ep. 5 : Up. 195000 : translation : 43.33 : stalled 4 times (last best: 43.94)
[2019-07-11 00:09:49] Ep. 5 : Up. 195500 : Sen. 3,618,078 : Cost 2.48184562 : Time 209.30s : 21100.34 words/s : L.r. 8.5824e-05
[2019-07-11 00:11:58] Ep. 5 : Up. 196000 : Sen. 3,797,029 : Cost 2.50203347 : Time 129.15s : 33839.14 words/s : L.r. 8.5714e-05
[2019-07-11 00:14:08] Ep. 5 : Up. 196500 : Sen. 3,983,678 : Cost 2.43685198 : Time 130.53s : 33753.69 words/s : L.r. 8.5605e-05
[2019-07-11 00:16:18] Ep. 5 : Up. 197000 : Sen. 4,157,475 : Cost 2.46691918 : Time 130.21s : 33831.14 words/s : L.r. 8.5496e-05
[2019-07-11 00:18:29] Ep. 5 : Up. 197500 : Sen. 4,334,528 : Cost 2.50702906 : Time 130.16s : 33941.47 words/s : L.r. 8.5388e-05
[2019-07-11 00:20:39] Ep. 5 : Up. 198000 : Sen. 4,512,144 : Cost 2.48493266 : Time 130.22s : 33994.58 words/s : L.r. 8.5280e-05
[2019-07-11 00:22:49] Ep. 5 : Up. 198500 : Sen. 4,698,961 : Cost 2.47968197 : Time 129.79s : 33807.15 words/s : L.r. 8.5173e-05
[2019-07-11 00:24:57] Ep. 5 : Up. 199000 : Sen. 4,872,222 : Cost 2.50108290 : Time 128.83s : 33671.83 words/s : L.r. 8.5066e-05
[2019-07-11 00:27:08] Ep. 5 : Up. 199500 : Sen. 5,051,646 : Cost 2.46311164 : Time 130.35s : 33780.77 words/s : L.r. 8.4959e-05
[2019-07-11 00:29:18] Ep. 5 : Up. 200000 : Sen. 5,232,859 : Cost 2.49680591 : Time 129.71s : 33679.19 words/s : L.r. 8.4853e-05
[2019-07-11 00:29:18] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 00:29:24] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 00:29:31] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 00:29:45] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 00:29:49] [valid] Ep. 5 : Up. 200000 : ce-mean-words : 1.25238 : new best
[2019-07-11 00:29:50] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 00:29:55] [valid] Ep. 5 : Up. 200000 : perplexity : 3.49866 : new best
[2019-07-11 00:30:34] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-translation.npz
[2019-07-11 00:30:39] [valid] Ep. 5 : Up. 200000 : translation : 44.43 : new best
[2019-07-11 00:32:50] Ep. 5 : Up. 200500 : Sen. 5,412,161 : Cost 2.48359179 : Time 212.07s : 20394.50 words/s : L.r. 8.4747e-05
[2019-07-11 00:35:00] Ep. 5 : Up. 201000 : Sen. 5,588,662 : Cost 2.46101713 : Time 130.34s : 34103.91 words/s : L.r. 8.4641e-05
[2019-07-11 00:37:10] Ep. 5 : Up. 201500 : Sen. 5,765,473 : Cost 2.53073835 : Time 130.26s : 34110.74 words/s : L.r. 8.4536e-05
[2019-07-11 00:39:20] Ep. 5 : Up. 202000 : Sen. 5,948,235 : Cost 2.45376611 : Time 129.42s : 33857.27 words/s : L.r. 8.4432e-05
[2019-07-11 00:41:29] Ep. 5 : Up. 202500 : Sen. 6,127,306 : Cost 2.47813630 : Time 129.26s : 33851.99 words/s : L.r. 8.4327e-05
[2019-07-11 00:43:39] Ep. 5 : Up. 203000 : Sen. 6,307,624 : Cost 2.47410631 : Time 129.98s : 33769.24 words/s : L.r. 8.4223e-05
[2019-07-11 00:45:49] Ep. 5 : Up. 203500 : Sen. 6,486,662 : Cost 2.45901704 : Time 129.96s : 33882.16 words/s : L.r. 8.4120e-05
[2019-07-11 00:47:57] Ep. 5 : Up. 204000 : Sen. 6,663,767 : Cost 2.48319244 : Time 128.52s : 33765.01 words/s : L.r. 8.4017e-05
[2019-07-11 00:50:08] Ep. 5 : Up. 204500 : Sen. 6,838,835 : Cost 2.49450278 : Time 130.47s : 34217.87 words/s : L.r. 8.3914e-05
[2019-07-11 00:52:17] Ep. 5 : Up. 205000 : Sen. 7,015,914 : Cost 2.51328707 : Time 129.15s : 33930.77 words/s : L.r. 8.3812e-05
[2019-07-11 00:52:17] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 00:52:23] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 00:52:30] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 00:52:43] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 00:52:48] [valid] Ep. 5 : Up. 205000 : ce-mean-words : 1.25048 : new best
[2019-07-11 00:52:49] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 00:52:54] [valid] Ep. 5 : Up. 205000 : perplexity : 3.49202 : new best
[2019-07-11 00:53:32] [valid] Ep. 5 : Up. 205000 : translation : 44.27 : stalled 1 times (last best: 44.43)
[2019-07-11 00:55:43] Ep. 5 : Up. 205500 : Sen. 7,191,330 : Cost 2.45599842 : Time 206.14s : 21186.12 words/s : L.r. 8.3710e-05
[2019-07-11 00:57:54] Ep. 5 : Up. 206000 : Sen. 7,371,115 : Cost 2.47159147 : Time 130.46s : 33830.43 words/s : L.r. 8.3608e-05
[2019-07-11 01:00:02] Ep. 5 : Up. 206500 : Sen. 7,554,770 : Cost 2.47843146 : Time 128.87s : 33805.81 words/s : L.r. 8.3507e-05
[2019-07-11 01:02:13] Ep. 5 : Up. 207000 : Sen. 7,730,742 : Cost 2.50103188 : Time 130.60s : 33909.81 words/s : L.r. 8.3406e-05
[2019-07-11 01:04:23] Ep. 5 : Up. 207500 : Sen. 7,912,684 : Cost 2.49088311 : Time 129.55s : 33874.32 words/s : L.r. 8.3305e-05
[2019-07-11 01:06:32] Ep. 5 : Up. 208000 : Sen. 8,088,028 : Cost 2.50401473 : Time 129.56s : 33984.91 words/s : L.r. 8.3205e-05
[2019-07-11 01:08:42] Ep. 5 : Up. 208500 : Sen. 8,267,437 : Cost 2.51051283 : Time 129.73s : 33741.22 words/s : L.r. 8.3105e-05
[2019-07-11 01:10:52] Ep. 5 : Up. 209000 : Sen. 8,446,747 : Cost 2.46551299 : Time 130.25s : 33829.60 words/s : L.r. 8.3006e-05
[2019-07-11 01:13:02] Ep. 5 : Up. 209500 : Sen. 8,627,150 : Cost 2.46554637 : Time 129.72s : 34027.28 words/s : L.r. 8.2907e-05
[2019-07-11 01:15:12] Ep. 5 : Up. 210000 : Sen. 8,808,739 : Cost 2.47785735 : Time 129.77s : 33979.24 words/s : L.r. 8.2808e-05
[2019-07-11 01:15:12] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 01:15:18] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 01:15:24] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 01:15:38] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 01:15:43] [valid] Ep. 5 : Up. 210000 : ce-mean-words : 1.24867 : new best
[2019-07-11 01:15:44] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 01:15:49] [valid] Ep. 5 : Up. 210000 : perplexity : 3.4857 : new best
[2019-07-11 01:16:31] [valid] Ep. 5 : Up. 210000 : translation : 41.01 : stalled 2 times (last best: 44.43)
[2019-07-11 01:18:41] Ep. 5 : Up. 210500 : Sen. 8,981,596 : Cost 2.48206711 : Time 209.83s : 20920.98 words/s : L.r. 8.2709e-05
[2019-07-11 01:20:51] Ep. 5 : Up. 211000 : Sen. 9,150,700 : Cost 2.50753784 : Time 129.82s : 33818.58 words/s : L.r. 8.2611e-05
[2019-07-11 01:23:00] Ep. 5 : Up. 211500 : Sen. 9,333,016 : Cost 2.49275255 : Time 128.71s : 33791.42 words/s : L.r. 8.2514e-05
[2019-07-11 01:25:10] Ep. 5 : Up. 212000 : Sen. 9,509,930 : Cost 2.46376276 : Time 129.71s : 33700.15 words/s : L.r. 8.2416e-05
[2019-07-11 01:27:19] Ep. 5 : Up. 212500 : Sen. 9,687,946 : Cost 2.49459720 : Time 129.34s : 33760.48 words/s : L.r. 8.2319e-05
[2019-07-11 01:29:29] Ep. 5 : Up. 213000 : Sen. 9,870,931 : Cost 2.48407412 : Time 130.31s : 34143.49 words/s : L.r. 8.2223e-05
[2019-07-11 01:31:39] Ep. 5 : Up. 213500 : Sen. 10,052,907 : Cost 2.47179699 : Time 130.04s : 33967.82 words/s : L.r. 8.2126e-05
[2019-07-11 01:33:48] Ep. 5 : Up. 214000 : Sen. 10,231,978 : Cost 2.46964741 : Time 129.11s : 34035.79 words/s : L.r. 8.2030e-05
[2019-07-11 01:35:58] Ep. 5 : Up. 214500 : Sen. 10,412,639 : Cost 2.53512931 : Time 129.50s : 34099.40 words/s : L.r. 8.1935e-05
[2019-07-11 01:38:07] Ep. 5 : Up. 215000 : Sen. 10,586,325 : Cost 2.50248337 : Time 129.10s : 33987.49 words/s : L.r. 8.1839e-05
[2019-07-11 01:38:07] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 01:38:13] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 01:38:20] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 01:38:33] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 01:38:38] [valid] Ep. 5 : Up. 215000 : ce-mean-words : 1.24716 : new best
[2019-07-11 01:38:38] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 01:38:43] [valid] Ep. 5 : Up. 215000 : perplexity : 3.48043 : new best
[2019-07-11 01:39:18] [valid] Ep. 5 : Up. 215000 : translation : 40.02 : stalled 3 times (last best: 44.43)
[2019-07-11 01:41:30] Ep. 5 : Up. 215500 : Sen. 10,762,173 : Cost 2.47294378 : Time 202.45s : 21740.05 words/s : L.r. 8.1744e-05
[2019-07-11 01:43:39] Ep. 5 : Up. 216000 : Sen. 10,945,126 : Cost 2.43510461 : Time 129.39s : 34035.57 words/s : L.r. 8.1650e-05
[2019-07-11 01:45:49] Ep. 5 : Up. 216500 : Sen. 11,132,895 : Cost 2.45088482 : Time 129.71s : 33819.57 words/s : L.r. 8.1555e-05
[2019-07-11 01:47:58] Ep. 5 : Up. 217000 : Sen. 11,302,219 : Cost 2.54301500 : Time 129.58s : 34135.12 words/s : L.r. 8.1461e-05
[2019-07-11 01:50:06] Ep. 5 : Up. 217500 : Sen. 11,483,146 : Cost 2.50435400 : Time 127.84s : 33703.77 words/s : L.r. 8.1368e-05
[2019-07-11 01:52:17] Ep. 5 : Up. 218000 : Sen. 11,660,627 : Cost 2.48513675 : Time 130.99s : 34291.50 words/s : L.r. 8.1274e-05
[2019-07-11 01:54:26] Ep. 5 : Up. 218500 : Sen. 11,840,467 : Cost 2.43005109 : Time 129.30s : 33624.00 words/s : L.r. 8.1181e-05
[2019-07-11 01:56:35] Ep. 5 : Up. 219000 : Sen. 12,017,660 : Cost 2.46038747 : Time 129.12s : 33991.26 words/s : L.r. 8.1088e-05
[2019-07-11 01:58:46] Ep. 5 : Up. 219500 : Sen. 12,200,331 : Cost 2.45315456 : Time 130.17s : 33829.62 words/s : L.r. 8.0996e-05
[2019-07-11 02:00:55] Ep. 5 : Up. 220000 : Sen. 12,375,845 : Cost 2.46958113 : Time 129.24s : 33886.79 words/s : L.r. 8.0904e-05
[2019-07-11 02:00:55] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 02:01:01] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 02:01:08] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 02:01:22] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 02:01:27] [valid] Ep. 5 : Up. 220000 : ce-mean-words : 1.24578 : new best
[2019-07-11 02:01:28] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 02:01:32] [valid] Ep. 5 : Up. 220000 : perplexity : 3.47565 : new best
[2019-07-11 02:02:10] [valid] Ep. 5 : Up. 220000 : translation : 39.84 : stalled 4 times (last best: 44.43)
[2019-07-11 02:04:23] Ep. 5 : Up. 220500 : Sen. 12,550,388 : Cost 2.49483633 : Time 207.69s : 21571.59 words/s : L.r. 8.0812e-05
[2019-07-11 02:06:32] Ep. 5 : Up. 221000 : Sen. 12,726,661 : Cost 2.48564458 : Time 129.17s : 33895.82 words/s : L.r. 8.0721e-05
[2019-07-11 02:08:41] Ep. 5 : Up. 221500 : Sen. 12,911,531 : Cost 2.50173306 : Time 128.77s : 33542.73 words/s : L.r. 8.0630e-05
[2019-07-11 02:10:50] Ep. 5 : Up. 222000 : Sen. 13,086,388 : Cost 2.48275447 : Time 129.88s : 34095.34 words/s : L.r. 8.0539e-05
[2019-07-11 02:13:00] Ep. 5 : Up. 222500 : Sen. 13,270,208 : Cost 2.48127651 : Time 129.72s : 33897.14 words/s : L.r. 8.0448e-05
[2019-07-11 02:15:10] Ep. 5 : Up. 223000 : Sen. 13,445,233 : Cost 2.48921442 : Time 129.63s : 33835.22 words/s : L.r. 8.0358e-05
[2019-07-11 02:17:19] Ep. 5 : Up. 223500 : Sen. 13,624,875 : Cost 2.50656343 : Time 129.68s : 34093.45 words/s : L.r. 8.0268e-05
[2019-07-11 02:19:29] Ep. 5 : Up. 224000 : Sen. 13,803,727 : Cost 2.45877671 : Time 129.50s : 33724.48 words/s : L.r. 8.0178e-05
[2019-07-11 02:21:39] Ep. 5 : Up. 224500 : Sen. 13,983,560 : Cost 2.46876693 : Time 130.09s : 33798.51 words/s : L.r. 8.0089e-05
[2019-07-11 02:23:48] Ep. 5 : Up. 225000 : Sen. 14,157,368 : Cost 2.48032880 : Time 129.38s : 33764.49 words/s : L.r. 8.0000e-05
[2019-07-11 02:23:48] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 02:23:55] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 02:24:02] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 02:24:16] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 02:24:21] [valid] Ep. 5 : Up. 225000 : ce-mean-words : 1.24407 : new best
[2019-07-11 02:24:21] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 02:24:26] [valid] Ep. 5 : Up. 225000 : perplexity : 3.46971 : new best
[2019-07-11 02:25:03] [valid] Ep. 5 : Up. 225000 : translation : 42.89 : stalled 5 times (last best: 44.43)
[2019-07-11 02:27:14] Ep. 5 : Up. 225500 : Sen. 14,332,780 : Cost 2.46488595 : Time 205.57s : 21616.35 words/s : L.r. 7.9911e-05
[2019-07-11 02:29:23] Ep. 5 : Up. 226000 : Sen. 14,515,199 : Cost 2.48165035 : Time 128.55s : 33702.98 words/s : L.r. 7.9823e-05
[2019-07-11 02:31:34] Ep. 5 : Up. 226500 : Sen. 14,692,327 : Cost 2.48341107 : Time 131.15s : 33838.24 words/s : L.r. 7.9735e-05
[2019-07-11 02:33:43] Ep. 5 : Up. 227000 : Sen. 14,875,594 : Cost 2.50336027 : Time 129.19s : 33795.23 words/s : L.r. 7.9647e-05
[2019-07-11 02:35:53] Ep. 5 : Up. 227500 : Sen. 15,057,835 : Cost 2.47010612 : Time 130.00s : 34196.34 words/s : L.r. 7.9559e-05
[2019-07-11 02:38:03] Ep. 5 : Up. 228000 : Sen. 15,235,212 : Cost 2.50763106 : Time 129.70s : 33722.82 words/s : L.r. 7.9472e-05
[2019-07-11 02:40:13] Ep. 5 : Up. 228500 : Sen. 15,415,577 : Cost 2.44449258 : Time 130.47s : 33715.33 words/s : L.r. 7.9385e-05
[2019-07-11 02:42:23] Ep. 5 : Up. 229000 : Sen. 15,593,170 : Cost 2.47466516 : Time 130.17s : 33990.53 words/s : L.r. 7.9298e-05
[2019-07-11 02:44:31] Ep. 5 : Up. 229500 : Sen. 15,769,683 : Cost 2.50731540 : Time 128.15s : 33736.40 words/s : L.r. 7.9212e-05
[2019-07-11 02:46:41] Ep. 5 : Up. 230000 : Sen. 15,949,583 : Cost 2.44348598 : Time 130.04s : 33849.72 words/s : L.r. 7.9126e-05
[2019-07-11 02:46:41] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 02:46:48] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 02:46:54] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 02:47:08] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 02:47:13] [valid] Ep. 5 : Up. 230000 : ce-mean-words : 1.24208 : new best
[2019-07-11 02:47:13] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 02:47:18] [valid] Ep. 5 : Up. 230000 : perplexity : 3.46279 : new best
[2019-07-11 02:47:55] [valid] Ep. 5 : Up. 230000 : translation : 41.53 : stalled 6 times (last best: 44.43)
[2019-07-11 02:50:06] Ep. 5 : Up. 230500 : Sen. 16,128,282 : Cost 2.46808004 : Time 204.48s : 21404.05 words/s : L.r. 7.9040e-05
[2019-07-11 02:52:16] Ep. 5 : Up. 231000 : Sen. 16,303,394 : Cost 2.47049880 : Time 129.80s : 33935.24 words/s : L.r. 7.8954e-05
[2019-07-11 02:54:25] Ep. 5 : Up. 231500 : Sen. 16,484,178 : Cost 2.50832772 : Time 129.41s : 33700.34 words/s : L.r. 7.8869e-05
[2019-07-11 02:55:13] Seen 16548172 samples
[2019-07-11 02:55:13] Starting epoch 6
[2019-07-11 02:55:13] [data] Shuffling data
[2019-07-11 02:55:28] [data] Done reading 19122526 sentences
[2019-07-11 02:57:36] [data] Done shuffling 19122526 sentences to temp files
[2019-07-11 02:59:46] Ep. 6 : Up. 232000 : Sen. 112,674 : Cost 2.46858215 : Time 320.70s : 13638.51 words/s : L.r. 7.8784e-05
[2019-07-11 03:01:55] Ep. 6 : Up. 232500 : Sen. 289,303 : Cost 2.48654985 : Time 129.53s : 34001.12 words/s : L.r. 7.8699e-05
[2019-07-11 03:04:04] Ep. 6 : Up. 233000 : Sen. 462,248 : Cost 2.49145794 : Time 128.85s : 33811.21 words/s : L.r. 7.8615e-05
[2019-07-11 03:06:13] Ep. 6 : Up. 233500 : Sen. 642,037 : Cost 2.48528790 : Time 129.13s : 33993.39 words/s : L.r. 7.8530e-05
[2019-07-11 03:08:24] Ep. 6 : Up. 234000 : Sen. 825,059 : Cost 2.42201447 : Time 130.42s : 33899.43 words/s : L.r. 7.8446e-05
[2019-07-11 03:10:33] Ep. 6 : Up. 234500 : Sen. 1,005,422 : Cost 2.44038725 : Time 129.64s : 33934.18 words/s : L.r. 7.8363e-05
[2019-07-11 03:12:43] Ep. 6 : Up. 235000 : Sen. 1,183,381 : Cost 2.47453260 : Time 129.76s : 33854.54 words/s : L.r. 7.8279e-05
[2019-07-11 03:12:43] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 03:12:51] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 03:12:58] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 03:13:12] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 03:13:17] [valid] Ep. 6 : Up. 235000 : ce-mean-words : 1.24127 : new best
[2019-07-11 03:13:18] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 03:13:23] [valid] Ep. 6 : Up. 235000 : perplexity : 3.45999 : new best
[2019-07-11 03:14:00] [valid] Ep. 6 : Up. 235000 : translation : 41.53 : stalled 7 times (last best: 44.43)
[2019-07-11 03:16:12] Ep. 6 : Up. 235500 : Sen. 1,365,022 : Cost 2.45667624 : Time 208.89s : 21145.65 words/s : L.r. 7.8196e-05
[2019-07-11 03:18:21] Ep. 6 : Up. 236000 : Sen. 1,544,690 : Cost 2.46292305 : Time 129.38s : 33829.32 words/s : L.r. 7.8113e-05
[2019-07-11 03:20:30] Ep. 6 : Up. 236500 : Sen. 1,720,199 : Cost 2.46029592 : Time 128.96s : 33701.47 words/s : L.r. 7.8031e-05
[2019-07-11 03:22:41] Ep. 6 : Up. 237000 : Sen. 1,898,215 : Cost 2.46573877 : Time 130.81s : 34059.19 words/s : L.r. 7.7948e-05
[2019-07-11 03:24:51] Ep. 6 : Up. 237500 : Sen. 2,080,828 : Cost 2.47996926 : Time 129.46s : 33657.33 words/s : L.r. 7.7866e-05
[2019-07-11 03:27:00] Ep. 6 : Up. 238000 : Sen. 2,262,784 : Cost 2.46377397 : Time 129.71s : 33677.26 words/s : L.r. 7.7784e-05
[2019-07-11 03:29:10] Ep. 6 : Up. 238500 : Sen. 2,440,854 : Cost 2.48494768 : Time 129.29s : 33903.72 words/s : L.r. 7.7703e-05
[2019-07-11 03:31:20] Ep. 6 : Up. 239000 : Sen. 2,619,629 : Cost 2.47809601 : Time 129.93s : 33917.99 words/s : L.r. 7.7622e-05
[2019-07-11 03:33:30] Ep. 6 : Up. 239500 : Sen. 2,799,800 : Cost 2.44788599 : Time 130.06s : 34031.76 words/s : L.r. 7.7540e-05
[2019-07-11 03:35:40] Ep. 6 : Up. 240000 : Sen. 2,971,432 : Cost 2.44342017 : Time 130.19s : 33723.57 words/s : L.r. 7.7460e-05
[2019-07-11 03:35:40] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 03:35:46] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 03:35:53] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 03:36:07] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 03:36:12] [valid] Ep. 6 : Up. 240000 : ce-mean-words : 1.23984 : new best
[2019-07-11 03:36:13] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 03:36:18] [valid] Ep. 6 : Up. 240000 : perplexity : 3.45504 : new best
[2019-07-11 03:36:57] [valid] Ep. 6 : Up. 240000 : translation : 41.71 : stalled 8 times (last best: 44.43)
[2019-07-11 03:39:07] Ep. 6 : Up. 240500 : Sen. 3,148,241 : Cost 2.47474074 : Time 207.07s : 21057.90 words/s : L.r. 7.7379e-05
[2019-07-11 03:41:17] Ep. 6 : Up. 241000 : Sen. 3,328,161 : Cost 2.44643211 : Time 129.92s : 33782.99 words/s : L.r. 7.7299e-05
[2019-07-11 03:43:27] Ep. 6 : Up. 241500 : Sen. 3,510,918 : Cost 2.45144033 : Time 130.53s : 34034.11 words/s : L.r. 7.7219e-05
[2019-07-11 03:45:36] Ep. 6 : Up. 242000 : Sen. 3,690,563 : Cost 2.47435188 : Time 128.32s : 33548.88 words/s : L.r. 7.7139e-05
[2019-07-11 03:47:45] Ep. 6 : Up. 242500 : Sen. 3,863,742 : Cost 2.49885154 : Time 129.69s : 33949.18 words/s : L.r. 7.7059e-05
[2019-07-11 03:49:57] Ep. 6 : Up. 243000 : Sen. 4,042,628 : Cost 2.45240855 : Time 131.27s : 34049.37 words/s : L.r. 7.6980e-05
[2019-07-11 03:52:07] Ep. 6 : Up. 243500 : Sen. 4,226,488 : Cost 2.48189259 : Time 130.52s : 34021.65 words/s : L.r. 7.6901e-05
[2019-07-11 03:54:16] Ep. 6 : Up. 244000 : Sen. 4,404,379 : Cost 2.47582221 : Time 129.02s : 33696.01 words/s : L.r. 7.6822e-05
[2019-07-11 03:56:25] Ep. 6 : Up. 244500 : Sen. 4,583,779 : Cost 2.47738671 : Time 128.56s : 33760.07 words/s : L.r. 7.6744e-05
[2019-07-11 03:58:35] Ep. 6 : Up. 245000 : Sen. 4,757,508 : Cost 2.46690202 : Time 130.55s : 34193.36 words/s : L.r. 7.6665e-05
[2019-07-11 03:58:35] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 03:58:42] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 03:58:49] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 03:59:03] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 03:59:08] [valid] Ep. 6 : Up. 245000 : ce-mean-words : 1.23856 : new best
[2019-07-11 03:59:09] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 03:59:14] [valid] Ep. 6 : Up. 245000 : perplexity : 3.45065 : new best
[2019-07-11 03:59:50] [valid] Ep. 6 : Up. 245000 : translation : 41.27 : stalled 9 times (last best: 44.43)
[2019-07-11 04:02:01] Ep. 6 : Up. 245500 : Sen. 4,936,547 : Cost 2.46131349 : Time 205.77s : 21194.65 words/s : L.r. 7.6587e-05
[2019-07-11 04:04:11] Ep. 6 : Up. 246000 : Sen. 5,116,890 : Cost 2.45531106 : Time 129.90s : 33969.57 words/s : L.r. 7.6509e-05
[2019-07-11 04:06:21] Ep. 6 : Up. 246500 : Sen. 5,292,012 : Cost 2.43308759 : Time 130.22s : 33827.77 words/s : L.r. 7.6432e-05
[2019-07-11 04:08:31] Ep. 6 : Up. 247000 : Sen. 5,464,815 : Cost 2.47986674 : Time 129.98s : 33911.48 words/s : L.r. 7.6354e-05
[2019-07-11 04:10:41] Ep. 6 : Up. 247500 : Sen. 5,640,876 : Cost 2.47878313 : Time 130.13s : 33814.63 words/s : L.r. 7.6277e-05
[2019-07-11 04:12:50] Ep. 6 : Up. 248000 : Sen. 5,822,941 : Cost 2.46853852 : Time 128.79s : 33518.74 words/s : L.r. 7.6200e-05
[2019-07-11 04:15:00] Ep. 6 : Up. 248500 : Sen. 6,005,444 : Cost 2.49068260 : Time 130.22s : 34000.25 words/s : L.r. 7.6123e-05
[2019-07-11 04:17:10] Ep. 6 : Up. 249000 : Sen. 6,178,730 : Cost 2.47613811 : Time 129.89s : 33962.97 words/s : L.r. 7.6047e-05
[2019-07-11 04:19:20] Ep. 6 : Up. 249500 : Sen. 6,355,219 : Cost 2.44093204 : Time 129.71s : 33837.83 words/s : L.r. 7.5971e-05
[2019-07-11 04:21:29] Ep. 6 : Up. 250000 : Sen. 6,539,149 : Cost 2.40459085 : Time 129.38s : 33833.97 words/s : L.r. 7.5895e-05
[2019-07-11 04:21:29] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 04:21:36] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 04:21:44] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 04:21:59] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 04:22:04] [valid] Ep. 6 : Up. 250000 : ce-mean-words : 1.23686 : new best
[2019-07-11 04:22:05] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 04:22:10] [valid] Ep. 6 : Up. 250000 : perplexity : 3.44478 : new best
[2019-07-11 04:22:49] [valid] Ep. 6 : Up. 250000 : translation : 41.12 : stalled 10 times (last best: 44.43)
[2019-07-11 04:25:01] Ep. 6 : Up. 250500 : Sen. 6,722,279 : Cost 2.45999026 : Time 211.93s : 20954.26 words/s : L.r. 7.5819e-05
[2019-07-11 04:27:10] Ep. 6 : Up. 251000 : Sen. 6,898,430 : Cost 2.51368308 : Time 128.80s : 33666.47 words/s : L.r. 7.5743e-05
[2019-07-11 04:29:21] Ep. 6 : Up. 251500 : Sen. 7,074,889 : Cost 2.51768184 : Time 131.16s : 33970.04 words/s : L.r. 7.5668e-05
[2019-07-11 04:31:30] Ep. 6 : Up. 252000 : Sen. 7,256,151 : Cost 2.45156097 : Time 128.89s : 33757.31 words/s : L.r. 7.5593e-05
[2019-07-11 04:33:39] Ep. 6 : Up. 252500 : Sen. 7,430,070 : Cost 2.49632764 : Time 129.04s : 33624.52 words/s : L.r. 7.5518e-05
[2019-07-11 04:35:49] Ep. 6 : Up. 253000 : Sen. 7,610,813 : Cost 2.48934007 : Time 129.83s : 34094.86 words/s : L.r. 7.5443e-05
[2019-07-11 04:37:58] Ep. 6 : Up. 253500 : Sen. 7,788,130 : Cost 2.45854473 : Time 129.53s : 33757.39 words/s : L.r. 7.5369e-05
[2019-07-11 04:40:09] Ep. 6 : Up. 254000 : Sen. 7,969,278 : Cost 2.41753960 : Time 130.90s : 33851.22 words/s : L.r. 7.5295e-05
[2019-07-11 04:42:18] Ep. 6 : Up. 254500 : Sen. 8,149,139 : Cost 2.47257137 : Time 128.69s : 33692.34 words/s : L.r. 7.5221e-05
[2019-07-11 04:44:28] Ep. 6 : Up. 255000 : Sen. 8,328,653 : Cost 2.45480442 : Time 129.97s : 33977.31 words/s : L.r. 7.5147e-05
[2019-07-11 04:44:28] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 04:44:35] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 04:44:42] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 04:44:57] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 04:45:02] [valid] Ep. 6 : Up. 255000 : ce-mean-words : 1.23455 : new best
[2019-07-11 04:45:03] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 04:45:08] [valid] Ep. 6 : Up. 255000 : perplexity : 3.43682 : new best
[2019-07-11 04:45:47] [valid] Ep. 6 : Up. 255000 : translation : 40.15 : stalled 11 times (last best: 44.43)
[2019-07-11 04:48:00] Ep. 6 : Up. 255500 : Sen. 8,505,242 : Cost 2.47368813 : Time 211.87s : 21124.32 words/s : L.r. 7.5073e-05
[2019-07-11 04:50:09] Ep. 6 : Up. 256000 : Sen. 8,685,377 : Cost 2.48782969 : Time 129.09s : 33699.33 words/s : L.r. 7.5000e-05
[2019-07-11 04:52:18] Ep. 6 : Up. 256500 : Sen. 8,865,805 : Cost 2.47565603 : Time 129.44s : 33817.03 words/s : L.r. 7.4927e-05
[2019-07-11 04:54:28] Ep. 6 : Up. 257000 : Sen. 9,039,938 : Cost 2.45137072 : Time 130.03s : 33854.43 words/s : L.r. 7.4854e-05
[2019-07-11 04:56:38] Ep. 6 : Up. 257500 : Sen. 9,223,146 : Cost 2.48222327 : Time 129.65s : 33749.22 words/s : L.r. 7.4781e-05
[2019-07-11 04:58:48] Ep. 6 : Up. 258000 : Sen. 9,397,467 : Cost 2.43533659 : Time 129.89s : 33761.23 words/s : L.r. 7.4709e-05
[2019-07-11 05:00:57] Ep. 6 : Up. 258500 : Sen. 9,573,468 : Cost 2.42501283 : Time 129.41s : 33861.30 words/s : L.r. 7.4636e-05
[2019-07-11 05:03:07] Ep. 6 : Up. 259000 : Sen. 9,751,490 : Cost 2.48702264 : Time 129.68s : 34137.21 words/s : L.r. 7.4564e-05
[2019-07-11 05:05:16] Ep. 6 : Up. 259500 : Sen. 9,934,382 : Cost 2.47795343 : Time 129.05s : 33920.43 words/s : L.r. 7.4493e-05
[2019-07-11 05:07:26] Ep. 6 : Up. 260000 : Sen. 10,119,629 : Cost 2.47619629 : Time 129.41s : 33915.23 words/s : L.r. 7.4421e-05
[2019-07-11 05:07:26] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 05:07:33] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 05:07:41] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 05:07:57] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 05:08:02] [valid] Ep. 6 : Up. 260000 : ce-mean-words : 1.23329 : new best
[2019-07-11 05:08:03] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 05:08:09] [valid] Ep. 6 : Up. 260000 : perplexity : 3.4325 : new best
[2019-07-11 05:08:50] [valid] Ep. 6 : Up. 260000 : translation : 39.79 : stalled 12 times (last best: 44.43)
[2019-07-11 05:11:02] Ep. 6 : Up. 260500 : Sen. 10,292,083 : Cost 2.46027684 : Time 216.39s : 20451.84 words/s : L.r. 7.4349e-05
[2019-07-11 05:13:11] Ep. 6 : Up. 261000 : Sen. 10,466,685 : Cost 2.44381356 : Time 129.31s : 33901.74 words/s : L.r. 7.4278e-05
[2019-07-11 05:15:21] Ep. 6 : Up. 261500 : Sen. 10,645,607 : Cost 2.45240831 : Time 129.72s : 33857.72 words/s : L.r. 7.4207e-05
[2019-07-11 05:17:31] Ep. 6 : Up. 262000 : Sen. 10,827,225 : Cost 2.45580363 : Time 130.40s : 33749.93 words/s : L.r. 7.4136e-05
[2019-07-11 05:19:41] Ep. 6 : Up. 262500 : Sen. 11,006,090 : Cost 2.52063227 : Time 129.45s : 33871.84 words/s : L.r. 7.4066e-05
[2019-07-11 05:21:51] Ep. 6 : Up. 263000 : Sen. 11,182,825 : Cost 2.44544697 : Time 129.98s : 33870.73 words/s : L.r. 7.3995e-05
[2019-07-11 05:24:02] Ep. 6 : Up. 263500 : Sen. 11,366,393 : Cost 2.44374943 : Time 130.83s : 33891.42 words/s : L.r. 7.3925e-05
[2019-07-11 05:26:11] Ep. 6 : Up. 264000 : Sen. 11,547,210 : Cost 2.48125148 : Time 129.28s : 33869.39 words/s : L.r. 7.3855e-05
[2019-07-11 05:28:21] Ep. 6 : Up. 264500 : Sen. 11,724,116 : Cost 2.51394916 : Time 130.26s : 33825.33 words/s : L.r. 7.3785e-05
[2019-07-11 05:30:31] Ep. 6 : Up. 265000 : Sen. 11,899,626 : Cost 2.44168639 : Time 129.34s : 33877.44 words/s : L.r. 7.3715e-05
[2019-07-11 05:30:31] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 05:30:38] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 05:30:46] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 05:31:01] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 05:31:06] [valid] Ep. 6 : Up. 265000 : ce-mean-words : 1.23165 : new best
[2019-07-11 05:31:07] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 05:31:12] [valid] Ep. 6 : Up. 265000 : perplexity : 3.42688 : new best
[2019-07-11 05:31:52] [valid] Ep. 6 : Up. 265000 : translation : 38.43 : stalled 13 times (last best: 44.43)
[2019-07-11 05:34:02] Ep. 6 : Up. 265500 : Sen. 12,075,645 : Cost 2.49976826 : Time 211.91s : 20405.69 words/s : L.r. 7.3646e-05
[2019-07-11 05:36:13] Ep. 6 : Up. 266000 : Sen. 12,260,839 : Cost 2.41512275 : Time 130.10s : 33852.38 words/s : L.r. 7.3577e-05
[2019-07-11 05:38:22] Ep. 6 : Up. 266500 : Sen. 12,432,472 : Cost 2.47179484 : Time 129.92s : 33959.61 words/s : L.r. 7.3508e-05
[2019-07-11 05:40:32] Ep. 6 : Up. 267000 : Sen. 12,605,423 : Cost 2.48847866 : Time 129.68s : 33894.25 words/s : L.r. 7.3439e-05
[2019-07-11 05:42:42] Ep. 6 : Up. 267500 : Sen. 12,783,760 : Cost 2.48469901 : Time 129.41s : 33925.67 words/s : L.r. 7.3370e-05
[2019-07-11 05:44:51] Ep. 6 : Up. 268000 : Sen. 12,964,658 : Cost 2.44576764 : Time 129.73s : 34043.38 words/s : L.r. 7.3302e-05
[2019-07-11 05:47:01] Ep. 6 : Up. 268500 : Sen. 13,151,398 : Cost 2.44801712 : Time 129.80s : 33795.43 words/s : L.r. 7.3233e-05
[2019-07-11 05:49:11] Ep. 6 : Up. 269000 : Sen. 13,330,889 : Cost 2.45937848 : Time 130.13s : 33964.48 words/s : L.r. 7.3165e-05
[2019-07-11 05:51:21] Ep. 6 : Up. 269500 : Sen. 13,504,307 : Cost 2.51212549 : Time 129.60s : 33981.44 words/s : L.r. 7.3097e-05
[2019-07-11 05:53:30] Ep. 6 : Up. 270000 : Sen. 13,684,262 : Cost 2.43725824 : Time 129.59s : 33754.82 words/s : L.r. 7.3030e-05
[2019-07-11 05:53:30] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 05:53:37] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 05:53:44] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 05:53:59] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 05:54:04] [valid] Ep. 6 : Up. 270000 : ce-mean-words : 1.23071 : new best
[2019-07-11 05:54:04] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 05:54:09] [valid] Ep. 6 : Up. 270000 : perplexity : 3.42367 : new best
[2019-07-11 05:54:48] [valid] Ep. 6 : Up. 270000 : translation : 41.1 : stalled 14 times (last best: 44.43)
[2019-07-11 05:56:59] Ep. 6 : Up. 270500 : Sen. 13,861,132 : Cost 2.48498321 : Time 208.88s : 21045.00 words/s : L.r. 7.2962e-05
[2019-07-11 05:59:08] Ep. 6 : Up. 271000 : Sen. 14,044,378 : Cost 2.46350622 : Time 129.10s : 33789.66 words/s : L.r. 7.2895e-05
[2019-07-11 06:01:19] Ep. 6 : Up. 271500 : Sen. 14,225,967 : Cost 2.46541977 : Time 130.39s : 33804.04 words/s : L.r. 7.2828e-05
[2019-07-11 06:03:28] Ep. 6 : Up. 272000 : Sen. 14,400,006 : Cost 2.47338700 : Time 129.69s : 33950.66 words/s : L.r. 7.2761e-05
[2019-07-11 06:05:38] Ep. 6 : Up. 272500 : Sen. 14,582,295 : Cost 2.44285369 : Time 129.67s : 34072.07 words/s : L.r. 7.2694e-05
[2019-07-11 06:07:48] Ep. 6 : Up. 273000 : Sen. 14,767,069 : Cost 2.44144702 : Time 130.21s : 33782.48 words/s : L.r. 7.2627e-05
[2019-07-11 06:09:57] Ep. 6 : Up. 273500 : Sen. 14,938,622 : Cost 2.48810124 : Time 129.10s : 33940.87 words/s : L.r. 7.2561e-05
[2019-07-11 06:12:06] Ep. 6 : Up. 274000 : Sen. 15,114,334 : Cost 2.52667785 : Time 129.01s : 33555.10 words/s : L.r. 7.2495e-05
[2019-07-11 06:14:17] Ep. 6 : Up. 274500 : Sen. 15,292,465 : Cost 2.43422151 : Time 130.52s : 34011.47 words/s : L.r. 7.2429e-05
[2019-07-11 06:16:26] Ep. 6 : Up. 275000 : Sen. 15,476,568 : Cost 2.44422722 : Time 129.33s : 33912.81 words/s : L.r. 7.2363e-05
[2019-07-11 06:16:26] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 06:16:34] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 06:16:42] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 06:16:57] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 06:17:02] [valid] Ep. 6 : Up. 275000 : ce-mean-words : 1.23044 : new best
[2019-07-11 06:17:03] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 06:17:08] [valid] Ep. 6 : Up. 275000 : perplexity : 3.42275 : new best
[2019-07-11 06:17:46] [valid] Ep. 6 : Up. 275000 : translation : 42.24 : stalled 15 times (last best: 44.43)
[2019-07-11 06:19:58] Ep. 6 : Up. 275500 : Sen. 15,652,646 : Cost 2.45538473 : Time 211.34s : 20759.65 words/s : L.r. 7.2297e-05
[2019-07-11 06:22:06] Ep. 6 : Up. 276000 : Sen. 15,831,449 : Cost 2.46333480 : Time 128.76s : 33733.96 words/s : L.r. 7.2232e-05
[2019-07-11 06:24:17] Ep. 6 : Up. 276500 : Sen. 16,006,880 : Cost 2.48173594 : Time 130.28s : 34162.25 words/s : L.r. 7.2166e-05
[2019-07-11 06:26:27] Ep. 6 : Up. 277000 : Sen. 16,187,177 : Cost 2.44543529 : Time 130.50s : 33858.83 words/s : L.r. 7.2101e-05
[2019-07-11 06:28:35] Ep. 6 : Up. 277500 : Sen. 16,365,276 : Cost 2.49278617 : Time 127.82s : 33542.00 words/s : L.r. 7.2036e-05
[2019-07-11 06:30:45] Ep. 6 : Up. 278000 : Sen. 16,540,550 : Cost 2.44531035 : Time 130.06s : 33799.59 words/s : L.r. 7.1971e-05
[2019-07-11 06:30:51] Seen 16548172 samples
[2019-07-11 06:30:51] Starting epoch 7
[2019-07-11 06:30:51] [data] Shuffling data
[2019-07-11 06:31:05] [data] Done reading 19122526 sentences
[2019-07-11 06:32:59] [data] Done shuffling 19122526 sentences to temp files
[2019-07-11 06:35:44] Ep. 7 : Up. 278500 : Sen. 170,812 : Cost 2.46043396 : Time 298.53s : 14835.13 words/s : L.r. 7.1907e-05
[2019-07-11 06:37:52] Ep. 7 : Up. 279000 : Sen. 344,105 : Cost 2.49889588 : Time 128.52s : 33911.32 words/s : L.r. 7.1842e-05
[2019-07-11 06:40:02] Ep. 7 : Up. 279500 : Sen. 527,508 : Cost 2.45023727 : Time 130.16s : 33996.33 words/s : L.r. 7.1778e-05
[2019-07-11 06:42:11] Ep. 7 : Up. 280000 : Sen. 703,001 : Cost 2.43847489 : Time 129.13s : 33730.39 words/s : L.r. 7.1714e-05
[2019-07-11 06:42:11] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 06:42:19] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 06:42:26] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 06:42:40] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 06:42:46] [valid] Ep. 7 : Up. 280000 : ce-mean-words : 1.23022 : new best
[2019-07-11 06:42:46] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 06:42:55] [valid] Ep. 7 : Up. 280000 : perplexity : 3.42198 : new best
[2019-07-11 06:43:34] [valid] Ep. 7 : Up. 280000 : translation : 41.45 : stalled 16 times (last best: 44.43)
[2019-07-11 06:45:47] Ep. 7 : Up. 280500 : Sen. 883,737 : Cost 2.46671820 : Time 215.35s : 20616.72 words/s : L.r. 7.1650e-05
[2019-07-11 06:47:56] Ep. 7 : Up. 281000 : Sen. 1,061,460 : Cost 2.38949418 : Time 129.46s : 33791.29 words/s : L.r. 7.1586e-05
[2019-07-11 06:50:05] Ep. 7 : Up. 281500 : Sen. 1,234,370 : Cost 2.44722915 : Time 129.06s : 33599.65 words/s : L.r. 7.1522e-05
[2019-07-11 06:52:15] Ep. 7 : Up. 282000 : Sen. 1,414,325 : Cost 2.48323274 : Time 129.50s : 33760.47 words/s : L.r. 7.1459e-05
[2019-07-11 06:54:25] Ep. 7 : Up. 282500 : Sen. 1,589,185 : Cost 2.44827580 : Time 130.07s : 33812.63 words/s : L.r. 7.1396e-05
[2019-07-11 06:56:35] Ep. 7 : Up. 283000 : Sen. 1,769,983 : Cost 2.44915390 : Time 129.73s : 33898.11 words/s : L.r. 7.1333e-05
[2019-07-11 06:58:45] Ep. 7 : Up. 283500 : Sen. 1,952,380 : Cost 2.44999528 : Time 129.96s : 34120.54 words/s : L.r. 7.1270e-05
[2019-07-11 07:00:54] Ep. 7 : Up. 284000 : Sen. 2,128,087 : Cost 2.45204663 : Time 129.39s : 33580.74 words/s : L.r. 7.1207e-05
[2019-07-11 07:03:04] Ep. 7 : Up. 284500 : Sen. 2,303,598 : Cost 2.44579887 : Time 130.37s : 33967.27 words/s : L.r. 7.1144e-05
[2019-07-11 07:05:13] Ep. 7 : Up. 285000 : Sen. 2,487,604 : Cost 2.46117473 : Time 128.30s : 33816.33 words/s : L.r. 7.1082e-05
[2019-07-11 07:05:13] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 07:05:21] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 07:05:29] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 07:05:44] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 07:05:51] [valid] Ep. 7 : Up. 285000 : ce-mean-words : 1.22979 : new best
[2019-07-11 07:05:52] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 07:05:57] [valid] Ep. 7 : Up. 285000 : perplexity : 3.42051 : new best
[2019-07-11 07:06:38] [valid] Ep. 7 : Up. 285000 : translation : 39.1 : stalled 17 times (last best: 44.43)
[2019-07-11 07:08:50] Ep. 7 : Up. 285500 : Sen. 2,665,733 : Cost 2.45388818 : Time 217.59s : 20415.44 words/s : L.r. 7.1020e-05
[2019-07-11 07:10:59] Ep. 7 : Up. 286000 : Sen. 2,843,558 : Cost 2.47741485 : Time 128.88s : 34082.88 words/s : L.r. 7.0957e-05
[2019-07-11 07:13:09] Ep. 7 : Up. 286500 : Sen. 3,026,956 : Cost 2.42204690 : Time 130.03s : 33936.87 words/s : L.r. 7.0896e-05
[2019-07-11 07:15:19] Ep. 7 : Up. 287000 : Sen. 3,203,523 : Cost 2.50636339 : Time 129.52s : 33811.49 words/s : L.r. 7.0834e-05
[2019-07-11 07:17:28] Ep. 7 : Up. 287500 : Sen. 3,390,581 : Cost 2.43964481 : Time 129.39s : 33756.80 words/s : L.r. 7.0772e-05
[2019-07-11 07:19:37] Ep. 7 : Up. 288000 : Sen. 3,564,967 : Cost 2.47139955 : Time 129.31s : 34151.29 words/s : L.r. 7.0711e-05
[2019-07-11 07:21:47] Ep. 7 : Up. 288500 : Sen. 3,741,691 : Cost 2.44951916 : Time 129.76s : 33816.96 words/s : L.r. 7.0649e-05
[2019-07-11 07:23:57] Ep. 7 : Up. 289000 : Sen. 3,922,972 : Cost 2.44707656 : Time 130.26s : 33922.55 words/s : L.r. 7.0588e-05
[2019-07-11 07:26:07] Ep. 7 : Up. 289500 : Sen. 4,094,212 : Cost 2.41348314 : Time 129.99s : 33792.37 words/s : L.r. 7.0527e-05
[2019-07-11 07:28:18] Ep. 7 : Up. 290000 : Sen. 4,277,960 : Cost 2.45664835 : Time 130.60s : 33498.14 words/s : L.r. 7.0466e-05
[2019-07-11 07:28:18] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 07:28:26] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 07:28:33] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 07:28:46] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 07:28:51] [valid] Ep. 7 : Up. 290000 : ce-mean-words : 1.22917 : new best
[2019-07-11 07:28:52] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 07:28:57] [valid] Ep. 7 : Up. 290000 : perplexity : 3.41839 : new best
[2019-07-11 07:29:35] [valid] Ep. 7 : Up. 290000 : translation : 42.11 : stalled 18 times (last best: 44.43)
[2019-07-11 07:31:48] Ep. 7 : Up. 290500 : Sen. 4,460,113 : Cost 2.47820735 : Time 209.62s : 21193.10 words/s : L.r. 7.0406e-05
[2019-07-11 07:33:58] Ep. 7 : Up. 291000 : Sen. 4,635,681 : Cost 2.46564174 : Time 130.28s : 34009.89 words/s : L.r. 7.0345e-05
[2019-07-11 07:36:07] Ep. 7 : Up. 291500 : Sen. 4,814,130 : Cost 2.44555759 : Time 129.03s : 33844.57 words/s : L.r. 7.0285e-05
[2019-07-11 07:38:16] Ep. 7 : Up. 292000 : Sen. 4,991,764 : Cost 2.45023322 : Time 128.84s : 33929.96 words/s : L.r. 7.0225e-05
[2019-07-11 07:40:25] Ep. 7 : Up. 292500 : Sen. 5,164,705 : Cost 2.46974349 : Time 128.97s : 34012.78 words/s : L.r. 7.0165e-05
[2019-07-11 07:42:35] Ep. 7 : Up. 293000 : Sen. 5,341,849 : Cost 2.45088720 : Time 129.86s : 33968.43 words/s : L.r. 7.0105e-05
[2019-07-11 07:44:45] Ep. 7 : Up. 293500 : Sen. 5,526,260 : Cost 2.44481611 : Time 130.11s : 33954.44 words/s : L.r. 7.0045e-05
[2019-07-11 07:46:55] Ep. 7 : Up. 294000 : Sen. 5,703,744 : Cost 2.43559313 : Time 130.14s : 33838.28 words/s : L.r. 6.9985e-05
[2019-07-11 07:49:04] Ep. 7 : Up. 294500 : Sen. 5,880,433 : Cost 2.47341514 : Time 128.99s : 33861.51 words/s : L.r. 6.9926e-05
[2019-07-11 07:51:14] Ep. 7 : Up. 295000 : Sen. 6,059,772 : Cost 2.44852304 : Time 129.74s : 33838.98 words/s : L.r. 6.9867e-05
[2019-07-11 07:51:14] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 07:51:20] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 07:51:27] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 07:51:41] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 07:51:46] [valid] Ep. 7 : Up. 295000 : ce-mean-words : 1.22814 : new best
[2019-07-11 07:51:46] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 07:51:51] [valid] Ep. 7 : Up. 295000 : perplexity : 3.41486 : new best
[2019-07-11 07:52:29] [valid] Ep. 7 : Up. 295000 : translation : 39.52 : stalled 19 times (last best: 44.43)
[2019-07-11 07:54:42] Ep. 7 : Up. 295500 : Sen. 6,233,784 : Cost 2.46460915 : Time 208.18s : 21341.98 words/s : L.r. 6.9808e-05
[2019-07-11 07:56:51] Ep. 7 : Up. 296000 : Sen. 6,413,179 : Cost 2.44278598 : Time 128.83s : 33798.62 words/s : L.r. 6.9749e-05
[2019-07-11 07:59:00] Ep. 7 : Up. 296500 : Sen. 6,597,076 : Cost 2.41786599 : Time 129.41s : 33818.30 words/s : L.r. 6.9690e-05
[2019-07-11 08:01:09] Ep. 7 : Up. 297000 : Sen. 6,776,760 : Cost 2.45511508 : Time 128.85s : 33794.94 words/s : L.r. 6.9631e-05
[2019-07-11 08:03:19] Ep. 7 : Up. 297500 : Sen. 6,954,029 : Cost 2.46036625 : Time 129.76s : 34046.78 words/s : L.r. 6.9573e-05
[2019-07-11 08:05:28] Ep. 7 : Up. 298000 : Sen. 7,129,695 : Cost 2.51455927 : Time 129.32s : 34023.16 words/s : L.r. 6.9514e-05
[2019-07-11 08:07:38] Ep. 7 : Up. 298500 : Sen. 7,308,002 : Cost 2.44476986 : Time 129.62s : 33901.79 words/s : L.r. 6.9456e-05
[2019-07-11 08:09:48] Ep. 7 : Up. 299000 : Sen. 7,483,656 : Cost 2.43432117 : Time 130.09s : 33712.86 words/s : L.r. 6.9398e-05
[2019-07-11 08:11:57] Ep. 7 : Up. 299500 : Sen. 7,670,789 : Cost 2.44494247 : Time 129.69s : 33843.10 words/s : L.r. 6.9340e-05
[2019-07-11 08:14:07] Ep. 7 : Up. 300000 : Sen. 7,847,077 : Cost 2.46729541 : Time 129.31s : 33803.24 words/s : L.r. 6.9282e-05
[2019-07-11 08:14:07] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 08:14:18] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 08:14:25] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 08:14:39] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 08:14:44] [valid] Ep. 7 : Up. 300000 : ce-mean-words : 1.22686 : new best
[2019-07-11 08:14:44] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 08:14:49] [valid] Ep. 7 : Up. 300000 : perplexity : 3.41052 : new best
[2019-07-11 08:15:28] [valid] Ep. 7 : Up. 300000 : translation : 39.52 : stalled 20 times (last best: 44.43)
[2019-07-11 08:17:40] Ep. 7 : Up. 300500 : Sen. 8,026,919 : Cost 2.45679379 : Time 213.02s : 20665.45 words/s : L.r. 6.9224e-05
[2019-07-11 08:19:50] Ep. 7 : Up. 301000 : Sen. 8,205,196 : Cost 2.48139119 : Time 130.66s : 34068.45 words/s : L.r. 6.9167e-05
[2019-07-11 08:22:00] Ep. 7 : Up. 301500 : Sen. 8,378,857 : Cost 2.43499398 : Time 129.63s : 33789.85 words/s : L.r. 6.9109e-05
[2019-07-11 08:24:09] Ep. 7 : Up. 302000 : Sen. 8,556,187 : Cost 2.48933363 : Time 129.05s : 33673.76 words/s : L.r. 6.9052e-05
[2019-07-11 08:26:19] Ep. 7 : Up. 302500 : Sen. 8,738,824 : Cost 2.44584084 : Time 129.82s : 34021.00 words/s : L.r. 6.8995e-05
[2019-07-11 08:28:28] Ep. 7 : Up. 303000 : Sen. 8,921,059 : Cost 2.41926718 : Time 128.90s : 33905.72 words/s : L.r. 6.8938e-05
[2019-07-11 08:30:38] Ep. 7 : Up. 303500 : Sen. 9,091,495 : Cost 2.49715972 : Time 130.73s : 34044.03 words/s : L.r. 6.8881e-05
[2019-07-11 08:32:47] Ep. 7 : Up. 304000 : Sen. 9,270,363 : Cost 2.46790838 : Time 128.88s : 33681.48 words/s : L.r. 6.8825e-05
[2019-07-11 08:34:57] Ep. 7 : Up. 304500 : Sen. 9,455,642 : Cost 2.46614623 : Time 129.71s : 33844.76 words/s : L.r. 6.8768e-05
[2019-07-11 08:37:06] Ep. 7 : Up. 305000 : Sen. 9,631,250 : Cost 2.46391845 : Time 129.35s : 33995.25 words/s : L.r. 6.8712e-05
[2019-07-11 08:37:06] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 08:37:15] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 08:37:25] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 08:37:44] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 08:37:49] [valid] Ep. 7 : Up. 305000 : ce-mean-words : 1.22607 : new best
[2019-07-11 08:37:50] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 08:37:55] [valid] Ep. 7 : Up. 305000 : perplexity : 3.40781 : new best
[2019-07-11 08:38:35] [valid] Ep. 7 : Up. 305000 : translation : 40.12 : stalled 21 times (last best: 44.43)
[2019-07-11 08:40:47] Ep. 7 : Up. 305500 : Sen. 9,809,357 : Cost 2.42069244 : Time 220.90s : 20017.77 words/s : L.r. 6.8656e-05
[2019-07-11 08:42:57] Ep. 7 : Up. 306000 : Sen. 9,991,096 : Cost 2.42834449 : Time 129.44s : 33933.92 words/s : L.r. 6.8599e-05
[2019-07-11 08:45:06] Ep. 7 : Up. 306500 : Sen. 10,168,527 : Cost 2.46194386 : Time 129.62s : 33818.69 words/s : L.r. 6.8543e-05
[2019-07-11 08:47:16] Ep. 7 : Up. 307000 : Sen. 10,347,070 : Cost 2.45666218 : Time 129.47s : 33786.11 words/s : L.r. 6.8488e-05
[2019-07-11 08:49:26] Ep. 7 : Up. 307500 : Sen. 10,532,310 : Cost 2.45125198 : Time 130.47s : 33780.73 words/s : L.r. 6.8432e-05
[2019-07-11 08:51:36] Ep. 7 : Up. 308000 : Sen. 10,707,731 : Cost 2.44003105 : Time 130.04s : 33844.99 words/s : L.r. 6.8376e-05
[2019-07-11 08:53:46] Ep. 7 : Up. 308500 : Sen. 10,884,003 : Cost 2.46166635 : Time 129.81s : 34072.55 words/s : L.r. 6.8321e-05
[2019-07-11 08:55:56] Ep. 7 : Up. 309000 : Sen. 11,066,122 : Cost 2.46924400 : Time 129.37s : 33928.53 words/s : L.r. 6.8266e-05
[2019-07-11 08:58:06] Ep. 7 : Up. 309500 : Sen. 11,245,625 : Cost 2.44318509 : Time 130.36s : 33998.62 words/s : L.r. 6.8210e-05
[2019-07-11 09:00:15] Ep. 7 : Up. 310000 : Sen. 11,422,513 : Cost 2.42823052 : Time 129.26s : 33833.24 words/s : L.r. 6.8155e-05
[2019-07-11 09:00:15] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 09:00:21] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 09:00:28] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 09:00:42] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 09:00:47] [valid] Ep. 7 : Up. 310000 : ce-mean-words : 1.22551 : new best
[2019-07-11 09:00:48] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 09:00:53] [valid] Ep. 7 : Up. 310000 : perplexity : 3.40591 : new best
[2019-07-11 09:01:34] [valid] Ep. 7 : Up. 310000 : translation : 39.52 : stalled 22 times (last best: 44.43)
[2019-07-11 09:03:44] Ep. 7 : Up. 310500 : Sen. 11,597,027 : Cost 2.48936844 : Time 209.02s : 20854.46 words/s : L.r. 6.8101e-05
[2019-07-11 09:05:55] Ep. 7 : Up. 311000 : Sen. 11,772,602 : Cost 2.44088936 : Time 130.50s : 33893.22 words/s : L.r. 6.8046e-05
[2019-07-11 09:08:04] Ep. 7 : Up. 311500 : Sen. 11,956,907 : Cost 2.45231843 : Time 129.58s : 33620.24 words/s : L.r. 6.7991e-05
[2019-07-11 09:10:14] Ep. 7 : Up. 312000 : Sen. 12,140,124 : Cost 2.46852779 : Time 130.14s : 33674.49 words/s : L.r. 6.7937e-05
[2019-07-11 09:12:24] Ep. 7 : Up. 312500 : Sen. 12,319,220 : Cost 2.42696142 : Time 129.60s : 33531.35 words/s : L.r. 6.7882e-05
[2019-07-11 09:14:35] Ep. 7 : Up. 313000 : Sen. 12,497,005 : Cost 2.42075181 : Time 131.19s : 33616.28 words/s : L.r. 6.7828e-05
[2019-07-11 09:16:46] Ep. 7 : Up. 313500 : Sen. 12,677,055 : Cost 2.47420382 : Time 131.05s : 33622.18 words/s : L.r. 6.7774e-05
[2019-07-11 09:19:00] Ep. 7 : Up. 314000 : Sen. 12,853,632 : Cost 2.45720768 : Time 133.39s : 32904.51 words/s : L.r. 6.7720e-05
[2019-07-11 09:21:14] Ep. 7 : Up. 314500 : Sen. 13,028,254 : Cost 2.46183467 : Time 133.93s : 33173.07 words/s : L.r. 6.7666e-05
[2019-07-11 09:23:23] Ep. 7 : Up. 315000 : Sen. 13,205,173 : Cost 2.48243690 : Time 129.62s : 33863.03 words/s : L.r. 6.7612e-05
[2019-07-11 09:23:23] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 09:23:30] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 09:23:36] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 09:23:49] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 09:23:54] [valid] Ep. 7 : Up. 315000 : ce-mean-words : 1.22466 : new best
[2019-07-11 09:23:55] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 09:24:00] [valid] Ep. 7 : Up. 315000 : perplexity : 3.403 : new best
[2019-07-11 09:24:37] [valid] Ep. 7 : Up. 315000 : translation : 38.79 : stalled 23 times (last best: 44.43)
[2019-07-11 09:26:50] Ep. 7 : Up. 315500 : Sen. 13,378,940 : Cost 2.46297336 : Time 206.62s : 21234.46 words/s : L.r. 6.7559e-05
[2019-07-11 09:29:00] Ep. 7 : Up. 316000 : Sen. 13,560,696 : Cost 2.42599940 : Time 130.02s : 33242.39 words/s : L.r. 6.7505e-05
[2019-07-11 09:31:10] Ep. 7 : Up. 316500 : Sen. 13,745,333 : Cost 2.38830376 : Time 129.85s : 34051.82 words/s : L.r. 6.7452e-05
[2019-07-11 09:33:20] Ep. 7 : Up. 317000 : Sen. 13,923,182 : Cost 2.49518561 : Time 129.89s : 34146.06 words/s : L.r. 6.7399e-05
[2019-07-11 09:35:30] Ep. 7 : Up. 317500 : Sen. 14,099,233 : Cost 2.48772359 : Time 129.99s : 34001.24 words/s : L.r. 6.7346e-05
[2019-07-11 09:37:39] Ep. 7 : Up. 318000 : Sen. 14,274,226 : Cost 2.45881152 : Time 129.90s : 33714.92 words/s : L.r. 6.7293e-05
[2019-07-11 09:39:49] Ep. 7 : Up. 318500 : Sen. 14,451,890 : Cost 2.42994189 : Time 129.56s : 33923.43 words/s : L.r. 6.7240e-05
[2019-07-11 09:41:58] Ep. 7 : Up. 319000 : Sen. 14,627,163 : Cost 2.45994973 : Time 128.89s : 33935.97 words/s : L.r. 6.7187e-05
[2019-07-11 09:44:07] Ep. 7 : Up. 319500 : Sen. 14,810,810 : Cost 2.46260619 : Time 129.18s : 33813.23 words/s : L.r. 6.7135e-05
[2019-07-11 09:46:17] Ep. 7 : Up. 320000 : Sen. 14,992,086 : Cost 2.45780754 : Time 129.91s : 34060.51 words/s : L.r. 6.7082e-05
[2019-07-11 09:46:17] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 09:46:23] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 09:46:30] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 09:46:43] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 09:46:48] [valid] Ep. 7 : Up. 320000 : ce-mean-words : 1.22436 : new best
[2019-07-11 09:46:49] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 09:46:54] [valid] Ep. 7 : Up. 320000 : perplexity : 3.40199 : new best
[2019-07-11 09:47:32] [valid] Ep. 7 : Up. 320000 : translation : 37.06 : stalled 24 times (last best: 44.43)
[2019-07-11 09:49:43] Ep. 7 : Up. 320500 : Sen. 15,169,970 : Cost 2.46968007 : Time 205.79s : 21357.28 words/s : L.r. 6.7030e-05
[2019-07-11 09:51:53] Ep. 7 : Up. 321000 : Sen. 15,346,804 : Cost 2.46402478 : Time 129.76s : 33902.45 words/s : L.r. 6.6977e-05
[2019-07-11 09:54:02] Ep. 7 : Up. 321500 : Sen. 15,527,263 : Cost 2.46278501 : Time 129.74s : 33841.15 words/s : L.r. 6.6925e-05
[2019-07-11 09:56:12] Ep. 7 : Up. 322000 : Sen. 15,706,626 : Cost 2.43146038 : Time 129.44s : 33904.41 words/s : L.r. 6.6873e-05
[2019-07-11 09:58:21] Ep. 7 : Up. 322500 : Sen. 15,888,920 : Cost 2.44790554 : Time 129.74s : 33951.83 words/s : L.r. 6.6822e-05
[2019-07-11 10:00:31] Ep. 7 : Up. 323000 : Sen. 16,067,272 : Cost 2.43590355 : Time 129.48s : 33951.64 words/s : L.r. 6.6770e-05
[2019-07-11 10:02:40] Ep. 7 : Up. 323500 : Sen. 16,250,156 : Cost 2.44749165 : Time 128.91s : 33729.80 words/s : L.r. 6.6718e-05
[2019-07-11 10:04:49] Ep. 7 : Up. 324000 : Sen. 16,419,367 : Cost 2.50333881 : Time 129.24s : 33740.74 words/s : L.r. 6.6667e-05
[2019-07-11 10:06:23] Seen 16548172 samples
[2019-07-11 10:06:23] Starting epoch 8
[2019-07-11 10:06:23] [data] Shuffling data
[2019-07-11 10:06:36] [data] Done reading 19122526 sentences
[2019-07-11 10:08:21] [data] Done shuffling 19122526 sentences to temp files
[2019-07-11 10:09:36] Ep. 8 : Up. 324500 : Sen. 51,558 : Cost 2.43732166 : Time 287.13s : 15304.75 words/s : L.r. 6.6615e-05
[2019-07-11 10:11:44] Ep. 8 : Up. 325000 : Sen. 225,317 : Cost 2.46326995 : Time 128.14s : 33853.84 words/s : L.r. 6.6564e-05
[2019-07-11 10:11:44] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 10:11:51] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 10:11:57] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 10:12:14] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 10:12:19] [valid] Ep. 8 : Up. 325000 : ce-mean-words : 1.22322 : new best
[2019-07-11 10:12:20] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 10:12:24] [valid] Ep. 8 : Up. 325000 : perplexity : 3.39812 : new best
[2019-07-11 10:13:02] [valid] Ep. 8 : Up. 325000 : translation : 37.74 : stalled 25 times (last best: 44.43)
[2019-07-11 10:15:13] Ep. 8 : Up. 325500 : Sen. 403,853 : Cost 2.46253324 : Time 208.92s : 21205.05 words/s : L.r. 6.6513e-05
[2019-07-11 10:17:23] Ep. 8 : Up. 326000 : Sen. 584,615 : Cost 2.42141056 : Time 129.32s : 34218.49 words/s : L.r. 6.6462e-05
[2019-07-11 10:19:32] Ep. 8 : Up. 326500 : Sen. 761,398 : Cost 2.44734097 : Time 128.95s : 34120.83 words/s : L.r. 6.6411e-05
[2019-07-11 10:21:40] Ep. 8 : Up. 327000 : Sen. 934,896 : Cost 2.42718053 : Time 128.39s : 34100.03 words/s : L.r. 6.6360e-05
[2019-07-11 10:23:48] Ep. 8 : Up. 327500 : Sen. 1,123,028 : Cost 2.42800879 : Time 127.92s : 33826.08 words/s : L.r. 6.6309e-05
[2019-07-11 10:25:57] Ep. 8 : Up. 328000 : Sen. 1,310,007 : Cost 2.44487810 : Time 129.14s : 34171.51 words/s : L.r. 6.6259e-05
[2019-07-11 10:28:06] Ep. 8 : Up. 328500 : Sen. 1,485,331 : Cost 2.44713831 : Time 129.08s : 34076.52 words/s : L.r. 6.6208e-05
[2019-07-11 10:30:16] Ep. 8 : Up. 329000 : Sen. 1,658,381 : Cost 2.45584655 : Time 130.11s : 34397.99 words/s : L.r. 6.6158e-05
[2019-07-11 10:32:25] Ep. 8 : Up. 329500 : Sen. 1,839,041 : Cost 2.43134022 : Time 128.53s : 33700.89 words/s : L.r. 6.6108e-05
[2019-07-11 10:34:34] Ep. 8 : Up. 330000 : Sen. 2,013,998 : Cost 2.43095469 : Time 129.65s : 34029.33 words/s : L.r. 6.6058e-05
[2019-07-11 10:34:34] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 10:34:40] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 10:34:47] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 10:35:00] [valid] Ep. 8 : Up. 330000 : ce-mean-words : 1.22346 : stalled 1 times (last best: 1.22322)
[2019-07-11 10:35:01] [valid] Ep. 8 : Up. 330000 : perplexity : 3.39893 : stalled 1 times (last best: 3.39812)
[2019-07-11 10:35:39] [valid] Ep. 8 : Up. 330000 : translation : 41.11 : stalled 26 times (last best: 44.43)
[2019-07-11 10:37:50] Ep. 8 : Up. 330500 : Sen. 2,197,024 : Cost 2.42695737 : Time 195.13s : 22607.16 words/s : L.r. 6.6008e-05
[2019-07-11 10:39:59] Ep. 8 : Up. 331000 : Sen. 2,369,833 : Cost 2.39849448 : Time 129.64s : 34109.74 words/s : L.r. 6.5958e-05
[2019-07-11 10:42:08] Ep. 8 : Up. 331500 : Sen. 2,546,922 : Cost 2.46115208 : Time 129.06s : 34104.74 words/s : L.r. 6.5908e-05
[2019-07-11 10:44:17] Ep. 8 : Up. 332000 : Sen. 2,722,533 : Cost 2.48055196 : Time 128.66s : 34094.12 words/s : L.r. 6.5859e-05
[2019-07-11 10:46:26] Ep. 8 : Up. 332500 : Sen. 2,899,171 : Cost 2.43771362 : Time 128.77s : 34051.57 words/s : L.r. 6.5809e-05
[2019-07-11 10:48:34] Ep. 8 : Up. 333000 : Sen. 3,083,609 : Cost 2.47241616 : Time 128.09s : 33838.20 words/s : L.r. 6.5760e-05
[2019-07-11 10:50:43] Ep. 8 : Up. 333500 : Sen. 3,256,509 : Cost 2.41947913 : Time 128.88s : 34129.32 words/s : L.r. 6.5710e-05
[2019-07-11 10:52:51] Ep. 8 : Up. 334000 : Sen. 3,432,101 : Cost 2.45103502 : Time 128.59s : 33962.56 words/s : L.r. 6.5661e-05
[2019-07-11 10:55:01] Ep. 8 : Up. 334500 : Sen. 3,612,367 : Cost 2.44166303 : Time 129.36s : 34032.38 words/s : L.r. 6.5612e-05
[2019-07-11 10:57:10] Ep. 8 : Up. 335000 : Sen. 3,794,678 : Cost 2.44151044 : Time 129.20s : 34319.34 words/s : L.r. 6.5563e-05
[2019-07-11 10:57:10] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 10:57:16] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 10:57:23] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 10:57:36] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 10:57:40] [valid] Ep. 8 : Up. 335000 : ce-mean-words : 1.22298 : new best
[2019-07-11 10:57:41] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 10:57:46] [valid] Ep. 8 : Up. 335000 : perplexity : 3.3973 : new best
[2019-07-11 10:58:23] [valid] Ep. 8 : Up. 335000 : translation : 43.24 : stalled 27 times (last best: 44.43)
[2019-07-11 11:00:32] Ep. 8 : Up. 335500 : Sen. 3,981,090 : Cost 2.45202208 : Time 202.42s : 21628.72 words/s : L.r. 6.5514e-05
[2019-07-11 11:02:41] Ep. 8 : Up. 336000 : Sen. 4,157,174 : Cost 2.44304800 : Time 128.73s : 33950.87 words/s : L.r. 6.5465e-05
[2019-07-11 11:04:50] Ep. 8 : Up. 336500 : Sen. 4,339,655 : Cost 2.44398046 : Time 129.34s : 34177.53 words/s : L.r. 6.5417e-05
[2019-07-11 11:07:00] Ep. 8 : Up. 337000 : Sen. 4,518,453 : Cost 2.45412302 : Time 129.45s : 34161.07 words/s : L.r. 6.5368e-05
[2019-07-11 11:09:09] Ep. 8 : Up. 337500 : Sen. 4,695,780 : Cost 2.45981050 : Time 129.13s : 34231.03 words/s : L.r. 6.5320e-05
[2019-07-11 11:11:17] Ep. 8 : Up. 338000 : Sen. 4,875,479 : Cost 2.44544029 : Time 128.52s : 34009.24 words/s : L.r. 6.5271e-05
[2019-07-11 11:13:25] Ep. 8 : Up. 338500 : Sen. 5,053,149 : Cost 2.43007851 : Time 127.79s : 33878.33 words/s : L.r. 6.5223e-05
[2019-07-11 11:15:34] Ep. 8 : Up. 339000 : Sen. 5,232,251 : Cost 2.47312427 : Time 128.44s : 33953.14 words/s : L.r. 6.5175e-05
[2019-07-11 11:17:43] Ep. 8 : Up. 339500 : Sen. 5,414,459 : Cost 2.42659354 : Time 129.76s : 34247.89 words/s : L.r. 6.5127e-05
[2019-07-11 11:19:52] Ep. 8 : Up. 340000 : Sen. 5,591,409 : Cost 2.45237541 : Time 128.58s : 34274.99 words/s : L.r. 6.5079e-05
[2019-07-11 11:19:52] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 11:19:58] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 11:20:05] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 11:20:20] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 11:20:24] [valid] Ep. 8 : Up. 340000 : ce-mean-words : 1.22227 : new best
[2019-07-11 11:20:25] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 11:20:32] [valid] Ep. 8 : Up. 340000 : perplexity : 3.3949 : new best
[2019-07-11 11:21:09] [valid] Ep. 8 : Up. 340000 : translation : 43.82 : stalled 28 times (last best: 44.43)
[2019-07-11 11:23:18] Ep. 8 : Up. 340500 : Sen. 5,762,835 : Cost 2.43968868 : Time 205.94s : 21254.55 words/s : L.r. 6.5031e-05
[2019-07-11 11:25:26] Ep. 8 : Up. 341000 : Sen. 5,942,776 : Cost 2.42030025 : Time 128.29s : 34334.90 words/s : L.r. 6.4984e-05
[2019-07-11 11:27:34] Ep. 8 : Up. 341500 : Sen. 6,127,705 : Cost 2.40402722 : Time 128.28s : 34408.60 words/s : L.r. 6.4936e-05
[2019-07-11 11:29:44] Ep. 8 : Up. 342000 : Sen. 6,306,911 : Cost 2.46148181 : Time 129.10s : 34510.79 words/s : L.r. 6.4889e-05
[2019-07-11 11:31:52] Ep. 8 : Up. 342500 : Sen. 6,485,592 : Cost 2.44801831 : Time 128.50s : 34551.32 words/s : L.r. 6.4841e-05
[2019-07-11 11:34:00] Ep. 8 : Up. 343000 : Sen. 6,659,434 : Cost 2.42244220 : Time 127.89s : 34049.41 words/s : L.r. 6.4794e-05
[2019-07-11 11:36:08] Ep. 8 : Up. 343500 : Sen. 6,835,619 : Cost 2.44478202 : Time 127.97s : 33869.93 words/s : L.r. 6.4747e-05
[2019-07-11 11:38:17] Ep. 8 : Up. 344000 : Sen. 7,012,268 : Cost 2.47442627 : Time 128.77s : 33757.05 words/s : L.r. 6.4700e-05
[2019-07-11 11:40:26] Ep. 8 : Up. 344500 : Sen. 7,188,435 : Cost 2.46984887 : Time 129.61s : 33878.65 words/s : L.r. 6.4653e-05
[2019-07-11 11:42:34] Ep. 8 : Up. 345000 : Sen. 7,366,660 : Cost 2.47400212 : Time 128.17s : 34364.77 words/s : L.r. 6.4606e-05
[2019-07-11 11:42:34] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 11:42:41] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 11:42:47] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 11:43:00] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 11:43:05] [valid] Ep. 8 : Up. 345000 : ce-mean-words : 1.22164 : new best
[2019-07-11 11:43:06] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 11:43:11] [valid] Ep. 8 : Up. 345000 : perplexity : 3.39275 : new best
[2019-07-11 11:43:46] [valid] Ep. 8 : Up. 345000 : translation : 43.38 : stalled 29 times (last best: 44.43)
[2019-07-11 11:45:58] Ep. 8 : Up. 345500 : Sen. 7,545,057 : Cost 2.45606589 : Time 203.88s : 21683.20 words/s : L.r. 6.4559e-05
[2019-07-11 11:48:09] Ep. 8 : Up. 346000 : Sen. 7,726,538 : Cost 2.40972590 : Time 131.00s : 33523.19 words/s : L.r. 6.4512e-05
[2019-07-11 11:50:21] Ep. 8 : Up. 346500 : Sen. 7,907,248 : Cost 2.42267823 : Time 132.09s : 33278.49 words/s : L.r. 6.4466e-05
[2019-07-11 11:52:33] Ep. 8 : Up. 347000 : Sen. 8,085,607 : Cost 2.45233440 : Time 131.12s : 33193.13 words/s : L.r. 6.4419e-05
[2019-07-11 11:54:46] Ep. 8 : Up. 347500 : Sen. 8,262,395 : Cost 2.47753072 : Time 133.35s : 33055.95 words/s : L.r. 6.4373e-05
[2019-07-11 11:56:59] Ep. 8 : Up. 348000 : Sen. 8,442,698 : Cost 2.45243669 : Time 133.20s : 32800.96 words/s : L.r. 6.4327e-05
[2019-07-11 11:59:12] Ep. 8 : Up. 348500 : Sen. 8,620,991 : Cost 2.41887975 : Time 132.62s : 33028.59 words/s : L.r. 6.4281e-05
[2019-07-11 12:01:24] Ep. 8 : Up. 349000 : Sen. 8,800,571 : Cost 2.43398547 : Time 131.97s : 33151.01 words/s : L.r. 6.4235e-05
[2019-07-11 12:03:36] Ep. 8 : Up. 349500 : Sen. 8,979,328 : Cost 2.44159579 : Time 132.52s : 33446.41 words/s : L.r. 6.4189e-05
[2019-07-11 12:05:47] Ep. 8 : Up. 350000 : Sen. 9,152,876 : Cost 2.41884255 : Time 130.48s : 33914.64 words/s : L.r. 6.4143e-05
[2019-07-11 12:05:47] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 12:05:53] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 12:05:59] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 12:06:13] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 12:06:18] [valid] Ep. 8 : Up. 350000 : ce-mean-words : 1.22086 : new best
[2019-07-11 12:06:18] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 12:06:23] [valid] Ep. 8 : Up. 350000 : perplexity : 3.3901 : new best
[2019-07-11 12:07:01] [valid] Ep. 8 : Up. 350000 : translation : 43.18 : stalled 30 times (last best: 44.43)
[2019-07-11 12:09:14] Ep. 8 : Up. 350500 : Sen. 9,333,720 : Cost 2.48787761 : Time 206.99s : 21146.91 words/s : L.r. 6.4097e-05
[2019-07-11 12:11:25] Ep. 8 : Up. 351000 : Sen. 9,513,007 : Cost 2.41075206 : Time 130.89s : 33298.32 words/s : L.r. 6.4051e-05
[2019-07-11 12:13:36] Ep. 8 : Up. 351500 : Sen. 9,691,999 : Cost 2.47850418 : Time 131.46s : 33366.04 words/s : L.r. 6.4006e-05
[2019-07-11 12:15:50] Ep. 8 : Up. 352000 : Sen. 9,873,304 : Cost 2.44842839 : Time 133.77s : 33143.98 words/s : L.r. 6.3960e-05
[2019-07-11 12:18:03] Ep. 8 : Up. 352500 : Sen. 10,052,094 : Cost 2.43224168 : Time 133.49s : 32886.44 words/s : L.r. 6.3915e-05
[2019-07-11 12:20:16] Ep. 8 : Up. 353000 : Sen. 10,223,602 : Cost 2.45727348 : Time 132.76s : 33076.23 words/s : L.r. 6.3870e-05
[2019-07-11 12:22:38] Ep. 8 : Up. 353500 : Sen. 10,404,208 : Cost 2.47150731 : Time 141.79s : 31093.80 words/s : L.r. 6.3824e-05
[2019-07-11 12:24:53] Ep. 8 : Up. 354000 : Sen. 10,580,020 : Cost 2.43652177 : Time 135.02s : 32491.75 words/s : L.r. 6.3779e-05
[2019-07-11 12:27:08] Ep. 8 : Up. 354500 : Sen. 10,753,526 : Cost 2.43746495 : Time 135.10s : 32316.37 words/s : L.r. 6.3734e-05
[2019-07-11 12:29:27] Ep. 8 : Up. 355000 : Sen. 10,939,940 : Cost 2.43869781 : Time 139.04s : 31874.64 words/s : L.r. 6.3689e-05
[2019-07-11 12:29:27] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 12:29:34] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 12:29:42] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 12:29:57] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 12:30:02] [valid] Ep. 8 : Up. 355000 : ce-mean-words : 1.22025 : new best
[2019-07-11 12:30:03] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 12:30:08] [valid] Ep. 8 : Up. 355000 : perplexity : 3.38805 : new best
[2019-07-11 12:30:48] [valid] Ep. 8 : Up. 355000 : translation : 43.19 : stalled 31 times (last best: 44.43)
[2019-07-11 12:33:07] Ep. 8 : Up. 355500 : Sen. 11,119,692 : Cost 2.46338677 : Time 220.07s : 19754.07 words/s : L.r. 6.3645e-05
[2019-07-11 12:35:19] Ep. 8 : Up. 356000 : Sen. 11,298,994 : Cost 2.43472219 : Time 131.61s : 33196.61 words/s : L.r. 6.3600e-05
[2019-07-11 12:37:31] Ep. 8 : Up. 356500 : Sen. 11,477,017 : Cost 2.42622876 : Time 132.45s : 32983.13 words/s : L.r. 6.3555e-05
[2019-07-11 12:39:45] Ep. 8 : Up. 357000 : Sen. 11,653,044 : Cost 2.43047905 : Time 134.29s : 32902.05 words/s : L.r. 6.3511e-05
[2019-07-11 12:41:59] Ep. 8 : Up. 357500 : Sen. 11,833,228 : Cost 2.44616866 : Time 133.69s : 33000.09 words/s : L.r. 6.3466e-05
[2019-07-11 12:44:13] Ep. 8 : Up. 358000 : Sen. 12,014,000 : Cost 2.45337129 : Time 133.79s : 33153.84 words/s : L.r. 6.3422e-05
[2019-07-11 12:46:26] Ep. 8 : Up. 358500 : Sen. 12,191,706 : Cost 2.44985437 : Time 133.07s : 33358.94 words/s : L.r. 6.3378e-05
[2019-07-11 12:48:38] Ep. 8 : Up. 359000 : Sen. 12,370,814 : Cost 2.42991877 : Time 131.69s : 33026.10 words/s : L.r. 6.3334e-05
[2019-07-11 12:50:50] Ep. 8 : Up. 359500 : Sen. 12,546,241 : Cost 2.45351911 : Time 132.14s : 33471.07 words/s : L.r. 6.3290e-05
[2019-07-11 12:53:04] Ep. 8 : Up. 360000 : Sen. 12,727,505 : Cost 2.46908689 : Time 133.99s : 32309.80 words/s : L.r. 6.3246e-05
[2019-07-11 12:53:04] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 12:53:11] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 12:53:19] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 12:53:34] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 12:53:39] [valid] Ep. 8 : Up. 360000 : ce-mean-words : 1.2192 : new best
[2019-07-11 12:53:40] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 12:53:45] [valid] Ep. 8 : Up. 360000 : perplexity : 3.38447 : new best
[2019-07-11 12:54:26] [valid] Ep. 8 : Up. 360000 : translation : 43.19 : stalled 32 times (last best: 44.43)
[2019-07-11 12:56:42] Ep. 8 : Up. 360500 : Sen. 12,904,974 : Cost 2.44392133 : Time 217.81s : 20379.72 words/s : L.r. 6.3202e-05
[2019-07-11 12:58:55] Ep. 8 : Up. 361000 : Sen. 13,088,122 : Cost 2.43295956 : Time 133.47s : 33168.33 words/s : L.r. 6.3158e-05
[2019-07-11 13:01:09] Ep. 8 : Up. 361500 : Sen. 13,259,672 : Cost 2.46759892 : Time 133.43s : 32702.11 words/s : L.r. 6.3114e-05
[2019-07-11 13:03:21] Ep. 8 : Up. 362000 : Sen. 13,439,930 : Cost 2.41072321 : Time 132.98s : 33254.18 words/s : L.r. 6.3071e-05
[2019-07-11 13:05:34] Ep. 8 : Up. 362500 : Sen. 13,624,021 : Cost 2.43313313 : Time 132.40s : 33266.10 words/s : L.r. 6.3027e-05
[2019-07-11 13:07:47] Ep. 8 : Up. 363000 : Sen. 13,801,584 : Cost 2.44911289 : Time 132.61s : 33165.50 words/s : L.r. 6.2984e-05
[2019-07-11 13:09:58] Ep. 8 : Up. 363500 : Sen. 13,980,478 : Cost 2.47581458 : Time 131.89s : 33083.32 words/s : L.r. 6.2940e-05
[2019-07-11 13:12:13] Ep. 8 : Up. 364000 : Sen. 14,160,029 : Cost 2.43809199 : Time 135.03s : 32730.89 words/s : L.r. 6.2897e-05
[2019-07-11 13:14:31] Ep. 8 : Up. 364500 : Sen. 14,336,862 : Cost 2.47725153 : Time 137.24s : 31861.68 words/s : L.r. 6.2854e-05
[2019-07-11 13:16:47] Ep. 8 : Up. 365000 : Sen. 14,512,909 : Cost 2.41655564 : Time 135.94s : 32316.58 words/s : L.r. 6.2811e-05
[2019-07-11 13:16:47] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 13:16:54] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 13:17:02] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 13:17:17] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 13:17:22] [valid] Ep. 8 : Up. 365000 : ce-mean-words : 1.21792 : new best
[2019-07-11 13:17:23] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 13:17:29] [valid] Ep. 8 : Up. 365000 : perplexity : 3.38014 : new best
[2019-07-11 13:18:11] [valid] Ep. 8 : Up. 365000 : translation : 43.65 : stalled 33 times (last best: 44.43)
[2019-07-11 13:20:24] Ep. 8 : Up. 365500 : Sen. 14,691,479 : Cost 2.47349024 : Time 217.36s : 20229.86 words/s : L.r. 6.2768e-05
[2019-07-11 13:22:35] Ep. 8 : Up. 366000 : Sen. 14,876,558 : Cost 2.44255924 : Time 130.75s : 33403.57 words/s : L.r. 6.2725e-05
[2019-07-11 13:24:47] Ep. 8 : Up. 366500 : Sen. 15,050,784 : Cost 2.43653607 : Time 132.32s : 33433.56 words/s : L.r. 6.2682e-05
[2019-07-11 13:26:59] Ep. 8 : Up. 367000 : Sen. 15,234,006 : Cost 2.41268492 : Time 131.68s : 33279.81 words/s : L.r. 6.2639e-05
[2019-07-11 13:29:10] Ep. 8 : Up. 367500 : Sen. 15,412,486 : Cost 2.45756674 : Time 131.76s : 33408.72 words/s : L.r. 6.2597e-05
[2019-07-11 13:31:21] Ep. 8 : Up. 368000 : Sen. 15,590,740 : Cost 2.43555999 : Time 130.60s : 33228.95 words/s : L.r. 6.2554e-05
[2019-07-11 13:33:33] Ep. 8 : Up. 368500 : Sen. 15,768,098 : Cost 2.45253134 : Time 131.54s : 33545.04 words/s : L.r. 6.2512e-05
[2019-07-11 13:35:46] Ep. 8 : Up. 369000 : Sen. 15,944,914 : Cost 2.44944477 : Time 133.04s : 33135.67 words/s : L.r. 6.2470e-05
[2019-07-11 13:38:01] Ep. 8 : Up. 369500 : Sen. 16,122,886 : Cost 2.38834929 : Time 135.51s : 32263.34 words/s : L.r. 6.2427e-05
[2019-07-11 13:40:15] Ep. 8 : Up. 370000 : Sen. 16,300,484 : Cost 2.44116592 : Time 133.42s : 33185.98 words/s : L.r. 6.2385e-05
[2019-07-11 13:40:15] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 13:40:21] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 13:40:28] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
[2019-07-11 13:40:42] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 13:40:47] [valid] Ep. 8 : Up. 370000 : ce-mean-words : 1.21669 : new best
[2019-07-11 13:40:48] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 13:40:53] [valid] Ep. 8 : Up. 370000 : perplexity : 3.37599 : new best
[2019-07-11 13:41:30] [valid] Ep. 8 : Up. 370000 : translation : 43.22 : stalled 34 times (last best: 44.43)
[2019-07-11 13:43:44] Ep. 8 : Up. 370500 : Sen. 16,478,380 : Cost 2.49380064 : Time 209.45s : 20736.89 words/s : L.r. 6.2343e-05
[2019-07-11 13:44:38] Seen 16548172 samples
[2019-07-11 13:44:38] Starting epoch 9
[2019-07-11 13:44:38] Training finished
[2019-07-11 13:44:40] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-ce-mean-words.npz
[2019-07-11 13:44:45] [valid] Ep. 9 : Up. 370699 : ce-mean-words : 1.21637 : new best
[2019-07-11 13:44:46] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.best-perplexity.npz
[2019-07-11 13:44:51] [valid] Ep. 9 : Up. 370699 : perplexity : 3.3749 : new best
[2019-07-11 13:45:36] [valid] Ep. 9 : Up. 370699 : translation : 42.48 : stalled 35 times (last best: 44.43)
[2019-07-11 13:45:38] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.orig.npz
[2019-07-11 13:45:45] Saving model weights and runtime parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz
[2019-07-11 13:45:52] Saving Adam parameters to models/wmt2017-transformer-de-en/model/model/ens2/model.npz.optimizer.npz
